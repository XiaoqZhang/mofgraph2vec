2023-02-07 18:16:03.480 | DEBUG    | mofgraph2vec.trainer.sweep:sweep:19 - No sweep id provided, creating new sweep
wandb: WARNING Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.
wandb: WARNING To avoid this, please fix the sweep config schema violations below:
wandb: WARNING   Violation 1. model.sklearn.reg_alpha uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.
wandb: WARNING   Violation 2. model.sklearn.learning_rate uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.
wandb: WARNING   Violation 3. model.sklearn.reg_lambda uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.
wandb: WARNING   Violation 4. model.gensim.alpha uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.
Create sweep with ID: xx96mndu
Sweep URL: https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
[2023-02-07 18:16:05,588][wandb.agents.pyagent][INFO] - Starting sweep agent: entity=None, project=None, count=100
wandb: Agent Starting Run: k6y2xl3o with config:
wandb: 	data.data.wl_step: 1
wandb: 	data.nn.batch_size: 302
wandb: 	model.gensim.alpha: 0.10616763409043747
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.6655196875984346
wandb: 	model.gensim.vector_size: 96
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.061865355675481744
wandb: 	model.sklearn.max_depth: 62
wandb: 	model.sklearn.min_child_weight: 0.07981429211493571
wandb: 	model.sklearn.n_estimators: 2370
wandb: 	model.sklearn.num_leaves: 207
wandb: 	model.sklearn.reg_alpha: 0.08600058437801261
wandb: 	model.sklearn.reg_lambda: 0.6550116156553033
wandb: 	model.sklearn.subsample: 0.44572493014509346
wandb: Currently logged in as: xiaoqiz. Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181607-k6y2xl3o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/k6y2xl3o
2023-02-07 18:16:38.370 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 1 for sweep.
2023-02-07 18:16:38.370 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 302 for sweep.
2023-02-07 18:16:38.371 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.10616763409043747 for sweep.
2023-02-07 18:16:38.371 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:16:38.371 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 18:16:38.372 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6655196875984346 for sweep.
2023-02-07 18:16:38.372 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 96 for sweep.
2023-02-07 18:16:38.372 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 18:16:38.372 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.061865355675481744 for sweep.
2023-02-07 18:16:38.372 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 62 for sweep.
2023-02-07 18:16:38.374 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.07981429211493571 for sweep.
2023-02-07 18:16:38.374 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2370 for sweep.
2023-02-07 18:16:38.374 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 207 for sweep.
2023-02-07 18:16:38.374 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.08600058437801261 for sweep.
2023-02-07 18:16:38.374 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.6550116156553033 for sweep.
2023-02-07 18:16:38.375 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.44572493014509346 for sweep.
2023-02-07 18:16:38.375 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:16:38.482 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 1}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181607-k6y2xl3o/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 302, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 96, 'window': 8, 'min_count': 6, 'dm': 1, 'sample': 0.6655196875984346, 'workers': 4, 'alpha': 0.10616763409043747, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2370, 'max_depth': 62, 'num_leaves': 207, 'reg_alpha': 0.08600058437801261, 'reg_lambda': 0.6550116156553033, 'subsample': 0.44572493014509346, 'min_child_weight': 0.07981429211493571, 'n_jobs': 4, 'learning_rate': 0.061865355675481744}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 28/3257 [00:00<00:11, 279.20it/s]  2%|‚ñè         | 56/3257 [00:00<00:11, 275.52it/s]  3%|‚ñé         | 90/3257 [00:00<00:10, 295.65it/s]  4%|‚ñé         | 120/3257 [00:00<00:17, 175.65it/s]  5%|‚ñç         | 151/3257 [00:00<00:14, 208.00it/s]  5%|‚ñå         | 179/3257 [00:00<00:13, 224.90it/s]  6%|‚ñã         | 211/3257 [00:00<00:12, 249.05it/s]  8%|‚ñä         | 245/3257 [00:00<00:11, 271.67it/s]  8%|‚ñä         | 276/3257 [00:01<00:10, 281.95it/s]  9%|‚ñâ         | 308/3257 [00:01<00:10, 290.43it/s] 10%|‚ñà         | 339/3257 [00:01<00:10, 291.06it/s] 11%|‚ñà‚ñè        | 369/3257 [00:01<00:09, 289.52it/s] 12%|‚ñà‚ñè        | 399/3257 [00:01<00:10, 279.70it/s] 13%|‚ñà‚ñé        | 428/3257 [00:01<00:10, 271.62it/s] 14%|‚ñà‚ñç        | 458/3257 [00:01<00:10, 279.38it/s] 15%|‚ñà‚ñç        | 488/3257 [00:01<00:09, 283.70it/s] 16%|‚ñà‚ñå        | 521/3257 [00:01<00:09, 296.70it/s] 17%|‚ñà‚ñã        | 551/3257 [00:02<00:09, 292.15it/s] 18%|‚ñà‚ñä        | 581/3257 [00:02<00:09, 274.22it/s] 19%|‚ñà‚ñâ        | 615/3257 [00:02<00:09, 289.89it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:02<00:09, 286.08it/s] 21%|‚ñà‚ñà        | 675/3257 [00:02<00:08, 287.64it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:02<00:09, 283.24it/s] 23%|‚ñà‚ñà‚ñé       | 734/3257 [00:02<00:08, 287.48it/s] 23%|‚ñà‚ñà‚ñé       | 763/3257 [00:02<00:08, 288.20it/s] 24%|‚ñà‚ñà‚ñç       | 792/3257 [00:02<00:08, 287.46it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:03<00:08, 288.94it/s] 26%|‚ñà‚ñà‚ñå       | 852/3257 [00:03<00:08, 277.23it/s] 27%|‚ñà‚ñà‚ñã       | 880/3257 [00:03<00:08, 274.12it/s] 28%|‚ñà‚ñà‚ñä       | 912/3257 [00:03<00:08, 287.18it/s] 29%|‚ñà‚ñà‚ñâ       | 941/3257 [00:03<00:08, 287.47it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:03<00:07, 290.70it/s] 31%|‚ñà‚ñà‚ñà       | 1002/3257 [00:03<00:07, 290.89it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1032/3257 [00:03<00:07, 283.30it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1061/3257 [00:03<00:07, 280.99it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:03<00:07, 285.34it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1121/3257 [00:04<00:07, 288.65it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1150/3257 [00:04<00:07, 285.79it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1180/3257 [00:04<00:07, 287.53it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1209/3257 [00:04<00:07, 275.28it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:04<00:06, 289.05it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:04<00:06, 288.91it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1301/3257 [00:04<00:10, 185.91it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1331/3257 [00:04<00:09, 208.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1362/3257 [00:05<00:08, 230.66it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1389/3257 [00:05<00:07, 238.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1425/3257 [00:05<00:06, 269.22it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1461/3257 [00:05<00:06, 291.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1494/3257 [00:05<00:05, 299.57it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1526/3257 [00:05<00:05, 296.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1557/3257 [00:05<00:05, 292.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1588/3257 [00:05<00:05, 295.89it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:05<00:05, 298.39it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:06<00:05, 291.94it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1680/3257 [00:06<00:05, 291.00it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1710/3257 [00:06<00:05, 287.66it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1739/3257 [00:06<00:05, 276.48it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:06<00:05, 285.21it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:06<00:04, 294.32it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1833/3257 [00:06<00:04, 289.24it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1868/3257 [00:06<00:04, 305.22it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:06<00:04, 306.56it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:06<00:04, 310.32it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1971/3257 [00:07<00:03, 333.88it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2005/3257 [00:07<00:03, 324.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2039/3257 [00:07<00:03, 326.64it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2072/3257 [00:07<00:03, 311.54it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2104/3257 [00:07<00:03, 310.43it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:07<00:03, 300.37it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2167/3257 [00:07<00:03, 302.68it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2198/3257 [00:07<00:03, 303.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2229/3257 [00:07<00:03, 297.16it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:08<00:03, 297.34it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2290/3257 [00:08<00:03, 299.47it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2325/3257 [00:08<00:02, 313.81it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2362/3257 [00:08<00:02, 327.87it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:08<00:02, 337.24it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2433/3257 [00:08<00:02, 320.30it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2468/3257 [00:08<00:02, 328.06it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2503/3257 [00:08<00:02, 333.62it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2539/3257 [00:08<00:02, 338.82it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:08<00:02, 321.26it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2607/3257 [00:09<00:02, 324.87it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2643/3257 [00:09<00:01, 333.86it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2677/3257 [00:09<00:01, 327.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2710/3257 [00:09<00:02, 213.09it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2747/3257 [00:09<00:02, 245.27it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:09<00:01, 261.90it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2815/3257 [00:09<00:01, 283.56it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2847/3257 [00:09<00:01, 289.29it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2887/3257 [00:10<00:01, 317.45it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2921/3257 [00:10<00:01, 317.95it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2955/3257 [00:10<00:00, 311.56it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2988/3257 [00:10<00:00, 312.36it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3023/3257 [00:10<00:00, 321.94it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3061/3257 [00:10<00:00, 338.05it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3096/3257 [00:10<00:00, 335.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3132/3257 [00:10<00:00, 341.21it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3167/3257 [00:10<00:00, 328.96it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3201/3257 [00:11<00:00, 324.63it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3235/3257 [00:11<00:00, 327.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:11<00:00, 290.25it/s]
2023-02-07 18:16:57.226 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:16:57,253][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d96,n5,w8,mc6,s0.66552,t4>', 'datetime': '2023-02-07T18:16:57.227931', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:16:57,253][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:16:57,254][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:16:57,396][gensim.models.doc2vec][INFO] - collected 924 word types and 3257 unique tags from a corpus of 3257 examples and 1455748 words
[2023-02-07 18:16:57,396][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:16:57,398][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 585 unique words (63.31% of original 924, drops 339)', 'datetime': '2023-02-07T18:16:57.398624', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:16:57,398][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 1454759 word corpus (99.93% of original 1455748, drops 989)', 'datetime': '2023-02-07T18:16:57.398890', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:16:57,401][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 924 items
[2023-02-07 18:16:57,401][gensim.models.word2vec][INFO] - sample=0.66552 downsamples 0 most-common words
[2023-02-07 18:16:57,401][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454759 word corpus (100.0%% of prior 1454759)', 'datetime': '2023-02-07T18:16:57.401863', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:16:57,405][gensim.models.word2vec][INFO] - estimated required memory for 585 words and 96 dimensions: 2643868 bytes
[2023-02-07 18:16:57,405][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:16:57,407][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 585 vocabulary and 96 features, using sg=0 hs=0 sample=0.6655196875984346 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T18:16:57.407879', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:16:58,036][gensim.models.word2vec][INFO] - EPOCH 0: training on 1455748 raw words (1458016 effective words) took 0.6s, 2332317 effective words/s
[2023-02-07 18:16:58,559][gensim.models.word2vec][INFO] - EPOCH 1: training on 1455748 raw words (1458016 effective words) took 0.5s, 2794275 effective words/s
[2023-02-07 18:16:59,033][gensim.models.word2vec][INFO] - EPOCH 2: training on 1455748 raw words (1458016 effective words) took 0.5s, 3087451 effective words/s
[2023-02-07 18:16:59,482][gensim.models.word2vec][INFO] - EPOCH 3: training on 1455748 raw words (1458016 effective words) took 0.4s, 3250745 effective words/s
[2023-02-07 18:16:59,922][gensim.models.word2vec][INFO] - EPOCH 4: training on 1455748 raw words (1458016 effective words) took 0.4s, 3325005 effective words/s
[2023-02-07 18:17:00,360][gensim.models.word2vec][INFO] - EPOCH 5: training on 1455748 raw words (1458016 effective words) took 0.4s, 3338856 effective words/s
[2023-02-07 18:17:00,996][gensim.models.word2vec][INFO] - EPOCH 6: training on 1455748 raw words (1458016 effective words) took 0.6s, 2294477 effective words/s
[2023-02-07 18:17:01,466][gensim.models.word2vec][INFO] - EPOCH 7: training on 1455748 raw words (1458016 effective words) took 0.5s, 3119139 effective words/s
[2023-02-07 18:17:01,985][gensim.models.word2vec][INFO] - EPOCH 8: training on 1455748 raw words (1458016 effective words) took 0.5s, 2814684 effective words/s
[2023-02-07 18:17:02,509][gensim.models.word2vec][INFO] - EPOCH 9: training on 1455748 raw words (1458016 effective words) took 0.5s, 2785581 effective words/s
[2023-02-07 18:17:03,010][gensim.models.word2vec][INFO] - EPOCH 10: training on 1455748 raw words (1458016 effective words) took 0.5s, 2918222 effective words/s
[2023-02-07 18:17:03,509][gensim.models.word2vec][INFO] - EPOCH 11: training on 1455748 raw words (1458016 effective words) took 0.5s, 2928151 effective words/s
[2023-02-07 18:17:04,018][gensim.models.word2vec][INFO] - EPOCH 12: training on 1455748 raw words (1458016 effective words) took 0.5s, 2870194 effective words/s
[2023-02-07 18:17:04,521][gensim.models.word2vec][INFO] - EPOCH 13: training on 1455748 raw words (1458016 effective words) took 0.5s, 2908079 effective words/s
[2023-02-07 18:17:05,023][gensim.models.word2vec][INFO] - EPOCH 14: training on 1455748 raw words (1458016 effective words) took 0.5s, 2911005 effective words/s
[2023-02-07 18:17:05,023][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 21836220 raw words (21870240 effective words) took 7.6s, 2871759 effective words/s', 'datetime': '2023-02-07T18:17:05.023870', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:17:05.024 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:17:05,766][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181607-k6y2xl3o/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:17:05.766436', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:17:05,767][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:17:05,771][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181607-k6y2xl3o/files/../tmp/embedding_model.pt
2023-02-07 18:17:05.772 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:17:06.921 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:17:07.367 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:17:36.302 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.2435719458656547, 'test_mae': 0.8856553563768147, 'test_r2': -3.9950753131100187}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.0
wandb: percentage 0.36688
wandb:   test_mae 0.88566
wandb:   test_mse 1.24357
wandb:    test_r2 -3.99508
wandb: 
wandb: üöÄ View run cool-sweep-1 at: https://wandb.ai/xiaoqiz/mof2vec/runs/k6y2xl3o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_181607-k6y2xl3o/logs
wandb: Agent Starting Run: btxwn3fy with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 940
wandb: 	model.gensim.alpha: 0.0005090381247757498
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.6470672384656849
wandb: 	model.gensim.vector_size: 391
wandb: 	model.gensim.window: 14
wandb: 	model.sklearn.learning_rate: 0.08684506681256016
wandb: 	model.sklearn.max_depth: 39
wandb: 	model.sklearn.min_child_weight: 0.08907671813611023
wandb: 	model.sklearn.n_estimators: 4129
wandb: 	model.sklearn.num_leaves: 32
wandb: 	model.sklearn.reg_alpha: 0.004411327704643031
wandb: 	model.sklearn.reg_lambda: 0.03766732682670242
wandb: 	model.sklearn.subsample: 0.6414737927701349
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181749-btxwn3fy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/btxwn3fy
2023-02-07 18:17:56.869 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 18:17:56.870 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 940 for sweep.
2023-02-07 18:17:56.870 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0005090381247757498 for sweep.
2023-02-07 18:17:56.871 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:17:56.871 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 18:17:56.871 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6470672384656849 for sweep.
2023-02-07 18:17:56.871 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 391 for sweep.
2023-02-07 18:17:56.872 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 14 for sweep.
2023-02-07 18:17:56.873 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.08684506681256016 for sweep.
2023-02-07 18:17:56.873 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 39 for sweep.
2023-02-07 18:17:56.874 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08907671813611023 for sweep.
2023-02-07 18:17:56.874 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4129 for sweep.
2023-02-07 18:17:56.875 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 32 for sweep.
2023-02-07 18:17:56.875 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004411327704643031 for sweep.
2023-02-07 18:17:56.875 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.03766732682670242 for sweep.
2023-02-07 18:17:56.875 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6414737927701349 for sweep.
2023-02-07 18:17:56.876 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:17:56.880 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181749-btxwn3fy/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 940, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 391, 'window': 14, 'min_count': 5, 'dm': 1, 'sample': 0.6470672384656849, 'workers': 4, 'alpha': 0.0005090381247757498, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4129, 'max_depth': 39, 'num_leaves': 32, 'reg_alpha': 0.004411327704643031, 'reg_lambda': 0.03766732682670242, 'subsample': 0.6414737927701349, 'min_child_weight': 0.08907671813611023, 'n_jobs': 4, 'learning_rate': 0.08684506681256016}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 171.03it/s]  1%|          | 38/3257 [00:00<00:17, 187.34it/s]  2%|‚ñè         | 57/3257 [00:00<00:17, 179.34it/s]  2%|‚ñè         | 79/3257 [00:00<00:16, 191.81it/s]  3%|‚ñé         | 99/3257 [00:00<00:16, 186.78it/s]  4%|‚ñé         | 118/3257 [00:00<00:17, 180.72it/s]  4%|‚ñç         | 138/3257 [00:00<00:16, 186.54it/s]  5%|‚ñç         | 158/3257 [00:00<00:16, 188.74it/s]  5%|‚ñå         | 177/3257 [00:00<00:16, 182.48it/s]  6%|‚ñå         | 197/3257 [00:01<00:16, 187.34it/s]  7%|‚ñã         | 219/3257 [00:01<00:15, 195.45it/s]  7%|‚ñã         | 242/3257 [00:01<00:14, 203.24it/s]  8%|‚ñä         | 263/3257 [00:01<00:15, 193.56it/s]  9%|‚ñâ         | 287/3257 [00:01<00:14, 203.56it/s]  9%|‚ñâ         | 308/3257 [00:01<00:14, 199.56it/s] 10%|‚ñà         | 329/3257 [00:01<00:14, 201.95it/s] 11%|‚ñà         | 350/3257 [00:01<00:14, 195.25it/s] 11%|‚ñà‚ñè        | 372/3257 [00:01<00:14, 200.39it/s] 12%|‚ñà‚ñè        | 393/3257 [00:02<00:15, 184.32it/s] 13%|‚ñà‚ñé        | 415/3257 [00:02<00:14, 193.64it/s] 13%|‚ñà‚ñé        | 435/3257 [00:02<00:17, 165.04it/s] 14%|‚ñà‚ñç        | 458/3257 [00:02<00:15, 178.67it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:15, 181.20it/s] 15%|‚ñà‚ñå        | 502/3257 [00:02<00:14, 192.49it/s] 16%|‚ñà‚ñå        | 522/3257 [00:02<00:14, 193.20it/s] 17%|‚ñà‚ñã        | 543/3257 [00:02<00:13, 195.49it/s] 17%|‚ñà‚ñã        | 563/3257 [00:02<00:14, 180.28it/s] 18%|‚ñà‚ñä        | 582/3257 [00:03<00:15, 176.57it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:14, 184.83it/s] 19%|‚ñà‚ñâ        | 623/3257 [00:03<00:14, 182.98it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:03<00:13, 190.22it/s] 20%|‚ñà‚ñà        | 664/3257 [00:03<00:14, 177.27it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:14, 177.06it/s] 22%|‚ñà‚ñà‚ñè       | 703/3257 [00:03<00:13, 182.62it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:03<00:13, 181.46it/s] 23%|‚ñà‚ñà‚ñé       | 741/3257 [00:04<00:23, 109.11it/s] 23%|‚ñà‚ñà‚ñé       | 763/3257 [00:04<00:19, 130.17it/s] 24%|‚ñà‚ñà‚ñç       | 780/3257 [00:04<00:18, 135.73it/s] 25%|‚ñà‚ñà‚ñç       | 801/3257 [00:04<00:16, 152.34it/s] 25%|‚ñà‚ñà‚ñå       | 819/3257 [00:04<00:15, 156.72it/s] 26%|‚ñà‚ñà‚ñå       | 837/3257 [00:04<00:15, 154.76it/s] 26%|‚ñà‚ñà‚ñå       | 854/3257 [00:04<00:15, 154.79it/s] 27%|‚ñà‚ñà‚ñã       | 873/3257 [00:04<00:14, 162.78it/s] 27%|‚ñà‚ñà‚ñã       | 890/3257 [00:05<00:14, 162.77it/s] 28%|‚ñà‚ñà‚ñä       | 912/3257 [00:05<00:13, 177.26it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:05<00:13, 178.33it/s] 29%|‚ñà‚ñà‚ñâ       | 951/3257 [00:05<00:12, 184.21it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:05<00:12, 185.70it/s] 30%|‚ñà‚ñà‚ñà       | 989/3257 [00:05<00:12, 182.61it/s] 31%|‚ñà‚ñà‚ñà       | 1008/3257 [00:05<00:12, 178.21it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:05<00:12, 176.85it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1045/3257 [00:05<00:12, 173.84it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1064/3257 [00:06<00:12, 178.19it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1082/3257 [00:06<00:12, 176.27it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1101/3257 [00:06<00:12, 179.21it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1119/3257 [00:06<00:12, 175.62it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1138/3257 [00:06<00:11, 177.93it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1156/3257 [00:06<00:12, 175.04it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:06<00:11, 176.55it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1193/3257 [00:06<00:12, 162.57it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:06<00:12, 159.65it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:06<00:11, 174.85it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1250/3257 [00:07<00:11, 173.04it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:07<00:11, 180.13it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:07<00:11, 168.48it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:07<00:11, 171.22it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1330/3257 [00:07<00:10, 181.21it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:07<00:10, 178.28it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1368/3257 [00:07<00:10, 178.15it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:07<00:10, 171.10it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1408/3257 [00:07<00:10, 184.39it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1430/3257 [00:08<00:09, 192.90it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1450/3257 [00:08<00:09, 190.98it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1472/3257 [00:08<00:09, 196.01it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1493/3257 [00:08<00:08, 199.04it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1514/3257 [00:08<00:08, 199.71it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1535/3257 [00:08<00:09, 179.72it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1554/3257 [00:08<00:09, 177.12it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:08<00:09, 180.66it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1593/3257 [00:08<00:09, 179.40it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1614/3257 [00:09<00:08, 187.87it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:09<00:09, 177.76it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1653/3257 [00:09<00:09, 175.59it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1671/3257 [00:09<00:09, 170.18it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:09<00:09, 173.48it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1711/3257 [00:09<00:08, 182.21it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1730/3257 [00:09<00:08, 172.02it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1749/3257 [00:09<00:08, 175.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1768/3257 [00:09<00:08, 178.31it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:10<00:07, 188.24it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1809/3257 [00:10<00:08, 177.49it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:10<00:08, 175.08it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:10<00:07, 184.52it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1875/3257 [00:10<00:06, 204.64it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:10<00:06, 207.27it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1920/3257 [00:10<00:06, 211.62it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1951/3257 [00:10<00:05, 238.49it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1977/3257 [00:10<00:05, 238.22it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2002/3257 [00:11<00:05, 240.06it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2027/3257 [00:11<00:05, 242.74it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:11<00:05, 221.02it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2075/3257 [00:11<00:05, 219.22it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2098/3257 [00:11<00:08, 136.16it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:11<00:07, 150.73it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2142/3257 [00:11<00:06, 165.61it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:11<00:06, 181.08it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2187/3257 [00:12<00:05, 187.04it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:12<00:05, 193.00it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2233/3257 [00:12<00:05, 204.04it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2255/3257 [00:12<00:04, 200.65it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:12<00:05, 192.26it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:12<00:04, 206.71it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2330/3257 [00:12<00:04, 229.43it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:12<00:03, 238.64it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2386/3257 [00:12<00:03, 243.86it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2411/3257 [00:13<00:03, 233.16it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2435/3257 [00:13<00:03, 222.46it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2458/3257 [00:13<00:03, 223.22it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2482/3257 [00:13<00:03, 227.44it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2509/3257 [00:13<00:03, 236.08it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2536/3257 [00:13<00:02, 242.41it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2561/3257 [00:13<00:03, 223.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2584/3257 [00:13<00:03, 213.32it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2610/3257 [00:13<00:02, 224.56it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2638/3257 [00:14<00:02, 236.65it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2662/3257 [00:14<00:02, 216.95it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:14<00:02, 223.41it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2710/3257 [00:14<00:02, 200.34it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2733/3257 [00:14<00:02, 208.00it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2758/3257 [00:14<00:02, 217.18it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2781/3257 [00:14<00:02, 213.55it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2806/3257 [00:14<00:02, 221.13it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2829/3257 [00:15<00:02, 202.44it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:15<00:01, 209.60it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2883/3257 [00:15<00:01, 233.78it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:15<00:01, 213.07it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2930/3257 [00:15<00:01, 214.89it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2952/3257 [00:15<00:01, 203.48it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:15<00:01, 205.34it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2997/3257 [00:15<00:01, 206.23it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:15<00:01, 204.97it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3044/3257 [00:16<00:00, 220.23it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3070/3257 [00:16<00:00, 230.27it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3094/3257 [00:16<00:00, 227.12it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3121/3257 [00:16<00:00, 237.87it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3145/3257 [00:16<00:00, 221.81it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3168/3257 [00:16<00:00, 220.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3191/3257 [00:16<00:00, 216.86it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:16<00:00, 208.38it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:16<00:00, 220.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 192.01it/s]
2023-02-07 18:18:14.535 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:18:14,537][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d391,n5,w14,mc5,s0.647067,t4>', 'datetime': '2023-02-07T18:18:14.537016', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:18:14,537][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:18:14,537][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:18:15,006][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 18:18:15,007][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:18:15,052][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 16108 unique words (50.65% of original 31803, drops 15695)', 'datetime': '2023-02-07T18:18:15.052691', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:18:15,053][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5056108 word corpus (99.23% of original 5095118, drops 39010)', 'datetime': '2023-02-07T18:18:15.053083', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:18:15,107][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 18:18:15,108][gensim.models.word2vec][INFO] - sample=0.647067 downsamples 0 most-common words
[2023-02-07 18:18:15,108][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5056108 word corpus (100.0%% of prior 5056108)', 'datetime': '2023-02-07T18:18:15.108863', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:18:15,204][gensim.models.word2vec][INFO] - estimated required memory for 16108 words and 391 dimensions: 64185172 bytes
[2023-02-07 18:18:15,204][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:18:15,235][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 16108 vocabulary and 391 features, using sg=0 hs=0 sample=0.6470672384656849 negative=5 window=14 shrink_windows=True', 'datetime': '2023-02-07T18:18:15.235112', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:18:16,243][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 17.50% examples, 858403 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:17,244][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 33.83% examples, 861927 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:18,249][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 51.21% examples, 877420 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:19,252][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 69.36% examples, 890821 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:20,253][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 89.28% examples, 903780 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:20,799][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5048130 effective words) took 5.6s, 907578 effective words/s
[2023-02-07 18:18:21,815][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 19.22% examples, 927705 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:22,820][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 36.91% examples, 946787 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:23,821][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 55.45% examples, 949393 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:24,822][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 74.64% examples, 951866 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:25,835][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 94.60% examples, 951152 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:26,119][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5048130 effective words) took 5.3s, 949133 effective words/s
[2023-02-07 18:18:27,121][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 17.75% examples, 881630 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:28,146][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 35.06% examples, 888489 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:29,146][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 52.47% examples, 895576 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:30,153][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 69.67% examples, 891765 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:31,154][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 88.70% examples, 893489 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:31,757][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5048130 effective words) took 5.6s, 895625 effective words/s
[2023-02-07 18:18:32,767][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 17.96% examples, 884296 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:33,788][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 35.06% examples, 886624 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:34,812][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 52.78% examples, 892588 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:35,815][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 70.65% examples, 899887 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:36,829][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 90.05% examples, 901016 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:37,349][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5048130 effective words) took 5.6s, 903060 effective words/s
[2023-02-07 18:18:38,352][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 18.15% examples, 900355 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:39,354][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 36.91% examples, 954765 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:40,364][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 57.94% examples, 992644 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:18:41,372][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 78.81% examples, 1000220 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:42,399][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 98.80% examples, 988547 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:42,443][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5048130 effective words) took 5.1s, 991403 effective words/s
[2023-02-07 18:18:43,446][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 19.22% examples, 939737 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:44,468][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 37.64% examples, 962203 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:45,471][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 57.02% examples, 973863 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:46,494][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 77.06% examples, 971544 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:47,498][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 96.96% examples, 969881 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:47,634][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5048130 effective words) took 5.2s, 972826 effective words/s
[2023-02-07 18:18:48,652][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 20.11% examples, 984247 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:18:49,654][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.66% examples, 990164 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:50,658][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 57.91% examples, 989743 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:51,668][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 78.08% examples, 987094 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:52,676][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 98.56% examples, 988194 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:52,735][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5048130 effective words) took 5.1s, 989874 effective words/s
[2023-02-07 18:18:53,740][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 19.77% examples, 973844 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:54,750][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 38.29% examples, 983224 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:55,760][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 57.78% examples, 986325 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:56,769][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 77.31% examples, 978075 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:57,788][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 96.59% examples, 966720 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:57,960][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5048130 effective words) took 5.2s, 966455 effective words/s
[2023-02-07 18:18:58,964][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 18.54% examples, 914855 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:59,976][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 35.77% examples, 911503 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:00,991][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 53.85% examples, 920837 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:19:02,000][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 72.74% examples, 923536 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:03,001][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 91.50% examples, 923582 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:03,412][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5048130 effective words) took 5.5s, 926218 effective words/s
[2023-02-07 18:19:04,414][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 18.39% examples, 908031 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:05,425][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 35.89% examples, 913119 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:06,427][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 53.45% examples, 919982 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:07,434][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 72.09% examples, 921157 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:08,438][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 91.40% examples, 924492 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:08,867][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5048130 effective words) took 5.5s, 925813 effective words/s
[2023-02-07 18:19:09,877][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 20.11% examples, 992071 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:19:10,880][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 40.71% examples, 1049749 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:11,880][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 61.28% examples, 1042868 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:12,892][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 81.24% examples, 1027842 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:19:13,831][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5048130 effective words) took 5.0s, 1017284 effective words/s
[2023-02-07 18:19:14,837][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 19.93% examples, 980244 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:15,839][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 38.66% examples, 996375 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:16,842][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 57.91% examples, 993692 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:17,852][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 78.08% examples, 990058 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:18,858][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 98.56% examples, 991069 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:18,917][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5048130 effective words) took 5.1s, 992799 effective words/s
[2023-02-07 18:19:19,925][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 19.90% examples, 978481 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:20,927][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 38.29% examples, 985615 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:19:21,928][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 57.66% examples, 988426 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:22,944][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 77.96% examples, 986395 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:23,953][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 98.65% examples, 991257 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:23,994][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5048130 effective words) took 5.1s, 994691 effective words/s
[2023-02-07 18:19:25,009][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 19.77% examples, 964037 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:26,010][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 38.47% examples, 987524 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:19:27,018][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 56.25% examples, 963572 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:19:28,023][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 75.22% examples, 958710 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:29,027][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 94.44% examples, 949849 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:29,318][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5048130 effective words) took 5.3s, 948307 effective words/s
[2023-02-07 18:19:30,322][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 18.54% examples, 914238 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:19:31,330][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 35.89% examples, 913217 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:19:32,342][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 53.85% examples, 922893 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:19:33,350][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 72.52% examples, 923130 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:34,350][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 91.50% examples, 925236 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:34,773][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5048130 effective words) took 5.5s, 925803 effective words/s
[2023-02-07 18:19:34,773][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75721950 effective words) took 79.5s, 952020 effective words/s', 'datetime': '2023-02-07T18:19:34.773793', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:19:34.774 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:19:40,260][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181749-btxwn3fy/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:19:40.260299', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:19:40,261][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:19:40,329][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181749-btxwn3fy/files/../tmp/embedding_model.pt
2023-02-07 18:19:40.329 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:19:42.516 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:19:43.287 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:19:45.792 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1318901064995224, 'test_mae': 0.8329494109640092, 'test_r2': -3.7474076954107165}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.08
wandb: percentage 0.49351
wandb:   test_mae 0.83295
wandb:   test_mse 1.13189
wandb:    test_r2 -3.74741
wandb: 
wandb: üöÄ View run polished-sweep-2 at: https://wandb.ai/xiaoqiz/mof2vec/runs/btxwn3fy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_181749-btxwn3fy/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: dibtvblx with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 585
wandb: 	model.gensim.alpha: 0.016186915564844983
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.31276431955419765
wandb: 	model.gensim.vector_size: 261
wandb: 	model.gensim.window: 4
wandb: 	model.sklearn.learning_rate: 0.019294615927713636
wandb: 	model.sklearn.max_depth: 58
wandb: 	model.sklearn.min_child_weight: 0.09545906660753024
wandb: 	model.sklearn.n_estimators: 2401
wandb: 	model.sklearn.num_leaves: 340
wandb: 	model.sklearn.reg_alpha: 0.003904817691763359
wandb: 	model.sklearn.reg_lambda: 0.019870275017745787
wandb: 	model.sklearn.subsample: 0.5542820532301596
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182005-dibtvblx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/dibtvblx
2023-02-07 18:20:13.432 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 18:20:13.432 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 585 for sweep.
2023-02-07 18:20:13.432 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.016186915564844983 for sweep.
2023-02-07 18:20:13.433 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:20:13.433 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 18:20:13.433 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.31276431955419765 for sweep.
2023-02-07 18:20:13.433 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 261 for sweep.
2023-02-07 18:20:13.434 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 4 for sweep.
2023-02-07 18:20:13.434 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.019294615927713636 for sweep.
2023-02-07 18:20:13.434 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 58 for sweep.
2023-02-07 18:20:13.434 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09545906660753024 for sweep.
2023-02-07 18:20:13.434 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2401 for sweep.
2023-02-07 18:20:13.435 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 340 for sweep.
2023-02-07 18:20:13.435 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.003904817691763359 for sweep.
2023-02-07 18:20:13.435 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.019870275017745787 for sweep.
2023-02-07 18:20:13.435 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5542820532301596 for sweep.
2023-02-07 18:20:13.435 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:20:13.440 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182005-dibtvblx/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 585, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 261, 'window': 4, 'min_count': 3, 'dm': 0, 'sample': 0.31276431955419765, 'workers': 4, 'alpha': 0.016186915564844983, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2401, 'max_depth': 58, 'num_leaves': 340, 'reg_alpha': 0.003904817691763359, 'reg_lambda': 0.019870275017745787, 'subsample': 0.5542820532301596, 'min_child_weight': 0.09545906660753024, 'n_jobs': 4, 'learning_rate': 0.019294615927713636}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 9/3257 [00:00<01:07, 48.00it/s]  1%|          | 30/3257 [00:00<00:27, 117.24it/s]  2%|‚ñè         | 50/3257 [00:00<00:22, 145.18it/s]  2%|‚ñè         | 68/3257 [00:00<00:20, 156.08it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 175.08it/s]  3%|‚ñé         | 109/3257 [00:00<00:18, 171.66it/s]  4%|‚ñç         | 129/3257 [00:00<00:17, 179.35it/s]  5%|‚ñç         | 151/3257 [00:00<00:16, 186.59it/s]  5%|‚ñå         | 170/3257 [00:01<00:16, 185.92it/s]  6%|‚ñå         | 190/3257 [00:01<00:16, 188.79it/s]  6%|‚ñã         | 211/3257 [00:01<00:15, 193.38it/s]  7%|‚ñã         | 236/3257 [00:01<00:14, 206.95it/s]  8%|‚ñä         | 257/3257 [00:01<00:14, 203.54it/s]  9%|‚ñä         | 282/3257 [00:01<00:13, 215.55it/s]  9%|‚ñâ         | 304/3257 [00:01<00:14, 208.19it/s] 10%|‚ñà         | 328/3257 [00:01<00:13, 209.27it/s] 11%|‚ñà         | 349/3257 [00:01<00:14, 200.87it/s] 11%|‚ñà‚ñè        | 372/3257 [00:01<00:13, 208.99it/s] 12%|‚ñà‚ñè        | 394/3257 [00:02<00:15, 190.14it/s] 13%|‚ñà‚ñé        | 418/3257 [00:02<00:14, 201.90it/s] 13%|‚ñà‚ñé        | 439/3257 [00:02<00:16, 171.72it/s] 14%|‚ñà‚ñç        | 461/3257 [00:02<00:15, 182.53it/s] 15%|‚ñà‚ñç        | 481/3257 [00:02<00:15, 181.50it/s] 15%|‚ñà‚ñå        | 504/3257 [00:02<00:14, 192.99it/s] 16%|‚ñà‚ñå        | 526/3257 [00:02<00:14, 194.82it/s] 17%|‚ñà‚ñã        | 547/3257 [00:02<00:13, 196.13it/s] 17%|‚ñà‚ñã        | 567/3257 [00:03<00:14, 186.08it/s] 18%|‚ñà‚ñä        | 586/3257 [00:03<00:15, 177.23it/s] 19%|‚ñà‚ñä        | 606/3257 [00:03<00:14, 182.64it/s] 19%|‚ñà‚ñâ        | 625/3257 [00:03<00:14, 181.47it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:14, 179.62it/s] 20%|‚ñà‚ñà        | 664/3257 [00:03<00:15, 172.06it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:15, 166.87it/s] 21%|‚ñà‚ñà‚ñè       | 700/3257 [00:03<00:15, 160.36it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:03<00:15, 164.09it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:04<00:15, 159.49it/s] 23%|‚ñà‚ñà‚ñé       | 752/3257 [00:04<00:15, 159.04it/s] 24%|‚ñà‚ñà‚ñé       | 772/3257 [00:04<00:14, 170.23it/s] 24%|‚ñà‚ñà‚ñç       | 790/3257 [00:04<00:14, 170.23it/s] 25%|‚ñà‚ñà‚ñç       | 809/3257 [00:04<00:14, 174.20it/s] 25%|‚ñà‚ñà‚ñå       | 827/3257 [00:04<00:14, 172.83it/s] 26%|‚ñà‚ñà‚ñå       | 845/3257 [00:04<00:14, 164.53it/s] 27%|‚ñà‚ñà‚ñã       | 865/3257 [00:04<00:13, 173.22it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:04<00:14, 168.73it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:05<00:12, 183.67it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:05<00:12, 190.61it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:05<00:12, 184.95it/s] 30%|‚ñà‚ñà‚ñâ       | 968/3257 [00:05<00:12, 188.67it/s] 30%|‚ñà‚ñà‚ñà       | 987/3257 [00:05<00:12, 182.41it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:05<00:12, 176.16it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:05<00:12, 174.85it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1045/3257 [00:05<00:12, 174.42it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1065/3257 [00:05<00:12, 180.18it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1084/3257 [00:06<00:12, 179.31it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1104/3257 [00:06<00:11, 183.34it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:06<00:11, 180.13it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1142/3257 [00:06<00:11, 177.43it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1163/3257 [00:06<00:11, 185.00it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1182/3257 [00:06<00:11, 176.12it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1200/3257 [00:06<00:12, 166.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1217/3257 [00:06<00:18, 112.23it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:07<00:14, 137.14it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:07<00:13, 144.05it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:07<00:13, 149.95it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:07<00:12, 151.58it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1311/3257 [00:07<00:12, 161.46it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1331/3257 [00:07<00:11, 170.67it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:07<00:11, 171.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1369/3257 [00:07<00:10, 176.57it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:07<00:11, 168.50it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1411/3257 [00:08<00:10, 184.40it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:08<00:09, 188.74it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1455/3257 [00:08<00:09, 198.78it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:08<00:08, 200.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1501/3257 [00:08<00:08, 211.30it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1523/3257 [00:08<00:08, 193.45it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1543/3257 [00:08<00:09, 188.71it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1563/3257 [00:08<00:09, 182.77it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1582/3257 [00:08<00:09, 177.38it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1604/3257 [00:09<00:08, 186.78it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1623/3257 [00:09<00:08, 182.99it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1642/3257 [00:09<00:09, 176.08it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1660/3257 [00:09<00:09, 174.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1678/3257 [00:09<00:09, 166.37it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1698/3257 [00:09<00:08, 174.26it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1716/3257 [00:09<00:08, 174.08it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1734/3257 [00:09<00:09, 161.66it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1755/3257 [00:09<00:08, 173.54it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1776/3257 [00:10<00:08, 182.86it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1797/3257 [00:10<00:07, 189.77it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1817/3257 [00:10<00:07, 188.39it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1836/3257 [00:10<00:07, 186.82it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1856/3257 [00:10<00:07, 190.18it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:10<00:07, 196.82it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:10<00:06, 194.37it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1919/3257 [00:10<00:07, 190.82it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1945/3257 [00:10<00:06, 210.22it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1971/3257 [00:10<00:05, 222.74it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1994/3257 [00:11<00:05, 210.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2016/3257 [00:11<00:06, 203.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2037/3257 [00:11<00:05, 205.43it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2058/3257 [00:11<00:06, 186.18it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2078/3257 [00:11<00:06, 184.15it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2097/3257 [00:11<00:06, 180.76it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2119/3257 [00:11<00:06, 188.80it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2139/3257 [00:11<00:06, 174.26it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2157/3257 [00:12<00:06, 174.01it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:12<00:06, 178.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2199/3257 [00:12<00:05, 186.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2218/3257 [00:12<00:05, 182.34it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:12<00:05, 183.69it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2256/3257 [00:12<00:05, 181.99it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:12<00:05, 172.20it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:12<00:05, 185.71it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2322/3257 [00:12<00:04, 197.43it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2347/3257 [00:12<00:04, 211.68it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2369/3257 [00:13<00:04, 210.28it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2393/3257 [00:13<00:03, 216.37it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2415/3257 [00:13<00:04, 205.52it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2436/3257 [00:13<00:04, 195.10it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2456/3257 [00:13<00:04, 195.91it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2479/3257 [00:13<00:03, 204.01it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2504/3257 [00:13<00:03, 215.78it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2526/3257 [00:13<00:03, 213.03it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2548/3257 [00:13<00:03, 213.80it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2570/3257 [00:14<00:03, 193.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2590/3257 [00:14<00:03, 189.73it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2618/3257 [00:14<00:02, 213.75it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2640/3257 [00:14<00:02, 215.08it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2662/3257 [00:14<00:05, 109.81it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2684/3257 [00:14<00:04, 128.68it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2703/3257 [00:15<00:04, 131.10it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2720/3257 [00:15<00:03, 138.27it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2744/3257 [00:15<00:03, 159.44it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2763/3257 [00:15<00:02, 165.76it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2782/3257 [00:15<00:02, 171.01it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2806/3257 [00:15<00:02, 186.16it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2826/3257 [00:15<00:02, 176.92it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2845/3257 [00:15<00:02, 178.91it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2874/3257 [00:15<00:01, 208.00it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2896/3257 [00:16<00:01, 195.99it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2919/3257 [00:16<00:01, 202.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2940/3257 [00:16<00:01, 200.47it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2961/3257 [00:16<00:01, 188.91it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2981/3257 [00:16<00:01, 183.55it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3005/3257 [00:16<00:01, 198.06it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:16<00:01, 194.75it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:16<00:01, 201.15it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:16<00:00, 214.54it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3097/3257 [00:17<00:00, 208.24it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3122/3257 [00:17<00:00, 216.76it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3144/3257 [00:17<00:00, 199.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:17<00:00, 194.60it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:17<00:00, 190.86it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:17<00:00, 197.46it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3227/3257 [00:17<00:00, 197.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3252/3257 [00:17<00:00, 211.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 182.17it/s]
2023-02-07 18:20:32.093 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:20:32,094][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d261,n5,mc3,s0.312764,t4>', 'datetime': '2023-02-07T18:20:32.094765', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:20:32,095][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:20:32,095][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:20:32,617][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 18:20:32,618][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:20:32,696][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 30516 unique words (71.46% of original 42701, drops 12185)', 'datetime': '2023-02-07T18:20:32.696897', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:20:32,697][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 5804704 word corpus (99.69% of original 5822992, drops 18288)', 'datetime': '2023-02-07T18:20:32.697340', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:20:32,803][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 18:20:32,806][gensim.models.word2vec][INFO] - sample=0.312764 downsamples 0 most-common words
[2023-02-07 18:20:32,806][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5804704 word corpus (100.0%% of prior 5804704)', 'datetime': '2023-02-07T18:20:32.806438', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:20:32,981][gensim.models.word2vec][INFO] - estimated required memory for 30516 words and 261 dimensions: 83027116 bytes
[2023-02-07 18:20:32,981][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:20:33,014][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 30516 vocabulary and 261 features, using sg=1 hs=0 sample=0.31276431955419765 negative=5 window=4 shrink_windows=True', 'datetime': '2023-02-07T18:20:33.014706', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:20:34,018][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 35.89% examples, 2094477 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:35,018][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 72.58% examples, 2124018 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:35,700][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5778362 effective words) took 2.7s, 2153095 effective words/s
[2023-02-07 18:20:36,705][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 43.94% examples, 2588275 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:37,711][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 87.07% examples, 2528579 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:20:37,984][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5778362 effective words) took 2.3s, 2531938 effective words/s
[2023-02-07 18:20:38,988][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 43.35% examples, 2563876 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:39,990][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 86.46% examples, 2513476 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:40,294][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5778362 effective words) took 2.3s, 2502288 effective words/s
[2023-02-07 18:20:41,297][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 41.42% examples, 2452279 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:42,301][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 83.39% examples, 2432118 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:42,664][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5778362 effective words) took 2.4s, 2440514 effective words/s
[2023-02-07 18:20:43,666][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 39.76% examples, 2362348 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:44,667][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 82.99% examples, 2421198 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:45,033][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5778362 effective words) took 2.4s, 2440586 effective words/s
[2023-02-07 18:20:46,039][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 45.69% examples, 2678684 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:47,042][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 91.34% examples, 2645184 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:47,222][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5778362 effective words) took 2.2s, 2641169 effective words/s
[2023-02-07 18:20:48,226][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 43.14% examples, 2556525 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:49,227][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 88.64% examples, 2571542 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:20:49,454][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5778362 effective words) took 2.2s, 2590449 effective words/s
[2023-02-07 18:20:50,460][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 45.69% examples, 2678046 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:51,461][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 91.43% examples, 2652478 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:51,632][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5778362 effective words) took 2.2s, 2654692 effective words/s
[2023-02-07 18:20:52,635][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 44.86% examples, 2641864 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:20:53,639][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 91.34% examples, 2648965 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:53,812][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5778362 effective words) took 2.2s, 2653045 effective words/s
[2023-02-07 18:20:54,814][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 46.45% examples, 2724336 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:55,814][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 94.38% examples, 2732404 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:55,925][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5778362 effective words) took 2.1s, 2736228 effective words/s
[2023-02-07 18:20:56,930][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 35.98% examples, 2111358 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:57,933][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 72.92% examples, 2134707 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:58,650][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5778362 effective words) took 2.7s, 2123138 effective words/s
[2023-02-07 18:20:59,652][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 45.75% examples, 2688611 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:00,655][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 93.74% examples, 2716823 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:00,769][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5778362 effective words) took 2.1s, 2730105 effective words/s
[2023-02-07 18:21:01,772][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 46.45% examples, 2722521 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:02,779][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 80.60% examples, 2338310 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:03,362][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5778362 effective words) took 2.6s, 2229494 effective words/s
[2023-02-07 18:21:04,367][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 41.91% examples, 2481932 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:21:05,369][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 84.89% examples, 2467716 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:21:05,696][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5778362 effective words) took 2.3s, 2477248 effective words/s
[2023-02-07 18:21:06,699][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 41.91% examples, 2486047 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:21:07,700][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 85.60% examples, 2490143 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:08,018][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5778362 effective words) took 2.3s, 2490696 effective words/s
[2023-02-07 18:21:08,018][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86675430 effective words) took 35.0s, 2476187 effective words/s', 'datetime': '2023-02-07T18:21:08.018686', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:21:08.018 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:21:12,195][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182005-dibtvblx/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:21:12.195481', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:21:12,196][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:21:12,347][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182005-dibtvblx/files/../tmp/embedding_model.pt
2023-02-07 18:21:12.348 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:21:14.263 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:21:14.810 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:21:16.721 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.8975096582051626, 'test_mae': 0.7145074759981384, 'test_r2': -1.8213347524989736}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.89
wandb: percentage 0.28536
wandb:   test_mae 0.71451
wandb:   test_mse 0.89751
wandb:    test_r2 -1.82133
wandb: 
wandb: üöÄ View run divine-sweep-3 at: https://wandb.ai/xiaoqiz/mof2vec/runs/dibtvblx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_182005-dibtvblx/logs
wandb: Agent Starting Run: 8lhe2dr1 with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 70
wandb: 	model.gensim.alpha: 0.005365321253912987
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.20322763773147456
wandb: 	model.gensim.vector_size: 57
wandb: 	model.gensim.window: 10
wandb: 	model.sklearn.learning_rate: 0.06038548648200343
wandb: 	model.sklearn.max_depth: 6
wandb: 	model.sklearn.min_child_weight: 0.09218263178683858
wandb: 	model.sklearn.n_estimators: 1149
wandb: 	model.sklearn.num_leaves: 483
wandb: 	model.sklearn.reg_alpha: 0.01637589749165122
wandb: 	model.sklearn.reg_lambda: 0.03337275532460417
wandb: 	model.sklearn.subsample: 0.7103708495759531
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182126-8lhe2dr1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/8lhe2dr1
2023-02-07 18:21:34.357 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 18:21:34.358 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 70 for sweep.
2023-02-07 18:21:34.358 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.005365321253912987 for sweep.
2023-02-07 18:21:34.358 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:21:34.359 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 18:21:34.359 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.20322763773147456 for sweep.
2023-02-07 18:21:34.359 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 57 for sweep.
2023-02-07 18:21:34.359 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 10 for sweep.
2023-02-07 18:21:34.360 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.06038548648200343 for sweep.
2023-02-07 18:21:34.360 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 6 for sweep.
2023-02-07 18:21:34.360 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09218263178683858 for sweep.
2023-02-07 18:21:34.360 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1149 for sweep.
2023-02-07 18:21:34.361 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 483 for sweep.
2023-02-07 18:21:34.361 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.01637589749165122 for sweep.
2023-02-07 18:21:34.361 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.03337275532460417 for sweep.
2023-02-07 18:21:34.361 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7103708495759531 for sweep.
2023-02-07 18:21:34.362 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:21:34.372 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182126-8lhe2dr1/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 70, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 57, 'window': 10, 'min_count': 9, 'dm': 1, 'sample': 0.20322763773147456, 'workers': 4, 'alpha': 0.005365321253912987, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1149, 'max_depth': 6, 'num_leaves': 483, 'reg_alpha': 0.01637589749165122, 'reg_lambda': 0.03337275532460417, 'subsample': 0.7103708495759531, 'min_child_weight': 0.09218263178683858, 'n_jobs': 4, 'learning_rate': 0.06038548648200343}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:26, 121.61it/s]  1%|          | 29/3257 [00:00<00:22, 141.41it/s]  1%|‚ñè         | 44/3257 [00:00<00:23, 136.96it/s]  2%|‚ñè         | 58/3257 [00:00<00:23, 136.01it/s]  2%|‚ñè         | 74/3257 [00:00<00:22, 144.06it/s]  3%|‚ñé         | 90/3257 [00:00<00:21, 147.95it/s]  3%|‚ñé         | 105/3257 [00:00<00:22, 143.17it/s]  4%|‚ñé         | 120/3257 [00:00<00:22, 142.48it/s]  4%|‚ñç         | 135/3257 [00:00<00:21, 142.00it/s]  5%|‚ñç         | 152/3257 [00:01<00:20, 149.28it/s]  5%|‚ñå         | 167/3257 [00:01<00:21, 141.44it/s]  6%|‚ñå         | 182/3257 [00:01<00:22, 138.46it/s]  6%|‚ñå         | 198/3257 [00:01<00:21, 143.78it/s]  7%|‚ñã         | 215/3257 [00:01<00:20, 151.19it/s]  7%|‚ñã         | 232/3257 [00:01<00:19, 156.23it/s]  8%|‚ñä         | 248/3257 [00:01<00:19, 155.17it/s]  8%|‚ñä         | 264/3257 [00:01<00:20, 148.92it/s]  9%|‚ñâ         | 285/3257 [00:01<00:18, 162.49it/s]  9%|‚ñâ         | 302/3257 [00:02<00:18, 157.48it/s] 10%|‚ñâ         | 318/3257 [00:02<00:18, 157.07it/s] 10%|‚ñà         | 335/3257 [00:02<00:18, 159.68it/s] 11%|‚ñà         | 352/3257 [00:02<00:18, 154.93it/s] 11%|‚ñà‚ñè        | 368/3257 [00:02<00:18, 154.51it/s] 12%|‚ñà‚ñè        | 384/3257 [00:02<00:19, 151.02it/s] 12%|‚ñà‚ñè        | 401/3257 [00:02<00:18, 156.25it/s] 13%|‚ñà‚ñé        | 420/3257 [00:02<00:17, 164.87it/s] 13%|‚ñà‚ñé        | 437/3257 [00:02<00:19, 146.74it/s] 14%|‚ñà‚ñç        | 458/3257 [00:03<00:17, 161.89it/s] 15%|‚ñà‚ñç        | 477/3257 [00:03<00:16, 169.56it/s] 15%|‚ñà‚ñå        | 498/3257 [00:03<00:15, 177.08it/s] 16%|‚ñà‚ñå        | 518/3257 [00:03<00:14, 183.44it/s] 16%|‚ñà‚ñã        | 537/3257 [00:03<00:14, 182.90it/s] 17%|‚ñà‚ñã        | 556/3257 [00:03<00:14, 183.41it/s] 18%|‚ñà‚ñä        | 575/3257 [00:03<00:16, 158.10it/s] 18%|‚ñà‚ñä        | 596/3257 [00:03<00:15, 170.43it/s] 19%|‚ñà‚ñâ        | 618/3257 [00:03<00:14, 182.93it/s] 20%|‚ñà‚ñâ        | 637/3257 [00:04<00:14, 176.35it/s] 20%|‚ñà‚ñà        | 656/3257 [00:04<00:16, 161.10it/s] 21%|‚ñà‚ñà        | 675/3257 [00:04<00:15, 166.99it/s] 21%|‚ñà‚ñà‚ñè       | 693/3257 [00:04<00:15, 162.69it/s] 22%|‚ñà‚ñà‚ñè       | 710/3257 [00:04<00:23, 109.82it/s] 22%|‚ñà‚ñà‚ñè       | 724/3257 [00:04<00:22, 114.09it/s] 23%|‚ñà‚ñà‚ñé       | 739/3257 [00:04<00:20, 120.14it/s] 23%|‚ñà‚ñà‚ñé       | 758/3257 [00:04<00:18, 136.50it/s] 24%|‚ñà‚ñà‚ñç       | 775/3257 [00:05<00:17, 143.72it/s] 24%|‚ñà‚ñà‚ñç       | 792/3257 [00:05<00:16, 147.22it/s] 25%|‚ñà‚ñà‚ñç       | 809/3257 [00:05<00:16, 151.96it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:05<00:16, 151.93it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:05<00:16, 148.12it/s] 26%|‚ñà‚ñà‚ñã       | 859/3257 [00:05<00:15, 155.61it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:05<00:15, 155.52it/s] 27%|‚ñà‚ñà‚ñã       | 892/3257 [00:05<00:14, 159.49it/s] 28%|‚ñà‚ñà‚ñä       | 911/3257 [00:05<00:14, 167.11it/s] 29%|‚ñà‚ñà‚ñä       | 929/3257 [00:06<00:13, 170.77it/s] 29%|‚ñà‚ñà‚ñâ       | 947/3257 [00:06<00:13, 168.14it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:06<00:13, 173.70it/s] 30%|‚ñà‚ñà‚ñà       | 984/3257 [00:06<00:13, 166.34it/s] 31%|‚ñà‚ñà‚ñà       | 1001/3257 [00:06<00:14, 160.21it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1018/3257 [00:06<00:13, 161.95it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1035/3257 [00:06<00:14, 152.83it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:06<00:14, 150.26it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1070/3257 [00:06<00:13, 159.94it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1087/3257 [00:07<00:13, 159.50it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1104/3257 [00:07<00:13, 161.54it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1121/3257 [00:07<00:13, 159.02it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1138/3257 [00:07<00:13, 161.31it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1155/3257 [00:07<00:13, 159.01it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:07<00:12, 163.42it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1190/3257 [00:07<00:14, 145.94it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:07<00:13, 146.70it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1223/3257 [00:07<00:13, 154.71it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:08<00:12, 163.91it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1260/3257 [00:08<00:12, 164.55it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:08<00:12, 157.20it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1293/3257 [00:08<00:12, 155.81it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:08<00:12, 151.61it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1326/3257 [00:08<00:12, 155.18it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1342/3257 [00:08<00:12, 152.39it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1358/3257 [00:08<00:13, 142.65it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1373/3257 [00:08<00:13, 137.92it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1387/3257 [00:09<00:13, 136.50it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1404/3257 [00:09<00:12, 144.06it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:09<00:12, 152.77it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:09<00:11, 151.73it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1459/3257 [00:09<00:10, 164.80it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1476/3257 [00:09<00:11, 160.67it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1493/3257 [00:09<00:10, 162.73it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:09<00:10, 166.48it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1528/3257 [00:09<00:11, 149.70it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1544/3257 [00:10<00:12, 140.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1559/3257 [00:10<00:11, 142.61it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:10<00:11, 141.47it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1592/3257 [00:10<00:11, 148.45it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1608/3257 [00:10<00:10, 151.43it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1624/3257 [00:10<00:10, 149.02it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1640/3257 [00:10<00:10, 147.24it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1655/3257 [00:10<00:11, 141.86it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1670/3257 [00:10<00:11, 139.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1684/3257 [00:11<00:11, 134.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1701/3257 [00:11<00:10, 142.26it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1716/3257 [00:11<00:10, 142.77it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:11<00:11, 135.53it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:11<00:11, 134.12it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:11<00:10, 143.20it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:11<00:10, 146.58it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:11<00:09, 151.46it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1812/3257 [00:11<00:10, 143.03it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:12<00:10, 142.82it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1844/3257 [00:12<00:09, 149.22it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1860/3257 [00:12<00:09, 147.58it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:12<00:08, 153.94it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:12<00:09, 148.65it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1913/3257 [00:12<00:08, 157.13it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1929/3257 [00:13<00:17, 77.52it/s]  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1951/3257 [00:13<00:12, 101.06it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1971/3257 [00:13<00:10, 118.13it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1988/3257 [00:13<00:10, 121.11it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:13<00:09, 129.41it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2025/3257 [00:13<00:08, 148.58it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2043/3257 [00:13<00:07, 154.53it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2061/3257 [00:13<00:08, 148.08it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:13<00:07, 163.63it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2101/3257 [00:14<00:07, 161.37it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:14<00:06, 165.48it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2138/3257 [00:14<00:06, 168.34it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2156/3257 [00:14<00:06, 166.79it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:14<00:06, 173.82it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2198/3257 [00:14<00:05, 180.04it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2217/3257 [00:14<00:06, 172.90it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:14<00:05, 176.59it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2255/3257 [00:14<00:05, 170.42it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2273/3257 [00:15<00:06, 160.44it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2296/3257 [00:15<00:05, 177.75it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:15<00:05, 174.64it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2339/3257 [00:15<00:04, 191.00it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2361/3257 [00:15<00:04, 197.35it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2381/3257 [00:15<00:04, 197.02it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2403/3257 [00:15<00:04, 201.19it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2424/3257 [00:15<00:04, 186.03it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:15<00:04, 171.97it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2464/3257 [00:16<00:04, 180.59it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2483/3257 [00:16<00:04, 183.06it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:16<00:03, 194.44it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2527/3257 [00:16<00:03, 192.25it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2547/3257 [00:16<00:03, 192.79it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2567/3257 [00:16<00:03, 179.22it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:16<00:03, 170.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2606/3257 [00:16<00:03, 178.61it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2629/3257 [00:16<00:03, 191.41it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2649/3257 [00:17<00:03, 179.17it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2668/3257 [00:17<00:03, 172.96it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:17<00:03, 176.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2705/3257 [00:17<00:03, 161.31it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2722/3257 [00:17<00:03, 157.51it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2745/3257 [00:17<00:02, 176.57it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2764/3257 [00:17<00:02, 174.89it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2782/3257 [00:17<00:02, 174.64it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2804/3257 [00:17<00:02, 186.95it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:18<00:02, 178.86it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:18<00:02, 170.23it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2863/3257 [00:18<00:02, 180.20it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2882/3257 [00:18<00:02, 182.57it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2901/3257 [00:18<00:02, 156.07it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2919/3257 [00:18<00:02, 159.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2936/3257 [00:18<00:02, 155.19it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2952/3257 [00:18<00:02, 142.62it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:19<00:01, 146.23it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:19<00:01, 140.19it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3003/3257 [00:19<00:01, 151.70it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3019/3257 [00:19<00:01, 146.52it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3037/3257 [00:19<00:01, 154.35it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3053/3257 [00:19<00:01, 154.54it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3072/3257 [00:19<00:01, 163.52it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3089/3257 [00:19<00:01, 159.22it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3107/3257 [00:19<00:00, 164.29it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3124/3257 [00:19<00:00, 164.24it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3141/3257 [00:20<00:00, 153.68it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3157/3257 [00:20<00:00, 147.20it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3172/3257 [00:20<00:00, 146.53it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3187/3257 [00:20<00:00, 142.31it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3204/3257 [00:20<00:00, 148.74it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3219/3257 [00:20<00:00, 139.72it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3238/3257 [00:20<00:00, 152.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3254/3257 [00:20<00:00, 150.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 155.90it/s]
2023-02-07 18:21:56.343 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:21:56,345][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d57,n5,w10,mc9,s0.203228,t4>', 'datetime': '2023-02-07T18:21:56.345024', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:21:56,345][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:21:56,345][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:21:57,024][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 18:21:57,025][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:21:57,087][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 18315 unique words (33.88% of original 54054, drops 35739)', 'datetime': '2023-02-07T18:21:57.087193', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:21:57,087][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 6422560 word corpus (98.04% of original 6550866, drops 128306)', 'datetime': '2023-02-07T18:21:57.087705', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:21:57,154][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 18:21:57,155][gensim.models.word2vec][INFO] - sample=0.203228 downsamples 0 most-common words
[2023-02-07 18:21:57,155][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6422560 word corpus (100.0%% of prior 6422560)', 'datetime': '2023-02-07T18:21:57.155929', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:21:57,269][gensim.models.word2vec][INFO] - estimated required memory for 18315 words and 57 dimensions: 18903136 bytes
[2023-02-07 18:21:57,270][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:21:57,278][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18315 vocabulary and 57 features, using sg=0 hs=0 sample=0.20322763773147456 negative=5 window=10 shrink_windows=True', 'datetime': '2023-02-07T18:21:57.278244', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:21:58,280][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 32.55% examples, 2096987 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:21:59,283][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 68.99% examples, 2241753 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:00,102][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6368654 effective words) took 2.8s, 2256548 effective words/s
[2023-02-07 18:22:01,107][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 34.26% examples, 2195170 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:02,113][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 65.80% examples, 2130905 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:03,060][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6368654 effective words) took 3.0s, 2153822 effective words/s
[2023-02-07 18:22:04,063][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 32.55% examples, 2094982 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:05,065][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 65.98% examples, 2142985 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:06,031][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6368654 effective words) took 3.0s, 2144451 effective words/s
[2023-02-07 18:22:07,034][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 34.26% examples, 2200395 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:08,036][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 67.09% examples, 2178472 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:08,949][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6368654 effective words) took 2.9s, 2183980 effective words/s
[2023-02-07 18:22:09,953][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 33.68% examples, 2163115 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:10,955][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 66.87% examples, 2168270 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:11,893][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6368654 effective words) took 2.9s, 2164622 effective words/s
[2023-02-07 18:22:12,902][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 34.45% examples, 2201030 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:13,908][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 68.19% examples, 2199855 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:14,777][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6368654 effective words) took 2.9s, 2209083 effective words/s
[2023-02-07 18:22:15,780][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 33.87% examples, 2176865 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:16,784][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 68.44% examples, 2219328 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:17,641][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6368654 effective words) took 2.9s, 2224920 effective words/s
[2023-02-07 18:22:18,644][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 34.45% examples, 2215905 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:19,652][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 68.84% examples, 2230054 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:20,484][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6368654 effective words) took 2.8s, 2241459 effective words/s
[2023-02-07 18:22:21,488][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 34.94% examples, 2247059 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:22,492][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 69.54% examples, 2256232 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:23,298][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6368654 effective words) took 2.8s, 2264072 effective words/s
[2023-02-07 18:22:24,305][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 35.19% examples, 2265992 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:25,307][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 70.43% examples, 2284279 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:26,098][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6368654 effective words) took 2.8s, 2276433 effective words/s
[2023-02-07 18:22:27,100][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 30.52% examples, 1953696 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:28,102][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 60.85% examples, 1967512 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:29,105][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 92.29% examples, 1968617 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:29,340][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6368654 effective words) took 3.2s, 1965536 effective words/s
[2023-02-07 18:22:30,344][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 30.73% examples, 1962186 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:31,347][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 60.67% examples, 1955676 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:32,351][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 91.86% examples, 1959930 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:32,581][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6368654 effective words) took 3.2s, 1965678 effective words/s
[2023-02-07 18:22:33,588][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 29.90% examples, 1897645 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:34,592][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 60.18% examples, 1938321 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:35,595][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 90.97% examples, 1935126 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:35,873][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6368654 effective words) took 3.3s, 1936201 effective words/s
[2023-02-07 18:22:36,879][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 30.61% examples, 1950868 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:37,881][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 60.67% examples, 1955902 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:38,887][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 91.71% examples, 1955644 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:39,118][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6368654 effective words) took 3.2s, 1963564 effective words/s
[2023-02-07 18:22:40,124][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 38.72% examples, 2506137 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:41,128][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 77.06% examples, 2471257 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:41,729][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6368654 effective words) took 2.6s, 2440208 effective words/s
[2023-02-07 18:22:41,730][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (95529810 effective words) took 44.5s, 2149076 effective words/s', 'datetime': '2023-02-07T18:22:41.730321', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:22:41.730 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:22:45,293][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182126-8lhe2dr1/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:22:45.293753', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:22:45,294][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:22:45,327][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182126-8lhe2dr1/files/../tmp/embedding_model.pt
2023-02-07 18:22:45.328 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:22:46.519 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:22:46.936 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:22:47.462 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1104143236142594, 'test_mae': 0.8045753954104119, 'test_r2': -2.429399392004555}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.51
wandb: percentage 0.66117
wandb:   test_mae 0.80458
wandb:   test_mse 1.11041
wandb:    test_r2 -2.4294
wandb: 
wandb: üöÄ View run ruby-sweep-4 at: https://wandb.ai/xiaoqiz/mof2vec/runs/8lhe2dr1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_182126-8lhe2dr1/logs
wandb: Agent Starting Run: 7sgb5qqf with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 992
wandb: 	model.gensim.alpha: 0.0010329998014057733
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.20308693194573824
wandb: 	model.gensim.vector_size: 15
wandb: 	model.gensim.window: 1
wandb: 	model.sklearn.learning_rate: 0.020068415455124933
wandb: 	model.sklearn.max_depth: 55
wandb: 	model.sklearn.min_child_weight: 0.0715158081660962
wandb: 	model.sklearn.n_estimators: 643
wandb: 	model.sklearn.num_leaves: 403
wandb: 	model.sklearn.reg_alpha: 0.01594595870299368
wandb: 	model.sklearn.reg_lambda: 0.1412444899922738
wandb: 	model.sklearn.subsample: 0.5450747915372145
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182259-7sgb5qqf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/7sgb5qqf
2023-02-07 18:23:07.853 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 18:23:07.854 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 992 for sweep.
2023-02-07 18:23:07.855 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0010329998014057733 for sweep.
2023-02-07 18:23:07.855 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:23:07.855 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 18:23:07.856 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.20308693194573824 for sweep.
2023-02-07 18:23:07.856 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 15 for sweep.
2023-02-07 18:23:07.856 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 1 for sweep.
2023-02-07 18:23:07.856 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.020068415455124933 for sweep.
2023-02-07 18:23:07.857 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 55 for sweep.
2023-02-07 18:23:07.857 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0715158081660962 for sweep.
2023-02-07 18:23:07.857 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 643 for sweep.
2023-02-07 18:23:07.858 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 403 for sweep.
2023-02-07 18:23:07.858 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.01594595870299368 for sweep.
2023-02-07 18:23:07.858 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.1412444899922738 for sweep.
2023-02-07 18:23:07.859 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5450747915372145 for sweep.
2023-02-07 18:23:07.859 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:23:07.865 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182259-7sgb5qqf/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 992, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 15, 'window': 1, 'min_count': 7, 'dm': 0, 'sample': 0.20308693194573824, 'workers': 4, 'alpha': 0.0010329998014057733, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 643, 'max_depth': 55, 'num_leaves': 403, 'reg_alpha': 0.01594595870299368, 'reg_lambda': 0.1412444899922738, 'subsample': 0.5450747915372145, 'min_child_weight': 0.0715158081660962, 'n_jobs': 4, 'learning_rate': 0.020068415455124933}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:51, 62.91it/s]  1%|          | 38/3257 [00:00<00:29, 108.35it/s]  2%|‚ñè         | 57/3257 [00:00<00:23, 134.08it/s]  2%|‚ñè         | 80/3257 [00:00<00:19, 162.88it/s]  3%|‚ñé         | 101/3257 [00:00<00:17, 176.59it/s]  4%|‚ñé         | 121/3257 [00:00<00:18, 171.36it/s]  4%|‚ñç         | 145/3257 [00:00<00:16, 187.53it/s]  5%|‚ñå         | 165/3257 [00:01<00:16, 183.79it/s]  6%|‚ñå         | 187/3257 [00:01<00:15, 191.94it/s]  6%|‚ñã         | 209/3257 [00:01<00:15, 199.88it/s]  7%|‚ñã         | 233/3257 [00:01<00:14, 210.17it/s]  8%|‚ñä         | 255/3257 [00:01<00:14, 208.83it/s]  9%|‚ñä         | 278/3257 [00:01<00:13, 213.54it/s]  9%|‚ñâ         | 300/3257 [00:01<00:13, 213.85it/s] 10%|‚ñà         | 326/3257 [00:01<00:13, 224.43it/s] 11%|‚ñà         | 349/3257 [00:01<00:13, 212.06it/s] 11%|‚ñà‚ñè        | 373/3257 [00:01<00:13, 217.52it/s] 12%|‚ñà‚ñè        | 395/3257 [00:02<00:14, 202.85it/s] 13%|‚ñà‚ñé        | 419/3257 [00:02<00:13, 211.44it/s] 14%|‚ñà‚ñé        | 441/3257 [00:02<00:14, 188.47it/s] 14%|‚ñà‚ñç        | 464/3257 [00:02<00:14, 198.62it/s] 15%|‚ñà‚ñç        | 485/3257 [00:02<00:13, 199.89it/s] 16%|‚ñà‚ñå        | 508/3257 [00:02<00:13, 207.52it/s] 16%|‚ñà‚ñã        | 530/3257 [00:02<00:13, 206.54it/s] 17%|‚ñà‚ñã        | 551/3257 [00:02<00:13, 207.00it/s] 18%|‚ñà‚ñä        | 572/3257 [00:03<00:14, 184.22it/s] 18%|‚ñà‚ñä        | 595/3257 [00:03<00:13, 196.19it/s] 19%|‚ñà‚ñâ        | 619/3257 [00:03<00:12, 207.40it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:03<00:12, 201.74it/s] 20%|‚ñà‚ñà        | 662/3257 [00:03<00:13, 191.17it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:13, 196.00it/s] 22%|‚ñà‚ñà‚ñè       | 703/3257 [00:03<00:13, 196.37it/s] 22%|‚ñà‚ñà‚ñè       | 723/3257 [00:03<00:13, 194.07it/s] 23%|‚ñà‚ñà‚ñé       | 743/3257 [00:03<00:13, 191.49it/s] 24%|‚ñà‚ñà‚ñé       | 766/3257 [00:03<00:12, 201.03it/s] 24%|‚ñà‚ñà‚ñç       | 787/3257 [00:04<00:12, 197.44it/s] 25%|‚ñà‚ñà‚ñç       | 808/3257 [00:04<00:12, 199.22it/s] 25%|‚ñà‚ñà‚ñå       | 828/3257 [00:04<00:12, 195.81it/s] 26%|‚ñà‚ñà‚ñå       | 848/3257 [00:04<00:12, 190.18it/s] 27%|‚ñà‚ñà‚ñã       | 869/3257 [00:04<00:12, 193.18it/s] 27%|‚ñà‚ñà‚ñã       | 889/3257 [00:04<00:12, 191.47it/s] 28%|‚ñà‚ñà‚ñä       | 913/3257 [00:04<00:11, 203.22it/s] 29%|‚ñà‚ñà‚ñä       | 934/3257 [00:04<00:11, 202.30it/s] 29%|‚ñà‚ñà‚ñâ       | 958/3257 [00:04<00:10, 210.62it/s] 30%|‚ñà‚ñà‚ñà       | 980/3257 [00:05<00:11, 202.78it/s] 31%|‚ñà‚ñà‚ñà       | 1001/3257 [00:05<00:11, 200.18it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1022/3257 [00:05<00:11, 199.71it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1043/3257 [00:05<00:11, 188.18it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1063/3257 [00:05<00:11, 191.19it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1083/3257 [00:05<00:11, 192.45it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1104/3257 [00:05<00:10, 196.85it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:05<00:11, 193.18it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:05<00:11, 190.02it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1166/3257 [00:06<00:10, 197.37it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1186/3257 [00:06<00:11, 186.46it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:06<00:11, 180.61it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1224/3257 [00:06<00:17, 116.14it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1246/3257 [00:06<00:14, 136.27it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1269/3257 [00:06<00:12, 156.58it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:06<00:12, 153.17it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:07<00:11, 163.96it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1332/3257 [00:07<00:10, 180.57it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:07<00:10, 186.85it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1376/3257 [00:07<00:09, 193.53it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1397/3257 [00:07<00:09, 197.95it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:07<00:08, 211.42it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1444/3257 [00:07<00:08, 209.26it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1468/3257 [00:07<00:08, 217.67it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1491/3257 [00:07<00:08, 218.95it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1515/3257 [00:07<00:07, 224.08it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1538/3257 [00:08<00:08, 208.33it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1560/3257 [00:08<00:08, 207.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1581/3257 [00:08<00:08, 203.93it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1605/3257 [00:08<00:07, 212.60it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1630/3257 [00:08<00:07, 221.77it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1653/3257 [00:08<00:07, 205.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:08<00:07, 199.95it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1695/3257 [00:08<00:07, 198.19it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1717/3257 [00:08<00:07, 203.89it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1738/3257 [00:09<00:07, 191.39it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:09<00:07, 203.06it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1787/3257 [00:09<00:06, 213.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1809/3257 [00:09<00:06, 211.90it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1838/3257 [00:09<00:06, 233.24it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:09<00:05, 247.55it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:09<00:05, 256.68it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1924/3257 [00:09<00:05, 258.63it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:09<00:04, 288.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1990/3257 [00:10<00:04, 284.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:10<00:04, 290.19it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:10<00:04, 273.85it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2080/3257 [00:10<00:04, 269.84it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2108/3257 [00:10<00:04, 266.39it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2135/3257 [00:10<00:04, 257.60it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2162/3257 [00:10<00:04, 259.51it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2190/3257 [00:10<00:04, 265.24it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2218/3257 [00:10<00:03, 267.51it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2245/3257 [00:10<00:03, 267.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2272/3257 [00:11<00:03, 262.34it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2300/3257 [00:11<00:03, 265.73it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2333/3257 [00:11<00:03, 284.46it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2365/3257 [00:11<00:03, 294.42it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2396/3257 [00:11<00:02, 296.74it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2426/3257 [00:11<00:02, 281.55it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2455/3257 [00:11<00:02, 267.88it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2485/3257 [00:11<00:02, 274.70it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2519/3257 [00:11<00:02, 289.11it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2549/3257 [00:12<00:02, 285.88it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2578/3257 [00:12<00:02, 267.59it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2606/3257 [00:12<00:02, 268.07it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2638/3257 [00:12<00:02, 282.19it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2667/3257 [00:12<00:02, 267.60it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2695/3257 [00:12<00:03, 163.26it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2717/3257 [00:12<00:03, 170.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2748/3257 [00:13<00:02, 199.36it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2772/3257 [00:13<00:02, 205.40it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2804/3257 [00:13<00:01, 232.37it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2830/3257 [00:13<00:01, 225.58it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2861/3257 [00:13<00:01, 246.42it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2889/3257 [00:13<00:01, 253.20it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:13<00:01, 247.67it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2943/3257 [00:13<00:01, 242.95it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2970/3257 [00:13<00:01, 249.31it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2996/3257 [00:14<00:01, 245.07it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3022/3257 [00:14<00:00, 245.78it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3054/3257 [00:14<00:00, 264.45it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3083/3257 [00:14<00:00, 269.74it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3111/3257 [00:14<00:00, 270.65it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3139/3257 [00:14<00:00, 264.40it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:14<00:00, 251.52it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3192/3257 [00:14<00:00, 251.77it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3218/3257 [00:14<00:00, 242.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3250/3257 [00:14<00:00, 262.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:15<00:00, 216.79it/s]
2023-02-07 18:23:23.357 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:23:23,358][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d15,n5,mc7,s0.203087,t4>', 'datetime': '2023-02-07T18:23:23.358255', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:23:23,359][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:23:23,359][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:23:23,696][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 18:23:23,697][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:23:23,715][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 6087 unique words (46.60% of original 13061, drops 6974)', 'datetime': '2023-02-07T18:23:23.715433', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:23:23,715][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 3619677 word corpus (99.46% of original 3639370, drops 19693)', 'datetime': '2023-02-07T18:23:23.715823', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:23:23,736][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 18:23:23,736][gensim.models.word2vec][INFO] - sample=0.203087 downsamples 0 most-common words
[2023-02-07 18:23:23,736][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3619677 word corpus (100.0%% of prior 3619677)', 'datetime': '2023-02-07T18:23:23.736919', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:23:23,771][gensim.models.word2vec][INFO] - estimated required memory for 6087 words and 15 dimensions: 4620760 bytes
[2023-02-07 18:23:23,772][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:23:23,773][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 6087 vocabulary and 15 features, using sg=1 hs=0 sample=0.20308693194573824 negative=5 window=1 shrink_windows=True', 'datetime': '2023-02-07T18:23:23.773274', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:23:24,747][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3622934 effective words) took 1.0s, 3725757 effective words/s
[2023-02-07 18:23:25,721][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3622934 effective words) took 1.0s, 3726678 effective words/s
[2023-02-07 18:23:26,663][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3622934 effective words) took 0.9s, 3848236 effective words/s
[2023-02-07 18:23:27,661][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3622934 effective words) took 1.0s, 3634236 effective words/s
[2023-02-07 18:23:28,642][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3622934 effective words) took 1.0s, 3699831 effective words/s
[2023-02-07 18:23:29,619][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3622934 effective words) took 1.0s, 3710891 effective words/s
[2023-02-07 18:23:30,580][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3622934 effective words) took 1.0s, 3777964 effective words/s
[2023-02-07 18:23:31,542][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3622934 effective words) took 1.0s, 3768953 effective words/s
[2023-02-07 18:23:32,515][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3622934 effective words) took 1.0s, 3727801 effective words/s
[2023-02-07 18:23:33,491][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3622934 effective words) took 1.0s, 3719322 effective words/s
[2023-02-07 18:23:34,458][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3622934 effective words) took 1.0s, 3750096 effective words/s
[2023-02-07 18:23:35,415][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3622934 effective words) took 1.0s, 3790291 effective words/s
[2023-02-07 18:23:36,371][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3622934 effective words) took 1.0s, 3794104 effective words/s
[2023-02-07 18:23:37,325][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3622934 effective words) took 1.0s, 3803791 effective words/s
[2023-02-07 18:23:38,257][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3622934 effective words) took 0.9s, 3891560 effective words/s
[2023-02-07 18:23:38,257][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54344010 effective words) took 14.5s, 3751938 effective words/s', 'datetime': '2023-02-07T18:23:38.257786', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:23:38.257 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:23:39,594][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182259-7sgb5qqf/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:23:39.594590', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:23:39,595][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:23:39,606][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182259-7sgb5qqf/files/../tmp/embedding_model.pt
2023-02-07 18:23:39.606 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:23:40.603 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:23:40.995 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:23:54.792 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0289605160084492, 'test_mae': 0.77730912596353, 'test_r2': -2.25795180118134}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.4
wandb: percentage 0.53396
wandb:   test_mae 0.77731
wandb:   test_mse 1.02896
wandb:    test_r2 -2.25795
wandb: 
wandb: üöÄ View run effortless-sweep-5 at: https://wandb.ai/xiaoqiz/mof2vec/runs/7sgb5qqf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_182259-7sgb5qqf/logs
wandb: Agent Starting Run: joygzhof with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 656
wandb: 	model.gensim.alpha: 0.006846492744357203
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.3897155999476116
wandb: 	model.gensim.vector_size: 429
wandb: 	model.gensim.window: 5
wandb: 	model.sklearn.learning_rate: 0.012678637698417986
wandb: 	model.sklearn.max_depth: 47
wandb: 	model.sklearn.min_child_weight: 0.09873199546046472
wandb: 	model.sklearn.n_estimators: 3409
wandb: 	model.sklearn.num_leaves: 291
wandb: 	model.sklearn.reg_alpha: 0.002722939921503931
wandb: 	model.sklearn.reg_lambda: 0.007193897820838474
wandb: 	model.sklearn.subsample: 0.25703057846818195
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182408-joygzhof
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/joygzhof
2023-02-07 18:24:16.275 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 18:24:16.275 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 656 for sweep.
2023-02-07 18:24:16.276 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.006846492744357203 for sweep.
2023-02-07 18:24:16.276 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:24:16.276 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 18:24:16.277 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.3897155999476116 for sweep.
2023-02-07 18:24:16.277 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 429 for sweep.
2023-02-07 18:24:16.277 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 5 for sweep.
2023-02-07 18:24:16.277 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.012678637698417986 for sweep.
2023-02-07 18:24:16.278 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 47 for sweep.
2023-02-07 18:24:16.278 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09873199546046472 for sweep.
2023-02-07 18:24:16.278 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3409 for sweep.
2023-02-07 18:24:16.278 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 291 for sweep.
2023-02-07 18:24:16.279 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.002722939921503931 for sweep.
2023-02-07 18:24:16.279 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.007193897820838474 for sweep.
2023-02-07 18:24:16.279 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.25703057846818195 for sweep.
2023-02-07 18:24:16.280 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:24:16.292 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182408-joygzhof/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 656, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 429, 'window': 5, 'min_count': 3, 'dm': 0, 'sample': 0.3897155999476116, 'workers': 4, 'alpha': 0.006846492744357203, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3409, 'max_depth': 47, 'num_leaves': 291, 'reg_alpha': 0.002722939921503931, 'reg_lambda': 0.007193897820838474, 'subsample': 0.25703057846818195, 'min_child_weight': 0.09873199546046472, 'n_jobs': 4, 'learning_rate': 0.012678637698417986}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 138.93it/s]  1%|          | 31/3257 [00:00<00:21, 152.40it/s]  1%|‚ñè         | 47/3257 [00:00<00:21, 149.12it/s]  2%|‚ñè         | 62/3257 [00:00<00:21, 147.95it/s]  2%|‚ñè         | 79/3257 [00:00<00:20, 154.63it/s]  3%|‚ñé         | 95/3257 [00:00<00:20, 153.83it/s]  3%|‚ñé         | 111/3257 [00:00<00:21, 144.72it/s]  4%|‚ñç         | 128/3257 [00:00<00:20, 151.61it/s]  5%|‚ñç         | 148/3257 [00:00<00:19, 163.07it/s]  5%|‚ñå         | 165/3257 [00:01<00:20, 153.09it/s]  6%|‚ñå         | 181/3257 [00:01<00:20, 152.73it/s]  6%|‚ñå         | 199/3257 [00:01<00:19, 159.62it/s]  7%|‚ñã         | 217/3257 [00:01<00:18, 163.74it/s]  7%|‚ñã         | 237/3257 [00:01<00:17, 168.82it/s]  8%|‚ñä         | 255/3257 [00:01<00:17, 169.82it/s]  8%|‚ñä         | 273/3257 [00:01<00:18, 165.45it/s]  9%|‚ñâ         | 294/3257 [00:01<00:16, 176.05it/s] 10%|‚ñâ         | 312/3257 [00:01<00:18, 162.66it/s] 10%|‚ñà         | 331/3257 [00:02<00:17, 167.70it/s] 11%|‚ñà         | 348/3257 [00:02<00:18, 158.83it/s] 11%|‚ñà         | 366/3257 [00:02<00:17, 161.02it/s] 12%|‚ñà‚ñè        | 383/3257 [00:02<00:19, 149.51it/s] 12%|‚ñà‚ñè        | 399/3257 [00:02<00:19, 145.21it/s] 13%|‚ñà‚ñé        | 417/3257 [00:02<00:18, 153.77it/s] 13%|‚ñà‚ñé        | 433/3257 [00:02<00:21, 130.85it/s] 14%|‚ñà‚ñç        | 450/3257 [00:02<00:20, 138.80it/s] 14%|‚ñà‚ñç        | 469/3257 [00:03<00:18, 150.11it/s] 15%|‚ñà‚ñç        | 485/3257 [00:03<00:18, 147.56it/s] 15%|‚ñà‚ñå        | 504/3257 [00:03<00:17, 157.56it/s] 16%|‚ñà‚ñå        | 522/3257 [00:03<00:17, 160.85it/s] 17%|‚ñà‚ñã        | 539/3257 [00:03<00:16, 159.94it/s] 17%|‚ñà‚ñã        | 556/3257 [00:03<00:16, 161.28it/s] 18%|‚ñà‚ñä        | 573/3257 [00:03<00:19, 135.57it/s] 18%|‚ñà‚ñä        | 590/3257 [00:03<00:18, 143.68it/s] 19%|‚ñà‚ñä        | 609/3257 [00:03<00:17, 153.81it/s] 19%|‚ñà‚ñâ        | 625/3257 [00:04<00:17, 149.40it/s] 20%|‚ñà‚ñâ        | 643/3257 [00:04<00:16, 155.17it/s] 20%|‚ñà‚ñà        | 659/3257 [00:04<00:18, 140.11it/s] 21%|‚ñà‚ñà        | 674/3257 [00:04<00:27, 92.33it/s]  21%|‚ñà‚ñà        | 686/3257 [00:04<00:26, 97.38it/s] 22%|‚ñà‚ñà‚ñè       | 702/3257 [00:04<00:23, 110.08it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:04<00:20, 121.68it/s] 23%|‚ñà‚ñà‚ñé       | 734/3257 [00:05<00:20, 123.70it/s] 23%|‚ñà‚ñà‚ñé       | 748/3257 [00:05<00:20, 125.20it/s] 24%|‚ñà‚ñà‚ñé       | 766/3257 [00:05<00:17, 138.59it/s] 24%|‚ñà‚ñà‚ñç       | 781/3257 [00:05<00:18, 134.61it/s] 24%|‚ñà‚ñà‚ñç       | 797/3257 [00:05<00:17, 140.92it/s] 25%|‚ñà‚ñà‚ñç       | 812/3257 [00:05<00:17, 142.27it/s] 25%|‚ñà‚ñà‚ñå       | 827/3257 [00:05<00:17, 137.09it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:05<00:18, 131.32it/s] 26%|‚ñà‚ñà‚ñã       | 857/3257 [00:05<00:17, 136.80it/s] 27%|‚ñà‚ñà‚ñã       | 873/3257 [00:06<00:16, 140.33it/s] 27%|‚ñà‚ñà‚ñã       | 888/3257 [00:06<00:16, 140.19it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:06<00:15, 147.77it/s] 28%|‚ñà‚ñà‚ñä       | 920/3257 [00:06<00:15, 146.99it/s] 29%|‚ñà‚ñà‚ñä       | 935/3257 [00:06<00:15, 146.91it/s] 29%|‚ñà‚ñà‚ñâ       | 952/3257 [00:06<00:15, 152.97it/s] 30%|‚ñà‚ñà‚ñâ       | 968/3257 [00:06<00:14, 154.40it/s] 30%|‚ñà‚ñà‚ñà       | 984/3257 [00:06<00:14, 152.45it/s] 31%|‚ñà‚ñà‚ñà       | 1000/3257 [00:06<00:15, 147.33it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:06<00:15, 144.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1030/3257 [00:07<00:15, 142.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1045/3257 [00:07<00:15, 141.36it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1061/3257 [00:07<00:15, 144.73it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:14, 145.51it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1096/3257 [00:07<00:14, 147.69it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1113/3257 [00:07<00:14, 151.94it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1129/3257 [00:07<00:15, 141.06it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:07<00:14, 143.14it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1161/3257 [00:07<00:14, 148.95it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1177/3257 [00:08<00:14, 146.20it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1192/3257 [00:08<00:15, 134.64it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1206/3257 [00:08<00:15, 134.56it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1221/3257 [00:08<00:14, 138.55it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:08<00:13, 151.56it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:08<00:13, 146.59it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1273/3257 [00:08<00:13, 149.95it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1289/3257 [00:08<00:14, 134.98it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1304/3257 [00:09<00:14, 136.87it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:09<00:13, 143.80it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1340/3257 [00:09<00:12, 154.77it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1356/3257 [00:09<00:13, 145.37it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1371/3257 [00:09<00:12, 145.29it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:09<00:13, 141.74it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1403/3257 [00:09<00:12, 148.03it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1426/3257 [00:09<00:10, 170.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1447/3257 [00:09<00:09, 181.70it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1471/3257 [00:09<00:09, 196.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1493/3257 [00:10<00:08, 201.52it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1516/3257 [00:10<00:08, 206.36it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1537/3257 [00:10<00:09, 185.63it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1556/3257 [00:10<00:09, 182.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:10<00:09, 183.30it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1597/3257 [00:10<00:08, 192.53it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:10<00:08, 197.59it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:10<00:08, 193.73it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1659/3257 [00:10<00:08, 189.73it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1679/3257 [00:11<00:08, 183.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:11<00:08, 188.33it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1720/3257 [00:11<00:08, 190.50it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1740/3257 [00:11<00:08, 172.51it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:11<00:08, 183.11it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1785/3257 [00:11<00:07, 192.54it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1805/3257 [00:11<00:07, 184.12it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1825/3257 [00:11<00:07, 184.96it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1845/3257 [00:11<00:07, 185.68it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1868/3257 [00:12<00:07, 195.44it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1888/3257 [00:12<00:07, 188.70it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1910/3257 [00:12<00:06, 194.29it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1930/3257 [00:12<00:07, 187.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1960/3257 [00:12<00:05, 217.68it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1983/3257 [00:12<00:10, 123.13it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2005/3257 [00:12<00:08, 140.24it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2028/3257 [00:13<00:07, 158.31it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2048/3257 [00:13<00:07, 155.96it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2067/3257 [00:13<00:07, 156.24it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:13<00:07, 161.43it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2103/3257 [00:13<00:06, 165.20it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:13<00:07, 161.64it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2139/3257 [00:13<00:06, 165.18it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2157/3257 [00:13<00:06, 161.13it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:14<00:06, 169.39it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2198/3257 [00:14<00:06, 175.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2216/3257 [00:14<00:06, 172.83it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:14<00:05, 176.00it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2254/3257 [00:14<00:05, 173.60it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2272/3257 [00:14<00:06, 162.96it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2295/3257 [00:14<00:05, 180.13it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2314/3257 [00:14<00:05, 180.67it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2339/3257 [00:14<00:04, 198.03it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2362/3257 [00:14<00:04, 206.36it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2383/3257 [00:15<00:04, 205.27it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:15<00:04, 206.39it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2425/3257 [00:15<00:04, 192.03it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2445/3257 [00:15<00:04, 181.29it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2467/3257 [00:15<00:04, 189.81it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2487/3257 [00:15<00:04, 190.54it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2511/3257 [00:15<00:03, 203.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2533/3257 [00:15<00:03, 206.54it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2554/3257 [00:15<00:03, 192.22it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2574/3257 [00:16<00:03, 182.15it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2593/3257 [00:16<00:03, 179.03it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2620/3257 [00:16<00:03, 202.21it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2641/3257 [00:16<00:03, 203.66it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2662/3257 [00:16<00:03, 183.52it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2684/3257 [00:16<00:02, 191.45it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:16<00:03, 171.32it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2722/3257 [00:16<00:03, 165.39it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2746/3257 [00:17<00:02, 183.22it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2765/3257 [00:17<00:02, 184.52it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2784/3257 [00:17<00:02, 182.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2805/3257 [00:17<00:02, 187.97it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2825/3257 [00:17<00:02, 171.75it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2843/3257 [00:17<00:02, 173.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2870/3257 [00:17<00:01, 198.23it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2891/3257 [00:17<00:01, 195.74it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2911/3257 [00:17<00:01, 186.48it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2930/3257 [00:18<00:01, 183.30it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2949/3257 [00:18<00:01, 176.12it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:18<00:01, 179.57it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2988/3257 [00:18<00:01, 171.84it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:18<00:01, 184.74it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3032/3257 [00:18<00:01, 188.43it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3054/3257 [00:18<00:01, 197.22it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3078/3257 [00:18<00:00, 208.65it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3100/3257 [00:18<00:00, 200.93it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3123/3257 [00:19<00:00, 208.77it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3145/3257 [00:19<00:00, 190.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:19<00:00, 187.18it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:19<00:00, 181.99it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:19<00:00, 188.03it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3226/3257 [00:19<00:00, 182.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3246/3257 [00:20<00:00, 97.12it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 162.09it/s]
2023-02-07 18:24:37.137 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:24:37,139][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d429,n5,mc3,s0.389716,t4>', 'datetime': '2023-02-07T18:24:37.138952', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:24:37,139][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:24:37,139][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:24:37,692][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 18:24:37,692][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:24:37,776][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 30516 unique words (71.46% of original 42701, drops 12185)', 'datetime': '2023-02-07T18:24:37.776776', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:24:37,777][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 5804704 word corpus (99.69% of original 5822992, drops 18288)', 'datetime': '2023-02-07T18:24:37.777207', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:24:37,883][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 18:24:37,884][gensim.models.word2vec][INFO] - sample=0.389716 downsamples 0 most-common words
[2023-02-07 18:24:37,884][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5804704 word corpus (100.0%% of prior 5804704)', 'datetime': '2023-02-07T18:24:37.884579', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:24:38,066][gensim.models.word2vec][INFO] - estimated required memory for 30516 words and 429 dimensions: 126229324 bytes
[2023-02-07 18:24:38,066][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:24:38,125][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 30516 vocabulary and 429 features, using sg=1 hs=0 sample=0.3897155999476116 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-07T18:24:38.124981', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:24:39,134][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 28.00% examples, 1609114 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:40,137][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 56.46% examples, 1660609 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:41,141][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 87.07% examples, 1685264 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:41,540][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5778362 effective words) took 3.4s, 1692792 effective words/s
[2023-02-07 18:24:42,542][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 32.88% examples, 1919324 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:43,549][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 65.83% examples, 1935716 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:44,542][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5778362 effective words) took 3.0s, 1925943 effective words/s
[2023-02-07 18:24:45,545][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 28.00% examples, 1620786 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:46,549][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 56.03% examples, 1653309 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:47,549][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 84.89% examples, 1647414 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:48,048][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5778362 effective words) took 3.5s, 1649692 effective words/s
[2023-02-07 18:24:49,054][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 28.58% examples, 1650480 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:50,058][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 56.62% examples, 1666074 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:51,059][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 86.46% examples, 1674605 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:51,499][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5778362 effective words) took 3.4s, 1675232 effective words/s
[2023-02-07 18:24:52,505][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 29.26% examples, 1685794 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:53,517][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 57.48% examples, 1682665 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:54,522][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 87.07% examples, 1681810 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:54,926][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5778362 effective words) took 3.4s, 1687122 effective words/s
[2023-02-07 18:24:55,934][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 29.23% examples, 1680423 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:56,939][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 58.03% examples, 1702979 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:57,943][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 89.90% examples, 1733775 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:58,192][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5778362 effective words) took 3.3s, 1769886 effective words/s
[2023-02-07 18:24:59,199][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.29% examples, 2250406 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:00,199][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 73.99% examples, 2163046 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:00,935][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5778362 effective words) took 2.7s, 2107386 effective words/s
[2023-02-07 18:25:01,937][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 33.25% examples, 1945129 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:02,938][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 65.37% examples, 1924689 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:03,915][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5778362 effective words) took 3.0s, 1940454 effective words/s
[2023-02-07 18:25:04,919][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 34.02% examples, 1981538 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:05,921][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 67.45% examples, 1982063 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:06,843][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5778362 effective words) took 2.9s, 1974056 effective words/s
[2023-02-07 18:25:07,848][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 34.26% examples, 1993715 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:08,850][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 67.52% examples, 1983151 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:09,745][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5778362 effective words) took 2.9s, 1992225 effective words/s
[2023-02-07 18:25:10,748][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 34.33% examples, 2003150 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:11,753][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 68.65% examples, 2018232 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:12,616][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5778362 effective words) took 2.9s, 2014319 effective words/s
[2023-02-07 18:25:13,617][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 34.45% examples, 2013934 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:14,622][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 69.14% examples, 2035447 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:15,443][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5778362 effective words) took 2.8s, 2044811 effective words/s
[2023-02-07 18:25:16,453][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 31.65% examples, 1821852 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:25:17,454][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 61.28% examples, 1787690 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:18,454][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 92.20% examples, 1781659 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:18,690][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5778362 effective words) took 3.2s, 1780172 effective words/s
[2023-02-07 18:25:19,694][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 30.24% examples, 1749470 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:20,694][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 60.30% examples, 1766541 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:21,695][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 90.76% examples, 1760042 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:21,977][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5778362 effective words) took 3.3s, 1759234 effective words/s
[2023-02-07 18:25:22,982][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 30.33% examples, 1755618 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:23,983][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 59.93% examples, 1756805 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:24,984][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 90.91% examples, 1761774 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:25,259][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5778362 effective words) took 3.3s, 1761350 effective words/s
[2023-02-07 18:25:25,259][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86675430 effective words) took 47.1s, 1838898 effective words/s', 'datetime': '2023-02-07T18:25:25.259867', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:25:25.260 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:25:30,458][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182408-joygzhof/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:25:30.458779', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:25:30,459][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182408-joygzhof/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 18:25:30,506][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182408-joygzhof/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 18:25:30,550][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:25:30,581][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182408-joygzhof/files/../tmp/embedding_model.pt
2023-02-07 18:25:30.581 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:25:32.832 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:25:33.662 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:25:36.522 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.8919994457169602, 'test_mae': 0.7043865883002983, 'test_r2': -1.6836144606915138}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.82
wandb: percentage 0.28536
wandb:   test_mae 0.70439
wandb:   test_mse 0.892
wandb:    test_r2 -1.68361
wandb: 
wandb: üöÄ View run noble-sweep-6 at: https://wandb.ai/xiaoqiz/mof2vec/runs/joygzhof
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_182408-joygzhof/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: sn8zf3wx with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 781
wandb: 	model.gensim.alpha: 0.02239441409528664
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.609312895904489
wandb: 	model.gensim.vector_size: 237
wandb: 	model.gensim.window: 3
wandb: 	model.sklearn.learning_rate: 0.0005423446636321297
wandb: 	model.sklearn.max_depth: 92
wandb: 	model.sklearn.min_child_weight: 0.08500901230693991
wandb: 	model.sklearn.n_estimators: 2405
wandb: 	model.sklearn.num_leaves: 291
wandb: 	model.sklearn.reg_alpha: 0.012275923425398736
wandb: 	model.sklearn.reg_lambda: 0.0028750016967990463
wandb: 	model.sklearn.subsample: 0.23109690064786137
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182556-sn8zf3wx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/sn8zf3wx
2023-02-07 18:26:04.513 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 18:26:04.513 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 781 for sweep.
2023-02-07 18:26:04.514 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.02239441409528664 for sweep.
2023-02-07 18:26:04.514 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:26:04.514 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 18:26:04.514 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.609312895904489 for sweep.
2023-02-07 18:26:04.515 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 237 for sweep.
2023-02-07 18:26:04.515 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 3 for sweep.
2023-02-07 18:26:04.515 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0005423446636321297 for sweep.
2023-02-07 18:26:04.516 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 92 for sweep.
2023-02-07 18:26:04.516 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08500901230693991 for sweep.
2023-02-07 18:26:04.516 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2405 for sweep.
2023-02-07 18:26:04.516 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 291 for sweep.
2023-02-07 18:26:04.516 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.012275923425398736 for sweep.
2023-02-07 18:26:04.517 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0028750016967990463 for sweep.
2023-02-07 18:26:04.517 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.23109690064786137 for sweep.
2023-02-07 18:26:04.517 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:26:04.523 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182556-sn8zf3wx/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 781, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 237, 'window': 3, 'min_count': 2, 'dm': 1, 'sample': 0.609312895904489, 'workers': 4, 'alpha': 0.02239441409528664, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2405, 'max_depth': 92, 'num_leaves': 291, 'reg_alpha': 0.012275923425398736, 'reg_lambda': 0.0028750016967990463, 'subsample': 0.23109690064786137, 'min_child_weight': 0.08500901230693991, 'n_jobs': 4, 'learning_rate': 0.0005423446636321297}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:19, 167.88it/s]  1%|          | 39/3257 [00:00<00:16, 190.74it/s]  2%|‚ñè         | 59/3257 [00:00<00:17, 181.72it/s]  3%|‚ñé         | 82/3257 [00:00<00:16, 196.39it/s]  3%|‚ñé         | 103/3257 [00:00<00:15, 198.37it/s]  4%|‚ñç         | 123/3257 [00:00<00:17, 179.71it/s]  4%|‚ñç         | 145/3257 [00:00<00:16, 190.20it/s]  5%|‚ñå         | 165/3257 [00:00<00:16, 183.74it/s]  6%|‚ñå         | 187/3257 [00:00<00:16, 191.40it/s]  6%|‚ñã         | 207/3257 [00:01<00:15, 193.00it/s]  7%|‚ñã         | 232/3257 [00:01<00:14, 207.92it/s]  8%|‚ñä         | 253/3257 [00:01<00:14, 205.78it/s]  8%|‚ñä         | 276/3257 [00:01<00:14, 212.04it/s]  9%|‚ñâ         | 299/3257 [00:01<00:13, 215.62it/s] 10%|‚ñâ         | 321/3257 [00:01<00:13, 215.57it/s] 11%|‚ñà         | 343/3257 [00:01<00:14, 208.12it/s] 11%|‚ñà         | 365/3257 [00:01<00:13, 209.91it/s] 12%|‚ñà‚ñè        | 387/3257 [00:01<00:14, 192.86it/s] 13%|‚ñà‚ñé        | 411/3257 [00:02<00:14, 201.61it/s] 13%|‚ñà‚ñé        | 432/3257 [00:02<00:15, 181.40it/s] 14%|‚ñà‚ñç        | 451/3257 [00:02<00:15, 179.93it/s] 15%|‚ñà‚ñç        | 474/3257 [00:02<00:14, 189.05it/s] 15%|‚ñà‚ñå        | 494/3257 [00:02<00:14, 190.44it/s] 16%|‚ñà‚ñå        | 517/3257 [00:02<00:13, 199.00it/s] 17%|‚ñà‚ñã        | 538/3257 [00:02<00:13, 194.68it/s] 17%|‚ñà‚ñã        | 558/3257 [00:02<00:14, 183.98it/s] 18%|‚ñà‚ñä        | 577/3257 [00:03<00:15, 170.82it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:14, 183.65it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:14, 182.86it/s] 20%|‚ñà‚ñâ        | 642/3257 [00:03<00:13, 192.16it/s] 20%|‚ñà‚ñà        | 662/3257 [00:03<00:15, 172.95it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:14, 177.96it/s] 22%|‚ñà‚ñà‚ñè       | 703/3257 [00:03<00:13, 183.36it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:03<00:13, 182.97it/s] 23%|‚ñà‚ñà‚ñé       | 741/3257 [00:03<00:14, 174.06it/s] 23%|‚ñà‚ñà‚ñé       | 759/3257 [00:04<00:14, 174.14it/s] 24%|‚ñà‚ñà‚ñç       | 777/3257 [00:04<00:15, 160.70it/s] 24%|‚ñà‚ñà‚ñç       | 796/3257 [00:04<00:14, 165.83it/s] 25%|‚ñà‚ñà‚ñå       | 815/3257 [00:04<00:14, 170.19it/s] 26%|‚ñà‚ñà‚ñå       | 833/3257 [00:04<00:14, 168.11it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:04<00:14, 161.77it/s] 27%|‚ñà‚ñà‚ñã       | 870/3257 [00:04<00:13, 171.38it/s] 27%|‚ñà‚ñà‚ñã       | 888/3257 [00:04<00:13, 169.57it/s] 28%|‚ñà‚ñà‚ñä       | 909/3257 [00:04<00:13, 180.53it/s] 29%|‚ñà‚ñà‚ñä       | 930/3257 [00:04<00:12, 187.44it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:05<00:12, 186.82it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:05<00:11, 190.70it/s] 30%|‚ñà‚ñà‚ñà       | 990/3257 [00:05<00:12, 184.67it/s] 31%|‚ñà‚ñà‚ñà       | 1009/3257 [00:05<00:12, 181.79it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1028/3257 [00:05<00:12, 178.92it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:05<00:12, 177.31it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1066/3257 [00:05<00:11, 183.76it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1085/3257 [00:05<00:11, 182.54it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:05<00:11, 183.40it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:06<00:11, 181.95it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:06<00:11, 181.34it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1162/3257 [00:06<00:18, 115.45it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1178/3257 [00:06<00:17, 120.99it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:06<00:15, 129.28it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:06<00:15, 136.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:06<00:12, 156.89it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1250/3257 [00:06<00:12, 160.90it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:07<00:11, 173.39it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:07<00:11, 165.61it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:07<00:11, 168.63it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1331/3257 [00:07<00:10, 181.32it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:07<00:10, 181.81it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:07<00:10, 182.45it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1389/3257 [00:07<00:10, 177.67it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1413/3257 [00:07<00:09, 193.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1434/3257 [00:07<00:09, 195.25it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1458/3257 [00:08<00:08, 206.09it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1479/3257 [00:08<00:08, 202.24it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1502/3257 [00:08<00:08, 208.32it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1523/3257 [00:08<00:09, 190.73it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1543/3257 [00:08<00:09, 188.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1563/3257 [00:08<00:09, 184.55it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1582/3257 [00:08<00:09, 182.02it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1604/3257 [00:08<00:08, 190.39it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1624/3257 [00:08<00:08, 189.32it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1644/3257 [00:09<00:08, 181.23it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1663/3257 [00:09<00:09, 174.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1681/3257 [00:09<00:09, 172.68it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:09<00:08, 176.98it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1718/3257 [00:09<00:08, 177.01it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1736/3257 [00:09<00:09, 162.47it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1757/3257 [00:09<00:08, 174.14it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1777/3257 [00:09<00:08, 179.33it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1797/3257 [00:09<00:07, 184.40it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1816/3257 [00:10<00:08, 178.87it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1835/3257 [00:10<00:07, 178.00it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1855/3257 [00:10<00:07, 182.96it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1877/3257 [00:10<00:07, 191.65it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:10<00:07, 186.46it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1917/3257 [00:10<00:07, 186.94it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1940/3257 [00:10<00:06, 198.30it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:10<00:06, 209.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1987/3257 [00:10<00:06, 202.22it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:11<00:06, 201.64it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2032/3257 [00:11<00:05, 210.79it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2054/3257 [00:11<00:06, 187.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2074/3257 [00:11<00:06, 184.66it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2093/3257 [00:11<00:06, 184.17it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2112/3257 [00:11<00:06, 180.52it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2131/3257 [00:11<00:06, 171.25it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2149/3257 [00:11<00:06, 169.76it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2171/3257 [00:11<00:05, 182.80it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2190/3257 [00:12<00:05, 182.61it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:12<00:05, 177.67it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2228/3257 [00:12<00:05, 181.08it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2247/3257 [00:12<00:05, 177.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2266/3257 [00:12<00:05, 179.95it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2286/3257 [00:12<00:05, 183.48it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2306/3257 [00:12<00:05, 184.13it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2331/3257 [00:12<00:04, 202.88it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2357/3257 [00:12<00:04, 218.70it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2379/3257 [00:13<00:04, 205.14it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2401/3257 [00:13<00:04, 209.27it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2423/3257 [00:13<00:07, 115.59it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2441/3257 [00:13<00:06, 125.08it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2462/3257 [00:13<00:05, 141.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2484/3257 [00:13<00:04, 156.75it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2509/3257 [00:13<00:04, 177.96it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2533/3257 [00:14<00:03, 193.04it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2555/3257 [00:14<00:03, 185.29it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2575/3257 [00:14<00:03, 179.45it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2594/3257 [00:14<00:03, 179.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2621/3257 [00:14<00:03, 203.26it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2643/3257 [00:14<00:03, 201.53it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2664/3257 [00:14<00:03, 193.34it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2686/3257 [00:14<00:02, 199.88it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2707/3257 [00:14<00:03, 177.83it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2726/3257 [00:15<00:02, 178.82it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2749/3257 [00:15<00:02, 192.43it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2769/3257 [00:15<00:02, 182.07it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:15<00:02, 193.39it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:15<00:02, 192.63it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:15<00:02, 181.74it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:15<00:02, 185.93it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2881/3257 [00:15<00:01, 207.89it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:15<00:01, 189.62it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2927/3257 [00:16<00:01, 202.83it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2948/3257 [00:16<00:01, 184.46it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:16<00:01, 187.49it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2989/3257 [00:16<00:01, 182.25it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:16<00:01, 193.73it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3034/3257 [00:16<00:01, 200.69it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3058/3257 [00:16<00:00, 210.75it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3081/3257 [00:16<00:00, 214.31it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3104/3257 [00:16<00:00, 217.72it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:17<00:00, 219.89it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3150/3257 [00:17<00:00, 202.81it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3171/3257 [00:17<00:00, 203.51it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3192/3257 [00:17<00:00, 199.53it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:17<00:00, 189.35it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3237/3257 [00:17<00:00, 201.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 183.66it/s]
2023-02-07 18:26:23.069 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:26:23,071][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d237,n5,w3,mc2,s0.609313,t4>', 'datetime': '2023-02-07T18:26:23.071520', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:26:23,071][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:26:23,072][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:26:23,606][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 18:26:23,606][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:26:23,697][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 36619 unique words (85.76% of original 42701, drops 6082)', 'datetime': '2023-02-07T18:26:23.697033', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:26:23,697][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5816910 word corpus (99.90% of original 5822992, drops 6082)', 'datetime': '2023-02-07T18:26:23.697362', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:26:23,817][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 18:26:23,818][gensim.models.word2vec][INFO] - sample=0.609313 downsamples 0 most-common words
[2023-02-07 18:26:23,818][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5816910 word corpus (100.0%% of prior 5816910)', 'datetime': '2023-02-07T18:26:23.818281', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:26:24,028][gensim.models.word2vec][INFO] - estimated required memory for 36619 words and 237 dimensions: 91478160 bytes
[2023-02-07 18:26:24,029][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:26:24,066][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 36619 vocabulary and 237 features, using sg=0 hs=0 sample=0.609312895904489 negative=5 window=3 shrink_windows=True', 'datetime': '2023-02-07T18:26:24.066068', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:26:25,070][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 33.90% examples, 1980780 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:26,072][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 69.70% examples, 2059874 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:26,868][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5790320 effective words) took 2.8s, 2068429 effective words/s
[2023-02-07 18:26:27,872][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 30.33% examples, 1761690 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:28,881][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 59.41% examples, 1744937 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:26:29,882][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 95.00% examples, 1830823 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:30,011][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5790320 effective words) took 3.1s, 1843374 effective words/s
[2023-02-07 18:26:31,018][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 36.48% examples, 2146774 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:32,020][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 72.92% examples, 2135321 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:32,721][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5790320 effective words) took 2.7s, 2137314 effective words/s
[2023-02-07 18:26:33,727][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 36.14% examples, 2116469 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:34,729][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 73.56% examples, 2151199 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:26:35,418][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5790320 effective words) took 2.7s, 2148286 effective words/s
[2023-02-07 18:26:36,425][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 38.29% examples, 2255021 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:37,425][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 76.94% examples, 2245417 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:38,003][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5790320 effective words) took 2.6s, 2241522 effective words/s
[2023-02-07 18:26:39,013][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 36.97% examples, 2171771 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:40,016][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 75.47% examples, 2204423 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:40,612][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5790320 effective words) took 2.6s, 2220083 effective words/s
[2023-02-07 18:26:41,614][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.29% examples, 2266043 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:42,620][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 78.05% examples, 2273696 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:43,173][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5790320 effective words) took 2.6s, 2261914 effective words/s
[2023-02-07 18:26:44,181][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 38.99% examples, 2291697 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:45,183][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 78.05% examples, 2273340 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:45,722][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5790320 effective words) took 2.5s, 2273739 effective words/s
[2023-02-07 18:26:46,724][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 37.58% examples, 2228166 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:47,730][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 78.26% examples, 2279738 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:48,253][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5790320 effective words) took 2.5s, 2289227 effective words/s
[2023-02-07 18:26:49,259][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 34.45% examples, 2010135 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:50,269][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 68.65% examples, 2014313 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:51,154][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5790320 effective words) took 2.9s, 1997566 effective words/s
[2023-02-07 18:26:52,156][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 38.29% examples, 2264939 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:53,162][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 77.10% examples, 2249006 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:53,779][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5790320 effective words) took 2.6s, 2206951 effective words/s
[2023-02-07 18:26:54,784][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 34.85% examples, 2039712 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:55,785][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 69.48% examples, 2052624 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:56,604][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5790320 effective words) took 2.8s, 2052036 effective words/s
[2023-02-07 18:26:57,609][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 35.31% examples, 2068099 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:58,615][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 69.88% examples, 2061416 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:59,418][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5790320 effective words) took 2.8s, 2058478 effective words/s
[2023-02-07 18:27:00,425][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 34.45% examples, 2008930 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:01,432][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 68.99% examples, 2028292 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:02,263][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5790320 effective words) took 2.8s, 2036827 effective words/s
[2023-02-07 18:27:03,265][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 35.40% examples, 2081258 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:04,269][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 70.22% examples, 2071698 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:05,064][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5790320 effective words) took 2.8s, 2068322 effective words/s
[2023-02-07 18:27:05,064][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86854800 effective words) took 41.0s, 2118492 effective words/s', 'datetime': '2023-02-07T18:27:05.064926', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:27:05.065 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:27:08,350][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182556-sn8zf3wx/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:27:08.350440', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:27:08,351][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:27:08,463][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182556-sn8zf3wx/files/../tmp/embedding_model.pt
2023-02-07 18:27:08.464 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:27:09.966 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:27:10.470 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:27:12.163 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1072120726895534, 'test_mae': 0.7900408009535695, 'test_r2': -2.872400754050412}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.82
wandb: percentage 0.14243
wandb:   test_mae 0.79004
wandb:   test_mse 1.10721
wandb:    test_r2 -2.8724
wandb: 
wandb: üöÄ View run eager-sweep-7 at: https://wandb.ai/xiaoqiz/mof2vec/runs/sn8zf3wx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_182556-sn8zf3wx/logs
wandb: Agent Starting Run: 5gjzdjyd with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 602
wandb: 	model.gensim.alpha: 0.09436442819811657
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.6405450990873068
wandb: 	model.gensim.vector_size: 361
wandb: 	model.gensim.window: 4
wandb: 	model.sklearn.learning_rate: 0.0007977197486303266
wandb: 	model.sklearn.max_depth: 63
wandb: 	model.sklearn.min_child_weight: 0.08226032784533709
wandb: 	model.sklearn.n_estimators: 3480
wandb: 	model.sklearn.num_leaves: 287
wandb: 	model.sklearn.reg_alpha: 0.004643284527133774
wandb: 	model.sklearn.reg_lambda: 0.0270108090585717
wandb: 	model.sklearn.subsample: 0.3744289450450885
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182720-5gjzdjyd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/5gjzdjyd
2023-02-07 18:27:28.603 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 18:27:28.604 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 602 for sweep.
2023-02-07 18:27:28.604 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.09436442819811657 for sweep.
2023-02-07 18:27:28.604 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:27:28.604 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 18:27:28.605 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6405450990873068 for sweep.
2023-02-07 18:27:28.605 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 361 for sweep.
2023-02-07 18:27:28.606 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 4 for sweep.
2023-02-07 18:27:28.606 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0007977197486303266 for sweep.
2023-02-07 18:27:28.606 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 63 for sweep.
2023-02-07 18:27:28.606 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08226032784533709 for sweep.
2023-02-07 18:27:28.607 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3480 for sweep.
2023-02-07 18:27:28.607 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 287 for sweep.
2023-02-07 18:27:28.607 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004643284527133774 for sweep.
2023-02-07 18:27:28.607 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0270108090585717 for sweep.
2023-02-07 18:27:28.608 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3744289450450885 for sweep.
2023-02-07 18:27:28.608 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:27:28.614 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182720-5gjzdjyd/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 602, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 361, 'window': 4, 'min_count': 1, 'dm': 0, 'sample': 0.6405450990873068, 'workers': 4, 'alpha': 0.09436442819811657, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3480, 'max_depth': 63, 'num_leaves': 287, 'reg_alpha': 0.004643284527133774, 'reg_lambda': 0.0270108090585717, 'subsample': 0.3744289450450885, 'min_child_weight': 0.08226032784533709, 'n_jobs': 4, 'learning_rate': 0.0007977197486303266}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 168.90it/s]  1%|          | 37/3257 [00:00<00:17, 184.94it/s]  2%|‚ñè         | 56/3257 [00:00<00:17, 183.76it/s]  2%|‚ñè         | 79/3257 [00:00<00:15, 198.96it/s]  3%|‚ñé         | 99/3257 [00:00<00:16, 196.59it/s]  4%|‚ñé         | 119/3257 [00:00<00:16, 192.73it/s]  4%|‚ñç         | 140/3257 [00:00<00:15, 197.97it/s]  5%|‚ñç         | 160/3257 [00:00<00:15, 195.45it/s]  6%|‚ñå         | 180/3257 [00:00<00:16, 190.00it/s]  6%|‚ñå         | 201/3257 [00:01<00:15, 191.04it/s]  7%|‚ñã         | 227/3257 [00:01<00:14, 210.98it/s]  8%|‚ñä         | 249/3257 [00:01<00:14, 206.54it/s]  8%|‚ñä         | 270/3257 [00:01<00:14, 200.66it/s]  9%|‚ñâ         | 296/3257 [00:01<00:13, 214.69it/s] 10%|‚ñâ         | 318/3257 [00:01<00:14, 207.69it/s] 10%|‚ñà         | 339/3257 [00:01<00:14, 206.89it/s] 11%|‚ñà         | 360/3257 [00:01<00:14, 205.14it/s] 12%|‚ñà‚ñè        | 381/3257 [00:01<00:14, 192.39it/s] 12%|‚ñà‚ñè        | 401/3257 [00:02<00:14, 191.03it/s] 13%|‚ñà‚ñé        | 421/3257 [00:02<00:14, 190.19it/s] 14%|‚ñà‚ñé        | 441/3257 [00:02<00:16, 172.43it/s] 14%|‚ñà‚ñç        | 464/3257 [00:02<00:14, 186.61it/s] 15%|‚ñà‚ñç        | 484/3257 [00:02<00:15, 184.13it/s] 16%|‚ñà‚ñå        | 506/3257 [00:02<00:14, 193.76it/s] 16%|‚ñà‚ñå        | 526/3257 [00:02<00:21, 130.04it/s] 17%|‚ñà‚ñã        | 547/3257 [00:02<00:18, 146.09it/s] 17%|‚ñà‚ñã        | 565/3257 [00:03<00:18, 149.24it/s] 18%|‚ñà‚ñä        | 582/3257 [00:03<00:17, 153.28it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:15, 168.15it/s] 19%|‚ñà‚ñâ        | 624/3257 [00:03<00:14, 176.47it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:14, 181.70it/s] 20%|‚ñà‚ñà        | 664/3257 [00:03<00:14, 177.58it/s] 21%|‚ñà‚ñà        | 684/3257 [00:03<00:14, 182.80it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:03<00:13, 186.12it/s] 22%|‚ñà‚ñà‚ñè       | 723/3257 [00:03<00:13, 182.27it/s] 23%|‚ñà‚ñà‚ñé       | 742/3257 [00:04<00:13, 179.92it/s] 24%|‚ñà‚ñà‚ñé       | 766/3257 [00:04<00:12, 195.12it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:04<00:13, 181.58it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:13, 181.95it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:04<00:13, 180.96it/s] 26%|‚ñà‚ñà‚ñå       | 844/3257 [00:04<00:13, 175.85it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:04<00:13, 181.05it/s] 27%|‚ñà‚ñà‚ñã       | 883/3257 [00:04<00:12, 182.94it/s] 28%|‚ñà‚ñà‚ñä       | 904/3257 [00:04<00:12, 189.82it/s] 28%|‚ñà‚ñà‚ñä       | 924/3257 [00:05<00:12, 191.91it/s] 29%|‚ñà‚ñà‚ñâ       | 944/3257 [00:05<00:12, 188.75it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:05<00:11, 196.02it/s] 30%|‚ñà‚ñà‚ñà       | 986/3257 [00:05<00:12, 188.36it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:05<00:12, 186.13it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:05<00:12, 183.76it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:05<00:12, 184.02it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1066/3257 [00:05<00:11, 188.27it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1085/3257 [00:05<00:11, 186.46it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1104/3257 [00:05<00:11, 186.49it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:06<00:11, 183.20it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1142/3257 [00:06<00:11, 179.95it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1163/3257 [00:06<00:11, 187.37it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1182/3257 [00:06<00:11, 178.64it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1200/3257 [00:06<00:11, 171.67it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:06<00:11, 173.56it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:06<00:10, 189.68it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:06<00:10, 192.22it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1282/3257 [00:06<00:10, 180.44it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1302/3257 [00:07<00:10, 181.91it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1324/3257 [00:07<00:10, 191.18it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:07<00:09, 193.34it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:07<00:10, 183.88it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1383/3257 [00:07<00:10, 178.64it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1405/3257 [00:07<00:09, 188.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1427/3257 [00:07<00:09, 197.49it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1448/3257 [00:07<00:09, 197.80it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1471/3257 [00:07<00:08, 205.25it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1492/3257 [00:08<00:08, 204.57it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1514/3257 [00:08<00:08, 205.76it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1535/3257 [00:08<00:09, 188.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:08<00:09, 188.16it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:08<00:08, 189.13it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1598/3257 [00:08<00:08, 198.29it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:08<00:08, 203.97it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1641/3257 [00:08<00:08, 200.35it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:08<00:08, 192.54it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1682/3257 [00:09<00:08, 192.39it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1703/3257 [00:09<00:07, 197.33it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:09<00:07, 193.25it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1743/3257 [00:09<00:09, 168.09it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:09<00:08, 171.64it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1781/3257 [00:09<00:08, 173.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1799/3257 [00:09<00:08, 169.69it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1817/3257 [00:10<00:15, 94.25it/s]  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1831/3257 [00:10<00:14, 101.41it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:10<00:12, 116.62it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:10<00:10, 131.35it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1886/3257 [00:10<00:09, 139.33it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1903/3257 [00:10<00:09, 144.84it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1919/3257 [00:10<00:09, 145.10it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:10<00:08, 153.83it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1960/3257 [00:10<00:07, 173.92it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1979/3257 [00:11<00:07, 165.37it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1997/3257 [00:11<00:07, 168.39it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2015/3257 [00:11<00:07, 165.62it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2034/3257 [00:11<00:07, 169.50it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:11<00:07, 159.27it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2069/3257 [00:11<00:07, 154.90it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2086/3257 [00:11<00:07, 157.38it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2102/3257 [00:11<00:07, 155.83it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:11<00:07, 154.62it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:12<00:07, 152.64it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2152/3257 [00:12<00:07, 149.30it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:12<00:07, 153.09it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:12<00:07, 153.12it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:12<00:06, 161.88it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2221/3257 [00:12<00:06, 161.92it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:12<00:06, 155.80it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2255/3257 [00:12<00:06, 157.15it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2271/3257 [00:12<00:06, 150.58it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2291/3257 [00:13<00:06, 160.93it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2308/3257 [00:13<00:06, 158.14it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2330/3257 [00:13<00:05, 173.39it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2352/3257 [00:13<00:04, 185.31it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2371/3257 [00:13<00:04, 178.06it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2393/3257 [00:13<00:04, 185.42it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2412/3257 [00:13<00:04, 174.85it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2430/3257 [00:13<00:04, 171.10it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2448/3257 [00:13<00:05, 159.95it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2469/3257 [00:14<00:04, 172.81it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2487/3257 [00:14<00:04, 169.74it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2508/3257 [00:14<00:04, 178.13it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2526/3257 [00:14<00:04, 178.30it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2545/3257 [00:14<00:03, 180.66it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2564/3257 [00:14<00:04, 169.38it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2582/3257 [00:14<00:04, 160.96it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2599/3257 [00:14<00:04, 160.99it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2623/3257 [00:14<00:03, 180.42it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2642/3257 [00:15<00:03, 176.32it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2660/3257 [00:15<00:03, 161.65it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2678/3257 [00:15<00:03, 166.34it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2695/3257 [00:15<00:03, 158.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2712/3257 [00:15<00:03, 148.58it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2728/3257 [00:15<00:03, 150.90it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2747/3257 [00:15<00:03, 158.90it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2764/3257 [00:15<00:03, 156.91it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2780/3257 [00:15<00:03, 156.17it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2801/3257 [00:16<00:02, 170.94it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2819/3257 [00:16<00:02, 162.70it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2836/3257 [00:16<00:02, 155.60it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2855/3257 [00:16<00:02, 163.88it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2880/3257 [00:16<00:02, 186.23it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2899/3257 [00:16<00:02, 168.51it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2917/3257 [00:16<00:02, 168.75it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2935/3257 [00:16<00:01, 169.30it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2953/3257 [00:17<00:01, 160.29it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2971/3257 [00:17<00:01, 164.12it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2988/3257 [00:17<00:01, 154.70it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3006/3257 [00:17<00:01, 160.99it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3023/3257 [00:17<00:01, 155.86it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3044/3257 [00:17<00:01, 169.86it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3065/3257 [00:17<00:01, 180.91it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3084/3257 [00:17<00:00, 180.31it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3103/3257 [00:17<00:00, 182.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3123/3257 [00:17<00:00, 185.41it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3142/3257 [00:18<00:00, 169.54it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3160/3257 [00:18<00:00, 162.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3177/3257 [00:18<00:00, 157.12it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3197/3257 [00:18<00:00, 163.44it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3214/3257 [00:18<00:00, 155.46it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3234/3257 [00:18<00:00, 166.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:18<00:00, 169.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 173.15it/s]
2023-02-07 18:27:48.219 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:27:48,221][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d361,n5,s0.640545,t4>', 'datetime': '2023-02-07T18:27:48.220954', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:27:48,221][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:27:48,221][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:27:48,720][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 18:27:48,721][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:27:48,811][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 31803 unique words (100.00% of original 31803, drops 0)', 'datetime': '2023-02-07T18:27:48.811628', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:27:48,813][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 5095118 word corpus (100.00% of original 5095118, drops 0)', 'datetime': '2023-02-07T18:27:48.813535', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:27:48,928][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 18:27:48,930][gensim.models.word2vec][INFO] - sample=0.640545 downsamples 0 most-common words
[2023-02-07 18:27:48,930][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5095118 word corpus (100.0%% of prior 5095118)', 'datetime': '2023-02-07T18:27:48.930412', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:27:49,129][gensim.models.word2vec][INFO] - estimated required memory for 31803 words and 361 dimensions: 113103072 bytes
[2023-02-07 18:27:49,130][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:27:49,186][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 31803 vocabulary and 361 features, using sg=1 hs=0 sample=0.6405450990873068 negative=5 window=4 shrink_windows=True', 'datetime': '2023-02-07T18:27:49.186885', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:27:50,197][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 36.91% examples, 1916321 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:51,197][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 76.85% examples, 1971787 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:27:51,640][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5086629 effective words) took 2.4s, 2077677 effective words/s
[2023-02-07 18:27:52,643][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 52.47% examples, 2727310 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:27:53,606][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5086629 effective words) took 2.0s, 2589730 effective words/s
[2023-02-07 18:27:54,615][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 43.84% examples, 2268776 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:55,616][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 90.11% examples, 2296663 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:27:55,814][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5086629 effective words) took 2.2s, 2305101 effective words/s
[2023-02-07 18:27:56,819][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 44.89% examples, 2323565 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:27:57,820][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 92.14% examples, 2352236 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:57,968][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5086629 effective words) took 2.2s, 2362551 effective words/s
[2023-02-07 18:27:58,971][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 46.91% examples, 2431939 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:27:59,976][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 94.90% examples, 2414059 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:00,077][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5086629 effective words) took 2.1s, 2414217 effective words/s
[2023-02-07 18:28:01,079][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 46.45% examples, 2400938 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:02,079][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 93.28% examples, 2384345 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:02,205][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5086629 effective words) took 2.1s, 2392704 effective words/s
[2023-02-07 18:28:03,209][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 35.98% examples, 1856641 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:04,215][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 72.64% examples, 1867516 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:04,922][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5086629 effective words) took 2.7s, 1873766 effective words/s
[2023-02-07 18:28:05,926][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 46.39% examples, 2391173 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:28:06,931][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 94.60% examples, 2404103 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:07,034][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5086629 effective words) took 2.1s, 2409909 effective words/s
[2023-02-07 18:28:08,037][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 46.21% examples, 2387691 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:09,040][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 94.44% examples, 2403490 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:09,146][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5086629 effective words) took 2.1s, 2410930 effective words/s
[2023-02-07 18:28:10,151][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.44% examples, 1889491 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:11,151][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 73.63% examples, 1896380 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:11,704][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5086629 effective words) took 2.6s, 1991844 effective words/s
[2023-02-07 18:28:12,707][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 47.62% examples, 2471858 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:13,710][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 94.44% examples, 2403324 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:13,835][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5086629 effective words) took 2.1s, 2389107 effective words/s
[2023-02-07 18:28:14,839][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 40.50% examples, 2111027 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:15,841][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 82.47% examples, 2108643 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:16,245][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5086629 effective words) took 2.4s, 2111756 effective words/s
[2023-02-07 18:28:17,248][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 40.50% examples, 2114488 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:18,250][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 82.78% examples, 2117733 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:18,648][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5086629 effective words) took 2.4s, 2118520 effective words/s
[2023-02-07 18:28:19,656][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 40.50% examples, 2104521 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:28:20,663][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 82.16% examples, 2092886 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:21,070][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5086629 effective words) took 2.4s, 2101980 effective words/s
[2023-02-07 18:28:22,073][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 39.51% examples, 2067721 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:28:23,077][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 81.24% examples, 2078028 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:23,531][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5086629 effective words) took 2.5s, 2068141 effective words/s
[2023-02-07 18:28:23,532][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76299435 effective words) took 34.3s, 2221769 effective words/s', 'datetime': '2023-02-07T18:28:23.532336', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:28:23.533 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:28:27,032][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182720-5gjzdjyd/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:28:27.032882', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:28:27,033][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182720-5gjzdjyd/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 18:28:27,076][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182720-5gjzdjyd/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 18:28:27,115][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:28:27,147][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182720-5gjzdjyd/files/../tmp/embedding_model.pt
2023-02-07 18:28:27.147 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:28:29.055 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:28:29.742 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:28:32.039 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0795104844688115, 'test_mae': 0.7885905025652581, 'test_r2': -3.087855567030232}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.94
wandb: percentage 0.0
wandb:   test_mae 0.78859
wandb:   test_mse 1.07951
wandb:    test_r2 -3.08786
wandb: 
wandb: üöÄ View run warm-sweep-8 at: https://wandb.ai/xiaoqiz/mof2vec/runs/5gjzdjyd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_182720-5gjzdjyd/logs
wandb: Agent Starting Run: l3tmee6h with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 500
wandb: 	model.gensim.alpha: 0.11726498277581134
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.2213392272019279
wandb: 	model.gensim.vector_size: 425
wandb: 	model.gensim.window: 13
wandb: 	model.sklearn.learning_rate: 0.0122371156064008
wandb: 	model.sklearn.max_depth: 76
wandb: 	model.sklearn.min_child_weight: 0.08611563458466218
wandb: 	model.sklearn.n_estimators: 3996
wandb: 	model.sklearn.num_leaves: 458
wandb: 	model.sklearn.reg_alpha: 0.002887991842511773
wandb: 	model.sklearn.reg_lambda: 0.009101540002223593
wandb: 	model.sklearn.subsample: 0.6038600285685041
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182844-l3tmee6h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/l3tmee6h
2023-02-07 18:28:53.571 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 18:28:53.571 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 500 for sweep.
2023-02-07 18:28:53.572 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.11726498277581134 for sweep.
2023-02-07 18:28:53.572 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:28:53.572 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 18:28:53.572 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2213392272019279 for sweep.
2023-02-07 18:28:53.573 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 425 for sweep.
2023-02-07 18:28:53.573 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 13 for sweep.
2023-02-07 18:28:53.573 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0122371156064008 for sweep.
2023-02-07 18:28:53.573 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 76 for sweep.
2023-02-07 18:28:53.574 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08611563458466218 for sweep.
2023-02-07 18:28:53.574 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3996 for sweep.
2023-02-07 18:28:53.574 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 458 for sweep.
2023-02-07 18:28:53.574 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.002887991842511773 for sweep.
2023-02-07 18:28:53.575 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.009101540002223593 for sweep.
2023-02-07 18:28:53.575 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6038600285685041 for sweep.
2023-02-07 18:28:53.575 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:28:53.586 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182844-l3tmee6h/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 500, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 425, 'window': 13, 'min_count': 5, 'dm': 0, 'sample': 0.2213392272019279, 'workers': 4, 'alpha': 0.11726498277581134, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3996, 'max_depth': 76, 'num_leaves': 458, 'reg_alpha': 0.002887991842511773, 'reg_lambda': 0.009101540002223593, 'subsample': 0.6038600285685041, 'min_child_weight': 0.08611563458466218, 'n_jobs': 4, 'learning_rate': 0.0122371156064008}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 4/3257 [00:00<03:02, 17.79it/s]  1%|          | 19/3257 [00:00<00:47, 68.46it/s]  1%|          | 34/3257 [00:00<00:33, 96.02it/s]  2%|‚ñè         | 51/3257 [00:00<00:26, 119.43it/s]  2%|‚ñè         | 67/3257 [00:00<00:25, 126.04it/s]  3%|‚ñé         | 86/3257 [00:00<00:21, 145.14it/s]  3%|‚ñé         | 102/3257 [00:00<00:21, 147.67it/s]  4%|‚ñé         | 118/3257 [00:00<00:22, 142.27it/s]  4%|‚ñç         | 134/3257 [00:01<00:21, 146.24it/s]  5%|‚ñç         | 152/3257 [00:01<00:20, 154.60it/s]  5%|‚ñå         | 168/3257 [00:01<00:20, 151.32it/s]  6%|‚ñå         | 184/3257 [00:01<00:20, 150.81it/s]  6%|‚ñå         | 201/3257 [00:01<00:20, 151.81it/s]  7%|‚ñã         | 221/3257 [00:01<00:18, 165.50it/s]  7%|‚ñã         | 240/3257 [00:01<00:17, 172.53it/s]  8%|‚ñä         | 258/3257 [00:01<00:17, 167.80it/s]  8%|‚ñä         | 275/3257 [00:01<00:17, 167.45it/s]  9%|‚ñâ         | 296/3257 [00:02<00:16, 177.67it/s] 10%|‚ñâ         | 314/3257 [00:02<00:17, 164.81it/s] 10%|‚ñà         | 333/3257 [00:02<00:17, 171.69it/s] 11%|‚ñà         | 351/3257 [00:02<00:17, 163.03it/s] 11%|‚ñà‚ñè        | 368/3257 [00:02<00:17, 162.86it/s] 12%|‚ñà‚ñè        | 385/3257 [00:02<00:18, 156.22it/s] 12%|‚ñà‚ñè        | 401/3257 [00:02<00:18, 153.67it/s] 13%|‚ñà‚ñé        | 418/3257 [00:02<00:18, 156.45it/s] 13%|‚ñà‚ñé        | 434/3257 [00:02<00:21, 131.92it/s] 14%|‚ñà‚ñç        | 451/3257 [00:03<00:19, 140.56it/s] 14%|‚ñà‚ñç        | 468/3257 [00:03<00:18, 147.25it/s] 15%|‚ñà‚ñç        | 484/3257 [00:03<00:19, 143.74it/s] 15%|‚ñà‚ñå        | 503/3257 [00:03<00:17, 154.32it/s] 16%|‚ñà‚ñå        | 520/3257 [00:03<00:17, 157.16it/s] 16%|‚ñà‚ñã        | 536/3257 [00:03<00:18, 151.05it/s] 17%|‚ñà‚ñã        | 553/3257 [00:03<00:17, 154.89it/s] 17%|‚ñà‚ñã        | 569/3257 [00:03<00:18, 146.23it/s] 18%|‚ñà‚ñä        | 584/3257 [00:03<00:19, 139.89it/s] 18%|‚ñà‚ñä        | 601/3257 [00:04<00:17, 148.03it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:04<00:17, 147.79it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:04<00:16, 157.41it/s] 20%|‚ñà‚ñà        | 655/3257 [00:04<00:17, 147.81it/s] 21%|‚ñà‚ñà        | 670/3257 [00:04<00:17, 148.24it/s] 21%|‚ñà‚ñà        | 685/3257 [00:04<00:17, 143.51it/s] 21%|‚ñà‚ñà‚ñè       | 700/3257 [00:04<00:17, 145.17it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:16, 154.31it/s] 23%|‚ñà‚ñà‚ñé       | 734/3257 [00:04<00:17, 147.98it/s] 23%|‚ñà‚ñà‚ñé       | 749/3257 [00:05<00:17, 143.52it/s] 24%|‚ñà‚ñà‚ñé       | 769/3257 [00:05<00:15, 156.53it/s] 24%|‚ñà‚ñà‚ñç       | 785/3257 [00:05<00:16, 147.38it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:15, 156.27it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:05<00:15, 159.98it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:05<00:15, 160.01it/s] 26%|‚ñà‚ñà‚ñã       | 862/3257 [00:05<00:13, 173.03it/s] 27%|‚ñà‚ñà‚ñã       | 880/3257 [00:05<00:13, 173.03it/s] 28%|‚ñà‚ñà‚ñä       | 902/3257 [00:05<00:12, 186.30it/s] 28%|‚ñà‚ñà‚ñä       | 924/3257 [00:06<00:12, 193.49it/s] 29%|‚ñà‚ñà‚ñâ       | 944/3257 [00:06<00:12, 192.51it/s] 30%|‚ñà‚ñà‚ñâ       | 967/3257 [00:06<00:11, 197.85it/s] 30%|‚ñà‚ñà‚ñà       | 987/3257 [00:06<00:11, 190.50it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:06<00:12, 186.33it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:06<00:12, 184.52it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:06<00:11, 184.26it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:06<00:11, 186.47it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:06<00:11, 190.76it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1108/3257 [00:07<00:11, 192.20it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1128/3257 [00:07<00:11, 181.51it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1147/3257 [00:07<00:11, 177.69it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:11, 185.63it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1189/3257 [00:07<00:12, 164.50it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:07<00:12, 166.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1229/3257 [00:07<00:11, 180.11it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1248/3257 [00:07<00:11, 178.08it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1270/3257 [00:07<00:10, 187.81it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:08<00:11, 168.88it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:08<00:11, 171.17it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1327/3257 [00:08<00:16, 115.37it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:08<00:14, 129.47it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:08<00:13, 138.75it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1381/3257 [00:08<00:12, 144.65it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1401/3257 [00:08<00:11, 158.51it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:09<00:10, 171.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1443/3257 [00:09<00:10, 176.92it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1466/3257 [00:09<00:09, 190.19it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1486/3257 [00:09<00:09, 188.83it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1509/3257 [00:09<00:08, 198.02it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:09<00:09, 180.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1549/3257 [00:09<00:09, 174.40it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1567/3257 [00:09<00:09, 175.88it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1585/3257 [00:09<00:09, 176.06it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1605/3257 [00:10<00:09, 180.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1624/3257 [00:10<00:09, 180.12it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1643/3257 [00:10<00:09, 174.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:10<00:09, 166.95it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1678/3257 [00:10<00:09, 165.67it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1697/3257 [00:10<00:09, 172.02it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:10<00:08, 172.63it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1733/3257 [00:10<00:09, 162.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1752/3257 [00:10<00:08, 167.76it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1772/3257 [00:10<00:08, 176.76it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:11<00:08, 181.45it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1811/3257 [00:11<00:08, 169.75it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1829/3257 [00:11<00:08, 169.48it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:11<00:07, 177.34it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:11<00:07, 183.20it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1888/3257 [00:11<00:07, 183.52it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1908/3257 [00:11<00:07, 186.58it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1927/3257 [00:11<00:07, 181.75it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:11<00:06, 203.87it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1975/3257 [00:12<00:06, 204.17it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1996/3257 [00:12<00:06, 199.36it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2016/3257 [00:12<00:06, 189.88it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2036/3257 [00:12<00:06, 190.68it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2056/3257 [00:12<00:07, 171.39it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2074/3257 [00:12<00:06, 172.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2092/3257 [00:12<00:06, 172.34it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2110/3257 [00:12<00:06, 170.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2128/3257 [00:12<00:06, 162.83it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2145/3257 [00:13<00:07, 157.45it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2167/3257 [00:13<00:06, 173.41it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:13<00:06, 169.39it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2206/3257 [00:13<00:05, 175.23it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2224/3257 [00:13<00:05, 175.06it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2242/3257 [00:13<00:05, 172.31it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:13<00:05, 171.80it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2278/3257 [00:13<00:05, 166.89it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:13<00:05, 175.36it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2321/3257 [00:14<00:04, 187.87it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2343/3257 [00:14<00:04, 196.78it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2364/3257 [00:14<00:04, 199.31it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2385/3257 [00:14<00:04, 200.35it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2406/3257 [00:14<00:04, 189.69it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2426/3257 [00:14<00:04, 190.03it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2446/3257 [00:14<00:04, 177.70it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2467/3257 [00:14<00:04, 185.57it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2487/3257 [00:14<00:04, 188.94it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2511/3257 [00:15<00:03, 201.16it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2534/3257 [00:15<00:03, 207.83it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2555/3257 [00:15<00:03, 189.04it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2575/3257 [00:15<00:03, 181.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2594/3257 [00:15<00:03, 177.99it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2620/3257 [00:15<00:03, 199.91it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2641/3257 [00:15<00:03, 201.16it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2662/3257 [00:15<00:03, 186.21it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2685/3257 [00:15<00:02, 197.58it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2706/3257 [00:16<00:05, 101.32it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2722/3257 [00:16<00:04, 109.81it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2746/3257 [00:16<00:03, 134.14it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2764/3257 [00:16<00:03, 143.24it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2782/3257 [00:16<00:03, 151.80it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2806/3257 [00:16<00:02, 169.97it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2826/3257 [00:17<00:02, 166.08it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2845/3257 [00:17<00:02, 169.02it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:17<00:01, 194.61it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2893/3257 [00:17<00:01, 190.25it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2914/3257 [00:17<00:01, 194.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2935/3257 [00:17<00:01, 190.98it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2955/3257 [00:17<00:01, 180.88it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:17<00:01, 180.24it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2995/3257 [00:17<00:01, 179.94it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:18<00:01, 187.69it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3038/3257 [00:18<00:01, 196.44it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3061/3257 [00:18<00:00, 205.51it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:18<00:00, 201.73it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3104/3257 [00:18<00:00, 205.69it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:18<00:00, 206.23it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3148/3257 [00:18<00:00, 193.36it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3168/3257 [00:18<00:00, 194.81it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3188/3257 [00:18<00:00, 188.40it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3208/3257 [00:18<00:00, 189.49it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3228/3257 [00:19<00:00, 188.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:19<00:00, 195.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 169.27it/s]
2023-02-07 18:29:13.606 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:29:13,608][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d425,n5,mc5,s0.221339,t4>', 'datetime': '2023-02-07T18:29:13.607957', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:29:13,608][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:29:13,609][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:29:14,141][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 18:29:14,141][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:29:14,201][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 21312 unique words (49.91% of original 42701, drops 21389)', 'datetime': '2023-02-07T18:29:14.201395', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:29:14,201][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5769229 word corpus (99.08% of original 5822992, drops 53763)', 'datetime': '2023-02-07T18:29:14.201812', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:29:14,274][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 18:29:14,275][gensim.models.word2vec][INFO] - sample=0.221339 downsamples 0 most-common words
[2023-02-07 18:29:14,278][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5769229 word corpus (100.0%% of prior 5769229)', 'datetime': '2023-02-07T18:29:14.278553', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:29:14,407][gensim.models.word2vec][INFO] - estimated required memory for 21312 words and 425 dimensions: 89305100 bytes
[2023-02-07 18:29:14,408][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:29:14,449][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 21312 vocabulary and 425 features, using sg=1 hs=0 sample=0.2213392272019279 negative=5 window=13 shrink_windows=True', 'datetime': '2023-02-07T18:29:14.449361', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:29:15,452][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 34.85% examples, 2026777 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:16,453][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 70.62% examples, 2071918 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:17,201][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5743174 effective words) took 2.8s, 2088234 effective words/s
[2023-02-07 18:29:18,208][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 39.94% examples, 2347614 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:19,209][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 75.47% examples, 2193355 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:29:19,860][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5743174 effective words) took 2.7s, 2161276 effective words/s
[2023-02-07 18:29:20,863][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 35.49% examples, 2065863 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:21,873][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 70.62% examples, 2062392 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:22,654][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5743174 effective words) took 2.8s, 2057021 effective words/s
[2023-02-07 18:29:23,662][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 35.31% examples, 2047845 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:24,663][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 70.34% examples, 2057714 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:25,440][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5743174 effective words) took 2.8s, 2063004 effective words/s
[2023-02-07 18:29:26,448][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 35.31% examples, 2048336 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:27,452][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 70.62% examples, 2064303 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:28,244][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5743174 effective words) took 2.8s, 2050227 effective words/s
[2023-02-07 18:29:29,247][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 35.49% examples, 2066958 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:29:30,249][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 70.34% examples, 2061321 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:29:31,026][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5743174 effective words) took 2.8s, 2065914 effective words/s
[2023-02-07 18:29:32,031][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 29.23% examples, 1677488 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:29:33,036][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 65.21% examples, 1895460 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:33,898][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5743174 effective words) took 2.9s, 2001028 effective words/s
[2023-02-07 18:29:34,901][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 39.15% examples, 2303459 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:29:35,907][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 79.28% examples, 2294270 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:36,404][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5743174 effective words) took 2.5s, 2293459 effective words/s
[2023-02-07 18:29:37,410][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 37.24% examples, 2185314 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:38,411][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 69.14% examples, 2022217 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:29:39,330][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5743174 effective words) took 2.9s, 1963885 effective words/s
[2023-02-07 18:29:40,334][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 39.09% examples, 2294312 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:29:41,334][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 79.49% examples, 2310823 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:29:41,810][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5743174 effective words) took 2.5s, 2318926 effective words/s
[2023-02-07 18:29:42,815][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 32.51% examples, 1883752 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:43,817][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 64.84% examples, 1890660 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:44,819][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 98.62% examples, 1886142 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:44,854][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5743174 effective words) took 3.0s, 1887910 effective words/s
[2023-02-07 18:29:45,864][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 39.94% examples, 2339067 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:29:46,867][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 82.04% examples, 2359602 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:47,290][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5743174 effective words) took 2.4s, 2359003 effective words/s
[2023-02-07 18:29:48,296][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 40.65% examples, 2388723 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:49,298][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 82.68% examples, 2383118 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:49,699][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5743174 effective words) took 2.4s, 2385696 effective words/s
[2023-02-07 18:29:50,704][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 36.48% examples, 2135527 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:51,704][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 71.91% examples, 2097592 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:29:52,470][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5743174 effective words) took 2.8s, 2073418 effective words/s
[2023-02-07 18:29:53,474][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 34.69% examples, 2017471 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:54,474][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 65.77% examples, 1925320 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:55,479][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 93.74% examples, 1798862 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:55,683][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5743174 effective words) took 3.2s, 1788543 effective words/s
[2023-02-07 18:29:55,684][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86147610 effective words) took 41.2s, 2089205 effective words/s', 'datetime': '2023-02-07T18:29:55.684460', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:29:55.684 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:29:59,912][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182844-l3tmee6h/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:29:59.912444', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:29:59,913][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:30:00,037][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182844-l3tmee6h/files/../tmp/embedding_model.pt
2023-02-07 18:30:00.038 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:30:02.601 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:30:03.470 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:30:07.042 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0954504681518284, 'test_mae': 0.7859651359038119, 'test_r2': -3.0693089225944306}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.92
wandb: percentage 0.5009
wandb:   test_mae 0.78597
wandb:   test_mse 1.09545
wandb:    test_r2 -3.06931
wandb: 
wandb: üöÄ View run dandy-sweep-9 at: https://wandb.ai/xiaoqiz/mof2vec/runs/l3tmee6h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_182844-l3tmee6h/logs
wandb: Agent Starting Run: b8x0zr2o with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 734
wandb: 	model.gensim.alpha: 0.03223544198904589
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 4
wandb: 	model.gensim.sample: 0.48622292548418256
wandb: 	model.gensim.vector_size: 372
wandb: 	model.gensim.window: 5
wandb: 	model.sklearn.learning_rate: 0.3921986301322621
wandb: 	model.sklearn.max_depth: 15
wandb: 	model.sklearn.min_child_weight: 0.0995216451792491
wandb: 	model.sklearn.n_estimators: 779
wandb: 	model.sklearn.num_leaves: 496
wandb: 	model.sklearn.reg_alpha: 0.0061704011090666245
wandb: 	model.sklearn.reg_lambda: 0.04372164147397283
wandb: 	model.sklearn.subsample: 0.6184857865871098
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183019-b8x0zr2o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/b8x0zr2o
2023-02-07 18:30:27.471 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 18:30:27.472 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 734 for sweep.
2023-02-07 18:30:27.472 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.03223544198904589 for sweep.
2023-02-07 18:30:27.473 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:30:27.473 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 4 for sweep.
2023-02-07 18:30:27.473 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.48622292548418256 for sweep.
2023-02-07 18:30:27.474 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 372 for sweep.
2023-02-07 18:30:27.474 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 5 for sweep.
2023-02-07 18:30:27.474 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.3921986301322621 for sweep.
2023-02-07 18:30:27.474 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 15 for sweep.
2023-02-07 18:30:27.475 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0995216451792491 for sweep.
2023-02-07 18:30:27.475 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 779 for sweep.
2023-02-07 18:30:27.475 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 496 for sweep.
2023-02-07 18:30:27.475 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0061704011090666245 for sweep.
2023-02-07 18:30:27.476 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.04372164147397283 for sweep.
2023-02-07 18:30:27.476 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6184857865871098 for sweep.
2023-02-07 18:30:27.476 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:30:27.485 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183019-b8x0zr2o/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 734, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 372, 'window': 5, 'min_count': 4, 'dm': 1, 'sample': 0.48622292548418256, 'workers': 4, 'alpha': 0.03223544198904589, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 779, 'max_depth': 15, 'num_leaves': 496, 'reg_alpha': 0.0061704011090666245, 'reg_lambda': 0.04372164147397283, 'subsample': 0.6184857865871098, 'min_child_weight': 0.0995216451792491, 'n_jobs': 4, 'learning_rate': 0.3921986301322621}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 138.33it/s]  1%|          | 30/3257 [00:00<00:21, 148.84it/s]  1%|‚ñè         | 47/3257 [00:00<00:20, 155.46it/s]  2%|‚ñè         | 64/3257 [00:00<00:19, 161.04it/s]  2%|‚ñè         | 81/3257 [00:00<00:19, 159.80it/s]  3%|‚ñé         | 97/3257 [00:00<00:20, 155.41it/s]  3%|‚ñé         | 113/3257 [00:00<00:20, 151.05it/s]  4%|‚ñç         | 130/3257 [00:00<00:19, 156.47it/s]  5%|‚ñç         | 149/3257 [00:00<00:19, 162.95it/s]  5%|‚ñå         | 166/3257 [00:01<00:19, 155.46it/s]  6%|‚ñå         | 182/3257 [00:01<00:20, 152.54it/s]  6%|‚ñå         | 199/3257 [00:01<00:19, 155.97it/s]  7%|‚ñã         | 217/3257 [00:01<00:18, 160.67it/s]  7%|‚ñã         | 237/3257 [00:01<00:18, 166.71it/s]  8%|‚ñä         | 256/3257 [00:01<00:17, 172.99it/s]  8%|‚ñä         | 274/3257 [00:01<00:17, 172.52it/s]  9%|‚ñâ         | 295/3257 [00:01<00:16, 181.50it/s] 10%|‚ñâ         | 314/3257 [00:01<00:17, 167.76it/s] 10%|‚ñà         | 333/3257 [00:02<00:16, 173.15it/s] 11%|‚ñà         | 351/3257 [00:02<00:17, 167.80it/s] 11%|‚ñà‚ñè        | 369/3257 [00:02<00:16, 169.97it/s] 12%|‚ñà‚ñè        | 387/3257 [00:02<00:18, 153.64it/s] 12%|‚ñà‚ñè        | 405/3257 [00:02<00:17, 160.50it/s] 13%|‚ñà‚ñé        | 422/3257 [00:02<00:17, 158.37it/s] 13%|‚ñà‚ñé        | 439/3257 [00:02<00:20, 136.39it/s] 14%|‚ñà‚ñç        | 456/3257 [00:02<00:19, 144.25it/s] 15%|‚ñà‚ñç        | 474/3257 [00:02<00:18, 150.90it/s] 15%|‚ñà‚ñå        | 490/3257 [00:03<00:18, 152.08it/s] 16%|‚ñà‚ñå        | 511/3257 [00:03<00:16, 166.00it/s] 16%|‚ñà‚ñå        | 528/3257 [00:03<00:17, 158.84it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:17, 158.18it/s] 17%|‚ñà‚ñã        | 563/3257 [00:03<00:18, 148.33it/s] 18%|‚ñà‚ñä        | 579/3257 [00:03<00:18, 144.94it/s] 18%|‚ñà‚ñä        | 598/3257 [00:03<00:17, 156.03it/s] 19%|‚ñà‚ñâ        | 615/3257 [00:03<00:16, 158.63it/s] 19%|‚ñà‚ñâ        | 632/3257 [00:03<00:16, 157.98it/s] 20%|‚ñà‚ñâ        | 648/3257 [00:04<00:17, 150.54it/s] 20%|‚ñà‚ñà        | 664/3257 [00:04<00:18, 142.09it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:17, 145.43it/s] 21%|‚ñà‚ñà‚ñè       | 700/3257 [00:04<00:17, 149.28it/s] 22%|‚ñà‚ñà‚ñè       | 719/3257 [00:04<00:15, 160.25it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:04<00:27, 93.13it/s]  23%|‚ñà‚ñà‚ñé       | 752/3257 [00:05<00:23, 105.32it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:05<00:20, 120.00it/s] 24%|‚ñà‚ñà‚ñç       | 785/3257 [00:05<00:19, 123.86it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:18, 134.80it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:17, 139.94it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:05<00:17, 137.72it/s] 26%|‚ñà‚ñà‚ñå       | 851/3257 [00:05<00:17, 138.84it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:05<00:15, 154.86it/s] 27%|‚ñà‚ñà‚ñã       | 890/3257 [00:05<00:14, 163.72it/s] 28%|‚ñà‚ñà‚ñä       | 912/3257 [00:06<00:13, 178.88it/s] 29%|‚ñà‚ñà‚ñä       | 932/3257 [00:06<00:12, 181.45it/s] 29%|‚ñà‚ñà‚ñâ       | 955/3257 [00:06<00:11, 194.13it/s] 30%|‚ñà‚ñà‚ñâ       | 975/3257 [00:06<00:11, 195.32it/s] 31%|‚ñà‚ñà‚ñà       | 995/3257 [00:06<00:12, 185.99it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:06<00:11, 189.69it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1035/3257 [00:06<00:12, 184.96it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1054/3257 [00:06<00:11, 183.66it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1078/3257 [00:06<00:10, 198.16it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1098/3257 [00:06<00:11, 183.27it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1119/3257 [00:07<00:11, 185.44it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1141/3257 [00:07<00:11, 190.33it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1163/3257 [00:07<00:10, 197.11it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1183/3257 [00:07<00:11, 184.09it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1202/3257 [00:07<00:12, 168.23it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1220/3257 [00:07<00:12, 168.26it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:07<00:10, 184.20it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:07<00:10, 184.66it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1281/3257 [00:08<00:11, 173.14it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1299/3257 [00:08<00:11, 174.94it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1319/3257 [00:08<00:10, 181.85it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1340/3257 [00:08<00:10, 189.19it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1360/3257 [00:08<00:10, 183.05it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1379/3257 [00:08<00:10, 179.38it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1398/3257 [00:08<00:10, 174.56it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:08<00:09, 190.38it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1442/3257 [00:08<00:09, 186.32it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1466/3257 [00:08<00:08, 199.33it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1487/3257 [00:09<00:08, 197.22it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1510/3257 [00:09<00:08, 206.18it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1531/3257 [00:09<00:09, 182.72it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:09<00:09, 176.59it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1569/3257 [00:09<00:09, 174.82it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1587/3257 [00:09<00:09, 172.68it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1605/3257 [00:09<00:09, 173.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1623/3257 [00:09<00:09, 172.25it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1641/3257 [00:09<00:09, 167.89it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1658/3257 [00:10<00:10, 159.37it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1675/3257 [00:10<00:10, 156.60it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:10<00:09, 158.55it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1713/3257 [00:10<00:09, 170.46it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:10<00:09, 155.79it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1747/3257 [00:10<00:09, 153.68it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1764/3257 [00:10<00:09, 155.89it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1785/3257 [00:10<00:08, 170.00it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:10<00:08, 170.15it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:11<00:08, 170.12it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1839/3257 [00:11<00:08, 168.09it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1857/3257 [00:11<00:08, 170.32it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1878/3257 [00:11<00:07, 180.90it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:11<00:07, 174.23it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:11<00:07, 175.31it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1934/3257 [00:11<00:07, 174.23it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1957/3257 [00:12<00:11, 109.57it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:12<00:10, 120.86it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1990/3257 [00:12<00:09, 128.51it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2007/3257 [00:12<00:09, 137.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2029/3257 [00:12<00:07, 156.11it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2047/3257 [00:12<00:08, 150.09it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2064/3257 [00:12<00:08, 149.06it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:12<00:07, 156.04it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:12<00:07, 151.88it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2119/3257 [00:13<00:07, 160.66it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:13<00:07, 152.19it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2152/3257 [00:13<00:07, 151.40it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:13<00:06, 155.70it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:13<00:06, 155.08it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:13<00:06, 164.59it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2222/3257 [00:13<00:06, 166.31it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2239/3257 [00:13<00:06, 155.47it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:13<00:06, 164.72it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:14<00:06, 152.11it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2298/3257 [00:14<00:05, 169.93it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2316/3257 [00:14<00:05, 170.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2339/3257 [00:14<00:04, 185.94it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2361/3257 [00:14<00:04, 194.73it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2381/3257 [00:14<00:04, 190.89it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2402/3257 [00:14<00:04, 194.83it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:14<00:04, 177.41it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2441/3257 [00:14<00:04, 168.95it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2461/3257 [00:15<00:04, 176.03it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:15<00:04, 181.27it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2501/3257 [00:15<00:04, 186.03it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2520/3257 [00:15<00:04, 180.72it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:15<00:03, 183.11it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2559/3257 [00:15<00:03, 178.01it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2577/3257 [00:15<00:03, 175.11it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2595/3257 [00:15<00:03, 170.94it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2621/3257 [00:15<00:03, 195.05it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2642/3257 [00:16<00:03, 195.83it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2662/3257 [00:16<00:03, 181.28it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2682/3257 [00:16<00:03, 185.92it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2701/3257 [00:16<00:03, 165.94it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:16<00:03, 166.75it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2743/3257 [00:16<00:02, 185.50it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2762/3257 [00:16<00:02, 181.23it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2781/3257 [00:16<00:02, 176.24it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:16<00:02, 184.50it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2822/3257 [00:17<00:02, 175.49it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2840/3257 [00:17<00:02, 167.58it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2865/3257 [00:17<00:02, 189.01it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:17<00:01, 191.60it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:17<00:01, 179.63it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:17<00:01, 183.84it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:17<00:01, 174.90it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:17<00:01, 176.90it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:18<00:01, 168.60it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3006/3257 [00:18<00:01, 182.17it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3025/3257 [00:18<00:01, 177.36it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3046/3257 [00:18<00:01, 186.15it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3067/3257 [00:18<00:00, 190.58it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3087/3257 [00:18<00:00, 186.60it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:18<00:00, 196.77it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3131/3257 [00:18<00:00, 195.74it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3151/3257 [00:18<00:00, 186.66it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3171/3257 [00:18<00:00, 189.68it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3191/3257 [00:19<00:00, 184.23it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3210/3257 [00:19<00:00, 181.22it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3229/3257 [00:19<00:00, 177.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:19<00:00, 184.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 167.44it/s]
2023-02-07 18:30:47.761 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:30:47,762][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d372,n5,w5,mc4,s0.486223,t4>', 'datetime': '2023-02-07T18:30:47.762868', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:30:47,763][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:30:47,763][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:30:48,284][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 18:30:48,285][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:30:48,361][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 retains 29175 unique words (68.32% of original 42701, drops 13526)', 'datetime': '2023-02-07T18:30:48.361220', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:30:48,361][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 leaves 5800681 word corpus (99.62% of original 5822992, drops 22311)', 'datetime': '2023-02-07T18:30:48.361592', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:30:48,459][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 18:30:48,460][gensim.models.word2vec][INFO] - sample=0.486223 downsamples 0 most-common words
[2023-02-07 18:30:48,460][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5800681 word corpus (100.0%% of prior 5800681)', 'datetime': '2023-02-07T18:30:48.460723', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:30:48,640][gensim.models.word2vec][INFO] - estimated required memory for 29175 words and 372 dimensions: 106910116 bytes
[2023-02-07 18:30:48,640][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:30:48,687][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 29175 vocabulary and 372 features, using sg=0 hs=0 sample=0.48622292548418256 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-07T18:30:48.687841', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:30:49,692][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 23.92% examples, 1369404 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:50,692][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 45.69% examples, 1342589 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:51,694][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 68.04% examples, 1334751 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:52,701][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 91.34% examples, 1323419 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:53,051][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5774537 effective words) took 4.4s, 1324046 effective words/s
[2023-02-07 18:30:54,055][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 23.03% examples, 1321612 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:55,056][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 44.86% examples, 1320683 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:56,059][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 67.30% examples, 1319445 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:57,064][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 91.34% examples, 1323684 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:57,410][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5774537 effective words) took 4.4s, 1325608 effective words/s
[2023-02-07 18:30:58,416][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 23.70% examples, 1352450 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:59,416][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 45.90% examples, 1345826 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:00,420][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 68.99% examples, 1353452 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:01,425][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 93.12% examples, 1348036 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:01,687][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5774537 effective words) took 4.3s, 1350818 effective words/s
[2023-02-07 18:31:02,699][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 19.80% examples, 1110463 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:03,705][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 42.59% examples, 1257049 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:04,719][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 66.90% examples, 1301676 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:05,724][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 90.76% examples, 1309009 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:06,069][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5774537 effective words) took 4.4s, 1318462 effective words/s
[2023-02-07 18:31:07,072][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 22.57% examples, 1286261 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:08,082][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 43.41% examples, 1282250 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:09,090][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 66.29% examples, 1294349 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:10,092][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 89.13% examples, 1289004 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:10,547][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5774537 effective words) took 4.5s, 1289963 effective words/s
[2023-02-07 18:31:11,551][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 26.34% examples, 1521209 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:12,555][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 52.16% examples, 1533607 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:13,561][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 79.28% examples, 1537045 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:14,290][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5774537 effective words) took 3.7s, 1543369 effective words/s
[2023-02-07 18:31:15,294][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 26.99% examples, 1561390 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:16,299][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.33% examples, 1573503 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:17,299][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 81.39% examples, 1576496 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:17,940][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5774537 effective words) took 3.6s, 1582898 effective words/s
[2023-02-07 18:31:18,945][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 27.23% examples, 1575758 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:19,958][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 50.38% examples, 1469500 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:20,962][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 73.84% examples, 1432062 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:21,966][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 97.88% examples, 1406455 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:22,045][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5774537 effective words) took 4.1s, 1407135 effective words/s
[2023-02-07 18:31:23,053][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 23.79% examples, 1356112 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:24,058][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 46.79% examples, 1368113 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:25,062][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 69.88% examples, 1371108 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:26,063][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 95.82% examples, 1378352 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:26,236][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5774537 effective words) took 4.2s, 1378577 effective words/s
[2023-02-07 18:31:27,246][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 24.04% examples, 1370765 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:31:28,248][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 47.13% examples, 1378704 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:31:29,248][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 70.99% examples, 1391675 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:30,256][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 96.56% examples, 1389622 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:30,384][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5774537 effective words) took 4.1s, 1392580 effective words/s
[2023-02-07 18:31:31,390][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 24.04% examples, 1376840 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:32,391][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 47.90% examples, 1409231 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:33,392][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 79.71% examples, 1549044 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:33,992][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5774537 effective words) took 3.6s, 1601091 effective words/s
[2023-02-07 18:31:34,994][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 30.70% examples, 1780250 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:35,996][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 61.53% examples, 1801740 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:37,002][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 92.48% examples, 1786792 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:37,214][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5774537 effective words) took 3.2s, 1793225 effective words/s
[2023-02-07 18:31:38,215][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 26.87% examples, 1558614 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:39,217][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 54.04% examples, 1595118 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:40,218][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 81.82% examples, 1586757 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:40,856][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5774537 effective words) took 3.6s, 1585610 effective words/s
[2023-02-07 18:31:41,866][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 27.66% examples, 1588778 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:42,877][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 53.09% examples, 1550914 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:43,887][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 80.81% examples, 1552876 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:44,570][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5774537 effective words) took 3.7s, 1555624 effective words/s
[2023-02-07 18:31:45,579][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 26.59% examples, 1531515 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:46,580][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 51.92% examples, 1527432 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:47,591][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 79.28% examples, 1533852 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:48,307][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5774537 effective words) took 3.7s, 1545671 effective words/s
[2023-02-07 18:31:48,308][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86618055 effective words) took 59.6s, 1452832 effective words/s', 'datetime': '2023-02-07T18:31:48.308409', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:31:48.308 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:31:54,033][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183019-b8x0zr2o/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:31:54.033559', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:31:54,034][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183019-b8x0zr2o/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 18:31:54,082][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183019-b8x0zr2o/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 18:31:54,121][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:31:54,154][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183019-b8x0zr2o/files/../tmp/embedding_model.pt
2023-02-07 18:31:54.154 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:31:56.499 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:31:57.241 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:32:22.817 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0458977837477208, 'test_mae': 0.7849375009993834, 'test_r2': -2.7242109022858707}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.83
wandb: percentage 0.31676
wandb:   test_mae 0.78494
wandb:   test_mse 1.0459
wandb:    test_r2 -2.72421
wandb: 
wandb: üöÄ View run hopeful-sweep-10 at: https://wandb.ai/xiaoqiz/mof2vec/runs/b8x0zr2o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_183019-b8x0zr2o/logs
wandb: Agent Starting Run: azjqen3h with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 543
wandb: 	model.gensim.alpha: 0.04567680750607397
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.567301417240818
wandb: 	model.gensim.vector_size: 442
wandb: 	model.gensim.window: 6
wandb: 	model.sklearn.learning_rate: 0.008322989793108717
wandb: 	model.sklearn.max_depth: 9
wandb: 	model.sklearn.min_child_weight: 0.08799434420962154
wandb: 	model.sklearn.n_estimators: 4174
wandb: 	model.sklearn.num_leaves: 215
wandb: 	model.sklearn.reg_alpha: 0.003001113416849814
wandb: 	model.sklearn.reg_lambda: 0.040895391262734254
wandb: 	model.sklearn.subsample: 0.3542756916601727
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183231-azjqen3h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/azjqen3h
2023-02-07 18:32:39.685 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 18:32:39.685 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 543 for sweep.
2023-02-07 18:32:39.685 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.04567680750607397 for sweep.
2023-02-07 18:32:39.686 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:32:39.686 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 18:32:39.686 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.567301417240818 for sweep.
2023-02-07 18:32:39.686 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 442 for sweep.
2023-02-07 18:32:39.687 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 6 for sweep.
2023-02-07 18:32:39.687 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.008322989793108717 for sweep.
2023-02-07 18:32:39.687 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 9 for sweep.
2023-02-07 18:32:39.687 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08799434420962154 for sweep.
2023-02-07 18:32:39.687 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4174 for sweep.
2023-02-07 18:32:39.688 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 215 for sweep.
2023-02-07 18:32:39.688 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.003001113416849814 for sweep.
2023-02-07 18:32:39.688 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.040895391262734254 for sweep.
2023-02-07 18:32:39.688 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3542756916601727 for sweep.
2023-02-07 18:32:39.688 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:32:39.694 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183231-azjqen3h/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 543, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 442, 'window': 6, 'min_count': 6, 'dm': 1, 'sample': 0.567301417240818, 'workers': 4, 'alpha': 0.04567680750607397, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4174, 'max_depth': 9, 'num_leaves': 215, 'reg_alpha': 0.003001113416849814, 'reg_lambda': 0.040895391262734254, 'subsample': 0.3542756916601727, 'min_child_weight': 0.08799434420962154, 'n_jobs': 4, 'learning_rate': 0.008322989793108717}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:19, 169.92it/s]  1%|          | 36/3257 [00:00<00:18, 175.21it/s]  2%|‚ñè         | 55/3257 [00:00<00:18, 175.94it/s]  2%|‚ñè         | 77/3257 [00:00<00:16, 192.38it/s]  3%|‚ñé         | 97/3257 [00:00<00:16, 188.47it/s]  4%|‚ñé         | 116/3257 [00:00<00:17, 181.37it/s]  4%|‚ñç         | 135/3257 [00:00<00:16, 183.65it/s]  5%|‚ñç         | 158/3257 [00:00<00:16, 188.69it/s]  5%|‚ñå         | 177/3257 [00:00<00:16, 182.71it/s]  6%|‚ñå         | 197/3257 [00:01<00:16, 186.71it/s]  7%|‚ñã         | 220/3257 [00:01<00:15, 197.68it/s]  7%|‚ñã         | 243/3257 [00:01<00:14, 204.72it/s]  8%|‚ñä         | 264/3257 [00:01<00:15, 195.59it/s]  9%|‚ñâ         | 290/3257 [00:01<00:14, 210.75it/s] 10%|‚ñâ         | 312/3257 [00:01<00:14, 199.37it/s] 10%|‚ñà         | 334/3257 [00:01<00:14, 204.16it/s] 11%|‚ñà         | 355/3257 [00:01<00:14, 202.23it/s] 12%|‚ñà‚ñè        | 376/3257 [00:01<00:15, 190.17it/s] 12%|‚ñà‚ñè        | 396/3257 [00:02<00:15, 184.03it/s] 13%|‚ñà‚ñé        | 417/3257 [00:02<00:15, 187.96it/s] 13%|‚ñà‚ñé        | 436/3257 [00:02<00:17, 157.11it/s] 14%|‚ñà‚ñç        | 457/3257 [00:02<00:16, 169.76it/s] 15%|‚ñà‚ñç        | 476/3257 [00:02<00:15, 174.95it/s] 15%|‚ñà‚ñå        | 498/3257 [00:02<00:14, 184.75it/s] 16%|‚ñà‚ñå        | 519/3257 [00:02<00:14, 190.10it/s] 17%|‚ñà‚ñã        | 539/3257 [00:02<00:14, 191.84it/s] 17%|‚ñà‚ñã        | 559/3257 [00:02<00:15, 179.55it/s] 18%|‚ñà‚ñä        | 578/3257 [00:03<00:15, 174.48it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:14, 183.04it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:14, 181.35it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:03<00:14, 184.69it/s] 20%|‚ñà‚ñà        | 660/3257 [00:03<00:15, 170.09it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:14, 173.55it/s] 22%|‚ñà‚ñà‚ñè       | 702/3257 [00:03<00:14, 177.49it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:03<00:14, 179.04it/s] 23%|‚ñà‚ñà‚ñé       | 740/3257 [00:04<00:15, 167.45it/s] 23%|‚ñà‚ñà‚ñé       | 762/3257 [00:04<00:13, 179.14it/s] 24%|‚ñà‚ñà‚ñç       | 781/3257 [00:04<00:14, 173.02it/s] 25%|‚ñà‚ñà‚ñç       | 800/3257 [00:04<00:13, 177.56it/s] 25%|‚ñà‚ñà‚ñå       | 818/3257 [00:04<00:14, 167.59it/s] 26%|‚ñà‚ñà‚ñå       | 835/3257 [00:04<00:15, 154.63it/s] 26%|‚ñà‚ñà‚ñå       | 851/3257 [00:04<00:16, 143.64it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:04<00:16, 143.63it/s] 27%|‚ñà‚ñà‚ñã       | 881/3257 [00:04<00:16, 141.16it/s] 28%|‚ñà‚ñà‚ñä       | 897/3257 [00:05<00:16, 145.33it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:05<00:16, 145.61it/s] 29%|‚ñà‚ñà‚ñä       | 932/3257 [00:05<00:15, 151.23it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:05<00:14, 154.45it/s] 30%|‚ñà‚ñà‚ñâ       | 967/3257 [00:05<00:14, 156.28it/s] 30%|‚ñà‚ñà‚ñà       | 983/3257 [00:05<00:14, 152.69it/s] 31%|‚ñà‚ñà‚ñà       | 999/3257 [00:05<00:15, 147.95it/s] 31%|‚ñà‚ñà‚ñà       | 1014/3257 [00:05<00:15, 143.73it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1029/3257 [00:05<00:15, 141.86it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1044/3257 [00:06<00:15, 139.05it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1060/3257 [00:06<00:15, 144.57it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:14, 145.75it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1096/3257 [00:06<00:14, 148.11it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1113/3257 [00:06<00:14, 151.64it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1129/3257 [00:06<00:14, 142.80it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:06<00:14, 143.74it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1160/3257 [00:06<00:14, 146.86it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:06<00:14, 145.27it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1190/3257 [00:07<00:15, 131.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:07<00:15, 131.88it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:07<00:15, 132.94it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1240/3257 [00:07<00:12, 155.62it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1256/3257 [00:07<00:22, 87.99it/s]  39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:07<00:19, 100.81it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1286/3257 [00:08<00:19, 102.90it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1304/3257 [00:08<00:16, 117.98it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1324/3257 [00:08<00:14, 136.98it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1343/3257 [00:08<00:12, 149.34it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1360/3257 [00:08<00:12, 153.16it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1377/3257 [00:08<00:12, 155.63it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1394/3257 [00:08<00:11, 157.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1418/3257 [00:08<00:10, 180.78it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1437/3257 [00:08<00:10, 179.86it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:08<00:09, 192.11it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1480/3257 [00:09<00:09, 191.60it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1502/3257 [00:09<00:08, 199.44it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1523/3257 [00:09<00:09, 183.42it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1542/3257 [00:09<00:09, 179.55it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1561/3257 [00:09<00:09, 175.16it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1579/3257 [00:09<00:09, 174.88it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1601/3257 [00:09<00:08, 185.78it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:09<00:08, 183.86it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:09<00:09, 178.54it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:10<00:09, 172.99it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1675/3257 [00:10<00:09, 169.95it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1693/3257 [00:10<00:09, 170.69it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1714/3257 [00:10<00:08, 179.83it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1733/3257 [00:10<00:09, 163.16it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1752/3257 [00:10<00:08, 169.58it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:10<00:08, 172.38it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1791/3257 [00:10<00:08, 179.40it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1810/3257 [00:10<00:08, 166.75it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:11<00:08, 165.28it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1845/3257 [00:11<00:08, 168.02it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1864/3257 [00:11<00:08, 173.83it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1882/3257 [00:11<00:07, 173.65it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1900/3257 [00:11<00:07, 170.08it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1918/3257 [00:11<00:08, 166.19it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1940/3257 [00:11<00:07, 179.19it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1963/3257 [00:11<00:06, 193.23it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1983/3257 [00:11<00:07, 177.67it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:12<00:06, 179.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2024/3257 [00:12<00:06, 182.98it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2043/3257 [00:12<00:06, 176.62it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2061/3257 [00:12<00:07, 158.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2082/3257 [00:12<00:07, 167.58it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:12<00:07, 159.40it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:12<00:07, 160.13it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:12<00:07, 159.62it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:12<00:07, 156.32it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2173/3257 [00:13<00:06, 164.37it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2190/3257 [00:13<00:06, 161.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2207/3257 [00:13<00:06, 163.34it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2224/3257 [00:13<00:06, 163.26it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2241/3257 [00:13<00:06, 158.90it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:13<00:06, 161.20it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:13<00:06, 146.83it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2297/3257 [00:13<00:05, 161.17it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:13<00:05, 162.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2339/3257 [00:14<00:05, 183.13it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:14<00:04, 184.92it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2379/3257 [00:14<00:04, 186.18it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:14<00:04, 186.58it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2418/3257 [00:14<00:04, 171.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2436/3257 [00:14<00:05, 161.18it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2453/3257 [00:15<00:08, 92.15it/s]  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:15<00:06, 113.01it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2494/3257 [00:15<00:05, 127.29it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:15<00:05, 142.80it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2536/3257 [00:15<00:04, 159.83it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2555/3257 [00:15<00:04, 156.30it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:15<00:04, 153.69it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2590/3257 [00:15<00:04, 149.18it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:15<00:03, 171.52it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2635/3257 [00:16<00:03, 181.61it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:16<00:03, 174.77it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:16<00:03, 177.61it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2692/3257 [00:16<00:03, 167.36it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2710/3257 [00:16<00:03, 138.16it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2725/3257 [00:16<00:03, 140.76it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2742/3257 [00:16<00:03, 146.90it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2758/3257 [00:16<00:03, 147.95it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:17<00:03, 138.14it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2794/3257 [00:17<00:03, 152.63it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2810/3257 [00:17<00:03, 148.21it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2826/3257 [00:17<00:03, 137.18it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2841/3257 [00:17<00:03, 131.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2858/3257 [00:17<00:02, 140.21it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2875/3257 [00:17<00:02, 147.31it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2891/3257 [00:17<00:02, 141.14it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:17<00:02, 131.03it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2921/3257 [00:18<00:02, 135.44it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2935/3257 [00:18<00:02, 133.43it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2949/3257 [00:18<00:02, 124.62it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:18<00:02, 133.50it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2980/3257 [00:18<00:02, 126.05it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2993/3257 [00:18<00:02, 124.20it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:18<00:01, 135.74it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:18<00:01, 134.35it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3043/3257 [00:19<00:01, 142.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3060/3257 [00:19<00:01, 148.20it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3076/3257 [00:19<00:01, 150.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3092/3257 [00:19<00:01, 142.32it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:19<00:00, 149.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:19<00:00, 153.29it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3143/3257 [00:19<00:00, 142.47it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3158/3257 [00:19<00:00, 144.26it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3173/3257 [00:19<00:00, 145.36it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3188/3257 [00:20<00:00, 140.06it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3205/3257 [00:20<00:00, 147.39it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3220/3257 [00:20<00:00, 139.58it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:20<00:00, 151.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3255/3257 [00:20<00:00, 151.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 159.27it/s]
2023-02-07 18:33:01.137 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:33:01,138][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d442,n5,w6,mc6,s0.567301,t4>', 'datetime': '2023-02-07T18:33:01.138734', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:33:01,139][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:33:01,139][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:33:01,694][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 18:33:01,695][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:33:01,761][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 25857 unique words (47.84% of original 54054, drops 28197)', 'datetime': '2023-02-07T18:33:01.761254', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:33:01,761][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 6477431 word corpus (98.88% of original 6550866, drops 73435)', 'datetime': '2023-02-07T18:33:01.761525', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:33:01,843][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 18:33:01,844][gensim.models.word2vec][INFO] - sample=0.567301 downsamples 0 most-common words
[2023-02-07 18:33:01,844][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6477431 word corpus (100.0%% of prior 6477431)', 'datetime': '2023-02-07T18:33:01.844398', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:33:01,987][gensim.models.word2vec][INFO] - estimated required memory for 25857 words and 442 dimensions: 110768628 bytes
[2023-02-07 18:33:01,988][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:33:02,033][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 25857 vocabulary and 442 features, using sg=0 hs=0 sample=0.567301417240818 negative=5 window=6 shrink_windows=True', 'datetime': '2023-02-07T18:33:02.032972', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:33:03,043][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 20.11% examples, 1258746 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:04,053][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 39.12% examples, 1270584 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:05,054][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 58.21% examples, 1265373 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:06,058][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 78.14% examples, 1260107 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:07,074][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 98.83% examples, 1262679 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:07,117][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6423064 effective words) took 5.1s, 1263750 effective words/s
[2023-02-07 18:33:08,130][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 17.96% examples, 1119314 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:09,139][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 34.82% examples, 1120715 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:10,147][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 51.64% examples, 1118753 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:11,155][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 68.84% examples, 1119137 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:12,156][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 87.17% examples, 1122310 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:33:12,714][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6423064 effective words) took 5.6s, 1147785 effective words/s
[2023-02-07 18:33:13,723][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 22.38% examples, 1412396 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:14,723][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 41.57% examples, 1367291 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:15,724][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 62.08% examples, 1343914 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:16,734][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 82.78% examples, 1333101 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:17,608][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6423064 effective words) took 4.9s, 1312944 effective words/s
[2023-02-07 18:33:18,622][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 18.18% examples, 1131143 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:33:19,623][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 35.19% examples, 1140763 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:20,626][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 52.47% examples, 1141328 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:21,633][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 69.85% examples, 1142618 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:22,634][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 90.73% examples, 1168033 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:23,024][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6423064 effective words) took 5.4s, 1186478 effective words/s
[2023-02-07 18:33:24,026][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 20.82% examples, 1311054 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:25,031][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 37.40% examples, 1227316 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:26,033][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 56.40% examples, 1232101 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:27,040][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 76.70% examples, 1242105 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:28,050][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 97.67% examples, 1251734 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:28,140][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6423064 effective words) took 5.1s, 1255829 effective words/s
[2023-02-07 18:33:29,148][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 20.20% examples, 1271170 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:30,153][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 39.30% examples, 1287419 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:31,157][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 59.53% examples, 1292455 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:32,157][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 79.77% examples, 1291308 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:33,114][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6423064 effective words) took 5.0s, 1291859 effective words/s
[2023-02-07 18:33:34,119][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 20.20% examples, 1274757 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:35,125][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 39.21% examples, 1283888 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:36,128][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 59.38% examples, 1290200 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:37,139][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 80.01% examples, 1290848 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:38,092][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6423064 effective words) took 5.0s, 1290876 effective words/s
[2023-02-07 18:33:39,099][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 20.20% examples, 1271028 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:40,104][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 39.48% examples, 1295859 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:41,115][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 59.96% examples, 1295226 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:42,117][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 80.78% examples, 1299669 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:43,028][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6423064 effective words) took 4.9s, 1301533 effective words/s
[2023-02-07 18:33:44,031][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 20.29% examples, 1286768 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:45,035][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 39.48% examples, 1298970 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:46,042][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 60.09% examples, 1301466 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:33:47,045][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 81.09% examples, 1307065 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:47,914][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6423064 effective words) took 4.9s, 1315136 effective words/s
[2023-02-07 18:33:48,916][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 21.37% examples, 1354047 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:49,920][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 41.45% examples, 1364704 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:50,926][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 62.48% examples, 1351009 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:51,927][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 81.42% examples, 1313890 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:52,910][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6423064 effective words) took 5.0s, 1285883 effective words/s
[2023-02-07 18:33:53,916][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 18.67% examples, 1168321 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:54,917][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 36.29% examples, 1179239 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:55,924][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 54.10% examples, 1180068 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:33:56,928][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 72.64% examples, 1179654 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:57,937][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 91.37% examples, 1176946 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:33:58,357][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6423064 effective words) took 5.4s, 1179796 effective words/s
[2023-02-07 18:33:59,363][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 18.67% examples, 1167725 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:34:00,366][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 36.29% examples, 1177981 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:34:01,380][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 54.47% examples, 1184989 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:02,382][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 73.10% examples, 1184201 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:03,394][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 91.86% examples, 1181167 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:34:03,793][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6423064 effective words) took 5.4s, 1182183 effective words/s
[2023-02-07 18:34:04,799][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 20.94% examples, 1313976 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:05,803][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 41.94% examples, 1379449 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:06,807][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 63.89% examples, 1384660 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:34:07,811][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 84.99% examples, 1372314 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:08,543][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6423064 effective words) took 4.7s, 1352759 effective words/s
[2023-02-07 18:34:09,547][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 20.69% examples, 1303113 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:10,551][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 39.61% examples, 1302058 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:11,554][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 60.42% examples, 1308178 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:12,561][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 81.15% examples, 1308549 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:13,454][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6423064 effective words) took 4.9s, 1308368 effective words/s
[2023-02-07 18:34:14,456][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 20.29% examples, 1286970 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:15,458][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 39.73% examples, 1308761 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:16,471][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 60.09% examples, 1299885 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:17,474][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 80.66% examples, 1299187 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:18,395][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6423064 effective words) took 4.9s, 1300225 effective words/s
[2023-02-07 18:34:18,396][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (96345960 effective words) took 76.4s, 1261683 effective words/s', 'datetime': '2023-02-07T18:34:18.396368', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:34:18.397 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:34:24,678][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183231-azjqen3h/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:34:24.678810', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:34:24,679][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183231-azjqen3h/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 18:34:24,726][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183231-azjqen3h/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 18:34:24,768][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:34:24,804][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183231-azjqen3h/files/../tmp/embedding_model.pt
2023-02-07 18:34:24.804 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:34:27.196 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:34:27.975 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:34:34.007 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.084720386414978, 'test_mae': 0.7698880752628566, 'test_r2': -2.572860394214128}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.85
wandb: percentage 0.52165
wandb:   test_mae 0.76989
wandb:   test_mse 1.08472
wandb:    test_r2 -2.57286
wandb: 
wandb: üöÄ View run peachy-sweep-11 at: https://wandb.ai/xiaoqiz/mof2vec/runs/azjqen3h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_183231-azjqen3h/logs
wandb: Agent Starting Run: 1pzyn0h6 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 515
wandb: 	model.gensim.alpha: 0.0931659058259534
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.3756239046212726
wandb: 	model.gensim.vector_size: 315
wandb: 	model.gensim.window: 10
wandb: 	model.sklearn.learning_rate: 0.012981106569555962
wandb: 	model.sklearn.max_depth: 53
wandb: 	model.sklearn.min_child_weight: 0.08292473087127546
wandb: 	model.sklearn.n_estimators: 4199
wandb: 	model.sklearn.num_leaves: 128
wandb: 	model.sklearn.reg_alpha: 0.009873939376004469
wandb: 	model.sklearn.reg_lambda: 0.003112822868175502
wandb: 	model.sklearn.subsample: 0.3555716317064116
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183448-1pzyn0h6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/1pzyn0h6
2023-02-07 18:34:56.650 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 18:34:56.651 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 515 for sweep.
2023-02-07 18:34:56.651 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0931659058259534 for sweep.
2023-02-07 18:34:56.651 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:34:56.651 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 18:34:56.652 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.3756239046212726 for sweep.
2023-02-07 18:34:56.652 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 315 for sweep.
2023-02-07 18:34:56.652 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 10 for sweep.
2023-02-07 18:34:56.652 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.012981106569555962 for sweep.
2023-02-07 18:34:56.652 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 53 for sweep.
2023-02-07 18:34:56.653 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08292473087127546 for sweep.
2023-02-07 18:34:56.653 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4199 for sweep.
2023-02-07 18:34:56.653 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 128 for sweep.
2023-02-07 18:34:56.653 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.009873939376004469 for sweep.
2023-02-07 18:34:56.654 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.003112822868175502 for sweep.
2023-02-07 18:34:56.654 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3555716317064116 for sweep.
2023-02-07 18:34:56.654 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:34:56.665 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183448-1pzyn0h6/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 515, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 315, 'window': 10, 'min_count': 2, 'dm': 1, 'sample': 0.3756239046212726, 'workers': 4, 'alpha': 0.0931659058259534, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4199, 'max_depth': 53, 'num_leaves': 128, 'reg_alpha': 0.009873939376004469, 'reg_lambda': 0.003112822868175502, 'subsample': 0.3555716317064116, 'min_child_weight': 0.08292473087127546, 'n_jobs': 4, 'learning_rate': 0.012981106569555962}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 19/3257 [00:00<00:17, 185.00it/s]  1%|          | 39/3257 [00:00<00:16, 189.51it/s]  2%|‚ñè         | 58/3257 [00:00<00:17, 185.69it/s]  2%|‚ñè         | 81/3257 [00:00<00:15, 201.64it/s]  3%|‚ñé         | 102/3257 [00:00<00:15, 200.40it/s]  4%|‚ñç         | 123/3257 [00:00<00:16, 193.78it/s]  5%|‚ñç         | 147/3257 [00:00<00:15, 206.37it/s]  5%|‚ñå         | 168/3257 [00:00<00:15, 200.81it/s]  6%|‚ñå         | 189/3257 [00:00<00:15, 201.75it/s]  6%|‚ñã         | 210/3257 [00:01<00:15, 200.74it/s]  7%|‚ñã         | 235/3257 [00:01<00:14, 215.14it/s]  8%|‚ñä         | 257/3257 [00:01<00:14, 208.93it/s]  9%|‚ñä         | 282/3257 [00:01<00:13, 219.87it/s]  9%|‚ñâ         | 305/3257 [00:01<00:13, 214.05it/s] 10%|‚ñà         | 328/3257 [00:01<00:13, 215.63it/s] 11%|‚ñà         | 350/3257 [00:01<00:13, 208.62it/s] 11%|‚ñà‚ñè        | 373/3257 [00:01<00:13, 212.15it/s] 12%|‚ñà‚ñè        | 395/3257 [00:01<00:14, 196.98it/s] 13%|‚ñà‚ñé        | 417/3257 [00:02<00:13, 202.95it/s] 13%|‚ñà‚ñé        | 438/3257 [00:02<00:15, 177.38it/s] 14%|‚ñà‚ñç        | 461/3257 [00:02<00:14, 189.41it/s] 15%|‚ñà‚ñç        | 481/3257 [00:02<00:14, 188.66it/s] 16%|‚ñà‚ñå        | 505/3257 [00:02<00:13, 202.60it/s] 16%|‚ñà‚ñå        | 526/3257 [00:02<00:13, 201.85it/s] 17%|‚ñà‚ñã        | 547/3257 [00:02<00:13, 202.62it/s] 17%|‚ñà‚ñã        | 568/3257 [00:02<00:13, 194.04it/s] 18%|‚ñà‚ñä        | 588/3257 [00:02<00:14, 190.09it/s] 19%|‚ñà‚ñâ        | 611/3257 [00:03<00:13, 200.41it/s] 19%|‚ñà‚ñâ        | 632/3257 [00:03<00:12, 203.07it/s] 20%|‚ñà‚ñà        | 653/3257 [00:03<00:13, 195.63it/s] 21%|‚ñà‚ñà        | 673/3257 [00:03<00:13, 190.07it/s] 21%|‚ñà‚ñà‚ñè       | 693/3257 [00:03<00:20, 126.47it/s] 22%|‚ñà‚ñà‚ñè       | 716/3257 [00:03<00:17, 147.87it/s] 23%|‚ñà‚ñà‚ñé       | 734/3257 [00:03<00:16, 152.94it/s] 23%|‚ñà‚ñà‚ñé       | 753/3257 [00:03<00:15, 160.84it/s] 24%|‚ñà‚ñà‚ñç       | 774/3257 [00:04<00:14, 171.93it/s] 24%|‚ñà‚ñà‚ñç       | 793/3257 [00:04<00:13, 176.41it/s] 25%|‚ñà‚ñà‚ñç       | 814/3257 [00:04<00:13, 183.77it/s] 26%|‚ñà‚ñà‚ñå       | 834/3257 [00:04<00:13, 181.83it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:04<00:13, 172.91it/s] 27%|‚ñà‚ñà‚ñã       | 874/3257 [00:04<00:13, 182.37it/s] 27%|‚ñà‚ñà‚ñã       | 893/3257 [00:04<00:12, 183.28it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:04<00:12, 187.81it/s] 29%|‚ñà‚ñà‚ñâ       | 937/3257 [00:04<00:11, 196.91it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:05<00:11, 202.23it/s] 30%|‚ñà‚ñà‚ñà       | 980/3257 [00:05<00:11, 197.21it/s] 31%|‚ñà‚ñà‚ñà       | 1000/3257 [00:05<00:11, 196.71it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1021/3257 [00:05<00:11, 199.17it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:05<00:12, 182.10it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:05<00:11, 189.22it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1082/3257 [00:05<00:11, 190.87it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1103/3257 [00:05<00:11, 194.14it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:05<00:11, 191.39it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:06<00:11, 188.35it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1165/3257 [00:06<00:10, 196.37it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:06<00:11, 183.90it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:06<00:11, 175.49it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1227/3257 [00:06<00:10, 189.02it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1248/3257 [00:06<00:10, 193.11it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:06<00:09, 200.20it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:06<00:10, 186.91it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:06<00:10, 191.75it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1338/3257 [00:07<00:09, 207.30it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1359/3257 [00:07<00:09, 193.19it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1379/3257 [00:07<00:10, 180.30it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1398/3257 [00:07<00:10, 174.26it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1420/3257 [00:07<00:09, 184.03it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:07<00:10, 173.75it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1462/3257 [00:07<00:09, 186.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1481/3257 [00:07<00:09, 183.06it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1500/3257 [00:07<00:09, 183.88it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1519/3257 [00:08<00:10, 172.19it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1537/3257 [00:08<00:10, 162.20it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1554/3257 [00:08<00:10, 159.44it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1572/3257 [00:08<00:10, 163.79it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1589/3257 [00:08<00:10, 161.26it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1606/3257 [00:08<00:10, 162.42it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1623/3257 [00:08<00:10, 160.38it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1640/3257 [00:08<00:10, 159.53it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1656/3257 [00:08<00:10, 156.65it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1672/3257 [00:09<00:10, 148.90it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1689/3257 [00:09<00:10, 152.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:09<00:09, 157.35it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1724/3257 [00:09<00:09, 159.84it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1741/3257 [00:09<00:10, 139.70it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1760/3257 [00:09<00:09, 151.48it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1777/3257 [00:09<00:09, 155.48it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:09<00:09, 161.41it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1813/3257 [00:09<00:09, 155.46it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1829/3257 [00:10<00:09, 153.75it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1847/3257 [00:10<00:08, 159.74it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1867/3257 [00:10<00:08, 170.74it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1885/3257 [00:10<00:08, 164.01it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1903/3257 [00:10<00:08, 166.55it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1920/3257 [00:10<00:08, 160.57it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1940/3257 [00:10<00:07, 170.61it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1963/3257 [00:10<00:06, 185.45it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:10<00:07, 172.81it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2000/3257 [00:11<00:07, 173.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2018/3257 [00:11<00:07, 169.68it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2036/3257 [00:11<00:13, 92.86it/s]  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2050/3257 [00:11<00:12, 98.74it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2065/3257 [00:11<00:11, 107.19it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:11<00:09, 121.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2098/3257 [00:11<00:09, 126.87it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:12<00:08, 142.19it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2133/3257 [00:12<00:08, 135.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2148/3257 [00:12<00:08, 135.59it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:12<00:07, 150.87it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2184/3257 [00:12<00:07, 149.87it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:12<00:06, 160.75it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2221/3257 [00:12<00:06, 160.17it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:12<00:06, 156.46it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2255/3257 [00:12<00:06, 159.60it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2272/3257 [00:13<00:06, 151.07it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2291/3257 [00:13<00:06, 160.52it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2308/3257 [00:13<00:06, 156.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2331/3257 [00:13<00:05, 175.14it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2353/3257 [00:13<00:04, 185.74it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2372/3257 [00:13<00:04, 180.86it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2394/3257 [00:13<00:04, 191.04it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2414/3257 [00:13<00:04, 177.62it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2433/3257 [00:14<00:04, 167.11it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2451/3257 [00:14<00:04, 161.76it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2473/3257 [00:14<00:04, 176.35it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2491/3257 [00:14<00:04, 173.25it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2509/3257 [00:14<00:04, 174.29it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2527/3257 [00:14<00:04, 171.79it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2546/3257 [00:14<00:04, 174.67it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2564/3257 [00:14<00:04, 164.50it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2581/3257 [00:14<00:04, 156.80it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2598/3257 [00:14<00:04, 159.85it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2621/3257 [00:15<00:03, 178.49it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2640/3257 [00:15<00:03, 180.28it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2659/3257 [00:15<00:03, 164.41it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2677/3257 [00:15<00:03, 167.56it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2695/3257 [00:15<00:03, 165.14it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2712/3257 [00:15<00:03, 152.36it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2730/3257 [00:15<00:03, 156.98it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2749/3257 [00:15<00:03, 165.77it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2766/3257 [00:16<00:03, 163.37it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2783/3257 [00:16<00:02, 162.48it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:16<00:02, 169.73it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2821/3257 [00:16<00:02, 162.73it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2838/3257 [00:16<00:02, 154.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2855/3257 [00:16<00:02, 158.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2881/3257 [00:16<00:02, 181.52it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2900/3257 [00:16<00:02, 165.41it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2919/3257 [00:16<00:01, 171.05it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2937/3257 [00:17<00:01, 169.19it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2955/3257 [00:17<00:01, 158.59it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2972/3257 [00:17<00:01, 161.16it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2989/3257 [00:17<00:01, 153.34it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:17<00:01, 169.01it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3029/3257 [00:17<00:01, 163.65it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:17<00:01, 170.69it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3069/3257 [00:17<00:01, 179.64it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3088/3257 [00:17<00:00, 174.72it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3109/3257 [00:18<00:00, 183.28it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3128/3257 [00:18<00:00, 180.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3147/3257 [00:18<00:00, 166.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:18<00:00, 165.53it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3182/3257 [00:18<00:00, 160.09it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3202/3257 [00:18<00:00, 170.61it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3220/3257 [00:18<00:00, 161.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3241/3257 [00:18<00:00, 173.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 172.13it/s]
2023-02-07 18:35:16.449 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:35:16,451][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d315,n5,w10,mc2,s0.375624,t4>', 'datetime': '2023-02-07T18:35:16.451443', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:35:16,452][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:35:16,452][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:35:16,915][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 18:35:16,916][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:35:16,982][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 27186 unique words (85.48% of original 31803, drops 4617)', 'datetime': '2023-02-07T18:35:16.982168', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:35:16,982][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5090501 word corpus (99.91% of original 5095118, drops 4617)', 'datetime': '2023-02-07T18:35:16.982469', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:35:17,072][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 18:35:17,073][gensim.models.word2vec][INFO] - sample=0.375624 downsamples 0 most-common words
[2023-02-07 18:35:17,073][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5090501 word corpus (100.0%% of prior 5090501)', 'datetime': '2023-02-07T18:35:17.073243', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:35:17,232][gensim.models.word2vec][INFO] - estimated required memory for 27186 words and 315 dimensions: 86856940 bytes
[2023-02-07 18:35:17,233][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:35:17,270][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 27186 vocabulary and 315 features, using sg=0 hs=0 sample=0.3756239046212726 negative=5 window=10 shrink_windows=True', 'datetime': '2023-02-07T18:35:17.270620', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:35:18,276][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 28.40% examples, 1442225 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:19,285][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 55.76% examples, 1442433 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:20,292][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 84.03% examples, 1428124 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:20,822][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5082292 effective words) took 3.5s, 1431645 effective words/s
[2023-02-07 18:35:21,831][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 27.14% examples, 1383368 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:35:22,833][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 54.44% examples, 1409563 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:23,841][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 83.48% examples, 1420542 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:24,402][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5082292 effective words) took 3.6s, 1420458 effective words/s
[2023-02-07 18:35:25,404][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 27.30% examples, 1392090 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:26,408][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 53.85% examples, 1401019 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:27,412][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 82.81% examples, 1411662 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:27,994][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5082292 effective words) took 3.6s, 1415841 effective words/s
[2023-02-07 18:35:29,008][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 27.88% examples, 1411543 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:30,012][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 55.27% examples, 1425486 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:31,019][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 84.22% examples, 1429560 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:31,531][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5082292 effective words) took 3.5s, 1437620 effective words/s
[2023-02-07 18:35:32,535][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 28.55% examples, 1451927 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:33,539][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 56.09% examples, 1456647 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:34,543][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 86.40% examples, 1469411 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:34,990][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5082292 effective words) took 3.5s, 1469929 effective words/s
[2023-02-07 18:35:36,008][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 28.65% examples, 1441408 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:35:37,014][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 57.57% examples, 1480291 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:38,027][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 84.03% examples, 1420995 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:38,626][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5082292 effective words) took 3.6s, 1398366 effective words/s
[2023-02-07 18:35:39,631][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 24.90% examples, 1255400 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:40,640][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 49.25% examples, 1269236 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:41,646][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 74.58% examples, 1274400 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:42,621][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5082292 effective words) took 4.0s, 1272928 effective words/s
[2023-02-07 18:35:43,625][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 24.78% examples, 1248184 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:44,627][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 48.36% examples, 1254581 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:45,631][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 73.44% examples, 1257404 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:46,637][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 99.57% examples, 1260366 words/s, in_qsize 3, out_qsize 1
[2023-02-07 18:35:46,646][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5082292 effective words) took 4.0s, 1263236 effective words/s
[2023-02-07 18:35:47,649][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 25.02% examples, 1267380 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:48,662][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 49.25% examples, 1268399 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:49,667][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 74.27% examples, 1268025 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:50,598][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5082292 effective words) took 3.9s, 1286899 effective words/s
[2023-02-07 18:35:51,602][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 31.56% examples, 1615686 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:52,604][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 61.01% examples, 1572776 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:53,610][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 89.93% examples, 1527701 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:53,949][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5082292 effective words) took 3.3s, 1517321 effective words/s
[2023-02-07 18:35:54,955][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 27.88% examples, 1421771 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:55,960][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 54.81% examples, 1418201 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:56,962][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 84.03% examples, 1432233 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:57,488][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5082292 effective words) took 3.5s, 1436957 effective words/s
[2023-02-07 18:35:58,493][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 23.18% examples, 1165333 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:59,502][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 46.79% examples, 1204091 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:00,504][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 69.73% examples, 1204064 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:01,506][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 99.11% examples, 1255517 words/s, in_qsize 5, out_qsize 0
[2023-02-07 18:36:01,532][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5082292 effective words) took 4.0s, 1257206 effective words/s
[2023-02-07 18:36:02,540][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 27.88% examples, 1418411 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:03,541][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 55.23% examples, 1429361 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:04,548][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 84.28% examples, 1433827 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:05,069][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5082292 effective words) took 3.5s, 1437564 effective words/s
[2023-02-07 18:36:06,077][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 28.25% examples, 1435235 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:07,082][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 56.09% examples, 1452935 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:08,087][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 85.66% examples, 1454471 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:08,552][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5082292 effective words) took 3.5s, 1459565 effective words/s
[2023-02-07 18:36:09,562][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 27.14% examples, 1381390 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:10,569][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 51.70% examples, 1334601 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:11,577][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 77.06% examples, 1310184 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:12,462][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5082292 effective words) took 3.9s, 1300396 effective words/s
[2023-02-07 18:36:12,463][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76234380 effective words) took 55.2s, 1381246 effective words/s', 'datetime': '2023-02-07T18:36:12.463406', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:36:12.463 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:36:17,554][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183448-1pzyn0h6/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:36:17.554287', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:36:17,556][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:36:17,664][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183448-1pzyn0h6/files/../tmp/embedding_model.pt
2023-02-07 18:36:17.665 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:36:19.808 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:36:20.582 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:36:22.818 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.2592412108661666, 'test_mae': 0.8881438981993067, 'test_r2': -3.5015386237126647}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.09
wandb: percentage 0.14517
wandb:   test_mae 0.88814
wandb:   test_mse 1.25924
wandb:    test_r2 -3.50154
wandb: 
wandb: üöÄ View run clean-sweep-12 at: https://wandb.ai/xiaoqiz/mof2vec/runs/1pzyn0h6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_183448-1pzyn0h6/logs
wandb: Agent Starting Run: laepnyai with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 633
wandb: 	model.gensim.alpha: 0.0004251064239923407
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 4
wandb: 	model.gensim.sample: 0.560489207758512
wandb: 	model.gensim.vector_size: 282
wandb: 	model.gensim.window: 1
wandb: 	model.sklearn.learning_rate: 0.005056570767044497
wandb: 	model.sklearn.max_depth: 49
wandb: 	model.sklearn.min_child_weight: 0.07216095204413121
wandb: 	model.sklearn.n_estimators: 1285
wandb: 	model.sklearn.num_leaves: 346
wandb: 	model.sklearn.reg_alpha: 0.01611530378895312
wandb: 	model.sklearn.reg_lambda: 0.04425956373856794
wandb: 	model.sklearn.subsample: 0.5376784656462625
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183634-laepnyai
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/laepnyai
2023-02-07 18:36:42.575 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 18:36:42.576 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 633 for sweep.
2023-02-07 18:36:42.576 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0004251064239923407 for sweep.
2023-02-07 18:36:42.576 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:36:42.577 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 4 for sweep.
2023-02-07 18:36:42.577 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.560489207758512 for sweep.
2023-02-07 18:36:42.577 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 282 for sweep.
2023-02-07 18:36:42.577 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 1 for sweep.
2023-02-07 18:36:42.578 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.005056570767044497 for sweep.
2023-02-07 18:36:42.578 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 49 for sweep.
2023-02-07 18:36:42.578 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.07216095204413121 for sweep.
2023-02-07 18:36:42.579 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1285 for sweep.
2023-02-07 18:36:42.579 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 346 for sweep.
2023-02-07 18:36:42.579 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.01611530378895312 for sweep.
2023-02-07 18:36:42.580 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.04425956373856794 for sweep.
2023-02-07 18:36:42.580 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5376784656462625 for sweep.
2023-02-07 18:36:42.580 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:36:42.590 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183634-laepnyai/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 633, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 282, 'window': 1, 'min_count': 4, 'dm': 1, 'sample': 0.560489207758512, 'workers': 4, 'alpha': 0.0004251064239923407, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1285, 'max_depth': 49, 'num_leaves': 346, 'reg_alpha': 0.01611530378895312, 'reg_lambda': 0.04425956373856794, 'subsample': 0.5376784656462625, 'min_child_weight': 0.07216095204413121, 'n_jobs': 4, 'learning_rate': 0.005056570767044497}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 12/3257 [00:00<00:27, 119.29it/s]  1%|          | 27/3257 [00:00<00:23, 136.91it/s]  1%|‚ñè         | 41/3257 [00:00<00:43, 74.34it/s]   2%|‚ñè         | 55/3257 [00:00<00:35, 90.57it/s]  2%|‚ñè         | 71/3257 [00:00<00:29, 109.16it/s]  3%|‚ñé         | 89/3257 [00:00<00:24, 128.60it/s]  3%|‚ñé         | 104/3257 [00:00<00:24, 129.28it/s]  4%|‚ñé         | 119/3257 [00:01<00:23, 130.78it/s]  4%|‚ñç         | 134/3257 [00:01<00:23, 133.25it/s]  5%|‚ñç         | 151/3257 [00:01<00:21, 142.52it/s]  5%|‚ñå         | 166/3257 [00:01<00:22, 137.91it/s]  6%|‚ñå         | 181/3257 [00:01<00:22, 137.06it/s]  6%|‚ñå         | 197/3257 [00:01<00:21, 140.81it/s]  7%|‚ñã         | 215/3257 [00:01<00:20, 151.82it/s]  7%|‚ñã         | 233/3257 [00:01<00:19, 159.05it/s]  8%|‚ñä         | 250/3257 [00:01<00:19, 156.94it/s]  8%|‚ñä         | 266/3257 [00:01<00:19, 151.45it/s]  9%|‚ñâ         | 287/3257 [00:02<00:18, 164.14it/s]  9%|‚ñâ         | 304/3257 [00:02<00:18, 157.25it/s] 10%|‚ñâ         | 321/3257 [00:02<00:18, 160.67it/s] 10%|‚ñà         | 338/3257 [00:02<00:18, 156.45it/s] 11%|‚ñà         | 355/3257 [00:02<00:18, 159.68it/s] 11%|‚ñà‚ñè        | 372/3257 [00:02<00:18, 156.86it/s] 12%|‚ñà‚ñè        | 388/3257 [00:02<00:20, 139.95it/s] 12%|‚ñà‚ñè        | 406/3257 [00:02<00:19, 149.40it/s] 13%|‚ñà‚ñé        | 422/3257 [00:03<00:18, 150.21it/s] 13%|‚ñà‚ñé        | 438/3257 [00:03<00:21, 131.40it/s] 14%|‚ñà‚ñç        | 453/3257 [00:03<00:20, 135.65it/s] 14%|‚ñà‚ñç        | 472/3257 [00:03<00:18, 147.79it/s] 15%|‚ñà‚ñç        | 488/3257 [00:03<00:18, 147.36it/s] 16%|‚ñà‚ñå        | 509/3257 [00:03<00:16, 164.06it/s] 16%|‚ñà‚ñå        | 526/3257 [00:03<00:17, 156.61it/s] 17%|‚ñà‚ñã        | 544/3257 [00:03<00:16, 162.08it/s] 17%|‚ñà‚ñã        | 561/3257 [00:03<00:18, 146.80it/s] 18%|‚ñà‚ñä        | 577/3257 [00:04<00:19, 140.16it/s] 18%|‚ñà‚ñä        | 595/3257 [00:04<00:17, 150.31it/s] 19%|‚ñà‚ñâ        | 613/3257 [00:04<00:16, 157.71it/s] 19%|‚ñà‚ñâ        | 630/3257 [00:04<00:16, 155.32it/s] 20%|‚ñà‚ñâ        | 646/3257 [00:04<00:17, 150.14it/s] 20%|‚ñà‚ñà        | 662/3257 [00:04<00:18, 139.76it/s] 21%|‚ñà‚ñà        | 681/3257 [00:04<00:17, 150.65it/s] 21%|‚ñà‚ñà‚ñè       | 697/3257 [00:04<00:17, 143.08it/s] 22%|‚ñà‚ñà‚ñè       | 716/3257 [00:04<00:16, 153.53it/s] 22%|‚ñà‚ñà‚ñè       | 732/3257 [00:05<00:17, 142.36it/s] 23%|‚ñà‚ñà‚ñé       | 747/3257 [00:05<00:17, 139.96it/s] 23%|‚ñà‚ñà‚ñé       | 765/3257 [00:05<00:16, 149.60it/s] 24%|‚ñà‚ñà‚ñç       | 781/3257 [00:05<00:17, 141.56it/s] 25%|‚ñà‚ñà‚ñç       | 798/3257 [00:05<00:16, 148.15it/s] 25%|‚ñà‚ñà‚ñç       | 814/3257 [00:05<00:16, 146.13it/s] 25%|‚ñà‚ñà‚ñå       | 829/3257 [00:05<00:17, 139.36it/s] 26%|‚ñà‚ñà‚ñå       | 844/3257 [00:05<00:17, 136.09it/s] 26%|‚ñà‚ñà‚ñã       | 859/3257 [00:06<00:17, 138.37it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:06<00:17, 139.78it/s] 27%|‚ñà‚ñà‚ñã       | 890/3257 [00:06<00:16, 141.17it/s] 28%|‚ñà‚ñà‚ñä       | 906/3257 [00:06<00:16, 146.25it/s] 28%|‚ñà‚ñà‚ñä       | 923/3257 [00:06<00:15, 151.31it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:06<00:15, 148.85it/s] 29%|‚ñà‚ñà‚ñâ       | 957/3257 [00:06<00:14, 155.63it/s] 30%|‚ñà‚ñà‚ñâ       | 973/3257 [00:06<00:15, 150.73it/s] 30%|‚ñà‚ñà‚ñà       | 989/3257 [00:06<00:15, 146.06it/s] 31%|‚ñà‚ñà‚ñà       | 1005/3257 [00:06<00:15, 147.88it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1020/3257 [00:07<00:15, 147.38it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1035/3257 [00:07<00:15, 140.16it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1050/3257 [00:07<00:16, 136.92it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:07<00:15, 144.12it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1082/3257 [00:07<00:15, 141.64it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1098/3257 [00:07<00:14, 144.48it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:07<00:14, 148.66it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1130/3257 [00:07<00:15, 141.75it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1145/3257 [00:07<00:15, 137.59it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1162/3257 [00:08<00:14, 145.56it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1177/3257 [00:08<00:25, 82.16it/s]  37%|‚ñà‚ñà‚ñà‚ñã      | 1189/3257 [00:08<00:24, 85.40it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:08<00:21, 97.15it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:08<00:19, 106.30it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1239/3257 [00:08<00:15, 130.57it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1254/3257 [00:09<00:15, 132.53it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:09<00:14, 139.34it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1286/3257 [00:09<00:15, 127.26it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1301/3257 [00:09<00:14, 131.66it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1317/3257 [00:09<00:14, 138.40it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1334/3257 [00:09<00:13, 147.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1352/3257 [00:09<00:12, 155.87it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:09<00:11, 162.59it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:09<00:11, 165.47it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:09<00:09, 185.80it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1434/3257 [00:10<00:09, 192.73it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1459/3257 [00:10<00:08, 208.33it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1480/3257 [00:10<00:08, 206.30it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1504/3257 [00:10<00:08, 213.50it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1526/3257 [00:10<00:08, 197.49it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1547/3257 [00:10<00:09, 185.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1567/3257 [00:10<00:08, 189.33it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1587/3257 [00:10<00:08, 188.54it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1608/3257 [00:10<00:08, 194.15it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1630/3257 [00:11<00:08, 201.21it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1651/3257 [00:11<00:09, 176.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1670/3257 [00:11<00:09, 175.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1688/3257 [00:11<00:09, 171.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:11<00:08, 173.27it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1727/3257 [00:11<00:08, 179.71it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1746/3257 [00:11<00:09, 160.14it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1765/3257 [00:11<00:08, 167.07it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1786/3257 [00:11<00:08, 177.88it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1805/3257 [00:12<00:08, 172.68it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1824/3257 [00:12<00:08, 174.45it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1842/3257 [00:12<00:08, 169.69it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1860/3257 [00:12<00:08, 163.02it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:12<00:08, 166.62it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:12<00:08, 166.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:12<00:07, 172.95it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1938/3257 [00:12<00:07, 185.34it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1964/3257 [00:12<00:06, 205.64it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1985/3257 [00:13<00:06, 185.23it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:13<00:06, 185.87it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2023/3257 [00:13<00:06, 185.20it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2042/3257 [00:13<00:06, 176.86it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2060/3257 [00:13<00:07, 162.35it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2082/3257 [00:13<00:06, 173.27it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:13<00:06, 165.85it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:13<00:06, 166.00it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:14<00:06, 165.72it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:14<00:06, 163.09it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2174/3257 [00:14<00:06, 172.61it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2192/3257 [00:14<00:06, 168.07it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:14<00:06, 162.85it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2226/3257 [00:14<00:06, 163.57it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2243/3257 [00:14<00:06, 154.13it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2261/3257 [00:14<00:06, 160.41it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2278/3257 [00:14<00:06, 156.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:15<00:05, 166.51it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2320/3257 [00:15<00:05, 178.53it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2342/3257 [00:15<00:04, 190.03it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2363/3257 [00:15<00:04, 195.30it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2383/3257 [00:15<00:04, 195.55it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:15<00:04, 197.85it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2424/3257 [00:15<00:04, 185.47it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:15<00:04, 170.99it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2462/3257 [00:15<00:04, 173.76it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:15<00:04, 178.03it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2503/3257 [00:16<00:04, 187.82it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2522/3257 [00:16<00:03, 187.50it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2541/3257 [00:16<00:03, 185.18it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2560/3257 [00:16<00:03, 178.52it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2578/3257 [00:16<00:07, 93.29it/s]  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2593/3257 [00:16<00:06, 102.52it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2617/3257 [00:17<00:04, 128.88it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2636/3257 [00:17<00:04, 141.18it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:17<00:04, 142.46it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2671/3257 [00:17<00:03, 146.82it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:17<00:03, 156.73it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2707/3257 [00:17<00:03, 144.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2723/3257 [00:17<00:03, 143.86it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2745/3257 [00:17<00:03, 163.65it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2763/3257 [00:17<00:03, 163.18it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2780/3257 [00:18<00:02, 162.91it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2802/3257 [00:18<00:02, 178.06it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2821/3257 [00:18<00:02, 171.82it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2839/3257 [00:18<00:02, 161.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2863/3257 [00:18<00:02, 180.71it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:18<00:01, 186.95it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2905/3257 [00:18<00:01, 176.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:18<00:01, 183.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:18<00:01, 176.25it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2965/3257 [00:19<00:01, 176.17it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2983/3257 [00:19<00:01, 159.96it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3003/3257 [00:19<00:01, 169.16it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3021/3257 [00:19<00:01, 167.11it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3043/3257 [00:19<00:01, 181.24it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3066/3257 [00:19<00:00, 193.88it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3086/3257 [00:19<00:00, 191.20it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3107/3257 [00:19<00:00, 193.76it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:19<00:00, 193.45it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3147/3257 [00:20<00:00, 177.55it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:20<00:00, 177.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3184/3257 [00:20<00:00, 170.60it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3205/3257 [00:20<00:00, 180.16it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3224/3257 [00:20<00:00, 166.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:20<00:00, 171.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 157.09it/s]
2023-02-07 18:37:04.162 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:37:04,164][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d282,n5,w1,mc4,s0.560489,t4>', 'datetime': '2023-02-07T18:37:04.164149', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:37:04,164][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:37:04,164][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:37:04,703][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 18:37:04,704][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:37:04,783][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 retains 29175 unique words (68.32% of original 42701, drops 13526)', 'datetime': '2023-02-07T18:37:04.783047', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:37:04,784][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 leaves 5800681 word corpus (99.62% of original 5822992, drops 22311)', 'datetime': '2023-02-07T18:37:04.784074', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:37:04,887][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 18:37:04,888][gensim.models.word2vec][INFO] - sample=0.560489 downsamples 0 most-common words
[2023-02-07 18:37:04,889][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5800681 word corpus (100.0%% of prior 5800681)', 'datetime': '2023-02-07T18:37:04.889043', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:37:05,060][gensim.models.word2vec][INFO] - estimated required memory for 29175 words and 282 dimensions: 84731596 bytes
[2023-02-07 18:37:05,060][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:37:05,096][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 29175 vocabulary and 282 features, using sg=0 hs=0 sample=0.560489207758512 negative=5 window=1 shrink_windows=True', 'datetime': '2023-02-07T18:37:05.096374', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:37:06,108][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 28.00% examples, 1604264 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:07,111][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 55.57% examples, 1632761 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:08,121][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 85.60% examples, 1648592 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:08,575][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5774537 effective words) took 3.5s, 1660852 effective words/s
[2023-02-07 18:37:09,580][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 25.30% examples, 1452533 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:10,587][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 49.89% examples, 1459842 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:11,604][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 76.14% examples, 1471878 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:12,468][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5774537 effective words) took 3.9s, 1483793 effective words/s
[2023-02-07 18:37:13,472][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 26.04% examples, 1503571 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:14,481][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 51.64% examples, 1515355 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:15,486][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 78.63% examples, 1521323 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:16,268][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5774537 effective words) took 3.8s, 1520480 effective words/s
[2023-02-07 18:37:17,273][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 26.59% examples, 1535517 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:18,281][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 53.09% examples, 1557064 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:19,285][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 80.90% examples, 1562863 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:19,944][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5774537 effective words) took 3.7s, 1571785 effective words/s
[2023-02-07 18:37:20,947][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 26.99% examples, 1566977 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:21,951][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 54.04% examples, 1593264 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:22,952][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 91.62% examples, 1773790 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:23,153][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5774537 effective words) took 3.2s, 1800554 effective words/s
[2023-02-07 18:37:24,159][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 35.71% examples, 2083391 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:25,164][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 73.84% examples, 2154771 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:25,840][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5774537 effective words) took 2.7s, 2151604 effective words/s
[2023-02-07 18:37:26,843][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 36.48% examples, 2145798 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:27,853][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 68.65% examples, 2011860 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:28,752][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5774537 effective words) took 2.9s, 1984279 effective words/s
[2023-02-07 18:37:29,754][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 30.55% examples, 1770520 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:30,762][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 61.93% examples, 1805955 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:37:31,762][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 95.64% examples, 1836518 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:31,913][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5774537 effective words) took 3.2s, 1827381 effective words/s
[2023-02-07 18:37:32,921][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 31.53% examples, 1827817 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:33,924][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 64.54% examples, 1889981 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:34,928][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 98.34% examples, 1886571 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:34,972][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5774537 effective words) took 3.1s, 1889074 effective words/s
[2023-02-07 18:37:35,981][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 32.02% examples, 1856958 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:36,988][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 63.99% examples, 1865093 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:37,989][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 94.53% examples, 1814006 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:38,146][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5774537 effective words) took 3.2s, 1819780 effective words/s
[2023-02-07 18:37:39,150][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 32.12% examples, 1868436 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:40,156][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 63.99% examples, 1871591 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:41,158][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 97.67% examples, 1877591 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:41,217][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5774537 effective words) took 3.1s, 1881110 effective words/s
[2023-02-07 18:37:42,219][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 32.67% examples, 1908676 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:43,223][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 65.46% examples, 1924097 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:44,222][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5774537 effective words) took 3.0s, 1922703 effective words/s
[2023-02-07 18:37:45,224][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 33.25% examples, 1944469 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:46,224][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 66.41% examples, 1957840 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:47,198][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5774537 effective words) took 3.0s, 1941255 effective words/s
[2023-02-07 18:37:48,202][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 33.13% examples, 1924616 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:49,203][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 66.04% examples, 1944281 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:50,191][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5774537 effective words) took 3.0s, 1930600 effective words/s
[2023-02-07 18:37:51,194][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 31.53% examples, 1836690 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:52,199][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 62.70% examples, 1829149 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:53,204][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 95.98% examples, 1840807 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:53,322][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5774537 effective words) took 3.1s, 1845279 effective words/s
[2023-02-07 18:37:53,323][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86618055 effective words) took 48.2s, 1796078 effective words/s', 'datetime': '2023-02-07T18:37:53.322994', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:37:53.323 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:37:57,917][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183634-laepnyai/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:37:57.917002', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:37:57,917][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:37:58,051][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183634-laepnyai/files/../tmp/embedding_model.pt
2023-02-07 18:37:58.052 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:37:59.885 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:38:00.493 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:38:23.885 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.093146257121506, 'test_mae': 0.8338648761434058, 'test_r2': -3.3429593453428987}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.18
wandb: percentage 0.31676
wandb:   test_mae 0.83386
wandb:   test_mse 1.09315
wandb:    test_r2 -3.34296
wandb: 
wandb: üöÄ View run polished-sweep-13 at: https://wandb.ai/xiaoqiz/mof2vec/runs/laepnyai
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_183634-laepnyai/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: i420iy34 with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 579
wandb: 	model.gensim.alpha: 0.0014678550786131218
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.27375720276816073
wandb: 	model.gensim.vector_size: 471
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.20359021020576204
wandb: 	model.sklearn.max_depth: 70
wandb: 	model.sklearn.min_child_weight: 0.08586562143852931
wandb: 	model.sklearn.n_estimators: 3055
wandb: 	model.sklearn.num_leaves: 317
wandb: 	model.sklearn.reg_alpha: 0.00975615306470954
wandb: 	model.sklearn.reg_lambda: 0.007734964972367994
wandb: 	model.sklearn.subsample: 0.45309548881127926
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183842-i420iy34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-14
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/i420iy34
2023-02-07 18:38:50.914 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 18:38:50.915 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 579 for sweep.
2023-02-07 18:38:50.915 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0014678550786131218 for sweep.
2023-02-07 18:38:50.916 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:38:50.916 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 18:38:50.916 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.27375720276816073 for sweep.
2023-02-07 18:38:50.916 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 471 for sweep.
2023-02-07 18:38:50.917 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 18:38:50.917 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.20359021020576204 for sweep.
2023-02-07 18:38:50.917 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 70 for sweep.
2023-02-07 18:38:50.917 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08586562143852931 for sweep.
2023-02-07 18:38:50.917 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3055 for sweep.
2023-02-07 18:38:50.918 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 317 for sweep.
2023-02-07 18:38:50.918 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.00975615306470954 for sweep.
2023-02-07 18:38:50.918 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.007734964972367994 for sweep.
2023-02-07 18:38:50.918 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.45309548881127926 for sweep.
2023-02-07 18:38:50.919 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:38:50.923 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183842-i420iy34/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 579, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 471, 'window': 11, 'min_count': 1, 'dm': 1, 'sample': 0.27375720276816073, 'workers': 4, 'alpha': 0.0014678550786131218, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3055, 'max_depth': 70, 'num_leaves': 317, 'reg_alpha': 0.00975615306470954, 'reg_lambda': 0.007734964972367994, 'subsample': 0.45309548881127926, 'min_child_weight': 0.08586562143852931, 'n_jobs': 4, 'learning_rate': 0.20359021020576204}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:20, 159.08it/s]  1%|          | 34/3257 [00:00<00:20, 160.15it/s]  2%|‚ñè         | 53/3257 [00:00<00:19, 162.08it/s]  2%|‚ñè         | 71/3257 [00:00<00:18, 168.03it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 169.43it/s]  3%|‚ñé         | 107/3257 [00:00<00:19, 157.97it/s]  4%|‚ñç         | 124/3257 [00:00<00:19, 159.75it/s]  4%|‚ñç         | 144/3257 [00:00<00:18, 171.10it/s]  5%|‚ñç         | 162/3257 [00:00<00:19, 161.54it/s]  5%|‚ñå         | 179/3257 [00:01<00:19, 160.27it/s]  6%|‚ñå         | 197/3257 [00:01<00:18, 165.31it/s]  7%|‚ñã         | 217/3257 [00:01<00:17, 174.48it/s]  7%|‚ñã         | 237/3257 [00:01<00:17, 176.44it/s]  8%|‚ñä         | 256/3257 [00:01<00:16, 177.72it/s]  8%|‚ñä         | 274/3257 [00:01<00:16, 178.18it/s]  9%|‚ñâ         | 297/3257 [00:01<00:15, 188.67it/s] 10%|‚ñâ         | 316/3257 [00:01<00:16, 178.49it/s] 10%|‚ñà         | 335/3257 [00:01<00:16, 180.34it/s] 11%|‚ñà         | 354/3257 [00:02<00:16, 181.34it/s] 11%|‚ñà‚ñè        | 373/3257 [00:02<00:16, 179.15it/s] 12%|‚ñà‚ñè        | 391/3257 [00:02<00:17, 164.11it/s] 13%|‚ñà‚ñé        | 410/3257 [00:02<00:16, 170.72it/s] 13%|‚ñà‚ñé        | 428/3257 [00:02<00:18, 150.13it/s] 14%|‚ñà‚ñé        | 445/3257 [00:02<00:18, 154.33it/s] 14%|‚ñà‚ñç        | 464/3257 [00:02<00:17, 163.53it/s] 15%|‚ñà‚ñç        | 481/3257 [00:02<00:17, 155.94it/s] 15%|‚ñà‚ñå        | 502/3257 [00:02<00:16, 168.91it/s] 16%|‚ñà‚ñå        | 521/3257 [00:03<00:15, 174.35it/s] 17%|‚ñà‚ñã        | 539/3257 [00:03<00:16, 169.26it/s] 17%|‚ñà‚ñã        | 557/3257 [00:03<00:15, 170.11it/s] 18%|‚ñà‚ñä        | 575/3257 [00:03<00:18, 145.69it/s] 18%|‚ñà‚ñä        | 595/3257 [00:03<00:16, 157.14it/s] 19%|‚ñà‚ñâ        | 615/3257 [00:03<00:15, 166.53it/s] 19%|‚ñà‚ñâ        | 633/3257 [00:03<00:15, 168.00it/s] 20%|‚ñà‚ñâ        | 651/3257 [00:03<00:16, 158.96it/s] 21%|‚ñà‚ñà        | 668/3257 [00:04<00:16, 152.98it/s] 21%|‚ñà‚ñà        | 684/3257 [00:04<00:25, 99.05it/s]  21%|‚ñà‚ñà‚ñè       | 699/3257 [00:04<00:23, 108.69it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:20, 126.18it/s] 23%|‚ñà‚ñà‚ñé       | 733/3257 [00:04<00:19, 128.46it/s] 23%|‚ñà‚ñà‚ñé       | 748/3257 [00:04<00:19, 131.01it/s] 24%|‚ñà‚ñà‚ñé       | 768/3257 [00:04<00:16, 148.74it/s] 24%|‚ñà‚ñà‚ñç       | 784/3257 [00:04<00:17, 142.65it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:16, 153.29it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:15, 154.55it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:05<00:16, 148.73it/s] 26%|‚ñà‚ñà‚ñå       | 852/3257 [00:05<00:16, 146.42it/s] 27%|‚ñà‚ñà‚ñã       | 869/3257 [00:05<00:15, 152.04it/s] 27%|‚ñà‚ñà‚ñã       | 885/3257 [00:05<00:15, 149.88it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:14, 163.80it/s] 28%|‚ñà‚ñà‚ñä       | 923/3257 [00:05<00:13, 167.44it/s] 29%|‚ñà‚ñà‚ñâ       | 940/3257 [00:05<00:13, 165.61it/s] 29%|‚ñà‚ñà‚ñâ       | 958/3257 [00:06<00:13, 169.62it/s] 30%|‚ñà‚ñà‚ñâ       | 976/3257 [00:06<00:13, 170.56it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:06<00:14, 151.48it/s] 31%|‚ñà‚ñà‚ñà       | 1010/3257 [00:06<00:15, 149.79it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:06<00:14, 149.27it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1043/3257 [00:06<00:15, 147.32it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1060/3257 [00:06<00:14, 153.00it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:14, 153.86it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:06<00:13, 155.62it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:07<00:13, 159.61it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1132/3257 [00:07<00:14, 150.08it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1148/3257 [00:07<00:14, 148.37it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1169/3257 [00:07<00:12, 164.39it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1186/3257 [00:07<00:13, 148.53it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1202/3257 [00:07<00:14, 140.58it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:07<00:14, 143.05it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1239/3257 [00:07<00:12, 159.93it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1256/3257 [00:08<00:12, 155.95it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1274/3257 [00:08<00:12, 161.66it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:08<00:13, 146.02it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:08<00:13, 148.82it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1327/3257 [00:08<00:12, 159.72it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1345/3257 [00:08<00:11, 163.51it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1362/3257 [00:08<00:11, 162.05it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1379/3257 [00:08<00:11, 157.62it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1395/3257 [00:08<00:12, 155.01it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1416/3257 [00:09<00:10, 170.00it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1434/3257 [00:09<00:10, 167.99it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1453/3257 [00:09<00:10, 170.71it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:09<00:09, 181.42it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1493/3257 [00:09<00:09, 183.57it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:09<00:09, 184.70it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1532/3257 [00:09<00:10, 167.97it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:09<00:10, 161.37it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1567/3257 [00:09<00:10, 162.79it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1584/3257 [00:10<00:10, 162.29it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1602/3257 [00:10<00:09, 166.60it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:10<00:09, 168.40it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1637/3257 [00:10<00:09, 164.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:10<00:09, 163.56it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1671/3257 [00:10<00:10, 156.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1689/3257 [00:10<00:09, 161.83it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1706/3257 [00:10<00:09, 161.28it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:10<00:09, 156.69it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1739/3257 [00:11<00:11, 133.44it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1754/3257 [00:11<00:11, 136.39it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1770/3257 [00:11<00:10, 141.72it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1786/3257 [00:11<00:10, 144.10it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1801/3257 [00:11<00:10, 140.80it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1816/3257 [00:11<00:10, 134.55it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1830/3257 [00:11<00:10, 130.86it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:11<00:10, 135.94it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1861/3257 [00:11<00:10, 138.67it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1877/3257 [00:12<00:09, 143.37it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1892/3257 [00:12<00:10, 136.10it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1910/3257 [00:12<00:09, 144.85it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1925/3257 [00:12<00:17, 74.95it/s]  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1945/3257 [00:12<00:13, 94.67it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1964/3257 [00:12<00:11, 112.77it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1980/3257 [00:13<00:11, 115.36it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1997/3257 [00:13<00:10, 125.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2012/3257 [00:13<00:09, 129.01it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2030/3257 [00:13<00:08, 139.58it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2046/3257 [00:13<00:08, 135.16it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2061/3257 [00:13<00:09, 120.37it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2078/3257 [00:13<00:09, 129.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2092/3257 [00:13<00:08, 131.90it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2106/3257 [00:13<00:08, 132.13it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:14<00:09, 124.97it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2133/3257 [00:14<00:09, 123.75it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2146/3257 [00:14<00:09, 121.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:14<00:08, 133.13it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2179/3257 [00:14<00:07, 139.01it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2194/3257 [00:14<00:07, 141.32it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:14<00:07, 134.87it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2224/3257 [00:14<00:07, 137.51it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:14<00:07, 132.52it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2252/3257 [00:15<00:07, 132.99it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2266/3257 [00:15<00:07, 134.00it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2280/3257 [00:15<00:07, 130.93it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2297/3257 [00:15<00:06, 140.42it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2312/3257 [00:15<00:06, 135.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2331/3257 [00:15<00:06, 148.40it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2349/3257 [00:15<00:05, 156.97it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2365/3257 [00:15<00:05, 156.95it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2381/3257 [00:15<00:05, 156.27it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2398/3257 [00:16<00:05, 159.39it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2414/3257 [00:16<00:05, 147.95it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2429/3257 [00:16<00:05, 142.00it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2444/3257 [00:16<00:06, 133.14it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2460/3257 [00:16<00:05, 139.42it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:16<00:05, 144.61it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2493/3257 [00:16<00:05, 150.38it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2510/3257 [00:16<00:04, 155.96it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2526/3257 [00:16<00:04, 152.70it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2542/3257 [00:17<00:04, 151.56it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2558/3257 [00:17<00:04, 146.01it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:17<00:05, 136.10it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2587/3257 [00:17<00:04, 134.84it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2604/3257 [00:17<00:04, 142.93it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2622/3257 [00:17<00:04, 153.09it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2638/3257 [00:17<00:04, 151.23it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:17<00:04, 138.53it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2669/3257 [00:17<00:04, 136.21it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2684/3257 [00:18<00:04, 138.30it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2698/3257 [00:18<00:04, 122.36it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2711/3257 [00:18<00:04, 121.52it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2726/3257 [00:18<00:04, 126.52it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2742/3257 [00:18<00:03, 134.18it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:18<00:03, 134.92it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2770/3257 [00:18<00:03, 127.52it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2787/3257 [00:18<00:03, 137.93it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:18<00:03, 142.84it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2818/3257 [00:19<00:03, 130.34it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2832/3257 [00:19<00:03, 128.57it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2846/3257 [00:19<00:03, 128.56it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2866/3257 [00:19<00:02, 146.09it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2884/3257 [00:19<00:02, 154.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2900/3257 [00:19<00:02, 134.67it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2915/3257 [00:19<00:02, 138.53it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2930/3257 [00:19<00:02, 134.43it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2944/3257 [00:20<00:02, 129.55it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2958/3257 [00:20<00:02, 125.81it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2974/3257 [00:20<00:02, 133.80it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2988/3257 [00:20<00:02, 126.02it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:20<00:01, 134.91it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:20<00:01, 129.07it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3033/3257 [00:20<00:01, 133.36it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:20<00:01, 133.77it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3065/3257 [00:20<00:01, 142.59it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3080/3257 [00:20<00:01, 141.70it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3095/3257 [00:21<00:01, 137.28it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:21<00:01, 140.28it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3126/3257 [00:21<00:00, 145.34it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3141/3257 [00:21<00:00, 138.38it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3155/3257 [00:21<00:00, 135.32it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3170/3257 [00:21<00:00, 138.62it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3184/3257 [00:21<00:00, 130.21it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3201/3257 [00:21<00:00, 141.14it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3216/3257 [00:21<00:00, 135.89it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3234/3257 [00:22<00:00, 147.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:22<00:00, 147.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 146.41it/s]
2023-02-07 18:39:14.226 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:39:14,227][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d471,n5,w11,s0.273757,t4>', 'datetime': '2023-02-07T18:39:14.227526', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:39:14,228][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:39:14,228][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:39:14,888][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 18:39:14,889][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:39:15,016][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 54054 unique words (100.00% of original 54054, drops 0)', 'datetime': '2023-02-07T18:39:15.016491', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:39:15,016][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 6550866 word corpus (100.00% of original 6550866, drops 0)', 'datetime': '2023-02-07T18:39:15.016833', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:39:15,189][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 18:39:15,190][gensim.models.word2vec][INFO] - sample=0.273757 downsamples 0 most-common words
[2023-02-07 18:39:15,190][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6550866 word corpus (100.0%% of prior 6550866)', 'datetime': '2023-02-07T18:39:15.190930', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:39:15,498][gensim.models.word2vec][INFO] - estimated required memory for 54054 words and 471 dimensions: 237490060 bytes
[2023-02-07 18:39:15,498][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:39:15,600][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 54054 vocabulary and 471 features, using sg=0 hs=0 sample=0.27375720276816073 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T18:39:15.600433', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:39:16,610][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 13.60% examples, 858375 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:17,613][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 25.79% examples, 831468 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:18,616][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 36.48% examples, 802075 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:19,631][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 49.68% examples, 815607 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:20,640][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 63.22% examples, 829036 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:21,645][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 77.25% examples, 838889 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:22,650][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 91.34% examples, 847080 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:23,233][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6494971 effective words) took 7.6s, 851065 effective words/s
[2023-02-07 18:39:24,242][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 14.25% examples, 894956 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:25,271][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 27.79% examples, 890239 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:26,275][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 40.84% examples, 895096 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:27,293][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 55.08% examples, 900284 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:28,303][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 69.33% examples, 906908 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:29,304][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 84.00% examples, 907839 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:30,306][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 98.83% examples, 909931 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:39:30,360][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6494971 effective words) took 7.1s, 911548 effective words/s
[2023-02-07 18:39:31,366][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 14.71% examples, 931548 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:32,375][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 28.77% examples, 930352 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:33,378][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 42.37% examples, 936651 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:34,380][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 57.02% examples, 942166 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:35,385][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 71.81% examples, 945554 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:36,393][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 86.40% examples, 938065 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:39:37,372][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6494971 effective words) took 7.0s, 926522 effective words/s
[2023-02-07 18:39:38,380][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 13.29% examples, 843560 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:39,383][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 26.01% examples, 840292 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:40,397][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 38.53% examples, 845984 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:41,401][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 51.37% examples, 846069 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:42,406][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 64.66% examples, 848913 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:43,416][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 78.14% examples, 848467 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:44,418][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 91.37% examples, 848830 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:45,004][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6494971 effective words) took 7.6s, 851299 effective words/s
[2023-02-07 18:39:46,016][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 13.60% examples, 856476 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:47,031][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 26.68% examples, 858003 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:48,031][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 39.21% examples, 861724 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:49,033][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 52.16% examples, 859815 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:50,033][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 67.79% examples, 893116 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:51,051][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 84.71% examples, 918147 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:52,033][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6494971 effective words) took 7.0s, 924149 effective words/s
[2023-02-07 18:39:53,041][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 14.37% examples, 903086 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:54,045][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 28.40% examples, 918560 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:55,049][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 41.82% examples, 924116 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:56,049][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 56.56% examples, 935550 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:57,054][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 70.56% examples, 932767 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:39:58,061][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 86.18% examples, 936907 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:58,962][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6494971 effective words) took 6.9s, 937647 effective words/s
[2023-02-07 18:39:59,968][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 15.04% examples, 950116 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:00,978][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 29.54% examples, 952780 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:01,982][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 43.41% examples, 958450 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:02,988][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 58.27% examples, 960322 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:40:03,989][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 73.32% examples, 960679 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:04,990][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 88.61% examples, 959519 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:05,718][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6494971 effective words) took 6.8s, 961697 effective words/s
[2023-02-07 18:40:06,722][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 15.26% examples, 960119 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:07,723][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 30.03% examples, 973312 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:08,725][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 43.94% examples, 970956 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:09,740][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 57.45% examples, 947691 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:10,742][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 70.56% examples, 931922 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:11,745][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 84.96% examples, 923636 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:12,751][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 98.86% examples, 914919 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:40:12,808][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6494971 effective words) took 7.1s, 916263 effective words/s
[2023-02-07 18:40:13,825][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 13.72% examples, 861536 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:14,829][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 27.11% examples, 875044 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:15,832][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 39.73% examples, 876928 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:16,838][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 53.21% examples, 878493 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:17,842][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 66.63% examples, 877128 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:18,860][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 81.15% examples, 878488 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:19,866][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 95.27% examples, 878394 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:20,200][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6494971 effective words) took 7.4s, 878863 effective words/s
[2023-02-07 18:40:21,218][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 13.72% examples, 860803 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:22,228][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 27.33% examples, 875674 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:23,229][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 42.52% examples, 938891 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:24,240][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 58.27% examples, 956958 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:25,255][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 73.81% examples, 960970 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:26,257][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 89.04% examples, 961955 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:26,966][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6494971 effective words) took 6.8s, 960220 effective words/s
[2023-02-07 18:40:27,975][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 15.04% examples, 947129 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:28,984][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 29.75% examples, 958653 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:29,984][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 43.94% examples, 967467 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:30,988][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 58.61% examples, 965729 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:31,988][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 73.10% examples, 959665 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:32,990][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 88.61% examples, 960064 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:33,726][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6494971 effective words) took 6.8s, 961077 effective words/s
[2023-02-07 18:40:34,729][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 14.86% examples, 943357 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:35,736][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 29.08% examples, 941199 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:36,743][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 43.11% examples, 954010 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:37,744][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 58.21% examples, 961597 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:38,745][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 73.32% examples, 962074 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:39,747][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 88.82% examples, 964922 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:40,442][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6494971 effective words) took 6.7s, 967368 effective words/s
[2023-02-07 18:40:41,453][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 14.40% examples, 901131 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:42,467][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 27.33% examples, 876410 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:43,472][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 39.73% examples, 874995 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:44,480][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 53.12% examples, 874444 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:45,483][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 66.44% examples, 873951 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:46,496][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 80.66% examples, 872226 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:47,511][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 94.50% examples, 870451 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:47,896][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6494971 effective words) took 7.5s, 871437 effective words/s
[2023-02-07 18:40:48,912][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 13.72% examples, 863130 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:49,912][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 26.68% examples, 862972 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:50,913][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 39.18% examples, 861530 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:51,921][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 52.47% examples, 864856 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:52,934][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 65.80% examples, 867003 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:53,948][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 79.77% examples, 866527 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:54,968][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 96.65% examples, 889290 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:55,153][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6494971 effective words) took 7.3s, 895312 effective words/s
[2023-02-07 18:40:56,161][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 16.58% examples, 1036009 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:57,165][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 30.92% examples, 1005854 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:58,166][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 45.04% examples, 990423 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:59,168][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 59.26% examples, 979341 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:41:00,187][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 74.52% examples, 974951 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:41:01,192][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 89.99% examples, 973033 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:41:01,832][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6494971 effective words) took 6.7s, 972698 effective words/s
[2023-02-07 18:41:01,833][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (97424565 effective words) took 106.2s, 917091 effective words/s', 'datetime': '2023-02-07T18:41:01.833023', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:41:01.833 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:41:09,796][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183842-i420iy34/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:41:09.796843', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:41:09,797][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183842-i420iy34/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 18:41:09,864][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183842-i420iy34/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 18:41:09,933][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:41:09,978][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183842-i420iy34/files/../tmp/embedding_model.pt
2023-02-07 18:41:09.978 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:41:12.535 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:41:13.495 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:41:17.379 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1644759939366964, 'test_mae': 0.8165774484810654, 'test_r2': -3.537003370013146}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.15
wandb: percentage 0.0
wandb:   test_mae 0.81658
wandb:   test_mse 1.16448
wandb:    test_r2 -3.537
wandb: 
wandb: üöÄ View run ethereal-sweep-14 at: https://wandb.ai/xiaoqiz/mof2vec/runs/i420iy34
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_183842-i420iy34/logs
wandb: Agent Starting Run: kpx750oj with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 683
wandb: 	model.gensim.alpha: 0.003123227982991524
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.23782865033901265
wandb: 	model.gensim.vector_size: 343
wandb: 	model.gensim.window: 10
wandb: 	model.sklearn.learning_rate: 0.1330169272387009
wandb: 	model.sklearn.max_depth: 38
wandb: 	model.sklearn.min_child_weight: 0.07496176272422196
wandb: 	model.sklearn.n_estimators: 2749
wandb: 	model.sklearn.num_leaves: 370
wandb: 	model.sklearn.reg_alpha: 0.005300313321709107
wandb: 	model.sklearn.reg_lambda: 0.0027010877817876516
wandb: 	model.sklearn.subsample: 0.49301879342166127
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184132-kpx750oj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-15
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/kpx750oj
2023-02-07 18:41:40.161 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 18:41:40.162 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 683 for sweep.
2023-02-07 18:41:40.162 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.003123227982991524 for sweep.
2023-02-07 18:41:40.162 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:41:40.163 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 18:41:40.163 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.23782865033901265 for sweep.
2023-02-07 18:41:40.163 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 343 for sweep.
2023-02-07 18:41:40.163 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 10 for sweep.
2023-02-07 18:41:40.164 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.1330169272387009 for sweep.
2023-02-07 18:41:40.164 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 38 for sweep.
2023-02-07 18:41:40.164 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.07496176272422196 for sweep.
2023-02-07 18:41:40.164 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2749 for sweep.
2023-02-07 18:41:40.164 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 370 for sweep.
2023-02-07 18:41:40.165 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.005300313321709107 for sweep.
2023-02-07 18:41:40.165 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0027010877817876516 for sweep.
2023-02-07 18:41:40.165 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.49301879342166127 for sweep.
2023-02-07 18:41:40.165 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:41:40.177 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184132-kpx750oj/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 683, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 343, 'window': 10, 'min_count': 8, 'dm': 0, 'sample': 0.23782865033901265, 'workers': 4, 'alpha': 0.003123227982991524, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2749, 'max_depth': 38, 'num_leaves': 370, 'reg_alpha': 0.005300313321709107, 'reg_lambda': 0.0027010877817876516, 'subsample': 0.49301879342166127, 'min_child_weight': 0.07496176272422196, 'n_jobs': 4, 'learning_rate': 0.1330169272387009}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 166.85it/s]  1%|          | 34/3257 [00:00<00:19, 167.91it/s]  2%|‚ñè         | 53/3257 [00:00<00:18, 173.80it/s]  2%|‚ñè         | 74/3257 [00:00<00:17, 185.88it/s]  3%|‚ñé         | 93/3257 [00:00<00:31, 101.03it/s]  3%|‚ñé         | 107/3257 [00:00<00:28, 108.75it/s]  4%|‚ñç         | 124/3257 [00:00<00:25, 121.01it/s]  4%|‚ñç         | 143/3257 [00:01<00:22, 137.97it/s]  5%|‚ñç         | 159/3257 [00:01<00:21, 142.67it/s]  5%|‚ñå         | 175/3257 [00:01<00:22, 140.07it/s]  6%|‚ñå         | 193/3257 [00:01<00:20, 148.97it/s]  6%|‚ñã         | 211/3257 [00:01<00:19, 155.01it/s]  7%|‚ñã         | 231/3257 [00:01<00:18, 164.57it/s]  8%|‚ñä         | 249/3257 [00:01<00:18, 166.63it/s]  8%|‚ñä         | 266/3257 [00:01<00:19, 156.88it/s]  9%|‚ñâ         | 288/3257 [00:01<00:17, 173.02it/s]  9%|‚ñâ         | 306/3257 [00:02<00:17, 167.46it/s] 10%|‚ñâ         | 325/3257 [00:02<00:17, 171.85it/s] 11%|‚ñà         | 343/3257 [00:02<00:18, 159.24it/s] 11%|‚ñà         | 361/3257 [00:02<00:17, 164.18it/s] 12%|‚ñà‚ñè        | 378/3257 [00:02<00:18, 151.83it/s] 12%|‚ñà‚ñè        | 394/3257 [00:02<00:19, 147.40it/s] 13%|‚ñà‚ñé        | 411/3257 [00:02<00:18, 153.13it/s] 13%|‚ñà‚ñé        | 427/3257 [00:02<00:20, 137.88it/s] 14%|‚ñà‚ñé        | 442/3257 [00:02<00:20, 140.48it/s] 14%|‚ñà‚ñç        | 459/3257 [00:03<00:18, 148.14it/s] 15%|‚ñà‚ñç        | 476/3257 [00:03<00:18, 152.38it/s] 15%|‚ñà‚ñå        | 493/3257 [00:03<00:17, 155.61it/s] 16%|‚ñà‚ñå        | 511/3257 [00:03<00:16, 162.09it/s] 16%|‚ñà‚ñå        | 528/3257 [00:03<00:17, 155.87it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:17, 158.46it/s] 17%|‚ñà‚ñã        | 562/3257 [00:03<00:17, 151.86it/s] 18%|‚ñà‚ñä        | 578/3257 [00:03<00:19, 139.82it/s] 18%|‚ñà‚ñä        | 595/3257 [00:03<00:18, 147.26it/s] 19%|‚ñà‚ñâ        | 614/3257 [00:04<00:16, 157.49it/s] 19%|‚ñà‚ñâ        | 630/3257 [00:04<00:17, 150.57it/s] 20%|‚ñà‚ñâ        | 646/3257 [00:04<00:17, 145.60it/s] 20%|‚ñà‚ñà        | 661/3257 [00:04<00:19, 136.36it/s] 21%|‚ñà‚ñà        | 681/3257 [00:04<00:16, 152.01it/s] 21%|‚ñà‚ñà‚ñè       | 697/3257 [00:04<00:17, 142.59it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:04<00:16, 154.28it/s] 23%|‚ñà‚ñà‚ñé       | 733/3257 [00:04<00:17, 145.32it/s] 23%|‚ñà‚ñà‚ñé       | 748/3257 [00:05<00:17, 140.56it/s] 23%|‚ñà‚ñà‚ñé       | 764/3257 [00:05<00:17, 145.50it/s] 24%|‚ñà‚ñà‚ñç       | 779/3257 [00:05<00:17, 141.85it/s] 24%|‚ñà‚ñà‚ñç       | 795/3257 [00:05<00:16, 145.65it/s] 25%|‚ñà‚ñà‚ñç       | 810/3257 [00:05<00:16, 146.25it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:05<00:17, 141.34it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:05<00:16, 142.53it/s] 26%|‚ñà‚ñà‚ñã       | 855/3257 [00:05<00:17, 137.61it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:05<00:16, 141.95it/s] 27%|‚ñà‚ñà‚ñã       | 886/3257 [00:05<00:16, 142.20it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:06<00:15, 153.44it/s] 28%|‚ñà‚ñà‚ñä       | 921/3257 [00:06<00:15, 153.92it/s] 29%|‚ñà‚ñà‚ñâ       | 937/3257 [00:06<00:15, 151.92it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:06<00:14, 160.01it/s] 30%|‚ñà‚ñà‚ñâ       | 973/3257 [00:06<00:14, 156.27it/s] 30%|‚ñà‚ñà‚ñà       | 989/3257 [00:06<00:15, 151.07it/s] 31%|‚ñà‚ñà‚ñà       | 1005/3257 [00:06<00:14, 150.91it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1021/3257 [00:06<00:14, 152.05it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1037/3257 [00:06<00:15, 142.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1052/3257 [00:07<00:15, 139.36it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1070/3257 [00:07<00:14, 149.74it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1086/3257 [00:07<00:14, 146.57it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1102/3257 [00:07<00:14, 149.16it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1118/3257 [00:07<00:14, 150.55it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1134/3257 [00:07<00:14, 146.34it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1149/3257 [00:07<00:14, 140.78it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:13, 151.45it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1186/3257 [00:08<00:14, 141.79it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1201/3257 [00:08<00:15, 131.73it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1216/3257 [00:08<00:15, 136.06it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1235/3257 [00:08<00:13, 148.71it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1251/3257 [00:08<00:24, 82.19it/s]  39%|‚ñà‚ñà‚ñà‚ñâ      | 1270/3257 [00:08<00:19, 99.61it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1284/3257 [00:09<00:19, 99.30it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1299/3257 [00:09<00:17, 109.10it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1315/3257 [00:09<00:16, 120.37it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1330/3257 [00:09<00:15, 127.56it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:09<00:14, 135.24it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1361/3257 [00:09<00:13, 138.53it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1376/3257 [00:09<00:13, 135.90it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1391/3257 [00:09<00:13, 133.99it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1410/3257 [00:09<00:12, 147.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1427/3257 [00:09<00:12, 152.03it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1443/3257 [00:10<00:12, 148.02it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1462/3257 [00:10<00:11, 158.00it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1479/3257 [00:10<00:11, 159.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:10<00:10, 160.41it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:10<00:10, 162.16it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:10<00:11, 148.75it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:10<00:12, 140.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1563/3257 [00:10<00:11, 146.67it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1578/3257 [00:10<00:11, 142.16it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1595/3257 [00:11<00:11, 146.89it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1611/3257 [00:11<00:11, 149.02it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1627/3257 [00:11<00:10, 151.36it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1643/3257 [00:11<00:11, 141.85it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1658/3257 [00:11<00:11, 140.15it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1673/3257 [00:11<00:11, 137.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1689/3257 [00:11<00:11, 141.54it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1705/3257 [00:11<00:10, 145.69it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1720/3257 [00:11<00:10, 146.19it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1735/3257 [00:12<00:11, 131.14it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1752/3257 [00:12<00:10, 140.38it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1768/3257 [00:12<00:10, 145.22it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1786/3257 [00:12<00:09, 152.61it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1802/3257 [00:12<00:09, 151.71it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1818/3257 [00:12<00:10, 143.76it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1833/3257 [00:12<00:10, 137.53it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:12<00:09, 140.81it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1868/3257 [00:12<00:09, 151.98it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1884/3257 [00:13<00:09, 147.31it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:13<00:09, 143.89it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:13<00:09, 145.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:13<00:09, 142.04it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1952/3257 [00:13<00:08, 160.75it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1973/3257 [00:13<00:07, 171.86it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1991/3257 [00:13<00:07, 172.62it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2010/3257 [00:13<00:07, 177.22it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:13<00:06, 187.14it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:14<00:06, 175.90it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2070/3257 [00:14<00:06, 172.43it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:14<00:06, 180.48it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2110/3257 [00:14<00:06, 181.11it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2129/3257 [00:14<00:06, 170.54it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2147/3257 [00:14<00:06, 170.22it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:14<00:05, 182.98it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2188/3257 [00:14<00:05, 183.09it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2207/3257 [00:14<00:05, 183.98it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2226/3257 [00:15<00:05, 184.29it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2245/3257 [00:15<00:05, 178.42it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2264/3257 [00:15<00:05, 180.02it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2283/3257 [00:15<00:05, 175.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:15<00:05, 175.04it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2326/3257 [00:15<00:04, 193.16it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2350/3257 [00:15<00:04, 205.58it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2371/3257 [00:15<00:04, 200.62it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2394/3257 [00:15<00:04, 207.63it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2415/3257 [00:16<00:04, 192.54it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2435/3257 [00:16<00:04, 182.57it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2454/3257 [00:16<00:04, 179.24it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2477/3257 [00:16<00:04, 192.66it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2498/3257 [00:16<00:03, 196.02it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2519/3257 [00:16<00:03, 199.55it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:16<00:03, 199.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2561/3257 [00:16<00:03, 190.33it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2581/3257 [00:16<00:03, 179.19it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:17<00:03, 177.86it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2625/3257 [00:17<00:03, 197.09it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2645/3257 [00:17<00:03, 188.57it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2665/3257 [00:17<00:05, 103.81it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2685/3257 [00:17<00:04, 120.49it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2702/3257 [00:17<00:04, 120.42it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2718/3257 [00:17<00:04, 128.12it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:18<00:03, 151.35it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2760/3257 [00:18<00:03, 160.39it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2778/3257 [00:18<00:03, 157.80it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2799/3257 [00:18<00:02, 171.21it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2818/3257 [00:18<00:02, 163.99it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2836/3257 [00:18<00:02, 163.00it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2858/3257 [00:18<00:02, 177.55it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2882/3257 [00:18<00:01, 193.82it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2902/3257 [00:18<00:02, 177.18it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2921/3257 [00:19<00:01, 179.54it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2940/3257 [00:19<00:01, 176.64it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2958/3257 [00:19<00:01, 161.04it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:19<00:01, 164.39it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2993/3257 [00:19<00:01, 159.97it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3013/3257 [00:19<00:01, 170.27it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3031/3257 [00:19<00:01, 171.07it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3050/3257 [00:19<00:01, 175.42it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3072/3257 [00:19<00:00, 186.44it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3091/3257 [00:20<00:00, 178.87it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3113/3257 [00:20<00:00, 189.67it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3133/3257 [00:20<00:00, 182.75it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3152/3257 [00:20<00:00, 171.05it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3170/3257 [00:20<00:00, 172.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3188/3257 [00:20<00:00, 164.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:20<00:00, 167.47it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3224/3257 [00:20<00:00, 163.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3245/3257 [00:20<00:00, 174.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 154.76it/s]
2023-02-07 18:42:02.020 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:42:02,021][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d343,n5,mc8,s0.237829,t4>', 'datetime': '2023-02-07T18:42:02.021347', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:42:02,021][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:42:02,021][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:42:02,557][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 18:42:02,557][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:42:02,611][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 18271 unique words (42.79% of original 42701, drops 24430)', 'datetime': '2023-02-07T18:42:02.610976', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:42:02,611][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 5751191 word corpus (98.77% of original 5822992, drops 71801)', 'datetime': '2023-02-07T18:42:02.611389', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:42:02,674][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 18:42:02,675][gensim.models.word2vec][INFO] - sample=0.237829 downsamples 0 most-common words
[2023-02-07 18:42:02,675][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5751191 word corpus (100.0%% of prior 5751191)', 'datetime': '2023-02-07T18:42:02.675607', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:42:02,782][gensim.models.word2vec][INFO] - estimated required memory for 18271 words and 343 dimensions: 64391128 bytes
[2023-02-07 18:42:02,783][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:42:02,813][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18271 vocabulary and 343 features, using sg=1 hs=0 sample=0.23782865033901265 negative=5 window=10 shrink_windows=True', 'datetime': '2023-02-07T18:42:02.813579', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:42:03,822][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 32.02% examples, 1845457 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:04,824][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 64.63% examples, 1876952 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:05,833][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 98.89% examples, 1879345 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:05,854][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5725443 effective words) took 3.0s, 1883990 effective words/s
[2023-02-07 18:42:06,858][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 34.45% examples, 1993280 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:07,868][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 69.17% examples, 2010812 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:08,680][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5725443 effective words) took 2.8s, 2026895 effective words/s
[2023-02-07 18:42:09,685][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 35.68% examples, 2066680 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:10,689][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 66.04% examples, 1924392 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:11,692][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 97.88% examples, 1864444 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:42:11,750][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5725443 effective words) took 3.1s, 1866139 effective words/s
[2023-02-07 18:42:12,755][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 30.89% examples, 1770972 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:13,759][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 60.85% examples, 1764923 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:14,766][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 92.42% examples, 1765759 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:14,989][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5725443 effective words) took 3.2s, 1768788 effective words/s
[2023-02-07 18:42:15,993][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 30.70% examples, 1764200 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:16,997][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 61.01% examples, 1770338 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:18,004][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 92.54% examples, 1768596 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:18,222][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5725443 effective words) took 3.2s, 1771868 effective words/s
[2023-02-07 18:42:19,229][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 30.70% examples, 1759338 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:20,229][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 60.85% examples, 1766817 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:21,233][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 92.48% examples, 1772031 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:21,444][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5725443 effective words) took 3.2s, 1778428 effective words/s
[2023-02-07 18:42:22,454][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 30.92% examples, 1772149 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:23,461][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 65.83% examples, 1911491 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:24,259][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5725443 effective words) took 2.8s, 2035457 effective words/s
[2023-02-07 18:42:25,261][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 37.58% examples, 2204645 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:26,263][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 80.44% examples, 2320248 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:26,726][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5725443 effective words) took 2.5s, 2322042 effective words/s
[2023-02-07 18:42:27,729][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 39.09% examples, 2285421 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:28,729][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 77.31% examples, 2234689 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:29,329][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5725443 effective words) took 2.6s, 2200845 effective words/s
[2023-02-07 18:42:30,335][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 34.97% examples, 2024535 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:31,336][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 68.22% examples, 1988367 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:42:32,227][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5725443 effective words) took 2.9s, 1976730 effective words/s
[2023-02-07 18:42:33,231][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 32.36% examples, 1872571 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:34,232][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 65.06% examples, 1892105 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:35,190][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5725443 effective words) took 3.0s, 1933115 effective words/s
[2023-02-07 18:42:36,194][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 34.20% examples, 1973935 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:37,196][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 66.04% examples, 1927137 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:38,197][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 99.97% examples, 1901975 words/s, in_qsize 1, out_qsize 1
[2023-02-07 18:42:38,199][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5725443 effective words) took 3.0s, 1904320 effective words/s
[2023-02-07 18:42:39,204][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 32.02% examples, 1851230 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:40,204][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 65.49% examples, 1909017 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:41,194][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5725443 effective words) took 3.0s, 1912356 effective words/s
[2023-02-07 18:42:42,196][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 33.25% examples, 1927002 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:43,197][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 66.41% examples, 1940108 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:44,140][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5725443 effective words) took 2.9s, 1944158 effective words/s
[2023-02-07 18:42:45,143][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 33.47% examples, 1936854 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:46,145][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 67.79% examples, 1977439 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:47,021][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5725443 effective words) took 2.9s, 1988187 effective words/s
[2023-02-07 18:42:47,022][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85881645 effective words) took 44.2s, 1942660 effective words/s', 'datetime': '2023-02-07T18:42:47.022274', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:42:47.022 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:42:51,281][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184132-kpx750oj/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:42:51.281438', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:42:51,282][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:42:51,370][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184132-kpx750oj/files/../tmp/embedding_model.pt
2023-02-07 18:42:51.370 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:42:53.389 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:42:54.094 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:42:57.008 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9408893455771986, 'test_mae': 0.7188933367835232, 'test_r2': -1.9260339278221474}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.75
wandb: percentage 0.57212
wandb:   test_mae 0.71889
wandb:   test_mse 0.94089
wandb:    test_r2 -1.92603
wandb: 
wandb: üöÄ View run swift-sweep-15 at: https://wandb.ai/xiaoqiz/mof2vec/runs/kpx750oj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_184132-kpx750oj/logs
wandb: Agent Starting Run: fheij8t6 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 395
wandb: 	model.gensim.alpha: 0.00996519594605666
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.5344223017385366
wandb: 	model.gensim.vector_size: 65
wandb: 	model.gensim.window: 9
wandb: 	model.sklearn.learning_rate: 0.004250266002539397
wandb: 	model.sklearn.max_depth: 35
wandb: 	model.sklearn.min_child_weight: 0.09341223567624408
wandb: 	model.sklearn.n_estimators: 1493
wandb: 	model.sklearn.num_leaves: 354
wandb: 	model.sklearn.reg_alpha: 0.002877170626749595
wandb: 	model.sklearn.reg_lambda: 0.04013218878802075
wandb: 	model.sklearn.subsample: 0.5200078598130877
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184312-fheij8t6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/fheij8t6
2023-02-07 18:43:20.915 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 18:43:20.916 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 395 for sweep.
2023-02-07 18:43:20.916 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.00996519594605666 for sweep.
2023-02-07 18:43:20.917 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:43:20.917 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 18:43:20.917 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5344223017385366 for sweep.
2023-02-07 18:43:20.918 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 65 for sweep.
2023-02-07 18:43:20.918 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 9 for sweep.
2023-02-07 18:43:20.918 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.004250266002539397 for sweep.
2023-02-07 18:43:20.918 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 35 for sweep.
2023-02-07 18:43:20.919 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09341223567624408 for sweep.
2023-02-07 18:43:20.919 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1493 for sweep.
2023-02-07 18:43:20.919 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 354 for sweep.
2023-02-07 18:43:20.919 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.002877170626749595 for sweep.
2023-02-07 18:43:20.920 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.04013218878802075 for sweep.
2023-02-07 18:43:20.920 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5200078598130877 for sweep.
2023-02-07 18:43:20.920 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:43:20.929 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184312-fheij8t6/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 395, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 65, 'window': 9, 'min_count': 1, 'dm': 0, 'sample': 0.5344223017385366, 'workers': 4, 'alpha': 0.00996519594605666, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1493, 'max_depth': 35, 'num_leaves': 354, 'reg_alpha': 0.002877170626749595, 'reg_lambda': 0.04013218878802075, 'subsample': 0.5200078598130877, 'min_child_weight': 0.09341223567624408, 'n_jobs': 4, 'learning_rate': 0.004250266002539397}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:25, 125.51it/s]  1%|          | 29/3257 [00:00<00:22, 141.46it/s]  1%|‚ñè         | 44/3257 [00:00<00:22, 143.51it/s]  2%|‚ñè         | 59/3257 [00:00<00:22, 140.54it/s]  2%|‚ñè         | 79/3257 [00:00<00:20, 157.14it/s]  3%|‚ñé         | 96/3257 [00:00<00:20, 157.19it/s]  3%|‚ñé         | 112/3257 [00:00<00:20, 151.32it/s]  4%|‚ñç         | 128/3257 [00:00<00:20, 153.17it/s]  5%|‚ñç         | 147/3257 [00:00<00:19, 162.75it/s]  5%|‚ñå         | 164/3257 [00:01<00:20, 151.25it/s]  6%|‚ñå         | 180/3257 [00:01<00:20, 152.79it/s]  6%|‚ñå         | 200/3257 [00:01<00:18, 164.60it/s]  7%|‚ñã         | 219/3257 [00:01<00:17, 169.60it/s]  7%|‚ñã         | 237/3257 [00:01<00:17, 168.66it/s]  8%|‚ñä         | 255/3257 [00:01<00:17, 171.65it/s]  8%|‚ñä         | 273/3257 [00:01<00:17, 166.87it/s]  9%|‚ñâ         | 295/3257 [00:01<00:16, 180.71it/s] 10%|‚ñâ         | 314/3257 [00:01<00:17, 171.61it/s] 10%|‚ñà         | 334/3257 [00:02<00:16, 179.38it/s] 11%|‚ñà         | 353/3257 [00:02<00:16, 176.33it/s] 11%|‚ñà‚ñè        | 371/3257 [00:02<00:16, 173.90it/s] 12%|‚ñà‚ñè        | 389/3257 [00:02<00:18, 156.08it/s] 12%|‚ñà‚ñè        | 407/3257 [00:02<00:17, 161.98it/s] 13%|‚ñà‚ñé        | 424/3257 [00:02<00:17, 163.07it/s] 14%|‚ñà‚ñé        | 441/3257 [00:02<00:19, 147.00it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:18, 152.71it/s] 15%|‚ñà‚ñç        | 476/3257 [00:02<00:17, 156.00it/s] 15%|‚ñà‚ñå        | 495/3257 [00:03<00:16, 164.53it/s] 16%|‚ñà‚ñå        | 514/3257 [00:03<00:16, 171.25it/s] 16%|‚ñà‚ñã        | 532/3257 [00:03<00:16, 168.38it/s] 17%|‚ñà‚ñã        | 552/3257 [00:03<00:15, 175.91it/s] 18%|‚ñà‚ñä        | 570/3257 [00:03<00:16, 164.84it/s] 18%|‚ñà‚ñä        | 587/3257 [00:03<00:16, 161.80it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:16, 163.90it/s] 19%|‚ñà‚ñâ        | 622/3257 [00:03<00:16, 164.25it/s] 20%|‚ñà‚ñâ        | 642/3257 [00:03<00:15, 173.97it/s] 20%|‚ñà‚ñà        | 660/3257 [00:04<00:25, 101.15it/s] 21%|‚ñà‚ñà        | 680/3257 [00:04<00:21, 119.92it/s] 21%|‚ñà‚ñà‚ñè       | 696/3257 [00:04<00:20, 123.32it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:04<00:18, 140.24it/s] 23%|‚ñà‚ñà‚ñé       | 734/3257 [00:04<00:17, 143.91it/s] 23%|‚ñà‚ñà‚ñé       | 751/3257 [00:04<00:17, 144.98it/s] 24%|‚ñà‚ñà‚ñé       | 771/3257 [00:04<00:15, 157.55it/s] 24%|‚ñà‚ñà‚ñç       | 788/3257 [00:05<00:15, 155.13it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:05<00:15, 156.95it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:05<00:15, 156.98it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:05<00:15, 158.08it/s] 26%|‚ñà‚ñà‚ñã       | 857/3257 [00:05<00:15, 154.53it/s] 27%|‚ñà‚ñà‚ñã       | 873/3257 [00:05<00:15, 155.21it/s] 27%|‚ñà‚ñà‚ñã       | 889/3257 [00:05<00:15, 155.96it/s] 28%|‚ñà‚ñà‚ñä       | 908/3257 [00:05<00:14, 164.66it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:05<00:13, 173.04it/s] 29%|‚ñà‚ñà‚ñâ       | 946/3257 [00:06<00:13, 171.20it/s] 30%|‚ñà‚ñà‚ñâ       | 964/3257 [00:06<00:13, 171.73it/s] 30%|‚ñà‚ñà‚ñà       | 982/3257 [00:06<00:14, 162.42it/s] 31%|‚ñà‚ñà‚ñà       | 999/3257 [00:06<00:13, 161.46it/s] 31%|‚ñà‚ñà‚ñà       | 1016/3257 [00:06<00:13, 163.61it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1033/3257 [00:06<00:13, 159.00it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1050/3257 [00:06<00:13, 159.20it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1070/3257 [00:06<00:12, 169.94it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:06<00:13, 164.13it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:07<00:13, 161.06it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1122/3257 [00:07<00:13, 163.47it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:07<00:13, 158.95it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1156/3257 [00:07<00:12, 161.64it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1174/3257 [00:07<00:12, 165.38it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:07<00:13, 148.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:07<00:13, 146.59it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1226/3257 [00:07<00:12, 157.38it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1244/3257 [00:07<00:12, 161.54it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:07<00:12, 164.13it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1279/3257 [00:08<00:12, 153.49it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1295/3257 [00:08<00:12, 154.49it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1318/3257 [00:08<00:11, 175.41it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1342/3257 [00:08<00:09, 193.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1363/3257 [00:08<00:09, 197.11it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1383/3257 [00:08<00:09, 192.55it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1406/3257 [00:08<00:09, 201.61it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1431/3257 [00:08<00:08, 214.43it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1453/3257 [00:08<00:08, 215.87it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:09<00:08, 222.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1504/3257 [00:09<00:07, 234.87it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1528/3257 [00:09<00:07, 219.04it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1551/3257 [00:09<00:08, 207.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1573/3257 [00:09<00:08, 204.44it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:09<00:08, 202.74it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:09<00:07, 207.12it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1638/3257 [00:09<00:07, 202.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1659/3257 [00:09<00:08, 198.53it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1679/3257 [00:10<00:08, 193.71it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:10<00:07, 196.63it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1720/3257 [00:10<00:07, 192.77it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1740/3257 [00:10<00:08, 180.88it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1761/3257 [00:10<00:07, 187.76it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1784/3257 [00:10<00:07, 197.89it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1805/3257 [00:10<00:07, 196.51it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:10<00:07, 194.37it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1848/3257 [00:10<00:07, 199.82it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1871/3257 [00:11<00:06, 207.94it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1892/3257 [00:11<00:06, 203.57it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:11<00:06, 204.18it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1938/3257 [00:11<00:06, 207.39it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:11<00:05, 222.82it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1988/3257 [00:11<00:05, 215.30it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2011/3257 [00:11<00:05, 219.35it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:11<00:05, 224.65it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2058/3257 [00:12<00:09, 131.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2079/3257 [00:12<00:08, 146.92it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2098/3257 [00:12<00:07, 154.37it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:12<00:06, 166.52it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2140/3257 [00:12<00:06, 174.16it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2161/3257 [00:12<00:06, 181.04it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2182/3257 [00:12<00:05, 185.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2206/3257 [00:12<00:05, 195.14it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2227/3257 [00:12<00:05, 197.36it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2248/3257 [00:13<00:05, 194.12it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:13<00:05, 195.05it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2294/3257 [00:13<00:04, 205.58it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:13<00:04, 204.77it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2341/3257 [00:13<00:04, 218.24it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2367/3257 [00:13<00:03, 226.26it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2393/3257 [00:13<00:03, 232.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2417/3257 [00:13<00:03, 221.95it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:13<00:03, 213.46it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2463/3257 [00:14<00:03, 217.37it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2487/3257 [00:14<00:03, 223.71it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:14<00:03, 233.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:14<00:03, 234.16it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2564/3257 [00:14<00:03, 223.12it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2587/3257 [00:14<00:03, 203.24it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2613/3257 [00:14<00:02, 218.21it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2638/3257 [00:14<00:02, 226.42it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2662/3257 [00:14<00:02, 209.31it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2686/3257 [00:15<00:02, 216.76it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:15<00:02, 187.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2730/3257 [00:15<00:02, 190.91it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2753/3257 [00:15<00:02, 200.03it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:15<00:02, 191.89it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2801/3257 [00:15<00:02, 212.03it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:15<00:02, 205.20it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2844/3257 [00:15<00:02, 197.46it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2873/3257 [00:15<00:01, 220.84it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2896/3257 [00:16<00:01, 205.93it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:16<00:01, 213.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2942/3257 [00:16<00:01, 214.72it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2964/3257 [00:16<00:01, 204.72it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:16<00:01, 197.09it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:16<00:01, 211.40it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3033/3257 [00:16<00:01, 205.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3058/3257 [00:16<00:00, 216.80it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3083/3257 [00:16<00:00, 224.36it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3108/3257 [00:17<00:00, 231.13it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3132/3257 [00:17<00:00, 227.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3155/3257 [00:17<00:00, 217.53it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3177/3257 [00:17<00:00, 210.76it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3201/3257 [00:17<00:00, 218.19it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3223/3257 [00:17<00:00, 206.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3250/3257 [00:17<00:00, 222.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 183.18it/s]
2023-02-07 18:43:39.423 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:43:39,424][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d65,n5,s0.534422,t4>', 'datetime': '2023-02-07T18:43:39.424774', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:43:39,425][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:43:39,425][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:43:39,879][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 18:43:39,879][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:43:39,958][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 31803 unique words (100.00% of original 31803, drops 0)', 'datetime': '2023-02-07T18:43:39.958939', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:43:39,959][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 5095118 word corpus (100.00% of original 5095118, drops 0)', 'datetime': '2023-02-07T18:43:39.959366', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:43:40,068][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 18:43:40,069][gensim.models.word2vec][INFO] - sample=0.534422 downsamples 0 most-common words
[2023-02-07 18:43:40,070][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5095118 word corpus (100.0%% of prior 5095118)', 'datetime': '2023-02-07T18:43:40.070050', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:43:40,262][gensim.models.word2vec][INFO] - estimated required memory for 31803 words and 65 dimensions: 33937280 bytes
[2023-02-07 18:43:40,263][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:43:40,272][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 31803 vocabulary and 65 features, using sg=1 hs=0 sample=0.5344223017385366 negative=5 window=9 shrink_windows=True', 'datetime': '2023-02-07T18:43:40.272659', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:43:41,275][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 70.65% examples, 3676500 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:41,670][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5086629 effective words) took 1.4s, 3644826 effective words/s
[2023-02-07 18:43:42,671][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 75.53% examples, 3899262 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:42,971][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5086629 effective words) took 1.3s, 3913269 effective words/s
[2023-02-07 18:43:43,976][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 74.06% examples, 3809333 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:44,310][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5086629 effective words) took 1.3s, 3803697 effective words/s
[2023-02-07 18:43:45,312][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 75.13% examples, 3880254 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:45,632][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5086629 effective words) took 1.3s, 3852792 effective words/s
[2023-02-07 18:43:46,637][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 74.27% examples, 3814901 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:46,971][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5086629 effective words) took 1.3s, 3801696 effective words/s
[2023-02-07 18:43:47,976][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 74.27% examples, 3817805 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:48,290][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5086629 effective words) took 1.3s, 3860290 effective words/s
[2023-02-07 18:43:49,295][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 76.54% examples, 3932114 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:49,579][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5086629 effective words) took 1.3s, 3951413 effective words/s
[2023-02-07 18:43:50,583][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 76.14% examples, 3917393 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:50,878][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5086629 effective words) took 1.3s, 3919831 effective words/s
[2023-02-07 18:43:51,882][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 77.06% examples, 3954006 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:52,163][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5086629 effective words) took 1.3s, 3962199 effective words/s
[2023-02-07 18:43:53,165][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 76.14% examples, 3924125 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:53,450][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5086629 effective words) took 1.3s, 3954587 effective words/s
[2023-02-07 18:43:54,455][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 78.08% examples, 4000640 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:54,719][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5086629 effective words) took 1.3s, 4016871 effective words/s
[2023-02-07 18:43:55,723][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 78.17% examples, 4007228 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:55,988][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5086629 effective words) took 1.3s, 4010778 effective words/s
[2023-02-07 18:43:56,992][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 78.69% examples, 4036625 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:57,249][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5086629 effective words) took 1.3s, 4037639 effective words/s
[2023-02-07 18:43:58,252][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 78.08% examples, 4003014 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:58,512][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5086629 effective words) took 1.3s, 4031268 effective words/s
[2023-02-07 18:43:59,523][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 62.39% examples, 3212780 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:00,102][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5086629 effective words) took 1.6s, 3221376 effective words/s
[2023-02-07 18:44:00,102][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76299435 effective words) took 19.8s, 3847752 effective words/s', 'datetime': '2023-02-07T18:44:00.102691', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:44:00.102 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:44:02,211][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184312-fheij8t6/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:44:02.211344', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:44:02,212][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:44:02,293][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184312-fheij8t6/files/../tmp/embedding_model.pt
2023-02-07 18:44:02.293 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:44:03.504 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:44:03.949 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:44:12.467 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9642106677377627, 'test_mae': 0.7598488364208695, 'test_r2': -1.9955726107571485}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.78
wandb: percentage 0.0
wandb:   test_mae 0.75985
wandb:   test_mse 0.96421
wandb:    test_r2 -1.99557
wandb: 
wandb: üöÄ View run dazzling-sweep-16 at: https://wandb.ai/xiaoqiz/mof2vec/runs/fheij8t6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_184312-fheij8t6/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qgdqkfvt with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 581
wandb: 	model.gensim.alpha: 0.004655376765978245
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.26726130440401646
wandb: 	model.gensim.vector_size: 235
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.1288786081279964
wandb: 	model.sklearn.max_depth: 45
wandb: 	model.sklearn.min_child_weight: 0.09695613310692336
wandb: 	model.sklearn.n_estimators: 2599
wandb: 	model.sklearn.num_leaves: 298
wandb: 	model.sklearn.reg_alpha: 0.01473323108484502
wandb: 	model.sklearn.reg_lambda: 0.011574321270565974
wandb: 	model.sklearn.subsample: 0.3892945616877131
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184430-qgdqkfvt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-17
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/qgdqkfvt
2023-02-07 18:44:38.645 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 18:44:38.645 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 581 for sweep.
2023-02-07 18:44:38.646 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.004655376765978245 for sweep.
2023-02-07 18:44:38.646 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:44:38.646 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 18:44:38.647 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.26726130440401646 for sweep.
2023-02-07 18:44:38.647 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 235 for sweep.
2023-02-07 18:44:38.647 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 18:44:38.647 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.1288786081279964 for sweep.
2023-02-07 18:44:38.648 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 45 for sweep.
2023-02-07 18:44:38.648 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09695613310692336 for sweep.
2023-02-07 18:44:38.648 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2599 for sweep.
2023-02-07 18:44:38.648 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 298 for sweep.
2023-02-07 18:44:38.649 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.01473323108484502 for sweep.
2023-02-07 18:44:38.649 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.011574321270565974 for sweep.
2023-02-07 18:44:38.649 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3892945616877131 for sweep.
2023-02-07 18:44:38.649 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:44:38.657 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184430-qgdqkfvt/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 581, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 235, 'window': 11, 'min_count': 5, 'dm': 0, 'sample': 0.26726130440401646, 'workers': 4, 'alpha': 0.004655376765978245, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2599, 'max_depth': 45, 'num_leaves': 298, 'reg_alpha': 0.01473323108484502, 'reg_lambda': 0.011574321270565974, 'subsample': 0.3892945616877131, 'min_child_weight': 0.09695613310692336, 'n_jobs': 4, 'learning_rate': 0.1288786081279964}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 162.73it/s]  1%|          | 34/3257 [00:00<00:19, 166.26it/s]  2%|‚ñè         | 52/3257 [00:00<00:18, 172.41it/s]  2%|‚ñè         | 70/3257 [00:00<00:18, 168.72it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 175.78it/s]  3%|‚ñé         | 108/3257 [00:00<00:19, 164.94it/s]  4%|‚ñç         | 125/3257 [00:00<00:18, 165.36it/s]  4%|‚ñç         | 142/3257 [00:01<00:28, 109.59it/s]  5%|‚ñç         | 159/3257 [00:01<00:25, 121.65it/s]  5%|‚ñå         | 175/3257 [00:01<00:23, 128.75it/s]  6%|‚ñå         | 195/3257 [00:01<00:21, 145.79it/s]  7%|‚ñã         | 215/3257 [00:01<00:19, 158.56it/s]  7%|‚ñã         | 236/3257 [00:01<00:17, 168.45it/s]  8%|‚ñä         | 254/3257 [00:01<00:17, 169.84it/s]  8%|‚ñä         | 272/3257 [00:01<00:17, 171.32it/s]  9%|‚ñâ         | 294/3257 [00:01<00:16, 184.94it/s] 10%|‚ñâ         | 313/3257 [00:01<00:16, 175.44it/s] 10%|‚ñà         | 333/3257 [00:02<00:16, 181.76it/s] 11%|‚ñà         | 352/3257 [00:02<00:16, 176.84it/s] 11%|‚ñà‚ñè        | 371/3257 [00:02<00:16, 179.00it/s] 12%|‚ñà‚ñè        | 390/3257 [00:02<00:17, 162.71it/s] 13%|‚ñà‚ñé        | 410/3257 [00:02<00:16, 171.12it/s] 13%|‚ñà‚ñé        | 428/3257 [00:02<00:18, 151.78it/s] 14%|‚ñà‚ñé        | 444/3257 [00:02<00:18, 153.25it/s] 14%|‚ñà‚ñç        | 462/3257 [00:02<00:17, 159.99it/s] 15%|‚ñà‚ñç        | 479/3257 [00:03<00:17, 156.62it/s] 15%|‚ñà‚ñå        | 499/3257 [00:03<00:16, 166.82it/s] 16%|‚ñà‚ñå        | 518/3257 [00:03<00:15, 172.43it/s] 16%|‚ñà‚ñã        | 536/3257 [00:03<00:16, 169.47it/s] 17%|‚ñà‚ñã        | 554/3257 [00:03<00:15, 169.48it/s] 18%|‚ñà‚ñä        | 572/3257 [00:03<00:18, 145.72it/s] 18%|‚ñà‚ñä        | 590/3257 [00:03<00:17, 154.34it/s] 19%|‚ñà‚ñä        | 608/3257 [00:03<00:16, 160.83it/s] 19%|‚ñà‚ñâ        | 625/3257 [00:03<00:16, 156.99it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:04<00:15, 164.33it/s] 20%|‚ñà‚ñà        | 661/3257 [00:04<00:17, 152.40it/s] 21%|‚ñà‚ñà        | 681/3257 [00:04<00:15, 163.04it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:04<00:16, 154.60it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:15, 165.19it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:04<00:15, 158.98it/s] 23%|‚ñà‚ñà‚ñé       | 752/3257 [00:04<00:16, 153.12it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:04<00:15, 159.50it/s] 24%|‚ñà‚ñà‚ñç       | 787/3257 [00:04<00:16, 153.24it/s] 25%|‚ñà‚ñà‚ñç       | 805/3257 [00:05<00:15, 159.95it/s] 25%|‚ñà‚ñà‚ñå       | 822/3257 [00:05<00:15, 158.38it/s] 26%|‚ñà‚ñà‚ñå       | 838/3257 [00:05<00:15, 151.90it/s] 26%|‚ñà‚ñà‚ñå       | 854/3257 [00:05<00:16, 148.76it/s] 27%|‚ñà‚ñà‚ñã       | 872/3257 [00:05<00:15, 156.21it/s] 27%|‚ñà‚ñà‚ñã       | 888/3257 [00:05<00:15, 153.69it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:05<00:14, 161.79it/s] 28%|‚ñà‚ñà‚ñä       | 927/3257 [00:05<00:13, 171.50it/s] 29%|‚ñà‚ñà‚ñâ       | 945/3257 [00:05<00:13, 167.64it/s] 30%|‚ñà‚ñà‚ñâ       | 962/3257 [00:06<00:13, 167.12it/s] 30%|‚ñà‚ñà‚ñà       | 979/3257 [00:06<00:14, 162.63it/s] 31%|‚ñà‚ñà‚ñà       | 996/3257 [00:06<00:14, 155.78it/s] 31%|‚ñà‚ñà‚ñà       | 1013/3257 [00:06<00:14, 158.30it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1029/3257 [00:06<00:14, 157.95it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1045/3257 [00:06<00:14, 154.76it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1061/3257 [00:06<00:14, 156.12it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:13, 159.07it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1098/3257 [00:06<00:13, 162.65it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1116/3257 [00:06<00:12, 166.88it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1133/3257 [00:07<00:13, 156.72it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1149/3257 [00:07<00:13, 153.55it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:12, 165.32it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:07<00:13, 157.50it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1203/3257 [00:07<00:14, 145.56it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:07<00:13, 148.92it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:07<00:12, 166.32it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:07<00:12, 161.10it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:08<00:12, 160.62it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:08<00:12, 154.90it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:08<00:12, 157.15it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:08<00:11, 162.21it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:08<00:11, 165.75it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1363/3257 [00:08<00:11, 165.26it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1380/3257 [00:08<00:11, 159.06it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1396/3257 [00:08<00:11, 157.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1417/3257 [00:08<00:10, 170.76it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1435/3257 [00:08<00:10, 171.88it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1461/3257 [00:09<00:09, 195.99it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1484/3257 [00:09<00:08, 203.27it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:09<00:07, 220.69it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1534/3257 [00:09<00:08, 202.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:09<00:12, 133.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1576/3257 [00:09<00:11, 148.00it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1601/3257 [00:09<00:09, 169.74it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1623/3257 [00:10<00:09, 180.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1644/3257 [00:10<00:08, 185.99it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1665/3257 [00:10<00:08, 185.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1685/3257 [00:10<00:08, 186.13it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:10<00:07, 198.09it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:10<00:08, 188.59it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1749/3257 [00:10<00:07, 189.50it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1769/3257 [00:10<00:07, 192.33it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:10<00:07, 201.32it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1813/3257 [00:11<00:07, 189.71it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1833/3257 [00:11<00:07, 191.57it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1856/3257 [00:11<00:06, 200.77it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1880/3257 [00:11<00:06, 208.92it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1902/3257 [00:11<00:06, 207.09it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1923/3257 [00:11<00:06, 202.98it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1951/3257 [00:11<00:05, 223.17it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1975/3257 [00:11<00:05, 226.94it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1998/3257 [00:11<00:05, 219.80it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2021/3257 [00:11<00:05, 221.86it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2044/3257 [00:12<00:05, 210.32it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2066/3257 [00:12<00:06, 193.79it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2086/3257 [00:12<00:05, 195.17it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2107/3257 [00:12<00:05, 197.41it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2127/3257 [00:12<00:06, 182.97it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2146/3257 [00:12<00:06, 179.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:12<00:05, 190.71it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2189/3257 [00:12<00:05, 190.32it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:12<00:05, 189.61it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2231/3257 [00:13<00:05, 198.03it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2251/3257 [00:13<00:05, 193.59it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2271/3257 [00:13<00:05, 185.45it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2294/3257 [00:13<00:04, 197.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2314/3257 [00:13<00:04, 197.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2339/3257 [00:13<00:04, 210.73it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2363/3257 [00:13<00:04, 217.22it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2386/3257 [00:13<00:03, 219.84it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2409/3257 [00:13<00:04, 205.78it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2430/3257 [00:14<00:04, 202.85it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2451/3257 [00:14<00:04, 191.39it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:14<00:03, 206.48it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2501/3257 [00:14<00:03, 217.11it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2523/3257 [00:14<00:03, 217.12it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2545/3257 [00:14<00:03, 215.64it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2567/3257 [00:14<00:03, 202.88it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2588/3257 [00:14<00:03, 193.72it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2612/3257 [00:14<00:03, 205.70it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:15<00:02, 209.51it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:15<00:02, 202.54it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2677/3257 [00:15<00:02, 197.66it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2697/3257 [00:15<00:02, 195.29it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2717/3257 [00:15<00:03, 179.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2744/3257 [00:15<00:02, 201.47it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2766/3257 [00:15<00:02, 204.60it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2788/3257 [00:15<00:02, 208.15it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2810/3257 [00:15<00:02, 207.24it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2831/3257 [00:16<00:02, 193.29it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2854/3257 [00:16<00:02, 200.61it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2882/3257 [00:16<00:01, 222.04it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2905/3257 [00:16<00:01, 202.32it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:16<00:01, 209.66it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:16<00:02, 108.64it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2972/3257 [00:17<00:02, 126.63it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2990/3257 [00:17<00:01, 134.54it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3014/3257 [00:17<00:01, 156.68it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3037/3257 [00:17<00:01, 172.56it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3060/3257 [00:17<00:01, 186.58it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:17<00:00, 192.72it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3105/3257 [00:17<00:00, 202.38it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3128/3257 [00:17<00:00, 207.20it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3150/3257 [00:17<00:00, 192.15it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3171/3257 [00:17<00:00, 194.90it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3192/3257 [00:18<00:00, 193.94it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3212/3257 [00:18<00:00, 190.17it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3232/3257 [00:18<00:00, 190.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:18<00:00, 190.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 176.62it/s]
2023-02-07 18:44:57.769 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:44:57,770][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d235,n5,mc5,s0.267261,t4>', 'datetime': '2023-02-07T18:44:57.770406', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:44:57,770][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:44:57,770][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:44:58,246][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 18:44:58,247][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:44:58,296][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 16108 unique words (50.65% of original 31803, drops 15695)', 'datetime': '2023-02-07T18:44:58.296302', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:44:58,296][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5056108 word corpus (99.23% of original 5095118, drops 39010)', 'datetime': '2023-02-07T18:44:58.296700', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:44:58,352][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 18:44:58,353][gensim.models.word2vec][INFO] - sample=0.267261 downsamples 0 most-common words
[2023-02-07 18:44:58,353][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5056108 word corpus (100.0%% of prior 5056108)', 'datetime': '2023-02-07T18:44:58.353642', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:44:58,447][gensim.models.word2vec][INFO] - estimated required memory for 16108 words and 235 dimensions: 42050020 bytes
[2023-02-07 18:44:58,448][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:44:58,467][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 16108 vocabulary and 235 features, using sg=1 hs=0 sample=0.26726130440401646 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T18:44:58.467320', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:44:59,472][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 39.30% examples, 2031692 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:00,481][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 73.35% examples, 1867839 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:01,220][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5048130 effective words) took 2.8s, 1834971 effective words/s
[2023-02-07 18:45:02,225][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 50.14% examples, 2567311 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:03,154][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5048130 effective words) took 1.9s, 2613442 effective words/s
[2023-02-07 18:45:04,156][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 51.70% examples, 2669971 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:05,064][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5048130 effective words) took 1.9s, 2644773 effective words/s
[2023-02-07 18:45:06,072][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 51.21% examples, 2626131 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:07,036][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5048130 effective words) took 2.0s, 2561568 effective words/s
[2023-02-07 18:45:08,041][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 45.13% examples, 2319609 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:45:09,048][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 91.40% examples, 2312654 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:09,217][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5048130 effective words) took 2.2s, 2318252 effective words/s
[2023-02-07 18:45:10,221][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 44.89% examples, 2312906 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:11,226][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 91.80% examples, 2329811 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:11,383][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5048130 effective words) took 2.2s, 2334459 effective words/s
[2023-02-07 18:45:12,387][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 44.73% examples, 2304517 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:13,389][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 90.67% examples, 2301979 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:45:13,570][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5048130 effective words) took 2.2s, 2311366 effective words/s
[2023-02-07 18:45:14,572][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 45.29% examples, 2332952 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:15,573][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 92.51% examples, 2348464 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:15,717][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5048130 effective words) took 2.1s, 2353770 effective words/s
[2023-02-07 18:45:16,723][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 33.47% examples, 1702906 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:17,724][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 67.21% examples, 1728934 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:18,416][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5048130 effective words) took 2.7s, 1871505 effective words/s
[2023-02-07 18:45:19,422][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 46.27% examples, 2364493 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:20,380][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5048130 effective words) took 2.0s, 2573233 effective words/s
[2023-02-07 18:45:21,385][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 59.47% examples, 3052488 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:22,109][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5048130 effective words) took 1.7s, 2921663 effective words/s
[2023-02-07 18:45:23,111][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 50.14% examples, 2571664 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:45:24,019][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5048130 effective words) took 1.9s, 2643793 effective words/s
[2023-02-07 18:45:25,026][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 50.63% examples, 2597900 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:25,925][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5048130 effective words) took 1.9s, 2650708 effective words/s
[2023-02-07 18:45:26,930][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 52.66% examples, 2717398 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:27,776][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5048130 effective words) took 1.8s, 2731073 effective words/s
[2023-02-07 18:45:28,787][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 51.89% examples, 2654843 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:45:29,678][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5048130 effective words) took 1.9s, 2655007 effective words/s
[2023-02-07 18:45:29,679][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75721950 effective words) took 31.2s, 2426083 effective words/s', 'datetime': '2023-02-07T18:45:29.679378', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:45:29.679 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:45:32,497][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184430-qgdqkfvt/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:45:32.496912', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:45:32,498][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:45:32,554][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184430-qgdqkfvt/files/../tmp/embedding_model.pt
2023-02-07 18:45:32.555 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:45:34.175 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:45:34.774 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:45:39.709 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.022817650815106, 'test_mae': 0.7799266811254566, 'test_r2': -2.0585107309686133}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.78
wandb: percentage 0.49351
wandb:   test_mae 0.77993
wandb:   test_mse 1.02282
wandb:    test_r2 -2.05851
wandb: 
wandb: üöÄ View run stellar-sweep-17 at: https://wandb.ai/xiaoqiz/mof2vec/runs/qgdqkfvt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_184430-qgdqkfvt/logs
wandb: Agent Starting Run: 8wim9zch with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 687
wandb: 	model.gensim.alpha: 0.008045463829353361
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.2012328484244388
wandb: 	model.gensim.vector_size: 287
wandb: 	model.gensim.window: 1
wandb: 	model.sklearn.learning_rate: 0.4386558157708853
wandb: 	model.sklearn.max_depth: 50
wandb: 	model.sklearn.min_child_weight: 0.09046994468555994
wandb: 	model.sklearn.n_estimators: 3014
wandb: 	model.sklearn.num_leaves: 457
wandb: 	model.sklearn.reg_alpha: 0.002812214208368184
wandb: 	model.sklearn.reg_lambda: 0.0071274180427308
wandb: 	model.sklearn.subsample: 0.2134066565175636
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184549-8wim9zch
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-18
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/8wim9zch
2023-02-07 18:45:57.748 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 18:45:57.749 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 687 for sweep.
2023-02-07 18:45:57.749 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.008045463829353361 for sweep.
2023-02-07 18:45:57.749 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:45:57.749 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 18:45:57.750 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2012328484244388 for sweep.
2023-02-07 18:45:57.750 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 287 for sweep.
2023-02-07 18:45:57.750 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 1 for sweep.
2023-02-07 18:45:57.750 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.4386558157708853 for sweep.
2023-02-07 18:45:57.751 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 50 for sweep.
2023-02-07 18:45:57.751 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09046994468555994 for sweep.
2023-02-07 18:45:57.751 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3014 for sweep.
2023-02-07 18:45:57.751 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 457 for sweep.
2023-02-07 18:45:57.751 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.002812214208368184 for sweep.
2023-02-07 18:45:57.752 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0071274180427308 for sweep.
2023-02-07 18:45:57.752 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2134066565175636 for sweep.
2023-02-07 18:45:57.752 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:45:57.761 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184549-8wim9zch/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 687, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 287, 'window': 1, 'min_count': 5, 'dm': 0, 'sample': 0.2012328484244388, 'workers': 4, 'alpha': 0.008045463829353361, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3014, 'max_depth': 50, 'num_leaves': 457, 'reg_alpha': 0.002812214208368184, 'reg_lambda': 0.0071274180427308, 'subsample': 0.2134066565175636, 'min_child_weight': 0.09046994468555994, 'n_jobs': 4, 'learning_rate': 0.4386558157708853}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 22/3257 [00:00<00:14, 219.79it/s]  1%|‚ñè         | 45/3257 [00:00<00:14, 225.43it/s]  2%|‚ñè         | 68/3257 [00:00<00:14, 227.37it/s]  3%|‚ñé         | 95/3257 [00:00<00:13, 241.41it/s]  4%|‚ñé         | 120/3257 [00:00<00:13, 239.47it/s]  5%|‚ñç         | 147/3257 [00:00<00:12, 247.83it/s]  5%|‚ñå         | 172/3257 [00:00<00:12, 241.49it/s]  6%|‚ñå         | 197/3257 [00:00<00:12, 236.86it/s]  7%|‚ñã         | 226/3257 [00:00<00:11, 252.74it/s]  8%|‚ñä         | 252/3257 [00:01<00:11, 251.72it/s]  9%|‚ñä         | 281/3257 [00:01<00:11, 262.71it/s]  9%|‚ñâ         | 308/3257 [00:01<00:11, 252.77it/s] 10%|‚ñà         | 335/3257 [00:01<00:11, 255.36it/s] 11%|‚ñà         | 361/3257 [00:01<00:11, 254.77it/s] 12%|‚ñà‚ñè        | 387/3257 [00:01<00:12, 237.29it/s] 13%|‚ñà‚ñé        | 414/3257 [00:01<00:11, 245.57it/s] 13%|‚ñà‚ñé        | 439/3257 [00:01<00:12, 222.58it/s] 14%|‚ñà‚ñç        | 466/3257 [00:01<00:11, 234.53it/s] 15%|‚ñà‚ñå        | 490/3257 [00:02<00:11, 232.53it/s] 16%|‚ñà‚ñå        | 517/3257 [00:02<00:11, 241.75it/s] 17%|‚ñà‚ñã        | 543/3257 [00:02<00:11, 246.17it/s] 17%|‚ñà‚ñã        | 568/3257 [00:02<00:11, 234.02it/s] 18%|‚ñà‚ñä        | 592/3257 [00:02<00:11, 229.98it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:02<00:11, 235.72it/s] 20%|‚ñà‚ñâ        | 646/3257 [00:02<00:10, 240.91it/s] 21%|‚ñà‚ñà        | 671/3257 [00:02<00:10, 237.81it/s] 21%|‚ñà‚ñà‚ñè       | 695/3257 [00:02<00:11, 227.37it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:03<00:10, 231.54it/s] 23%|‚ñà‚ñà‚ñé       | 744/3257 [00:03<00:11, 225.98it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:03<00:10, 234.75it/s] 24%|‚ñà‚ñà‚ñç       | 794/3257 [00:03<00:10, 229.65it/s] 25%|‚ñà‚ñà‚ñå       | 819/3257 [00:03<00:10, 233.35it/s] 26%|‚ñà‚ñà‚ñå       | 843/3257 [00:03<00:10, 220.59it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:03<00:10, 224.72it/s] 27%|‚ñà‚ñà‚ñã       | 891/3257 [00:03<00:10, 221.32it/s] 28%|‚ñà‚ñà‚ñä       | 916/3257 [00:03<00:10, 226.54it/s] 29%|‚ñà‚ñà‚ñâ       | 943/3257 [00:03<00:09, 237.80it/s] 30%|‚ñà‚ñà‚ñâ       | 967/3257 [00:04<00:14, 154.64it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:04<00:13, 165.81it/s] 31%|‚ñà‚ñà‚ñà       | 1008/3257 [00:04<00:13, 172.34it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1032/3257 [00:04<00:11, 188.61it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1053/3257 [00:04<00:11, 191.61it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:04<00:10, 200.98it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:04<00:10, 210.97it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1127/3257 [00:05<00:10, 211.92it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1149/3257 [00:05<00:09, 212.48it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:05<00:09, 225.44it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1198/3257 [00:05<00:09, 216.73it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1220/3257 [00:05<00:09, 211.48it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:05<00:08, 226.27it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:05<00:08, 229.96it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1296/3257 [00:05<00:09, 216.63it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:05<00:08, 222.68it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1348/3257 [00:05<00:08, 235.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1372/3257 [00:06<00:08, 222.14it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1395/3257 [00:06<00:08, 223.87it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:06<00:07, 237.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1449/3257 [00:06<00:07, 243.35it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:06<00:07, 252.11it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1506/3257 [00:06<00:06, 261.67it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1533/3257 [00:06<00:07, 241.71it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1558/3257 [00:06<00:07, 234.35it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1582/3257 [00:06<00:07, 232.67it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1610/3257 [00:07<00:06, 244.85it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:07<00:06, 236.02it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1659/3257 [00:07<00:06, 230.74it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1683/3257 [00:07<00:07, 223.41it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:07<00:06, 227.48it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:07<00:06, 220.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1754/3257 [00:07<00:06, 220.94it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1780/3257 [00:07<00:06, 229.94it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1805/3257 [00:07<00:06, 232.68it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1829/3257 [00:08<00:06, 229.18it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1856/3257 [00:08<00:05, 239.69it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1883/3257 [00:08<00:05, 245.35it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1910/3257 [00:08<00:05, 251.13it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:08<00:05, 253.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1969/3257 [00:08<00:04, 270.94it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1997/3257 [00:08<00:04, 258.51it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2024/3257 [00:08<00:04, 251.69it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2050/3257 [00:08<00:05, 239.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2075/3257 [00:09<00:04, 239.98it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:09<00:04, 233.00it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2124/3257 [00:09<00:04, 228.84it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2147/3257 [00:09<00:04, 222.40it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2177/3257 [00:09<00:04, 239.77it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2202/3257 [00:09<00:04, 238.46it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2226/3257 [00:09<00:06, 147.44it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2250/3257 [00:09<00:06, 165.48it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2271/3257 [00:10<00:05, 175.29it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2298/3257 [00:10<00:04, 197.89it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2321/3257 [00:10<00:04, 201.17it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2344/3257 [00:10<00:04, 207.45it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2367/3257 [00:10<00:04, 209.90it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2390/3257 [00:10<00:04, 213.28it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2413/3257 [00:10<00:04, 197.16it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2434/3257 [00:10<00:04, 188.09it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2454/3257 [00:10<00:04, 189.68it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2478/3257 [00:11<00:03, 200.98it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2502/3257 [00:11<00:03, 209.85it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:11<00:03, 211.07it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2546/3257 [00:11<00:03, 212.05it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2568/3257 [00:11<00:03, 198.48it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2589/3257 [00:11<00:03, 192.36it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:11<00:03, 205.57it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2636/3257 [00:11<00:02, 209.50it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2658/3257 [00:11<00:02, 199.86it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2680/3257 [00:12<00:02, 204.10it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2701/3257 [00:12<00:02, 191.38it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2721/3257 [00:12<00:02, 193.28it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2748/3257 [00:12<00:02, 212.62it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2770/3257 [00:12<00:02, 202.42it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2794/3257 [00:12<00:02, 211.77it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2816/3257 [00:12<00:02, 206.56it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:12<00:02, 196.71it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2861/3257 [00:12<00:01, 208.24it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:13<00:01, 218.82it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2909/3257 [00:13<00:01, 208.81it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2931/3257 [00:13<00:01, 209.59it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2953/3257 [00:13<00:01, 203.30it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:13<00:01, 204.17it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2997/3257 [00:13<00:01, 205.41it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:13<00:01, 205.44it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3043/3257 [00:13<00:00, 216.50it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3069/3257 [00:13<00:00, 226.87it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3092/3257 [00:14<00:00, 221.39it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:14<00:00, 230.35it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3142/3257 [00:14<00:00, 221.92it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:14<00:00, 210.31it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3187/3257 [00:14<00:00, 202.77it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3208/3257 [00:14<00:00, 200.86it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3229/3257 [00:14<00:00, 201.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:14<00:00, 208.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:14<00:00, 219.82it/s]
2023-02-07 18:46:13.178 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:46:13,180][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d287,n5,mc5,s0.201233,t4>', 'datetime': '2023-02-07T18:46:13.180629', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:46:13,181][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:46:13,181][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:46:13,548][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 18:46:13,548][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:46:13,571][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 6948 unique words (53.20% of original 13061, drops 6113)', 'datetime': '2023-02-07T18:46:13.571565', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:46:13,572][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 3624596 word corpus (99.59% of original 3639370, drops 14774)', 'datetime': '2023-02-07T18:46:13.572066', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:46:13,596][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 18:46:13,597][gensim.models.word2vec][INFO] - sample=0.201233 downsamples 0 most-common words
[2023-02-07 18:46:13,597][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3624596 word corpus (100.0%% of prior 3624596)', 'datetime': '2023-02-07T18:46:13.597756', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:46:13,641][gensim.models.word2vec][INFO] - estimated required memory for 6948 words and 287 dimensions: 23817044 bytes
[2023-02-07 18:46:13,642][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:46:13,655][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 6948 vocabulary and 287 features, using sg=1 hs=0 sample=0.2012328484244388 negative=5 window=1 shrink_windows=True', 'datetime': '2023-02-07T18:46:13.655861', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:46:14,659][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 49.62% examples, 1832241 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:15,588][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3627853 effective words) took 1.9s, 1879962 effective words/s
[2023-02-07 18:46:16,595][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 58.89% examples, 2177092 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:17,249][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3627853 effective words) took 1.7s, 2186700 effective words/s
[2023-02-07 18:46:18,252][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 58.46% examples, 2167974 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:18,929][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3627853 effective words) took 1.7s, 2161905 effective words/s
[2023-02-07 18:46:19,934][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 58.21% examples, 2153775 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:20,627][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3627853 effective words) took 1.7s, 2138695 effective words/s
[2023-02-07 18:46:21,631][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 64.45% examples, 2380733 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:22,101][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3627853 effective words) took 1.5s, 2465189 effective words/s
[2023-02-07 18:46:23,113][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 69.05% examples, 2531903 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:23,551][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3627853 effective words) took 1.4s, 2504029 effective words/s
[2023-02-07 18:46:24,558][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 61.59% examples, 2259906 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:25,142][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3627853 effective words) took 1.6s, 2281779 effective words/s
[2023-02-07 18:46:26,151][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 62.82% examples, 2298656 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:26,700][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3627853 effective words) took 1.6s, 2330694 effective words/s
[2023-02-07 18:46:27,703][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 63.37% examples, 2339783 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:28,259][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3627853 effective words) took 1.6s, 2330024 effective words/s
[2023-02-07 18:46:29,262][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 62.94% examples, 2321278 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:29,834][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3627853 effective words) took 1.6s, 2306093 effective words/s
[2023-02-07 18:46:30,844][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 49.31% examples, 1810978 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:31,834][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3627853 effective words) took 2.0s, 1815058 effective words/s
[2023-02-07 18:46:32,838][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 65.09% examples, 2405002 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:33,353][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3627853 effective words) took 1.5s, 2390480 effective words/s
[2023-02-07 18:46:34,357][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 64.35% examples, 2374770 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:34,881][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3627853 effective words) took 1.5s, 2377202 effective words/s
[2023-02-07 18:46:35,885][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 64.75% examples, 2388878 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:36,396][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3627853 effective words) took 1.5s, 2398121 effective words/s
[2023-02-07 18:46:37,398][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 65.92% examples, 2446316 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:37,891][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3627853 effective words) took 1.5s, 2428086 effective words/s
[2023-02-07 18:46:37,892][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54417795 effective words) took 24.2s, 2245324 effective words/s', 'datetime': '2023-02-07T18:46:37.892386', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:46:37.892 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:46:40,650][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184549-8wim9zch/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:46:40.649962', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:46:40,650][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:46:40,687][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184549-8wim9zch/files/../tmp/embedding_model.pt
2023-02-07 18:46:40.687 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:46:42.650 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:46:43.366 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:46:52.208 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.8922861083065388, 'test_mae': 0.7136924983990705, 'test_r2': -1.7829880036150048}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.72
wandb: percentage 0.46803
wandb:   test_mae 0.71369
wandb:   test_mse 0.89229
wandb:    test_r2 -1.78299
wandb: 
wandb: üöÄ View run eternal-sweep-18 at: https://wandb.ai/xiaoqiz/mof2vec/runs/8wim9zch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_184549-8wim9zch/logs
wandb: Agent Starting Run: sasaodj6 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 520
wandb: 	model.gensim.alpha: 0.023238971367929788
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 4
wandb: 	model.gensim.sample: 0.23720468290070784
wandb: 	model.gensim.vector_size: 219
wandb: 	model.gensim.window: 4
wandb: 	model.sklearn.learning_rate: 0.01755055912446437
wandb: 	model.sklearn.max_depth: 53
wandb: 	model.sklearn.min_child_weight: 0.09731543214362603
wandb: 	model.sklearn.n_estimators: 2858
wandb: 	model.sklearn.num_leaves: 352
wandb: 	model.sklearn.reg_alpha: 0.006695181689934806
wandb: 	model.sklearn.reg_lambda: 0.011855450764984206
wandb: 	model.sklearn.subsample: 0.52354767195189
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184703-sasaodj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/sasaodj6
2023-02-07 18:47:12.756 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 18:47:12.757 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 520 for sweep.
2023-02-07 18:47:12.757 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.023238971367929788 for sweep.
2023-02-07 18:47:12.757 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:47:12.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 4 for sweep.
2023-02-07 18:47:12.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.23720468290070784 for sweep.
2023-02-07 18:47:12.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 219 for sweep.
2023-02-07 18:47:12.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 4 for sweep.
2023-02-07 18:47:12.759 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.01755055912446437 for sweep.
2023-02-07 18:47:12.759 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 53 for sweep.
2023-02-07 18:47:12.759 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09731543214362603 for sweep.
2023-02-07 18:47:12.759 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2858 for sweep.
2023-02-07 18:47:12.760 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 352 for sweep.
2023-02-07 18:47:12.760 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.006695181689934806 for sweep.
2023-02-07 18:47:12.760 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.011855450764984206 for sweep.
2023-02-07 18:47:12.760 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.52354767195189 for sweep.
2023-02-07 18:47:12.761 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:47:12.764 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184703-sasaodj6/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 520, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 219, 'window': 4, 'min_count': 4, 'dm': 0, 'sample': 0.23720468290070784, 'workers': 4, 'alpha': 0.023238971367929788, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2858, 'max_depth': 53, 'num_leaves': 352, 'reg_alpha': 0.006695181689934806, 'reg_lambda': 0.011855450764984206, 'subsample': 0.52354767195189, 'min_child_weight': 0.09731543214362603, 'n_jobs': 4, 'learning_rate': 0.01755055912446437}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 166.22it/s]  1%|          | 35/3257 [00:00<00:18, 171.81it/s]  2%|‚ñè         | 53/3257 [00:00<00:19, 165.63it/s]  2%|‚ñè         | 72/3257 [00:00<00:18, 172.17it/s]  3%|‚ñé         | 91/3257 [00:00<00:17, 177.90it/s]  3%|‚ñé         | 109/3257 [00:00<00:18, 166.38it/s]  4%|‚ñç         | 127/3257 [00:00<00:18, 169.78it/s]  4%|‚ñç         | 146/3257 [00:00<00:17, 175.79it/s]  5%|‚ñå         | 164/3257 [00:00<00:18, 166.35it/s]  6%|‚ñå         | 181/3257 [00:01<00:18, 166.52it/s]  6%|‚ñå         | 201/3257 [00:01<00:18, 167.98it/s]  7%|‚ñã         | 221/3257 [00:01<00:17, 176.33it/s]  7%|‚ñã         | 242/3257 [00:01<00:16, 184.99it/s]  8%|‚ñä         | 261/3257 [00:01<00:27, 109.35it/s]  9%|‚ñâ         | 285/3257 [00:01<00:22, 133.71it/s]  9%|‚ñâ         | 303/3257 [00:01<00:21, 140.58it/s] 10%|‚ñâ         | 324/3257 [00:02<00:18, 155.24it/s] 11%|‚ñà         | 342/3257 [00:02<00:18, 156.64it/s] 11%|‚ñà         | 362/3257 [00:02<00:17, 165.08it/s] 12%|‚ñà‚ñè        | 380/3257 [00:02<00:17, 163.21it/s] 12%|‚ñà‚ñè        | 398/3257 [00:02<00:17, 163.61it/s] 13%|‚ñà‚ñé        | 418/3257 [00:02<00:16, 172.35it/s] 13%|‚ñà‚ñé        | 436/3257 [00:02<00:19, 147.55it/s] 14%|‚ñà‚ñç        | 454/3257 [00:02<00:18, 155.50it/s] 15%|‚ñà‚ñç        | 473/3257 [00:02<00:17, 163.15it/s] 15%|‚ñà‚ñå        | 490/3257 [00:03<00:17, 162.64it/s] 16%|‚ñà‚ñå        | 511/3257 [00:03<00:15, 174.06it/s] 16%|‚ñà‚ñå        | 529/3257 [00:03<00:16, 168.99it/s] 17%|‚ñà‚ñã        | 547/3257 [00:03<00:16, 168.52it/s] 17%|‚ñà‚ñã        | 565/3257 [00:03<00:16, 159.18it/s] 18%|‚ñà‚ñä        | 582/3257 [00:03<00:17, 150.32it/s] 19%|‚ñà‚ñä        | 603/3257 [00:03<00:16, 165.76it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:16, 162.84it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:03<00:15, 171.29it/s] 20%|‚ñà‚ñà        | 658/3257 [00:04<00:16, 158.18it/s] 21%|‚ñà‚ñà        | 677/3257 [00:04<00:15, 165.23it/s] 21%|‚ñà‚ñà‚ñè       | 694/3257 [00:04<00:15, 163.53it/s] 22%|‚ñà‚ñà‚ñè       | 713/3257 [00:04<00:15, 168.52it/s] 22%|‚ñà‚ñà‚ñè       | 731/3257 [00:04<00:15, 158.63it/s] 23%|‚ñà‚ñà‚ñé       | 748/3257 [00:04<00:15, 158.62it/s] 24%|‚ñà‚ñà‚ñé       | 768/3257 [00:04<00:14, 169.19it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:04<00:15, 161.34it/s] 25%|‚ñà‚ñà‚ñç       | 805/3257 [00:04<00:14, 168.39it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:05<00:14, 162.28it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:05<00:14, 163.45it/s] 26%|‚ñà‚ñà‚ñã       | 857/3257 [00:05<00:14, 160.70it/s] 27%|‚ñà‚ñà‚ñã       | 874/3257 [00:05<00:14, 162.77it/s] 27%|‚ñà‚ñà‚ñã       | 891/3257 [00:05<00:14, 160.42it/s] 28%|‚ñà‚ñà‚ñä       | 912/3257 [00:05<00:13, 171.19it/s] 29%|‚ñà‚ñà‚ñä       | 930/3257 [00:05<00:13, 171.07it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:05<00:14, 163.37it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:05<00:13, 167.60it/s] 30%|‚ñà‚ñà‚ñà       | 983/3257 [00:06<00:13, 163.08it/s] 31%|‚ñà‚ñà‚ñà       | 1000/3257 [00:06<00:13, 161.74it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1018/3257 [00:06<00:13, 166.08it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1036/3257 [00:06<00:13, 169.03it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1055/3257 [00:06<00:12, 173.70it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:11, 183.02it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1103/3257 [00:06<00:11, 194.79it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:06<00:10, 195.82it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1145/3257 [00:06<00:10, 196.32it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:10, 205.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:07<00:10, 188.52it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1211/3257 [00:07<00:10, 189.47it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1238/3257 [00:07<00:09, 209.06it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1261/3257 [00:07<00:09, 214.05it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1283/3257 [00:07<00:09, 206.25it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1305/3257 [00:07<00:09, 209.11it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1329/3257 [00:07<00:08, 215.83it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1351/3257 [00:07<00:08, 214.78it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1373/3257 [00:08<00:08, 212.54it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1395/3257 [00:08<00:13, 135.23it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:08<00:11, 161.25it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1448/3257 [00:08<00:10, 179.90it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:08<00:08, 198.43it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1501/3257 [00:08<00:08, 216.45it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1525/3257 [00:08<00:08, 208.63it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1548/3257 [00:08<00:08, 205.32it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1571/3257 [00:09<00:07, 211.31it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:09<00:07, 213.93it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1618/3257 [00:09<00:07, 221.12it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1641/3257 [00:09<00:07, 216.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1663/3257 [00:09<00:07, 206.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1684/3257 [00:09<00:07, 205.64it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:09<00:07, 212.99it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1730/3257 [00:09<00:07, 205.17it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1751/3257 [00:09<00:07, 204.31it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1776/3257 [00:10<00:06, 213.74it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1800/3257 [00:10<00:06, 218.44it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1822/3257 [00:10<00:06, 218.66it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1844/3257 [00:10<00:06, 215.26it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:10<00:06, 217.92it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1891/3257 [00:10<00:06, 218.16it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:10<00:06, 221.74it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1944/3257 [00:10<00:05, 238.28it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1972/3257 [00:10<00:05, 249.89it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1998/3257 [00:11<00:05, 222.72it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2021/3257 [00:11<00:05, 213.06it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2043/3257 [00:11<00:06, 200.82it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2064/3257 [00:11<00:06, 191.68it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:11<00:06, 191.96it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2107/3257 [00:11<00:05, 197.45it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2127/3257 [00:11<00:06, 187.23it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2146/3257 [00:11<00:06, 180.79it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:11<00:05, 193.57it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2189/3257 [00:12<00:05, 195.03it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:12<00:05, 194.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2231/3257 [00:12<00:05, 201.04it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2252/3257 [00:12<00:05, 196.56it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2272/3257 [00:12<00:05, 182.99it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2297/3257 [00:12<00:04, 198.19it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2321/3257 [00:12<00:04, 207.71it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2348/3257 [00:12<00:04, 225.29it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2372/3257 [00:12<00:03, 227.04it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:13<00:03, 235.78it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2423/3257 [00:13<00:03, 226.25it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2446/3257 [00:13<00:03, 217.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2471/3257 [00:13<00:03, 226.02it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2494/3257 [00:13<00:03, 224.46it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2520/3257 [00:13<00:03, 233.93it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2545/3257 [00:13<00:03, 236.65it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2569/3257 [00:13<00:03, 215.99it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2591/3257 [00:13<00:03, 213.25it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2620/3257 [00:13<00:02, 233.68it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2644/3257 [00:14<00:02, 225.48it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2667/3257 [00:14<00:02, 221.87it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2691/3257 [00:14<00:02, 224.42it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2714/3257 [00:14<00:02, 201.83it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2738/3257 [00:14<00:02, 211.48it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:14<00:02, 209.82it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2783/3257 [00:14<00:02, 212.54it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:14<00:02, 213.92it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2829/3257 [00:15<00:02, 202.05it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:15<00:01, 210.07it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2883/3257 [00:15<00:01, 234.08it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:15<00:03, 108.34it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2929/3257 [00:15<00:02, 125.38it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2949/3257 [00:15<00:02, 135.08it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2972/3257 [00:16<00:01, 153.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2992/3257 [00:16<00:01, 160.98it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:16<00:01, 178.20it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3041/3257 [00:16<00:01, 196.22it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3068/3257 [00:16<00:00, 214.38it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3092/3257 [00:16<00:00, 214.40it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3120/3257 [00:16<00:00, 231.48it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3145/3257 [00:16<00:00, 216.88it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3168/3257 [00:16<00:00, 217.25it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3191/3257 [00:17<00:00, 214.40it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:17<00:00, 207.00it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:17<00:00, 219.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 188.01it/s]
2023-02-07 18:47:30.763 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:47:30,765][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d219,n5,mc4,s0.237205,t4>', 'datetime': '2023-02-07T18:47:30.765017', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:47:30,765][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:47:30,765][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:47:31,222][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 18:47:31,223][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:47:31,279][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 retains 21730 unique words (68.33% of original 31803, drops 10073)', 'datetime': '2023-02-07T18:47:31.279045', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:47:31,279][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 leaves 5078596 word corpus (99.68% of original 5095118, drops 16522)', 'datetime': '2023-02-07T18:47:31.279290', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:47:31,351][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 18:47:31,352][gensim.models.word2vec][INFO] - sample=0.237205 downsamples 0 most-common words
[2023-02-07 18:47:31,352][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5078596 word corpus (100.0%% of prior 5078596)', 'datetime': '2023-02-07T18:47:31.352633', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:47:31,480][gensim.models.word2vec][INFO] - estimated required memory for 21730 words and 219 dimensions: 52440492 bytes
[2023-02-07 18:47:31,480][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:47:31,502][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 21730 vocabulary and 219 features, using sg=1 hs=0 sample=0.23720468290070784 negative=5 window=4 shrink_windows=True', 'datetime': '2023-02-07T18:47:31.502843', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:47:32,509][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 33.59% examples, 1721042 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:33,512][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 77.10% examples, 1968356 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:34,008][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5070569 effective words) took 2.5s, 2025459 effective words/s
[2023-02-07 18:47:35,015][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 45.69% examples, 2349110 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:36,016][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 91.50% examples, 2329953 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:47:36,187][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5070569 effective words) took 2.2s, 2328436 effective words/s
[2023-02-07 18:47:37,191][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 45.96% examples, 2368125 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:38,193][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 94.75% examples, 2404568 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:38,293][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5070569 effective words) took 2.1s, 2410698 effective words/s
[2023-02-07 18:47:39,294][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 47.71% examples, 2473243 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:40,304][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 97.36% examples, 2458831 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:47:40,349][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5070569 effective words) took 2.1s, 2467597 effective words/s
[2023-02-07 18:47:41,350][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 47.62% examples, 2464513 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:42,355][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 92.78% examples, 2363279 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:42,494][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5070569 effective words) took 2.1s, 2365079 effective words/s
[2023-02-07 18:47:43,498][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 43.23% examples, 2246240 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:44,499][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 91.28% examples, 2323960 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:44,670][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5070569 effective words) took 2.2s, 2331400 effective words/s
[2023-02-07 18:47:45,676][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 47.22% examples, 2428266 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:46,687][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 96.59% examples, 2432812 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:46,746][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5070569 effective words) took 2.1s, 2444194 effective words/s
[2023-02-07 18:47:47,751][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 45.32% examples, 2335745 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:48,752][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 90.67% examples, 2310433 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:48,944][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5070569 effective words) took 2.2s, 2308379 effective words/s
[2023-02-07 18:47:49,947][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 46.79% examples, 2413888 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:50,949][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 96.62% examples, 2447908 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:51,013][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5070569 effective words) took 2.1s, 2452774 effective words/s
[2023-02-07 18:47:52,016][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 46.76% examples, 2412483 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:53,016][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 95.43% examples, 2419067 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:53,101][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5070569 effective words) took 2.1s, 2429348 effective words/s
[2023-02-07 18:47:54,102][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 47.62% examples, 2465323 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:55,104][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 96.38% examples, 2442023 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:55,177][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5070569 effective words) took 2.1s, 2443643 effective words/s
[2023-02-07 18:47:56,178][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 45.96% examples, 2371243 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:57,184][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 97.36% examples, 2463595 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:57,231][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5070569 effective words) took 2.1s, 2470165 effective words/s
[2023-02-07 18:47:58,238][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 49.25% examples, 2532713 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:59,240][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 99.72% examples, 2520649 words/s, in_qsize 1, out_qsize 1
[2023-02-07 18:47:59,242][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5070569 effective words) took 2.0s, 2522705 effective words/s
[2023-02-07 18:48:00,247][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 47.71% examples, 2464575 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:48:01,248][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 99.57% examples, 2517750 words/s, in_qsize 3, out_qsize 1
[2023-02-07 18:48:01,254][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5070569 effective words) took 2.0s, 2521351 effective words/s
[2023-02-07 18:48:02,257][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 49.25% examples, 2541703 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:03,257][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5070569 effective words) took 2.0s, 2532619 effective words/s
[2023-02-07 18:48:03,257][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76058535 effective words) took 31.8s, 2395194 effective words/s', 'datetime': '2023-02-07T18:48:03.257879', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:48:03.258 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:48:06,272][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184703-sasaodj6/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:48:06.272513', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:48:06,273][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:48:06,340][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184703-sasaodj6/files/../tmp/embedding_model.pt
2023-02-07 18:48:06.340 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:48:07.849 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:48:08.405 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:48:10.622 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0823110008026822, 'test_mae': 0.7841984549640146, 'test_r2': -2.522088329731848}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.94
wandb: percentage 0.31673
wandb:   test_mae 0.7842
wandb:   test_mse 1.08231
wandb:    test_r2 -2.52209
wandb: 
wandb: üöÄ View run winter-sweep-19 at: https://wandb.ai/xiaoqiz/mof2vec/runs/sasaodj6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_184703-sasaodj6/logs
wandb: Agent Starting Run: pyhro68r with config:
wandb: 	data.data.wl_step: 1
wandb: 	data.nn.batch_size: 964
wandb: 	model.gensim.alpha: 0.007257790511029141
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.9895029702078292
wandb: 	model.gensim.vector_size: 87
wandb: 	model.gensim.window: 10
wandb: 	model.sklearn.learning_rate: 0.001774827273944025
wandb: 	model.sklearn.max_depth: 70
wandb: 	model.sklearn.min_child_weight: 0.03655824780464883
wandb: 	model.sklearn.n_estimators: 303
wandb: 	model.sklearn.num_leaves: 31
wandb: 	model.sklearn.reg_alpha: 0.014759906197807138
wandb: 	model.sklearn.reg_lambda: 0.4106606162463578
wandb: 	model.sklearn.subsample: 0.3093752974484827
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184819-pyhro68r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/pyhro68r
2023-02-07 18:48:27.837 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 1 for sweep.
2023-02-07 18:48:27.838 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 964 for sweep.
2023-02-07 18:48:27.838 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.007257790511029141 for sweep.
2023-02-07 18:48:27.838 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:48:27.839 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 18:48:27.839 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9895029702078292 for sweep.
2023-02-07 18:48:27.839 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 87 for sweep.
2023-02-07 18:48:27.839 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 10 for sweep.
2023-02-07 18:48:27.839 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.001774827273944025 for sweep.
2023-02-07 18:48:27.840 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 70 for sweep.
2023-02-07 18:48:27.840 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03655824780464883 for sweep.
2023-02-07 18:48:27.840 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 303 for sweep.
2023-02-07 18:48:27.841 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 31 for sweep.
2023-02-07 18:48:27.842 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.014759906197807138 for sweep.
2023-02-07 18:48:27.842 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.4106606162463578 for sweep.
2023-02-07 18:48:27.842 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3093752974484827 for sweep.
2023-02-07 18:48:27.842 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:48:27.848 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 1}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184819-pyhro68r/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 964, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 87, 'window': 10, 'min_count': 2, 'dm': 0, 'sample': 0.9895029702078292, 'workers': 4, 'alpha': 0.007257790511029141, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 303, 'max_depth': 70, 'num_leaves': 31, 'reg_alpha': 0.014759906197807138, 'reg_lambda': 0.4106606162463578, 'subsample': 0.3093752974484827, 'min_child_weight': 0.03655824780464883, 'n_jobs': 4, 'learning_rate': 0.001774827273944025}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|‚ñè         | 41/3257 [00:00<00:07, 405.88it/s]  3%|‚ñé         | 85/3257 [00:00<00:07, 425.76it/s]  4%|‚ñç         | 128/3257 [00:00<00:07, 409.77it/s]  5%|‚ñå         | 171/3257 [00:00<00:07, 415.96it/s]  7%|‚ñã         | 216/3257 [00:00<00:07, 426.58it/s]  8%|‚ñä         | 260/3257 [00:00<00:07, 426.14it/s]  9%|‚ñâ         | 306/3257 [00:00<00:06, 436.93it/s] 11%|‚ñà         | 350/3257 [00:00<00:06, 430.58it/s] 12%|‚ñà‚ñè        | 394/3257 [00:00<00:06, 424.00it/s] 13%|‚ñà‚ñé        | 437/3257 [00:01<00:07, 401.20it/s] 15%|‚ñà‚ñç        | 480/3257 [00:01<00:06, 408.36it/s] 16%|‚ñà‚ñå        | 524/3257 [00:01<00:06, 416.00it/s] 17%|‚ñà‚ñã        | 566/3257 [00:01<00:06, 408.15it/s] 19%|‚ñà‚ñä        | 610/3257 [00:01<00:06, 415.53it/s] 20%|‚ñà‚ñà        | 655/3257 [00:01<00:06, 421.50it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:01<00:06, 398.99it/s] 23%|‚ñà‚ñà‚ñé       | 739/3257 [00:01<00:06, 389.78it/s] 24%|‚ñà‚ñà‚ñç       | 784/3257 [00:01<00:06, 406.12it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:02<00:06, 401.78it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:02<00:05, 399.37it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:02<00:08, 286.19it/s] 29%|‚ñà‚ñà‚ñâ       | 946/3257 [00:02<00:07, 308.87it/s] 30%|‚ñà‚ñà‚ñà       | 986/3257 [00:02<00:06, 328.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:02<00:06, 345.22it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1072/3257 [00:02<00:05, 370.90it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:02<00:05, 376.94it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1152/3257 [00:02<00:05, 361.33it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1190/3257 [00:03<00:05, 349.19it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:03<00:05, 364.47it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1274/3257 [00:03<00:05, 378.31it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:03<00:05, 374.48it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1351/3257 [00:03<00:05, 374.59it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1389/3257 [00:03<00:05, 358.05it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:03<00:04, 375.59it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1476/3257 [00:03<00:04, 392.96it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1516/3257 [00:03<00:04, 385.74it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:04<00:04, 358.48it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:04<00:04, 371.27it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:04<00:04, 372.05it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1672/3257 [00:04<00:04, 364.38it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1713/3257 [00:04<00:04, 376.36it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1751/3257 [00:04<00:04, 365.84it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:04<00:03, 378.44it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1831/3257 [00:04<00:03, 376.29it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1875/3257 [00:04<00:03, 393.35it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1917/3257 [00:05<00:03, 397.61it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:05<00:03, 415.91it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2007/3257 [00:05<00:03, 410.58it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2049/3257 [00:05<00:02, 403.48it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2090/3257 [00:05<00:04, 283.21it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2128/3257 [00:05<00:03, 304.20it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:05<00:03, 325.61it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:05<00:03, 342.72it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2249/3257 [00:05<00:02, 357.49it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2290/3257 [00:06<00:02, 370.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2331/3257 [00:06<00:02, 380.75it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2371/3257 [00:06<00:02, 374.46it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2410/3257 [00:06<00:02, 375.40it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2449/3257 [00:06<00:02, 374.10it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2494/3257 [00:06<00:01, 395.55it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:06<00:01, 408.06it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2582/3257 [00:06<00:01, 394.98it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2622/3257 [00:06<00:01, 388.60it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2662/3257 [00:07<00:01, 364.82it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2701/3257 [00:07<00:01, 369.81it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2747/3257 [00:07<00:01, 393.47it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2787/3257 [00:07<00:01, 384.84it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2826/3257 [00:07<00:01, 367.39it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2870/3257 [00:07<00:01, 386.92it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2910/3257 [00:07<00:00, 389.92it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:07<00:00, 368.87it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2988/3257 [00:07<00:00, 360.71it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3030/3257 [00:08<00:00, 376.15it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3079/3257 [00:08<00:00, 404.93it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3125/3257 [00:08<00:00, 418.60it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3168/3257 [00:08<00:00, 411.21it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3210/3257 [00:08<00:00, 404.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3251/3257 [00:08<00:00, 401.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:08<00:00, 379.97it/s]
2023-02-07 18:48:36.605 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:48:36,606][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d87,n5,mc2,s0.989503,t4>', 'datetime': '2023-02-07T18:48:36.606784', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:48:36,607][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:48:36,607][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:48:36,739][gensim.models.doc2vec][INFO] - collected 924 word types and 3257 unique tags from a corpus of 3257 examples and 1455748 words
[2023-02-07 18:48:36,739][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:48:36,742][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 881 unique words (95.35% of original 924, drops 43)', 'datetime': '2023-02-07T18:48:36.742120', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:48:36,742][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 1455705 word corpus (100.00% of original 1455748, drops 43)', 'datetime': '2023-02-07T18:48:36.742324', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:48:36,745][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 924 items
[2023-02-07 18:48:36,745][gensim.models.word2vec][INFO] - sample=0.989503 downsamples 0 most-common words
[2023-02-07 18:48:36,746][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 1455705 word corpus (100.0%% of prior 1455705)', 'datetime': '2023-02-07T18:48:36.746215', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:48:36,751][gensim.models.word2vec][INFO] - estimated required memory for 881 words and 87 dimensions: 2838512 bytes
[2023-02-07 18:48:36,751][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:48:36,753][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 881 vocabulary and 87 features, using sg=1 hs=0 sample=0.9895029702078292 negative=5 window=10 shrink_windows=True', 'datetime': '2023-02-07T18:48:36.753733', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:48:37,249][gensim.models.word2vec][INFO] - EPOCH 0: training on 1455748 raw words (1458962 effective words) took 0.5s, 2955703 effective words/s
[2023-02-07 18:48:37,682][gensim.models.word2vec][INFO] - EPOCH 1: training on 1455748 raw words (1458962 effective words) took 0.4s, 3372693 effective words/s
[2023-02-07 18:48:38,129][gensim.models.word2vec][INFO] - EPOCH 2: training on 1455748 raw words (1458962 effective words) took 0.4s, 3276668 effective words/s
[2023-02-07 18:48:38,547][gensim.models.word2vec][INFO] - EPOCH 3: training on 1455748 raw words (1458962 effective words) took 0.4s, 3500319 effective words/s
[2023-02-07 18:48:38,955][gensim.models.word2vec][INFO] - EPOCH 4: training on 1455748 raw words (1458962 effective words) took 0.4s, 3587769 effective words/s
[2023-02-07 18:48:39,364][gensim.models.word2vec][INFO] - EPOCH 5: training on 1455748 raw words (1458962 effective words) took 0.4s, 3580304 effective words/s
[2023-02-07 18:48:39,777][gensim.models.word2vec][INFO] - EPOCH 6: training on 1455748 raw words (1458962 effective words) took 0.4s, 3537182 effective words/s
[2023-02-07 18:48:40,207][gensim.models.word2vec][INFO] - EPOCH 7: training on 1455748 raw words (1458962 effective words) took 0.4s, 3405036 effective words/s
[2023-02-07 18:48:40,630][gensim.models.word2vec][INFO] - EPOCH 8: training on 1455748 raw words (1458962 effective words) took 0.4s, 3460212 effective words/s
[2023-02-07 18:48:41,038][gensim.models.word2vec][INFO] - EPOCH 9: training on 1455748 raw words (1458962 effective words) took 0.4s, 3586332 effective words/s
[2023-02-07 18:48:41,443][gensim.models.word2vec][INFO] - EPOCH 10: training on 1455748 raw words (1458962 effective words) took 0.4s, 3612660 effective words/s
[2023-02-07 18:48:41,849][gensim.models.word2vec][INFO] - EPOCH 11: training on 1455748 raw words (1458962 effective words) took 0.4s, 3602637 effective words/s
[2023-02-07 18:48:42,262][gensim.models.word2vec][INFO] - EPOCH 12: training on 1455748 raw words (1458962 effective words) took 0.4s, 3543419 effective words/s
[2023-02-07 18:48:42,683][gensim.models.word2vec][INFO] - EPOCH 13: training on 1455748 raw words (1458962 effective words) took 0.4s, 3478977 effective words/s
[2023-02-07 18:48:43,099][gensim.models.word2vec][INFO] - EPOCH 14: training on 1455748 raw words (1458962 effective words) took 0.4s, 3515553 effective words/s
[2023-02-07 18:48:43,100][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 21836220 raw words (21884430 effective words) took 6.3s, 3448358 effective words/s', 'datetime': '2023-02-07T18:48:43.100311', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:48:43.100 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:48:43,886][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184819-pyhro68r/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:48:43.886458', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:48:43,888][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:48:43,892][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184819-pyhro68r/files/../tmp/embedding_model.pt
2023-02-07 18:48:43.893 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:48:44.921 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:48:45.344 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:49:12.694 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9369036643584973, 'test_mae': 0.7466142057366898, 'test_r2': -1.7173458427178914}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.49
wandb: percentage 0.04654
wandb:   test_mae 0.74661
wandb:   test_mse 0.9369
wandb:    test_r2 -1.71735
wandb: 
wandb: üöÄ View run vocal-sweep-20 at: https://wandb.ai/xiaoqiz/mof2vec/runs/pyhro68r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_184819-pyhro68r/logs
wandb: Agent Starting Run: fati4tnx with config:
wandb: 	data.data.wl_step: 3
wandb: 	data.nn.batch_size: 698
wandb: 	model.gensim.alpha: 0.000454213188303158
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.7591432529366637
wandb: 	model.gensim.vector_size: 160
wandb: 	model.gensim.window: 17
wandb: 	model.sklearn.learning_rate: 0.03432913323087443
wandb: 	model.sklearn.max_depth: 69
wandb: 	model.sklearn.min_child_weight: 0.0908949883310828
wandb: 	model.sklearn.n_estimators: 1914
wandb: 	model.sklearn.num_leaves: 139
wandb: 	model.sklearn.reg_alpha: 0.0038244570927814464
wandb: 	model.sklearn.reg_lambda: 0.004850074676344734
wandb: 	model.sklearn.subsample: 0.8031771194569115
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184931-fati4tnx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-21
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/fati4tnx
2023-02-07 18:49:40.482 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 3 for sweep.
2023-02-07 18:49:40.482 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 698 for sweep.
2023-02-07 18:49:40.483 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.000454213188303158 for sweep.
2023-02-07 18:49:40.483 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:49:40.483 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 18:49:40.484 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7591432529366637 for sweep.
2023-02-07 18:49:40.484 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 160 for sweep.
2023-02-07 18:49:40.485 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 17 for sweep.
2023-02-07 18:49:40.485 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.03432913323087443 for sweep.
2023-02-07 18:49:40.485 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 69 for sweep.
2023-02-07 18:49:40.485 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0908949883310828 for sweep.
2023-02-07 18:49:40.486 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1914 for sweep.
2023-02-07 18:49:40.486 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 139 for sweep.
2023-02-07 18:49:40.486 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0038244570927814464 for sweep.
2023-02-07 18:49:40.486 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.004850074676344734 for sweep.
2023-02-07 18:49:40.486 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8031771194569115 for sweep.
2023-02-07 18:49:40.487 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:49:40.497 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 3}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184931-fati4tnx/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 698, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 160, 'window': 17, 'min_count': 5, 'dm': 1, 'sample': 0.7591432529366637, 'workers': 4, 'alpha': 0.000454213188303158, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1914, 'max_depth': 69, 'num_leaves': 139, 'reg_alpha': 0.0038244570927814464, 'reg_lambda': 0.004850074676344734, 'subsample': 0.8031771194569115, 'min_child_weight': 0.0908949883310828, 'n_jobs': 4, 'learning_rate': 0.03432913323087443}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 20/3257 [00:00<00:16, 197.28it/s]  1%|‚ñè         | 41/3257 [00:00<00:16, 195.79it/s]  2%|‚ñè         | 61/3257 [00:00<00:29, 109.71it/s]  3%|‚ñé         | 85/3257 [00:00<00:22, 143.05it/s]  3%|‚ñé         | 106/3257 [00:00<00:20, 156.33it/s]  4%|‚ñç         | 129/3257 [00:00<00:17, 176.31it/s]  5%|‚ñç         | 152/3257 [00:00<00:16, 190.01it/s]  5%|‚ñå         | 173/3257 [00:01<00:16, 192.48it/s]  6%|‚ñå         | 198/3257 [00:01<00:14, 207.70it/s]  7%|‚ñã         | 226/3257 [00:01<00:13, 227.94it/s]  8%|‚ñä         | 250/3257 [00:01<00:13, 227.28it/s]  8%|‚ñä         | 274/3257 [00:01<00:13, 228.91it/s]  9%|‚ñâ         | 300/3257 [00:01<00:12, 236.81it/s] 10%|‚ñà         | 327/3257 [00:01<00:11, 244.99it/s] 11%|‚ñà         | 352/3257 [00:01<00:12, 232.82it/s] 12%|‚ñà‚ñè        | 376/3257 [00:01<00:12, 227.95it/s] 12%|‚ñà‚ñè        | 399/3257 [00:01<00:12, 222.60it/s] 13%|‚ñà‚ñé        | 422/3257 [00:02<00:12, 224.11it/s] 14%|‚ñà‚ñé        | 445/3257 [00:02<00:13, 204.55it/s] 14%|‚ñà‚ñç        | 469/3257 [00:02<00:13, 213.34it/s] 15%|‚ñà‚ñå        | 492/3257 [00:02<00:12, 217.14it/s] 16%|‚ñà‚ñå        | 517/3257 [00:02<00:12, 222.42it/s] 17%|‚ñà‚ñã        | 542/3257 [00:02<00:11, 229.11it/s] 17%|‚ñà‚ñã        | 566/3257 [00:02<00:12, 216.55it/s] 18%|‚ñà‚ñä        | 590/3257 [00:02<00:12, 222.05it/s] 19%|‚ñà‚ñâ        | 622/3257 [00:02<00:10, 246.02it/s] 20%|‚ñà‚ñà        | 654/3257 [00:03<00:09, 264.04it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:09, 265.34it/s] 22%|‚ñà‚ñà‚ñè       | 715/3257 [00:03<00:09, 279.53it/s] 23%|‚ñà‚ñà‚ñé       | 744/3257 [00:03<00:09, 260.03it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:03<00:09, 266.00it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:03<00:08, 274.62it/s] 26%|‚ñà‚ñà‚ñå       | 832/3257 [00:03<00:09, 268.80it/s] 26%|‚ñà‚ñà‚ñã       | 860/3257 [00:03<00:08, 269.65it/s] 27%|‚ñà‚ñà‚ñã       | 888/3257 [00:03<00:08, 263.51it/s] 28%|‚ñà‚ñà‚ñä       | 918/3257 [00:04<00:08, 272.50it/s] 29%|‚ñà‚ñà‚ñâ       | 946/3257 [00:04<00:08, 273.58it/s] 30%|‚ñà‚ñà‚ñâ       | 975/3257 [00:04<00:08, 277.45it/s] 31%|‚ñà‚ñà‚ñà       | 1005/3257 [00:04<00:07, 283.89it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1034/3257 [00:04<00:08, 271.99it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:04<00:08, 267.55it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1090/3257 [00:04<00:08, 270.85it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1118/3257 [00:04<00:07, 269.61it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1146/3257 [00:04<00:08, 260.86it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:04<00:07, 265.72it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1202/3257 [00:05<00:11, 175.62it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:05<00:10, 200.91it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:05<00:09, 213.30it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1283/3257 [00:05<00:09, 217.55it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:05<00:08, 225.13it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1341/3257 [00:05<00:07, 250.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1368/3257 [00:05<00:07, 243.80it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1394/3257 [00:06<00:07, 245.04it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1424/3257 [00:06<00:07, 259.77it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1456/3257 [00:06<00:06, 275.23it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1486/3257 [00:06<00:06, 279.61it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1518/3257 [00:06<00:06, 288.36it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1548/3257 [00:06<00:06, 263.21it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:06<00:06, 260.92it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1604/3257 [00:06<00:06, 268.68it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:06<00:06, 266.44it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:06<00:06, 255.35it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1687/3257 [00:07<00:06, 253.93it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:07<00:05, 257.35it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1741/3257 [00:07<00:06, 243.98it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:07<00:05, 256.18it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1799/3257 [00:07<00:05, 261.35it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:07<00:05, 257.58it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1853/3257 [00:07<00:05, 260.74it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1883/3257 [00:07<00:05, 270.59it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1913/3257 [00:07<00:04, 278.16it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1942/3257 [00:08<00:04, 281.32it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:08<00:04, 290.05it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:08<00:04, 278.58it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:08<00:04, 280.73it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2062/3257 [00:08<00:04, 260.40it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:08<00:04, 268.24it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2119/3257 [00:08<00:04, 268.49it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2147/3257 [00:08<00:04, 248.11it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:08<00:04, 260.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2206/3257 [00:09<00:03, 264.03it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2233/3257 [00:09<00:03, 256.69it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:09<00:03, 256.71it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2289/3257 [00:09<00:03, 263.77it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2319/3257 [00:09<00:03, 273.19it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2354/3257 [00:09<00:03, 295.28it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2384/3257 [00:09<00:02, 292.13it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2414/3257 [00:09<00:02, 285.94it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:09<00:02, 277.54it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2471/3257 [00:09<00:02, 277.64it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2499/3257 [00:10<00:02, 272.59it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2534/3257 [00:10<00:02, 293.92it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2564/3257 [00:10<00:03, 177.16it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2589/3257 [00:10<00:03, 190.98it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2626/3257 [00:10<00:02, 229.49it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:10<00:02, 235.64it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2684/3257 [00:10<00:02, 249.85it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2712/3257 [00:11<00:02, 240.42it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2744/3257 [00:11<00:01, 258.68it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2772/3257 [00:11<00:01, 256.65it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2806/3257 [00:11<00:01, 276.81it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2835/3257 [00:11<00:01, 265.67it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:11<00:01, 290.34it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2902/3257 [00:11<00:01, 281.87it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2932/3257 [00:11<00:01, 285.95it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2961/3257 [00:11<00:01, 278.44it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2990/3257 [00:12<00:00, 271.54it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3021/3257 [00:12<00:00, 282.21it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3053/3257 [00:12<00:00, 292.75it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3086/3257 [00:12<00:00, 301.78it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3120/3257 [00:12<00:00, 311.02it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3152/3257 [00:12<00:00, 294.96it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3182/3257 [00:12<00:00, 285.83it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:12<00:00, 290.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3249/3257 [00:12<00:00, 309.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:12<00:00, 251.83it/s]
2023-02-07 18:49:53.802 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:49:53,803][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d160,n5,w17,mc5,s0.759143,t4>', 'datetime': '2023-02-07T18:49:53.803568', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:49:53,803][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:49:53,804][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:49:54,085][gensim.models.doc2vec][INFO] - collected 6662 word types and 3257 unique tags from a corpus of 3257 examples and 2911496 words
[2023-02-07 18:49:54,087][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:49:54,097][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 3705 unique words (55.61% of original 6662, drops 2957)', 'datetime': '2023-02-07T18:49:54.097732', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:49:54,098][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2904334 word corpus (99.75% of original 2911496, drops 7162)', 'datetime': '2023-02-07T18:49:54.098100', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:49:54,110][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 6662 items
[2023-02-07 18:49:54,111][gensim.models.word2vec][INFO] - sample=0.759143 downsamples 0 most-common words
[2023-02-07 18:49:54,111][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2904334 word corpus (100.0%% of prior 2904334)', 'datetime': '2023-02-07T18:49:54.111365', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:49:54,133][gensim.models.word2vec][INFO] - estimated required memory for 3705 words and 160 dimensions: 9330780 bytes
[2023-02-07 18:49:54,133][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:49:54,138][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 3705 vocabulary and 160 features, using sg=0 hs=0 sample=0.7591432529366637 negative=5 window=17 shrink_windows=True', 'datetime': '2023-02-07T18:49:54.138172', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:49:55,140][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 46.58% examples, 1375799 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:56,149][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 96.47% examples, 1396990 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:56,205][gensim.models.word2vec][INFO] - EPOCH 0: training on 2911496 raw words (2907591 effective words) took 2.1s, 1407890 effective words/s
[2023-02-07 18:49:57,211][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 49.43% examples, 1457088 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:58,162][gensim.models.word2vec][INFO] - EPOCH 1: training on 2911496 raw words (2907591 effective words) took 2.0s, 1486852 effective words/s
[2023-02-07 18:49:59,170][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 50.14% examples, 1473277 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:00,115][gensim.models.word2vec][INFO] - EPOCH 2: training on 2911496 raw words (2907591 effective words) took 2.0s, 1489521 effective words/s
[2023-02-07 18:50:01,121][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 50.57% examples, 1495766 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:02,041][gensim.models.word2vec][INFO] - EPOCH 3: training on 2911496 raw words (2907591 effective words) took 1.9s, 1511154 effective words/s
[2023-02-07 18:50:03,046][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 47.04% examples, 1388425 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:04,052][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 95.46% examples, 1383108 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:50:04,134][gensim.models.word2vec][INFO] - EPOCH 4: training on 2911496 raw words (2907591 effective words) took 2.1s, 1390334 effective words/s
[2023-02-07 18:50:05,142][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 46.76% examples, 1377743 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:06,143][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 95.46% examples, 1384852 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:06,225][gensim.models.word2vec][INFO] - EPOCH 5: training on 2911496 raw words (2907591 effective words) took 2.1s, 1391931 effective words/s
[2023-02-07 18:50:07,234][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 47.04% examples, 1382891 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:08,235][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 95.89% examples, 1388490 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:08,315][gensim.models.word2vec][INFO] - EPOCH 6: training on 2911496 raw words (2907591 effective words) took 2.1s, 1391853 effective words/s
[2023-02-07 18:50:09,328][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 47.04% examples, 1378109 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:50:10,340][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 95.89% examples, 1378601 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:10,413][gensim.models.word2vec][INFO] - EPOCH 7: training on 2911496 raw words (2907591 effective words) took 2.1s, 1387488 effective words/s
[2023-02-07 18:50:11,416][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 47.31% examples, 1400955 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:50:12,428][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 98.93% examples, 1430623 words/s, in_qsize 3, out_qsize 1
[2023-02-07 18:50:12,435][gensim.models.word2vec][INFO] - EPOCH 8: training on 2911496 raw words (2907591 effective words) took 2.0s, 1438706 effective words/s
[2023-02-07 18:50:13,445][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 48.23% examples, 1419831 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:14,447][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 98.62% examples, 1428186 words/s, in_qsize 4, out_qsize 0
[2023-02-07 18:50:14,469][gensim.models.word2vec][INFO] - EPOCH 9: training on 2911496 raw words (2907591 effective words) took 2.0s, 1430435 effective words/s
[2023-02-07 18:50:15,473][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 50.14% examples, 1479738 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:16,316][gensim.models.word2vec][INFO] - EPOCH 10: training on 2911496 raw words (2907591 effective words) took 1.8s, 1575670 effective words/s
[2023-02-07 18:50:17,321][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 51.06% examples, 1511839 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:18,291][gensim.models.word2vec][INFO] - EPOCH 11: training on 2911496 raw words (2907591 effective words) took 2.0s, 1472857 effective words/s
[2023-02-07 18:50:19,294][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 49.25% examples, 1458608 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:20,294][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 99.82% examples, 1448635 words/s, in_qsize 1, out_qsize 1
[2023-02-07 18:50:20,296][gensim.models.word2vec][INFO] - EPOCH 12: training on 2911496 raw words (2907591 effective words) took 2.0s, 1451333 effective words/s
[2023-02-07 18:50:21,301][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 49.25% examples, 1454199 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:22,281][gensim.models.word2vec][INFO] - EPOCH 13: training on 2911496 raw words (2907591 effective words) took 2.0s, 1465592 effective words/s
[2023-02-07 18:50:23,298][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 50.14% examples, 1458879 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:50:24,242][gensim.models.word2vec][INFO] - EPOCH 14: training on 2911496 raw words (2907591 effective words) took 2.0s, 1483672 effective words/s
[2023-02-07 18:50:24,242][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 43672440 raw words (43613865 effective words) took 30.1s, 1448771 effective words/s', 'datetime': '2023-02-07T18:50:24.242628', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:50:24.243 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:50:25,870][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184931-fati4tnx/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:50:25.870682', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:50:25,871][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:50:25,891][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184931-fati4tnx/files/../tmp/embedding_model.pt
2023-02-07 18:50:25.891 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:50:27.209 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:50:27.714 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:50:50.560 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1798155161002086, 'test_mae': 0.851865808336647, 'test_r2': -3.3855155445767124}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.09
wandb: percentage 0.44386
wandb:   test_mae 0.85187
wandb:   test_mse 1.17982
wandb:    test_r2 -3.38552
wandb: 
wandb: üöÄ View run fresh-sweep-21 at: https://wandb.ai/xiaoqiz/mof2vec/runs/fati4tnx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_184931-fati4tnx/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4g7rgbhk with config:
wandb: 	data.data.wl_step: 3
wandb: 	data.nn.batch_size: 97
wandb: 	model.gensim.alpha: 0.0008390841915735689
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.26736711699319005
wandb: 	model.gensim.vector_size: 386
wandb: 	model.gensim.window: 1
wandb: 	model.sklearn.learning_rate: 0.042339501279737415
wandb: 	model.sklearn.max_depth: 16
wandb: 	model.sklearn.min_child_weight: 0.024763065353293548
wandb: 	model.sklearn.n_estimators: 4137
wandb: 	model.sklearn.num_leaves: 21
wandb: 	model.sklearn.reg_alpha: 0.002947482816999471
wandb: 	model.sklearn.reg_lambda: 0.6172792062509176
wandb: 	model.sklearn.subsample: 0.8601924355927437
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185108-4g7rgbhk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-22
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/4g7rgbhk
2023-02-07 18:51:17.324 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 3 for sweep.
2023-02-07 18:51:17.324 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 97 for sweep.
2023-02-07 18:51:17.325 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0008390841915735689 for sweep.
2023-02-07 18:51:17.325 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:51:17.326 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 18:51:17.326 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.26736711699319005 for sweep.
2023-02-07 18:51:17.326 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 386 for sweep.
2023-02-07 18:51:17.326 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 1 for sweep.
2023-02-07 18:51:17.327 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.042339501279737415 for sweep.
2023-02-07 18:51:17.327 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 16 for sweep.
2023-02-07 18:51:17.327 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.024763065353293548 for sweep.
2023-02-07 18:51:17.327 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4137 for sweep.
2023-02-07 18:51:17.328 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 21 for sweep.
2023-02-07 18:51:17.328 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.002947482816999471 for sweep.
2023-02-07 18:51:17.328 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.6172792062509176 for sweep.
2023-02-07 18:51:17.328 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8601924355927437 for sweep.
2023-02-07 18:51:17.329 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:51:17.335 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 3}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185108-4g7rgbhk/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 97, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 386, 'window': 1, 'min_count': 9, 'dm': 0, 'sample': 0.26736711699319005, 'workers': 4, 'alpha': 0.0008390841915735689, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4137, 'max_depth': 16, 'num_leaves': 21, 'reg_alpha': 0.002947482816999471, 'reg_lambda': 0.6172792062509176, 'subsample': 0.8601924355927437, 'min_child_weight': 0.024763065353293548, 'n_jobs': 4, 'learning_rate': 0.042339501279737415}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 21/3257 [00:00<00:15, 208.42it/s]  1%|‚ñè         | 45/3257 [00:00<00:14, 225.48it/s]  2%|‚ñè         | 69/3257 [00:00<00:13, 229.28it/s]  3%|‚ñé         | 95/3257 [00:00<00:13, 239.46it/s]  4%|‚ñé         | 119/3257 [00:00<00:13, 237.71it/s]  4%|‚ñç         | 146/3257 [00:00<00:12, 245.03it/s]  5%|‚ñå         | 171/3257 [00:00<00:12, 241.10it/s]  6%|‚ñå         | 197/3257 [00:00<00:12, 242.30it/s]  7%|‚ñã         | 227/3257 [00:00<00:11, 258.58it/s]  8%|‚ñä         | 253/3257 [00:01<00:11, 257.65it/s]  9%|‚ñä         | 282/3257 [00:01<00:11, 266.29it/s]  9%|‚ñâ         | 309/3257 [00:01<00:11, 258.32it/s] 10%|‚ñà         | 335/3257 [00:01<00:11, 257.71it/s] 11%|‚ñà         | 361/3257 [00:01<00:11, 257.62it/s] 12%|‚ñà‚ñè        | 387/3257 [00:01<00:12, 237.19it/s] 13%|‚ñà‚ñé        | 417/3257 [00:01<00:11, 254.28it/s] 14%|‚ñà‚ñé        | 443/3257 [00:01<00:11, 245.07it/s] 15%|‚ñà‚ñç        | 475/3257 [00:01<00:10, 265.59it/s] 16%|‚ñà‚ñå        | 510/3257 [00:01<00:09, 287.25it/s] 17%|‚ñà‚ñã        | 542/3257 [00:02<00:09, 294.50it/s] 18%|‚ñà‚ñä        | 572/3257 [00:02<00:09, 270.15it/s] 19%|‚ñà‚ñä        | 606/3257 [00:02<00:09, 288.02it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:02<00:08, 297.11it/s] 21%|‚ñà‚ñà        | 670/3257 [00:02<00:12, 212.91it/s] 21%|‚ñà‚ñà‚ñè       | 696/3257 [00:02<00:11, 223.04it/s] 22%|‚ñà‚ñà‚ñè       | 726/3257 [00:02<00:10, 238.96it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:02<00:10, 249.01it/s] 24%|‚ñà‚ñà‚ñç       | 783/3257 [00:03<00:09, 259.10it/s] 25%|‚ñà‚ñà‚ñç       | 814/3257 [00:03<00:09, 269.54it/s] 26%|‚ñà‚ñà‚ñå       | 842/3257 [00:03<00:09, 258.87it/s] 27%|‚ñà‚ñà‚ñã       | 870/3257 [00:03<00:09, 264.25it/s] 28%|‚ñà‚ñà‚ñä       | 898/3257 [00:03<00:08, 268.08it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:03<00:08, 274.76it/s] 29%|‚ñà‚ñà‚ñâ       | 957/3257 [00:03<00:08, 279.15it/s] 30%|‚ñà‚ñà‚ñà       | 986/3257 [00:03<00:08, 268.38it/s] 31%|‚ñà‚ñà‚ñà       | 1014/3257 [00:03<00:08, 264.30it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:04<00:08, 252.94it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1070/3257 [00:04<00:08, 262.44it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:04<00:08, 259.76it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1125/3257 [00:04<00:08, 263.77it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1152/3257 [00:04<00:08, 258.58it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1178/3257 [00:04<00:08, 255.08it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:04<00:08, 246.16it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:04<00:07, 258.47it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1261/3257 [00:04<00:07, 263.94it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:05<00:07, 249.24it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1315/3257 [00:05<00:07, 254.33it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:05<00:07, 264.37it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1371/3257 [00:05<00:07, 258.35it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1397/3257 [00:05<00:07, 252.64it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1424/3257 [00:05<00:07, 254.61it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1451/3257 [00:05<00:06, 258.35it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1481/3257 [00:05<00:06, 268.39it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:05<00:06, 276.57it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1539/3257 [00:05<00:06, 258.94it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1566/3257 [00:06<00:06, 257.25it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1593/3257 [00:06<00:06, 260.17it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1621/3257 [00:06<00:06, 261.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1648/3257 [00:06<00:06, 255.26it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:06<00:06, 250.49it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:06<00:06, 251.92it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:06<00:06, 250.79it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1754/3257 [00:06<00:06, 248.54it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:07<00:08, 166.29it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1806/3257 [00:07<00:07, 187.73it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1833/3257 [00:07<00:06, 206.08it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1864/3257 [00:07<00:06, 231.51it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1891/3257 [00:07<00:05, 240.22it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1918/3257 [00:07<00:05, 246.64it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1951/3257 [00:07<00:04, 269.00it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1979/3257 [00:07<00:04, 270.41it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:07<00:04, 274.59it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2038/3257 [00:08<00:04, 277.82it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2067/3257 [00:08<00:04, 258.58it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2096/3257 [00:08<00:04, 261.66it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2123/3257 [00:08<00:04, 254.89it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2149/3257 [00:08<00:04, 247.45it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:08<00:04, 256.26it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2205/3257 [00:08<00:04, 259.93it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2232/3257 [00:08<00:03, 258.63it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:08<00:03, 259.59it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2286/3257 [00:09<00:03, 261.38it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:09<00:03, 265.64it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2351/3257 [00:09<00:03, 292.58it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2381/3257 [00:09<00:03, 286.52it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2410/3257 [00:09<00:03, 280.71it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2439/3257 [00:09<00:03, 269.87it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2469/3257 [00:09<00:02, 277.87it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2500/3257 [00:09<00:02, 286.36it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2533/3257 [00:09<00:02, 298.18it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2563/3257 [00:09<00:02, 285.01it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2592/3257 [00:10<00:02, 273.34it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2628/3257 [00:10<00:02, 296.20it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2658/3257 [00:10<00:02, 278.78it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2691/3257 [00:10<00:01, 288.66it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2721/3257 [00:10<00:02, 259.11it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:10<00:01, 279.13it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2786/3257 [00:10<00:01, 283.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2815/3257 [00:10<00:01, 281.45it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2844/3257 [00:10<00:01, 271.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2882/3257 [00:11<00:01, 300.96it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2913/3257 [00:11<00:01, 288.28it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2943/3257 [00:11<00:01, 280.57it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2974/3257 [00:11<00:00, 286.51it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3003/3257 [00:11<00:00, 286.85it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3033/3257 [00:11<00:00, 290.30it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3066/3257 [00:11<00:00, 301.77it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3097/3257 [00:11<00:00, 297.91it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3130/3257 [00:11<00:00, 306.41it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3161/3257 [00:12<00:00, 298.19it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3191/3257 [00:12<00:00, 292.18it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3221/3257 [00:12<00:00, 286.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3250/3257 [00:12<00:00, 175.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:12<00:00, 258.13it/s]
2023-02-07 18:51:30.312 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:51:30,313][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d386,n5,mc9,s0.267367,t4>', 'datetime': '2023-02-07T18:51:30.313647', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:51:30,314][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:51:30,314][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:51:30,581][gensim.models.doc2vec][INFO] - collected 6662 word types and 3257 unique tags from a corpus of 3257 examples and 2911496 words
[2023-02-07 18:51:30,581][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:51:30,590][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 2762 unique words (41.46% of original 6662, drops 3900)', 'datetime': '2023-02-07T18:51:30.590360', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:51:30,590][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 2897962 word corpus (99.54% of original 2911496, drops 13534)', 'datetime': '2023-02-07T18:51:30.590729', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:51:30,600][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 6662 items
[2023-02-07 18:51:30,600][gensim.models.word2vec][INFO] - sample=0.267367 downsamples 0 most-common words
[2023-02-07 18:51:30,600][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2897962 word corpus (100.0%% of prior 2897962)', 'datetime': '2023-02-07T18:51:30.600817', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:51:30,617][gensim.models.word2vec][INFO] - estimated required memory for 2762 words and 386 dimensions: 15590264 bytes
[2023-02-07 18:51:30,617][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:51:30,626][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 2762 vocabulary and 386 features, using sg=1 hs=0 sample=0.26736711699319005 negative=5 window=1 shrink_windows=True', 'datetime': '2023-02-07T18:51:30.626016', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:51:31,628][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 51.34% examples, 1524312 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:32,500][gensim.models.word2vec][INFO] - EPOCH 0: training on 2911496 raw words (2901219 effective words) took 1.9s, 1549400 effective words/s
[2023-02-07 18:51:33,503][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 52.63% examples, 1558788 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:34,360][gensim.models.word2vec][INFO] - EPOCH 1: training on 2911496 raw words (2901219 effective words) took 1.9s, 1561010 effective words/s
[2023-02-07 18:51:35,377][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 51.06% examples, 1491539 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:36,296][gensim.models.word2vec][INFO] - EPOCH 2: training on 2911496 raw words (2901219 effective words) took 1.9s, 1499753 effective words/s
[2023-02-07 18:51:37,302][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 49.80% examples, 1463991 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:38,255][gensim.models.word2vec][INFO] - EPOCH 3: training on 2911496 raw words (2901219 effective words) took 2.0s, 1482166 effective words/s
[2023-02-07 18:51:39,258][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 50.29% examples, 1489136 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:40,186][gensim.models.word2vec][INFO] - EPOCH 4: training on 2911496 raw words (2901219 effective words) took 1.9s, 1504556 effective words/s
[2023-02-07 18:51:41,196][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 50.29% examples, 1478632 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:42,134][gensim.models.word2vec][INFO] - EPOCH 5: training on 2911496 raw words (2901219 effective words) took 1.9s, 1491044 effective words/s
[2023-02-07 18:51:43,141][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 50.14% examples, 1472857 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:44,091][gensim.models.word2vec][INFO] - EPOCH 6: training on 2911496 raw words (2901219 effective words) took 2.0s, 1484339 effective words/s
[2023-02-07 18:51:45,094][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 50.14% examples, 1478005 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:46,034][gensim.models.word2vec][INFO] - EPOCH 7: training on 2911496 raw words (2901219 effective words) took 1.9s, 1494643 effective words/s
[2023-02-07 18:51:47,040][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 50.29% examples, 1483891 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:47,962][gensim.models.word2vec][INFO] - EPOCH 8: training on 2911496 raw words (2901219 effective words) took 1.9s, 1506755 effective words/s
[2023-02-07 18:51:48,975][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 57.35% examples, 1681894 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:51:49,660][gensim.models.word2vec][INFO] - EPOCH 9: training on 2911496 raw words (2901219 effective words) took 1.7s, 1709753 effective words/s
[2023-02-07 18:51:50,666][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 32.73% examples, 955225 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:51,669][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 81.82% examples, 1193047 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:51,963][gensim.models.word2vec][INFO] - EPOCH 10: training on 2911496 raw words (2901219 effective words) took 2.3s, 1261030 effective words/s
[2023-02-07 18:51:52,980][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 55.97% examples, 1637739 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:51:53,765][gensim.models.word2vec][INFO] - EPOCH 11: training on 2911496 raw words (2901219 effective words) took 1.8s, 1611365 effective words/s
[2023-02-07 18:51:54,769][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 51.92% examples, 1539198 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:55,630][gensim.models.word2vec][INFO] - EPOCH 12: training on 2911496 raw words (2901219 effective words) took 1.9s, 1556690 effective words/s
[2023-02-07 18:51:56,638][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 45.84% examples, 1344386 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:57,641][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 94.38% examples, 1365995 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:57,742][gensim.models.word2vec][INFO] - EPOCH 13: training on 2911496 raw words (2901219 effective words) took 2.1s, 1374427 effective words/s
[2023-02-07 18:51:58,748][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 45.84% examples, 1349014 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:59,754][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 92.39% examples, 1341937 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:59,893][gensim.models.word2vec][INFO] - EPOCH 14: training on 2911496 raw words (2901219 effective words) took 2.1s, 1350075 effective words/s
[2023-02-07 18:51:59,894][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 43672440 raw words (43518285 effective words) took 29.3s, 1486890 effective words/s', 'datetime': '2023-02-07T18:51:59.894417', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:51:59.894 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:52:01,719][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185108-4g7rgbhk/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:52:01.719483', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:52:01,721][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:52:01,745][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185108-4g7rgbhk/files/../tmp/embedding_model.pt
2023-02-07 18:52:01.746 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:52:03.853 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:52:04.574 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:52:37.022 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0570237427377718, 'test_mae': 0.7981956850257388, 'test_r2': -2.010569763898133}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.013 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: / 0.013 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.3
wandb: percentage 0.58541
wandb:   test_mae 0.7982
wandb:   test_mse 1.05702
wandb:    test_r2 -2.01057
wandb: 
wandb: üöÄ View run grateful-sweep-22 at: https://wandb.ai/xiaoqiz/mof2vec/runs/4g7rgbhk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_185108-4g7rgbhk/logs
wandb: Agent Starting Run: 71lq2do5 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 961
wandb: 	model.gensim.alpha: 0.0021668802171658824
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.8648599076618593
wandb: 	model.gensim.vector_size: 217
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.0012063244238465932
wandb: 	model.sklearn.max_depth: 8
wandb: 	model.sklearn.min_child_weight: 0.04209593214903703
wandb: 	model.sklearn.n_estimators: 4924
wandb: 	model.sklearn.num_leaves: 247
wandb: 	model.sklearn.reg_alpha: 0.15115395666366463
wandb: 	model.sklearn.reg_lambda: 0.012757793720953512
wandb: 	model.sklearn.subsample: 0.7215920473360624
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185246-71lq2do5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/71lq2do5
2023-02-07 18:52:54.741 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 18:52:54.742 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 961 for sweep.
2023-02-07 18:52:54.742 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0021668802171658824 for sweep.
2023-02-07 18:52:54.743 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:52:54.743 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 18:52:54.743 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8648599076618593 for sweep.
2023-02-07 18:52:54.743 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 217 for sweep.
2023-02-07 18:52:54.744 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 18:52:54.744 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0012063244238465932 for sweep.
2023-02-07 18:52:54.744 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 8 for sweep.
2023-02-07 18:52:54.744 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.04209593214903703 for sweep.
2023-02-07 18:52:54.745 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4924 for sweep.
2023-02-07 18:52:54.745 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 247 for sweep.
2023-02-07 18:52:54.745 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.15115395666366463 for sweep.
2023-02-07 18:52:54.745 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.012757793720953512 for sweep.
2023-02-07 18:52:54.745 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7215920473360624 for sweep.
2023-02-07 18:52:54.746 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:52:54.750 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185246-71lq2do5/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 961, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 217, 'window': 2, 'min_count': 5, 'dm': 1, 'sample': 0.8648599076618593, 'workers': 4, 'alpha': 0.0021668802171658824, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4924, 'max_depth': 8, 'num_leaves': 247, 'reg_alpha': 0.15115395666366463, 'reg_lambda': 0.012757793720953512, 'subsample': 0.7215920473360624, 'min_child_weight': 0.04209593214903703, 'n_jobs': 4, 'learning_rate': 0.0012063244238465932}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 22/3257 [00:00<00:15, 214.58it/s]  1%|‚ñè         | 44/3257 [00:00<00:15, 205.45it/s]  2%|‚ñè         | 67/3257 [00:00<00:15, 206.40it/s]  3%|‚ñé         | 92/3257 [00:00<00:14, 221.42it/s]  4%|‚ñé         | 115/3257 [00:00<00:15, 206.26it/s]  4%|‚ñç         | 136/3257 [00:00<00:15, 205.00it/s]  5%|‚ñç         | 159/3257 [00:00<00:14, 210.49it/s]  6%|‚ñå         | 181/3257 [00:00<00:15, 201.37it/s]  6%|‚ñã         | 204/3257 [00:00<00:14, 208.12it/s]  7%|‚ñã         | 232/3257 [00:01<00:13, 227.65it/s]  8%|‚ñä         | 256/3257 [00:01<00:13, 229.93it/s]  9%|‚ñä         | 282/3257 [00:01<00:12, 234.78it/s]  9%|‚ñâ         | 306/3257 [00:01<00:12, 230.70it/s] 10%|‚ñà         | 331/3257 [00:01<00:12, 236.21it/s] 11%|‚ñà         | 355/3257 [00:01<00:12, 232.14it/s] 12%|‚ñà‚ñè        | 379/3257 [00:01<00:13, 215.16it/s] 12%|‚ñà‚ñè        | 402/3257 [00:01<00:13, 216.97it/s] 13%|‚ñà‚ñé        | 424/3257 [00:01<00:13, 213.79it/s] 14%|‚ñà‚ñé        | 446/3257 [00:02<00:14, 196.22it/s] 14%|‚ñà‚ñç        | 470/3257 [00:02<00:13, 206.40it/s] 15%|‚ñà‚ñå        | 491/3257 [00:02<00:13, 205.81it/s] 16%|‚ñà‚ñå        | 516/3257 [00:02<00:12, 217.32it/s] 17%|‚ñà‚ñã        | 538/3257 [00:02<00:12, 214.44it/s] 17%|‚ñà‚ñã        | 560/3257 [00:02<00:13, 203.23it/s] 18%|‚ñà‚ñä        | 581/3257 [00:02<00:13, 197.59it/s] 19%|‚ñà‚ñä        | 606/3257 [00:02<00:12, 210.93it/s] 19%|‚ñà‚ñâ        | 628/3257 [00:02<00:12, 212.87it/s] 20%|‚ñà‚ñâ        | 651/3257 [00:03<00:12, 215.92it/s] 21%|‚ñà‚ñà        | 673/3257 [00:03<00:11, 217.10it/s] 21%|‚ñà‚ñà‚ñè       | 695/3257 [00:03<00:12, 212.65it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:03<00:11, 221.24it/s] 23%|‚ñà‚ñà‚ñé       | 743/3257 [00:03<00:11, 210.00it/s] 24%|‚ñà‚ñà‚ñé       | 768/3257 [00:03<00:11, 220.92it/s] 24%|‚ñà‚ñà‚ñç       | 791/3257 [00:03<00:11, 213.92it/s] 25%|‚ñà‚ñà‚ñç       | 814/3257 [00:03<00:11, 214.09it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:03<00:11, 205.89it/s] 26%|‚ñà‚ñà‚ñã       | 857/3257 [00:04<00:11, 200.67it/s] 27%|‚ñà‚ñà‚ñã       | 878/3257 [00:04<00:12, 193.61it/s] 28%|‚ñà‚ñà‚ñä       | 904/3257 [00:04<00:11, 211.16it/s] 28%|‚ñà‚ñà‚ñä       | 926/3257 [00:04<00:10, 212.55it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:04<00:11, 207.84it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:04<00:10, 213.55it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:04<00:10, 211.32it/s] 31%|‚ñà‚ñà‚ñà       | 1016/3257 [00:04<00:10, 207.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1037/3257 [00:04<00:11, 199.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1058/3257 [00:05<00:11, 196.48it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:05<00:10, 197.92it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1102/3257 [00:05<00:10, 203.65it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:05<00:10, 201.04it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:05<00:10, 196.61it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1167/3257 [00:05<00:10, 205.98it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:05<00:16, 122.27it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:05<00:15, 134.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1231/3257 [00:06<00:12, 157.28it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1251/3257 [00:06<00:12, 160.67it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:06<00:11, 170.25it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:06<00:12, 163.58it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:06<00:11, 169.33it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1331/3257 [00:06<00:10, 182.44it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1352/3257 [00:06<00:10, 188.58it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1372/3257 [00:06<00:10, 187.38it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1392/3257 [00:06<00:09, 189.35it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1419/3257 [00:07<00:08, 211.49it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1441/3257 [00:07<00:08, 203.24it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1465/3257 [00:07<00:08, 212.81it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1487/3257 [00:07<00:08, 211.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1512/3257 [00:07<00:07, 220.28it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1535/3257 [00:07<00:08, 197.78it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1556/3257 [00:07<00:08, 194.15it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1576/3257 [00:07<00:08, 193.43it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1598/3257 [00:07<00:08, 198.78it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:08<00:08, 201.87it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1640/3257 [00:08<00:08, 198.03it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1660/3257 [00:08<00:08, 188.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1680/3257 [00:08<00:08, 181.87it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:08<00:08, 183.79it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1720/3257 [00:08<00:08, 185.72it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1739/3257 [00:08<00:08, 174.94it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1760/3257 [00:08<00:08, 184.10it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1781/3257 [00:08<00:07, 190.56it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1801/3257 [00:09<00:07, 191.53it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:09<00:07, 189.85it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1841/3257 [00:09<00:07, 189.31it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1862/3257 [00:09<00:07, 194.64it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1884/3257 [00:09<00:06, 199.56it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1905/3257 [00:09<00:06, 201.76it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1926/3257 [00:09<00:06, 195.93it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:09<00:06, 216.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1976/3257 [00:09<00:05, 216.20it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1998/3257 [00:09<00:05, 210.66it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2020/3257 [00:10<00:05, 209.12it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2041/3257 [00:10<00:06, 194.76it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2061/3257 [00:10<00:06, 182.50it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:10<00:06, 188.73it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2103/3257 [00:10<00:06, 186.37it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2122/3257 [00:10<00:06, 181.10it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2142/3257 [00:10<00:05, 185.87it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2161/3257 [00:10<00:05, 184.84it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2182/3257 [00:10<00:05, 187.60it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2205/3257 [00:11<00:05, 198.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2225/3257 [00:11<00:05, 190.59it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2245/3257 [00:11<00:05, 188.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2265/3257 [00:11<00:05, 189.42it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2284/3257 [00:11<00:05, 187.58it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2303/3257 [00:11<00:05, 186.12it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2327/3257 [00:11<00:04, 201.18it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2353/3257 [00:11<00:04, 216.08it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2375/3257 [00:11<00:04, 213.01it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:12<00:03, 217.93it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2421/3257 [00:12<00:04, 206.70it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2442/3257 [00:12<00:04, 188.34it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2465/3257 [00:12<00:04, 197.04it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2486/3257 [00:12<00:03, 195.20it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2511/3257 [00:12<00:03, 208.69it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2535/3257 [00:12<00:03, 216.43it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2557/3257 [00:12<00:03, 204.52it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2578/3257 [00:13<00:05, 115.77it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2597/3257 [00:13<00:05, 128.95it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2625/3257 [00:13<00:03, 159.25it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2646/3257 [00:13<00:03, 163.73it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2666/3257 [00:13<00:03, 169.97it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2688/3257 [00:13<00:03, 182.31it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:13<00:03, 168.87it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:14<00:02, 180.08it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:14<00:02, 191.53it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2777/3257 [00:14<00:02, 187.20it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:14<00:02, 204.16it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2825/3257 [00:14<00:02, 192.68it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2846/3257 [00:14<00:02, 197.06it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2875/3257 [00:14<00:01, 221.34it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2898/3257 [00:14<00:01, 209.59it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:14<00:01, 209.77it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2942/3257 [00:15<00:01, 209.70it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2964/3257 [00:15<00:01, 197.76it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:15<00:01, 190.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3009/3257 [00:15<00:01, 202.75it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3030/3257 [00:15<00:01, 198.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3054/3257 [00:15<00:00, 208.05it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3079/3257 [00:15<00:00, 217.14it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3101/3257 [00:15<00:00, 217.61it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3126/3257 [00:15<00:00, 226.59it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3149/3257 [00:16<00:00, 205.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3171/3257 [00:16<00:00, 207.35it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3193/3257 [00:16<00:00, 208.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3215/3257 [00:16<00:00, 189.86it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:16<00:00, 202.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 196.84it/s]
2023-02-07 18:53:12.015 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:53:12,017][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d217,n5,w2,mc5,s0.86486,t4>', 'datetime': '2023-02-07T18:53:12.017617', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:53:12,017][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:53:12,018][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:53:12,483][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 18:53:12,484][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:53:12,530][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 16108 unique words (50.65% of original 31803, drops 15695)', 'datetime': '2023-02-07T18:53:12.530447', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:53:12,530][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5056108 word corpus (99.23% of original 5095118, drops 39010)', 'datetime': '2023-02-07T18:53:12.530863', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:53:12,586][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 18:53:12,587][gensim.models.word2vec][INFO] - sample=0.86486 downsamples 0 most-common words
[2023-02-07 18:53:12,587][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5056108 word corpus (100.0%% of prior 5056108)', 'datetime': '2023-02-07T18:53:12.587336', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:53:12,681][gensim.models.word2vec][INFO] - estimated required memory for 16108 words and 217 dimensions: 39495964 bytes
[2023-02-07 18:53:12,682][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:53:12,700][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 16108 vocabulary and 217 features, using sg=0 hs=0 sample=0.8648599076618593 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T18:53:12.700572', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:53:13,704][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 36.48% examples, 1883293 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:14,713][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 77.06% examples, 1956808 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:15,241][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5048130 effective words) took 2.5s, 1988517 effective words/s
[2023-02-07 18:53:16,245][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 40.96% examples, 2111705 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:17,250][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 83.48% examples, 2120263 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:17,600][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5048130 effective words) took 2.4s, 2140856 effective words/s
[2023-02-07 18:53:18,602][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 42.28% examples, 2197134 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:19,603][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 86.67% examples, 2203409 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:19,890][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5048130 effective words) took 2.3s, 2205909 effective words/s
[2023-02-07 18:53:20,892][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 41.94% examples, 2177319 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:21,897][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 86.77% examples, 2204100 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:22,174][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5048130 effective words) took 2.3s, 2211158 effective words/s
[2023-02-07 18:53:23,186][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 43.81% examples, 2246829 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:53:24,186][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 89.93% examples, 2272110 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:24,397][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5048130 effective words) took 2.2s, 2273144 effective words/s
[2023-02-07 18:53:25,398][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 43.84% examples, 2268611 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:26,398][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 91.00% examples, 2313806 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:26,599][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5048130 effective words) took 2.2s, 2293510 effective words/s
[2023-02-07 18:53:27,602][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.47% examples, 1987926 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:28,608][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 78.54% examples, 1995566 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:29,128][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5048130 effective words) took 2.5s, 1997584 effective words/s
[2023-02-07 18:53:30,132][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 38.29% examples, 1976823 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:31,133][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 77.96% examples, 1982939 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:31,666][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5048130 effective words) took 2.5s, 1990675 effective words/s
[2023-02-07 18:53:32,673][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 39.18% examples, 2021055 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:33,676][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 79.52% examples, 2024103 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:34,158][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5048130 effective words) took 2.5s, 2027060 effective words/s
[2023-02-07 18:53:35,164][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 38.47% examples, 1982339 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:36,165][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 78.08% examples, 1985100 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:36,698][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5048130 effective words) took 2.5s, 1988803 effective words/s
[2023-02-07 18:53:37,708][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 39.18% examples, 2015118 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:38,710][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 80.66% examples, 2041783 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:39,172][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5048130 effective words) took 2.5s, 2041962 effective words/s
[2023-02-07 18:53:40,182][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 40.50% examples, 2085096 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:41,184][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 92.29% examples, 2331841 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:41,318][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5048130 effective words) took 2.1s, 2354677 effective words/s
[2023-02-07 18:53:42,320][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 47.22% examples, 2431237 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:43,320][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 92.78% examples, 2357192 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:43,469][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5048130 effective words) took 2.1s, 2348376 effective words/s
[2023-02-07 18:53:44,472][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 43.23% examples, 2241197 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:45,473][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 87.29% examples, 2221488 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:45,740][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5048130 effective words) took 2.3s, 2224187 effective words/s
[2023-02-07 18:53:46,745][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 44.15% examples, 2279795 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:47,746][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 89.93% examples, 2279570 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:47,954][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5048130 effective words) took 2.2s, 2282396 effective words/s
[2023-02-07 18:53:47,954][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75721950 effective words) took 35.3s, 2147918 effective words/s', 'datetime': '2023-02-07T18:53:47.954674', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:53:47.954 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:53:51,138][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185246-71lq2do5/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:53:51.138767', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:53:51,139][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:53:51,195][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185246-71lq2do5/files/../tmp/embedding_model.pt
2023-02-07 18:53:51.195 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:53:52.833 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:53:53.418 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:54:03.107 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1202550063646954, 'test_mae': 0.81870710049853, 'test_r2': -3.7353031118098086}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.46
wandb: percentage 0.49351
wandb:   test_mae 0.81871
wandb:   test_mse 1.12026
wandb:    test_r2 -3.7353
wandb: 
wandb: üöÄ View run robust-sweep-23 at: https://wandb.ai/xiaoqiz/mof2vec/runs/71lq2do5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_185246-71lq2do5/logs
wandb: Agent Starting Run: z5vt0jey with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 577
wandb: 	model.gensim.alpha: 0.05179763316309034
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.2958332166581077
wandb: 	model.gensim.vector_size: 121
wandb: 	model.gensim.window: 6
wandb: 	model.sklearn.learning_rate: 0.003407177712175693
wandb: 	model.sklearn.max_depth: 55
wandb: 	model.sklearn.min_child_weight: 0.04638885839880756
wandb: 	model.sklearn.n_estimators: 626
wandb: 	model.sklearn.num_leaves: 190
wandb: 	model.sklearn.reg_alpha: 0.11395304379295056
wandb: 	model.sklearn.reg_lambda: 0.028954548794314923
wandb: 	model.sklearn.subsample: 0.28111764339743606
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185421-z5vt0jey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/z5vt0jey
2023-02-07 18:54:29.287 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 18:54:29.288 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 577 for sweep.
2023-02-07 18:54:29.288 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.05179763316309034 for sweep.
2023-02-07 18:54:29.289 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:54:29.289 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 18:54:29.289 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2958332166581077 for sweep.
2023-02-07 18:54:29.289 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 121 for sweep.
2023-02-07 18:54:29.289 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 6 for sweep.
2023-02-07 18:54:29.290 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.003407177712175693 for sweep.
2023-02-07 18:54:29.290 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 55 for sweep.
2023-02-07 18:54:29.291 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.04638885839880756 for sweep.
2023-02-07 18:54:29.291 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 626 for sweep.
2023-02-07 18:54:29.291 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 190 for sweep.
2023-02-07 18:54:29.291 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.11395304379295056 for sweep.
2023-02-07 18:54:29.291 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.028954548794314923 for sweep.
2023-02-07 18:54:29.292 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.28111764339743606 for sweep.
2023-02-07 18:54:29.292 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:54:29.299 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185421-z5vt0jey/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 577, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 121, 'window': 6, 'min_count': 1, 'dm': 1, 'sample': 0.2958332166581077, 'workers': 4, 'alpha': 0.05179763316309034, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 626, 'max_depth': 55, 'num_leaves': 190, 'reg_alpha': 0.11395304379295056, 'reg_lambda': 0.028954548794314923, 'subsample': 0.28111764339743606, 'min_child_weight': 0.04638885839880756, 'n_jobs': 4, 'learning_rate': 0.003407177712175693}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 24/3257 [00:00<00:13, 233.10it/s]  1%|‚ñè         | 48/3257 [00:00<00:13, 230.94it/s]  2%|‚ñè         | 72/3257 [00:00<00:14, 225.16it/s]  3%|‚ñé         | 97/3257 [00:00<00:13, 233.33it/s]  4%|‚ñé         | 121/3257 [00:00<00:13, 227.71it/s]  5%|‚ñç         | 149/3257 [00:00<00:12, 243.10it/s]  5%|‚ñå         | 174/3257 [00:00<00:13, 229.84it/s]  6%|‚ñå         | 201/3257 [00:00<00:13, 234.93it/s]  7%|‚ñã         | 234/3257 [00:00<00:11, 261.50it/s]  8%|‚ñä         | 261/3257 [00:01<00:11, 253.05it/s]  9%|‚ñâ         | 291/3257 [00:01<00:11, 264.82it/s] 10%|‚ñâ         | 318/3257 [00:01<00:11, 261.03it/s] 11%|‚ñà         | 345/3257 [00:01<00:11, 253.35it/s] 11%|‚ñà‚ñè        | 373/3257 [00:01<00:11, 259.91it/s] 12%|‚ñà‚ñè        | 400/3257 [00:01<00:12, 228.92it/s] 13%|‚ñà‚ñé        | 424/3257 [00:01<00:12, 218.20it/s] 14%|‚ñà‚ñé        | 447/3257 [00:01<00:14, 191.98it/s] 14%|‚ñà‚ñç        | 470/3257 [00:02<00:13, 199.22it/s] 15%|‚ñà‚ñå        | 491/3257 [00:02<00:14, 195.92it/s] 16%|‚ñà‚ñå        | 512/3257 [00:02<00:13, 199.34it/s] 16%|‚ñà‚ñã        | 533/3257 [00:02<00:14, 192.89it/s] 17%|‚ñà‚ñã        | 553/3257 [00:02<00:14, 191.19it/s] 18%|‚ñà‚ñä        | 573/3257 [00:02<00:15, 172.88it/s] 18%|‚ñà‚ñä        | 595/3257 [00:02<00:14, 184.28it/s] 19%|‚ñà‚ñâ        | 617/3257 [00:02<00:13, 192.67it/s] 20%|‚ñà‚ñâ        | 637/3257 [00:02<00:13, 189.97it/s] 20%|‚ñà‚ñà        | 657/3257 [00:03<00:14, 174.20it/s] 21%|‚ñà‚ñà        | 678/3257 [00:03<00:14, 181.89it/s] 21%|‚ñà‚ñà‚ñè       | 697/3257 [00:03<00:14, 179.30it/s] 22%|‚ñà‚ñà‚ñè       | 719/3257 [00:03<00:13, 190.00it/s] 23%|‚ñà‚ñà‚ñé       | 739/3257 [00:03<00:14, 174.69it/s] 23%|‚ñà‚ñà‚ñé       | 761/3257 [00:03<00:13, 186.45it/s] 24%|‚ñà‚ñà‚ñç       | 781/3257 [00:03<00:21, 113.01it/s] 25%|‚ñà‚ñà‚ñç       | 801/3257 [00:04<00:19, 129.24it/s] 25%|‚ñà‚ñà‚ñå       | 819/3257 [00:04<00:17, 139.41it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:04<00:16, 143.63it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:04<00:16, 146.63it/s] 27%|‚ñà‚ñà‚ñã       | 873/3257 [00:04<00:15, 158.63it/s] 27%|‚ñà‚ñà‚ñã       | 891/3257 [00:04<00:14, 162.19it/s] 28%|‚ñà‚ñà‚ñä       | 913/3257 [00:04<00:13, 176.84it/s] 29%|‚ñà‚ñà‚ñä       | 932/3257 [00:04<00:13, 175.91it/s] 29%|‚ñà‚ñà‚ñâ       | 953/3257 [00:04<00:12, 184.62it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:05<00:12, 184.78it/s] 30%|‚ñà‚ñà‚ñà       | 991/3257 [00:05<00:12, 182.69it/s] 31%|‚ñà‚ñà‚ñà       | 1010/3257 [00:05<00:12, 180.69it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1029/3257 [00:05<00:12, 181.26it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1048/3257 [00:05<00:12, 176.64it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:05<00:12, 179.67it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1086/3257 [00:05<00:11, 181.80it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1106/3257 [00:05<00:11, 186.08it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1125/3257 [00:05<00:11, 182.50it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:05<00:11, 182.79it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1165/3257 [00:06<00:11, 189.43it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1184/3257 [00:06<00:11, 177.16it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1202/3257 [00:06<00:12, 167.71it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:06<00:12, 168.21it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:06<00:10, 187.16it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1263/3257 [00:06<00:10, 190.00it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1283/3257 [00:06<00:11, 179.06it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1302/3257 [00:06<00:10, 179.75it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1322/3257 [00:06<00:10, 185.42it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1343/3257 [00:07<00:09, 191.92it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1363/3257 [00:07<00:09, 190.07it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1383/3257 [00:07<00:10, 182.05it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1404/3257 [00:07<00:09, 189.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1429/3257 [00:07<00:08, 204.28it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1451/3257 [00:07<00:08, 207.51it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:07<00:08, 213.40it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:07<00:08, 214.77it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1518/3257 [00:07<00:08, 210.42it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1540/3257 [00:08<00:08, 192.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1560/3257 [00:08<00:09, 187.26it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1580/3257 [00:08<00:08, 188.80it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1602/3257 [00:08<00:08, 197.26it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1623/3257 [00:08<00:08, 198.55it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1643/3257 [00:08<00:08, 197.04it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1663/3257 [00:08<00:08, 190.82it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1683/3257 [00:08<00:08, 188.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1704/3257 [00:08<00:08, 193.27it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1725/3257 [00:08<00:07, 196.83it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:09<00:08, 177.26it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1766/3257 [00:09<00:08, 184.66it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:09<00:07, 199.80it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1811/3257 [00:09<00:07, 189.01it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1831/3257 [00:09<00:07, 187.84it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1852/3257 [00:09<00:07, 192.90it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1876/3257 [00:09<00:06, 203.55it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:09<00:06, 194.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1917/3257 [00:09<00:06, 192.96it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1941/3257 [00:10<00:06, 205.88it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:10<00:06, 213.66it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1987/3257 [00:10<00:06, 209.05it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2009/3257 [00:10<00:05, 211.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:10<00:05, 214.57it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:10<00:06, 192.11it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2075/3257 [00:10<00:06, 191.24it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2095/3257 [00:10<00:06, 191.47it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2116/3257 [00:10<00:05, 194.77it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:11<00:06, 185.20it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2155/3257 [00:11<00:10, 107.57it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:11<00:08, 128.46it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2200/3257 [00:11<00:07, 146.83it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:11<00:06, 155.62it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:11<00:06, 163.79it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:11<00:05, 173.47it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2278/3257 [00:12<00:05, 174.38it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2300/3257 [00:12<00:05, 186.61it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2326/3257 [00:12<00:04, 206.47it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2352/3257 [00:12<00:04, 220.45it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2375/3257 [00:12<00:04, 217.29it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:12<00:03, 220.54it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:12<00:03, 210.75it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2444/3257 [00:12<00:04, 202.11it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2468/3257 [00:12<00:03, 211.42it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2490/3257 [00:13<00:03, 211.71it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:13<00:03, 218.50it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2539/3257 [00:13<00:03, 225.49it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2562/3257 [00:13<00:03, 209.51it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2584/3257 [00:13<00:03, 203.36it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2607/3257 [00:13<00:03, 210.33it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2633/3257 [00:13<00:02, 223.56it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:13<00:02, 210.24it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2678/3257 [00:13<00:02, 204.39it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2699/3257 [00:14<00:02, 193.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:14<00:02, 192.14it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2744/3257 [00:14<00:02, 205.90it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2766/3257 [00:14<00:02, 208.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2789/3257 [00:14<00:02, 213.49it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:14<00:02, 217.09it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:14<00:01, 223.60it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:14<00:01, 260.10it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2899/3257 [00:14<00:01, 260.23it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:15<00:01, 265.40it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2955/3257 [00:15<00:01, 257.77it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2981/3257 [00:15<00:01, 256.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:15<00:00, 267.20it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3043/3257 [00:15<00:00, 277.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:15<00:00, 288.21it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3106/3257 [00:15<00:00, 293.03it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3136/3257 [00:15<00:00, 290.60it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:15<00:00, 284.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3196/3257 [00:15<00:00, 287.09it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3225/3257 [00:16<00:00, 280.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 201.63it/s]
2023-02-07 18:54:45.935 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:54:45,936][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d121,n5,w6,s0.295833,t4>', 'datetime': '2023-02-07T18:54:45.936346', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:54:45,936][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:54:45,936][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:54:46,248][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 18:54:46,248][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:54:46,279][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 13061 unique words (100.00% of original 13061, drops 0)', 'datetime': '2023-02-07T18:54:46.279945', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:54:46,280][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3639370 word corpus (100.00% of original 3639370, drops 0)', 'datetime': '2023-02-07T18:54:46.280288', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:54:46,323][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 18:54:46,324][gensim.models.word2vec][INFO] - sample=0.295833 downsamples 0 most-common words
[2023-02-07 18:54:46,324][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3639370 word corpus (100.0%% of prior 3639370)', 'datetime': '2023-02-07T18:54:46.324655', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:54:46,397][gensim.models.word2vec][INFO] - estimated required memory for 13061 words and 121 dimensions: 21401336 bytes
[2023-02-07 18:54:46,397][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:54:46,405][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 13061 vocabulary and 121 features, using sg=0 hs=0 sample=0.2958332166581077 negative=5 window=6 shrink_windows=True', 'datetime': '2023-02-07T18:54:46.405827', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:54:47,411][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 61.59% examples, 2273088 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:48,035][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3642627 effective words) took 1.6s, 2238370 effective words/s
[2023-02-07 18:54:49,039][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 58.00% examples, 2157489 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:49,708][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3642627 effective words) took 1.7s, 2179138 effective words/s
[2023-02-07 18:54:50,711][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 60.30% examples, 2231005 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:51,345][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3642627 effective words) took 1.6s, 2228812 effective words/s
[2023-02-07 18:54:52,351][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 59.90% examples, 2213181 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:52,986][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3642627 effective words) took 1.6s, 2220789 effective words/s
[2023-02-07 18:54:53,997][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 61.59% examples, 2261382 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:54:54,587][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3642627 effective words) took 1.6s, 2278969 effective words/s
[2023-02-07 18:54:55,590][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 62.82% examples, 2319716 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:56,158][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3642627 effective words) took 1.6s, 2319915 effective words/s
[2023-02-07 18:54:57,162][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 61.87% examples, 2285337 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:57,740][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3642627 effective words) took 1.6s, 2304635 effective words/s
[2023-02-07 18:54:58,744][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 62.82% examples, 2316964 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:59,306][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3642627 effective words) took 1.6s, 2327963 effective words/s
[2023-02-07 18:55:00,308][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 63.37% examples, 2350603 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:00,861][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3642627 effective words) took 1.6s, 2344137 effective words/s
[2023-02-07 18:55:01,865][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 63.68% examples, 2354578 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:02,471][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3642627 effective words) took 1.6s, 2264161 effective words/s
[2023-02-07 18:55:03,473][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 56.19% examples, 2101870 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:04,214][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3642627 effective words) took 1.7s, 2092536 effective words/s
[2023-02-07 18:55:05,220][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 56.19% examples, 2093721 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:05,949][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3642627 effective words) took 1.7s, 2101183 effective words/s
[2023-02-07 18:55:06,951][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 46.64% examples, 1729831 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:07,952][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 93.74% examples, 1713939 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:08,076][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3642627 effective words) took 2.1s, 1713812 effective words/s
[2023-02-07 18:55:09,084][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 55.51% examples, 2063450 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:09,809][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3642627 effective words) took 1.7s, 2105376 effective words/s
[2023-02-07 18:55:10,811][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 57.78% examples, 2153511 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:11,509][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3642627 effective words) took 1.7s, 2144096 effective words/s
[2023-02-07 18:55:11,511][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54639405 effective words) took 25.1s, 2176433 effective words/s', 'datetime': '2023-02-07T18:55:11.511263', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:55:11.511 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:55:13,823][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185421-z5vt0jey/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:55:13.823869', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:55:13,825][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:55:13,855][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185421-z5vt0jey/files/../tmp/embedding_model.pt
2023-02-07 18:55:13.856 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:55:15.151 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:55:15.575 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:55:17.508 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0788246711693212, 'test_mae': 0.8040144392774881, 'test_r2': -2.5998715350834583}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.85
wandb: percentage 0.0
wandb:   test_mae 0.80401
wandb:   test_mse 1.07882
wandb:    test_r2 -2.59987
wandb: 
wandb: üöÄ View run feasible-sweep-24 at: https://wandb.ai/xiaoqiz/mof2vec/runs/z5vt0jey
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_185421-z5vt0jey/logs
wandb: Agent Starting Run: m10dla2n with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 486
wandb: 	model.gensim.alpha: 0.4578341738868098
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.549060397412662
wandb: 	model.gensim.vector_size: 387
wandb: 	model.gensim.window: 1
wandb: 	model.sklearn.learning_rate: 0.0019927049749166484
wandb: 	model.sklearn.max_depth: 28
wandb: 	model.sklearn.min_child_weight: 0.0304627674858922
wandb: 	model.sklearn.n_estimators: 4775
wandb: 	model.sklearn.num_leaves: 63
wandb: 	model.sklearn.reg_alpha: 0.2382204991662384
wandb: 	model.sklearn.reg_lambda: 0.10107027585436112
wandb: 	model.sklearn.subsample: 0.7518420651431363
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185529-m10dla2n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-25
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/m10dla2n
2023-02-07 18:55:38.382 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 18:55:38.383 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 486 for sweep.
2023-02-07 18:55:38.383 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.4578341738868098 for sweep.
2023-02-07 18:55:38.384 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:55:38.385 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 18:55:38.385 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.549060397412662 for sweep.
2023-02-07 18:55:38.385 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 387 for sweep.
2023-02-07 18:55:38.385 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 1 for sweep.
2023-02-07 18:55:38.386 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0019927049749166484 for sweep.
2023-02-07 18:55:38.386 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 28 for sweep.
2023-02-07 18:55:38.386 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0304627674858922 for sweep.
2023-02-07 18:55:38.386 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4775 for sweep.
2023-02-07 18:55:38.387 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 63 for sweep.
2023-02-07 18:55:38.387 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.2382204991662384 for sweep.
2023-02-07 18:55:38.387 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.10107027585436112 for sweep.
2023-02-07 18:55:38.387 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7518420651431363 for sweep.
2023-02-07 18:55:38.388 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:55:38.400 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185529-m10dla2n/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 486, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 387, 'window': 1, 'min_count': 8, 'dm': 0, 'sample': 0.549060397412662, 'workers': 4, 'alpha': 0.4578341738868098, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4775, 'max_depth': 28, 'num_leaves': 63, 'reg_alpha': 0.2382204991662384, 'reg_lambda': 0.10107027585436112, 'subsample': 0.7518420651431363, 'min_child_weight': 0.0304627674858922, 'n_jobs': 4, 'learning_rate': 0.0019927049749166484}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 168.86it/s]  1%|          | 37/3257 [00:00<00:17, 183.98it/s]  2%|‚ñè         | 56/3257 [00:00<00:17, 182.86it/s]  2%|‚ñè         | 78/3257 [00:00<00:16, 197.13it/s]  3%|‚ñé         | 98/3257 [00:00<00:16, 193.53it/s]  4%|‚ñé         | 118/3257 [00:00<00:16, 189.77it/s]  4%|‚ñç         | 140/3257 [00:00<00:15, 198.10it/s]  5%|‚ñç         | 160/3257 [00:00<00:15, 195.23it/s]  6%|‚ñå         | 180/3257 [00:00<00:16, 189.04it/s]  6%|‚ñå         | 201/3257 [00:01<00:15, 193.18it/s]  7%|‚ñã         | 227/3257 [00:01<00:14, 211.42it/s]  8%|‚ñä         | 249/3257 [00:01<00:14, 212.60it/s]  8%|‚ñä         | 271/3257 [00:01<00:14, 203.10it/s]  9%|‚ñâ         | 297/3257 [00:01<00:13, 214.78it/s] 10%|‚ñâ         | 319/3257 [00:01<00:21, 139.48it/s] 10%|‚ñà         | 339/3257 [00:01<00:19, 151.29it/s] 11%|‚ñà         | 359/3257 [00:01<00:18, 159.33it/s] 12%|‚ñà‚ñè        | 378/3257 [00:02<00:18, 158.50it/s] 12%|‚ñà‚ñè        | 397/3257 [00:02<00:17, 166.04it/s] 13%|‚ñà‚ñé        | 419/3257 [00:02<00:15, 178.50it/s] 13%|‚ñà‚ñé        | 438/3257 [00:02<00:17, 163.21it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:16, 174.45it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:15, 180.16it/s] 15%|‚ñà‚ñå        | 502/3257 [00:02<00:14, 192.27it/s] 16%|‚ñà‚ñå        | 524/3257 [00:02<00:13, 196.72it/s] 17%|‚ñà‚ñã        | 546/3257 [00:02<00:13, 196.79it/s] 17%|‚ñà‚ñã        | 566/3257 [00:03<00:14, 190.07it/s] 18%|‚ñà‚ñä        | 586/3257 [00:03<00:14, 185.05it/s] 19%|‚ñà‚ñä        | 606/3257 [00:03<00:14, 189.13it/s] 19%|‚ñà‚ñâ        | 626/3257 [00:03<00:13, 188.57it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:14, 185.80it/s] 20%|‚ñà‚ñà        | 664/3257 [00:03<00:14, 177.77it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:14, 177.83it/s] 22%|‚ñà‚ñà‚ñè       | 702/3257 [00:03<00:14, 180.31it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:03<00:13, 181.31it/s] 23%|‚ñà‚ñà‚ñé       | 741/3257 [00:04<00:14, 173.94it/s] 23%|‚ñà‚ñà‚ñé       | 764/3257 [00:04<00:13, 189.32it/s] 24%|‚ñà‚ñà‚ñç       | 784/3257 [00:04<00:13, 182.65it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:13, 185.73it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:04<00:13, 183.06it/s] 26%|‚ñà‚ñà‚ñå       | 844/3257 [00:04<00:13, 178.49it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:04<00:13, 182.91it/s] 27%|‚ñà‚ñà‚ñã       | 883/3257 [00:04<00:12, 184.78it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:04<00:12, 192.20it/s] 28%|‚ñà‚ñà‚ñä       | 927/3257 [00:05<00:11, 200.05it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:05<00:11, 197.76it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:05<00:11, 201.01it/s] 30%|‚ñà‚ñà‚ñà       | 991/3257 [00:05<00:11, 193.30it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:05<00:11, 191.46it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1031/3257 [00:05<00:11, 192.42it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1054/3257 [00:05<00:10, 202.97it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:05<00:10, 216.00it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1107/3257 [00:05<00:09, 228.48it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1131/3257 [00:05<00:09, 229.83it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1158/3257 [00:06<00:08, 240.50it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1183/3257 [00:06<00:08, 238.65it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:06<00:09, 227.36it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1236/3257 [00:06<00:08, 245.08it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1261/3257 [00:06<00:08, 246.07it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1286/3257 [00:06<00:08, 234.54it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1311/3257 [00:06<00:08, 238.11it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:06<00:07, 249.55it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1365/3257 [00:06<00:07, 241.99it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1390/3257 [00:07<00:07, 243.26it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1421/3257 [00:07<00:07, 261.77it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1448/3257 [00:07<00:07, 257.52it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:07<00:10, 172.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1503/3257 [00:07<00:08, 197.91it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1527/3257 [00:07<00:08, 202.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:07<00:08, 207.44it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:07<00:07, 214.82it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1603/3257 [00:08<00:07, 231.86it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1631/3257 [00:08<00:06, 244.32it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:08<00:06, 231.16it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1681/3257 [00:08<00:07, 223.33it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:08<00:06, 231.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:08<00:06, 223.60it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1754/3257 [00:08<00:06, 225.35it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1783/3257 [00:08<00:06, 243.48it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1808/3257 [00:08<00:06, 234.20it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1832/3257 [00:09<00:06, 235.81it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1858/3257 [00:09<00:05, 241.01it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1886/3257 [00:09<00:05, 250.20it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1913/3257 [00:09<00:05, 255.02it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1939/3257 [00:09<00:05, 248.98it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1968/3257 [00:09<00:04, 259.92it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1995/3257 [00:09<00:05, 249.48it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2021/3257 [00:09<00:04, 247.25it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2046/3257 [00:09<00:05, 239.25it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2071/3257 [00:10<00:05, 226.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2095/3257 [00:10<00:05, 229.06it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2119/3257 [00:10<00:04, 229.52it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:10<00:05, 210.08it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:10<00:04, 222.41it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2195/3257 [00:10<00:04, 232.49it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:10<00:04, 231.01it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2243/3257 [00:10<00:04, 222.00it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2268/3257 [00:10<00:04, 227.65it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2291/3257 [00:10<00:04, 226.48it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:11<00:04, 225.35it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2344/3257 [00:11<00:03, 241.84it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2371/3257 [00:11<00:03, 247.66it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2400/3257 [00:11<00:03, 257.42it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2426/3257 [00:11<00:03, 244.18it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2451/3257 [00:11<00:03, 228.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2479/3257 [00:11<00:03, 242.14it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:11<00:02, 252.34it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2536/3257 [00:11<00:02, 261.85it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2563/3257 [00:12<00:02, 246.81it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2589/3257 [00:12<00:02, 234.09it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2621/3257 [00:12<00:02, 254.97it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2647/3257 [00:12<00:02, 247.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:12<00:02, 245.55it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2698/3257 [00:12<00:02, 230.76it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2722/3257 [00:12<00:02, 228.53it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2752/3257 [00:12<00:02, 247.89it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2778/3257 [00:12<00:01, 241.31it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:13<00:01, 251.94it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:13<00:01, 243.90it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2858/3257 [00:13<00:02, 149.94it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2888/3257 [00:13<00:02, 177.52it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2911/3257 [00:13<00:01, 187.56it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2937/3257 [00:13<00:01, 203.99it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2961/3257 [00:13<00:01, 208.78it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:14<00:01, 212.89it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:14<00:01, 229.07it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3041/3257 [00:14<00:00, 243.77it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3072/3257 [00:14<00:00, 260.78it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3099/3257 [00:14<00:00, 259.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3129/3257 [00:14<00:00, 268.33it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3157/3257 [00:14<00:00, 253.47it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:14<00:00, 237.77it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3209/3257 [00:14<00:00, 242.24it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3237/3257 [00:15<00:00, 249.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:15<00:00, 215.58it/s]
2023-02-07 18:55:53.992 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:55:53,993][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d387,n5,mc8,s0.54906,t4>', 'datetime': '2023-02-07T18:55:53.993328', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:55:53,993][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:55:53,993][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:55:54,320][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 18:55:54,320][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:55:54,336][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 5936 unique words (45.45% of original 13061, drops 7125)', 'datetime': '2023-02-07T18:55:54.336703', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:55:54,337][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 3618620 word corpus (99.43% of original 3639370, drops 20750)', 'datetime': '2023-02-07T18:55:54.337032', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:55:54,356][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 18:55:54,357][gensim.models.word2vec][INFO] - sample=0.54906 downsamples 0 most-common words
[2023-02-07 18:55:54,357][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3618620 word corpus (100.0%% of prior 3618620)', 'datetime': '2023-02-07T18:55:54.357719', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:55:54,392][gensim.models.word2vec][INFO] - estimated required memory for 5936 words and 387 dimensions: 27039092 bytes
[2023-02-07 18:55:54,392][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:55:54,407][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 5936 vocabulary and 387 features, using sg=1 hs=0 sample=0.549060397412662 negative=5 window=1 shrink_windows=True', 'datetime': '2023-02-07T18:55:54.407177', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:55:55,211][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3621877 effective words) took 0.8s, 4521188 effective words/s
[2023-02-07 18:55:55,981][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3621877 effective words) took 0.8s, 4710780 effective words/s
[2023-02-07 18:55:56,745][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3621877 effective words) took 0.8s, 4749536 effective words/s
[2023-02-07 18:55:57,516][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3621877 effective words) took 0.8s, 4707338 effective words/s
[2023-02-07 18:55:58,271][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3621877 effective words) took 0.8s, 4802063 effective words/s
[2023-02-07 18:55:59,036][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3621877 effective words) took 0.8s, 4742728 effective words/s
[2023-02-07 18:55:59,812][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3621877 effective words) took 0.8s, 4672204 effective words/s
[2023-02-07 18:56:00,679][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3621877 effective words) took 0.9s, 4186510 effective words/s
[2023-02-07 18:56:01,536][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3621877 effective words) took 0.9s, 4234425 effective words/s
[2023-02-07 18:56:02,394][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3621877 effective words) took 0.9s, 4225666 effective words/s
[2023-02-07 18:56:03,268][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3621877 effective words) took 0.9s, 4151320 effective words/s
[2023-02-07 18:56:04,152][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3621877 effective words) took 0.9s, 4104038 effective words/s
[2023-02-07 18:56:05,019][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3621877 effective words) took 0.9s, 4183465 effective words/s
[2023-02-07 18:56:05,873][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3621877 effective words) took 0.9s, 4248675 effective words/s
[2023-02-07 18:56:06,733][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3621877 effective words) took 0.9s, 4215303 effective words/s
[2023-02-07 18:56:06,734][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54328155 effective words) took 12.3s, 4407690 effective words/s', 'datetime': '2023-02-07T18:56:06.734233', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:56:06.734 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:56:08,588][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185529-m10dla2n/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:56:08.588456', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:56:08,589][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:56:08,631][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185529-m10dla2n/files/../tmp/embedding_model.pt
2023-02-07 18:56:08.631 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:56:10.906 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:56:11.733 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:56:14.260 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.240191699787606, 'test_mae': 0.862443191187879, 'test_r2': -3.7347629807553453}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.026 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.026 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.026 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.0
wandb: percentage 0.54552
wandb:   test_mae 0.86244
wandb:   test_mse 1.24019
wandb:    test_r2 -3.73476
wandb: 
wandb: üöÄ View run true-sweep-25 at: https://wandb.ai/xiaoqiz/mof2vec/runs/m10dla2n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_185529-m10dla2n/logs
wandb: Agent Starting Run: 27nb1f3j with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 546
wandb: 	model.gensim.alpha: 0.006070527263805297
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.22463270463250865
wandb: 	model.gensim.vector_size: 59
wandb: 	model.gensim.window: 4
wandb: 	model.sklearn.learning_rate: 0.0018854340919096351
wandb: 	model.sklearn.max_depth: 13
wandb: 	model.sklearn.min_child_weight: 0.0569300900508852
wandb: 	model.sklearn.n_estimators: 1572
wandb: 	model.sklearn.num_leaves: 309
wandb: 	model.sklearn.reg_alpha: 0.004026040481124858
wandb: 	model.sklearn.reg_lambda: 0.020156546860540588
wandb: 	model.sklearn.subsample: 0.5901737665972926
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185628-27nb1f3j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-26
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/27nb1f3j
2023-02-07 18:56:35.877 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 18:56:35.877 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 546 for sweep.
2023-02-07 18:56:35.878 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.006070527263805297 for sweep.
2023-02-07 18:56:35.878 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:56:35.878 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 18:56:35.878 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.22463270463250865 for sweep.
2023-02-07 18:56:35.879 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 59 for sweep.
2023-02-07 18:56:35.879 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 4 for sweep.
2023-02-07 18:56:35.879 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0018854340919096351 for sweep.
2023-02-07 18:56:35.879 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 13 for sweep.
2023-02-07 18:56:35.880 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0569300900508852 for sweep.
2023-02-07 18:56:35.880 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1572 for sweep.
2023-02-07 18:56:35.880 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 309 for sweep.
2023-02-07 18:56:35.881 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004026040481124858 for sweep.
2023-02-07 18:56:35.881 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.020156546860540588 for sweep.
2023-02-07 18:56:35.881 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5901737665972926 for sweep.
2023-02-07 18:56:35.881 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:56:35.886 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185628-27nb1f3j/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 546, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 59, 'window': 4, 'min_count': 2, 'dm': 0, 'sample': 0.22463270463250865, 'workers': 4, 'alpha': 0.006070527263805297, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1572, 'max_depth': 13, 'num_leaves': 309, 'reg_alpha': 0.004026040481124858, 'reg_lambda': 0.020156546860540588, 'subsample': 0.5901737665972926, 'min_child_weight': 0.0569300900508852, 'n_jobs': 4, 'learning_rate': 0.0018854340919096351}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 163.86it/s]  1%|          | 34/3257 [00:00<00:19, 165.88it/s]  2%|‚ñè         | 53/3257 [00:00<00:19, 167.23it/s]  2%|‚ñè         | 72/3257 [00:00<00:18, 174.30it/s]  3%|‚ñé         | 91/3257 [00:00<00:17, 178.07it/s]  3%|‚ñé         | 109/3257 [00:00<00:18, 166.94it/s]  4%|‚ñç         | 128/3257 [00:00<00:18, 172.52it/s]  5%|‚ñç         | 149/3257 [00:00<00:17, 181.14it/s]  5%|‚ñå         | 168/3257 [00:00<00:17, 172.23it/s]  6%|‚ñå         | 186/3257 [00:01<00:18, 168.94it/s]  6%|‚ñå         | 203/3257 [00:01<00:18, 166.40it/s]  7%|‚ñã         | 227/3257 [00:01<00:16, 186.59it/s]  8%|‚ñä         | 246/3257 [00:01<00:16, 186.39it/s]  8%|‚ñä         | 265/3257 [00:01<00:16, 178.42it/s]  9%|‚ñâ         | 290/3257 [00:01<00:15, 195.23it/s] 10%|‚ñâ         | 310/3257 [00:01<00:15, 187.51it/s] 10%|‚ñà         | 329/3257 [00:01<00:15, 186.30it/s] 11%|‚ñà         | 348/3257 [00:01<00:16, 176.84it/s] 11%|‚ñà‚ñè        | 368/3257 [00:02<00:15, 182.29it/s] 12%|‚ñà‚ñè        | 387/3257 [00:02<00:16, 169.42it/s] 13%|‚ñà‚ñé        | 408/3257 [00:02<00:15, 178.54it/s] 13%|‚ñà‚ñé        | 427/3257 [00:02<00:17, 159.42it/s] 14%|‚ñà‚ñé        | 445/3257 [00:02<00:17, 164.20it/s] 14%|‚ñà‚ñç        | 465/3257 [00:02<00:16, 171.71it/s] 15%|‚ñà‚ñç        | 483/3257 [00:02<00:16, 168.48it/s] 16%|‚ñà‚ñå        | 505/3257 [00:02<00:15, 180.54it/s] 16%|‚ñà‚ñå        | 524/3257 [00:02<00:14, 182.26it/s] 17%|‚ñà‚ñã        | 543/3257 [00:03<00:14, 184.30it/s] 17%|‚ñà‚ñã        | 562/3257 [00:03<00:15, 168.50it/s] 18%|‚ñà‚ñä        | 580/3257 [00:03<00:16, 163.39it/s] 18%|‚ñà‚ñä        | 600/3257 [00:03<00:15, 172.64it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:15, 170.81it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:03<00:14, 178.05it/s] 20%|‚ñà‚ñà        | 659/3257 [00:03<00:16, 161.61it/s] 21%|‚ñà‚ñà        | 680/3257 [00:03<00:14, 172.67it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:04<00:15, 161.94it/s] 22%|‚ñà‚ñà‚ñè       | 719/3257 [00:04<00:14, 173.48it/s] 23%|‚ñà‚ñà‚ñé       | 737/3257 [00:04<00:15, 157.99it/s] 23%|‚ñà‚ñà‚ñé       | 755/3257 [00:04<00:15, 163.40it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:04<00:15, 165.30it/s] 24%|‚ñà‚ñà‚ñç       | 790/3257 [00:04<00:14, 165.56it/s] 25%|‚ñà‚ñà‚ñç       | 807/3257 [00:04<00:15, 161.19it/s] 25%|‚ñà‚ñà‚ñå       | 824/3257 [00:04<00:23, 105.52it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:05<00:21, 114.77it/s] 26%|‚ñà‚ñà‚ñå       | 854/3257 [00:05<00:20, 118.95it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:05<00:18, 131.03it/s] 27%|‚ñà‚ñà‚ñã       | 887/3257 [00:05<00:17, 137.72it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:05<00:15, 152.38it/s] 28%|‚ñà‚ñà‚ñä       | 925/3257 [00:05<00:14, 159.73it/s] 29%|‚ñà‚ñà‚ñâ       | 942/3257 [00:05<00:14, 156.37it/s] 30%|‚ñà‚ñà‚ñâ       | 961/3257 [00:05<00:13, 165.21it/s] 30%|‚ñà‚ñà‚ñà       | 979/3257 [00:05<00:13, 163.90it/s] 31%|‚ñà‚ñà‚ñà       | 996/3257 [00:06<00:14, 160.56it/s] 31%|‚ñà‚ñà‚ñà       | 1013/3257 [00:06<00:13, 161.10it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1030/3257 [00:06<00:14, 156.85it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:06<00:14, 152.60it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:06<00:14, 154.52it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:14, 155.30it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:06<00:13, 157.47it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:06<00:13, 163.75it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1132/3257 [00:06<00:14, 151.78it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1148/3257 [00:07<00:13, 150.67it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:12, 161.95it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:07<00:13, 155.30it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1203/3257 [00:07<00:14, 145.42it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:07<00:13, 147.86it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:07<00:12, 166.86it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1259/3257 [00:07<00:12, 163.35it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1276/3257 [00:07<00:12, 158.71it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:07<00:12, 153.19it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:08<00:12, 154.15it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:08<00:11, 162.89it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1348/3257 [00:08<00:11, 172.20it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1366/3257 [00:08<00:11, 163.30it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1383/3257 [00:08<00:11, 158.99it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:08<00:11, 165.17it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:08<00:10, 177.26it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1441/3257 [00:08<00:10, 175.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:08<00:09, 188.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1482/3257 [00:09<00:09, 187.63it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1503/3257 [00:09<00:09, 192.76it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1523/3257 [00:09<00:09, 174.34it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1541/3257 [00:09<00:10, 168.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1559/3257 [00:09<00:10, 162.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1576/3257 [00:09<00:10, 161.32it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:09<00:09, 169.40it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:09<00:09, 175.94it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:09<00:09, 166.39it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1652/3257 [00:10<00:09, 162.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1669/3257 [00:10<00:09, 161.28it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1686/3257 [00:10<00:10, 156.38it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1705/3257 [00:10<00:09, 164.20it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:10<00:09, 166.82it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1740/3257 [00:10<00:10, 149.44it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1760/3257 [00:10<00:09, 160.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1777/3257 [00:10<00:09, 162.70it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:10<00:08, 169.39it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:11<00:08, 162.66it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1831/3257 [00:11<00:08, 160.98it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1850/3257 [00:11<00:08, 167.76it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:11<00:08, 173.03it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1887/3257 [00:11<00:07, 173.01it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1906/3257 [00:11<00:07, 176.43it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1924/3257 [00:11<00:07, 169.99it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1948/3257 [00:11<00:07, 186.74it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1970/3257 [00:11<00:06, 195.87it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1990/3257 [00:12<00:06, 181.05it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2009/3257 [00:12<00:07, 178.13it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2030/3257 [00:12<00:06, 186.36it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2049/3257 [00:12<00:07, 166.20it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2067/3257 [00:12<00:07, 156.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:12<00:07, 157.80it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2102/3257 [00:12<00:07, 156.99it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:13<00:12, 92.50it/s]  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:13<00:10, 105.93it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2153/3257 [00:13<00:09, 116.55it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2172/3257 [00:13<00:08, 132.83it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2188/3257 [00:13<00:07, 138.24it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2207/3257 [00:13<00:07, 149.32it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2224/3257 [00:13<00:06, 154.01it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2241/3257 [00:13<00:06, 153.47it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:13<00:06, 158.67it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2277/3257 [00:14<00:06, 152.98it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:14<00:05, 165.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2321/3257 [00:14<00:05, 178.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2343/3257 [00:14<00:04, 189.06it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2366/3257 [00:14<00:04, 198.88it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2387/3257 [00:14<00:04, 199.24it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2408/3257 [00:14<00:04, 187.99it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2428/3257 [00:14<00:04, 181.64it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2447/3257 [00:14<00:04, 172.16it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2467/3257 [00:15<00:04, 178.81it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2486/3257 [00:15<00:04, 177.72it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2508/3257 [00:15<00:04, 186.68it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2527/3257 [00:15<00:03, 186.62it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2546/3257 [00:15<00:03, 186.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2565/3257 [00:15<00:03, 173.14it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2583/3257 [00:15<00:04, 163.33it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:15<00:04, 161.04it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2623/3257 [00:15<00:03, 178.06it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2642/3257 [00:16<00:03, 173.95it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2660/3257 [00:16<00:03, 163.86it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2680/3257 [00:16<00:03, 170.67it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2698/3257 [00:16<00:03, 157.23it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2715/3257 [00:16<00:03, 152.53it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2737/3257 [00:16<00:03, 169.89it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:16<00:02, 171.50it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:16<00:03, 160.73it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:17<00:02, 172.03it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:17<00:02, 167.85it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2830/3257 [00:17<00:02, 156.96it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2846/3257 [00:17<00:02, 154.80it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2869/3257 [00:17<00:02, 174.42it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2887/3257 [00:17<00:02, 167.42it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2904/3257 [00:17<00:02, 154.89it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2926/3257 [00:17<00:01, 171.19it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2944/3257 [00:17<00:02, 154.90it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2962/3257 [00:18<00:01, 161.16it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2979/3257 [00:18<00:01, 159.19it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2999/3257 [00:18<00:01, 169.50it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3017/3257 [00:18<00:01, 169.01it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3038/3257 [00:18<00:01, 178.08it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3058/3257 [00:18<00:01, 182.78it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3079/3257 [00:18<00:00, 189.08it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3099/3257 [00:18<00:00, 184.88it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3122/3257 [00:18<00:00, 195.04it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3142/3257 [00:19<00:00, 187.10it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3161/3257 [00:19<00:00, 182.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3180/3257 [00:19<00:00, 170.06it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3201/3257 [00:19<00:00, 179.95it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3220/3257 [00:19<00:00, 170.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:19<00:00, 185.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 165.52it/s]
2023-02-07 18:56:56.493 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:56:56,495][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d59,n5,mc2,s0.224633,t4>', 'datetime': '2023-02-07T18:56:56.495011', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:56:56,495][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:56:56,495][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:56:57,105][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 18:56:57,106][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:56:57,229][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 46469 unique words (85.97% of original 54054, drops 7585)', 'datetime': '2023-02-07T18:56:57.229540', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:56:57,230][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 6543281 word corpus (99.88% of original 6550866, drops 7585)', 'datetime': '2023-02-07T18:56:57.229987', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:56:57,392][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 18:56:57,393][gensim.models.word2vec][INFO] - sample=0.224633 downsamples 0 most-common words
[2023-02-07 18:56:57,394][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6543281 word corpus (100.0%% of prior 6543281)', 'datetime': '2023-02-07T18:56:57.394926', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:56:57,673][gensim.models.word2vec][INFO] - estimated required memory for 46469 words and 59 dimensions: 46587920 bytes
[2023-02-07 18:56:57,674][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:56:57,686][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 46469 vocabulary and 59 features, using sg=1 hs=0 sample=0.22463270463250865 negative=5 window=4 shrink_windows=True', 'datetime': '2023-02-07T18:56:57.686193', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:56:58,689][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 35.95% examples, 2362332 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:59,689][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 71.81% examples, 2370540 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:00,337][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6488146 effective words) took 2.6s, 2449020 effective words/s
[2023-02-07 18:57:01,339][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 43.66% examples, 2898116 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:02,339][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 89.87% examples, 2928936 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:02,551][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6488146 effective words) took 2.2s, 2933025 effective words/s
[2023-02-07 18:57:03,553][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 45.32% examples, 2992317 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:04,554][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 91.34% examples, 2979112 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:04,730][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6488146 effective words) took 2.2s, 2979130 effective words/s
[2023-02-07 18:57:05,732][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 44.89% examples, 2966587 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:06,736][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 85.78% examples, 2798647 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:07,065][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6488146 effective words) took 2.3s, 2779990 effective words/s
[2023-02-07 18:57:08,073][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 38.72% examples, 2546507 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:09,074][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 80.44% examples, 2622085 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:09,530][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6488146 effective words) took 2.5s, 2633686 effective words/s
[2023-02-07 18:57:10,532][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 40.59% examples, 2699115 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:11,536][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 82.32% examples, 2686795 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:11,935][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6488146 effective words) took 2.4s, 2699633 effective words/s
[2023-02-07 18:57:12,938][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 40.50% examples, 2691751 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:57:13,943][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 82.84% examples, 2707281 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:14,324][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6488146 effective words) took 2.4s, 2718179 effective words/s
[2023-02-07 18:57:15,329][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 40.84% examples, 2712734 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:16,331][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 84.31% examples, 2754073 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:16,686][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6488146 effective words) took 2.4s, 2750102 effective words/s
[2023-02-07 18:57:17,690][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 40.84% examples, 2710181 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:18,691][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 88.58% examples, 2881490 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:18,890][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6488146 effective words) took 2.2s, 2946239 effective words/s
[2023-02-07 18:57:19,895][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 51.64% examples, 3409562 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:20,749][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6488146 effective words) took 1.9s, 3491602 effective words/s
[2023-02-07 18:57:21,751][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 52.47% examples, 3472414 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:22,626][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6488146 effective words) took 1.9s, 3459573 effective words/s
[2023-02-07 18:57:23,628][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 51.40% examples, 3398672 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:24,507][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6488146 effective words) took 1.9s, 3450140 effective words/s
[2023-02-07 18:57:25,516][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 40.59% examples, 2693661 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:26,517][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 93.06% examples, 3032003 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:26,642][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6488146 effective words) took 2.1s, 3048348 effective words/s
[2023-02-07 18:57:27,644][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 47.62% examples, 3148623 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:28,647][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 96.19% examples, 3117137 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:28,723][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6488146 effective words) took 2.1s, 3119355 effective words/s
[2023-02-07 18:57:29,726][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 46.45% examples, 3053996 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:30,727][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 93.58% examples, 3046034 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:30,849][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6488146 effective words) took 2.1s, 3053734 effective words/s
[2023-02-07 18:57:30,849][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (97322190 effective words) took 33.2s, 2934644 effective words/s', 'datetime': '2023-02-07T18:57:30.849775', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:57:30.850 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:57:34,333][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185628-27nb1f3j/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:57:34.333543', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:57:34,335][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:57:34,399][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185628-27nb1f3j/files/../tmp/embedding_model.pt
2023-02-07 18:57:34.400 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:57:35.511 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:57:35.902 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:57:37.010 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9947764284400188, 'test_mae': 0.7505342602455543, 'test_r2': -1.9452916528956705}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: | 0.030 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: / 0.030 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.82
wandb: percentage 0.14032
wandb:   test_mae 0.75053
wandb:   test_mse 0.99478
wandb:    test_r2 -1.94529
wandb: 
wandb: üöÄ View run stellar-sweep-26 at: https://wandb.ai/xiaoqiz/mof2vec/runs/27nb1f3j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_185628-27nb1f3j/logs
wandb: Agent Starting Run: jhgex1gy with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 908
wandb: 	model.gensim.alpha: 0.0014940981986199889
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.2665181181429347
wandb: 	model.gensim.vector_size: 186
wandb: 	model.gensim.window: 5
wandb: 	model.sklearn.learning_rate: 0.5598065238367826
wandb: 	model.sklearn.max_depth: 62
wandb: 	model.sklearn.min_child_weight: 0.09476853726773488
wandb: 	model.sklearn.n_estimators: 4621
wandb: 	model.sklearn.num_leaves: 323
wandb: 	model.sklearn.reg_alpha: 0.014760471003937152
wandb: 	model.sklearn.reg_lambda: 0.0052638708236399205
wandb: 	model.sklearn.subsample: 0.3517974477222458
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185747-jhgex1gy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-27
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/jhgex1gy
2023-02-07 18:57:55.947 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 18:57:55.948 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 908 for sweep.
2023-02-07 18:57:55.949 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0014940981986199889 for sweep.
2023-02-07 18:57:55.949 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:57:55.949 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 18:57:55.949 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2665181181429347 for sweep.
2023-02-07 18:57:55.950 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 186 for sweep.
2023-02-07 18:57:55.950 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 5 for sweep.
2023-02-07 18:57:55.950 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.5598065238367826 for sweep.
2023-02-07 18:57:55.951 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 62 for sweep.
2023-02-07 18:57:55.951 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09476853726773488 for sweep.
2023-02-07 18:57:55.951 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4621 for sweep.
2023-02-07 18:57:55.951 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 323 for sweep.
2023-02-07 18:57:55.952 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.014760471003937152 for sweep.
2023-02-07 18:57:55.952 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0052638708236399205 for sweep.
2023-02-07 18:57:55.952 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3517974477222458 for sweep.
2023-02-07 18:57:55.952 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:57:55.963 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185747-jhgex1gy/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 908, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 186, 'window': 5, 'min_count': 7, 'dm': 0, 'sample': 0.2665181181429347, 'workers': 4, 'alpha': 0.0014940981986199889, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4621, 'max_depth': 62, 'num_leaves': 323, 'reg_alpha': 0.014760471003937152, 'reg_lambda': 0.0052638708236399205, 'subsample': 0.3517974477222458, 'min_child_weight': 0.09476853726773488, 'n_jobs': 4, 'learning_rate': 0.5598065238367826}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 19/3257 [00:00<00:17, 186.95it/s]  1%|          | 40/3257 [00:00<00:16, 197.07it/s]  2%|‚ñè         | 60/3257 [00:00<00:16, 188.74it/s]  3%|‚ñé         | 82/3257 [00:00<00:16, 196.65it/s]  3%|‚ñé         | 102/3257 [00:00<00:16, 196.21it/s]  4%|‚ñé         | 122/3257 [00:00<00:16, 186.02it/s]  4%|‚ñç         | 145/3257 [00:00<00:15, 197.05it/s]  5%|‚ñå         | 165/3257 [00:00<00:16, 190.10it/s]  6%|‚ñå         | 186/3257 [00:00<00:15, 194.86it/s]  6%|‚ñã         | 207/3257 [00:01<00:15, 197.48it/s]  7%|‚ñã         | 233/3257 [00:01<00:14, 215.36it/s]  8%|‚ñä         | 255/3257 [00:01<00:14, 210.27it/s]  9%|‚ñä         | 279/3257 [00:01<00:13, 217.49it/s]  9%|‚ñâ         | 301/3257 [00:01<00:13, 214.12it/s] 10%|‚ñà         | 327/3257 [00:01<00:12, 226.73it/s] 11%|‚ñà         | 350/3257 [00:01<00:20, 139.21it/s] 11%|‚ñà‚ñè        | 373/3257 [00:02<00:18, 156.76it/s] 12%|‚ñà‚ñè        | 393/3257 [00:02<00:18, 157.98it/s] 13%|‚ñà‚ñé        | 415/3257 [00:02<00:16, 171.80it/s] 13%|‚ñà‚ñé        | 435/3257 [00:02<00:17, 157.54it/s] 14%|‚ñà‚ñç        | 457/3257 [00:02<00:16, 172.36it/s] 15%|‚ñà‚ñç        | 478/3257 [00:02<00:15, 180.50it/s] 15%|‚ñà‚ñå        | 499/3257 [00:02<00:14, 187.91it/s] 16%|‚ñà‚ñå        | 522/3257 [00:02<00:13, 196.22it/s] 17%|‚ñà‚ñã        | 543/3257 [00:02<00:13, 198.50it/s] 17%|‚ñà‚ñã        | 564/3257 [00:03<00:14, 186.04it/s] 18%|‚ñà‚ñä        | 584/3257 [00:03<00:14, 188.62it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:14, 188.89it/s] 19%|‚ñà‚ñâ        | 624/3257 [00:03<00:13, 191.78it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:13, 194.39it/s] 20%|‚ñà‚ñà        | 665/3257 [00:03<00:13, 185.72it/s] 21%|‚ñà‚ñà        | 684/3257 [00:03<00:13, 183.98it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:03<00:13, 187.92it/s] 22%|‚ñà‚ñà‚ñè       | 723/3257 [00:03<00:13, 184.02it/s] 23%|‚ñà‚ñà‚ñé       | 742/3257 [00:03<00:13, 182.07it/s] 24%|‚ñà‚ñà‚ñé       | 766/3257 [00:04<00:12, 197.92it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:04<00:12, 191.00it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:13, 188.15it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:04<00:13, 186.49it/s] 26%|‚ñà‚ñà‚ñå       | 844/3257 [00:04<00:13, 182.39it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:04<00:12, 186.73it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:04<00:12, 183.34it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:04<00:11, 195.98it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:04<00:11, 197.41it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:05<00:11, 193.98it/s] 30%|‚ñà‚ñà‚ñâ       | 969/3257 [00:05<00:11, 198.58it/s] 30%|‚ñà‚ñà‚ñà       | 989/3257 [00:05<00:11, 190.97it/s] 31%|‚ñà‚ñà‚ñà       | 1009/3257 [00:05<00:11, 187.38it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1028/3257 [00:05<00:12, 181.58it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1047/3257 [00:05<00:12, 179.86it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1066/3257 [00:05<00:12, 182.25it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1085/3257 [00:05<00:11, 182.70it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:05<00:11, 185.46it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:06<00:11, 181.60it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:06<00:11, 178.74it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1165/3257 [00:06<00:11, 188.83it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1184/3257 [00:06<00:11, 177.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1202/3257 [00:06<00:12, 170.74it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1221/3257 [00:06<00:11, 175.16it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1244/3257 [00:06<00:10, 188.84it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1266/3257 [00:06<00:10, 195.81it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1286/3257 [00:06<00:10, 181.41it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1307/3257 [00:07<00:10, 187.28it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:07<00:10, 192.20it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:07<00:09, 194.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:07<00:09, 192.13it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1390/3257 [00:07<00:09, 187.34it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1416/3257 [00:07<00:08, 206.84it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1437/3257 [00:07<00:08, 206.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1461/3257 [00:07<00:08, 215.90it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1483/3257 [00:07<00:08, 214.99it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1507/3257 [00:07<00:07, 220.35it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:08<00:08, 200.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1551/3257 [00:08<00:08, 194.30it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1571/3257 [00:08<00:08, 193.68it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:08<00:08, 190.08it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1611/3257 [00:08<00:14, 116.31it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:08<00:12, 132.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:08<00:11, 145.66it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1672/3257 [00:09<00:10, 152.32it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:09<00:09, 163.59it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:09<00:08, 178.64it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1735/3257 [00:09<00:08, 182.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1764/3257 [00:09<00:07, 210.46it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1793/3257 [00:09<00:06, 232.65it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1818/3257 [00:09<00:06, 236.71it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1845/3257 [00:09<00:05, 243.61it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1876/3257 [00:09<00:05, 259.30it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1904/3257 [00:10<00:05, 263.21it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:10<00:05, 265.13it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:10<00:04, 286.16it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1994/3257 [00:10<00:04, 285.81it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2023/3257 [00:10<00:04, 286.76it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:10<00:04, 273.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2080/3257 [00:10<00:04, 268.33it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2107/3257 [00:10<00:04, 265.15it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:10<00:04, 255.46it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2160/3257 [00:10<00:04, 251.63it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2189/3257 [00:11<00:04, 260.57it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2216/3257 [00:11<00:03, 262.02it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2243/3257 [00:11<00:04, 252.54it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:11<00:03, 256.37it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:11<00:03, 262.94it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2334/3257 [00:11<00:03, 286.74it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2367/3257 [00:11<00:03, 296.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2400/3257 [00:11<00:02, 306.01it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2431/3257 [00:11<00:02, 283.45it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2462/3257 [00:12<00:02, 288.77it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2494/3257 [00:12<00:02, 297.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2528/3257 [00:12<00:02, 309.30it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2560/3257 [00:12<00:02, 299.66it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2591/3257 [00:12<00:02, 286.13it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2630/3257 [00:12<00:01, 313.72it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2662/3257 [00:12<00:02, 292.92it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:12<00:01, 293.04it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2724/3257 [00:12<00:01, 281.00it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2760/3257 [00:13<00:01, 301.60it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:13<00:01, 303.66it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:13<00:01, 299.62it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2854/3257 [00:13<00:01, 298.41it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2892/3257 [00:13<00:01, 318.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2925/3257 [00:13<00:01, 314.66it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2957/3257 [00:13<00:01, 292.10it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2987/3257 [00:13<00:00, 290.02it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3021/3257 [00:13<00:00, 303.60it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3058/3257 [00:13<00:00, 321.49it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3091/3257 [00:14<00:00, 320.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3124/3257 [00:14<00:00, 179.00it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3150/3257 [00:14<00:00, 191.91it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3178/3257 [00:14<00:00, 209.39it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3211/3257 [00:14<00:00, 235.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:14<00:00, 255.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:14<00:00, 218.16it/s]
2023-02-07 18:58:11.360 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:58:11,361][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d186,n5,mc7,s0.266518,t4>', 'datetime': '2023-02-07T18:58:11.361359', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:58:11,361][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:58:11,361][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:58:11,666][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 18:58:11,666][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:58:11,682][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 6087 unique words (46.60% of original 13061, drops 6974)', 'datetime': '2023-02-07T18:58:11.682856', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:58:11,683][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 3619677 word corpus (99.46% of original 3639370, drops 19693)', 'datetime': '2023-02-07T18:58:11.683068', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:58:11,702][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 18:58:11,703][gensim.models.word2vec][INFO] - sample=0.266518 downsamples 0 most-common words
[2023-02-07 18:58:11,703][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3619677 word corpus (100.0%% of prior 3619677)', 'datetime': '2023-02-07T18:58:11.703343', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:58:11,737][gensim.models.word2vec][INFO] - estimated required memory for 6087 words and 186 dimensions: 15175564 bytes
[2023-02-07 18:58:11,738][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:58:11,744][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 6087 vocabulary and 186 features, using sg=1 hs=0 sample=0.2665181181429347 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-07T18:58:11.744458', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:58:12,753][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 69.85% examples, 2576187 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:13,144][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3622934 effective words) took 1.4s, 2590556 effective words/s
[2023-02-07 18:58:14,146][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 70.77% examples, 2620325 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:14,528][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3622934 effective words) took 1.4s, 2620373 effective words/s
[2023-02-07 18:58:15,530][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 71.45% examples, 2637218 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:15,888][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3622934 effective words) took 1.4s, 2666353 effective words/s
[2023-02-07 18:58:16,894][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 73.93% examples, 2712912 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:17,236][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3622934 effective words) took 1.3s, 2694633 effective words/s
[2023-02-07 18:58:18,242][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 45.04% examples, 1660301 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:19,242][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 91.03% examples, 1656466 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:19,410][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3622934 effective words) took 2.2s, 1668078 effective words/s
[2023-02-07 18:58:20,412][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 72.18% examples, 2657840 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:20,771][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3622934 effective words) took 1.4s, 2664931 effective words/s
[2023-02-07 18:58:21,773][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 72.64% examples, 2671678 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:22,129][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3622934 effective words) took 1.4s, 2669807 effective words/s
[2023-02-07 18:58:23,131][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 71.72% examples, 2648391 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:23,496][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3622934 effective words) took 1.4s, 2652457 effective words/s
[2023-02-07 18:58:24,498][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 71.05% examples, 2630704 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:24,868][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3622934 effective words) took 1.4s, 2642521 effective words/s
[2023-02-07 18:58:25,872][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 71.72% examples, 2642194 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:26,237][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3622934 effective words) took 1.4s, 2650680 effective words/s
[2023-02-07 18:58:27,238][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 72.86% examples, 2681643 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:27,585][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3622934 effective words) took 1.3s, 2688447 effective words/s
[2023-02-07 18:58:28,588][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 72.86% examples, 2678518 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:28,944][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3622934 effective words) took 1.4s, 2668921 effective words/s
[2023-02-07 18:58:29,945][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 73.26% examples, 2691940 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:30,287][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3622934 effective words) took 1.3s, 2698922 effective words/s
[2023-02-07 18:58:31,293][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 72.86% examples, 2672500 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:31,642][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3622934 effective words) took 1.4s, 2677069 effective words/s
[2023-02-07 18:58:32,650][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 65.34% examples, 2399424 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:33,146][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3622934 effective words) took 1.5s, 2410004 effective words/s
[2023-02-07 18:58:33,147][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54344010 effective words) took 21.4s, 2539116 effective words/s', 'datetime': '2023-02-07T18:58:33.147427', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:58:33.148 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:58:36,083][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185747-jhgex1gy/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:58:36.083626', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:58:36,084][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:58:36,106][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185747-jhgex1gy/files/../tmp/embedding_model.pt
2023-02-07 18:58:36.107 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:58:37.590 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:58:38.162 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:58:46.044 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0546559829357205, 'test_mae': 0.794405411037565, 'test_r2': -2.5267689223428524}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.42
wandb: percentage 0.53396
wandb:   test_mae 0.79441
wandb:   test_mse 1.05466
wandb:    test_r2 -2.52677
wandb: 
wandb: üöÄ View run lemon-sweep-27 at: https://wandb.ai/xiaoqiz/mof2vec/runs/jhgex1gy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_185747-jhgex1gy/logs
wandb: Agent Starting Run: 712lcufi with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 683
wandb: 	model.gensim.alpha: 0.007305795450684003
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.2660378219665746
wandb: 	model.gensim.vector_size: 226
wandb: 	model.gensim.window: 4
wandb: 	model.sklearn.learning_rate: 0.07938065279478353
wandb: 	model.sklearn.max_depth: 67
wandb: 	model.sklearn.min_child_weight: 0.07978260598879383
wandb: 	model.sklearn.n_estimators: 553
wandb: 	model.sklearn.num_leaves: 474
wandb: 	model.sklearn.reg_alpha: 0.003079397868827585
wandb: 	model.sklearn.reg_lambda: 0.06356102221516641
wandb: 	model.sklearn.subsample: 0.7132084494194555
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185856-712lcufi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-28
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/712lcufi
2023-02-07 18:59:04.497 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 18:59:04.497 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 683 for sweep.
2023-02-07 18:59:04.498 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.007305795450684003 for sweep.
2023-02-07 18:59:04.498 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:59:04.498 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 18:59:04.499 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2660378219665746 for sweep.
2023-02-07 18:59:04.499 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 226 for sweep.
2023-02-07 18:59:04.499 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 4 for sweep.
2023-02-07 18:59:04.499 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.07938065279478353 for sweep.
2023-02-07 18:59:04.499 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 67 for sweep.
2023-02-07 18:59:04.500 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.07978260598879383 for sweep.
2023-02-07 18:59:04.500 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 553 for sweep.
2023-02-07 18:59:04.500 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 474 for sweep.
2023-02-07 18:59:04.500 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.003079397868827585 for sweep.
2023-02-07 18:59:04.501 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.06356102221516641 for sweep.
2023-02-07 18:59:04.501 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7132084494194555 for sweep.
2023-02-07 18:59:04.501 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:59:04.510 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185856-712lcufi/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 683, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 226, 'window': 4, 'min_count': 2, 'dm': 0, 'sample': 0.2660378219665746, 'workers': 4, 'alpha': 0.007305795450684003, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 553, 'max_depth': 67, 'num_leaves': 474, 'reg_alpha': 0.003079397868827585, 'reg_lambda': 0.06356102221516641, 'subsample': 0.7132084494194555, 'min_child_weight': 0.07978260598879383, 'n_jobs': 4, 'learning_rate': 0.07938065279478353}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:20, 159.67it/s]  1%|          | 35/3257 [00:00<00:18, 170.96it/s]  2%|‚ñè         | 53/3257 [00:00<00:18, 169.34it/s]  2%|‚ñè         | 73/3257 [00:00<00:17, 178.93it/s]  3%|‚ñé         | 94/3257 [00:00<00:17, 184.14it/s]  3%|‚ñé         | 113/3257 [00:00<00:17, 177.66it/s]  4%|‚ñç         | 131/3257 [00:00<00:17, 176.68it/s]  5%|‚ñç         | 152/3257 [00:00<00:16, 184.12it/s]  5%|‚ñå         | 171/3257 [00:00<00:17, 179.61it/s]  6%|‚ñå         | 191/3257 [00:01<00:16, 183.94it/s]  6%|‚ñã         | 210/3257 [00:01<00:16, 183.44it/s]  7%|‚ñã         | 233/3257 [00:01<00:15, 195.84it/s]  8%|‚ñä         | 253/3257 [00:01<00:15, 190.89it/s]  8%|‚ñä         | 273/3257 [00:01<00:15, 190.15it/s]  9%|‚ñâ         | 297/3257 [00:01<00:14, 200.16it/s] 10%|‚ñâ         | 318/3257 [00:01<00:15, 194.65it/s] 10%|‚ñà         | 338/3257 [00:01<00:15, 194.25it/s] 11%|‚ñà         | 359/3257 [00:01<00:14, 194.53it/s] 12%|‚ñà‚ñè        | 379/3257 [00:02<00:15, 180.66it/s] 12%|‚ñà‚ñè        | 398/3257 [00:02<00:15, 179.60it/s] 13%|‚ñà‚ñé        | 419/3257 [00:02<00:15, 187.36it/s] 13%|‚ñà‚ñé        | 438/3257 [00:02<00:17, 159.32it/s] 14%|‚ñà‚ñç        | 458/3257 [00:02<00:16, 169.49it/s] 15%|‚ñà‚ñç        | 477/3257 [00:02<00:15, 173.90it/s] 15%|‚ñà‚ñå        | 496/3257 [00:02<00:15, 178.03it/s] 16%|‚ñà‚ñå        | 517/3257 [00:02<00:14, 184.43it/s] 16%|‚ñà‚ñã        | 536/3257 [00:02<00:14, 183.36it/s] 17%|‚ñà‚ñã        | 556/3257 [00:03<00:14, 187.17it/s] 18%|‚ñà‚ñä        | 575/3257 [00:03<00:16, 161.49it/s] 18%|‚ñà‚ñä        | 596/3257 [00:03<00:15, 174.14it/s] 19%|‚ñà‚ñâ        | 618/3257 [00:03<00:14, 185.09it/s] 20%|‚ñà‚ñâ        | 638/3257 [00:03<00:14, 179.84it/s] 20%|‚ñà‚ñà        | 657/3257 [00:03<00:15, 162.80it/s] 21%|‚ñà‚ñà        | 678/3257 [00:03<00:14, 173.08it/s] 21%|‚ñà‚ñà‚ñè       | 696/3257 [00:03<00:15, 166.41it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:03<00:14, 178.19it/s] 23%|‚ñà‚ñà‚ñé       | 737/3257 [00:04<00:15, 163.86it/s] 23%|‚ñà‚ñà‚ñé       | 756/3257 [00:04<00:14, 170.47it/s] 24%|‚ñà‚ñà‚ñç       | 774/3257 [00:04<00:14, 172.70it/s] 24%|‚ñà‚ñà‚ñç       | 792/3257 [00:04<00:14, 170.79it/s] 25%|‚ñà‚ñà‚ñç       | 811/3257 [00:04<00:13, 175.57it/s] 25%|‚ñà‚ñà‚ñå       | 829/3257 [00:04<00:14, 165.26it/s] 26%|‚ñà‚ñà‚ñå       | 846/3257 [00:04<00:15, 159.08it/s] 27%|‚ñà‚ñà‚ñã       | 865/3257 [00:04<00:14, 166.03it/s] 27%|‚ñà‚ñà‚ñã       | 882/3257 [00:04<00:14, 165.70it/s] 28%|‚ñà‚ñà‚ñä       | 903/3257 [00:05<00:13, 177.55it/s] 28%|‚ñà‚ñà‚ñä       | 921/3257 [00:05<00:13, 176.61it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:05<00:13, 172.80it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:05<00:12, 177.35it/s] 30%|‚ñà‚ñà‚ñà       | 978/3257 [00:05<00:12, 179.81it/s] 31%|‚ñà‚ñà‚ñà       | 997/3257 [00:05<00:13, 168.74it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:05<00:13, 169.78it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1033/3257 [00:05<00:13, 164.03it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1050/3257 [00:05<00:13, 161.16it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1069/3257 [00:06<00:13, 168.03it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1086/3257 [00:06<00:13, 165.79it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1103/3257 [00:06<00:13, 165.59it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1120/3257 [00:06<00:13, 163.71it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1138/3257 [00:06<00:12, 167.20it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1155/3257 [00:06<00:12, 165.86it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1174/3257 [00:06<00:12, 172.23it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1192/3257 [00:06<00:13, 154.00it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1208/3257 [00:07<00:22, 92.18it/s]  38%|‚ñà‚ñà‚ñà‚ñä      | 1228/3257 [00:07<00:18, 112.03it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1246/3257 [00:07<00:16, 124.97it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1265/3257 [00:07<00:14, 138.51it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1282/3257 [00:07<00:14, 135.74it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1299/3257 [00:07<00:13, 143.29it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1319/3257 [00:07<00:12, 157.00it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:07<00:11, 166.08it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1357/3257 [00:08<00:11, 163.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1374/3257 [00:08<00:11, 161.75it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1391/3257 [00:08<00:11, 160.30it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1413/3257 [00:08<00:10, 175.87it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1433/3257 [00:08<00:10, 182.00it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1455/3257 [00:08<00:09, 191.83it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1475/3257 [00:08<00:09, 194.19it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:08<00:08, 196.60it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1517/3257 [00:08<00:08, 197.55it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1537/3257 [00:09<00:09, 174.15it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:09<00:10, 169.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:09<00:09, 174.27it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1592/3257 [00:09<00:09, 174.13it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1613/3257 [00:09<00:08, 183.90it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1633/3257 [00:09<00:08, 188.07it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1652/3257 [00:09<00:09, 167.33it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1670/3257 [00:09<00:09, 167.47it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1688/3257 [00:09<00:09, 163.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:10<00:09, 167.19it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1727/3257 [00:10<00:08, 172.74it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:10<00:09, 153.48it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1764/3257 [00:10<00:09, 162.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1785/3257 [00:10<00:08, 173.00it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:10<00:08, 172.29it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:10<00:08, 170.38it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1839/3257 [00:10<00:08, 165.69it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1857/3257 [00:10<00:08, 168.54it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1877/3257 [00:11<00:07, 177.27it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:11<00:08, 170.15it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:11<00:07, 172.01it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1934/3257 [00:11<00:07, 173.78it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1958/3257 [00:11<00:06, 190.51it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1978/3257 [00:11<00:07, 179.70it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1997/3257 [00:11<00:06, 182.24it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2016/3257 [00:11<00:06, 178.59it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2036/3257 [00:11<00:06, 182.41it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:12<00:07, 165.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2072/3257 [00:12<00:07, 165.64it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2089/3257 [00:12<00:07, 165.50it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2107/3257 [00:12<00:06, 167.28it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2124/3257 [00:12<00:07, 154.80it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2142/3257 [00:12<00:07, 159.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2160/3257 [00:12<00:06, 160.51it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2179/3257 [00:12<00:06, 168.35it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2198/3257 [00:12<00:06, 173.77it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2216/3257 [00:13<00:06, 168.34it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2234/3257 [00:13<00:05, 171.55it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2252/3257 [00:13<00:06, 165.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:13<00:06, 163.35it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2290/3257 [00:13<00:05, 171.11it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2308/3257 [00:13<00:05, 168.96it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2332/3257 [00:13<00:04, 188.92it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2357/3257 [00:13<00:04, 205.08it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2378/3257 [00:13<00:04, 194.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:14<00:04, 198.29it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2420/3257 [00:14<00:04, 186.83it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2439/3257 [00:14<00:04, 179.71it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2458/3257 [00:14<00:04, 180.54it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2479/3257 [00:14<00:04, 187.13it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2501/3257 [00:14<00:03, 196.14it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2521/3257 [00:14<00:03, 196.66it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2541/3257 [00:14<00:03, 196.30it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2561/3257 [00:14<00:03, 187.32it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2580/3257 [00:15<00:03, 176.15it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2599/3257 [00:15<00:03, 177.73it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2625/3257 [00:15<00:03, 200.29it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2646/3257 [00:15<00:03, 187.96it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2666/3257 [00:15<00:06, 96.92it/s]  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:15<00:04, 114.79it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:16<00:04, 117.55it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2720/3257 [00:16<00:04, 125.49it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2744/3257 [00:16<00:03, 149.48it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2762/3257 [00:16<00:03, 155.46it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2780/3257 [00:16<00:02, 160.32it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2802/3257 [00:16<00:02, 175.94it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2821/3257 [00:16<00:02, 172.27it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2840/3257 [00:16<00:02, 162.84it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2864/3257 [00:16<00:02, 182.47it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:16<00:01, 189.76it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:17<00:01, 177.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:17<00:01, 185.00it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:17<00:01, 175.28it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2965/3257 [00:17<00:01, 174.33it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2983/3257 [00:17<00:01, 162.86it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3003/3257 [00:17<00:01, 172.72it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3021/3257 [00:17<00:01, 167.15it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3041/3257 [00:17<00:01, 175.45it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:18<00:01, 185.51it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:18<00:00, 183.06it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3103/3257 [00:18<00:00, 188.79it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3124/3257 [00:18<00:00, 192.39it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3144/3257 [00:18<00:00, 179.25it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3163/3257 [00:18<00:00, 178.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3182/3257 [00:18<00:00, 167.86it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:18<00:00, 177.91it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3222/3257 [00:18<00:00, 169.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:19<00:00, 178.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 170.43it/s]
2023-02-07 18:59:24.472 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:59:24,473][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d226,n5,mc2,s0.266038,t4>', 'datetime': '2023-02-07T18:59:24.473596', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:59:24,474][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:59:24,474][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:59:25,036][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 18:59:25,037][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:59:25,137][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 36619 unique words (85.76% of original 42701, drops 6082)', 'datetime': '2023-02-07T18:59:25.137071', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:59:25,138][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5816910 word corpus (99.90% of original 5822992, drops 6082)', 'datetime': '2023-02-07T18:59:25.138090', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:59:25,269][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 18:59:25,270][gensim.models.word2vec][INFO] - sample=0.266038 downsamples 0 most-common words
[2023-02-07 18:59:25,270][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5816910 word corpus (100.0%% of prior 5816910)', 'datetime': '2023-02-07T18:59:25.270969', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:59:25,490][gensim.models.word2vec][INFO] - estimated required memory for 36619 words and 226 dimensions: 88112380 bytes
[2023-02-07 18:59:25,490][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:59:25,529][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 36619 vocabulary and 226 features, using sg=1 hs=0 sample=0.2660378219665746 negative=5 window=4 shrink_windows=True', 'datetime': '2023-02-07T18:59:25.529497', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:59:26,531][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 39.24% examples, 2332045 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:27,533][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 80.90% examples, 2358873 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:27,969][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5790320 effective words) took 2.4s, 2374760 effective words/s
[2023-02-07 18:59:28,974][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 44.43% examples, 2629275 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:29,977][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 90.14% examples, 2620337 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:30,181][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5790320 effective words) took 2.2s, 2621899 effective words/s
[2023-02-07 18:59:31,186][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 44.18% examples, 2612868 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:32,187][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 90.14% examples, 2619540 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:32,386][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5790320 effective words) took 2.2s, 2627357 effective words/s
[2023-02-07 18:59:33,390][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 45.38% examples, 2673311 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:34,395][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 92.42% examples, 2681444 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:34,544][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5790320 effective words) took 2.2s, 2685436 effective words/s
[2023-02-07 18:59:35,546][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 44.43% examples, 2631605 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:36,551][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 91.34% examples, 2654357 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:36,723][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5790320 effective words) took 2.2s, 2658976 effective words/s
[2023-02-07 18:59:37,727][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 45.23% examples, 2663389 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:38,729][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 91.62% examples, 2667307 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:38,888][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5790320 effective words) took 2.2s, 2676032 effective words/s
[2023-02-07 18:59:39,894][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 45.04% examples, 2650355 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:40,897][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 92.42% examples, 2681929 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:41,043][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5790320 effective words) took 2.2s, 2689159 effective words/s
[2023-02-07 18:59:42,047][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 46.15% examples, 2707984 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:43,054][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 93.74% examples, 2712754 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:43,173][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5790320 effective words) took 2.1s, 2719796 effective words/s
[2023-02-07 18:59:44,178][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 44.67% examples, 2633180 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:45,179][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 91.77% examples, 2672608 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:45,330][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5790320 effective words) took 2.2s, 2686526 effective words/s
[2023-02-07 18:59:46,332][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 46.91% examples, 2766993 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:47,339][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 95.98% examples, 2769063 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:47,418][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5790320 effective words) took 2.1s, 2775133 effective words/s
[2023-02-07 18:59:48,421][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 46.61% examples, 2737881 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:49,422][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 94.78% examples, 2749581 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:49,527][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5790320 effective words) took 2.1s, 2747448 effective words/s
[2023-02-07 18:59:50,530][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 45.90% examples, 2701007 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:51,533][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 92.48% examples, 2688823 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:51,678][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5790320 effective words) took 2.2s, 2693047 effective words/s
[2023-02-07 18:59:52,681][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 45.90% examples, 2702562 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:53,682][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 94.01% examples, 2728445 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:53,799][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5790320 effective words) took 2.1s, 2733194 effective words/s
[2023-02-07 18:59:54,802][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 46.61% examples, 2735603 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:55,804][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 95.00% examples, 2751304 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:55,907][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5790320 effective words) took 2.1s, 2748104 effective words/s
[2023-02-07 18:59:56,908][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 45.53% examples, 2686681 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:57,909][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 92.42% examples, 2689493 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:58,052][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5790320 effective words) took 2.1s, 2700501 effective words/s
[2023-02-07 18:59:58,053][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86854800 effective words) took 32.5s, 2670516 effective words/s', 'datetime': '2023-02-07T18:59:58.053637', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:59:58.053 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:00:01,627][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185856-712lcufi/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:00:01.626916', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:00:01,627][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:00:01,745][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185856-712lcufi/files/../tmp/embedding_model.pt
2023-02-07 19:00:01.745 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:00:03.392 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:00:03.998 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:00:06.961 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.980769176682174, 'test_mae': 0.7624541174140445, 'test_r2': -2.0896195326527223}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.81
wandb: percentage 0.14243
wandb:   test_mae 0.76245
wandb:   test_mse 0.98077
wandb:    test_r2 -2.08962
wandb: 
wandb: üöÄ View run fluent-sweep-28 at: https://wandb.ai/xiaoqiz/mof2vec/runs/712lcufi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_185856-712lcufi/logs
wandb: Agent Starting Run: k2vqwhkc with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 591
wandb: 	model.gensim.alpha: 0.004779876331287196
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.27239297578224897
wandb: 	model.gensim.vector_size: 187
wandb: 	model.gensim.window: 4
wandb: 	model.sklearn.learning_rate: 0.02954454674412729
wandb: 	model.sklearn.max_depth: 74
wandb: 	model.sklearn.min_child_weight: 0.03582353539429399
wandb: 	model.sklearn.n_estimators: 2260
wandb: 	model.sklearn.num_leaves: 487
wandb: 	model.sklearn.reg_alpha: 0.004077453081184512
wandb: 	model.sklearn.reg_lambda: 0.061893631995577576
wandb: 	model.sklearn.subsample: 0.2329739832459434
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190021-k2vqwhkc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-29
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/k2vqwhkc
2023-02-07 19:00:28.839 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 19:00:28.840 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 591 for sweep.
2023-02-07 19:00:28.840 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.004779876331287196 for sweep.
2023-02-07 19:00:28.841 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:00:28.841 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 19:00:28.841 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.27239297578224897 for sweep.
2023-02-07 19:00:28.841 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 187 for sweep.
2023-02-07 19:00:28.842 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 4 for sweep.
2023-02-07 19:00:28.842 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.02954454674412729 for sweep.
2023-02-07 19:00:28.842 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 74 for sweep.
2023-02-07 19:00:28.842 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03582353539429399 for sweep.
2023-02-07 19:00:28.842 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2260 for sweep.
2023-02-07 19:00:28.843 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 487 for sweep.
2023-02-07 19:00:28.843 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004077453081184512 for sweep.
2023-02-07 19:00:28.843 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.061893631995577576 for sweep.
2023-02-07 19:00:28.843 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2329739832459434 for sweep.
2023-02-07 19:00:28.844 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:00:28.848 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190021-k2vqwhkc/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 591, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 187, 'window': 4, 'min_count': 3, 'dm': 0, 'sample': 0.27239297578224897, 'workers': 4, 'alpha': 0.004779876331287196, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2260, 'max_depth': 74, 'num_leaves': 487, 'reg_alpha': 0.004077453081184512, 'reg_lambda': 0.061893631995577576, 'subsample': 0.2329739832459434, 'min_child_weight': 0.03582353539429399, 'n_jobs': 4, 'learning_rate': 0.02954454674412729}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 23/3257 [00:00<00:14, 226.75it/s]  1%|‚ñè         | 46/3257 [00:00<00:14, 222.90it/s]  2%|‚ñè         | 69/3257 [00:00<00:14, 217.30it/s]  3%|‚ñé         | 93/3257 [00:00<00:14, 224.20it/s]  4%|‚ñé         | 116/3257 [00:00<00:14, 212.49it/s]  4%|‚ñç         | 141/3257 [00:00<00:13, 223.15it/s]  5%|‚ñå         | 164/3257 [00:00<00:14, 219.14it/s]  6%|‚ñå         | 189/3257 [00:00<00:13, 226.57it/s]  7%|‚ñã         | 212/3257 [00:00<00:13, 226.74it/s]  7%|‚ñã         | 237/3257 [00:01<00:13, 232.28it/s]  8%|‚ñä         | 261/3257 [00:01<00:13, 219.47it/s]  9%|‚ñâ         | 290/3257 [00:01<00:12, 236.58it/s] 10%|‚ñâ         | 314/3257 [00:01<00:12, 231.09it/s] 10%|‚ñà         | 340/3257 [00:01<00:12, 236.58it/s] 11%|‚ñà         | 365/3257 [00:01<00:12, 239.71it/s] 12%|‚ñà‚ñè        | 390/3257 [00:01<00:12, 223.31it/s] 13%|‚ñà‚ñé        | 416/3257 [00:01<00:12, 233.17it/s] 14%|‚ñà‚ñé        | 440/3257 [00:01<00:13, 207.75it/s] 14%|‚ñà‚ñç        | 465/3257 [00:02<00:12, 217.00it/s] 15%|‚ñà‚ñç        | 488/3257 [00:02<00:12, 215.64it/s] 16%|‚ñà‚ñå        | 514/3257 [00:02<00:12, 227.38it/s] 17%|‚ñà‚ñã        | 538/3257 [00:02<00:11, 228.30it/s] 17%|‚ñà‚ñã        | 562/3257 [00:02<00:12, 217.32it/s] 18%|‚ñà‚ñä        | 585/3257 [00:02<00:12, 213.02it/s] 19%|‚ñà‚ñâ        | 611/3257 [00:02<00:11, 223.52it/s] 20%|‚ñà‚ñâ        | 636/3257 [00:02<00:11, 228.63it/s] 20%|‚ñà‚ñà        | 660/3257 [00:02<00:12, 209.50it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:12, 211.68it/s] 22%|‚ñà‚ñà‚ñè       | 707/3257 [00:03<00:11, 218.38it/s] 22%|‚ñà‚ñà‚ñè       | 730/3257 [00:03<00:11, 213.19it/s] 23%|‚ñà‚ñà‚ñé       | 752/3257 [00:03<00:17, 140.43it/s] 24%|‚ñà‚ñà‚ñç       | 775/3257 [00:03<00:15, 157.88it/s] 24%|‚ñà‚ñà‚ñç       | 797/3257 [00:03<00:14, 171.47it/s] 25%|‚ñà‚ñà‚ñå       | 819/3257 [00:03<00:13, 182.63it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:03<00:13, 184.96it/s] 26%|‚ñà‚ñà‚ñã       | 861/3257 [00:04<00:12, 190.22it/s] 27%|‚ñà‚ñà‚ñã       | 882/3257 [00:04<00:12, 193.59it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:04<00:11, 206.60it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:04<00:11, 211.26it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:04<00:10, 220.04it/s] 30%|‚ñà‚ñà‚ñà       | 979/3257 [00:04<00:10, 217.80it/s] 31%|‚ñà‚ñà‚ñà       | 1002/3257 [00:04<00:10, 214.82it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:04<00:10, 215.09it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1047/3257 [00:04<00:10, 201.34it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1071/3257 [00:05<00:10, 210.78it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1093/3257 [00:05<00:10, 208.28it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:05<00:09, 214.96it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:05<00:10, 210.62it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1163/3257 [00:05<00:09, 216.33it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:05<00:10, 206.28it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1206/3257 [00:05<00:10, 198.94it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:05<00:09, 212.04it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1255/3257 [00:05<00:09, 213.72it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:06<00:09, 206.92it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1298/3257 [00:06<00:09, 201.94it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1322/3257 [00:06<00:09, 210.65it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:06<00:08, 218.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1368/3257 [00:06<00:08, 213.70it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1390/3257 [00:06<00:08, 208.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1420/3257 [00:06<00:07, 232.86it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1444/3257 [00:06<00:07, 229.00it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1471/3257 [00:06<00:07, 239.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:07<00:07, 239.42it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1521/3257 [00:07<00:07, 230.02it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1545/3257 [00:07<00:07, 221.87it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1570/3257 [00:07<00:07, 227.87it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:07<00:07, 230.90it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:07<00:06, 237.94it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1644/3257 [00:07<00:07, 228.24it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1667/3257 [00:07<00:07, 221.43it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:07<00:07, 218.67it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1714/3257 [00:07<00:06, 224.61it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1737/3257 [00:08<00:07, 205.70it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:08<00:06, 216.94it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:08<00:06, 229.92it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:08<00:06, 218.56it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1838/3257 [00:08<00:06, 223.66it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1863/3257 [00:08<00:06, 230.87it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1887/3257 [00:08<00:06, 226.40it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1912/3257 [00:08<00:05, 232.16it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1936/3257 [00:08<00:05, 234.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:09<00:05, 245.39it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1990/3257 [00:09<00:05, 237.52it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2014/3257 [00:09<00:05, 235.58it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2039/3257 [00:09<00:05, 238.08it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2063/3257 [00:09<00:05, 217.43it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2086/3257 [00:09<00:08, 133.39it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2108/3257 [00:09<00:07, 149.71it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2127/3257 [00:10<00:07, 158.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2146/3257 [00:10<00:06, 165.54it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2172/3257 [00:10<00:05, 188.95it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2194/3257 [00:10<00:05, 196.53it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2216/3257 [00:10<00:05, 197.82it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:10<00:05, 202.32it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:10<00:04, 206.30it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2282/3257 [00:10<00:04, 207.47it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2306/3257 [00:10<00:04, 215.56it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2336/3257 [00:10<00:03, 237.25it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2364/3257 [00:11<00:03, 248.13it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2391/3257 [00:11<00:03, 254.43it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2417/3257 [00:11<00:03, 239.36it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2442/3257 [00:11<00:03, 229.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2471/3257 [00:11<00:03, 244.86it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2496/3257 [00:11<00:03, 245.94it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:11<00:02, 253.37it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2550/3257 [00:11<00:02, 253.54it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2576/3257 [00:11<00:02, 233.80it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:12<00:02, 232.50it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2631/3257 [00:12<00:02, 250.67it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2657/3257 [00:12<00:02, 239.75it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2682/3257 [00:12<00:02, 241.76it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2707/3257 [00:12<00:02, 225.08it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:12<00:02, 228.54it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2758/3257 [00:12<00:02, 235.94it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2782/3257 [00:12<00:02, 234.85it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2809/3257 [00:12<00:01, 243.06it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2834/3257 [00:13<00:01, 229.80it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2863/3257 [00:13<00:01, 245.34it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2890/3257 [00:13<00:01, 251.96it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:13<00:01, 242.82it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2941/3257 [00:13<00:01, 242.22it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:13<00:01, 233.41it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2990/3257 [00:13<00:01, 223.49it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:13<00:01, 232.17it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3043/3257 [00:13<00:00, 241.89it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3072/3257 [00:14<00:00, 253.44it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3098/3257 [00:14<00:00, 252.66it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:14<00:00, 259.10it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3153/3257 [00:14<00:00, 242.61it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3178/3257 [00:14<00:00, 233.78it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:14<00:00, 243.88it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3232/3257 [00:14<00:00, 244.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:14<00:00, 219.98it/s]
2023-02-07 19:00:44.191 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:00:44,192][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d187,n5,mc3,s0.272393,t4>', 'datetime': '2023-02-07T19:00:44.192763', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:00:44,193][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:00:44,193][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:00:44,534][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 19:00:44,534][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:00:44,559][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 9372 unique words (71.76% of original 13061, drops 3689)', 'datetime': '2023-02-07T19:00:44.559161', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:00:44,559][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 3633898 word corpus (99.85% of original 3639370, drops 5472)', 'datetime': '2023-02-07T19:00:44.559573', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:00:44,591][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 19:00:44,592][gensim.models.word2vec][INFO] - sample=0.272393 downsamples 0 most-common words
[2023-02-07 19:00:44,592][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3633898 word corpus (100.0%% of prior 3633898)', 'datetime': '2023-02-07T19:00:44.592293', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:00:44,647][gensim.models.word2vec][INFO] - estimated required memory for 9372 words and 187 dimensions: 21794148 bytes
[2023-02-07 19:00:44,647][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:00:44,658][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 9372 vocabulary and 187 features, using sg=1 hs=0 sample=0.27239297578224897 negative=5 window=4 shrink_windows=True', 'datetime': '2023-02-07T19:00:44.658211', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:00:45,664][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 65.34% examples, 2418206 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:46,150][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3637155 effective words) took 1.5s, 2442214 effective words/s
[2023-02-07 19:00:47,154][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 72.64% examples, 2677402 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:47,509][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3637155 effective words) took 1.4s, 2680454 effective words/s
[2023-02-07 19:00:48,510][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 73.26% examples, 2702962 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:48,856][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3637155 effective words) took 1.3s, 2702073 effective words/s
[2023-02-07 19:00:49,863][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 71.05% examples, 2625848 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:50,236][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3637155 effective words) took 1.4s, 2637496 effective words/s
[2023-02-07 19:00:51,245][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 71.05% examples, 2623055 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:51,607][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3637155 effective words) took 1.4s, 2656202 effective words/s
[2023-02-07 19:00:52,612][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 75.68% examples, 2784599 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:52,917][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3637155 effective words) took 1.3s, 2782235 effective words/s
[2023-02-07 19:00:53,922][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 74.18% examples, 2727436 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:54,250][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3637155 effective words) took 1.3s, 2730695 effective words/s
[2023-02-07 19:00:55,252][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 73.60% examples, 2712474 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:55,594][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3637155 effective words) took 1.3s, 2709827 effective words/s
[2023-02-07 19:00:56,598][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 72.64% examples, 2677332 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:56,950][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3637155 effective words) took 1.4s, 2685572 effective words/s
[2023-02-07 19:00:57,952][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 74.79% examples, 2761935 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:58,268][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3637155 effective words) took 1.3s, 2763356 effective words/s
[2023-02-07 19:00:59,270][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 74.79% examples, 2762730 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:59,589][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3637155 effective words) took 1.3s, 2756390 effective words/s
[2023-02-07 19:01:00,591][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 73.81% examples, 2719355 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:01:00,924][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3637155 effective words) took 1.3s, 2726279 effective words/s
[2023-02-07 19:01:01,927][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 74.18% examples, 2735788 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:01:02,255][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3637155 effective words) took 1.3s, 2736146 effective words/s
[2023-02-07 19:01:03,258][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 74.61% examples, 2753122 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:01:03,582][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3637155 effective words) took 1.3s, 2744618 effective words/s
[2023-02-07 19:01:04,586][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 73.93% examples, 2722576 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:01:04,917][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3637155 effective words) took 1.3s, 2728634 effective words/s
[2023-02-07 19:01:04,917][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54557325 effective words) took 20.3s, 2693114 effective words/s', 'datetime': '2023-02-07T19:01:04.917583', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:01:04.917 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:01:06,821][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190021-k2vqwhkc/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:01:06.821734', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:01:06,822][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:01:06,852][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190021-k2vqwhkc/files/../tmp/embedding_model.pt
2023-02-07 19:01:06.853 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:01:08.371 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:01:08.928 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:01:17.734 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.8926869013491762, 'test_mae': 0.7170298392513047, 'test_r2': -1.6652285797468238}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.7
wandb: percentage 0.28244
wandb:   test_mae 0.71703
wandb:   test_mse 0.89269
wandb:    test_r2 -1.66523
wandb: 
wandb: üöÄ View run fine-sweep-29 at: https://wandb.ai/xiaoqiz/mof2vec/runs/k2vqwhkc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_190021-k2vqwhkc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bqt5h2l1 with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 783
wandb: 	model.gensim.alpha: 0.0012045920511388022
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.3735773848905827
wandb: 	model.gensim.vector_size: 92
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.017971766790353932
wandb: 	model.sklearn.max_depth: 91
wandb: 	model.sklearn.min_child_weight: 0.06778933552495023
wandb: 	model.sklearn.n_estimators: 2033
wandb: 	model.sklearn.num_leaves: 341
wandb: 	model.sklearn.reg_alpha: 0.0028746554609042625
wandb: 	model.sklearn.reg_lambda: 0.13796820759744532
wandb: 	model.sklearn.subsample: 0.33983461952170957
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190136-bqt5h2l1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/bqt5h2l1
2023-02-07 19:01:45.085 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 19:01:45.086 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 783 for sweep.
2023-02-07 19:01:45.086 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0012045920511388022 for sweep.
2023-02-07 19:01:45.087 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:01:45.087 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 19:01:45.087 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.3735773848905827 for sweep.
2023-02-07 19:01:45.087 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 92 for sweep.
2023-02-07 19:01:45.088 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 19:01:45.088 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.017971766790353932 for sweep.
2023-02-07 19:01:45.088 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 91 for sweep.
2023-02-07 19:01:45.088 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.06778933552495023 for sweep.
2023-02-07 19:01:45.088 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2033 for sweep.
2023-02-07 19:01:45.089 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 341 for sweep.
2023-02-07 19:01:45.089 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0028746554609042625 for sweep.
2023-02-07 19:01:45.089 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.13796820759744532 for sweep.
2023-02-07 19:01:45.089 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.33983461952170957 for sweep.
2023-02-07 19:01:45.090 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:01:45.095 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190136-bqt5h2l1/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 783, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 92, 'window': 2, 'min_count': 2, 'dm': 0, 'sample': 0.3735773848905827, 'workers': 4, 'alpha': 0.0012045920511388022, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2033, 'max_depth': 91, 'num_leaves': 341, 'reg_alpha': 0.0028746554609042625, 'reg_lambda': 0.13796820759744532, 'subsample': 0.33983461952170957, 'min_child_weight': 0.06778933552495023, 'n_jobs': 4, 'learning_rate': 0.017971766790353932}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 19/3257 [00:00<00:17, 187.79it/s]  1%|          | 40/3257 [00:00<00:16, 199.54it/s]  2%|‚ñè         | 60/3257 [00:00<00:16, 194.05it/s]  3%|‚ñé         | 83/3257 [00:00<00:15, 207.35it/s]  3%|‚ñé         | 104/3257 [00:00<00:15, 204.41it/s]  4%|‚ñç         | 125/3257 [00:00<00:15, 196.45it/s]  5%|‚ñç         | 148/3257 [00:00<00:15, 206.14it/s]  5%|‚ñå         | 169/3257 [00:00<00:15, 200.92it/s]  6%|‚ñå         | 191/3257 [00:00<00:14, 204.82it/s]  7%|‚ñã         | 212/3257 [00:01<00:22, 135.77it/s]  7%|‚ñã         | 236/3257 [00:01<00:19, 158.41it/s]  8%|‚ñä         | 257/3257 [00:01<00:17, 168.75it/s]  9%|‚ñä         | 281/3257 [00:01<00:15, 186.20it/s]  9%|‚ñâ         | 302/3257 [00:01<00:15, 186.95it/s] 10%|‚ñà         | 326/3257 [00:01<00:14, 201.06it/s] 11%|‚ñà         | 348/3257 [00:01<00:15, 191.32it/s] 11%|‚ñà‚ñè        | 371/3257 [00:01<00:14, 201.64it/s] 12%|‚ñà‚ñè        | 392/3257 [00:02<00:15, 189.01it/s] 13%|‚ñà‚ñé        | 415/3257 [00:02<00:14, 198.33it/s] 13%|‚ñà‚ñé        | 436/3257 [00:02<00:15, 176.74it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:14, 187.06it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:14, 189.19it/s] 15%|‚ñà‚ñå        | 503/3257 [00:02<00:13, 200.64it/s] 16%|‚ñà‚ñå        | 524/3257 [00:02<00:13, 199.97it/s] 17%|‚ñà‚ñã        | 546/3257 [00:02<00:13, 199.71it/s] 17%|‚ñà‚ñã        | 567/3257 [00:02<00:13, 195.58it/s] 18%|‚ñà‚ñä        | 587/3257 [00:03<00:13, 192.26it/s] 19%|‚ñà‚ñä        | 610/3257 [00:03<00:13, 201.97it/s] 19%|‚ñà‚ñâ        | 631/3257 [00:03<00:13, 201.65it/s] 20%|‚ñà‚ñà        | 652/3257 [00:03<00:13, 194.22it/s] 21%|‚ñà‚ñà        | 672/3257 [00:03<00:13, 192.49it/s] 21%|‚ñà‚ñà        | 692/3257 [00:03<00:13, 183.58it/s] 22%|‚ñà‚ñà‚ñè       | 715/3257 [00:03<00:13, 195.08it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:03<00:13, 185.73it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:03<00:13, 183.32it/s] 24%|‚ñà‚ñà‚ñç       | 774/3257 [00:04<00:13, 186.44it/s] 24%|‚ñà‚ñà‚ñç       | 793/3257 [00:04<00:13, 185.58it/s] 25%|‚ñà‚ñà‚ñç       | 813/3257 [00:04<00:12, 189.38it/s] 26%|‚ñà‚ñà‚ñå       | 833/3257 [00:04<00:13, 182.62it/s] 26%|‚ñà‚ñà‚ñå       | 852/3257 [00:04<00:13, 177.58it/s] 27%|‚ñà‚ñà‚ñã       | 872/3257 [00:04<00:13, 182.96it/s] 27%|‚ñà‚ñà‚ñã       | 891/3257 [00:04<00:13, 180.97it/s] 28%|‚ñà‚ñà‚ñä       | 913/3257 [00:04<00:12, 190.90it/s] 29%|‚ñà‚ñà‚ñä       | 933/3257 [00:04<00:12, 189.46it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:05<00:11, 200.96it/s] 30%|‚ñà‚ñà‚ñâ       | 977/3257 [00:05<00:11, 203.39it/s] 31%|‚ñà‚ñà‚ñà       | 998/3257 [00:05<00:11, 193.38it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1019/3257 [00:05<00:11, 195.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1039/3257 [00:05<00:12, 183.66it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1058/3257 [00:05<00:11, 183.72it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:05<00:11, 187.56it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1100/3257 [00:05<00:11, 190.42it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1120/3257 [00:05<00:11, 185.14it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:06<00:11, 184.53it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1161/3257 [00:06<00:10, 192.42it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1181/3257 [00:06<00:11, 185.42it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1200/3257 [00:06<00:11, 177.71it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:06<00:11, 175.46it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:06<00:10, 193.35it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1264/3257 [00:06<00:10, 196.64it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1284/3257 [00:06<00:10, 181.71it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1303/3257 [00:06<00:10, 183.18it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1325/3257 [00:07<00:10, 192.51it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:07<00:09, 196.41it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1366/3257 [00:07<00:09, 191.78it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:07<00:09, 187.49it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1408/3257 [00:07<00:09, 195.91it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1431/3257 [00:07<00:08, 204.35it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:07<00:08, 204.13it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1473/3257 [00:07<00:13, 129.61it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:08<00:11, 149.34it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1518/3257 [00:08<00:10, 164.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1538/3257 [00:08<00:10, 164.55it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1557/3257 [00:08<00:09, 170.41it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1576/3257 [00:08<00:09, 174.96it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1597/3257 [00:08<00:09, 184.44it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:08<00:08, 190.98it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:08<00:08, 189.99it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1659/3257 [00:08<00:08, 186.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1678/3257 [00:09<00:08, 180.41it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1699/3257 [00:09<00:08, 187.14it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1718/3257 [00:09<00:08, 186.65it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1737/3257 [00:09<00:08, 175.75it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1759/3257 [00:09<00:08, 185.88it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1780/3257 [00:09<00:07, 190.50it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1801/3257 [00:09<00:07, 194.51it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:09<00:07, 193.76it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1841/3257 [00:09<00:07, 191.16it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1862/3257 [00:09<00:07, 195.72it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1884/3257 [00:10<00:06, 201.54it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1905/3257 [00:10<00:06, 203.89it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1926/3257 [00:10<00:06, 202.02it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1957/3257 [00:10<00:05, 230.19it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1981/3257 [00:10<00:05, 219.29it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:10<00:05, 216.23it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2028/3257 [00:10<00:05, 222.47it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2051/3257 [00:10<00:06, 199.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2072/3257 [00:10<00:06, 194.89it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2092/3257 [00:11<00:05, 194.88it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2112/3257 [00:11<00:05, 193.50it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:11<00:06, 184.71it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2151/3257 [00:11<00:06, 184.12it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2173/3257 [00:11<00:05, 193.93it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2193/3257 [00:11<00:05, 193.23it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2213/3257 [00:11<00:05, 188.06it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2234/3257 [00:11<00:05, 192.96it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2254/3257 [00:11<00:05, 190.83it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2274/3257 [00:12<00:05, 177.53it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2298/3257 [00:12<00:04, 193.12it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2320/3257 [00:12<00:04, 199.94it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2344/3257 [00:12<00:04, 209.98it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2367/3257 [00:12<00:04, 214.08it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2391/3257 [00:12<00:03, 221.04it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2414/3257 [00:12<00:04, 209.87it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2436/3257 [00:12<00:04, 199.09it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2457/3257 [00:12<00:03, 201.99it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:13<00:03, 209.75it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:13<00:03, 220.98it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2532/3257 [00:13<00:03, 229.01it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2556/3257 [00:13<00:03, 219.32it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2579/3257 [00:13<00:03, 206.67it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2602/3257 [00:13<00:03, 212.45it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2631/3257 [00:13<00:02, 230.86it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2655/3257 [00:13<00:02, 219.88it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2678/3257 [00:13<00:02, 216.38it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2700/3257 [00:14<00:02, 202.25it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2721/3257 [00:14<00:02, 201.15it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2749/3257 [00:14<00:02, 220.66it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2772/3257 [00:14<00:02, 207.76it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2799/3257 [00:14<00:02, 224.05it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2822/3257 [00:14<00:02, 217.06it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2844/3257 [00:14<00:02, 206.07it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:14<00:01, 225.78it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2895/3257 [00:15<00:03, 117.05it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2918/3257 [00:15<00:02, 136.15it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2940/3257 [00:15<00:02, 151.19it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2960/3257 [00:15<00:01, 157.13it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2981/3257 [00:15<00:01, 166.76it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3005/3257 [00:15<00:01, 183.68it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:15<00:01, 185.76it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3050/3257 [00:15<00:01, 198.80it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3076/3257 [00:16<00:00, 214.36it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3099/3257 [00:16<00:00, 212.72it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3124/3257 [00:16<00:00, 222.85it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3147/3257 [00:16<00:00, 209.38it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3169/3257 [00:16<00:00, 207.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3191/3257 [00:16<00:00, 204.28it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3212/3257 [00:16<00:00, 205.17it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3236/3257 [00:16<00:00, 213.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 192.18it/s]
2023-02-07 19:02:02.569 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:02:02,571][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d92,n5,mc2,s0.373577,t4>', 'datetime': '2023-02-07T19:02:02.571602', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:02:02,572][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:02:02,572][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:02:02,939][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 19:02:02,940][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:02:02,971][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 11155 unique words (85.41% of original 13061, drops 1906)', 'datetime': '2023-02-07T19:02:02.971417', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:02:02,972][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 3637464 word corpus (99.95% of original 3639370, drops 1906)', 'datetime': '2023-02-07T19:02:02.972831', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:02:03,014][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 19:02:03,015][gensim.models.word2vec][INFO] - sample=0.373577 downsamples 0 most-common words
[2023-02-07 19:02:03,015][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3637464 word corpus (100.0%% of prior 3637464)', 'datetime': '2023-02-07T19:02:03.015708', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:02:03,087][gensim.models.word2vec][INFO] - estimated required memory for 11155 words and 92 dimensions: 15637556 bytes
[2023-02-07 19:02:03,088][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:02:03,096][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11155 vocabulary and 92 features, using sg=1 hs=0 sample=0.3735773848905827 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T19:02:03.096754', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:02:04,100][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 64.75% examples, 2398118 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:04,615][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3640721 effective words) took 1.5s, 2400574 effective words/s
[2023-02-07 19:02:05,620][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 65.09% examples, 2409983 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:06,115][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3640721 effective words) took 1.5s, 2430733 effective words/s
[2023-02-07 19:02:07,125][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 67.12% examples, 2474771 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:07,592][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3640721 effective words) took 1.5s, 2465857 effective words/s
[2023-02-07 19:02:08,597][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 65.92% examples, 2448045 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:09,080][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3640721 effective words) took 1.5s, 2450365 effective words/s
[2023-02-07 19:02:10,085][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 66.81% examples, 2471802 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:10,549][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3640721 effective words) took 1.5s, 2480710 effective words/s
[2023-02-07 19:02:11,555][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 65.77% examples, 2435589 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:12,042][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3640721 effective words) took 1.5s, 2441476 effective words/s
[2023-02-07 19:02:13,044][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 65.55% examples, 2436114 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:13,538][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3640721 effective words) took 1.5s, 2436091 effective words/s
[2023-02-07 19:02:14,541][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 65.34% examples, 2425774 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:15,031][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3640721 effective words) took 1.5s, 2441389 effective words/s
[2023-02-07 19:02:16,037][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 66.29% examples, 2453865 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:16,512][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3640721 effective words) took 1.5s, 2461315 effective words/s
[2023-02-07 19:02:17,524][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 67.12% examples, 2472148 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:17,979][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3640721 effective words) took 1.5s, 2484972 effective words/s
[2023-02-07 19:02:18,982][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 67.12% examples, 2493391 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:19,440][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3640721 effective words) took 1.5s, 2494801 effective words/s
[2023-02-07 19:02:20,445][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 66.93% examples, 2480539 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:20,905][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3640721 effective words) took 1.5s, 2488343 effective words/s
[2023-02-07 19:02:21,907][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 65.92% examples, 2453982 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:22,389][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3640721 effective words) took 1.5s, 2455199 effective words/s
[2023-02-07 19:02:23,392][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 65.92% examples, 2451623 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:23,875][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3640721 effective words) took 1.5s, 2452294 effective words/s
[2023-02-07 19:02:24,884][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 66.17% examples, 2446990 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:25,364][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3640721 effective words) took 1.5s, 2447569 effective words/s
[2023-02-07 19:02:25,365][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54610815 effective words) took 22.3s, 2452427 effective words/s', 'datetime': '2023-02-07T19:02:25.365293', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:02:25.365 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:02:27,556][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190136-bqt5h2l1/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:02:27.556029', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:02:27,556][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:02:27,581][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190136-bqt5h2l1/files/../tmp/embedding_model.pt
2023-02-07 19:02:27.581 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:02:28.807 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:02:29.287 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:02:45.684 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0263835424216763, 'test_mae': 0.7730602286070403, 'test_r2': -2.7062300417269594}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.41
wandb: percentage 0.14593
wandb:   test_mae 0.77306
wandb:   test_mse 1.02638
wandb:    test_r2 -2.70623
wandb: 
wandb: üöÄ View run lively-sweep-30 at: https://wandb.ai/xiaoqiz/mof2vec/runs/bqt5h2l1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_190136-bqt5h2l1/logs
wandb: Agent Starting Run: 6hsvn03d with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 687
wandb: 	model.gensim.alpha: 0.0007705178106277489
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.3342612936915084
wandb: 	model.gensim.vector_size: 258
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.026145302110633067
wandb: 	model.sklearn.max_depth: 23
wandb: 	model.sklearn.min_child_weight: 0.08859719257793854
wandb: 	model.sklearn.n_estimators: 158
wandb: 	model.sklearn.num_leaves: 346
wandb: 	model.sklearn.reg_alpha: 0.02656611203686025
wandb: 	model.sklearn.reg_lambda: 0.055564453849360755
wandb: 	model.sklearn.subsample: 0.4248937723647663
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190256-6hsvn03d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/6hsvn03d
2023-02-07 19:03:04.453 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 19:03:04.454 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 687 for sweep.
2023-02-07 19:03:04.454 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0007705178106277489 for sweep.
2023-02-07 19:03:04.454 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:03:04.455 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 19:03:04.455 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.3342612936915084 for sweep.
2023-02-07 19:03:04.455 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 258 for sweep.
2023-02-07 19:03:04.455 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 19:03:04.456 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.026145302110633067 for sweep.
2023-02-07 19:03:04.456 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 23 for sweep.
2023-02-07 19:03:04.456 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08859719257793854 for sweep.
2023-02-07 19:03:04.456 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 158 for sweep.
2023-02-07 19:03:04.457 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 346 for sweep.
2023-02-07 19:03:04.457 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.02656611203686025 for sweep.
2023-02-07 19:03:04.457 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.055564453849360755 for sweep.
2023-02-07 19:03:04.457 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.4248937723647663 for sweep.
2023-02-07 19:03:04.458 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:03:04.462 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190256-6hsvn03d/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 687, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 258, 'window': 2, 'min_count': 3, 'dm': 0, 'sample': 0.3342612936915084, 'workers': 4, 'alpha': 0.0007705178106277489, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 158, 'max_depth': 23, 'num_leaves': 346, 'reg_alpha': 0.02656611203686025, 'reg_lambda': 0.055564453849360755, 'subsample': 0.4248937723647663, 'min_child_weight': 0.08859719257793854, 'n_jobs': 4, 'learning_rate': 0.026145302110633067}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 21/3257 [00:00<00:15, 204.31it/s]  1%|‚ñè         | 42/3257 [00:00<00:16, 195.70it/s]  2%|‚ñè         | 64/3257 [00:00<00:15, 205.72it/s]  3%|‚ñé         | 85/3257 [00:00<00:15, 207.34it/s]  3%|‚ñé         | 106/3257 [00:00<00:16, 187.54it/s]  4%|‚ñç         | 127/3257 [00:00<00:16, 194.31it/s]  5%|‚ñç         | 151/3257 [00:00<00:15, 203.96it/s]  5%|‚ñå         | 172/3257 [00:00<00:15, 199.50it/s]  6%|‚ñå         | 193/3257 [00:00<00:15, 202.05it/s]  7%|‚ñã         | 214/3257 [00:01<00:14, 204.05it/s]  7%|‚ñã         | 237/3257 [00:01<00:14, 204.92it/s]  8%|‚ñä         | 259/3257 [00:01<00:14, 206.59it/s]  9%|‚ñâ         | 285/3257 [00:01<00:13, 219.79it/s]  9%|‚ñâ         | 308/3257 [00:01<00:13, 214.84it/s] 10%|‚ñà         | 331/3257 [00:01<00:13, 217.02it/s] 11%|‚ñà         | 353/3257 [00:01<00:13, 210.79it/s] 12%|‚ñà‚ñè        | 375/3257 [00:01<00:14, 204.05it/s] 12%|‚ñà‚ñè        | 396/3257 [00:01<00:14, 195.46it/s] 13%|‚ñà‚ñé        | 419/3257 [00:02<00:13, 203.75it/s] 14%|‚ñà‚ñé        | 440/3257 [00:02<00:15, 178.60it/s] 14%|‚ñà‚ñç        | 463/3257 [00:02<00:14, 191.75it/s] 15%|‚ñà‚ñç        | 483/3257 [00:02<00:14, 188.65it/s] 16%|‚ñà‚ñå        | 510/3257 [00:02<00:13, 206.80it/s] 16%|‚ñà‚ñã        | 532/3257 [00:02<00:13, 200.46it/s] 17%|‚ñà‚ñã        | 555/3257 [00:02<00:13, 207.57it/s] 18%|‚ñà‚ñä        | 577/3257 [00:02<00:14, 186.79it/s] 18%|‚ñà‚ñä        | 601/3257 [00:02<00:13, 199.77it/s] 19%|‚ñà‚ñâ        | 622/3257 [00:03<00:13, 194.54it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:13, 199.53it/s] 20%|‚ñà‚ñà        | 666/3257 [00:03<00:13, 192.78it/s] 21%|‚ñà‚ñà        | 686/3257 [00:03<00:13, 191.20it/s] 22%|‚ñà‚ñà‚ñè       | 709/3257 [00:03<00:12, 199.90it/s] 22%|‚ñà‚ñà‚ñè       | 730/3257 [00:03<00:13, 188.94it/s] 23%|‚ñà‚ñà‚ñé       | 750/3257 [00:03<00:13, 187.22it/s] 24%|‚ñà‚ñà‚ñé       | 772/3257 [00:03<00:12, 193.38it/s] 24%|‚ñà‚ñà‚ñç       | 792/3257 [00:03<00:13, 188.37it/s] 25%|‚ñà‚ñà‚ñç       | 811/3257 [00:04<00:19, 123.11it/s] 25%|‚ñà‚ñà‚ñå       | 829/3257 [00:04<00:18, 133.98it/s] 26%|‚ñà‚ñà‚ñå       | 846/3257 [00:04<00:17, 140.95it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:04<00:15, 154.82it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:04<00:14, 159.02it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:04<00:13, 177.67it/s] 29%|‚ñà‚ñà‚ñä       | 929/3257 [00:04<00:12, 189.09it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:05<00:12, 189.61it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:05<00:11, 193.75it/s] 30%|‚ñà‚ñà‚ñà       | 990/3257 [00:05<00:11, 190.01it/s] 31%|‚ñà‚ñà‚ñà       | 1010/3257 [00:05<00:11, 188.38it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1030/3257 [00:05<00:11, 188.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1050/3257 [00:05<00:12, 182.74it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1071/3257 [00:05<00:11, 189.44it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:05<00:11, 183.39it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1113/3257 [00:05<00:11, 193.27it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1133/3257 [00:05<00:11, 183.84it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1152/3257 [00:06<00:11, 183.15it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:06<00:11, 189.00it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1193/3257 [00:06<00:11, 173.70it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1211/3257 [00:06<00:11, 170.99it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:06<00:11, 182.59it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1252/3257 [00:06<00:10, 182.94it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:06<00:10, 186.76it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:06<00:11, 176.37it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1310/3257 [00:06<00:10, 178.68it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1332/3257 [00:07<00:10, 188.67it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1352/3257 [00:07<00:10, 185.67it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1371/3257 [00:07<00:10, 186.72it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1390/3257 [00:07<00:10, 183.40it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1415/3257 [00:07<00:09, 202.48it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1436/3257 [00:07<00:08, 203.16it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1461/3257 [00:07<00:08, 215.93it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1484/3257 [00:07<00:08, 214.30it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1509/3257 [00:07<00:07, 224.18it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1532/3257 [00:08<00:08, 203.15it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1553/3257 [00:08<00:09, 188.47it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:08<00:08, 192.84it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:08<00:08, 193.30it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:08<00:08, 198.28it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1638/3257 [00:08<00:08, 189.21it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1658/3257 [00:08<00:08, 183.32it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:08<00:08, 175.75it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1696/3257 [00:08<00:08, 178.87it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1716/3257 [00:09<00:08, 181.62it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1735/3257 [00:09<00:08, 170.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1756/3257 [00:09<00:08, 180.81it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1777/3257 [00:09<00:07, 187.37it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1797/3257 [00:09<00:07, 189.60it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1817/3257 [00:09<00:07, 185.28it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1836/3257 [00:09<00:07, 184.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1857/3257 [00:09<00:07, 188.64it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:09<00:07, 194.30it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:10<00:07, 189.81it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1919/3257 [00:10<00:07, 188.36it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1944/3257 [00:10<00:06, 205.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1966/3257 [00:10<00:06, 208.64it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1987/3257 [00:10<00:06, 198.27it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:10<00:06, 200.46it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2029/3257 [00:10<00:10, 120.52it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2046/3257 [00:11<00:09, 129.26it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2063/3257 [00:11<00:09, 131.27it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:11<00:08, 145.55it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:11<00:07, 151.33it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:11<00:07, 159.59it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2138/3257 [00:11<00:06, 162.18it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2156/3257 [00:11<00:06, 163.66it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:11<00:06, 172.88it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2199/3257 [00:11<00:05, 181.48it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2218/3257 [00:11<00:05, 179.92it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:12<00:05, 181.28it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:12<00:05, 185.11it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2278/3257 [00:12<00:05, 174.43it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:12<00:05, 183.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2324/3257 [00:12<00:04, 200.52it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2349/3257 [00:12<00:04, 214.53it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2371/3257 [00:12<00:04, 211.94it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2396/3257 [00:12<00:03, 220.95it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2419/3257 [00:12<00:04, 204.41it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:13<00:04, 198.28it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2461/3257 [00:13<00:04, 196.45it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2483/3257 [00:13<00:03, 200.46it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:13<00:03, 207.99it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2529/3257 [00:13<00:03, 210.49it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2551/3257 [00:13<00:03, 207.22it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:13<00:03, 191.14it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2592/3257 [00:13<00:03, 188.25it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2619/3257 [00:13<00:03, 207.16it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2641/3257 [00:14<00:02, 209.09it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2663/3257 [00:14<00:03, 195.60it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2685/3257 [00:14<00:02, 202.02it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2706/3257 [00:14<00:02, 183.78it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2725/3257 [00:14<00:02, 180.38it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2749/3257 [00:14<00:02, 195.81it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2769/3257 [00:14<00:02, 185.18it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:14<00:02, 196.01it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:14<00:02, 195.14it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:15<00:02, 186.37it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2854/3257 [00:15<00:02, 191.97it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2881/3257 [00:15<00:01, 213.56it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:15<00:01, 196.54it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2925/3257 [00:15<00:01, 202.70it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2946/3257 [00:15<00:01, 189.37it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:15<00:01, 190.39it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2986/3257 [00:15<00:01, 180.45it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:16<00:01, 195.15it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3035/3257 [00:16<00:01, 203.19it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3057/3257 [00:16<00:00, 207.77it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3081/3257 [00:16<00:00, 213.72it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3103/3257 [00:16<00:00, 215.37it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:16<00:00, 219.24it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3150/3257 [00:16<00:00, 203.70it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3171/3257 [00:16<00:00, 200.84it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3192/3257 [00:16<00:00, 197.25it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3212/3257 [00:16<00:00, 193.36it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3234/3257 [00:17<00:00, 198.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3254/3257 [00:17<00:00, 198.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 189.18it/s]
2023-02-07 19:03:22.346 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:03:22,347][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d258,n5,mc3,s0.334261,t4>', 'datetime': '2023-02-07T19:03:22.347498', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:03:22,348][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:03:22,348][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:03:22,789][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 19:03:22,790][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:03:22,834][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 15507 unique words (71.46% of original 21699, drops 6192)', 'datetime': '2023-02-07T19:03:22.834542', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:03:22,834][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 4358064 word corpus (99.79% of original 4367244, drops 9180)', 'datetime': '2023-02-07T19:03:22.834965', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:03:22,892][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 19:03:22,893][gensim.models.word2vec][INFO] - sample=0.334261 downsamples 0 most-common words
[2023-02-07 19:03:22,893][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4358064 word corpus (100.0%% of prior 4358064)', 'datetime': '2023-02-07T19:03:22.893492', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:03:22,992][gensim.models.word2vec][INFO] - estimated required memory for 15507 words and 258 dimensions: 43772572 bytes
[2023-02-07 19:03:22,993][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:03:23,014][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 15507 vocabulary and 258 features, using sg=1 hs=0 sample=0.3342612936915084 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T19:03:23.014884', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:03:24,022][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 46.64% examples, 2060378 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:03:25,024][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 95.36% examples, 2074795 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:25,111][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4359560 effective words) took 2.1s, 2081961 effective words/s
[2023-02-07 19:03:26,121][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 46.70% examples, 2052775 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:03:27,123][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 95.15% examples, 2068682 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:27,213][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4359560 effective words) took 2.1s, 2075524 effective words/s
[2023-02-07 19:03:28,220][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 45.81% examples, 2022423 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:29,224][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 94.20% examples, 2050710 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:29,332][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4359560 effective words) took 2.1s, 2059380 effective words/s
[2023-02-07 19:03:30,334][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 37.03% examples, 1655158 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:31,337][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 84.37% examples, 1852185 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:31,657][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4359560 effective words) took 2.3s, 1875610 effective words/s
[2023-02-07 19:03:32,661][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 45.32% examples, 2009822 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:33,662][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 91.22% examples, 1999527 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:33,825][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4359560 effective words) took 2.2s, 2013082 effective words/s
[2023-02-07 19:03:34,837][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 45.72% examples, 2013436 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:35,844][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 95.15% examples, 2060762 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:35,937][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4359560 effective words) took 2.1s, 2065740 effective words/s
[2023-02-07 19:03:36,939][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 45.10% examples, 2006494 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:37,942][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 93.00% examples, 2036869 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:38,074][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4359560 effective words) took 2.1s, 2042138 effective words/s
[2023-02-07 19:03:39,083][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 45.81% examples, 2018470 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:40,085][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 93.31% examples, 2035175 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:40,210][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4359560 effective words) took 2.1s, 2042187 effective words/s
[2023-02-07 19:03:41,212][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 45.53% examples, 2023303 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:42,214][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 94.69% examples, 2066739 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:42,316][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4359560 effective words) took 2.1s, 2072164 effective words/s
[2023-02-07 19:03:43,318][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 45.99% examples, 2041728 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:44,318][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 94.20% examples, 2058621 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:03:44,430][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4359560 effective words) took 2.1s, 2063035 effective words/s
[2023-02-07 19:03:45,432][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 44.55% examples, 1985702 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:46,436][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 91.25% examples, 1998020 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:46,607][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4359560 effective words) took 2.2s, 2004199 effective words/s
[2023-02-07 19:03:47,611][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 46.12% examples, 2039695 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:48,616][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 94.20% examples, 2052986 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:48,722][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4359560 effective words) took 2.1s, 2062801 effective words/s
[2023-02-07 19:03:49,727][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 46.64% examples, 2063392 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:03:50,734][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 94.20% examples, 2049667 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:50,847][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4359560 effective words) took 2.1s, 2052779 effective words/s
[2023-02-07 19:03:51,850][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 46.36% examples, 2051652 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:52,851][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 93.00% examples, 2038850 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:52,984][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4359560 effective words) took 2.1s, 2042359 effective words/s
[2023-02-07 19:03:53,989][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 45.81% examples, 2028182 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:54,995][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 94.20% examples, 2050631 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:03:55,107][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4359560 effective words) took 2.1s, 2055264 effective words/s
[2023-02-07 19:03:55,108][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65393400 effective words) took 32.1s, 2037629 effective words/s', 'datetime': '2023-02-07T19:03:55.108228', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:03:55.108 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:03:57,720][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190256-6hsvn03d/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:03:57.720708', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:03:57,721][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:03:57,778][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190256-6hsvn03d/files/../tmp/embedding_model.pt
2023-02-07 19:03:57.778 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:03:59.601 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:04:00.262 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:04:02.097 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9872668271335541, 'test_mae': 0.7673309687182216, 'test_r2': -2.3587357628983687}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.29
wandb: percentage 0.28536
wandb:   test_mae 0.76733
wandb:   test_mse 0.98727
wandb:    test_r2 -2.35874
wandb: 
wandb: üöÄ View run silver-sweep-31 at: https://wandb.ai/xiaoqiz/mof2vec/runs/6hsvn03d
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_190256-6hsvn03d/logs
wandb: Agent Starting Run: 4m90edlr with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 657
wandb: 	model.gensim.alpha: 0.004127113641234494
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.2603825515205796
wandb: 	model.gensim.vector_size: 413
wandb: 	model.gensim.window: 4
wandb: 	model.sklearn.learning_rate: 0.017190151699134196
wandb: 	model.sklearn.max_depth: 23
wandb: 	model.sklearn.min_child_weight: 0.03934666213460499
wandb: 	model.sklearn.n_estimators: 2883
wandb: 	model.sklearn.num_leaves: 453
wandb: 	model.sklearn.reg_alpha: 0.007667537883284979
wandb: 	model.sklearn.reg_lambda: 0.005841761427223042
wandb: 	model.sklearn.subsample: 0.208291658687543
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190415-4m90edlr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-32
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/4m90edlr
2023-02-07 19:04:23.964 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:04:23.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 657 for sweep.
2023-02-07 19:04:23.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.004127113641234494 for sweep.
2023-02-07 19:04:23.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:04:23.966 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 19:04:23.966 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2603825515205796 for sweep.
2023-02-07 19:04:23.966 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 413 for sweep.
2023-02-07 19:04:23.966 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 4 for sweep.
2023-02-07 19:04:23.967 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.017190151699134196 for sweep.
2023-02-07 19:04:23.967 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 23 for sweep.
2023-02-07 19:04:23.967 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03934666213460499 for sweep.
2023-02-07 19:04:23.967 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2883 for sweep.
2023-02-07 19:04:23.968 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 453 for sweep.
2023-02-07 19:04:23.968 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.007667537883284979 for sweep.
2023-02-07 19:04:23.968 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.005841761427223042 for sweep.
2023-02-07 19:04:23.968 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.208291658687543 for sweep.
2023-02-07 19:04:23.969 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:04:23.974 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190415-4m90edlr/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 657, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 413, 'window': 4, 'min_count': 5, 'dm': 1, 'sample': 0.2603825515205796, 'workers': 4, 'alpha': 0.004127113641234494, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2883, 'max_depth': 23, 'num_leaves': 453, 'reg_alpha': 0.007667537883284979, 'reg_lambda': 0.005841761427223042, 'subsample': 0.208291658687543, 'min_child_weight': 0.03934666213460499, 'n_jobs': 4, 'learning_rate': 0.017190151699134196}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:21, 149.30it/s]  1%|          | 33/3257 [00:00<00:19, 164.14it/s]  2%|‚ñè         | 50/3257 [00:00<00:20, 159.31it/s]  2%|‚ñè         | 67/3257 [00:00<00:20, 155.81it/s]  3%|‚ñé         | 87/3257 [00:00<00:18, 169.80it/s]  3%|‚ñé         | 105/3257 [00:00<00:30, 104.14it/s]  4%|‚ñé         | 121/3257 [00:00<00:27, 113.45it/s]  4%|‚ñç         | 141/3257 [00:01<00:23, 133.04it/s]  5%|‚ñç         | 158/3257 [00:01<00:21, 141.83it/s]  5%|‚ñå         | 174/3257 [00:01<00:21, 145.23it/s]  6%|‚ñå         | 193/3257 [00:01<00:19, 154.82it/s]  7%|‚ñã         | 212/3257 [00:01<00:18, 162.39it/s]  7%|‚ñã         | 234/3257 [00:01<00:16, 178.15it/s]  8%|‚ñä         | 253/3257 [00:01<00:17, 172.49it/s]  8%|‚ñä         | 271/3257 [00:01<00:17, 171.99it/s]  9%|‚ñâ         | 295/3257 [00:01<00:15, 190.71it/s] 10%|‚ñâ         | 315/3257 [00:02<00:16, 176.57it/s] 10%|‚ñà         | 335/3257 [00:02<00:16, 181.22it/s] 11%|‚ñà         | 354/3257 [00:02<00:16, 177.43it/s] 11%|‚ñà‚ñè        | 372/3257 [00:02<00:16, 176.98it/s] 12%|‚ñà‚ñè        | 390/3257 [00:02<00:17, 160.43it/s] 13%|‚ñà‚ñé        | 409/3257 [00:02<00:17, 166.76it/s] 13%|‚ñà‚ñé        | 426/3257 [00:02<00:19, 147.91it/s] 14%|‚ñà‚ñé        | 442/3257 [00:02<00:18, 150.09it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:18, 151.58it/s] 15%|‚ñà‚ñç        | 476/3257 [00:03<00:17, 154.59it/s] 15%|‚ñà‚ñå        | 493/3257 [00:03<00:17, 158.10it/s] 16%|‚ñà‚ñå        | 512/3257 [00:03<00:16, 166.83it/s] 16%|‚ñà‚ñå        | 529/3257 [00:03<00:16, 161.58it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:16, 162.22it/s] 17%|‚ñà‚ñã        | 563/3257 [00:03<00:17, 150.75it/s] 18%|‚ñà‚ñä        | 579/3257 [00:03<00:17, 149.12it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:16, 158.90it/s] 19%|‚ñà‚ñâ        | 619/3257 [00:03<00:15, 169.04it/s] 20%|‚ñà‚ñâ        | 637/3257 [00:04<00:16, 160.35it/s] 20%|‚ñà‚ñà        | 654/3257 [00:04<00:17, 153.06it/s] 21%|‚ñà‚ñà        | 670/3257 [00:04<00:17, 150.99it/s] 21%|‚ñà‚ñà        | 686/3257 [00:04<00:17, 147.06it/s] 22%|‚ñà‚ñà‚ñè       | 703/3257 [00:04<00:16, 151.63it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:04<00:16, 156.42it/s] 23%|‚ñà‚ñà‚ñé       | 737/3257 [00:04<00:16, 149.58it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:04<00:16, 152.89it/s] 24%|‚ñà‚ñà‚ñé       | 772/3257 [00:04<00:15, 158.72it/s] 24%|‚ñà‚ñà‚ñç       | 788/3257 [00:05<00:16, 152.85it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:05<00:16, 152.33it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:05<00:16, 149.42it/s] 26%|‚ñà‚ñà‚ñå       | 838/3257 [00:05<00:16, 145.24it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:05<00:17, 139.79it/s] 27%|‚ñà‚ñà‚ñã       | 869/3257 [00:05<00:16, 144.74it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:05<00:16, 139.98it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:15, 156.79it/s] 28%|‚ñà‚ñà‚ñä       | 921/3257 [00:05<00:14, 156.92it/s] 29%|‚ñà‚ñà‚ñâ       | 937/3257 [00:06<00:15, 152.42it/s] 29%|‚ñà‚ñà‚ñâ       | 955/3257 [00:06<00:14, 159.84it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:06<00:15, 152.12it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:06<00:15, 149.44it/s] 31%|‚ñà‚ñà‚ñà       | 1005/3257 [00:06<00:14, 154.65it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1021/3257 [00:06<00:14, 155.71it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1037/3257 [00:06<00:15, 146.60it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1052/3257 [00:06<00:15, 142.53it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1070/3257 [00:06<00:14, 152.20it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1086/3257 [00:07<00:14, 150.04it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1102/3257 [00:07<00:14, 152.67it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1119/3257 [00:07<00:14, 151.02it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1135/3257 [00:07<00:13, 152.77it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1151/3257 [00:07<00:14, 148.34it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:13, 159.30it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:07<00:13, 149.02it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1203/3257 [00:07<00:14, 139.66it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:07<00:14, 141.15it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1240/3257 [00:08<00:12, 162.19it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:08<00:12, 153.96it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1274/3257 [00:08<00:12, 157.93it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:08<00:13, 144.74it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:08<00:13, 149.87it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1327/3257 [00:08<00:12, 158.43it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:08<00:11, 159.56it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1361/3257 [00:08<00:12, 155.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1377/3257 [00:09<00:20, 90.30it/s]  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1391/3257 [00:09<00:18, 98.96it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1411/3257 [00:09<00:15, 119.87it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1430/3257 [00:09<00:13, 135.52it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1447/3257 [00:09<00:12, 143.62it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1467/3257 [00:09<00:11, 156.98it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1485/3257 [00:09<00:11, 157.52it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1508/3257 [00:09<00:09, 175.96it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1527/3257 [00:10<00:10, 160.54it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1544/3257 [00:10<00:11, 153.58it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1561/3257 [00:10<00:10, 156.32it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1578/3257 [00:10<00:10, 156.71it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1597/3257 [00:10<00:10, 164.25it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:10<00:09, 170.05it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:10<00:10, 160.95it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1652/3257 [00:10<00:10, 156.86it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:10<00:10, 153.98it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1684/3257 [00:11<00:10, 151.18it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1702/3257 [00:11<00:09, 157.42it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1718/3257 [00:11<00:09, 156.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1734/3257 [00:11<00:10, 142.21it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1753/3257 [00:11<00:09, 152.98it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1772/3257 [00:11<00:09, 161.88it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1791/3257 [00:11<00:08, 168.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1809/3257 [00:11<00:09, 156.00it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:11<00:09, 156.31it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1844/3257 [00:12<00:08, 161.47it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1861/3257 [00:12<00:08, 161.19it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:12<00:08, 163.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1896/3257 [00:12<00:08, 159.49it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:12<00:08, 160.95it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1935/3257 [00:12<00:07, 167.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1958/3257 [00:12<00:07, 183.79it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1977/3257 [00:12<00:07, 177.74it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1996/3257 [00:12<00:06, 180.77it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2015/3257 [00:13<00:07, 172.65it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2034/3257 [00:13<00:06, 176.00it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:13<00:07, 161.29it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2069/3257 [00:13<00:07, 155.97it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:13<00:07, 156.61it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2101/3257 [00:13<00:07, 153.58it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:13<00:07, 153.55it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:13<00:07, 152.53it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2152/3257 [00:13<00:07, 149.50it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2170/3257 [00:14<00:06, 156.42it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2186/3257 [00:14<00:06, 154.16it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2205/3257 [00:14<00:06, 163.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2222/3257 [00:14<00:06, 158.29it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:14<00:06, 154.52it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2255/3257 [00:14<00:06, 158.11it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2271/3257 [00:14<00:06, 151.38it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2291/3257 [00:14<00:05, 162.73it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2308/3257 [00:14<00:05, 159.87it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2330/3257 [00:15<00:05, 176.46it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2352/3257 [00:15<00:04, 188.57it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2372/3257 [00:15<00:04, 177.99it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2393/3257 [00:15<00:04, 185.34it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2412/3257 [00:15<00:04, 171.19it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2430/3257 [00:15<00:04, 165.55it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2447/3257 [00:15<00:05, 160.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2464/3257 [00:15<00:04, 163.18it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:15<00:04, 164.83it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2501/3257 [00:16<00:04, 173.46it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2519/3257 [00:16<00:04, 171.66it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2539/3257 [00:16<00:04, 178.41it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2557/3257 [00:16<00:04, 165.55it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2574/3257 [00:16<00:04, 156.13it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2590/3257 [00:16<00:04, 152.99it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:16<00:03, 174.73it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:16<00:03, 180.80it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2653/3257 [00:16<00:03, 171.32it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2671/3257 [00:17<00:03, 168.43it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2689/3257 [00:17<00:03, 168.46it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2706/3257 [00:17<00:03, 150.28it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2722/3257 [00:17<00:03, 144.30it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2742/3257 [00:17<00:03, 158.20it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2760/3257 [00:17<00:03, 162.46it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2777/3257 [00:17<00:03, 152.53it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2798/3257 [00:17<00:02, 167.45it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2816/3257 [00:18<00:02, 159.70it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:18<00:05, 79.17it/s]  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2851/3257 [00:18<00:04, 94.38it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2873/3257 [00:18<00:03, 116.57it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2890/3257 [00:18<00:02, 126.75it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:18<00:02, 128.36it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:19<00:02, 140.36it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2944/3257 [00:19<00:02, 134.74it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2959/3257 [00:19<00:02, 136.14it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:19<00:02, 138.27it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2991/3257 [00:19<00:01, 137.29it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3010/3257 [00:19<00:01, 151.12it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:19<00:01, 145.15it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3044/3257 [00:19<00:01, 154.40it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:19<00:01, 163.54it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3080/3257 [00:20<00:01, 163.09it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3097/3257 [00:20<00:01, 158.06it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3117/3257 [00:20<00:00, 169.26it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3135/3257 [00:20<00:00, 156.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3151/3257 [00:20<00:00, 149.19it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3167/3257 [00:20<00:00, 150.51it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:20<00:00, 145.00it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3202/3257 [00:20<00:00, 155.99it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3218/3257 [00:20<00:00, 147.77it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3237/3257 [00:21<00:00, 157.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:21<00:00, 157.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 153.60it/s]
2023-02-07 19:04:46.058 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:04:46,060][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d413,n5,w4,mc5,s0.260383,t4>', 'datetime': '2023-02-07T19:04:46.059898', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:04:46,060][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:04:46,060][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:04:46,665][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:04:46,666][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:04:46,732][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 21312 unique words (49.91% of original 42701, drops 21389)', 'datetime': '2023-02-07T19:04:46.732558', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:04:46,733][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5769229 word corpus (99.08% of original 5822992, drops 53763)', 'datetime': '2023-02-07T19:04:46.733014', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:04:46,812][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:04:46,813][gensim.models.word2vec][INFO] - sample=0.260383 downsamples 0 most-common words
[2023-02-07 19:04:46,814][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5769229 word corpus (100.0%% of prior 5769229)', 'datetime': '2023-02-07T19:04:46.814193', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:04:46,953][gensim.models.word2vec][INFO] - estimated required memory for 21312 words and 413 dimensions: 87102812 bytes
[2023-02-07 19:04:46,954][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:04:47,001][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 21312 vocabulary and 413 features, using sg=0 hs=0 sample=0.2603825515205796 negative=5 window=4 shrink_windows=True', 'datetime': '2023-02-07T19:04:47.001313', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:04:48,010][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 15.26% examples, 850673 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:49,012][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 30.92% examples, 892475 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:50,016][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 47.19% examples, 918208 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:51,021][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 64.54% examples, 940230 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:52,026][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 85.78% examples, 988949 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:52,646][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5743174 effective words) took 5.6s, 1018078 effective words/s
[2023-02-07 19:04:53,653][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 21.40% examples, 1208812 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:54,655][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 41.97% examples, 1231977 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:55,658][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 64.17% examples, 1245249 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:56,663][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 86.25% examples, 1243296 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:04:57,250][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5743174 effective words) took 4.6s, 1247781 effective words/s
[2023-02-07 19:04:58,258][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 22.11% examples, 1246746 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:59,258][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 42.98% examples, 1265805 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:00,269][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 65.83% examples, 1280595 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:01,270][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 89.50% examples, 1287472 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:01,722][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5743174 effective words) took 4.5s, 1284880 effective words/s
[2023-02-07 19:05:02,724][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 22.57% examples, 1280698 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:03,730][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 44.03% examples, 1292063 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:04,733][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 66.17% examples, 1290372 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:05,741][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 89.65% examples, 1289698 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:06,172][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5743174 effective words) took 4.4s, 1291172 effective words/s
[2023-02-07 19:05:07,185][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 22.20% examples, 1249096 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:05:08,185][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 43.69% examples, 1279597 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:09,185][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 66.38% examples, 1292189 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:10,187][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 89.90% examples, 1294775 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:10,608][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5743174 effective words) took 4.4s, 1294995 effective words/s
[2023-02-07 19:05:11,614][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 22.35% examples, 1268527 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:12,628][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 43.78% examples, 1280568 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:05:13,631][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 66.38% examples, 1288610 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:14,639][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 89.65% examples, 1286032 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:15,074][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5743174 effective words) took 4.5s, 1286790 effective words/s
[2023-02-07 19:05:16,080][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 23.61% examples, 1334794 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:17,090][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 45.69% examples, 1327667 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:18,091][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 67.61% examples, 1313219 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:19,092][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 90.85% examples, 1309580 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:19,451][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5743174 effective words) took 4.4s, 1312671 effective words/s
[2023-02-07 19:05:20,452][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 22.78% examples, 1298650 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:21,456][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 44.43% examples, 1303495 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:22,461][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 66.41% examples, 1294897 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:23,465][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 90.33% examples, 1299960 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:23,875][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5743174 effective words) took 4.4s, 1298594 effective words/s
[2023-02-07 19:05:24,880][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 22.72% examples, 1295680 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:25,881][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 44.61% examples, 1306994 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:26,885][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 67.82% examples, 1322814 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:27,890][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 91.77% examples, 1323784 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:28,216][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5743174 effective words) took 4.3s, 1323487 effective words/s
[2023-02-07 19:05:29,224][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 23.15% examples, 1314683 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:30,228][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 45.69% examples, 1330417 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:31,230][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 68.16% examples, 1326940 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:32,235][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 92.42% examples, 1329051 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:32,535][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5743174 effective words) took 4.3s, 1330276 effective words/s
[2023-02-07 19:05:33,538][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 22.90% examples, 1306368 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:34,542][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 45.19% examples, 1319770 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:05:35,544][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 68.65% examples, 1338046 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:36,549][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 91.96% examples, 1325915 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:36,871][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5743174 effective words) took 4.3s, 1324970 effective words/s
[2023-02-07 19:05:37,880][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 22.78% examples, 1289786 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:38,887][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 44.18% examples, 1291824 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:39,890][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 66.60% examples, 1293985 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:05:40,892][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 90.33% examples, 1298041 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:41,280][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5743174 effective words) took 4.4s, 1303199 effective words/s
[2023-02-07 19:05:42,284][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 23.40% examples, 1327892 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:43,288][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 44.86% examples, 1310595 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:44,290][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 67.45% examples, 1312996 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:45,290][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 90.51% examples, 1305953 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:45,677][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5743174 effective words) took 4.4s, 1306577 effective words/s
[2023-02-07 19:05:46,682][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 22.72% examples, 1295840 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:47,683][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 44.61% examples, 1307204 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:48,687][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 67.30% examples, 1311091 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:49,690][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 91.19% examples, 1313892 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:50,058][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5743174 effective words) took 4.4s, 1311396 effective words/s
[2023-02-07 19:05:51,078][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 21.58% examples, 1202883 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:52,080][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 39.24% examples, 1145379 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:53,091][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 58.58% examples, 1132873 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:05:54,091][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 78.17% examples, 1122900 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:55,092][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 98.25% examples, 1122317 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:55,176][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5743174 effective words) took 5.1s, 1122645 effective words/s
[2023-02-07 19:05:55,176][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86147610 effective words) took 68.2s, 1263628 effective words/s', 'datetime': '2023-02-07T19:05:55.176647', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:05:55.177 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:06:01,341][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190415-4m90edlr/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:06:01.340988', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:06:01,341][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:06:01,453][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190415-4m90edlr/files/../tmp/embedding_model.pt
2023-02-07 19:06:01.454 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:06:04.029 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:06:04.907 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:06:13.253 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1313808116723005, 'test_mae': 0.8139447559334018, 'test_r2': -2.3399651122136307}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.49
wandb: percentage 0.5009
wandb:   test_mae 0.81394
wandb:   test_mse 1.13138
wandb:    test_r2 -2.33997
wandb: 
wandb: üöÄ View run misty-sweep-32 at: https://wandb.ai/xiaoqiz/mof2vec/runs/4m90edlr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_190415-4m90edlr/logs
wandb: Agent Starting Run: 2zyt9pui with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 876
wandb: 	model.gensim.alpha: 0.004702932264062657
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.4500958579431899
wandb: 	model.gensim.vector_size: 338
wandb: 	model.gensim.window: 13
wandb: 	model.sklearn.learning_rate: 0.2510673139112755
wandb: 	model.sklearn.max_depth: 36
wandb: 	model.sklearn.min_child_weight: 0.029307489004954928
wandb: 	model.sklearn.n_estimators: 873
wandb: 	model.sklearn.num_leaves: 328
wandb: 	model.sklearn.reg_alpha: 0.002623125599841999
wandb: 	model.sklearn.reg_lambda: 0.013774084876732644
wandb: 	model.sklearn.subsample: 0.2796150708132095
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190626-2zyt9pui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-33
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/2zyt9pui
2023-02-07 19:06:34.701 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:06:34.701 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 876 for sweep.
2023-02-07 19:06:34.702 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.004702932264062657 for sweep.
2023-02-07 19:06:34.702 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:06:34.702 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 19:06:34.703 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4500958579431899 for sweep.
2023-02-07 19:06:34.703 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 338 for sweep.
2023-02-07 19:06:34.704 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 13 for sweep.
2023-02-07 19:06:34.704 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.2510673139112755 for sweep.
2023-02-07 19:06:34.704 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 36 for sweep.
2023-02-07 19:06:34.704 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.029307489004954928 for sweep.
2023-02-07 19:06:34.705 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 873 for sweep.
2023-02-07 19:06:34.705 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 328 for sweep.
2023-02-07 19:06:34.705 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.002623125599841999 for sweep.
2023-02-07 19:06:34.705 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.013774084876732644 for sweep.
2023-02-07 19:06:34.706 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2796150708132095 for sweep.
2023-02-07 19:06:34.706 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:06:34.713 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190626-2zyt9pui/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 876, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 338, 'window': 13, 'min_count': 6, 'dm': 0, 'sample': 0.4500958579431899, 'workers': 4, 'alpha': 0.004702932264062657, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 873, 'max_depth': 36, 'num_leaves': 328, 'reg_alpha': 0.002623125599841999, 'reg_lambda': 0.013774084876732644, 'subsample': 0.2796150708132095, 'min_child_weight': 0.029307489004954928, 'n_jobs': 4, 'learning_rate': 0.2510673139112755}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:22, 143.36it/s]  1%|          | 33/3257 [00:00<00:20, 159.43it/s]  2%|‚ñè         | 49/3257 [00:00<00:20, 159.00it/s]  2%|‚ñè         | 67/3257 [00:00<00:20, 152.04it/s]  3%|‚ñé         | 88/3257 [00:00<00:18, 170.97it/s]  3%|‚ñé         | 106/3257 [00:00<00:20, 151.62it/s]  4%|‚ñç         | 124/3257 [00:00<00:20, 155.91it/s]  4%|‚ñç         | 145/3257 [00:00<00:18, 168.01it/s]  5%|‚ñå         | 163/3257 [00:01<00:19, 158.79it/s]  6%|‚ñå         | 181/3257 [00:01<00:18, 162.99it/s]  6%|‚ñå         | 201/3257 [00:01<00:18, 166.81it/s]  7%|‚ñã         | 223/3257 [00:01<00:16, 180.94it/s]  7%|‚ñã         | 243/3257 [00:01<00:16, 185.04it/s]  8%|‚ñä         | 262/3257 [00:01<00:17, 173.23it/s]  9%|‚ñâ         | 285/3257 [00:01<00:15, 188.14it/s]  9%|‚ñâ         | 305/3257 [00:01<00:16, 180.07it/s] 10%|‚ñà         | 326/3257 [00:01<00:15, 185.86it/s] 11%|‚ñà         | 345/3257 [00:02<00:16, 173.85it/s] 11%|‚ñà         | 364/3257 [00:02<00:16, 176.50it/s] 12%|‚ñà‚ñè        | 382/3257 [00:02<00:17, 165.89it/s] 12%|‚ñà‚ñè        | 399/3257 [00:02<00:17, 161.38it/s] 13%|‚ñà‚ñé        | 419/3257 [00:02<00:16, 170.31it/s] 13%|‚ñà‚ñé        | 437/3257 [00:02<00:19, 143.55it/s] 14%|‚ñà‚ñç        | 457/3257 [00:02<00:18, 155.38it/s] 15%|‚ñà‚ñç        | 475/3257 [00:02<00:17, 160.22it/s] 15%|‚ñà‚ñå        | 492/3257 [00:02<00:17, 161.75it/s] 16%|‚ñà‚ñå        | 511/3257 [00:03<00:16, 169.09it/s] 16%|‚ñà‚ñå        | 529/3257 [00:03<00:16, 163.19it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:16, 162.88it/s] 17%|‚ñà‚ñã        | 563/3257 [00:03<00:17, 153.24it/s] 18%|‚ñà‚ñä        | 579/3257 [00:03<00:17, 151.71it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:16, 160.09it/s] 19%|‚ñà‚ñâ        | 619/3257 [00:03<00:15, 169.65it/s] 20%|‚ñà‚ñâ        | 637/3257 [00:03<00:16, 158.80it/s] 20%|‚ñà‚ñà        | 654/3257 [00:03<00:17, 152.33it/s] 21%|‚ñà‚ñà        | 670/3257 [00:04<00:17, 150.34it/s] 21%|‚ñà‚ñà        | 686/3257 [00:04<00:17, 146.09it/s] 22%|‚ñà‚ñà‚ñè       | 703/3257 [00:04<00:16, 151.02it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:04<00:16, 155.76it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:04<00:17, 144.80it/s] 23%|‚ñà‚ñà‚ñé       | 753/3257 [00:04<00:16, 149.89it/s] 24%|‚ñà‚ñà‚ñé       | 771/3257 [00:04<00:15, 155.94it/s] 24%|‚ñà‚ñà‚ñç       | 787/3257 [00:04<00:16, 150.30it/s] 25%|‚ñà‚ñà‚ñç       | 805/3257 [00:04<00:15, 157.34it/s] 25%|‚ñà‚ñà‚ñå       | 821/3257 [00:05<00:16, 151.67it/s] 26%|‚ñà‚ñà‚ñå       | 837/3257 [00:05<00:16, 145.74it/s] 26%|‚ñà‚ñà‚ñå       | 852/3257 [00:05<00:16, 142.69it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:05<00:16, 145.67it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:05<00:16, 141.71it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:14, 157.58it/s] 28%|‚ñà‚ñà‚ñä       | 921/3257 [00:05<00:14, 157.82it/s] 29%|‚ñà‚ñà‚ñâ       | 937/3257 [00:05<00:14, 155.76it/s] 29%|‚ñà‚ñà‚ñâ       | 957/3257 [00:05<00:13, 166.15it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:06<00:14, 162.70it/s] 30%|‚ñà‚ñà‚ñà       | 991/3257 [00:06<00:23, 95.69it/s]  31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:06<00:21, 104.73it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:06<00:18, 119.75it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1040/3257 [00:06<00:18, 121.24it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1055/3257 [00:06<00:17, 126.78it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1073/3257 [00:06<00:15, 139.37it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1089/3257 [00:07<00:15, 141.22it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:07<00:14, 144.38it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1121/3257 [00:07<00:14, 145.43it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1137/3257 [00:07<00:14, 148.27it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1153/3257 [00:07<00:14, 145.71it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:07<00:13, 152.67it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:07<00:14, 146.86it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1202/3257 [00:07<00:15, 136.52it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1217/3257 [00:07<00:14, 140.03it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1238/3257 [00:08<00:12, 157.71it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1255/3257 [00:08<00:13, 153.36it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:08<00:12, 156.43it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:08<00:13, 144.00it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1304/3257 [00:08<00:13, 148.27it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1322/3257 [00:08<00:12, 155.84it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1341/3257 [00:08<00:11, 163.97it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1358/3257 [00:08<00:12, 156.55it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1374/3257 [00:08<00:12, 153.91it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1390/3257 [00:09<00:12, 150.96it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:09<00:11, 167.39it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:09<00:10, 170.16it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:09<00:10, 176.05it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1472/3257 [00:09<00:09, 181.26it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1491/3257 [00:09<00:09, 179.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:09<00:09, 183.81it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:09<00:10, 164.21it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1547/3257 [00:09<00:11, 154.33it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1565/3257 [00:10<00:10, 158.12it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1582/3257 [00:10<00:10, 155.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1602/3257 [00:10<00:09, 166.06it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:10<00:09, 167.84it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1637/3257 [00:10<00:10, 161.53it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:10<00:10, 160.00it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1671/3257 [00:10<00:10, 153.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1689/3257 [00:10<00:09, 158.60it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:10<00:09, 161.55it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1726/3257 [00:11<00:09, 169.35it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:11<00:10, 147.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:11<00:09, 156.50it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1783/3257 [00:11<00:08, 167.70it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1801/3257 [00:11<00:08, 167.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1819/3257 [00:11<00:08, 163.71it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1836/3257 [00:11<00:08, 158.82it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1853/3257 [00:11<00:08, 161.34it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1871/3257 [00:11<00:08, 166.09it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1888/3257 [00:12<00:08, 163.91it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1906/3257 [00:12<00:08, 166.72it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1923/3257 [00:12<00:08, 160.68it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1945/3257 [00:12<00:07, 175.37it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1966/3257 [00:12<00:07, 183.50it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1985/3257 [00:12<00:07, 169.48it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:12<00:07, 170.58it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2023/3257 [00:12<00:07, 173.93it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2041/3257 [00:12<00:07, 165.27it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2058/3257 [00:13<00:07, 158.27it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2075/3257 [00:13<00:07, 158.40it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:13<00:07, 157.93it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2107/3257 [00:13<00:07, 154.70it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2123/3257 [00:13<00:07, 144.01it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2140/3257 [00:13<00:07, 149.44it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2156/3257 [00:13<00:07, 146.87it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2176/3257 [00:13<00:06, 160.49it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2193/3257 [00:13<00:06, 154.28it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:14<00:06, 150.42it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2226/3257 [00:14<00:06, 154.62it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2242/3257 [00:14<00:06, 151.86it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:14<00:06, 155.66it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:14<00:06, 144.34it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2297/3257 [00:14<00:05, 162.22it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2314/3257 [00:14<00:05, 161.00it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2335/3257 [00:14<00:05, 174.07it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2358/3257 [00:14<00:04, 187.92it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2377/3257 [00:15<00:04, 176.70it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2398/3257 [00:15<00:08, 100.17it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2413/3257 [00:15<00:07, 106.67it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2430/3257 [00:15<00:07, 117.82it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2445/3257 [00:15<00:06, 123.91it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2464/3257 [00:15<00:05, 138.55it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:16<00:05, 145.88it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2502/3257 [00:16<00:04, 162.48it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2520/3257 [00:16<00:04, 163.94it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:16<00:04, 167.26it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2558/3257 [00:16<00:04, 163.88it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2575/3257 [00:16<00:04, 154.49it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2591/3257 [00:16<00:04, 148.92it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:16<00:03, 169.15it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:16<00:03, 175.71it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2652/3257 [00:17<00:03, 165.48it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2669/3257 [00:17<00:03, 164.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:17<00:03, 167.98it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:17<00:03, 147.18it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2720/3257 [00:17<00:03, 146.47it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:17<00:03, 160.72it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2759/3257 [00:17<00:03, 165.35it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2776/3257 [00:17<00:03, 158.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2798/3257 [00:17<00:02, 173.87it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2816/3257 [00:18<00:02, 166.45it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:18<00:02, 161.63it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2852/3257 [00:18<00:02, 167.40it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2876/3257 [00:18<00:02, 187.70it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2896/3257 [00:18<00:02, 170.07it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:18<00:01, 174.85it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2934/3257 [00:18<00:01, 168.57it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2952/3257 [00:18<00:01, 153.09it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:18<00:01, 156.91it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2986/3257 [00:19<00:01, 147.58it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3006/3257 [00:19<00:01, 161.18it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3023/3257 [00:19<00:01, 154.89it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3042/3257 [00:19<00:01, 163.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:19<00:01, 172.16it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3081/3257 [00:19<00:01, 170.07it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3099/3257 [00:19<00:00, 168.67it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:19<00:00, 174.21it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3136/3257 [00:19<00:00, 165.79it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3153/3257 [00:20<00:00, 157.37it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3169/3257 [00:20<00:00, 156.04it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:20<00:00, 150.17it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:20<00:00, 158.12it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3219/3257 [00:20<00:00, 150.14it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:20<00:00, 162.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3256/3257 [00:20<00:00, 162.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 156.80it/s]
2023-02-07 19:06:56.404 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:06:56,405][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d338,n5,mc6,s0.450096,t4>', 'datetime': '2023-02-07T19:06:56.405736', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:06:56,406][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:06:56,406][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:06:57,022][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:06:57,023][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:06:57,086][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 20659 unique words (48.38% of original 42701, drops 22042)', 'datetime': '2023-02-07T19:06:57.086650', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:06:57,087][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 5765964 word corpus (99.02% of original 5822992, drops 57028)', 'datetime': '2023-02-07T19:06:57.087129', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:06:57,163][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:06:57,165][gensim.models.word2vec][INFO] - sample=0.450096 downsamples 0 most-common words
[2023-02-07 19:06:57,165][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5765964 word corpus (100.0%% of prior 5765964)', 'datetime': '2023-02-07T19:06:57.165293', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:06:57,300][gensim.models.word2vec][INFO] - estimated required memory for 20659 words and 338 dimensions: 71246300 bytes
[2023-02-07 19:06:57,300][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:06:57,343][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 20659 vocabulary and 338 features, using sg=1 hs=0 sample=0.4500958579431899 negative=5 window=13 shrink_windows=True', 'datetime': '2023-02-07T19:06:57.343283', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:06:58,345][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 29.81% examples, 1714892 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:06:59,353][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 59.41% examples, 1732727 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:00,358][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 91.34% examples, 1751522 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:00,610][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5739976 effective words) took 3.3s, 1757842 effective words/s
[2023-02-07 19:07:01,613][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 32.67% examples, 1898108 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:02,615][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 65.34% examples, 1909345 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:03,596][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5739976 effective words) took 3.0s, 1923732 effective words/s
[2023-02-07 19:07:04,601][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 34.20% examples, 1977035 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:05,602][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 67.45% examples, 1969460 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:06,549][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5739976 effective words) took 3.0s, 1945035 effective words/s
[2023-02-07 19:07:07,555][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 32.67% examples, 1891455 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:08,555][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 65.83% examples, 1926161 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:09,498][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5739976 effective words) took 2.9s, 1947706 effective words/s
[2023-02-07 19:07:10,506][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 33.25% examples, 1921978 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:11,507][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 65.83% examples, 1923962 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:07:12,481][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5739976 effective words) took 3.0s, 1925103 effective words/s
[2023-02-07 19:07:13,485][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 34.26% examples, 1983887 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:14,486][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 67.79% examples, 1981806 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:15,366][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5739976 effective words) took 2.9s, 1990419 effective words/s
[2023-02-07 19:07:16,369][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 34.26% examples, 1986923 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:17,373][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 67.45% examples, 1969514 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:18,273][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5739976 effective words) took 2.9s, 1976084 effective words/s
[2023-02-07 19:07:19,277][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 34.57% examples, 2007356 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:20,282][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 68.04% examples, 1986462 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:21,190][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5739976 effective words) took 2.9s, 1969528 effective words/s
[2023-02-07 19:07:22,200][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 33.90% examples, 1954712 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:23,206][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 67.79% examples, 1972389 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:24,072][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5739976 effective words) took 2.9s, 1994037 effective words/s
[2023-02-07 19:07:25,075][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 34.20% examples, 1980160 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:26,077][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 68.41% examples, 1998850 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:26,956][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5739976 effective words) took 2.9s, 1992081 effective words/s
[2023-02-07 19:07:27,960][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 34.85% examples, 2023910 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:28,962][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 68.35% examples, 1997627 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:07:29,837][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5739976 effective words) took 2.9s, 1993358 effective words/s
[2023-02-07 19:07:30,846][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 33.71% examples, 1946026 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:31,849][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 66.93% examples, 1950544 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:32,782][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5739976 effective words) took 2.9s, 1950484 effective words/s
[2023-02-07 19:07:33,786][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 33.71% examples, 1955361 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:34,792][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 66.99% examples, 1955869 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:35,711][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5739976 effective words) took 2.9s, 1960771 effective words/s
[2023-02-07 19:07:36,716][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 34.33% examples, 1985924 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:37,719][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 67.24% examples, 1962622 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:07:38,640][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5739976 effective words) took 2.9s, 1960522 effective words/s
[2023-02-07 19:07:39,644][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 33.31% examples, 1937642 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:07:40,651][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 66.69% examples, 1946679 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:07:41,588][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5739976 effective words) took 2.9s, 1948492 effective words/s
[2023-02-07 19:07:41,588][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86099640 effective words) took 44.2s, 1945973 effective words/s', 'datetime': '2023-02-07T19:07:41.588787', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:07:41.589 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:07:46,294][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190626-2zyt9pui/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:07:46.294685', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:07:46,295][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:07:46,398][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190626-2zyt9pui/files/../tmp/embedding_model.pt
2023-02-07 19:07:46.399 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:07:48.654 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:07:49.451 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:08:18.034 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9480073175117226, 'test_mae': 0.7414769508813056, 'test_r2': -1.7073948875387814}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.77
wandb: percentage 0.51619
wandb:   test_mae 0.74148
wandb:   test_mse 0.94801
wandb:    test_r2 -1.70739
wandb: 
wandb: üöÄ View run resilient-sweep-33 at: https://wandb.ai/xiaoqiz/mof2vec/runs/2zyt9pui
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_190626-2zyt9pui/logs
wandb: Agent Starting Run: dwhwn4qx with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 633
wandb: 	model.gensim.alpha: 0.010234616700751651
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.6071990287723343
wandb: 	model.gensim.vector_size: 302
wandb: 	model.gensim.window: 5
wandb: 	model.sklearn.learning_rate: 0.208613041561614
wandb: 	model.sklearn.max_depth: 36
wandb: 	model.sklearn.min_child_weight: 0.04515003817587657
wandb: 	model.sklearn.n_estimators: 2235
wandb: 	model.sklearn.num_leaves: 416
wandb: 	model.sklearn.reg_alpha: 0.007673408758200015
wandb: 	model.sklearn.reg_lambda: 0.12091543571298972
wandb: 	model.sklearn.subsample: 0.46605042094671784
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190828-dwhwn4qx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-34
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/dwhwn4qx
2023-02-07 19:08:37.485 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:08:37.486 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 633 for sweep.
2023-02-07 19:08:37.486 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.010234616700751651 for sweep.
2023-02-07 19:08:37.487 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:08:37.487 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 19:08:37.487 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6071990287723343 for sweep.
2023-02-07 19:08:37.487 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 302 for sweep.
2023-02-07 19:08:37.488 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 5 for sweep.
2023-02-07 19:08:37.488 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.208613041561614 for sweep.
2023-02-07 19:08:37.488 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 36 for sweep.
2023-02-07 19:08:37.488 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.04515003817587657 for sweep.
2023-02-07 19:08:37.489 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2235 for sweep.
2023-02-07 19:08:37.489 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 416 for sweep.
2023-02-07 19:08:37.489 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.007673408758200015 for sweep.
2023-02-07 19:08:37.489 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.12091543571298972 for sweep.
2023-02-07 19:08:37.490 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.46605042094671784 for sweep.
2023-02-07 19:08:37.490 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:08:37.496 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190828-dwhwn4qx/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 633, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 302, 'window': 5, 'min_count': 8, 'dm': 0, 'sample': 0.6071990287723343, 'workers': 4, 'alpha': 0.010234616700751651, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2235, 'max_depth': 36, 'num_leaves': 416, 'reg_alpha': 0.007673408758200015, 'reg_lambda': 0.12091543571298972, 'subsample': 0.46605042094671784, 'min_child_weight': 0.04515003817587657, 'n_jobs': 4, 'learning_rate': 0.208613041561614}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:25, 129.29it/s]  1%|          | 29/3257 [00:00<00:22, 145.01it/s]  1%|‚ñè         | 44/3257 [00:00<00:22, 141.43it/s]  2%|‚ñè         | 59/3257 [00:00<00:23, 138.26it/s]  2%|‚ñè         | 76/3257 [00:00<00:21, 146.70it/s]  3%|‚ñé         | 91/3257 [00:00<00:21, 145.91it/s]  3%|‚ñé         | 106/3257 [00:00<00:22, 138.70it/s]  4%|‚ñç         | 123/3257 [00:00<00:21, 146.61it/s]  4%|‚ñç         | 140/3257 [00:00<00:20, 152.21it/s]  5%|‚ñç         | 156/3257 [00:01<00:20, 153.65it/s]  5%|‚ñå         | 172/3257 [00:01<00:21, 146.37it/s]  6%|‚ñå         | 188/3257 [00:01<00:20, 149.83it/s]  6%|‚ñã         | 204/3257 [00:01<00:21, 144.53it/s]  7%|‚ñã         | 225/3257 [00:01<00:18, 162.31it/s]  7%|‚ñã         | 242/3257 [00:01<00:18, 163.09it/s]  8%|‚ñä         | 259/3257 [00:01<00:19, 152.84it/s]  8%|‚ñä         | 276/3257 [00:01<00:19, 156.49it/s]  9%|‚ñâ         | 295/3257 [00:01<00:17, 165.86it/s] 10%|‚ñâ         | 312/3257 [00:02<00:19, 153.27it/s] 10%|‚ñà         | 331/3257 [00:02<00:18, 162.40it/s] 11%|‚ñà         | 348/3257 [00:02<00:18, 155.93it/s] 11%|‚ñà         | 366/3257 [00:02<00:18, 160.43it/s] 12%|‚ñà‚ñè        | 383/3257 [00:02<00:18, 152.25it/s] 12%|‚ñà‚ñè        | 399/3257 [00:02<00:19, 145.34it/s] 13%|‚ñà‚ñé        | 417/3257 [00:02<00:18, 153.47it/s] 13%|‚ñà‚ñé        | 433/3257 [00:02<00:22, 126.98it/s] 14%|‚ñà‚ñç        | 449/3257 [00:03<00:20, 134.30it/s] 14%|‚ñà‚ñç        | 464/3257 [00:03<00:28, 96.65it/s]  15%|‚ñà‚ñç        | 479/3257 [00:03<00:26, 104.41it/s] 15%|‚ñà‚ñå        | 496/3257 [00:03<00:23, 118.03it/s] 16%|‚ñà‚ñå        | 512/3257 [00:03<00:21, 127.76it/s] 16%|‚ñà‚ñå        | 527/3257 [00:03<00:21, 126.94it/s] 17%|‚ñà‚ñã        | 545/3257 [00:03<00:19, 139.47it/s] 17%|‚ñà‚ñã        | 560/3257 [00:03<00:21, 125.86it/s] 18%|‚ñà‚ñä        | 574/3257 [00:04<00:22, 120.14it/s] 18%|‚ñà‚ñä        | 590/3257 [00:04<00:20, 129.61it/s] 19%|‚ñà‚ñä        | 607/3257 [00:04<00:19, 139.05it/s] 19%|‚ñà‚ñâ        | 622/3257 [00:04<00:19, 134.89it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:04<00:18, 144.57it/s] 20%|‚ñà‚ñà        | 655/3257 [00:04<00:19, 136.01it/s] 21%|‚ñà‚ñà        | 669/3257 [00:04<00:19, 135.95it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:19, 131.55it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:05<00:19, 134.22it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:05<00:17, 147.19it/s] 22%|‚ñà‚ñà‚ñè       | 732/3257 [00:05<00:18, 137.93it/s] 23%|‚ñà‚ñà‚ñé       | 746/3257 [00:05<00:18, 135.51it/s] 23%|‚ñà‚ñà‚ñé       | 762/3257 [00:05<00:17, 141.71it/s] 24%|‚ñà‚ñà‚ñç       | 777/3257 [00:05<00:18, 137.12it/s] 24%|‚ñà‚ñà‚ñç       | 792/3257 [00:05<00:17, 140.37it/s] 25%|‚ñà‚ñà‚ñç       | 807/3257 [00:05<00:17, 139.83it/s] 25%|‚ñà‚ñà‚ñå       | 822/3257 [00:05<00:17, 142.53it/s] 26%|‚ñà‚ñà‚ñå       | 837/3257 [00:05<00:17, 135.68it/s] 26%|‚ñà‚ñà‚ñå       | 851/3257 [00:06<00:18, 128.63it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:06<00:17, 134.05it/s] 27%|‚ñà‚ñà‚ñã       | 880/3257 [00:06<00:17, 133.52it/s] 27%|‚ñà‚ñà‚ñã       | 895/3257 [00:06<00:17, 136.15it/s] 28%|‚ñà‚ñà‚ñä       | 912/3257 [00:06<00:16, 145.67it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:06<00:15, 148.73it/s] 29%|‚ñà‚ñà‚ñâ       | 943/3257 [00:06<00:16, 143.94it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:06<00:15, 145.63it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:06<00:16, 142.35it/s] 30%|‚ñà‚ñà‚ñà       | 989/3257 [00:07<00:16, 139.24it/s] 31%|‚ñà‚ñà‚ñà       | 1004/3257 [00:07<00:16, 140.26it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1019/3257 [00:07<00:16, 139.79it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1034/3257 [00:07<00:16, 130.83it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1048/3257 [00:07<00:17, 129.34it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:07<00:16, 131.91it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:16, 133.31it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:07<00:16, 132.51it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1111/3257 [00:07<00:15, 140.95it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1126/3257 [00:08<00:15, 133.83it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1140/3257 [00:08<00:15, 132.87it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1154/3257 [00:08<00:15, 132.31it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:08<00:15, 138.46it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1184/3257 [00:08<00:16, 128.29it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1197/3257 [00:08<00:16, 125.30it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:08<00:16, 121.75it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1227/3257 [00:08<00:15, 133.54it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:08<00:14, 136.90it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:09<00:14, 134.59it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:09<00:14, 137.58it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1286/3257 [00:09<00:15, 123.93it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1301/3257 [00:09<00:15, 129.17it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1316/3257 [00:09<00:14, 134.32it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1330/3257 [00:09<00:14, 135.69it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:09<00:13, 139.88it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1361/3257 [00:09<00:13, 138.07it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1375/3257 [00:09<00:14, 132.32it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1389/3257 [00:10<00:14, 126.40it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1407/3257 [00:10<00:13, 140.29it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1424/3257 [00:10<00:12, 146.69it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:10<00:12, 146.69it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1458/3257 [00:10<00:11, 158.00it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:10<00:11, 153.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1490/3257 [00:10<00:11, 151.79it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1509/3257 [00:10<00:10, 162.45it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1526/3257 [00:10<00:12, 142.91it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1541/3257 [00:11<00:12, 139.11it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1556/3257 [00:11<00:12, 135.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1572/3257 [00:11<00:11, 140.76it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1587/3257 [00:11<00:12, 137.96it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1603/3257 [00:11<00:11, 143.50it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:11<00:11, 145.92it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:11<00:11, 138.30it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1648/3257 [00:12<00:20, 77.00it/s]  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:12<00:18, 87.64it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1675/3257 [00:12<00:16, 95.95it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:12<00:14, 105.82it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1706/3257 [00:12<00:13, 118.52it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1720/3257 [00:12<00:12, 123.43it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1734/3257 [00:12<00:13, 112.98it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1751/3257 [00:12<00:11, 126.25it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1766/3257 [00:13<00:11, 130.39it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1783/3257 [00:13<00:10, 139.99it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1798/3257 [00:13<00:10, 140.15it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1813/3257 [00:13<00:10, 135.54it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:13<00:10, 135.96it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1843/3257 [00:13<00:09, 142.28it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1858/3257 [00:13<00:10, 138.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1876/3257 [00:13<00:09, 148.76it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1892/3257 [00:13<00:09, 138.96it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1910/3257 [00:14<00:09, 148.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1926/3257 [00:14<00:09, 142.32it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1947/3257 [00:14<00:08, 159.09it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:14<00:07, 163.64it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:14<00:08, 156.66it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:14<00:08, 155.97it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2015/3257 [00:14<00:08, 153.21it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:14<00:07, 155.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2049/3257 [00:14<00:08, 142.66it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2064/3257 [00:15<00:08, 135.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2079/3257 [00:15<00:08, 139.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2095/3257 [00:15<00:08, 141.17it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2110/3257 [00:15<00:08, 138.85it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2124/3257 [00:15<00:08, 129.30it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2140/3257 [00:15<00:08, 134.68it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:15<00:08, 133.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2170/3257 [00:15<00:07, 140.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:15<00:07, 137.30it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2202/3257 [00:16<00:07, 144.39it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2217/3257 [00:16<00:07, 138.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2233/3257 [00:16<00:07, 142.82it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2248/3257 [00:16<00:07, 134.73it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2262/3257 [00:16<00:07, 135.34it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:16<00:07, 127.78it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2296/3257 [00:16<00:06, 143.91it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2311/3257 [00:16<00:06, 139.44it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2331/3257 [00:16<00:05, 154.73it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2350/3257 [00:17<00:05, 163.99it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2367/3257 [00:17<00:05, 162.14it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2385/3257 [00:17<00:05, 165.51it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2402/3257 [00:17<00:05, 165.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2419/3257 [00:17<00:05, 147.32it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2435/3257 [00:17<00:05, 141.23it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2450/3257 [00:17<00:05, 137.03it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2471/3257 [00:17<00:05, 154.83it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2487/3257 [00:17<00:05, 150.29it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:18<00:04, 161.69it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:18<00:04, 162.80it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2541/3257 [00:18<00:04, 158.65it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2557/3257 [00:18<00:04, 151.97it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:18<00:04, 141.27it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2588/3257 [00:18<00:04, 134.82it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2605/3257 [00:18<00:04, 141.72it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2625/3257 [00:18<00:04, 155.38it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2641/3257 [00:19<00:04, 149.86it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2657/3257 [00:19<00:04, 139.56it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2672/3257 [00:19<00:04, 141.64it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:19<00:04, 141.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2702/3257 [00:19<00:04, 124.11it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2715/3257 [00:19<00:04, 121.63it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:19<00:03, 133.05it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2749/3257 [00:19<00:03, 142.38it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2764/3257 [00:19<00:03, 138.42it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:20<00:03, 136.78it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2797/3257 [00:20<00:03, 147.68it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:20<00:03, 145.86it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2828/3257 [00:20<00:03, 135.65it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:20<00:03, 133.69it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2860/3257 [00:20<00:02, 146.22it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2880/3257 [00:20<00:02, 158.59it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2897/3257 [00:20<00:02, 139.55it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2913/3257 [00:20<00:02, 143.57it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:21<00:02, 141.06it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2943/3257 [00:21<00:02, 132.53it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2957/3257 [00:21<00:02, 129.38it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2971/3257 [00:21<00:04, 66.54it/s]  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2982/3257 [00:21<00:03, 72.64it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3000/3257 [00:22<00:02, 91.85it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3014/3257 [00:22<00:02, 101.41it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3028/3257 [00:22<00:02, 108.65it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3046/3257 [00:22<00:01, 125.08it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:22<00:01, 135.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3079/3257 [00:22<00:01, 139.82it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3094/3257 [00:22<00:01, 139.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3114/3257 [00:22<00:00, 155.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3131/3257 [00:22<00:00, 151.79it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3147/3257 [00:22<00:00, 145.85it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3164/3257 [00:23<00:00, 148.65it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3180/3257 [00:23<00:00, 141.86it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3198/3257 [00:23<00:00, 150.51it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3214/3257 [00:23<00:00, 142.42it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3234/3257 [00:23<00:00, 154.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:23<00:00, 153.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:23<00:00, 137.41it/s]
2023-02-07 19:09:02.269 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:09:02,270][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d302,n5,mc8,s0.607199,t4>', 'datetime': '2023-02-07T19:09:02.270544', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:09:02,270][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:09:02,271][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:09:02,960][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 19:09:02,961][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:09:03,036][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 22849 unique words (42.27% of original 54054, drops 31205)', 'datetime': '2023-02-07T19:09:03.036510', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:09:03,037][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 6458832 word corpus (98.60% of original 6550866, drops 92034)', 'datetime': '2023-02-07T19:09:03.036987', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:09:03,128][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 19:09:03,130][gensim.models.word2vec][INFO] - sample=0.607199 downsamples 0 most-common words
[2023-02-07 19:09:03,131][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6458832 word corpus (100.0%% of prior 6458832)', 'datetime': '2023-02-07T19:09:03.131101', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:09:03,283][gensim.models.word2vec][INFO] - estimated required memory for 22849 words and 302 dimensions: 71213540 bytes
[2023-02-07 19:09:03,283][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:09:03,317][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 22849 vocabulary and 302 features, using sg=1 hs=0 sample=0.6071990287723343 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-07T19:09:03.317409', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:09:04,331][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 27.85% examples, 1770634 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:09:05,332][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 56.19% examples, 1833098 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:06,335][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 86.67% examples, 1856186 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:06,761][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6404777 effective words) took 3.4s, 1860849 effective words/s
[2023-02-07 19:09:07,766][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 32.88% examples, 2121427 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:08,775][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 64.35% examples, 2086539 words/s, in_qsize 7, out_qsize 1
[2023-02-07 19:09:09,777][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 97.51% examples, 2075952 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:09,850][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6404777 effective words) took 3.1s, 2075089 effective words/s
[2023-02-07 19:09:10,856][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 31.99% examples, 2063731 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:11,857][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 63.49% examples, 2064279 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:12,863][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 96.65% examples, 2058519 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:12,959][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6404777 effective words) took 3.1s, 2060796 effective words/s
[2023-02-07 19:09:13,962][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 32.39% examples, 2096955 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:14,964][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 65.06% examples, 2116035 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:15,966][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 99.42% examples, 2120419 words/s, in_qsize 5, out_qsize 0
[2023-02-07 19:09:15,979][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6404777 effective words) took 3.0s, 2122149 effective words/s
[2023-02-07 19:09:16,984][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 33.16% examples, 2143978 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:17,989][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 65.80% examples, 2146627 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:18,962][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6404777 effective words) took 3.0s, 2149197 effective words/s
[2023-02-07 19:09:19,967][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 33.68% examples, 2175158 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:20,975][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 67.09% examples, 2181325 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:21,904][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6404777 effective words) took 2.9s, 2178202 effective words/s
[2023-02-07 19:09:22,907][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 33.93% examples, 2195533 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:23,907][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 67.09% examples, 2192282 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:24,808][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6404777 effective words) took 2.9s, 2207100 effective words/s
[2023-02-07 19:09:25,811][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 34.45% examples, 2227814 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:26,820][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 68.19% examples, 2216607 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:09:27,702][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6404777 effective words) took 2.9s, 2214589 effective words/s
[2023-02-07 19:09:28,706][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 34.08% examples, 2200168 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:09:29,712][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 67.70% examples, 2200697 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:30,618][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6404777 effective words) took 2.9s, 2197695 effective words/s
[2023-02-07 19:09:31,621][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 34.57% examples, 2237149 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:32,622][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 68.28% examples, 2230225 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:33,482][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6404777 effective words) took 2.9s, 2237527 effective words/s
[2023-02-07 19:09:34,491][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 34.33% examples, 2210378 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:35,494][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 68.19% examples, 2218541 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:36,379][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6404777 effective words) took 2.9s, 2213787 effective words/s
[2023-02-07 19:09:37,385][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 34.33% examples, 2216567 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:38,387][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 68.62% examples, 2235951 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:39,252][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6404777 effective words) took 2.9s, 2231928 effective words/s
[2023-02-07 19:09:40,259][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 33.87% examples, 2180400 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:41,261][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 68.65% examples, 2236301 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:42,102][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6404777 effective words) took 2.8s, 2248812 effective words/s
[2023-02-07 19:09:43,105][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 34.82% examples, 2256030 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:44,105][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 69.36% examples, 2267468 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:44,955][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6404777 effective words) took 2.9s, 2246262 effective words/s
[2023-02-07 19:09:45,963][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 34.45% examples, 2220378 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:46,967][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 68.10% examples, 2218346 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:47,835][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6404777 effective words) took 2.9s, 2225973 effective words/s
[2023-02-07 19:09:47,836][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (96071655 effective words) took 44.5s, 2158017 effective words/s', 'datetime': '2023-02-07T19:09:47.836393', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:09:47.836 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:09:52,643][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190828-dwhwn4qx/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:09:52.643159', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:09:52,643][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:09:52,767][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190828-dwhwn4qx/files/../tmp/embedding_model.pt
2023-02-07 19:09:52.767 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:09:54.912 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:09:55.635 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:10:57.176 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9001247320411033, 'test_mae': 0.7262719628726778, 'test_r2': -1.814034138589764}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.86
wandb: percentage 0.57729
wandb:   test_mae 0.72627
wandb:   test_mse 0.90012
wandb:    test_r2 -1.81403
wandb: 
wandb: üöÄ View run upbeat-sweep-34 at: https://wandb.ai/xiaoqiz/mof2vec/runs/dwhwn4qx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_190828-dwhwn4qx/logs
wandb: Agent Starting Run: pbdwu8yg with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 258
wandb: 	model.gensim.alpha: 0.0032615758783076437
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.5270065333853069
wandb: 	model.gensim.vector_size: 269
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.003620840837787222
wandb: 	model.sklearn.max_depth: 36
wandb: 	model.sklearn.min_child_weight: 0.02929588181185439
wandb: 	model.sklearn.n_estimators: 327
wandb: 	model.sklearn.num_leaves: 441
wandb: 	model.sklearn.reg_alpha: 0.004098359502321953
wandb: 	model.sklearn.reg_lambda: 0.063309660021915
wandb: 	model.sklearn.subsample: 0.26971504011191105
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191106-pbdwu8yg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-35
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/pbdwu8yg
2023-02-07 19:11:14.930 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:11:14.930 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 258 for sweep.
2023-02-07 19:11:14.930 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0032615758783076437 for sweep.
2023-02-07 19:11:14.931 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:11:14.931 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 19:11:14.931 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5270065333853069 for sweep.
2023-02-07 19:11:14.931 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 269 for sweep.
2023-02-07 19:11:14.932 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 19:11:14.932 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.003620840837787222 for sweep.
2023-02-07 19:11:14.932 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 36 for sweep.
2023-02-07 19:11:14.932 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.02929588181185439 for sweep.
2023-02-07 19:11:14.932 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 327 for sweep.
2023-02-07 19:11:14.933 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 441 for sweep.
2023-02-07 19:11:14.933 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004098359502321953 for sweep.
2023-02-07 19:11:14.933 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.063309660021915 for sweep.
2023-02-07 19:11:14.933 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.26971504011191105 for sweep.
2023-02-07 19:11:14.934 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:11:14.940 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191106-pbdwu8yg/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 258, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 269, 'window': 11, 'min_count': 3, 'dm': 0, 'sample': 0.5270065333853069, 'workers': 4, 'alpha': 0.0032615758783076437, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 327, 'max_depth': 36, 'num_leaves': 441, 'reg_alpha': 0.004098359502321953, 'reg_lambda': 0.063309660021915, 'subsample': 0.26971504011191105, 'min_child_weight': 0.02929588181185439, 'n_jobs': 4, 'learning_rate': 0.003620840837787222}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:22, 143.45it/s]  1%|          | 33/3257 [00:00<00:20, 159.66it/s]  2%|‚ñè         | 50/3257 [00:00<00:20, 156.94it/s]  2%|‚ñè         | 67/3257 [00:00<00:20, 152.85it/s]  3%|‚ñé         | 88/3257 [00:00<00:18, 171.19it/s]  3%|‚ñé         | 106/3257 [00:00<00:20, 150.71it/s]  4%|‚ñç         | 124/3257 [00:00<00:20, 156.38it/s]  4%|‚ñç         | 145/3257 [00:00<00:18, 167.70it/s]  5%|‚ñå         | 163/3257 [00:01<00:19, 157.76it/s]  6%|‚ñå         | 181/3257 [00:01<00:18, 162.07it/s]  6%|‚ñå         | 200/3257 [00:01<00:18, 168.38it/s]  7%|‚ñã         | 218/3257 [00:01<00:17, 169.15it/s]  7%|‚ñã         | 237/3257 [00:01<00:17, 172.46it/s]  8%|‚ñä         | 255/3257 [00:01<00:17, 172.87it/s]  8%|‚ñä         | 273/3257 [00:01<00:17, 170.79it/s]  9%|‚ñâ         | 295/3257 [00:01<00:16, 182.69it/s] 10%|‚ñâ         | 314/3257 [00:01<00:17, 169.43it/s] 10%|‚ñà         | 334/3257 [00:01<00:16, 175.75it/s] 11%|‚ñà         | 352/3257 [00:02<00:16, 172.68it/s] 11%|‚ñà‚ñè        | 370/3257 [00:02<00:16, 172.63it/s] 12%|‚ñà‚ñè        | 388/3257 [00:02<00:18, 154.76it/s] 12%|‚ñà‚ñè        | 407/3257 [00:02<00:17, 162.52it/s] 13%|‚ñà‚ñé        | 424/3257 [00:02<00:17, 157.68it/s] 14%|‚ñà‚ñé        | 441/3257 [00:02<00:19, 142.02it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:18, 148.62it/s] 15%|‚ñà‚ñç        | 476/3257 [00:02<00:18, 152.75it/s] 15%|‚ñà‚ñå        | 493/3257 [00:03<00:17, 157.17it/s] 16%|‚ñà‚ñå        | 512/3257 [00:03<00:16, 165.37it/s] 16%|‚ñà‚ñå        | 529/3257 [00:03<00:16, 162.33it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:16, 160.42it/s] 17%|‚ñà‚ñã        | 563/3257 [00:03<00:17, 151.17it/s] 18%|‚ñà‚ñä        | 579/3257 [00:03<00:17, 149.11it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:16, 159.43it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:16, 158.30it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:03<00:15, 165.41it/s] 20%|‚ñà‚ñà        | 656/3257 [00:04<00:16, 153.45it/s] 21%|‚ñà‚ñà        | 675/3257 [00:04<00:16, 161.02it/s] 21%|‚ñà‚ñà        | 692/3257 [00:04<00:16, 154.55it/s] 22%|‚ñà‚ñà‚ñè       | 711/3257 [00:04<00:15, 161.44it/s] 22%|‚ñà‚ñà‚ñè       | 728/3257 [00:04<00:16, 150.27it/s] 23%|‚ñà‚ñà‚ñé       | 744/3257 [00:04<00:16, 147.88it/s] 23%|‚ñà‚ñà‚ñé       | 764/3257 [00:04<00:15, 159.51it/s] 24%|‚ñà‚ñà‚ñç       | 781/3257 [00:04<00:16, 153.87it/s] 25%|‚ñà‚ñà‚ñç       | 799/3257 [00:04<00:15, 159.65it/s] 25%|‚ñà‚ñà‚ñå       | 816/3257 [00:05<00:15, 158.15it/s] 26%|‚ñà‚ñà‚ñå       | 832/3257 [00:05<00:16, 150.51it/s] 26%|‚ñà‚ñà‚ñå       | 848/3257 [00:05<00:16, 144.74it/s] 27%|‚ñà‚ñà‚ñã       | 865/3257 [00:05<00:15, 150.34it/s] 27%|‚ñà‚ñà‚ñã       | 881/3257 [00:05<00:15, 149.01it/s] 28%|‚ñà‚ñà‚ñä       | 899/3257 [00:05<00:14, 157.58it/s] 28%|‚ñà‚ñà‚ñä       | 915/3257 [00:05<00:23, 99.37it/s]  29%|‚ñà‚ñà‚ñä       | 933/3257 [00:06<00:20, 113.75it/s] 29%|‚ñà‚ñà‚ñâ       | 952/3257 [00:06<00:17, 129.14it/s] 30%|‚ñà‚ñà‚ñâ       | 969/3257 [00:06<00:16, 138.15it/s] 30%|‚ñà‚ñà‚ñà       | 985/3257 [00:06<00:16, 141.78it/s] 31%|‚ñà‚ñà‚ñà       | 1001/3257 [00:06<00:15, 141.31it/s] 31%|‚ñà‚ñà‚ñà       | 1017/3257 [00:06<00:15, 144.60it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1033/3257 [00:06<00:16, 138.61it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1048/3257 [00:06<00:15, 138.79it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1064/3257 [00:06<00:15, 142.61it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:15, 142.46it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1095/3257 [00:07<00:15, 143.42it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:07<00:14, 150.86it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1128/3257 [00:07<00:14, 142.46it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:07<00:14, 144.27it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1160/3257 [00:07<00:14, 149.36it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1176/3257 [00:07<00:14, 147.10it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:07<00:15, 132.71it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:07<00:15, 131.74it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1220/3257 [00:08<00:14, 135.88it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:08<00:13, 154.11it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:08<00:13, 146.36it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1273/3257 [00:08<00:13, 148.92it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1289/3257 [00:08<00:14, 134.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1304/3257 [00:08<00:14, 136.27it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:08<00:13, 142.52it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:08<00:12, 149.08it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1355/3257 [00:08<00:13, 141.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:09<00:13, 141.93it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:09<00:13, 139.01it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:09<00:12, 145.03it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:09<00:11, 156.35it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:09<00:11, 155.92it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:09<00:10, 167.36it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:09<00:11, 160.38it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:09<00:10, 166.03it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1514/3257 [00:09<00:10, 168.13it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1531/3257 [00:10<00:11, 152.70it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1547/3257 [00:10<00:11, 143.27it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1563/3257 [00:10<00:11, 147.58it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1578/3257 [00:10<00:11, 144.23it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1595/3257 [00:10<00:10, 151.19it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1612/3257 [00:10<00:10, 156.46it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1629/3257 [00:10<00:10, 158.89it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1646/3257 [00:10<00:11, 145.71it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:10<00:11, 139.16it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:11<00:11, 139.43it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:11<00:11, 141.35it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:11<00:10, 148.72it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1727/3257 [00:11<00:09, 156.97it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1743/3257 [00:11<00:11, 134.76it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:11<00:10, 147.17it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1780/3257 [00:11<00:09, 152.09it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:11<00:09, 153.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1812/3257 [00:12<00:09, 144.92it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:12<00:09, 145.62it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1845/3257 [00:12<00:09, 152.01it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1862/3257 [00:12<00:08, 156.42it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:12<00:08, 156.86it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:12<00:08, 152.51it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1915/3257 [00:12<00:08, 164.50it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1932/3257 [00:12<00:08, 155.04it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:12<00:07, 172.69it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1973/3257 [00:12<00:07, 175.09it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1991/3257 [00:13<00:07, 163.01it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:13<00:07, 158.86it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2025/3257 [00:13<00:07, 161.42it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2042/3257 [00:13<00:07, 152.18it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2058/3257 [00:13<00:08, 144.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2073/3257 [00:13<00:08, 144.27it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2088/3257 [00:13<00:08, 142.39it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2103/3257 [00:13<00:08, 137.67it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:14<00:08, 135.97it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:14<00:08, 135.51it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2148/3257 [00:14<00:08, 130.53it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:14<00:07, 141.29it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:14<00:07, 139.80it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2198/3257 [00:14<00:07, 147.94it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2213/3257 [00:14<00:07, 135.77it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2227/3257 [00:15<00:14, 72.31it/s]  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2239/3257 [00:15<00:12, 79.37it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2255/3257 [00:15<00:10, 94.60it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2269/3257 [00:15<00:09, 104.11it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2282/3257 [00:15<00:08, 109.36it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:15<00:08, 119.70it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:15<00:07, 127.71it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2335/3257 [00:15<00:06, 146.66it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2355/3257 [00:15<00:05, 160.95it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2372/3257 [00:16<00:05, 150.85it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2391/3257 [00:16<00:05, 160.87it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2408/3257 [00:16<00:05, 149.61it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2424/3257 [00:16<00:05, 149.38it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:16<00:05, 141.18it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2455/3257 [00:16<00:05, 135.96it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2474/3257 [00:16<00:05, 149.95it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2490/3257 [00:16<00:05, 149.88it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2509/3257 [00:17<00:04, 158.27it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2526/3257 [00:17<00:04, 158.58it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2542/3257 [00:17<00:04, 157.30it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2558/3257 [00:17<00:04, 152.78it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2574/3257 [00:17<00:04, 138.37it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2589/3257 [00:17<00:05, 132.13it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2607/3257 [00:17<00:04, 143.12it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2626/3257 [00:17<00:04, 153.41it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2642/3257 [00:17<00:04, 147.99it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2658/3257 [00:18<00:04, 136.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2674/3257 [00:18<00:04, 138.65it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:18<00:03, 143.41it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2705/3257 [00:18<00:04, 124.35it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2718/3257 [00:18<00:04, 119.55it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2734/3257 [00:18<00:04, 129.05it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2751/3257 [00:18<00:03, 135.52it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2765/3257 [00:18<00:03, 136.35it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:18<00:03, 130.44it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2796/3257 [00:19<00:03, 138.42it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2811/3257 [00:19<00:03, 139.21it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2826/3257 [00:19<00:03, 126.29it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2839/3257 [00:19<00:03, 124.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2855/3257 [00:19<00:03, 132.89it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2874/3257 [00:19<00:02, 147.38it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2889/3257 [00:19<00:02, 143.12it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2904/3257 [00:19<00:02, 130.63it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:20<00:02, 135.42it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2934/3257 [00:20<00:02, 134.36it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2948/3257 [00:20<00:02, 128.78it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2962/3257 [00:20<00:02, 129.69it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:20<00:02, 127.81it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2989/3257 [00:20<00:02, 125.65it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3008/3257 [00:20<00:01, 140.91it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3023/3257 [00:20<00:01, 135.53it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3041/3257 [00:20<00:01, 145.33it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3057/3257 [00:21<00:01, 149.06it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:21<00:01, 153.98it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3091/3257 [00:21<00:01, 145.65it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:21<00:00, 157.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:21<00:00, 160.08it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3144/3257 [00:21<00:00, 147.92it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3160/3257 [00:21<00:00, 147.41it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3175/3257 [00:21<00:00, 146.82it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3190/3257 [00:21<00:00, 144.68it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:22<00:00, 146.23it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3222/3257 [00:22<00:00, 143.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3241/3257 [00:22<00:00, 154.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 155.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 145.78it/s]
2023-02-07 19:11:38.334 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:11:38,336][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d269,n5,mc3,s0.527007,t4>', 'datetime': '2023-02-07T19:11:38.336297', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:11:38,336][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:11:38,336][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:11:39,019][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 19:11:39,019][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:11:39,135][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 38627 unique words (71.46% of original 54054, drops 15427)', 'datetime': '2023-02-07T19:11:39.134987', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:11:39,135][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 6527597 word corpus (99.64% of original 6550866, drops 23269)', 'datetime': '2023-02-07T19:11:39.135851', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:11:39,280][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 19:11:39,281][gensim.models.word2vec][INFO] - sample=0.527007 downsamples 0 most-common words
[2023-02-07 19:11:39,282][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6527597 word corpus (100.0%% of prior 6527597)', 'datetime': '2023-02-07T19:11:39.282106', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:11:39,532][gensim.models.word2vec][INFO] - estimated required memory for 38627 words and 269 dimensions: 106594736 bytes
[2023-02-07 19:11:39,535][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:11:39,584][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 38627 vocabulary and 269 features, using sg=1 hs=0 sample=0.5270065333853069 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T19:11:39.584470', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:11:40,587][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 26.99% examples, 1752041 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:41,595][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 54.47% examples, 1796173 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:42,598][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 83.36% examples, 1814012 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:43,149][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6472763 effective words) took 3.6s, 1817130 effective words/s
[2023-02-07 19:11:44,153][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 29.08% examples, 1880264 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:45,154][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 57.14% examples, 1886874 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:46,158][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 87.17% examples, 1894964 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:46,550][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6472763 effective words) took 3.4s, 1904145 effective words/s
[2023-02-07 19:11:47,553][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 29.75% examples, 1924637 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:48,556][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 58.21% examples, 1920885 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:49,559][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 88.89% examples, 1927255 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:49,904][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6472763 effective words) took 3.4s, 1930993 effective words/s
[2023-02-07 19:11:50,906][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 29.66% examples, 1916950 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:51,909][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 57.60% examples, 1900380 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:52,913][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 88.09% examples, 1907584 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:53,288][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6472763 effective words) took 3.4s, 1913665 effective words/s
[2023-02-07 19:11:54,291][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 30.12% examples, 1956145 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:55,294][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 58.80% examples, 1934865 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:56,295][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 88.61% examples, 1916783 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:56,658][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6472763 effective words) took 3.4s, 1921726 effective words/s
[2023-02-07 19:11:57,666][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 30.06% examples, 1937103 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:58,674][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 58.80% examples, 1925283 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:59,679][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 89.41% examples, 1928302 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:00,008][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6472763 effective words) took 3.3s, 1932768 effective words/s
[2023-02-07 19:12:01,013][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 29.90% examples, 1926915 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:02,016][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 58.83% examples, 1938054 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:03,017][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 89.25% examples, 1934649 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:03,351][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6472763 effective words) took 3.3s, 1937268 effective words/s
[2023-02-07 19:12:04,355][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 29.23% examples, 1892771 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:05,357][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 57.35% examples, 1892039 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:06,359][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 87.04% examples, 1893105 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:06,762][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6472763 effective words) took 3.4s, 1899463 effective words/s
[2023-02-07 19:12:07,764][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 29.23% examples, 1893902 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:08,765][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 57.84% examples, 1910852 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:09,768][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 88.61% examples, 1918226 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:12:10,132][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6472763 effective words) took 3.4s, 1921672 effective words/s
[2023-02-07 19:12:11,136][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 29.90% examples, 1932846 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:12,136][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 58.61% examples, 1933671 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:13,137][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 88.67% examples, 1922782 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:13,501][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6472763 effective words) took 3.4s, 1923036 effective words/s
[2023-02-07 19:12:14,508][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 29.66% examples, 1909542 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:15,509][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 59.10% examples, 1947736 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:16,511][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 90.18% examples, 1952137 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:16,818][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6472763 effective words) took 3.3s, 1952356 effective words/s
[2023-02-07 19:12:17,820][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 30.03% examples, 1942539 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:18,821][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 58.21% examples, 1923431 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:19,822][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 88.09% examples, 1910749 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:20,208][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6472763 effective words) took 3.4s, 1910003 effective words/s
[2023-02-07 19:12:21,220][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 29.66% examples, 1901692 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:12:22,220][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 58.21% examples, 1915527 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:23,221][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 88.61% examples, 1914201 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:23,593][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6472763 effective words) took 3.4s, 1913900 effective words/s
[2023-02-07 19:12:24,599][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 29.08% examples, 1875494 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:25,604][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 57.60% examples, 1894124 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:26,607][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 87.84% examples, 1901397 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:26,989][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6472763 effective words) took 3.4s, 1906923 effective words/s
[2023-02-07 19:12:27,991][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 29.75% examples, 1924877 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:28,997][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 58.80% examples, 1932839 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:29,998][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 89.16% examples, 1933142 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:30,339][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6472763 effective words) took 3.3s, 1933279 effective words/s
[2023-02-07 19:12:30,339][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (97091445 effective words) took 50.8s, 1912958 effective words/s', 'datetime': '2023-02-07T19:12:30.339580', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:12:30.339 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:12:35,680][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191106-pbdwu8yg/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:12:35.680521', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:12:35,681][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:12:35,825][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191106-pbdwu8yg/files/../tmp/embedding_model.pt
2023-02-07 19:12:35.825 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:12:37.852 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:12:38.539 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:12:49.599 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0578297544127424, 'test_mae': 0.7689599022269249, 'test_r2': -2.2265835828324856}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.65
wandb: percentage 0.2854
wandb:   test_mae 0.76896
wandb:   test_mse 1.05783
wandb:    test_r2 -2.22658
wandb: 
wandb: üöÄ View run warm-sweep-35 at: https://wandb.ai/xiaoqiz/mof2vec/runs/pbdwu8yg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_191106-pbdwu8yg/logs
wandb: Agent Starting Run: g1kdaelz with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 761
wandb: 	model.gensim.alpha: 0.00434609502353148
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.39235258294331754
wandb: 	model.gensim.vector_size: 325
wandb: 	model.gensim.window: 5
wandb: 	model.sklearn.learning_rate: 0.08501283929184503
wandb: 	model.sklearn.max_depth: 15
wandb: 	model.sklearn.min_child_weight: 0.05984637077629056
wandb: 	model.sklearn.n_estimators: 1863
wandb: 	model.sklearn.num_leaves: 420
wandb: 	model.sklearn.reg_alpha: 0.005646031784517388
wandb: 	model.sklearn.reg_lambda: 0.013941154169714318
wandb: 	model.sklearn.subsample: 0.3326547684123492
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191307-g1kdaelz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-36
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/g1kdaelz
2023-02-07 19:13:16.593 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:13:16.594 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 761 for sweep.
2023-02-07 19:13:16.594 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.00434609502353148 for sweep.
2023-02-07 19:13:16.594 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:13:16.595 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 19:13:16.595 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.39235258294331754 for sweep.
2023-02-07 19:13:16.595 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 325 for sweep.
2023-02-07 19:13:16.596 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 5 for sweep.
2023-02-07 19:13:16.596 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.08501283929184503 for sweep.
2023-02-07 19:13:16.596 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 15 for sweep.
2023-02-07 19:13:16.596 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05984637077629056 for sweep.
2023-02-07 19:13:16.597 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1863 for sweep.
2023-02-07 19:13:16.597 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 420 for sweep.
2023-02-07 19:13:16.597 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.005646031784517388 for sweep.
2023-02-07 19:13:16.597 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.013941154169714318 for sweep.
2023-02-07 19:13:16.598 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3326547684123492 for sweep.
2023-02-07 19:13:16.598 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:13:16.603 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191307-g1kdaelz/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 761, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 325, 'window': 5, 'min_count': 6, 'dm': 0, 'sample': 0.39235258294331754, 'workers': 4, 'alpha': 0.00434609502353148, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1863, 'max_depth': 15, 'num_leaves': 420, 'reg_alpha': 0.005646031784517388, 'reg_lambda': 0.013941154169714318, 'subsample': 0.3326547684123492, 'min_child_weight': 0.05984637077629056, 'n_jobs': 4, 'learning_rate': 0.08501283929184503}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:26, 124.10it/s]  1%|          | 29/3257 [00:00<00:22, 142.65it/s]  1%|‚ñè         | 44/3257 [00:00<00:23, 138.81it/s]  2%|‚ñè         | 58/3257 [00:00<00:23, 135.33it/s]  2%|‚ñè         | 74/3257 [00:00<00:22, 142.46it/s]  3%|‚ñé         | 90/3257 [00:00<00:21, 145.19it/s]  3%|‚ñé         | 105/3257 [00:00<00:22, 140.14it/s]  4%|‚ñé         | 120/3257 [00:00<00:22, 138.70it/s]  4%|‚ñç         | 134/3257 [00:00<00:22, 138.18it/s]  5%|‚ñç         | 151/3257 [00:01<00:21, 145.51it/s]  5%|‚ñå         | 166/3257 [00:01<00:22, 138.75it/s]  6%|‚ñå         | 180/3257 [00:01<00:22, 137.47it/s]  6%|‚ñå         | 197/3257 [00:01<00:20, 146.09it/s]  7%|‚ñã         | 215/3257 [00:01<00:19, 154.44it/s]  7%|‚ñã         | 233/3257 [00:01<00:18, 161.03it/s]  8%|‚ñä         | 250/3257 [00:01<00:19, 156.95it/s]  8%|‚ñä         | 266/3257 [00:01<00:19, 152.34it/s]  9%|‚ñâ         | 287/3257 [00:01<00:18, 164.79it/s]  9%|‚ñâ         | 304/3257 [00:02<00:18, 158.84it/s] 10%|‚ñâ         | 322/3257 [00:02<00:17, 163.51it/s] 10%|‚ñà         | 339/3257 [00:02<00:19, 152.73it/s] 11%|‚ñà         | 357/3257 [00:02<00:18, 159.49it/s] 11%|‚ñà‚ñè        | 374/3257 [00:02<00:18, 152.45it/s] 12%|‚ñà‚ñè        | 390/3257 [00:02<00:31, 92.17it/s]  12%|‚ñà‚ñè        | 406/3257 [00:02<00:27, 104.19it/s] 13%|‚ñà‚ñé        | 421/3257 [00:03<00:25, 112.59it/s] 13%|‚ñà‚ñé        | 435/3257 [00:03<00:26, 104.67it/s] 14%|‚ñà‚ñç        | 451/3257 [00:03<00:24, 116.72it/s] 14%|‚ñà‚ñç        | 468/3257 [00:03<00:21, 129.46it/s] 15%|‚ñà‚ñç        | 483/3257 [00:03<00:21, 129.18it/s] 15%|‚ñà‚ñå        | 501/3257 [00:03<00:19, 140.30it/s] 16%|‚ñà‚ñå        | 518/3257 [00:03<00:18, 146.53it/s] 16%|‚ñà‚ñã        | 534/3257 [00:03<00:18, 144.16it/s] 17%|‚ñà‚ñã        | 550/3257 [00:03<00:18, 145.32it/s] 17%|‚ñà‚ñã        | 565/3257 [00:04<00:19, 135.26it/s] 18%|‚ñà‚ñä        | 579/3257 [00:04<00:20, 131.47it/s] 18%|‚ñà‚ñä        | 597/3257 [00:04<00:18, 143.47it/s] 19%|‚ñà‚ñâ        | 614/3257 [00:04<00:17, 150.79it/s] 19%|‚ñà‚ñâ        | 630/3257 [00:04<00:18, 145.52it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:04<00:19, 136.53it/s] 20%|‚ñà‚ñà        | 659/3257 [00:04<00:19, 130.28it/s] 21%|‚ñà‚ñà        | 677/3257 [00:04<00:18, 142.15it/s] 21%|‚ñà‚ñà        | 692/3257 [00:05<00:18, 138.89it/s] 22%|‚ñà‚ñà‚ñè       | 707/3257 [00:05<00:18, 141.66it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:05<00:18, 138.93it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:05<00:19, 130.82it/s] 23%|‚ñà‚ñà‚ñé       | 751/3257 [00:05<00:18, 135.93it/s] 24%|‚ñà‚ñà‚ñé       | 768/3257 [00:05<00:17, 144.97it/s] 24%|‚ñà‚ñà‚ñç       | 783/3257 [00:05<00:18, 134.93it/s] 25%|‚ñà‚ñà‚ñç       | 801/3257 [00:05<00:16, 145.25it/s] 25%|‚ñà‚ñà‚ñå       | 816/3257 [00:05<00:16, 143.64it/s] 26%|‚ñà‚ñà‚ñå       | 831/3257 [00:06<00:17, 136.20it/s] 26%|‚ñà‚ñà‚ñå       | 845/3257 [00:06<00:19, 126.14it/s] 26%|‚ñà‚ñà‚ñã       | 861/3257 [00:06<00:17, 133.33it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:06<00:18, 131.86it/s] 27%|‚ñà‚ñà‚ñã       | 889/3257 [00:06<00:17, 133.96it/s] 28%|‚ñà‚ñà‚ñä       | 906/3257 [00:06<00:16, 142.66it/s] 28%|‚ñà‚ñà‚ñä       | 922/3257 [00:06<00:15, 147.09it/s] 29%|‚ñà‚ñà‚ñâ       | 937/3257 [00:06<00:16, 143.79it/s] 29%|‚ñà‚ñà‚ñâ       | 954/3257 [00:06<00:15, 149.48it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:06<00:15, 147.25it/s] 30%|‚ñà‚ñà‚ñà       | 985/3257 [00:07<00:15, 144.29it/s] 31%|‚ñà‚ñà‚ñà       | 1000/3257 [00:07<00:16, 138.33it/s] 31%|‚ñà‚ñà‚ñà       | 1014/3257 [00:07<00:16, 134.07it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1028/3257 [00:07<00:17, 129.46it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:07<00:17, 125.29it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1055/3257 [00:07<00:17, 128.53it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1070/3257 [00:07<00:16, 133.62it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1084/3257 [00:07<00:16, 130.85it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1098/3257 [00:07<00:16, 130.01it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1114/3257 [00:08<00:15, 137.16it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1128/3257 [00:08<00:17, 124.77it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1141/3257 [00:08<00:16, 124.60it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1154/3257 [00:08<00:16, 124.77it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:08<00:15, 130.51it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1184/3257 [00:08<00:17, 121.92it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1197/3257 [00:08<00:17, 120.86it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:08<00:18, 112.94it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1225/3257 [00:09<00:16, 122.49it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:09<00:15, 131.53it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1255/3257 [00:09<00:15, 127.20it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:09<00:15, 130.96it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1285/3257 [00:09<00:16, 118.11it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1298/3257 [00:09<00:16, 120.85it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:09<00:15, 126.31it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:09<00:14, 130.08it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:09<00:13, 137.26it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1358/3257 [00:10<00:14, 131.24it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1372/3257 [00:10<00:14, 127.80it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:10<00:14, 127.53it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:10<00:13, 134.73it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:10<00:12, 150.29it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1438/3257 [00:10<00:12, 143.38it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1457/3257 [00:10<00:11, 155.66it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1473/3257 [00:10<00:11, 152.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1489/3257 [00:10<00:11, 152.82it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1506/3257 [00:11<00:11, 156.45it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1522/3257 [00:11<00:12, 139.45it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1537/3257 [00:11<00:12, 132.32it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1552/3257 [00:11<00:12, 131.81it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1566/3257 [00:11<00:12, 132.97it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1580/3257 [00:11<00:12, 131.14it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:11<00:12, 137.48it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1611/3257 [00:11<00:11, 140.28it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1626/3257 [00:11<00:11, 139.31it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1640/3257 [00:12<00:12, 133.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:12<00:12, 127.86it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1667/3257 [00:12<00:12, 124.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1681/3257 [00:12<00:12, 125.51it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1694/3257 [00:12<00:12, 124.50it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1709/3257 [00:12<00:11, 130.81it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:13<00:21, 71.47it/s]  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1734/3257 [00:13<00:20, 73.60it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1750/3257 [00:13<00:16, 89.45it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1764/3257 [00:13<00:14, 99.99it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:13<00:13, 109.68it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1794/3257 [00:13<00:12, 119.33it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1808/3257 [00:13<00:12, 115.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1825/3257 [00:13<00:11, 124.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1839/3257 [00:13<00:11, 127.77it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1855/3257 [00:14<00:10, 133.56it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1871/3257 [00:14<00:09, 139.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1886/3257 [00:14<00:09, 137.94it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1901/3257 [00:14<00:09, 139.30it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:14<00:09, 139.85it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:14<00:09, 141.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1952/3257 [00:14<00:08, 159.92it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1969/3257 [00:14<00:07, 162.00it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1986/3257 [00:14<00:08, 150.74it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2003/3257 [00:14<00:08, 155.19it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2019/3257 [00:15<00:08, 154.53it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:15<00:07, 153.61it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2051/3257 [00:15<00:08, 137.43it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2066/3257 [00:15<00:08, 133.69it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2082/3257 [00:15<00:08, 138.60it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2097/3257 [00:15<00:08, 132.23it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2113/3257 [00:15<00:08, 138.70it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2128/3257 [00:15<00:08, 127.98it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2142/3257 [00:16<00:08, 126.40it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2155/3257 [00:16<00:08, 125.62it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2170/3257 [00:16<00:08, 131.65it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2184/3257 [00:16<00:08, 129.79it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2201/3257 [00:16<00:07, 139.56it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2216/3257 [00:16<00:07, 134.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2231/3257 [00:16<00:07, 137.84it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2245/3257 [00:16<00:07, 131.36it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:16<00:07, 133.88it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2274/3257 [00:17<00:07, 127.84it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2293/3257 [00:17<00:06, 143.21it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2308/3257 [00:17<00:06, 138.82it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2328/3257 [00:17<00:05, 155.32it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2346/3257 [00:17<00:05, 162.24it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2364/3257 [00:17<00:05, 163.28it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2381/3257 [00:17<00:05, 161.99it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2398/3257 [00:17<00:05, 163.53it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2415/3257 [00:17<00:05, 149.71it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2431/3257 [00:18<00:05, 140.57it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2447/3257 [00:18<00:05, 144.37it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2463/3257 [00:18<00:05, 147.94it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2479/3257 [00:18<00:05, 149.81it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2495/3257 [00:18<00:05, 151.85it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2512/3257 [00:18<00:04, 155.43it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2528/3257 [00:18<00:04, 152.22it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2544/3257 [00:18<00:04, 151.00it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2560/3257 [00:18<00:04, 145.73it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2575/3257 [00:19<00:04, 137.11it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2589/3257 [00:19<00:05, 131.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2608/3257 [00:19<00:04, 145.07it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2627/3257 [00:19<00:04, 157.39it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2643/3257 [00:19<00:04, 143.97it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2658/3257 [00:19<00:04, 134.55it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2674/3257 [00:19<00:04, 136.70it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2691/3257 [00:19<00:04, 140.98it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2706/3257 [00:19<00:04, 127.13it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2720/3257 [00:20<00:04, 121.29it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2737/3257 [00:20<00:03, 133.07it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2751/3257 [00:20<00:03, 134.22it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2765/3257 [00:20<00:03, 135.01it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:20<00:03, 130.09it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:20<00:03, 138.30it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2810/3257 [00:20<00:03, 136.85it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2824/3257 [00:20<00:03, 125.64it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2838/3257 [00:20<00:03, 127.52it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:21<00:03, 132.60it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2873/3257 [00:21<00:02, 149.15it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2889/3257 [00:21<00:02, 144.88it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2904/3257 [00:21<00:02, 133.00it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:21<00:02, 139.44it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2935/3257 [00:21<00:02, 135.16it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2949/3257 [00:21<00:02, 125.68it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2965/3257 [00:21<00:02, 133.55it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2979/3257 [00:22<00:02, 126.01it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2992/3257 [00:22<00:02, 126.18it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:22<00:01, 142.82it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:22<00:01, 137.31it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3040/3257 [00:22<00:03, 67.55it/s]  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3057/3257 [00:22<00:02, 83.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:23<00:01, 99.85it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3089/3257 [00:23<00:01, 104.32it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3107/3257 [00:23<00:01, 120.04it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3124/3257 [00:23<00:01, 130.81it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3139/3257 [00:23<00:00, 132.09it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3154/3257 [00:23<00:00, 131.15it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3169/3257 [00:23<00:00, 135.81it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3184/3257 [00:23<00:00, 133.05it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:23<00:00, 145.65it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3218/3257 [00:24<00:00, 137.79it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3237/3257 [00:24<00:00, 150.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:24<00:00, 149.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:24<00:00, 134.04it/s]
2023-02-07 19:13:41.911 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:13:41,913][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d325,n5,mc6,s0.392353,t4>', 'datetime': '2023-02-07T19:13:41.913783', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:13:41,914][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:13:41,914][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:13:42,603][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 19:13:42,603][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:13:42,686][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 25857 unique words (47.84% of original 54054, drops 28197)', 'datetime': '2023-02-07T19:13:42.686010', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:13:42,687][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 6477431 word corpus (98.88% of original 6550866, drops 73435)', 'datetime': '2023-02-07T19:13:42.687628', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:13:42,785][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 19:13:42,787][gensim.models.word2vec][INFO] - sample=0.392353 downsamples 0 most-common words
[2023-02-07 19:13:42,787][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6477431 word corpus (100.0%% of prior 6477431)', 'datetime': '2023-02-07T19:13:42.787757', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:13:42,956][gensim.models.word2vec][INFO] - estimated required memory for 25857 words and 325 dimensions: 85042200 bytes
[2023-02-07 19:13:42,957][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:13:43,001][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 25857 vocabulary and 325 features, using sg=1 hs=0 sample=0.39235258294331754 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-07T19:13:43.001025', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:13:44,006][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 25.94% examples, 1668118 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:13:45,012][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 51.40% examples, 1677975 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:13:46,020][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 78.81% examples, 1696145 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:13:46,770][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6423064 effective words) took 3.8s, 1705390 effective words/s
[2023-02-07 19:13:47,775][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 27.85% examples, 1791737 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:13:48,776][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 55.27% examples, 1814242 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:13:49,779][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 83.97% examples, 1812547 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:13:50,309][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6423064 effective words) took 3.5s, 1816450 effective words/s
[2023-02-07 19:13:51,320][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 28.55% examples, 1820977 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:13:52,325][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 56.65% examples, 1848412 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:13:53,327][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 85.78% examples, 1841737 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:13:53,800][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6423064 effective words) took 3.5s, 1841026 effective words/s
[2023-02-07 19:13:54,807][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 28.55% examples, 1826081 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:13:55,810][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 56.65% examples, 1853140 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:13:56,810][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 86.28% examples, 1854039 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:13:57,256][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6423064 effective words) took 3.5s, 1859267 effective words/s
[2023-02-07 19:13:58,266][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 29.08% examples, 1855298 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:13:59,273][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 57.45% examples, 1870318 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:00,274][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 87.04% examples, 1871930 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:00,693][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6423064 effective words) took 3.4s, 1870151 effective words/s
[2023-02-07 19:14:01,695][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 29.08% examples, 1868752 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:14:02,695][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 57.14% examples, 1874086 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:03,698][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 86.83% examples, 1873224 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:04,110][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6423064 effective words) took 3.4s, 1880356 effective words/s
[2023-02-07 19:14:05,113][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 32.27% examples, 2091260 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:06,115][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 68.44% examples, 2239453 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:06,958][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6423064 effective words) took 2.8s, 2256491 effective words/s
[2023-02-07 19:14:07,966][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 37.06% examples, 2418618 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:08,968][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 74.33% examples, 2408775 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:14:09,628][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6423064 effective words) took 2.7s, 2406159 effective words/s
[2023-02-07 19:14:10,638][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 38.19% examples, 2485921 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:11,639][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 77.06% examples, 2492998 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:12,205][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6423064 effective words) took 2.6s, 2495419 effective words/s
[2023-02-07 19:14:13,208][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 38.19% examples, 2500359 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:14,213][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 77.80% examples, 2513261 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:14,760][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6423064 effective words) took 2.6s, 2514867 effective words/s
[2023-02-07 19:14:15,764][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 38.19% examples, 2498496 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:16,766][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 76.70% examples, 2487367 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:17,380][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6423064 effective words) took 2.6s, 2452659 effective words/s
[2023-02-07 19:14:18,384][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 36.44% examples, 2381217 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:19,389][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 73.84% examples, 2399713 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:20,047][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6423064 effective words) took 2.7s, 2411097 effective words/s
[2023-02-07 19:14:21,050][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 36.81% examples, 2410251 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:22,062][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 70.56% examples, 2300351 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:22,963][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6423064 effective words) took 2.9s, 2204418 effective words/s
[2023-02-07 19:14:23,966][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 33.83% examples, 2195829 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:24,966][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 64.29% examples, 2098622 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:25,970][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 99.26% examples, 2123827 words/s, in_qsize 6, out_qsize 0
[2023-02-07 19:14:25,984][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6423064 effective words) took 3.0s, 2127688 effective words/s
[2023-02-07 19:14:26,987][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 32.55% examples, 2111082 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:27,997][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 64.42% examples, 2092902 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:28,999][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 97.54% examples, 2084062 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:29,064][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6423064 effective words) took 3.1s, 2086469 effective words/s
[2023-02-07 19:14:29,065][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (96345960 effective words) took 46.1s, 2091575 effective words/s', 'datetime': '2023-02-07T19:14:29.065294', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:14:29.065 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:14:33,196][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191307-g1kdaelz/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:14:33.196016', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:14:33,197][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:14:33,311][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191307-g1kdaelz/files/../tmp/embedding_model.pt
2023-02-07 19:14:33.311 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:14:35.324 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:14:36.000 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:14:38.434 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.001903945403936, 'test_mae': 0.7561004498710662, 'test_r2': -1.936947445794186}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.76
wandb: percentage 0.52165
wandb:   test_mae 0.7561
wandb:   test_mse 1.0019
wandb:    test_r2 -1.93695
wandb: 
wandb: üöÄ View run rare-sweep-36 at: https://wandb.ai/xiaoqiz/mof2vec/runs/g1kdaelz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_191307-g1kdaelz/logs
wandb: Agent Starting Run: 67578ylk with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 726
wandb: 	model.gensim.alpha: 0.1951562086931469
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.4468079565897221
wandb: 	model.gensim.vector_size: 355
wandb: 	model.gensim.window: 6
wandb: 	model.sklearn.learning_rate: 0.2908103432425729
wandb: 	model.sklearn.max_depth: 77
wandb: 	model.sklearn.min_child_weight: 0.04851869355451718
wandb: 	model.sklearn.n_estimators: 1593
wandb: 	model.sklearn.num_leaves: 487
wandb: 	model.sklearn.reg_alpha: 0.015132119261088796
wandb: 	model.sklearn.reg_lambda: 0.0071353304768229575
wandb: 	model.sklearn.subsample: 0.48951649362772526
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191449-67578ylk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-37
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/67578ylk
2023-02-07 19:14:57.084 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:14:57.085 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 726 for sweep.
2023-02-07 19:14:57.085 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.1951562086931469 for sweep.
2023-02-07 19:14:57.085 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:14:57.086 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 19:14:57.086 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4468079565897221 for sweep.
2023-02-07 19:14:57.086 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 355 for sweep.
2023-02-07 19:14:57.086 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 6 for sweep.
2023-02-07 19:14:57.087 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.2908103432425729 for sweep.
2023-02-07 19:14:57.087 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 77 for sweep.
2023-02-07 19:14:57.087 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.04851869355451718 for sweep.
2023-02-07 19:14:57.087 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1593 for sweep.
2023-02-07 19:14:57.087 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 487 for sweep.
2023-02-07 19:14:57.088 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.015132119261088796 for sweep.
2023-02-07 19:14:57.088 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0071353304768229575 for sweep.
2023-02-07 19:14:57.088 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.48951649362772526 for sweep.
2023-02-07 19:14:57.088 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:14:57.096 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191449-67578ylk/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 726, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 355, 'window': 6, 'min_count': 7, 'dm': 0, 'sample': 0.4468079565897221, 'workers': 4, 'alpha': 0.1951562086931469, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1593, 'max_depth': 77, 'num_leaves': 487, 'reg_alpha': 0.015132119261088796, 'reg_lambda': 0.0071353304768229575, 'subsample': 0.48951649362772526, 'min_child_weight': 0.04851869355451718, 'n_jobs': 4, 'learning_rate': 0.2908103432425729}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:20, 157.10it/s]  1%|          | 34/3257 [00:00<00:19, 168.05it/s]  2%|‚ñè         | 53/3257 [00:00<00:18, 171.90it/s]  2%|‚ñè         | 74/3257 [00:00<00:17, 183.57it/s]  3%|‚ñé         | 94/3257 [00:00<00:16, 186.30it/s]  3%|‚ñé         | 113/3257 [00:00<00:17, 178.04it/s]  4%|‚ñç         | 134/3257 [00:00<00:17, 183.07it/s]  5%|‚ñç         | 156/3257 [00:00<00:15, 194.03it/s]  5%|‚ñå         | 176/3257 [00:00<00:17, 180.70it/s]  6%|‚ñå         | 197/3257 [00:01<00:16, 185.46it/s]  7%|‚ñã         | 219/3257 [00:01<00:15, 194.46it/s]  7%|‚ñã         | 243/3257 [00:01<00:14, 205.33it/s]  8%|‚ñä         | 264/3257 [00:01<00:15, 197.36it/s]  9%|‚ñâ         | 290/3257 [00:01<00:13, 212.80it/s] 10%|‚ñâ         | 312/3257 [00:01<00:14, 201.56it/s] 10%|‚ñà         | 335/3257 [00:01<00:14, 206.60it/s] 11%|‚ñà         | 357/3257 [00:01<00:13, 209.81it/s] 12%|‚ñà‚ñè        | 379/3257 [00:01<00:15, 189.11it/s] 12%|‚ñà‚ñè        | 399/3257 [00:02<00:15, 188.32it/s] 13%|‚ñà‚ñé        | 420/3257 [00:02<00:14, 191.57it/s] 14%|‚ñà‚ñé        | 440/3257 [00:02<00:16, 166.22it/s] 14%|‚ñà‚ñç        | 460/3257 [00:02<00:16, 174.33it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:15, 173.92it/s] 15%|‚ñà‚ñå        | 501/3257 [00:02<00:14, 184.88it/s] 16%|‚ñà‚ñå        | 522/3257 [00:02<00:14, 188.70it/s] 17%|‚ñà‚ñã        | 542/3257 [00:02<00:14, 191.61it/s] 17%|‚ñà‚ñã        | 562/3257 [00:03<00:15, 176.43it/s] 18%|‚ñà‚ñä        | 581/3257 [00:03<00:15, 169.12it/s] 18%|‚ñà‚ñä        | 602/3257 [00:03<00:14, 177.94it/s] 19%|‚ñà‚ñâ        | 621/3257 [00:03<00:14, 177.61it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:03<00:14, 182.11it/s] 20%|‚ñà‚ñà        | 660/3257 [00:03<00:15, 166.55it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:14, 171.61it/s] 22%|‚ñà‚ñà‚ñè       | 702/3257 [00:03<00:14, 175.40it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:03<00:14, 176.21it/s] 23%|‚ñà‚ñà‚ñé       | 739/3257 [00:04<00:15, 164.64it/s] 23%|‚ñà‚ñà‚ñé       | 761/3257 [00:04<00:14, 178.20it/s] 24%|‚ñà‚ñà‚ñç       | 780/3257 [00:04<00:14, 173.24it/s] 25%|‚ñà‚ñà‚ñç       | 800/3257 [00:04<00:13, 180.21it/s] 25%|‚ñà‚ñà‚ñå       | 819/3257 [00:04<00:13, 179.24it/s] 26%|‚ñà‚ñà‚ñå       | 838/3257 [00:04<00:14, 168.79it/s] 26%|‚ñà‚ñà‚ñã       | 856/3257 [00:04<00:14, 165.75it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:04<00:14, 168.27it/s] 27%|‚ñà‚ñà‚ñã       | 893/3257 [00:04<00:13, 170.84it/s] 28%|‚ñà‚ñà‚ñä       | 913/3257 [00:05<00:13, 177.46it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:05<00:13, 172.88it/s] 29%|‚ñà‚ñà‚ñâ       | 950/3257 [00:05<00:13, 176.91it/s] 30%|‚ñà‚ñà‚ñâ       | 969/3257 [00:05<00:12, 178.26it/s] 30%|‚ñà‚ñà‚ñà       | 987/3257 [00:05<00:13, 172.28it/s] 31%|‚ñà‚ñà‚ñà       | 1005/3257 [00:05<00:12, 173.69it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1023/3257 [00:05<00:12, 175.35it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:05<00:14, 157.71it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1060/3257 [00:05<00:13, 165.01it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:13, 166.72it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:06<00:20, 105.95it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1116/3257 [00:06<00:17, 122.63it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1132/3257 [00:06<00:16, 125.58it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1148/3257 [00:06<00:15, 132.80it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:06<00:14, 147.99it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:06<00:14, 145.80it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1203/3257 [00:07<00:14, 140.41it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:07<00:14, 144.10it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:07<00:12, 163.76it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:07<00:12, 160.25it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:07<00:12, 158.78it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:07<00:12, 152.83it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:07<00:12, 155.23it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:07<00:11, 163.48it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:07<00:11, 167.11it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1363/3257 [00:07<00:11, 166.36it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1380/3257 [00:08<00:11, 160.10it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1397/3257 [00:08<00:11, 158.68it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1419/3257 [00:08<00:10, 175.59it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1437/3257 [00:08<00:10, 173.21it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1459/3257 [00:08<00:09, 185.64it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1478/3257 [00:08<00:09, 184.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1500/3257 [00:08<00:09, 192.57it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1520/3257 [00:08<00:09, 178.95it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1539/3257 [00:08<00:09, 173.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1557/3257 [00:09<00:10, 168.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:09<00:10, 166.42it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:09<00:09, 172.57it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:09<00:09, 180.90it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:09<00:09, 169.71it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1652/3257 [00:09<00:09, 167.46it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1669/3257 [00:09<00:09, 164.17it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1686/3257 [00:09<00:09, 162.57it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1706/3257 [00:09<00:09, 171.05it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1724/3257 [00:10<00:08, 171.74it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1742/3257 [00:10<00:09, 153.01it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:10<00:08, 166.10it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1783/3257 [00:10<00:08, 174.20it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1801/3257 [00:10<00:08, 171.70it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1819/3257 [00:10<00:08, 168.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1837/3257 [00:10<00:08, 165.89it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1855/3257 [00:10<00:08, 167.78it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1876/3257 [00:10<00:07, 176.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1894/3257 [00:11<00:07, 171.32it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1915/3257 [00:11<00:07, 182.05it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1934/3257 [00:11<00:07, 177.57it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1959/3257 [00:11<00:06, 197.74it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1979/3257 [00:11<00:06, 188.63it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:11<00:06, 187.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2019/3257 [00:11<00:06, 188.94it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2038/3257 [00:11<00:06, 185.17it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2057/3257 [00:11<00:07, 167.90it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2075/3257 [00:12<00:06, 170.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2094/3257 [00:12<00:06, 173.35it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2112/3257 [00:12<00:06, 170.86it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2130/3257 [00:12<00:07, 159.68it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2147/3257 [00:12<00:07, 157.69it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:12<00:06, 171.89it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2186/3257 [00:12<00:06, 168.71it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2206/3257 [00:12<00:06, 173.84it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2224/3257 [00:12<00:05, 173.33it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2242/3257 [00:13<00:06, 168.27it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:13<00:05, 169.65it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2278/3257 [00:13<00:05, 163.93it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:13<00:05, 173.33it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2320/3257 [00:13<00:05, 183.57it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2342/3257 [00:13<00:04, 193.39it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2364/3257 [00:13<00:04, 199.67it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2385/3257 [00:13<00:04, 200.18it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2406/3257 [00:13<00:04, 183.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2425/3257 [00:14<00:08, 98.45it/s]  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2441/3257 [00:14<00:07, 106.73it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2461/3257 [00:14<00:06, 123.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:14<00:05, 139.16it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2504/3257 [00:14<00:04, 158.83it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:14<00:04, 167.86it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2544/3257 [00:14<00:04, 174.34it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2563/3257 [00:15<00:04, 169.27it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2581/3257 [00:15<00:04, 163.87it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2599/3257 [00:15<00:04, 164.29it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2624/3257 [00:15<00:03, 187.12it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2644/3257 [00:15<00:03, 181.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2663/3257 [00:15<00:03, 176.84it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2684/3257 [00:15<00:03, 185.23it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2703/3257 [00:15<00:03, 163.83it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2720/3257 [00:16<00:03, 162.23it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2743/3257 [00:16<00:02, 179.44it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2762/3257 [00:16<00:02, 176.70it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2780/3257 [00:16<00:02, 176.77it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:16<00:02, 188.24it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:16<00:02, 182.01it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:16<00:02, 172.01it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2866/3257 [00:16<00:02, 189.20it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:16<00:01, 191.71it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:17<00:01, 178.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:17<00:01, 184.67it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:17<00:01, 178.31it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:17<00:01, 180.05it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:17<00:01, 169.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3007/3257 [00:17<00:01, 182.86it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:17<00:01, 177.43it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:17<00:01, 187.77it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3072/3257 [00:17<00:00, 201.35it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3093/3257 [00:18<00:00, 194.97it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:18<00:00, 205.04it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3139/3257 [00:18<00:00, 197.03it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3159/3257 [00:18<00:00, 185.18it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3178/3257 [00:18<00:00, 173.30it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3200/3257 [00:18<00:00, 184.48it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3219/3257 [00:18<00:00, 174.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3241/3257 [00:18<00:00, 185.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 172.11it/s]
2023-02-07 19:15:16.847 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:15:16,849][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d355,n5,mc7,s0.446808,t4>', 'datetime': '2023-02-07T19:15:16.849137', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:15:16,849][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:15:16,849][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:15:17,424][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:15:17,424][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:15:17,480][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 18716 unique words (43.83% of original 42701, drops 23985)', 'datetime': '2023-02-07T19:15:17.480526', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:15:17,480][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 5754306 word corpus (98.82% of original 5822992, drops 68686)', 'datetime': '2023-02-07T19:15:17.480945', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:15:17,546][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:15:17,547][gensim.models.word2vec][INFO] - sample=0.446808 downsamples 0 most-common words
[2023-02-07 19:15:17,547][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5754306 word corpus (100.0%% of prior 5754306)', 'datetime': '2023-02-07T19:15:17.547897', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:15:17,660][gensim.models.word2vec][INFO] - estimated required memory for 18716 words and 355 dimensions: 67787780 bytes
[2023-02-07 19:15:17,660][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:15:17,696][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18716 vocabulary and 355 features, using sg=1 hs=0 sample=0.4468079565897221 negative=5 window=6 shrink_windows=True', 'datetime': '2023-02-07T19:15:17.696451', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:15:18,699][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 43.35% examples, 2548355 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:19,700][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 90.76% examples, 2617737 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:19,877][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5728381 effective words) took 2.2s, 2628638 effective words/s
[2023-02-07 19:15:20,880][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 51.34% examples, 3002389 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:21,680][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5728381 effective words) took 1.8s, 3179973 effective words/s
[2023-02-07 19:15:22,685][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 61.01% examples, 3543354 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:15:23,285][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5728381 effective words) took 1.6s, 3574758 effective words/s
[2023-02-07 19:15:24,287][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 62.82% examples, 3647107 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:24,855][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5728381 effective words) took 1.6s, 3651410 effective words/s
[2023-02-07 19:15:25,858][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 62.36% examples, 3613965 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:26,448][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5728381 effective words) took 1.6s, 3599015 effective words/s
[2023-02-07 19:15:27,451][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 61.28% examples, 3558009 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:28,053][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5728381 effective words) took 1.6s, 3572698 effective words/s
[2023-02-07 19:15:29,056][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 61.53% examples, 3573953 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:29,650][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5728381 effective words) took 1.6s, 3588675 effective words/s
[2023-02-07 19:15:30,654][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 60.39% examples, 3505525 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:31,263][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5728381 effective words) took 1.6s, 3554526 effective words/s
[2023-02-07 19:15:32,266][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 62.60% examples, 3626525 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:32,844][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5728381 effective words) took 1.6s, 3628105 effective words/s
[2023-02-07 19:15:33,851][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 61.01% examples, 3531818 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:15:34,457][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5728381 effective words) took 1.6s, 3553809 effective words/s
[2023-02-07 19:15:35,459][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 61.53% examples, 3577875 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:36,057][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5728381 effective words) took 1.6s, 3581672 effective words/s
[2023-02-07 19:15:37,061][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 61.53% examples, 3574555 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:37,661][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5728381 effective words) took 1.6s, 3575487 effective words/s
[2023-02-07 19:15:38,665][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 61.01% examples, 3544424 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:39,270][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5728381 effective words) took 1.6s, 3562243 effective words/s
[2023-02-07 19:15:40,273][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 60.76% examples, 3531485 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:40,889][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5728381 effective words) took 1.6s, 3543125 effective words/s
[2023-02-07 19:15:41,890][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 60.76% examples, 3536861 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:42,516][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5728381 effective words) took 1.6s, 3522007 effective words/s
[2023-02-07 19:15:42,517][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85925715 effective words) took 24.8s, 3461893 effective words/s', 'datetime': '2023-02-07T19:15:42.517348', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:15:42.518 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:15:45,674][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191449-67578ylk/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:15:45.674708', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:15:45,675][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:15:45,773][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191449-67578ylk/files/../tmp/embedding_model.pt
2023-02-07 19:15:45.773 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:15:47.918 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:15:48.652 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:16:52.510 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1755139460980315, 'test_mae': 0.8180709335427343, 'test_r2': -4.246633214317218}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.56
wandb: percentage 0.5617
wandb:   test_mae 0.81807
wandb:   test_mse 1.17551
wandb:    test_r2 -4.24663
wandb: 
wandb: üöÄ View run lunar-sweep-37 at: https://wandb.ai/xiaoqiz/mof2vec/runs/67578ylk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_191449-67578ylk/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vkew6eov with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 987
wandb: 	model.gensim.alpha: 0.014403039962746488
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.6186910252533324
wandb: 	model.gensim.vector_size: 384
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.8752108486484907
wandb: 	model.sklearn.max_depth: 28
wandb: 	model.sklearn.min_child_weight: 0.024817060636506814
wandb: 	model.sklearn.n_estimators: 3548
wandb: 	model.sklearn.num_leaves: 463
wandb: 	model.sklearn.reg_alpha: 0.014398952500383488
wandb: 	model.sklearn.reg_lambda: 0.08004933107157679
wandb: 	model.sklearn.subsample: 0.2358484700516477
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191711-vkew6eov
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-38
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/vkew6eov
2023-02-07 19:17:20.091 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:17:20.091 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 987 for sweep.
2023-02-07 19:17:20.092 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.014403039962746488 for sweep.
2023-02-07 19:17:20.093 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:17:20.093 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 19:17:20.093 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6186910252533324 for sweep.
2023-02-07 19:17:20.093 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 384 for sweep.
2023-02-07 19:17:20.094 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 19:17:20.094 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.8752108486484907 for sweep.
2023-02-07 19:17:20.094 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 28 for sweep.
2023-02-07 19:17:20.094 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.024817060636506814 for sweep.
2023-02-07 19:17:20.095 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3548 for sweep.
2023-02-07 19:17:20.095 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 463 for sweep.
2023-02-07 19:17:20.095 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.014398952500383488 for sweep.
2023-02-07 19:17:20.095 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.08004933107157679 for sweep.
2023-02-07 19:17:20.096 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2358484700516477 for sweep.
2023-02-07 19:17:20.096 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:17:20.103 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191711-vkew6eov/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 987, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 384, 'window': 8, 'min_count': 8, 'dm': 0, 'sample': 0.6186910252533324, 'workers': 4, 'alpha': 0.014403039962746488, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3548, 'max_depth': 28, 'num_leaves': 463, 'reg_alpha': 0.014398952500383488, 'reg_lambda': 0.08004933107157679, 'subsample': 0.2358484700516477, 'min_child_weight': 0.024817060636506814, 'n_jobs': 4, 'learning_rate': 0.8752108486484907}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:22, 144.43it/s]  1%|          | 32/3257 [00:00<00:20, 158.81it/s]  1%|‚ñè         | 48/3257 [00:00<00:20, 155.89it/s]  2%|‚ñè         | 64/3257 [00:00<00:20, 156.72it/s]  2%|‚ñè         | 81/3257 [00:00<00:19, 159.43it/s]  3%|‚ñé         | 97/3257 [00:00<00:20, 155.61it/s]  3%|‚ñé         | 113/3257 [00:00<00:20, 153.88it/s]  4%|‚ñç         | 130/3257 [00:00<00:19, 158.47it/s]  5%|‚ñç         | 149/3257 [00:00<00:18, 164.27it/s]  5%|‚ñå         | 166/3257 [00:01<00:19, 155.45it/s]  6%|‚ñå         | 183/3257 [00:01<00:19, 157.28it/s]  6%|‚ñå         | 201/3257 [00:01<00:19, 159.15it/s]  7%|‚ñã         | 222/3257 [00:01<00:17, 173.34it/s]  7%|‚ñã         | 242/3257 [00:01<00:16, 178.87it/s]  8%|‚ñä         | 260/3257 [00:01<00:17, 167.18it/s]  9%|‚ñä         | 282/3257 [00:01<00:16, 180.64it/s]  9%|‚ñâ         | 301/3257 [00:01<00:17, 171.12it/s] 10%|‚ñâ         | 320/3257 [00:01<00:16, 174.57it/s] 10%|‚ñà         | 338/3257 [00:02<00:16, 172.03it/s] 11%|‚ñà         | 356/3257 [00:02<00:16, 173.21it/s] 11%|‚ñà‚ñè        | 374/3257 [00:02<00:17, 168.00it/s] 12%|‚ñà‚ñè        | 391/3257 [00:02<00:18, 155.92it/s] 13%|‚ñà‚ñé        | 409/3257 [00:02<00:17, 161.36it/s] 13%|‚ñà‚ñé        | 426/3257 [00:02<00:19, 144.44it/s] 14%|‚ñà‚ñé        | 442/3257 [00:02<00:19, 146.61it/s] 14%|‚ñà‚ñç        | 459/3257 [00:03<00:27, 103.23it/s] 15%|‚ñà‚ñç        | 476/3257 [00:03<00:23, 116.09it/s] 15%|‚ñà‚ñå        | 493/3257 [00:03<00:21, 127.65it/s] 16%|‚ñà‚ñå        | 513/3257 [00:03<00:19, 143.89it/s] 16%|‚ñà‚ñã        | 530/3257 [00:03<00:18, 149.85it/s] 17%|‚ñà‚ñã        | 547/3257 [00:03<00:17, 153.13it/s] 17%|‚ñà‚ñã        | 564/3257 [00:03<00:18, 146.52it/s] 18%|‚ñà‚ñä        | 580/3257 [00:03<00:18, 148.24it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:16, 158.51it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:04<00:16, 158.34it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:04<00:15, 166.01it/s] 20%|‚ñà‚ñà        | 656/3257 [00:04<00:16, 153.90it/s] 21%|‚ñà‚ñà        | 674/3257 [00:04<00:16, 159.38it/s] 21%|‚ñà‚ñà        | 691/3257 [00:04<00:16, 153.13it/s] 22%|‚ñà‚ñà‚ñè       | 709/3257 [00:04<00:15, 159.88it/s] 22%|‚ñà‚ñà‚ñè       | 726/3257 [00:04<00:17, 148.66it/s] 23%|‚ñà‚ñà‚ñé       | 742/3257 [00:04<00:17, 145.70it/s] 23%|‚ñà‚ñà‚ñé       | 759/3257 [00:04<00:16, 150.70it/s] 24%|‚ñà‚ñà‚ñç       | 775/3257 [00:05<00:16, 152.31it/s] 24%|‚ñà‚ñà‚ñç       | 791/3257 [00:05<00:16, 152.28it/s] 25%|‚ñà‚ñà‚ñç       | 807/3257 [00:05<00:16, 151.69it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:05<00:16, 149.04it/s] 26%|‚ñà‚ñà‚ñå       | 838/3257 [00:05<00:16, 148.52it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:05<00:16, 142.01it/s] 27%|‚ñà‚ñà‚ñã       | 869/3257 [00:05<00:16, 145.60it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:05<00:16, 140.12it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:15, 155.29it/s] 28%|‚ñà‚ñà‚ñä       | 922/3257 [00:05<00:14, 158.58it/s] 29%|‚ñà‚ñà‚ñâ       | 938/3257 [00:06<00:15, 151.60it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:06<00:14, 158.06it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:06<00:14, 152.70it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:06<00:15, 150.56it/s] 31%|‚ñà‚ñà‚ñà       | 1004/3257 [00:06<00:14, 151.61it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1020/3257 [00:06<00:14, 149.92it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1036/3257 [00:06<00:15, 141.07it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:06<00:16, 137.01it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:07<00:15, 142.74it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1082/3257 [00:07<00:15, 143.13it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:07<00:15, 143.03it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1114/3257 [00:07<00:14, 150.21it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1130/3257 [00:07<00:14, 142.60it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1145/3257 [00:07<00:15, 140.54it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1163/3257 [00:07<00:13, 149.62it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1179/3257 [00:07<00:14, 140.08it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:07<00:15, 133.90it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1208/3257 [00:08<00:15, 130.12it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1226/3257 [00:08<00:14, 143.02it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:08<00:13, 147.97it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:08<00:13, 145.42it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:08<00:13, 144.13it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:08<00:14, 138.19it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1305/3257 [00:08<00:13, 140.98it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:08<00:13, 143.60it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:08<00:12, 150.99it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1355/3257 [00:09<00:13, 143.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:09<00:13, 144.87it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:09<00:13, 143.76it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:09<00:12, 149.04it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:09<00:11, 161.47it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1440/3257 [00:09<00:11, 157.16it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:09<00:10, 168.84it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:09<00:10, 166.07it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:09<00:10, 171.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1514/3257 [00:09<00:10, 170.50it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1532/3257 [00:10<00:11, 154.91it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1548/3257 [00:10<00:11, 145.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1565/3257 [00:10<00:11, 147.94it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1580/3257 [00:10<00:11, 145.18it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1597/3257 [00:10<00:11, 150.10it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:10<00:10, 157.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1631/3257 [00:10<00:10, 153.31it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1647/3257 [00:10<00:11, 140.49it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:11<00:11, 137.95it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:11<00:11, 136.25it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:11<00:11, 137.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:11<00:10, 143.90it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1724/3257 [00:11<00:10, 148.27it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1739/3257 [00:11<00:11, 132.13it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1755/3257 [00:11<00:10, 138.16it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:11<00:10, 142.63it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1788/3257 [00:11<00:09, 149.57it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1804/3257 [00:12<00:09, 149.01it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1820/3257 [00:12<00:17, 82.70it/s]  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1832/3257 [00:12<00:16, 88.40it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1848/3257 [00:12<00:13, 102.70it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1867/3257 [00:12<00:11, 121.54it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1882/3257 [00:12<00:10, 126.41it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:12<00:10, 128.92it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:13<00:09, 137.09it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1932/3257 [00:13<00:09, 142.48it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1952/3257 [00:13<00:08, 157.86it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1969/3257 [00:13<00:08, 160.99it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1986/3257 [00:13<00:08, 151.74it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:13<00:08, 154.42it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:13<00:07, 158.52it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2039/3257 [00:13<00:07, 154.20it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:13<00:08, 141.03it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2070/3257 [00:14<00:08, 138.37it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:14<00:08, 140.51it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:14<00:08, 137.78it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2119/3257 [00:14<00:07, 150.07it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2135/3257 [00:14<00:08, 138.12it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2150/3257 [00:14<00:08, 135.22it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:14<00:07, 140.41it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:14<00:07, 140.43it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2198/3257 [00:14<00:07, 147.12it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2213/3257 [00:15<00:07, 137.69it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2229/3257 [00:15<00:07, 143.32it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2244/3257 [00:15<00:07, 139.28it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:15<00:07, 141.40it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:15<00:07, 134.26it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2295/3257 [00:15<00:06, 151.70it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2311/3257 [00:15<00:06, 146.84it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2331/3257 [00:15<00:05, 159.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2350/3257 [00:15<00:05, 166.49it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2367/3257 [00:16<00:05, 164.29it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2386/3257 [00:16<00:05, 168.81it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:16<00:05, 169.66it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:16<00:05, 155.59it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2438/3257 [00:16<00:05, 147.82it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2454/3257 [00:16<00:05, 144.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:16<00:04, 158.35it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2492/3257 [00:16<00:04, 158.68it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2511/3257 [00:16<00:04, 166.15it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2528/3257 [00:17<00:04, 165.44it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2545/3257 [00:17<00:04, 166.57it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2562/3257 [00:17<00:04, 152.02it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2578/3257 [00:17<00:04, 148.50it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2594/3257 [00:17<00:04, 141.23it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2616/3257 [00:17<00:03, 160.81it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2635/3257 [00:17<00:03, 167.56it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2653/3257 [00:17<00:03, 156.81it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2670/3257 [00:18<00:03, 156.23it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:18<00:03, 159.75it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:18<00:03, 142.57it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:18<00:03, 140.09it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2739/3257 [00:18<00:03, 155.27it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:18<00:03, 156.72it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2772/3257 [00:18<00:03, 148.57it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:18<00:02, 159.71it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2809/3257 [00:18<00:02, 156.66it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2825/3257 [00:19<00:02, 146.57it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2840/3257 [00:19<00:02, 146.74it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2861/3257 [00:19<00:02, 162.54it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2881/3257 [00:19<00:02, 170.99it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2899/3257 [00:19<00:02, 156.98it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:19<00:02, 153.35it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2932/3257 [00:19<00:02, 152.93it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2948/3257 [00:19<00:02, 143.31it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2963/3257 [00:19<00:02, 144.01it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2978/3257 [00:20<00:02, 136.50it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2992/3257 [00:20<00:01, 135.64it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:20<00:01, 150.03it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3027/3257 [00:20<00:01, 144.14it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3046/3257 [00:20<00:01, 155.77it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3064/3257 [00:20<00:01, 162.30it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3081/3257 [00:20<00:01, 159.42it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3098/3257 [00:20<00:01, 156.12it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3117/3257 [00:20<00:00, 164.99it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3134/3257 [00:21<00:00, 154.96it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3150/3257 [00:21<00:00, 146.41it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:21<00:00, 145.38it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3180/3257 [00:21<00:00, 139.74it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3198/3257 [00:21<00:00, 149.13it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3214/3257 [00:21<00:00, 139.64it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3231/3257 [00:21<00:00, 146.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3248/3257 [00:21<00:00, 152.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 148.57it/s]
2023-02-07 19:17:42.973 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:17:42,975][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d384,n5,mc8,s0.618691,t4>', 'datetime': '2023-02-07T19:17:42.975123', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:17:42,975][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:17:42,975][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:17:43,629][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:17:43,629][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:17:43,689][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 18271 unique words (42.79% of original 42701, drops 24430)', 'datetime': '2023-02-07T19:17:43.689845', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:17:43,690][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 5751191 word corpus (98.77% of original 5822992, drops 71801)', 'datetime': '2023-02-07T19:17:43.690394', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:17:43,759][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:17:43,760][gensim.models.word2vec][INFO] - sample=0.618691 downsamples 0 most-common words
[2023-02-07 19:17:43,760][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5751191 word corpus (100.0%% of prior 5751191)', 'datetime': '2023-02-07T19:17:43.760920', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:17:43,881][gensim.models.word2vec][INFO] - estimated required memory for 18271 words and 384 dimensions: 70918164 bytes
[2023-02-07 19:17:43,881][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:17:43,924][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18271 vocabulary and 384 features, using sg=1 hs=0 sample=0.6186910252533324 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T19:17:43.924886', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:17:44,929][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 32.91% examples, 1908880 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:45,930][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 67.24% examples, 1960561 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:46,808][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5725443 effective words) took 2.9s, 1986621 effective words/s
[2023-02-07 19:17:47,812][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 37.09% examples, 2175490 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:48,813][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 73.56% examples, 2130319 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:49,508][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5725443 effective words) took 2.7s, 2122124 effective words/s
[2023-02-07 19:17:50,511][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 36.48% examples, 2134738 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:51,512][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 73.63% examples, 2133093 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:52,195][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5725443 effective words) took 2.7s, 2132274 effective words/s
[2023-02-07 19:17:53,202][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 37.58% examples, 2198715 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:17:54,204][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 77.10% examples, 2225870 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:54,779][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5725443 effective words) took 2.6s, 2219188 effective words/s
[2023-02-07 19:17:55,782][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 37.40% examples, 2195617 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:56,782][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 76.27% examples, 2211882 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:17:57,356][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5725443 effective words) took 2.6s, 2222978 effective words/s
[2023-02-07 19:17:58,359][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 38.16% examples, 2232014 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:59,360][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 77.96% examples, 2249438 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:59,893][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5725443 effective words) took 2.5s, 2258667 effective words/s
[2023-02-07 19:18:00,899][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.99% examples, 2269959 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:01,899][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 79.28% examples, 2290069 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:02,397][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5725443 effective words) took 2.5s, 2287457 effective words/s
[2023-02-07 19:18:03,406][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 38.87% examples, 2263018 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:18:04,407][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 79.28% examples, 2285486 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:04,894][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5725443 effective words) took 2.5s, 2294975 effective words/s
[2023-02-07 19:18:05,900][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 31.10% examples, 1777622 words/s, in_qsize 6, out_qsize 2
[2023-02-07 19:18:06,906][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 62.36% examples, 1799349 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:18:07,915][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 94.32% examples, 1793818 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:08,077][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5725443 effective words) took 3.2s, 1799376 effective words/s
[2023-02-07 19:18:09,083][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 38.87% examples, 2274723 words/s, in_qsize 8, out_qsize 2
[2023-02-07 19:18:10,083][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 79.15% examples, 2288156 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:10,566][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5725443 effective words) took 2.5s, 2303445 effective words/s
[2023-02-07 19:18:11,572][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 39.76% examples, 2335912 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:12,578][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 81.82% examples, 2350791 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:13,002][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5725443 effective words) took 2.4s, 2352832 effective words/s
[2023-02-07 19:18:14,004][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 39.64% examples, 2334843 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:15,010][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 80.81% examples, 2323879 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:18:15,455][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5725443 effective words) took 2.5s, 2335292 effective words/s
[2023-02-07 19:18:16,461][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 39.94% examples, 2348327 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:17,462][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 82.16% examples, 2367240 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:17,875][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5725443 effective words) took 2.4s, 2369743 effective words/s
[2023-02-07 19:18:18,879][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 39.94% examples, 2347972 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:19,884][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 81.39% examples, 2339675 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:20,330][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5725443 effective words) took 2.5s, 2334069 effective words/s
[2023-02-07 19:18:21,332][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 39.24% examples, 2305315 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:22,335][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 78.78% examples, 2272923 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:22,849][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5725443 effective words) took 2.5s, 2273408 effective words/s
[2023-02-07 19:18:22,850][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85881645 effective words) took 38.9s, 2206328 effective words/s', 'datetime': '2023-02-07T19:18:22.850507', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:18:22.850 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:18:26,460][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191711-vkew6eov/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:18:26.460733', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:18:26,461][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:18:26,558][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191711-vkew6eov/files/../tmp/embedding_model.pt
2023-02-07 19:18:26.558 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:18:28.885 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:18:29.716 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:18:32.922 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9812802331451891, 'test_mae': 0.7597063593794963, 'test_r2': -1.7208296790472617}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.8
wandb: percentage 0.57212
wandb:   test_mae 0.75971
wandb:   test_mse 0.98128
wandb:    test_r2 -1.72083
wandb: 
wandb: üöÄ View run divine-sweep-38 at: https://wandb.ai/xiaoqiz/mof2vec/runs/vkew6eov
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_191711-vkew6eov/logs
wandb: Agent Starting Run: l73h33fj with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 566
wandb: 	model.gensim.alpha: 0.015170019952497686
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.32901383737927936
wandb: 	model.gensim.vector_size: 160
wandb: 	model.gensim.window: 6
wandb: 	model.sklearn.learning_rate: 0.0007202569329969994
wandb: 	model.sklearn.max_depth: 37
wandb: 	model.sklearn.min_child_weight: 0.08758222555061358
wandb: 	model.sklearn.n_estimators: 495
wandb: 	model.sklearn.num_leaves: 244
wandb: 	model.sklearn.reg_alpha: 0.009087466056437418
wandb: 	model.sklearn.reg_lambda: 0.014080003834947374
wandb: 	model.sklearn.subsample: 0.33132341544926347
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191846-l73h33fj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-39
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/l73h33fj
2023-02-07 19:18:55.428 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:18:55.429 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 566 for sweep.
2023-02-07 19:18:55.429 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.015170019952497686 for sweep.
2023-02-07 19:18:55.429 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:18:55.430 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 19:18:55.430 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.32901383737927936 for sweep.
2023-02-07 19:18:55.430 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 160 for sweep.
2023-02-07 19:18:55.430 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 6 for sweep.
2023-02-07 19:18:55.431 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0007202569329969994 for sweep.
2023-02-07 19:18:55.431 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 37 for sweep.
2023-02-07 19:18:55.431 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08758222555061358 for sweep.
2023-02-07 19:18:55.431 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 495 for sweep.
2023-02-07 19:18:55.432 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 244 for sweep.
2023-02-07 19:18:55.432 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.009087466056437418 for sweep.
2023-02-07 19:18:55.432 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.014080003834947374 for sweep.
2023-02-07 19:18:55.433 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.33132341544926347 for sweep.
2023-02-07 19:18:55.433 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:18:55.437 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191846-l73h33fj/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 566, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 160, 'window': 6, 'min_count': 2, 'dm': 0, 'sample': 0.32901383737927936, 'workers': 4, 'alpha': 0.015170019952497686, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 495, 'max_depth': 37, 'num_leaves': 244, 'reg_alpha': 0.009087466056437418, 'reg_lambda': 0.014080003834947374, 'subsample': 0.33132341544926347, 'min_child_weight': 0.08758222555061358, 'n_jobs': 4, 'learning_rate': 0.0007202569329969994}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:22, 145.58it/s]  1%|          | 31/3257 [00:00<00:21, 152.58it/s]  1%|‚ñè         | 47/3257 [00:00<00:20, 153.34it/s]  2%|‚ñè         | 63/3257 [00:00<00:21, 148.62it/s]  2%|‚ñè         | 79/3257 [00:00<00:20, 152.18it/s]  3%|‚ñé         | 95/3257 [00:00<00:20, 151.79it/s]  3%|‚ñé         | 111/3257 [00:00<00:21, 144.89it/s]  4%|‚ñç         | 128/3257 [00:00<00:20, 151.29it/s]  5%|‚ñç         | 147/3257 [00:00<00:19, 162.55it/s]  5%|‚ñå         | 164/3257 [00:01<00:20, 152.35it/s]  6%|‚ñå         | 180/3257 [00:01<00:20, 152.08it/s]  6%|‚ñå         | 198/3257 [00:01<00:19, 159.55it/s]  7%|‚ñã         | 216/3257 [00:01<00:18, 162.86it/s]  7%|‚ñã         | 236/3257 [00:01<00:17, 171.90it/s]  8%|‚ñä         | 254/3257 [00:01<00:17, 169.80it/s]  8%|‚ñä         | 272/3257 [00:01<00:17, 168.42it/s]  9%|‚ñâ         | 294/3257 [00:01<00:16, 180.62it/s] 10%|‚ñâ         | 313/3257 [00:01<00:17, 165.77it/s] 10%|‚ñà         | 334/3257 [00:02<00:16, 173.76it/s] 11%|‚ñà         | 352/3257 [00:02<00:17, 169.56it/s] 11%|‚ñà‚ñè        | 371/3257 [00:02<00:16, 173.59it/s] 12%|‚ñà‚ñè        | 389/3257 [00:02<00:18, 156.10it/s] 12%|‚ñà‚ñè        | 407/3257 [00:02<00:17, 161.71it/s] 13%|‚ñà‚ñé        | 424/3257 [00:02<00:17, 159.24it/s] 14%|‚ñà‚ñé        | 441/3257 [00:02<00:19, 141.79it/s] 14%|‚ñà‚ñç        | 458/3257 [00:02<00:19, 146.93it/s] 15%|‚ñà‚ñç        | 475/3257 [00:02<00:18, 152.57it/s] 15%|‚ñà‚ñå        | 493/3257 [00:03<00:17, 157.98it/s] 16%|‚ñà‚ñå        | 512/3257 [00:03<00:16, 164.36it/s] 16%|‚ñà‚ñå        | 529/3257 [00:03<00:16, 160.93it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:16, 162.67it/s] 17%|‚ñà‚ñã        | 563/3257 [00:03<00:17, 152.55it/s] 18%|‚ñà‚ñä        | 579/3257 [00:03<00:17, 149.39it/s] 18%|‚ñà‚ñä        | 598/3257 [00:03<00:16, 159.92it/s] 19%|‚ñà‚ñâ        | 617/3257 [00:03<00:15, 167.63it/s] 19%|‚ñà‚ñâ        | 634/3257 [00:03<00:15, 167.07it/s] 20%|‚ñà‚ñâ        | 651/3257 [00:04<00:16, 158.33it/s] 20%|‚ñà‚ñà        | 667/3257 [00:04<00:16, 154.53it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:16, 152.55it/s] 21%|‚ñà‚ñà‚ñè       | 699/3257 [00:04<00:16, 152.73it/s] 22%|‚ñà‚ñà‚ñè       | 719/3257 [00:04<00:15, 165.05it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:04<00:16, 151.40it/s] 23%|‚ñà‚ñà‚ñé       | 753/3257 [00:04<00:16, 154.23it/s] 24%|‚ñà‚ñà‚ñé       | 771/3257 [00:04<00:15, 160.77it/s] 24%|‚ñà‚ñà‚ñç       | 788/3257 [00:04<00:16, 153.65it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:05<00:15, 155.52it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:05<00:15, 155.63it/s] 26%|‚ñà‚ñà‚ñå       | 839/3257 [00:05<00:15, 154.92it/s] 26%|‚ñà‚ñà‚ñã       | 855/3257 [00:05<00:16, 149.56it/s] 27%|‚ñà‚ñà‚ñã       | 873/3257 [00:05<00:15, 154.49it/s] 27%|‚ñà‚ñà‚ñã       | 889/3257 [00:05<00:15, 152.02it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:05<00:14, 156.76it/s] 28%|‚ñà‚ñà‚ñä       | 926/3257 [00:05<00:14, 164.66it/s] 29%|‚ñà‚ñà‚ñâ       | 943/3257 [00:05<00:14, 159.74it/s] 30%|‚ñà‚ñà‚ñâ       | 961/3257 [00:06<00:13, 164.55it/s] 30%|‚ñà‚ñà‚ñà       | 978/3257 [00:06<00:13, 166.06it/s] 31%|‚ñà‚ñà‚ñà       | 995/3257 [00:06<00:14, 152.15it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:06<00:14, 151.30it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:06<00:14, 148.72it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1042/3257 [00:06<00:15, 146.05it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1058/3257 [00:06<00:14, 149.42it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1077/3257 [00:06<00:13, 159.33it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:06<00:14, 146.12it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:07<00:13, 154.96it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1128/3257 [00:07<00:14, 145.99it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:07<00:14, 149.38it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1161/3257 [00:07<00:13, 154.40it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1177/3257 [00:07<00:13, 151.19it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1193/3257 [00:07<00:14, 140.48it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1208/3257 [00:07<00:24, 84.50it/s]  38%|‚ñà‚ñà‚ñà‚ñä      | 1227/3257 [00:08<00:19, 103.47it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1244/3257 [00:08<00:17, 116.66it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1260/3257 [00:08<00:15, 125.12it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:08<00:15, 129.24it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:08<00:15, 130.37it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1306/3257 [00:08<00:14, 138.11it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1322/3257 [00:08<00:13, 143.83it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1341/3257 [00:08<00:12, 155.01it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1358/3257 [00:08<00:12, 150.44it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1374/3257 [00:09<00:12, 147.72it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1390/3257 [00:09<00:12, 145.92it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1410/3257 [00:09<00:11, 159.62it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1429/3257 [00:09<00:10, 168.05it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1447/3257 [00:09<00:10, 166.31it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1467/3257 [00:09<00:10, 175.11it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1485/3257 [00:09<00:10, 171.77it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1506/3257 [00:09<00:09, 182.48it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1525/3257 [00:09<00:10, 165.67it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1542/3257 [00:10<00:10, 162.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1559/3257 [00:10<00:10, 158.12it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:10<00:10, 157.93it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:10<00:09, 166.82it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1614/3257 [00:10<00:09, 175.18it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1632/3257 [00:10<00:09, 171.09it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:10<00:10, 152.98it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1666/3257 [00:10<00:10, 151.38it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1682/3257 [00:10<00:10, 151.71it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1699/3257 [00:11<00:10, 155.05it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:11<00:09, 154.54it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:11<00:10, 146.65it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1747/3257 [00:11<00:10, 149.72it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1764/3257 [00:11<00:09, 155.14it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1783/3257 [00:11<00:09, 163.19it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1800/3257 [00:11<00:08, 161.98it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1817/3257 [00:11<00:08, 160.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1834/3257 [00:11<00:09, 157.41it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1852/3257 [00:12<00:08, 162.70it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1872/3257 [00:12<00:08, 172.61it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1890/3257 [00:12<00:07, 171.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1909/3257 [00:12<00:07, 176.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1927/3257 [00:12<00:07, 168.17it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1951/3257 [00:12<00:06, 187.02it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1972/3257 [00:12<00:06, 191.41it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1992/3257 [00:12<00:07, 180.18it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2011/3257 [00:12<00:07, 176.79it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2032/3257 [00:12<00:06, 185.08it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2051/3257 [00:13<00:07, 164.48it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2068/3257 [00:13<00:07, 160.55it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:13<00:07, 162.71it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2102/3257 [00:13<00:07, 160.56it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:13<00:07, 158.36it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:13<00:07, 156.40it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2152/3257 [00:13<00:07, 153.41it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2170/3257 [00:13<00:06, 159.20it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2186/3257 [00:13<00:06, 156.01it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:14<00:06, 162.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2221/3257 [00:14<00:06, 160.24it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:14<00:06, 150.67it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2255/3257 [00:14<00:06, 153.94it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2271/3257 [00:14<00:06, 147.50it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2291/3257 [00:14<00:06, 159.65it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2308/3257 [00:14<00:05, 161.51it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2331/3257 [00:14<00:05, 180.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2353/3257 [00:14<00:04, 189.70it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2373/3257 [00:15<00:04, 181.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2396/3257 [00:15<00:04, 192.36it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2416/3257 [00:15<00:04, 177.59it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2435/3257 [00:15<00:04, 167.97it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2453/3257 [00:15<00:04, 164.98it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:15<00:04, 178.34it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2494/3257 [00:15<00:04, 180.65it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:15<00:04, 184.95it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2535/3257 [00:15<00:03, 188.67it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2554/3257 [00:16<00:03, 176.14it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:16<00:04, 162.84it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2589/3257 [00:16<00:04, 160.12it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2613/3257 [00:16<00:03, 180.65it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2633/3257 [00:16<00:03, 185.27it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2652/3257 [00:16<00:03, 173.86it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2670/3257 [00:17<00:06, 93.03it/s]  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2688/3257 [00:17<00:05, 107.77it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2703/3257 [00:17<00:05, 109.23it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2717/3257 [00:17<00:04, 115.21it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2739/3257 [00:17<00:03, 138.43it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:17<00:03, 146.61it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:17<00:03, 146.12it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2796/3257 [00:17<00:02, 164.93it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2814/3257 [00:17<00:02, 165.18it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2832/3257 [00:18<00:02, 156.74it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2851/3257 [00:18<00:02, 162.85it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2874/3257 [00:18<00:02, 179.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2893/3257 [00:18<00:02, 169.88it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2911/3257 [00:18<00:02, 170.98it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2929/3257 [00:18<00:01, 171.71it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:18<00:01, 166.71it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2965/3257 [00:18<00:01, 169.43it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2983/3257 [00:19<00:01, 156.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3003/3257 [00:19<00:01, 167.64it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3021/3257 [00:19<00:01, 164.89it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3041/3257 [00:19<00:01, 174.29it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:19<00:01, 184.18it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:19<00:00, 178.52it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3101/3257 [00:19<00:00, 175.71it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3121/3257 [00:19<00:00, 179.86it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3140/3257 [00:19<00:00, 169.86it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3158/3257 [00:20<00:00, 164.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3176/3257 [00:20<00:00, 164.42it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3195/3257 [00:20<00:00, 170.85it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:20<00:00, 159.60it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3234/3257 [00:20<00:00, 172.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:20<00:00, 173.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 158.26it/s]
2023-02-07 19:19:16.807 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:19:16,809][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d160,n5,mc2,s0.329014,t4>', 'datetime': '2023-02-07T19:19:16.808975', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:19:16,809][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:19:16,809][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:19:17,341][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:19:17,341][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:19:17,419][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 27186 unique words (85.48% of original 31803, drops 4617)', 'datetime': '2023-02-07T19:19:17.419837', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:19:17,420][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5090501 word corpus (99.91% of original 5095118, drops 4617)', 'datetime': '2023-02-07T19:19:17.420265', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:19:17,522][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:19:17,525][gensim.models.word2vec][INFO] - sample=0.329014 downsamples 0 most-common words
[2023-02-07 19:19:17,525][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5090501 word corpus (100.0%% of prior 5090501)', 'datetime': '2023-02-07T19:19:17.525408', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:19:17,704][gensim.models.word2vec][INFO] - estimated required memory for 27186 words and 160 dimensions: 51126960 bytes
[2023-02-07 19:19:17,705][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:19:17,728][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 27186 vocabulary and 160 features, using sg=1 hs=0 sample=0.32901383737927936 negative=5 window=6 shrink_windows=True', 'datetime': '2023-02-07T19:19:17.728165', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:19:18,734][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 53.30% examples, 2769397 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:19,549][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5082292 effective words) took 1.8s, 2794069 effective words/s
[2023-02-07 19:19:20,552][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 59.75% examples, 3087751 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:21,199][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5082292 effective words) took 1.6s, 3081981 effective words/s
[2023-02-07 19:19:22,202][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 60.85% examples, 3139663 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:22,826][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5082292 effective words) took 1.6s, 3126890 effective words/s
[2023-02-07 19:19:23,830][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 61.28% examples, 3156385 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:24,435][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5082292 effective words) took 1.6s, 3162732 effective words/s
[2023-02-07 19:19:25,440][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 61.01% examples, 3141557 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:26,041][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5082292 effective words) took 1.6s, 3167430 effective words/s
[2023-02-07 19:19:27,043][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 62.85% examples, 3245723 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:27,616][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5082292 effective words) took 1.6s, 3231456 effective words/s
[2023-02-07 19:19:28,618][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 63.40% examples, 3277377 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:29,180][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5082292 effective words) took 1.6s, 3252085 effective words/s
[2023-02-07 19:19:30,182][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 63.22% examples, 3267274 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:30,737][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5082292 effective words) took 1.6s, 3266806 effective words/s
[2023-02-07 19:19:31,748][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 52.29% examples, 2713265 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:32,623][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5082292 effective words) took 1.9s, 2707656 effective words/s
[2023-02-07 19:19:33,628][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 62.60% examples, 3216880 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:34,192][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5082292 effective words) took 1.6s, 3242003 effective words/s
[2023-02-07 19:19:35,194][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 63.77% examples, 3293549 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:35,735][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5082292 effective words) took 1.5s, 3297016 effective words/s
[2023-02-07 19:19:36,740][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 64.35% examples, 3320866 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:37,274][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5082292 effective words) took 1.5s, 3305095 effective words/s
[2023-02-07 19:19:38,278][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 63.22% examples, 3265267 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:38,839][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5082292 effective words) took 1.6s, 3251420 effective words/s
[2023-02-07 19:19:39,841][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 62.39% examples, 3211593 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:40,424][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5082292 effective words) took 1.6s, 3209272 effective words/s
[2023-02-07 19:19:41,429][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 62.60% examples, 3215884 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:42,003][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5082292 effective words) took 1.6s, 3221443 effective words/s
[2023-02-07 19:19:42,004][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76234380 effective words) took 24.3s, 3140339 effective words/s', 'datetime': '2023-02-07T19:19:42.004448', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:19:42.004 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:19:44,850][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191846-l73h33fj/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:19:44.850392', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:19:44,851][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:19:44,934][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191846-l73h33fj/files/../tmp/embedding_model.pt
2023-02-07 19:19:44.934 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:19:46.550 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:19:47.143 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:20:47.083 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.8781090461425571, 'test_mae': 0.7020229986565976, 'test_r2': -1.9314248929952278}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.83
wandb: percentage 0.14517
wandb:   test_mae 0.70202
wandb:   test_mse 0.87811
wandb:    test_r2 -1.93142
wandb: 
wandb: üöÄ View run summer-sweep-39 at: https://wandb.ai/xiaoqiz/mof2vec/runs/l73h33fj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_191846-l73h33fj/logs
wandb: Agent Starting Run: o4gka47c with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 500
wandb: 	model.gensim.alpha: 0.0239998035976908
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.4552651070051755
wandb: 	model.gensim.vector_size: 306
wandb: 	model.gensim.window: 6
wandb: 	model.sklearn.learning_rate: 0.3242954551289716
wandb: 	model.sklearn.max_depth: 18
wandb: 	model.sklearn.min_child_weight: 0.06752363459717566
wandb: 	model.sklearn.n_estimators: 1913
wandb: 	model.sklearn.num_leaves: 399
wandb: 	model.sklearn.reg_alpha: 0.008287016944225766
wandb: 	model.sklearn.reg_lambda: 0.8804121054319832
wandb: 	model.sklearn.subsample: 0.48512213407434857
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192058-o4gka47c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-40
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/o4gka47c
2023-02-07 19:21:06.379 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 19:21:06.380 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 500 for sweep.
2023-02-07 19:21:06.380 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0239998035976908 for sweep.
2023-02-07 19:21:06.380 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:21:06.380 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 19:21:06.381 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4552651070051755 for sweep.
2023-02-07 19:21:06.381 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 306 for sweep.
2023-02-07 19:21:06.381 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 6 for sweep.
2023-02-07 19:21:06.381 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.3242954551289716 for sweep.
2023-02-07 19:21:06.382 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 18 for sweep.
2023-02-07 19:21:06.382 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.06752363459717566 for sweep.
2023-02-07 19:21:06.382 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1913 for sweep.
2023-02-07 19:21:06.382 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 399 for sweep.
2023-02-07 19:21:06.383 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.008287016944225766 for sweep.
2023-02-07 19:21:06.383 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.8804121054319832 for sweep.
2023-02-07 19:21:06.383 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.48512213407434857 for sweep.
2023-02-07 19:21:06.383 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:21:06.391 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192058-o4gka47c/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 500, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 306, 'window': 6, 'min_count': 7, 'dm': 0, 'sample': 0.4552651070051755, 'workers': 4, 'alpha': 0.0239998035976908, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1913, 'max_depth': 18, 'num_leaves': 399, 'reg_alpha': 0.008287016944225766, 'reg_lambda': 0.8804121054319832, 'subsample': 0.48512213407434857, 'min_child_weight': 0.06752363459717566, 'n_jobs': 4, 'learning_rate': 0.3242954551289716}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 20/3257 [00:00<00:16, 193.49it/s]  1%|‚ñè         | 41/3257 [00:00<00:16, 199.10it/s]  2%|‚ñè         | 63/3257 [00:00<00:15, 207.94it/s]  3%|‚ñé         | 86/3257 [00:00<00:14, 214.33it/s]  3%|‚ñé         | 108/3257 [00:00<00:15, 198.81it/s]  4%|‚ñç         | 130/3257 [00:00<00:15, 205.07it/s]  5%|‚ñç         | 152/3257 [00:00<00:14, 207.59it/s]  5%|‚ñå         | 173/3257 [00:00<00:15, 198.51it/s]  6%|‚ñå         | 197/3257 [00:00<00:14, 206.36it/s]  7%|‚ñã         | 221/3257 [00:01<00:14, 213.34it/s]  8%|‚ñä         | 245/3257 [00:01<00:13, 218.70it/s]  8%|‚ñä         | 267/3257 [00:01<00:14, 212.77it/s]  9%|‚ñâ         | 296/3257 [00:01<00:12, 231.67it/s] 10%|‚ñâ         | 320/3257 [00:01<00:13, 222.28it/s] 11%|‚ñà         | 343/3257 [00:01<00:13, 214.77it/s] 11%|‚ñà‚ñè        | 367/3257 [00:01<00:13, 219.02it/s] 12%|‚ñà‚ñè        | 389/3257 [00:01<00:13, 206.05it/s] 13%|‚ñà‚ñé        | 411/3257 [00:01<00:13, 209.63it/s] 13%|‚ñà‚ñé        | 433/3257 [00:02<00:14, 190.35it/s] 14%|‚ñà‚ñç        | 454/3257 [00:02<00:14, 194.72it/s] 15%|‚ñà‚ñç        | 475/3257 [00:02<00:14, 197.07it/s] 15%|‚ñà‚ñå        | 497/3257 [00:02<00:13, 203.22it/s] 16%|‚ñà‚ñå        | 518/3257 [00:02<00:13, 202.06it/s] 17%|‚ñà‚ñã        | 539/3257 [00:02<00:13, 203.51it/s] 17%|‚ñà‚ñã        | 560/3257 [00:02<00:13, 193.50it/s] 18%|‚ñà‚ñä        | 580/3257 [00:02<00:14, 187.95it/s] 18%|‚ñà‚ñä        | 602/3257 [00:02<00:13, 195.18it/s] 19%|‚ñà‚ñâ        | 622/3257 [00:03<00:13, 191.18it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:13, 195.76it/s] 20%|‚ñà‚ñà        | 665/3257 [00:03<00:20, 128.96it/s] 21%|‚ñà‚ñà        | 685/3257 [00:03<00:18, 142.52it/s] 22%|‚ñà‚ñà‚ñè       | 709/3257 [00:03<00:15, 163.91it/s] 22%|‚ñà‚ñà‚ñè       | 728/3257 [00:03<00:15, 166.10it/s] 23%|‚ñà‚ñà‚ñé       | 747/3257 [00:03<00:14, 172.16it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:03<00:13, 185.28it/s] 24%|‚ñà‚ñà‚ñç       | 791/3257 [00:04<00:12, 190.63it/s] 25%|‚ñà‚ñà‚ñç       | 812/3257 [00:04<00:12, 194.18it/s] 26%|‚ñà‚ñà‚ñå       | 832/3257 [00:04<00:12, 192.08it/s] 26%|‚ñà‚ñà‚ñå       | 852/3257 [00:04<00:12, 186.82it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:04<00:12, 194.55it/s] 27%|‚ñà‚ñà‚ñã       | 895/3257 [00:04<00:12, 195.91it/s] 28%|‚ñà‚ñà‚ñä       | 917/3257 [00:04<00:11, 202.07it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:04<00:11, 204.27it/s] 30%|‚ñà‚ñà‚ñâ       | 961/3257 [00:04<00:11, 206.07it/s] 30%|‚ñà‚ñà‚ñà       | 982/3257 [00:05<00:11, 201.60it/s] 31%|‚ñà‚ñà‚ñà       | 1003/3257 [00:05<00:11, 199.43it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:05<00:11, 199.11it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1045/3257 [00:05<00:11, 185.24it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:05<00:11, 190.93it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1087/3257 [00:05<00:11, 192.23it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1108/3257 [00:05<00:10, 195.41it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1128/3257 [00:05<00:11, 190.57it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1148/3257 [00:05<00:11, 185.51it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:06<00:10, 196.75it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:06<00:11, 179.93it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:06<00:11, 178.64it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1234/3257 [00:06<00:10, 194.88it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1254/3257 [00:06<00:10, 195.35it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:06<00:10, 190.58it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1295/3257 [00:06<00:10, 184.98it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1318/3257 [00:06<00:09, 196.21it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1340/3257 [00:06<00:09, 202.21it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1361/3257 [00:07<00:09, 196.44it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1381/3257 [00:07<00:09, 191.75it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1403/3257 [00:07<00:09, 198.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1427/3257 [00:07<00:08, 207.98it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1450/3257 [00:07<00:08, 214.08it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1473/3257 [00:07<00:08, 216.48it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1498/3257 [00:07<00:07, 223.25it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1521/3257 [00:07<00:08, 209.96it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1543/3257 [00:07<00:08, 206.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1564/3257 [00:07<00:08, 201.38it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1585/3257 [00:08<00:08, 197.59it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1606/3257 [00:08<00:08, 200.90it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1630/3257 [00:08<00:07, 210.20it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1652/3257 [00:08<00:08, 195.49it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1672/3257 [00:08<00:08, 193.66it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:08<00:08, 193.95it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:08<00:07, 198.28it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1735/3257 [00:08<00:08, 181.22it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1758/3257 [00:08<00:07, 192.92it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:09<00:07, 197.32it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1800/3257 [00:09<00:07, 200.74it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:09<00:07, 199.92it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1842/3257 [00:09<00:07, 198.69it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1863/3257 [00:09<00:06, 201.84it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1884/3257 [00:09<00:11, 121.62it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1905/3257 [00:09<00:09, 139.09it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1923/3257 [00:10<00:09, 147.48it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1951/3257 [00:10<00:07, 177.98it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:10<00:06, 189.89it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1996/3257 [00:10<00:06, 195.35it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2018/3257 [00:10<00:06, 194.16it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2039/3257 [00:10<00:06, 195.78it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2060/3257 [00:10<00:06, 179.05it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:10<00:06, 190.49it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2103/3257 [00:10<00:06, 188.52it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2123/3257 [00:11<00:06, 181.28it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:11<00:06, 178.97it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:11<00:05, 191.81it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2186/3257 [00:11<00:05, 189.69it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2208/3257 [00:11<00:05, 197.75it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2228/3257 [00:11<00:05, 195.93it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2248/3257 [00:11<00:05, 192.71it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2269/3257 [00:11<00:05, 196.27it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2290/3257 [00:11<00:04, 199.24it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2310/3257 [00:11<00:04, 198.01it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2336/3257 [00:12<00:04, 215.59it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2361/3257 [00:12<00:04, 223.59it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2384/3257 [00:12<00:03, 225.33it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2407/3257 [00:12<00:03, 215.66it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2429/3257 [00:12<00:03, 212.70it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2451/3257 [00:12<00:04, 199.44it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:12<00:03, 211.76it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2501/3257 [00:12<00:03, 221.57it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:12<00:03, 222.76it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2547/3257 [00:13<00:03, 220.84it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2570/3257 [00:13<00:03, 201.33it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2591/3257 [00:13<00:03, 196.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2619/3257 [00:13<00:02, 217.50it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2642/3257 [00:13<00:02, 215.77it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2664/3257 [00:13<00:02, 208.28it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:13<00:02, 214.14it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:13<00:02, 191.13it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:13<00:02, 196.79it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:14<00:02, 205.27it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2777/3257 [00:14<00:02, 197.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:14<00:02, 211.69it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2825/3257 [00:14<00:02, 197.53it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2846/3257 [00:14<00:02, 199.40it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2874/3257 [00:14<00:01, 219.79it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2897/3257 [00:14<00:01, 207.73it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:14<00:01, 211.51it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2942/3257 [00:14<00:01, 211.60it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2964/3257 [00:15<00:01, 199.74it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:15<00:01, 189.12it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3010/3257 [00:15<00:01, 205.10it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3031/3257 [00:15<00:01, 201.72it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3055/3257 [00:15<00:00, 210.62it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3079/3257 [00:15<00:00, 218.74it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3102/3257 [00:15<00:00, 219.01it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3126/3257 [00:15<00:00, 224.90it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3149/3257 [00:15<00:00, 206.39it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3171/3257 [00:16<00:00, 206.89it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3192/3257 [00:16<00:00, 206.76it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:16<00:00, 197.81it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:16<00:00, 213.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 193.74it/s]
2023-02-07 19:21:23.802 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:21:23,804][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d306,n5,mc7,s0.455265,t4>', 'datetime': '2023-02-07T19:21:23.804078', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:21:23,804][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:21:23,805][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:21:24,236][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 19:21:24,236][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:21:24,267][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 9824 unique words (45.27% of original 21699, drops 11875)', 'datetime': '2023-02-07T19:21:24.267609', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:21:24,268][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 4333599 word corpus (99.23% of original 4367244, drops 33645)', 'datetime': '2023-02-07T19:21:24.268092', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:21:24,304][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 19:21:24,305][gensim.models.word2vec][INFO] - sample=0.455265 downsamples 0 most-common words
[2023-02-07 19:21:24,305][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4333599 word corpus (100.0%% of prior 4333599)', 'datetime': '2023-02-07T19:21:24.305221', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:21:24,366][gensim.models.word2vec][INFO] - estimated required memory for 9824 words and 306 dimensions: 33599120 bytes
[2023-02-07 19:21:24,367][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:21:24,385][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 9824 vocabulary and 306 features, using sg=1 hs=0 sample=0.4552651070051755 negative=5 window=6 shrink_windows=True', 'datetime': '2023-02-07T19:21:24.385248', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:21:25,388][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 47.68% examples, 2112294 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:26,389][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 99.57% examples, 2156330 words/s, in_qsize 3, out_qsize 1
[2023-02-07 19:21:26,391][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4335166 effective words) took 2.0s, 2163115 effective words/s
[2023-02-07 19:21:27,396][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 53.05% examples, 2351345 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:28,258][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4335166 effective words) took 1.9s, 2324593 effective words/s
[2023-02-07 19:21:29,261][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 51.64% examples, 2286434 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:30,135][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4335166 effective words) took 1.9s, 2311582 effective words/s
[2023-02-07 19:21:31,138][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 52.44% examples, 2327323 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:31,985][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4335166 effective words) took 1.8s, 2344909 effective words/s
[2023-02-07 19:21:32,995][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 54.77% examples, 2411135 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:33,795][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4335166 effective words) took 1.8s, 2397010 effective words/s
[2023-02-07 19:21:34,803][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 54.10% examples, 2390304 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:35,615][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4335166 effective words) took 1.8s, 2384878 effective words/s
[2023-02-07 19:21:36,617][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.02% examples, 2347403 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:37,454][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4335166 effective words) took 1.8s, 2358642 effective words/s
[2023-02-07 19:21:38,461][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 53.05% examples, 2349867 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:39,284][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4335166 effective words) took 1.8s, 2373128 effective words/s
[2023-02-07 19:21:40,288][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 54.31% examples, 2410521 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:41,130][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4335166 effective words) took 1.8s, 2350615 effective words/s
[2023-02-07 19:21:42,135][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 53.05% examples, 2351920 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:42,970][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4335166 effective words) took 1.8s, 2359097 effective words/s
[2023-02-07 19:21:43,973][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 53.67% examples, 2385030 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:44,790][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4335166 effective words) took 1.8s, 2384763 effective words/s
[2023-02-07 19:21:45,793][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 53.21% examples, 2364495 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:46,635][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4335166 effective words) took 1.8s, 2351493 effective words/s
[2023-02-07 19:21:47,641][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 53.24% examples, 2358407 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:48,466][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4335166 effective words) took 1.8s, 2369104 effective words/s
[2023-02-07 19:21:49,472][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 53.05% examples, 2349326 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:50,302][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4335166 effective words) took 1.8s, 2362655 effective words/s
[2023-02-07 19:21:51,308][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 53.05% examples, 2349704 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:52,152][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4335166 effective words) took 1.8s, 2345631 effective words/s
[2023-02-07 19:21:52,153][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65027490 effective words) took 27.8s, 2341853 effective words/s', 'datetime': '2023-02-07T19:21:52.153256', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:21:52.153 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:21:55,002][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192058-o4gka47c/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:21:55.002222', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:21:55,003][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:21:55,056][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192058-o4gka47c/files/../tmp/embedding_model.pt
2023-02-07 19:21:55.056 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:21:57.170 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:21:57.922 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:22:07.813 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9387100388031907, 'test_mae': 0.7205497933768787, 'test_r2': -1.9581738074314794}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.94
wandb: percentage 0.54726
wandb:   test_mae 0.72055
wandb:   test_mse 0.93871
wandb:    test_r2 -1.95817
wandb: 
wandb: üöÄ View run lunar-sweep-40 at: https://wandb.ai/xiaoqiz/mof2vec/runs/o4gka47c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_192058-o4gka47c/logs
wandb: Agent Starting Run: 22yx3apb with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 600
wandb: 	model.gensim.alpha: 0.0004591424558207449
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.41482849326478094
wandb: 	model.gensim.vector_size: 166
wandb: 	model.gensim.window: 3
wandb: 	model.sklearn.learning_rate: 0.023265075028407665
wandb: 	model.sklearn.max_depth: 85
wandb: 	model.sklearn.min_child_weight: 0.0409717249194211
wandb: 	model.sklearn.n_estimators: 1353
wandb: 	model.sklearn.num_leaves: 492
wandb: 	model.sklearn.reg_alpha: 0.002608851523609972
wandb: 	model.sklearn.reg_lambda: 0.155956250307251
wandb: 	model.sklearn.subsample: 0.33112145982646624
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192217-22yx3apb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-41
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/22yx3apb
2023-02-07 19:22:26.547 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:22:26.548 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 600 for sweep.
2023-02-07 19:22:26.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0004591424558207449 for sweep.
2023-02-07 19:22:26.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:22:26.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 19:22:26.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.41482849326478094 for sweep.
2023-02-07 19:22:26.550 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 166 for sweep.
2023-02-07 19:22:26.550 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 3 for sweep.
2023-02-07 19:22:26.550 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.023265075028407665 for sweep.
2023-02-07 19:22:26.550 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 85 for sweep.
2023-02-07 19:22:26.551 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0409717249194211 for sweep.
2023-02-07 19:22:26.551 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1353 for sweep.
2023-02-07 19:22:26.551 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 492 for sweep.
2023-02-07 19:22:26.552 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.002608851523609972 for sweep.
2023-02-07 19:22:26.552 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.155956250307251 for sweep.
2023-02-07 19:22:26.552 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.33112145982646624 for sweep.
2023-02-07 19:22:26.552 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:22:26.562 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192217-22yx3apb/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 600, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 166, 'window': 3, 'min_count': 6, 'dm': 0, 'sample': 0.41482849326478094, 'workers': 4, 'alpha': 0.0004591424558207449, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1353, 'max_depth': 85, 'num_leaves': 492, 'reg_alpha': 0.002608851523609972, 'reg_lambda': 0.155956250307251, 'subsample': 0.33112145982646624, 'min_child_weight': 0.0409717249194211, 'n_jobs': 4, 'learning_rate': 0.023265075028407665}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:21, 153.48it/s]  1%|          | 33/3257 [00:00<00:19, 162.60it/s]  2%|‚ñè         | 50/3257 [00:00<00:19, 160.83it/s]  2%|‚ñè         | 67/3257 [00:00<00:20, 157.17it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 174.77it/s]  3%|‚ñé         | 108/3257 [00:00<00:19, 165.66it/s]  4%|‚ñç         | 125/3257 [00:00<00:18, 165.00it/s]  4%|‚ñç         | 146/3257 [00:00<00:17, 177.60it/s]  5%|‚ñå         | 164/3257 [00:00<00:18, 164.73it/s]  6%|‚ñå         | 181/3257 [00:01<00:18, 165.19it/s]  6%|‚ñå         | 201/3257 [00:01<00:18, 167.96it/s]  7%|‚ñã         | 224/3257 [00:01<00:16, 184.32it/s]  7%|‚ñã         | 244/3257 [00:01<00:16, 188.11it/s]  8%|‚ñä         | 263/3257 [00:01<00:16, 178.53it/s]  9%|‚ñâ         | 286/3257 [00:01<00:15, 191.11it/s]  9%|‚ñâ         | 306/3257 [00:01<00:15, 184.94it/s] 10%|‚ñà         | 328/3257 [00:01<00:15, 187.32it/s] 11%|‚ñà         | 347/3257 [00:01<00:16, 179.18it/s] 11%|‚ñà         | 366/3257 [00:02<00:16, 179.23it/s] 12%|‚ñà‚ñè        | 384/3257 [00:02<00:17, 168.76it/s] 12%|‚ñà‚ñè        | 401/3257 [00:02<00:17, 167.28it/s] 13%|‚ñà‚ñé        | 420/3257 [00:02<00:16, 167.40it/s] 13%|‚ñà‚ñé        | 437/3257 [00:02<00:19, 146.90it/s] 14%|‚ñà‚ñç        | 456/3257 [00:02<00:17, 157.95it/s] 15%|‚ñà‚ñç        | 474/3257 [00:02<00:17, 161.17it/s] 15%|‚ñà‚ñå        | 491/3257 [00:02<00:16, 163.24it/s] 16%|‚ñà‚ñå        | 511/3257 [00:02<00:15, 172.41it/s] 16%|‚ñà‚ñå        | 529/3257 [00:03<00:16, 165.63it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:16, 165.66it/s] 17%|‚ñà‚ñã        | 563/3257 [00:03<00:17, 156.28it/s] 18%|‚ñà‚ñä        | 579/3257 [00:03<00:17, 156.29it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:15, 166.78it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:16, 164.63it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:03<00:15, 173.35it/s] 20%|‚ñà‚ñà        | 658/3257 [00:03<00:16, 161.41it/s] 21%|‚ñà‚ñà        | 678/3257 [00:04<00:15, 170.34it/s] 21%|‚ñà‚ñà‚ñè       | 696/3257 [00:04<00:15, 162.70it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:04<00:14, 172.94it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:04<00:15, 164.00it/s] 23%|‚ñà‚ñà‚ñé       | 752/3257 [00:04<00:15, 158.78it/s] 24%|‚ñà‚ñà‚ñé       | 771/3257 [00:04<00:14, 166.59it/s] 24%|‚ñà‚ñà‚ñç       | 788/3257 [00:04<00:15, 162.52it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:15, 162.41it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:04<00:15, 160.71it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:05<00:15, 159.98it/s] 26%|‚ñà‚ñà‚ñã       | 857/3257 [00:05<00:15, 158.72it/s] 27%|‚ñà‚ñà‚ñã       | 874/3257 [00:05<00:14, 161.32it/s] 27%|‚ñà‚ñà‚ñã       | 891/3257 [00:05<00:14, 158.84it/s] 28%|‚ñà‚ñà‚ñä       | 912/3257 [00:05<00:13, 171.16it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:05<00:13, 169.70it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:05<00:13, 171.51it/s] 30%|‚ñà‚ñà‚ñâ       | 968/3257 [00:05<00:13, 174.95it/s] 30%|‚ñà‚ñà‚ñà       | 986/3257 [00:05<00:13, 167.76it/s] 31%|‚ñà‚ñà‚ñà       | 1004/3257 [00:05<00:13, 168.90it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1022/3257 [00:06<00:13, 170.52it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1040/3257 [00:06<00:13, 160.21it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1057/3257 [00:06<00:13, 157.18it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1079/3257 [00:06<00:12, 174.38it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:06<00:13, 162.65it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1116/3257 [00:06<00:12, 169.01it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1134/3257 [00:06<00:13, 160.41it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1151/3257 [00:06<00:13, 156.59it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:07<00:12, 164.89it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:07<00:13, 149.92it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:07<00:13, 151.33it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1221/3257 [00:07<00:13, 155.60it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1237/3257 [00:07<00:20, 99.15it/s]  38%|‚ñà‚ñà‚ñà‚ñä      | 1250/3257 [00:07<00:19, 104.85it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1270/3257 [00:07<00:15, 124.90it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1285/3257 [00:08<00:16, 121.90it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1302/3257 [00:08<00:14, 131.14it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:08<00:13, 144.72it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1341/3257 [00:08<00:12, 157.33it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1358/3257 [00:08<00:12, 152.73it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1374/3257 [00:08<00:12, 154.25it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1390/3257 [00:08<00:12, 153.03it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:08<00:10, 169.55it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1431/3257 [00:08<00:10, 175.08it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1449/3257 [00:08<00:10, 175.43it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1470/3257 [00:09<00:09, 183.43it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1489/3257 [00:09<00:09, 179.66it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1510/3257 [00:09<00:09, 185.32it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1529/3257 [00:09<00:10, 167.99it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1547/3257 [00:09<00:10, 159.58it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1565/3257 [00:09<00:10, 162.96it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1582/3257 [00:09<00:10, 160.66it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1603/3257 [00:09<00:09, 172.43it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1621/3257 [00:09<00:09, 172.13it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:10<00:09, 170.29it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:10<00:09, 161.94it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:10<00:10, 158.12it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:10<00:09, 156.94it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:10<00:09, 162.78it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:10<00:09, 159.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:10<00:09, 156.61it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1765/3257 [00:10<00:08, 166.84it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1785/3257 [00:10<00:08, 175.70it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:11<00:08, 175.26it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:11<00:08, 173.08it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1839/3257 [00:11<00:08, 167.88it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1856/3257 [00:11<00:08, 168.32it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1876/3257 [00:11<00:07, 176.62it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1894/3257 [00:11<00:08, 170.07it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:11<00:07, 176.47it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1935/3257 [00:11<00:07, 179.36it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1959/3257 [00:11<00:06, 195.78it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1979/3257 [00:12<00:06, 183.43it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1998/3257 [00:12<00:06, 184.16it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2017/3257 [00:12<00:06, 180.26it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2036/3257 [00:12<00:06, 182.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:12<00:07, 168.02it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2073/3257 [00:12<00:06, 170.01it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2092/3257 [00:12<00:06, 174.36it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2110/3257 [00:12<00:06, 171.84it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2128/3257 [00:12<00:06, 167.08it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2145/3257 [00:13<00:06, 161.52it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2165/3257 [00:13<00:06, 172.05it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2183/3257 [00:13<00:06, 167.04it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:13<00:05, 176.56it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2222/3257 [00:13<00:05, 172.54it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2240/3257 [00:13<00:06, 165.21it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:13<00:05, 169.97it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2278/3257 [00:13<00:05, 165.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:13<00:05, 174.85it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2321/3257 [00:14<00:05, 185.17it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2341/3257 [00:14<00:04, 188.70it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2363/3257 [00:14<00:04, 196.05it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2383/3257 [00:14<00:04, 191.97it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:14<00:04, 196.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2424/3257 [00:14<00:04, 182.80it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:14<00:04, 168.76it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2463/3257 [00:14<00:04, 176.91it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2482/3257 [00:14<00:04, 178.79it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2506/3257 [00:15<00:03, 194.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2526/3257 [00:15<00:03, 191.66it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2546/3257 [00:15<00:03, 193.77it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2566/3257 [00:15<00:03, 179.04it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2585/3257 [00:15<00:03, 171.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2607/3257 [00:15<00:03, 184.00it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2631/3257 [00:15<00:03, 195.96it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2651/3257 [00:15<00:03, 185.99it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2670/3257 [00:15<00:03, 184.62it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:16<00:03, 188.65it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2710/3257 [00:16<00:03, 164.74it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2728/3257 [00:16<00:05, 91.48it/s]  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2748/3257 [00:16<00:04, 109.47it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2765/3257 [00:16<00:04, 121.04it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2783/3257 [00:16<00:03, 133.27it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2804/3257 [00:16<00:02, 151.22it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2822/3257 [00:17<00:02, 152.72it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2840/3257 [00:17<00:02, 153.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2864/3257 [00:17<00:02, 175.16it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:17<00:02, 182.45it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:17<00:02, 175.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:17<00:01, 182.59it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:17<00:01, 177.50it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2967/3257 [00:17<00:01, 180.81it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2986/3257 [00:18<00:01, 170.90it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3010/3257 [00:18<00:01, 188.92it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3030/3257 [00:18<00:01, 182.76it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3052/3257 [00:18<00:01, 191.38it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:18<00:00, 201.30it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3096/3257 [00:18<00:00, 195.36it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3120/3257 [00:18<00:00, 207.39it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3141/3257 [00:18<00:00, 194.65it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3161/3257 [00:18<00:00, 189.79it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3181/3257 [00:19<00:00, 179.11it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:19<00:00, 186.59it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3222/3257 [00:19<00:00, 179.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:19<00:00, 186.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 167.69it/s]
2023-02-07 19:22:46.791 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:22:46,792][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d166,n5,mc6,s0.414828,t4>', 'datetime': '2023-02-07T19:22:46.792366', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:22:46,792][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:22:46,792][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:22:47,311][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:22:47,311][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:22:47,359][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 15588 unique words (49.01% of original 31803, drops 16215)', 'datetime': '2023-02-07T19:22:47.359855', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:22:47,360][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 5053508 word corpus (99.18% of original 5095118, drops 41610)', 'datetime': '2023-02-07T19:22:47.360297', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:22:47,418][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:22:47,420][gensim.models.word2vec][INFO] - sample=0.414828 downsamples 0 most-common words
[2023-02-07 19:22:47,420][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5053508 word corpus (100.0%% of prior 5053508)', 'datetime': '2023-02-07T19:22:47.420840', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:22:47,522][gensim.models.word2vec][INFO] - estimated required memory for 15588 words and 166 dimensions: 31308912 bytes
[2023-02-07 19:22:47,522][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:22:47,536][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 15588 vocabulary and 166 features, using sg=1 hs=0 sample=0.41482849326478094 negative=5 window=3 shrink_windows=True', 'datetime': '2023-02-07T19:22:47.536871', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:22:48,542][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 47.56% examples, 2439545 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:49,543][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 96.28% examples, 2427376 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:49,618][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5045550 effective words) took 2.1s, 2427912 effective words/s
[2023-02-07 19:22:50,622][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 46.27% examples, 2367401 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:51,627][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 93.74% examples, 2367141 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:51,742][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5045550 effective words) took 2.1s, 2377830 effective words/s
[2023-02-07 19:22:52,747][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 47.22% examples, 2422701 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:53,753][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 96.59% examples, 2428085 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:53,815][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5045550 effective words) took 2.1s, 2435266 effective words/s
[2023-02-07 19:22:54,817][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 46.64% examples, 2396677 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:55,817][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 94.90% examples, 2400511 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:55,916][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5045550 effective words) took 2.1s, 2403258 effective words/s
[2023-02-07 19:22:56,923][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 34.94% examples, 1783609 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:57,930][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 69.88% examples, 1798006 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:58,716][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5045550 effective words) took 2.8s, 1804374 effective words/s
[2023-02-07 19:22:59,730][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 44.73% examples, 2300585 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:00,736][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 92.85% examples, 2347205 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:00,864][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5045550 effective words) took 2.1s, 2362354 effective words/s
[2023-02-07 19:23:01,866][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 46.79% examples, 2404455 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:02,869][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 95.89% examples, 2415464 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:02,949][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5045550 effective words) took 2.1s, 2421392 effective words/s
[2023-02-07 19:23:03,952][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 46.95% examples, 2413079 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:04,955][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 95.67% examples, 2410410 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:05,045][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5045550 effective words) took 2.1s, 2409840 effective words/s
[2023-02-07 19:23:06,055][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 34.76% examples, 1773570 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:07,062][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 68.84% examples, 1766680 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:07,918][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5045550 effective words) took 2.9s, 1760436 effective words/s
[2023-02-07 19:23:08,924][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 45.96% examples, 2349243 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:09,925][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 93.52% examples, 2364232 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:10,050][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5045550 effective words) took 2.1s, 2368059 effective words/s
[2023-02-07 19:23:11,061][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 33.47% examples, 1695414 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:23:12,061][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 66.29% examples, 1699292 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:13,043][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5045550 effective words) took 3.0s, 1686901 effective words/s
[2023-02-07 19:23:14,045][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 46.45% examples, 2381800 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:15,049][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 93.80% examples, 2368531 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:15,168][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5045550 effective words) took 2.1s, 2376257 effective words/s
[2023-02-07 19:23:16,170][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 45.04% examples, 2322485 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:17,171][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 91.50% examples, 2324379 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:17,338][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5045550 effective words) took 2.2s, 2327204 effective words/s
[2023-02-07 19:23:18,340][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 46.95% examples, 2413413 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:19,340][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 96.28% examples, 2429988 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:19,412][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5045550 effective words) took 2.1s, 2434339 effective words/s
[2023-02-07 19:23:20,414][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 45.96% examples, 2358386 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:21,416][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 94.60% examples, 2389431 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:21,516][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5045550 effective words) took 2.1s, 2399733 effective words/s
[2023-02-07 19:23:21,516][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75683250 effective words) took 34.0s, 2227329 effective words/s', 'datetime': '2023-02-07T19:23:21.516705', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:23:21.517 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:23:24,337][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192217-22yx3apb/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:23:24.337116', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:23:24,338][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:23:24,387][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192217-22yx3apb/files/../tmp/embedding_model.pt
2023-02-07 19:23:24.387 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:23:25.983 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:23:26.567 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:23:29.819 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1505302287174073, 'test_mae': 0.8212843029502711, 'test_r2': -3.275375048227266}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.18
wandb: percentage 0.50986
wandb:   test_mae 0.82128
wandb:   test_mse 1.15053
wandb:    test_r2 -3.27538
wandb: 
wandb: üöÄ View run earnest-sweep-41 at: https://wandb.ai/xiaoqiz/mof2vec/runs/22yx3apb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_192217-22yx3apb/logs
wandb: Agent Starting Run: bs2qhvvi with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 758
wandb: 	model.gensim.alpha: 0.09950539931181791
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.43676118742731174
wandb: 	model.gensim.vector_size: 210
wandb: 	model.gensim.window: 9
wandb: 	model.sklearn.learning_rate: 0.01893873102631571
wandb: 	model.sklearn.max_depth: 45
wandb: 	model.sklearn.min_child_weight: 0.033907076267546424
wandb: 	model.sklearn.n_estimators: 3380
wandb: 	model.sklearn.num_leaves: 383
wandb: 	model.sklearn.reg_alpha: 0.003220858086375242
wandb: 	model.sklearn.reg_lambda: 0.2783340775079443
wandb: 	model.sklearn.subsample: 0.6533782787764282
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192341-bs2qhvvi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-42
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/bs2qhvvi
2023-02-07 19:23:50.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:23:50.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 758 for sweep.
2023-02-07 19:23:50.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.09950539931181791 for sweep.
2023-02-07 19:23:50.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:23:50.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 19:23:50.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.43676118742731174 for sweep.
2023-02-07 19:23:50.021 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 210 for sweep.
2023-02-07 19:23:50.021 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 9 for sweep.
2023-02-07 19:23:50.021 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.01893873102631571 for sweep.
2023-02-07 19:23:50.022 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 45 for sweep.
2023-02-07 19:23:50.022 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.033907076267546424 for sweep.
2023-02-07 19:23:50.022 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3380 for sweep.
2023-02-07 19:23:50.022 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 383 for sweep.
2023-02-07 19:23:50.023 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.003220858086375242 for sweep.
2023-02-07 19:23:50.023 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.2783340775079443 for sweep.
2023-02-07 19:23:50.023 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6533782787764282 for sweep.
2023-02-07 19:23:50.023 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:23:50.030 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192341-bs2qhvvi/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 758, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 210, 'window': 9, 'min_count': 7, 'dm': 0, 'sample': 0.43676118742731174, 'workers': 4, 'alpha': 0.09950539931181791, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3380, 'max_depth': 45, 'num_leaves': 383, 'reg_alpha': 0.003220858086375242, 'reg_lambda': 0.2783340775079443, 'subsample': 0.6533782787764282, 'min_child_weight': 0.033907076267546424, 'n_jobs': 4, 'learning_rate': 0.01893873102631571}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 138.97it/s]  1%|          | 32/3257 [00:00<00:19, 162.26it/s]  2%|‚ñè         | 49/3257 [00:00<00:19, 164.63it/s]  2%|‚ñè         | 66/3257 [00:00<00:19, 164.50it/s]  3%|‚ñé         | 83/3257 [00:00<00:19, 164.18it/s]  3%|‚ñé         | 100/3257 [00:00<00:19, 161.62it/s]  4%|‚ñé         | 117/3257 [00:00<00:20, 155.89it/s]  4%|‚ñç         | 135/3257 [00:00<00:19, 161.32it/s]  5%|‚ñç         | 154/3257 [00:00<00:18, 168.35it/s]  5%|‚ñå         | 171/3257 [00:01<00:18, 164.22it/s]  6%|‚ñå         | 190/3257 [00:01<00:18, 169.28it/s]  6%|‚ñã         | 207/3257 [00:01<00:18, 168.05it/s]  7%|‚ñã         | 230/3257 [00:01<00:16, 183.06it/s]  8%|‚ñä         | 249/3257 [00:01<00:16, 183.82it/s]  8%|‚ñä         | 268/3257 [00:01<00:17, 173.27it/s]  9%|‚ñâ         | 291/3257 [00:01<00:15, 188.90it/s] 10%|‚ñâ         | 311/3257 [00:01<00:15, 186.86it/s] 10%|‚ñà         | 331/3257 [00:01<00:15, 188.29it/s] 11%|‚ñà         | 350/3257 [00:02<00:16, 179.56it/s] 11%|‚ñà‚ñè        | 369/3257 [00:02<00:15, 180.96it/s] 12%|‚ñà‚ñè        | 388/3257 [00:02<00:17, 162.55it/s] 13%|‚ñà‚ñé        | 408/3257 [00:02<00:16, 170.80it/s] 13%|‚ñà‚ñé        | 426/3257 [00:02<00:18, 153.80it/s] 14%|‚ñà‚ñé        | 442/3257 [00:02<00:18, 154.98it/s] 14%|‚ñà‚ñç        | 461/3257 [00:02<00:17, 162.66it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:16, 164.55it/s] 15%|‚ñà‚ñå        | 499/3257 [00:02<00:15, 173.81it/s] 16%|‚ñà‚ñå        | 517/3257 [00:03<00:15, 175.32it/s] 16%|‚ñà‚ñã        | 535/3257 [00:03<00:15, 172.62it/s] 17%|‚ñà‚ñã        | 553/3257 [00:03<00:15, 173.44it/s] 18%|‚ñà‚ñä        | 571/3257 [00:03<00:17, 153.25it/s] 18%|‚ñà‚ñä        | 590/3257 [00:03<00:16, 162.90it/s] 19%|‚ñà‚ñä        | 609/3257 [00:03<00:15, 169.90it/s] 19%|‚ñà‚ñâ        | 627/3257 [00:03<00:15, 164.98it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:15, 164.14it/s] 20%|‚ñà‚ñà        | 662/3257 [00:04<00:25, 100.69it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:22, 115.78it/s] 21%|‚ñà‚ñà‚ñè       | 700/3257 [00:04<00:20, 126.14it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:04<00:18, 139.19it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:04<00:18, 137.14it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:04<00:17, 145.63it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:04<00:16, 153.04it/s] 24%|‚ñà‚ñà‚ñç       | 790/3257 [00:04<00:15, 156.96it/s] 25%|‚ñà‚ñà‚ñç       | 807/3257 [00:05<00:15, 157.35it/s] 25%|‚ñà‚ñà‚ñå       | 824/3257 [00:05<00:15, 155.60it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:05<00:15, 154.69it/s] 26%|‚ñà‚ñà‚ñã       | 856/3257 [00:05<00:15, 153.23it/s] 27%|‚ñà‚ñà‚ñã       | 873/3257 [00:05<00:15, 157.63it/s] 27%|‚ñà‚ñà‚ñã       | 890/3257 [00:05<00:14, 159.72it/s] 28%|‚ñà‚ñà‚ñä       | 908/3257 [00:05<00:14, 163.73it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:05<00:13, 171.28it/s] 29%|‚ñà‚ñà‚ñâ       | 946/3257 [00:05<00:13, 170.18it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:05<00:12, 178.25it/s] 30%|‚ñà‚ñà‚ñà       | 984/3257 [00:06<00:13, 170.02it/s] 31%|‚ñà‚ñà‚ñà       | 1002/3257 [00:06<00:13, 165.62it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1020/3257 [00:06<00:13, 168.57it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1037/3257 [00:06<00:13, 160.97it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1054/3257 [00:06<00:14, 157.19it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1072/3257 [00:06<00:13, 161.64it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1089/3257 [00:06<00:13, 161.15it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1106/3257 [00:06<00:13, 159.53it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1122/3257 [00:06<00:13, 157.05it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1138/3257 [00:07<00:13, 156.98it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1154/3257 [00:07<00:13, 152.02it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:07<00:13, 155.45it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:07<00:13, 149.52it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1203/3257 [00:07<00:14, 142.52it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:07<00:14, 144.14it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1240/3257 [00:07<00:12, 164.51it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:07<00:12, 156.94it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:07<00:12, 157.14it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:08<00:13, 149.26it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:08<00:12, 154.57it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1327/3257 [00:08<00:11, 163.17it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1345/3257 [00:08<00:11, 166.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1362/3257 [00:08<00:11, 164.15it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1379/3257 [00:08<00:11, 164.51it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1396/3257 [00:08<00:11, 163.97it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1417/3257 [00:08<00:10, 175.61it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1435/3257 [00:08<00:10, 172.78it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1457/3257 [00:09<00:09, 185.28it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1476/3257 [00:09<00:09, 180.78it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1495/3257 [00:09<00:09, 180.22it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1514/3257 [00:09<00:09, 180.74it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1533/3257 [00:09<00:10, 166.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:09<00:10, 162.01it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1567/3257 [00:09<00:10, 158.30it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1583/3257 [00:09<00:10, 157.00it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1604/3257 [00:09<00:09, 169.42it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1622/3257 [00:10<00:09, 169.11it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:10<00:09, 167.01it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1656/3257 [00:10<00:09, 165.80it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1673/3257 [00:10<00:09, 159.86it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:10<00:09, 161.22it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1709/3257 [00:10<00:09, 168.20it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:10<00:09, 160.20it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:10<00:09, 157.61it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1765/3257 [00:10<00:08, 168.27it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1785/3257 [00:11<00:08, 177.14it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:11<00:08, 174.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:11<00:08, 172.75it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1839/3257 [00:11<00:08, 171.09it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1858/3257 [00:11<00:08, 171.82it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1880/3257 [00:11<00:07, 183.13it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:11<00:07, 179.91it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1918/3257 [00:12<00:13, 102.39it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1941/3257 [00:12<00:10, 125.54it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:12<00:08, 146.28it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1984/3257 [00:12<00:08, 150.62it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2005/3257 [00:12<00:07, 163.64it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2027/3257 [00:12<00:06, 177.48it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2047/3257 [00:12<00:07, 168.13it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2066/3257 [00:12<00:07, 164.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:12<00:07, 167.09it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2103/3257 [00:13<00:07, 164.46it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:13<00:06, 162.86it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:13<00:06, 163.77it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:13<00:06, 161.71it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2175/3257 [00:13<00:06, 175.00it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2193/3257 [00:13<00:06, 173.01it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2211/3257 [00:13<00:06, 167.30it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2232/3257 [00:13<00:05, 178.25it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2250/3257 [00:13<00:05, 171.99it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2268/3257 [00:14<00:05, 172.62it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2286/3257 [00:14<00:05, 173.72it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2304/3257 [00:14<00:05, 173.88it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2327/3257 [00:14<00:04, 189.70it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2349/3257 [00:14<00:04, 198.39it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2369/3257 [00:14<00:04, 196.34it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2389/3257 [00:14<00:04, 196.86it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2409/3257 [00:14<00:04, 181.08it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2428/3257 [00:14<00:04, 180.96it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2447/3257 [00:14<00:04, 174.65it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2467/3257 [00:15<00:04, 180.89it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2486/3257 [00:15<00:04, 180.47it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2509/3257 [00:15<00:03, 191.58it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2531/3257 [00:15<00:03, 199.38it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2552/3257 [00:15<00:03, 196.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:15<00:03, 176.53it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2591/3257 [00:15<00:03, 172.19it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2616/3257 [00:15<00:03, 192.47it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2637/3257 [00:15<00:03, 196.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2658/3257 [00:16<00:03, 178.91it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2677/3257 [00:16<00:03, 180.63it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2696/3257 [00:16<00:03, 175.60it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2714/3257 [00:16<00:03, 164.78it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2733/3257 [00:16<00:03, 171.20it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2754/3257 [00:16<00:02, 180.39it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2773/3257 [00:16<00:02, 171.34it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:16<00:02, 182.57it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2814/3257 [00:16<00:02, 178.56it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:17<00:02, 168.14it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2852/3257 [00:17<00:02, 172.21it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2878/3257 [00:17<00:01, 196.26it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2898/3257 [00:17<00:02, 177.71it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2917/3257 [00:17<00:01, 179.69it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2936/3257 [00:17<00:01, 177.01it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2954/3257 [00:17<00:01, 167.38it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2974/3257 [00:17<00:01, 174.20it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2992/3257 [00:18<00:01, 167.73it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3014/3257 [00:18<00:01, 180.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3033/3257 [00:18<00:01, 183.10it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3054/3257 [00:18<00:01, 189.97it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3076/3257 [00:18<00:00, 197.74it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3096/3257 [00:18<00:00, 188.70it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:18<00:00, 194.79it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3138/3257 [00:18<00:00, 184.14it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3157/3257 [00:18<00:00, 176.56it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3175/3257 [00:18<00:00, 176.36it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3193/3257 [00:19<00:00, 176.76it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3211/3257 [00:19<00:00, 170.71it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3230/3257 [00:19<00:00, 175.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:19<00:00, 180.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 167.41it/s]
2023-02-07 19:24:10.307 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:24:10,309][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d210,n5,mc7,s0.436761,t4>', 'datetime': '2023-02-07T19:24:10.309270', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:24:10,309][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:24:10,309][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:24:10,831][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:24:10,832][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:24:10,880][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 14137 unique words (44.45% of original 31803, drops 17666)', 'datetime': '2023-02-07T19:24:10.880460', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:24:10,881][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 5044802 word corpus (99.01% of original 5095118, drops 50316)', 'datetime': '2023-02-07T19:24:10.881067', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:24:10,933][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:24:10,934][gensim.models.word2vec][INFO] - sample=0.436761 downsamples 0 most-common words
[2023-02-07 19:24:10,934][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5044802 word corpus (100.0%% of prior 5044802)', 'datetime': '2023-02-07T19:24:10.934602', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:24:11,024][gensim.models.word2vec][INFO] - estimated required memory for 14137 words and 210 dimensions: 34205940 bytes
[2023-02-07 19:24:11,025][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:24:11,041][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14137 vocabulary and 210 features, using sg=1 hs=0 sample=0.43676118742731174 negative=5 window=9 shrink_windows=True', 'datetime': '2023-02-07T19:24:11.041747', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:24:12,047][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 49.46% examples, 2535078 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:13,037][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5036861 effective words) took 2.0s, 2528039 effective words/s
[2023-02-07 19:24:14,040][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 52.47% examples, 2700634 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:14,900][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5036861 effective words) took 1.9s, 2706231 effective words/s
[2023-02-07 19:24:15,903][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 41.45% examples, 2146886 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:16,911][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 83.24% examples, 2110993 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:17,276][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5036861 effective words) took 2.4s, 2120997 effective words/s
[2023-02-07 19:24:18,280][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 53.30% examples, 2750349 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:19,120][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5036861 effective words) took 1.8s, 2734016 effective words/s
[2023-02-07 19:24:20,134][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 40.28% examples, 2077637 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:21,136][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 83.14% examples, 2108322 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:21,450][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5036861 effective words) took 2.3s, 2169252 effective words/s
[2023-02-07 19:24:22,454][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 52.63% examples, 2707047 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:23,302][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5036861 effective words) took 1.8s, 2724173 effective words/s
[2023-02-07 19:24:24,309][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.30% examples, 2741412 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:25,132][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5036861 effective words) took 1.8s, 2754015 effective words/s
[2023-02-07 19:24:26,134][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 53.05% examples, 2737268 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:26,997][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5036861 effective words) took 1.9s, 2703200 effective words/s
[2023-02-07 19:24:28,002][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 53.85% examples, 2774420 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:28,816][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5036861 effective words) took 1.8s, 2771251 effective words/s
[2023-02-07 19:24:29,824][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 52.78% examples, 2703384 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:30,677][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5036861 effective words) took 1.9s, 2709375 effective words/s
[2023-02-07 19:24:31,678][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 53.30% examples, 2756874 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:32,504][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5036861 effective words) took 1.8s, 2758674 effective words/s
[2023-02-07 19:24:33,514][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 51.89% examples, 2653806 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:34,368][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5036861 effective words) took 1.9s, 2704851 effective words/s
[2023-02-07 19:24:35,369][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 52.78% examples, 2718423 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:36,207][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5036861 effective words) took 1.8s, 2740450 effective words/s
[2023-02-07 19:24:37,212][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 51.89% examples, 2666844 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:38,108][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5036861 effective words) took 1.9s, 2652412 effective words/s
[2023-02-07 19:24:39,111][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 51.21% examples, 2632184 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:39,992][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5036861 effective words) took 1.9s, 2675231 effective words/s
[2023-02-07 19:24:39,992][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75552915 effective words) took 28.9s, 2609899 effective words/s', 'datetime': '2023-02-07T19:24:39.992708', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:24:39.992 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:24:43,036][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192341-bs2qhvvi/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:24:43.036060', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:24:43,037][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:24:43,087][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192341-bs2qhvvi/files/../tmp/embedding_model.pt
2023-02-07 19:24:43.088 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:24:44.792 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:24:45.436 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:24:59.213 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9067102761203821, 'test_mae': 0.7342948826269869, 'test_r2': -2.3385712004302026}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.88
wandb: percentage 0.55548
wandb:   test_mae 0.73429
wandb:   test_mse 0.90671
wandb:    test_r2 -2.33857
wandb: 
wandb: üöÄ View run azure-sweep-42 at: https://wandb.ai/xiaoqiz/mof2vec/runs/bs2qhvvi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_192341-bs2qhvvi/logs
wandb: Agent Starting Run: u5pdo58e with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 912
wandb: 	model.gensim.alpha: 0.007514565986321241
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.6127657291531072
wandb: 	model.gensim.vector_size: 299
wandb: 	model.gensim.window: 13
wandb: 	model.sklearn.learning_rate: 0.19920942480240184
wandb: 	model.sklearn.max_depth: 47
wandb: 	model.sklearn.min_child_weight: 0.05268967126246312
wandb: 	model.sklearn.n_estimators: 3465
wandb: 	model.sklearn.num_leaves: 376
wandb: 	model.sklearn.reg_alpha: 0.0026052406428952223
wandb: 	model.sklearn.reg_lambda: 0.865768882944438
wandb: 	model.sklearn.subsample: 0.4791154057019025
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192512-u5pdo58e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-43
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/u5pdo58e
2023-02-07 19:25:20.917 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:25:20.918 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 912 for sweep.
2023-02-07 19:25:20.919 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.007514565986321241 for sweep.
2023-02-07 19:25:20.919 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:25:20.919 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 19:25:20.919 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6127657291531072 for sweep.
2023-02-07 19:25:20.920 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 299 for sweep.
2023-02-07 19:25:20.920 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 13 for sweep.
2023-02-07 19:25:20.920 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.19920942480240184 for sweep.
2023-02-07 19:25:20.920 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 47 for sweep.
2023-02-07 19:25:20.921 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05268967126246312 for sweep.
2023-02-07 19:25:20.921 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3465 for sweep.
2023-02-07 19:25:20.922 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 376 for sweep.
2023-02-07 19:25:20.922 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0026052406428952223 for sweep.
2023-02-07 19:25:20.922 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.865768882944438 for sweep.
2023-02-07 19:25:20.923 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.4791154057019025 for sweep.
2023-02-07 19:25:20.923 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:25:20.930 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192512-u5pdo58e/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 912, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 299, 'window': 13, 'min_count': 8, 'dm': 0, 'sample': 0.6127657291531072, 'workers': 4, 'alpha': 0.007514565986321241, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3465, 'max_depth': 47, 'num_leaves': 376, 'reg_alpha': 0.0026052406428952223, 'reg_lambda': 0.865768882944438, 'subsample': 0.4791154057019025, 'min_child_weight': 0.05268967126246312, 'n_jobs': 4, 'learning_rate': 0.19920942480240184}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 135.45it/s]  1%|          | 30/3257 [00:00<00:22, 143.90it/s]  1%|‚ñè         | 46/3257 [00:00<00:21, 149.42it/s]  2%|‚ñè         | 61/3257 [00:00<00:22, 143.62it/s]  2%|‚ñè         | 79/3257 [00:00<00:20, 152.63it/s]  3%|‚ñé         | 95/3257 [00:00<00:20, 152.86it/s]  3%|‚ñé         | 111/3257 [00:00<00:21, 144.52it/s]  4%|‚ñç         | 127/3257 [00:00<00:20, 149.06it/s]  4%|‚ñç         | 146/3257 [00:00<00:19, 160.17it/s]  5%|‚ñå         | 163/3257 [00:01<00:29, 104.16it/s]  5%|‚ñå         | 179/3257 [00:01<00:26, 115.97it/s]  6%|‚ñå         | 197/3257 [00:01<00:23, 128.83it/s]  7%|‚ñã         | 216/3257 [00:01<00:21, 142.50it/s]  7%|‚ñã         | 236/3257 [00:01<00:19, 156.69it/s]  8%|‚ñä         | 253/3257 [00:01<00:19, 155.14it/s]  8%|‚ñä         | 270/3257 [00:01<00:19, 155.39it/s]  9%|‚ñâ         | 292/3257 [00:01<00:17, 172.55it/s] 10%|‚ñâ         | 310/3257 [00:02<00:17, 168.22it/s] 10%|‚ñà         | 328/3257 [00:02<00:17, 168.86it/s] 11%|‚ñà         | 346/3257 [00:02<00:17, 163.26it/s] 11%|‚ñà         | 364/3257 [00:02<00:17, 165.75it/s] 12%|‚ñà‚ñè        | 381/3257 [00:02<00:18, 156.00it/s] 12%|‚ñà‚ñè        | 397/3257 [00:02<00:18, 153.79it/s] 13%|‚ñà‚ñé        | 415/3257 [00:02<00:17, 160.63it/s] 13%|‚ñà‚ñé        | 432/3257 [00:02<00:19, 141.33it/s] 14%|‚ñà‚ñé        | 447/3257 [00:03<00:19, 141.46it/s] 14%|‚ñà‚ñç        | 465/3257 [00:03<00:18, 150.60it/s] 15%|‚ñà‚ñç        | 481/3257 [00:03<00:18, 146.32it/s] 15%|‚ñà‚ñå        | 501/3257 [00:03<00:17, 159.02it/s] 16%|‚ñà‚ñå        | 519/3257 [00:03<00:16, 164.12it/s] 16%|‚ñà‚ñã        | 536/3257 [00:03<00:16, 160.25it/s] 17%|‚ñà‚ñã        | 553/3257 [00:03<00:16, 161.66it/s] 18%|‚ñà‚ñä        | 570/3257 [00:03<00:17, 151.57it/s] 18%|‚ñà‚ñä        | 586/3257 [00:03<00:18, 146.48it/s] 19%|‚ñà‚ñä        | 604/3257 [00:04<00:17, 151.89it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:04<00:17, 152.02it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:04<00:16, 161.49it/s] 20%|‚ñà‚ñà        | 656/3257 [00:04<00:17, 147.80it/s] 21%|‚ñà‚ñà        | 674/3257 [00:04<00:16, 153.73it/s] 21%|‚ñà‚ñà        | 690/3257 [00:04<00:17, 147.46it/s] 22%|‚ñà‚ñà‚ñè       | 706/3257 [00:04<00:17, 149.11it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:04<00:17, 145.26it/s] 23%|‚ñà‚ñà‚ñé       | 737/3257 [00:04<00:17, 142.23it/s] 23%|‚ñà‚ñà‚ñé       | 753/3257 [00:05<00:17, 146.95it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:05<00:16, 152.07it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:05<00:17, 145.28it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:16, 150.54it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:16, 146.60it/s] 26%|‚ñà‚ñà‚ñå       | 835/3257 [00:05<00:17, 140.68it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:05<00:18, 133.26it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:05<00:17, 139.65it/s] 27%|‚ñà‚ñà‚ñã       | 881/3257 [00:05<00:17, 138.25it/s] 28%|‚ñà‚ñà‚ñä       | 897/3257 [00:06<00:16, 143.48it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:06<00:16, 144.44it/s] 29%|‚ñà‚ñà‚ñä       | 932/3257 [00:06<00:15, 150.58it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:06<00:14, 155.66it/s] 30%|‚ñà‚ñà‚ñâ       | 967/3257 [00:06<00:14, 159.23it/s] 30%|‚ñà‚ñà‚ñà       | 983/3257 [00:06<00:14, 156.82it/s] 31%|‚ñà‚ñà‚ñà       | 999/3257 [00:06<00:14, 152.22it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:06<00:14, 150.91it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1031/3257 [00:06<00:15, 148.19it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:07<00:15, 143.37it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:07<00:14, 146.49it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:14, 148.53it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1096/3257 [00:07<00:14, 151.13it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1113/3257 [00:07<00:13, 155.83it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1129/3257 [00:07<00:14, 144.53it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1145/3257 [00:07<00:14, 144.62it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1163/3257 [00:07<00:13, 152.90it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1179/3257 [00:07<00:14, 143.89it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:08<00:14, 140.11it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1209/3257 [00:08<00:15, 136.27it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1228/3257 [00:08<00:13, 150.67it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:08<00:13, 151.71it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1263/3257 [00:08<00:12, 158.30it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1279/3257 [00:08<00:13, 148.04it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1295/3257 [00:08<00:13, 144.70it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:08<00:12, 150.81it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1329/3257 [00:08<00:12, 152.54it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:09<00:12, 157.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1362/3257 [00:09<00:12, 154.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1378/3257 [00:09<00:12, 148.62it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1393/3257 [00:09<00:12, 146.21it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:09<00:11, 156.89it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1431/3257 [00:09<00:11, 164.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1448/3257 [00:09<00:11, 160.77it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1466/3257 [00:09<00:10, 166.04it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1483/3257 [00:09<00:10, 165.25it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1500/3257 [00:09<00:10, 160.98it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1517/3257 [00:10<00:18, 95.47it/s]  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:10<00:17, 100.88it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1544/3257 [00:10<00:15, 108.01it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1561/3257 [00:10<00:14, 120.65it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1576/3257 [00:10<00:13, 127.87it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1595/3257 [00:10<00:11, 143.24it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:10<00:10, 156.60it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1633/3257 [00:11<00:10, 161.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:11<00:10, 147.22it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1666/3257 [00:11<00:10, 148.37it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1682/3257 [00:11<00:10, 149.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1699/3257 [00:11<00:10, 154.77it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:11<00:10, 152.71it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:11<00:10, 142.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1746/3257 [00:11<00:10, 142.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:11<00:10, 147.75it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1781/3257 [00:12<00:09, 155.77it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1797/3257 [00:12<00:09, 153.36it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1813/3257 [00:12<00:09, 146.97it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:12<00:09, 143.85it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:12<00:09, 153.76it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1865/3257 [00:12<00:08, 163.96it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1882/3257 [00:12<00:08, 163.02it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:12<00:08, 160.24it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:12<00:08, 161.69it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1936/3257 [00:13<00:07, 171.44it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1958/3257 [00:13<00:07, 183.80it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1977/3257 [00:13<00:07, 177.24it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1996/3257 [00:13<00:07, 180.12it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2015/3257 [00:13<00:07, 170.60it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:13<00:06, 176.63it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2053/3257 [00:13<00:07, 161.69it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2070/3257 [00:13<00:07, 156.55it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2087/3257 [00:13<00:07, 158.60it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2104/3257 [00:14<00:07, 156.67it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:14<00:07, 150.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:14<00:07, 151.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2152/3257 [00:14<00:07, 149.24it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:14<00:07, 153.63it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:14<00:07, 152.99it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:14<00:06, 161.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2221/3257 [00:14<00:06, 156.76it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:14<00:06, 155.13it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2253/3257 [00:15<00:06, 152.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2269/3257 [00:15<00:06, 151.19it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2285/3257 [00:15<00:06, 151.98it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:15<00:06, 147.27it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2322/3257 [00:15<00:05, 163.72it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2343/3257 [00:15<00:05, 174.67it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2364/3257 [00:15<00:04, 183.28it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2383/3257 [00:15<00:04, 181.42it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2403/3257 [00:15<00:04, 185.66it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:16<00:04, 171.69it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:16<00:04, 164.41it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2457/3257 [00:16<00:04, 161.00it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:16<00:04, 166.67it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2495/3257 [00:16<00:04, 172.21it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2515/3257 [00:16<00:04, 179.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2535/3257 [00:16<00:03, 183.34it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2554/3257 [00:16<00:04, 168.58it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:16<00:04, 155.52it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2588/3257 [00:17<00:04, 152.90it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2607/3257 [00:17<00:04, 162.26it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2629/3257 [00:17<00:03, 175.22it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2647/3257 [00:17<00:03, 165.08it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2664/3257 [00:17<00:03, 161.54it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2682/3257 [00:17<00:03, 166.04it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2699/3257 [00:17<00:03, 150.30it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2715/3257 [00:17<00:03, 144.77it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2737/3257 [00:17<00:03, 163.57it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:18<00:03, 166.56it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2773/3257 [00:18<00:03, 161.18it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:18<00:02, 167.20it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2809/3257 [00:18<00:02, 165.96it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2826/3257 [00:18<00:02, 156.96it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:18<00:02, 155.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2866/3257 [00:18<00:02, 176.13it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:18<00:02, 180.42it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2905/3257 [00:18<00:02, 165.42it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2922/3257 [00:19<00:03, 89.09it/s]  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2938/3257 [00:19<00:03, 100.14it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2952/3257 [00:19<00:02, 104.15it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2970/3257 [00:19<00:02, 119.66it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:19<00:02, 123.19it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:19<00:01, 136.77it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3020/3257 [00:20<00:01, 138.81it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3039/3257 [00:20<00:01, 149.92it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3057/3257 [00:20<00:01, 157.52it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3076/3257 [00:20<00:01, 164.61it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3093/3257 [00:20<00:01, 159.80it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3112/3257 [00:20<00:00, 167.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3130/3257 [00:20<00:00, 168.37it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3148/3257 [00:20<00:00, 156.30it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:20<00:00, 156.30it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3181/3257 [00:21<00:00, 152.03it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3200/3257 [00:21<00:00, 162.06it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3217/3257 [00:21<00:00, 154.35it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3237/3257 [00:21<00:00, 165.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3254/3257 [00:21<00:00, 163.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 151.75it/s]
2023-02-07 19:25:43.324 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:25:43,325][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d299,n5,mc8,s0.612766,t4>', 'datetime': '2023-02-07T19:25:43.325622', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:25:43,326][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:25:43,326][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:25:43,942][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:25:43,944][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:25:44,002][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 18271 unique words (42.79% of original 42701, drops 24430)', 'datetime': '2023-02-07T19:25:44.002661', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:25:44,003][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 5751191 word corpus (98.77% of original 5822992, drops 71801)', 'datetime': '2023-02-07T19:25:44.003124', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:25:44,071][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:25:44,072][gensim.models.word2vec][INFO] - sample=0.612766 downsamples 0 most-common words
[2023-02-07 19:25:44,073][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5751191 word corpus (100.0%% of prior 5751191)', 'datetime': '2023-02-07T19:25:44.073016', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:25:44,189][gensim.models.word2vec][INFO] - estimated required memory for 18271 words and 299 dimensions: 57386504 bytes
[2023-02-07 19:25:44,190][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:25:44,222][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18271 vocabulary and 299 features, using sg=1 hs=0 sample=0.6127657291531072 negative=5 window=13 shrink_windows=True', 'datetime': '2023-02-07T19:25:44.222114', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:25:45,226][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 34.02% examples, 1965947 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:25:46,229][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 67.79% examples, 1975307 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:25:47,119][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5725443 effective words) took 2.9s, 1977602 effective words/s
[2023-02-07 19:25:48,123][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 38.16% examples, 2230303 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:25:49,127][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 76.27% examples, 2208161 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:25:49,727][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5725443 effective words) took 2.6s, 2197527 effective words/s
[2023-02-07 19:25:50,730][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 37.40% examples, 2195343 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:25:51,731][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 74.64% examples, 2168513 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:52,377][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5725443 effective words) took 2.6s, 2162217 effective words/s
[2023-02-07 19:25:53,383][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 36.97% examples, 2159196 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:54,389][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 75.13% examples, 2172478 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:25:55,003][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5725443 effective words) took 2.6s, 2181662 effective words/s
[2023-02-07 19:25:56,006][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 37.58% examples, 2201884 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:25:57,009][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 75.41% examples, 2188106 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:57,636][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5725443 effective words) took 2.6s, 2175459 effective words/s
[2023-02-07 19:25:58,643][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 36.97% examples, 2159383 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:59,643][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 75.90% examples, 2195582 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:00,248][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5725443 effective words) took 2.6s, 2193442 effective words/s
[2023-02-07 19:26:01,252][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.29% examples, 2241402 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:02,254][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 77.68% examples, 2242395 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:02,815][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5725443 effective words) took 2.6s, 2233049 effective words/s
[2023-02-07 19:26:03,819][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 38.07% examples, 2220142 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:04,823][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 77.68% examples, 2238979 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:05,379][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5725443 effective words) took 2.6s, 2235141 effective words/s
[2023-02-07 19:26:06,389][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 38.99% examples, 2260860 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:07,390][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 78.63% examples, 2263067 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:07,910][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5725443 effective words) took 2.5s, 2263009 effective words/s
[2023-02-07 19:26:08,921][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 38.90% examples, 2263867 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:09,922][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 78.91% examples, 2272276 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:10,436][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5725443 effective words) took 2.5s, 2269511 effective words/s
[2023-02-07 19:26:11,440][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 38.29% examples, 2238120 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:12,442][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 77.77% examples, 2242679 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:12,990][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5725443 effective words) took 2.6s, 2243243 effective words/s
[2023-02-07 19:26:13,998][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 38.99% examples, 2266243 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:15,000][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 78.05% examples, 2247241 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:15,535][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5725443 effective words) took 2.5s, 2251834 effective words/s
[2023-02-07 19:26:16,541][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 39.24% examples, 2300315 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:17,542][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 79.49% examples, 2299370 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:18,023][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5725443 effective words) took 2.5s, 2303841 effective words/s
[2023-02-07 19:26:19,032][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 38.29% examples, 2226013 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:20,034][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 77.77% examples, 2236862 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:20,584][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5725443 effective words) took 2.6s, 2237242 effective words/s
[2023-02-07 19:26:21,591][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 38.99% examples, 2267210 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:22,593][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 78.17% examples, 2253085 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:26:23,129][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5725443 effective words) took 2.5s, 2251048 effective words/s
[2023-02-07 19:26:23,130][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85881645 effective words) took 38.9s, 2207306 effective words/s', 'datetime': '2023-02-07T19:26:23.130465', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:26:23.130 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:26:27,089][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192512-u5pdo58e/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:26:27.089610', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:26:27,090][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:26:27,167][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192512-u5pdo58e/files/../tmp/embedding_model.pt
2023-02-07 19:26:27.168 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:26:29.260 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:26:29.971 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:26:59.959 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0020763323672972, 'test_mae': 0.7581259886637056, 'test_r2': -2.0698646691193776}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.82
wandb: percentage 0.57212
wandb:   test_mae 0.75813
wandb:   test_mse 1.00208
wandb:    test_r2 -2.06986
wandb: 
wandb: üöÄ View run leafy-sweep-43 at: https://wandb.ai/xiaoqiz/mof2vec/runs/u5pdo58e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_192512-u5pdo58e/logs
wandb: Agent Starting Run: tu52r0cy with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 695
wandb: 	model.gensim.alpha: 0.018863400604887424
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.7660191434481887
wandb: 	model.gensim.vector_size: 274
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.232339458115808
wandb: 	model.sklearn.max_depth: 47
wandb: 	model.sklearn.min_child_weight: 0.024046134324494976
wandb: 	model.sklearn.n_estimators: 898
wandb: 	model.sklearn.num_leaves: 473
wandb: 	model.sklearn.reg_alpha: 0.0047877063844639495
wandb: 	model.sklearn.reg_lambda: 0.6278424409756916
wandb: 	model.sklearn.subsample: 0.4378195157761538
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192712-tu52r0cy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-44
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/tu52r0cy
2023-02-07 19:27:21.017 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 19:27:21.017 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 695 for sweep.
2023-02-07 19:27:21.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.018863400604887424 for sweep.
2023-02-07 19:27:21.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:27:21.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 19:27:21.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7660191434481887 for sweep.
2023-02-07 19:27:21.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 274 for sweep.
2023-02-07 19:27:21.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 19:27:21.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.232339458115808 for sweep.
2023-02-07 19:27:21.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 47 for sweep.
2023-02-07 19:27:21.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.024046134324494976 for sweep.
2023-02-07 19:27:21.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 898 for sweep.
2023-02-07 19:27:21.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 473 for sweep.
2023-02-07 19:27:21.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0047877063844639495 for sweep.
2023-02-07 19:27:21.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.6278424409756916 for sweep.
2023-02-07 19:27:21.021 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.4378195157761538 for sweep.
2023-02-07 19:27:21.021 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:27:21.030 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192712-tu52r0cy/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 695, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 274, 'window': 11, 'min_count': 8, 'dm': 0, 'sample': 0.7660191434481887, 'workers': 4, 'alpha': 0.018863400604887424, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 898, 'max_depth': 47, 'num_leaves': 473, 'reg_alpha': 0.0047877063844639495, 'reg_lambda': 0.6278424409756916, 'subsample': 0.4378195157761538, 'min_child_weight': 0.024046134324494976, 'n_jobs': 4, 'learning_rate': 0.232339458115808}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 170.92it/s]  1%|          | 39/3257 [00:00<00:16, 190.41it/s]  2%|‚ñè         | 59/3257 [00:00<00:17, 179.60it/s]  2%|‚ñè         | 81/3257 [00:00<00:16, 191.87it/s]  3%|‚ñé         | 101/3257 [00:00<00:16, 191.43it/s]  4%|‚ñé         | 121/3257 [00:00<00:17, 181.97it/s]  4%|‚ñç         | 144/3257 [00:00<00:15, 195.73it/s]  5%|‚ñå         | 164/3257 [00:00<00:17, 181.09it/s]  6%|‚ñå         | 184/3257 [00:00<00:16, 184.00it/s]  6%|‚ñã         | 204/3257 [00:01<00:16, 186.68it/s]  7%|‚ñã         | 230/3257 [00:01<00:14, 205.93it/s]  8%|‚ñä         | 251/3257 [00:01<00:14, 202.72it/s]  8%|‚ñä         | 272/3257 [00:01<00:14, 199.34it/s]  9%|‚ñâ         | 296/3257 [00:01<00:14, 210.72it/s] 10%|‚ñâ         | 318/3257 [00:01<00:14, 197.87it/s] 10%|‚ñà         | 339/3257 [00:01<00:14, 194.96it/s] 11%|‚ñà         | 360/3257 [00:01<00:14, 197.72it/s] 12%|‚ñà‚ñè        | 380/3257 [00:01<00:15, 185.99it/s] 12%|‚ñà‚ñè        | 399/3257 [00:02<00:15, 183.88it/s] 13%|‚ñà‚ñé        | 420/3257 [00:02<00:14, 190.34it/s] 14%|‚ñà‚ñé        | 440/3257 [00:02<00:16, 170.04it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:15, 174.98it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:15, 176.95it/s] 15%|‚ñà‚ñå        | 501/3257 [00:02<00:14, 188.23it/s] 16%|‚ñà‚ñå        | 521/3257 [00:02<00:14, 191.48it/s] 17%|‚ñà‚ñã        | 541/3257 [00:02<00:14, 189.72it/s] 17%|‚ñà‚ñã        | 561/3257 [00:02<00:15, 175.85it/s] 18%|‚ñà‚ñä        | 579/3257 [00:03<00:15, 169.45it/s] 18%|‚ñà‚ñä        | 600/3257 [00:03<00:14, 179.11it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:14, 181.39it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:03<00:14, 185.95it/s] 20%|‚ñà‚ñà        | 660/3257 [00:03<00:15, 171.56it/s] 21%|‚ñà‚ñà        | 682/3257 [00:03<00:14, 183.52it/s] 22%|‚ñà‚ñà‚ñè       | 701/3257 [00:03<00:14, 176.95it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:03<00:14, 180.74it/s] 23%|‚ñà‚ñà‚ñé       | 740/3257 [00:04<00:14, 172.68it/s] 23%|‚ñà‚ñà‚ñé       | 762/3257 [00:04<00:13, 184.90it/s] 24%|‚ñà‚ñà‚ñç       | 781/3257 [00:04<00:13, 178.88it/s] 25%|‚ñà‚ñà‚ñç       | 803/3257 [00:04<00:12, 189.15it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:04<00:13, 177.90it/s] 26%|‚ñà‚ñà‚ñå       | 842/3257 [00:04<00:14, 169.89it/s] 26%|‚ñà‚ñà‚ñã       | 860/3257 [00:04<00:13, 172.40it/s] 27%|‚ñà‚ñà‚ñã       | 878/3257 [00:04<00:14, 166.16it/s] 28%|‚ñà‚ñà‚ñä       | 897/3257 [00:04<00:13, 171.78it/s] 28%|‚ñà‚ñà‚ñä       | 915/3257 [00:05<00:20, 115.21it/s] 29%|‚ñà‚ñà‚ñä       | 935/3257 [00:05<00:17, 131.75it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:05<00:15, 147.45it/s] 30%|‚ñà‚ñà‚ñâ       | 973/3257 [00:05<00:15, 151.38it/s] 30%|‚ñà‚ñà‚ñà       | 990/3257 [00:05<00:14, 153.96it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:05<00:14, 155.44it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:05<00:13, 161.73it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1044/3257 [00:05<00:13, 160.92it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:06<00:13, 165.74it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:13, 167.14it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1098/3257 [00:06<00:12, 170.26it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:06<00:12, 172.53it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1135/3257 [00:06<00:12, 170.33it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1153/3257 [00:06<00:12, 166.90it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:06<00:12, 173.39it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:06<00:13, 157.99it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1208/3257 [00:06<00:13, 157.48it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1230/3257 [00:07<00:11, 173.33it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1248/3257 [00:07<00:11, 169.06it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1269/3257 [00:07<00:11, 178.54it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:07<00:12, 159.38it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1307/3257 [00:07<00:11, 165.56it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1325/3257 [00:07<00:11, 169.27it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1345/3257 [00:07<00:10, 177.40it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:07<00:11, 171.88it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1382/3257 [00:07<00:11, 166.38it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:08<00:10, 173.50it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1424/3257 [00:08<00:09, 184.25it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1445/3257 [00:08<00:09, 189.99it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1468/3257 [00:08<00:08, 198.98it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1489/3257 [00:08<00:09, 195.49it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:08<00:08, 200.05it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1532/3257 [00:08<00:09, 181.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1551/3257 [00:08<00:09, 174.74it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1569/3257 [00:08<00:09, 174.33it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1587/3257 [00:09<00:09, 173.76it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1606/3257 [00:09<00:09, 175.91it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1625/3257 [00:09<00:09, 179.43it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1644/3257 [00:09<00:09, 169.63it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:09<00:09, 163.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1679/3257 [00:09<00:09, 160.15it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1696/3257 [00:09<00:09, 162.63it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1714/3257 [00:09<00:09, 167.17it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:09<00:09, 154.88it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1748/3257 [00:10<00:09, 158.82it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1766/3257 [00:10<00:09, 163.15it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1786/3257 [00:10<00:08, 172.40it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1804/3257 [00:10<00:08, 172.16it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1823/3257 [00:10<00:08, 173.34it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1841/3257 [00:10<00:08, 169.33it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1858/3257 [00:10<00:08, 165.55it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:10<00:07, 175.59it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:10<00:08, 169.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:10<00:07, 170.72it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1936/3257 [00:11<00:07, 177.72it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1959/3257 [00:11<00:06, 192.35it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1979/3257 [00:11<00:06, 182.74it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1998/3257 [00:11<00:06, 184.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2017/3257 [00:11<00:06, 182.10it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2036/3257 [00:11<00:06, 182.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:11<00:07, 167.71it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2073/3257 [00:11<00:06, 169.89it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:11<00:06, 169.82it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2109/3257 [00:12<00:06, 167.41it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2126/3257 [00:12<00:11, 95.96it/s]  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:12<00:10, 106.47it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2162/3257 [00:12<00:08, 123.40it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:12<00:07, 135.47it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2201/3257 [00:12<00:07, 148.96it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2218/3257 [00:12<00:06, 151.02it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:13<00:06, 156.91it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2253/3257 [00:13<00:06, 158.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:13<00:06, 156.86it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2290/3257 [00:13<00:05, 168.08it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2308/3257 [00:13<00:05, 167.51it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2332/3257 [00:13<00:04, 186.87it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2357/3257 [00:13<00:04, 203.01it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2378/3257 [00:13<00:04, 195.46it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2400/3257 [00:13<00:04, 201.69it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2421/3257 [00:14<00:04, 191.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2441/3257 [00:14<00:04, 181.00it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2461/3257 [00:14<00:04, 186.01it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:14<00:04, 189.41it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2504/3257 [00:14<00:03, 200.05it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2525/3257 [00:14<00:03, 198.96it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2546/3257 [00:14<00:03, 196.12it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2566/3257 [00:14<00:03, 184.63it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2585/3257 [00:14<00:03, 178.81it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2605/3257 [00:15<00:03, 182.34it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2630/3257 [00:15<00:03, 200.95it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2651/3257 [00:15<00:03, 187.28it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2671/3257 [00:15<00:03, 187.46it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2691/3257 [00:15<00:02, 189.10it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2711/3257 [00:15<00:03, 166.88it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:15<00:02, 176.30it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2754/3257 [00:15<00:02, 186.42it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:15<00:02, 176.10it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2798/3257 [00:16<00:02, 191.87it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2818/3257 [00:16<00:02, 182.11it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:16<00:02, 178.30it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2860/3257 [00:16<00:02, 192.23it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2885/3257 [00:16<00:01, 206.99it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:16<00:01, 186.42it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:16<00:01, 189.37it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2948/3257 [00:16<00:01, 183.67it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2968/3257 [00:16<00:01, 187.85it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2988/3257 [00:17<00:01, 176.42it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:17<00:01, 189.88it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3032/3257 [00:17<00:01, 191.67it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3053/3257 [00:17<00:01, 196.52it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3078/3257 [00:17<00:00, 210.19it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3100/3257 [00:17<00:00, 201.37it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3124/3257 [00:17<00:00, 209.11it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3146/3257 [00:17<00:00, 190.71it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:18<00:00, 190.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3186/3257 [00:18<00:00, 186.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:18<00:00, 190.24it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3227/3257 [00:18<00:00, 186.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3252/3257 [00:18<00:00, 203.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 176.19it/s]
2023-02-07 19:27:40.193 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:27:40,195][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d274,n5,mc8,s0.766019,t4>', 'datetime': '2023-02-07T19:27:40.195722', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:27:40,196][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:27:40,197][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:27:40,631][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 19:27:40,632][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:27:40,661][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 9584 unique words (44.17% of original 21699, drops 12115)', 'datetime': '2023-02-07T19:27:40.661817', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:27:40,662][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 4331919 word corpus (99.19% of original 4367244, drops 35325)', 'datetime': '2023-02-07T19:27:40.662273', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:27:40,697][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 19:27:40,698][gensim.models.word2vec][INFO] - sample=0.766019 downsamples 0 most-common words
[2023-02-07 19:27:40,698][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4331919 word corpus (100.0%% of prior 4331919)', 'datetime': '2023-02-07T19:27:40.698516', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:27:40,759][gensim.models.word2vec][INFO] - estimated required memory for 9584 words and 274 dimensions: 30021200 bytes
[2023-02-07 19:27:40,760][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:27:40,775][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 9584 vocabulary and 274 features, using sg=1 hs=0 sample=0.7660191434481887 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T19:27:40.775516', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:27:41,779][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 49.22% examples, 2174785 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:42,738][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4333519 effective words) took 2.0s, 2210806 effective words/s
[2023-02-07 19:27:43,742][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 52.44% examples, 2326489 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:27:44,617][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4333519 effective words) took 1.9s, 2309162 effective words/s
[2023-02-07 19:27:45,622][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 52.04% examples, 2300999 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:46,496][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4333519 effective words) took 1.9s, 2308437 effective words/s
[2023-02-07 19:27:47,500][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 53.05% examples, 2352010 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:48,327][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4333519 effective words) took 1.8s, 2367466 effective words/s
[2023-02-07 19:27:49,332][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 53.85% examples, 2391783 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:50,139][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4333519 effective words) took 1.8s, 2394968 effective words/s
[2023-02-07 19:27:51,141][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 54.77% examples, 2430098 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:51,923][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4333519 effective words) took 1.8s, 2430771 effective words/s
[2023-02-07 19:27:52,929][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 55.02% examples, 2431247 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:53,704][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4333519 effective words) took 1.8s, 2435448 effective words/s
[2023-02-07 19:27:54,706][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 54.50% examples, 2420129 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:55,482][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4333519 effective words) took 1.8s, 2439085 effective words/s
[2023-02-07 19:27:56,493][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 56.34% examples, 2486391 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:57,237][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4333519 effective words) took 1.8s, 2473392 effective words/s
[2023-02-07 19:27:58,241][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 55.54% examples, 2464230 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:59,000][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4333519 effective words) took 1.8s, 2459905 effective words/s
[2023-02-07 19:28:00,008][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 55.20% examples, 2435902 words/s, in_qsize 5, out_qsize 2
[2023-02-07 19:28:00,780][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4333519 effective words) took 1.8s, 2436587 effective words/s
[2023-02-07 19:28:01,785][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 54.77% examples, 2426195 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:28:02,560][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4333519 effective words) took 1.8s, 2438323 effective words/s
[2023-02-07 19:28:03,564][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 55.20% examples, 2448463 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:28:04,334][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4333519 effective words) took 1.8s, 2448068 effective words/s
[2023-02-07 19:28:05,337][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 58.86% examples, 2608547 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:28:05,929][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4333519 effective words) took 1.6s, 2721174 effective words/s
[2023-02-07 19:28:06,930][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 68.38% examples, 3027934 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:28:07,365][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4333519 effective words) took 1.4s, 3018703 effective words/s
[2023-02-07 19:28:07,366][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65002785 effective words) took 26.6s, 2444605 effective words/s', 'datetime': '2023-02-07T19:28:07.366288', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:28:07.366 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:28:09,556][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192712-tu52r0cy/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:28:09.556165', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:28:09,557][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:28:09,595][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192712-tu52r0cy/files/../tmp/embedding_model.pt
2023-02-07 19:28:09.596 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:28:11.153 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:28:11.719 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:28:21.500 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9473878625715597, 'test_mae': 0.7388437708919765, 'test_r2': -1.9144671789435566}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.91
wandb: percentage 0.55832
wandb:   test_mae 0.73884
wandb:   test_mse 0.94739
wandb:    test_r2 -1.91447
wandb: 
wandb: üöÄ View run vital-sweep-44 at: https://wandb.ai/xiaoqiz/mof2vec/runs/tu52r0cy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_192712-tu52r0cy/logs
wandb: Agent Starting Run: c2i8t8qx with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 763
wandb: 	model.gensim.alpha: 0.0017157845425321613
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 4
wandb: 	model.gensim.sample: 0.23771818112883256
wandb: 	model.gensim.vector_size: 232
wandb: 	model.gensim.window: 6
wandb: 	model.sklearn.learning_rate: 0.04991518256344195
wandb: 	model.sklearn.max_depth: 32
wandb: 	model.sklearn.min_child_weight: 0.09470262585489948
wandb: 	model.sklearn.n_estimators: 2051
wandb: 	model.sklearn.num_leaves: 151
wandb: 	model.sklearn.reg_alpha: 0.005530427687892872
wandb: 	model.sklearn.reg_lambda: 0.09358313316179598
wandb: 	model.sklearn.subsample: 0.4606474199527779
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192832-c2i8t8qx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-45
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/c2i8t8qx
2023-02-07 19:28:39.973 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:28:39.973 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 763 for sweep.
2023-02-07 19:28:39.974 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0017157845425321613 for sweep.
2023-02-07 19:28:39.974 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:28:39.974 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 4 for sweep.
2023-02-07 19:28:39.974 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.23771818112883256 for sweep.
2023-02-07 19:28:39.974 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 232 for sweep.
2023-02-07 19:28:39.975 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 6 for sweep.
2023-02-07 19:28:39.975 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.04991518256344195 for sweep.
2023-02-07 19:28:39.975 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 32 for sweep.
2023-02-07 19:28:39.975 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09470262585489948 for sweep.
2023-02-07 19:28:39.976 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2051 for sweep.
2023-02-07 19:28:39.976 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 151 for sweep.
2023-02-07 19:28:39.976 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.005530427687892872 for sweep.
2023-02-07 19:28:39.977 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.09358313316179598 for sweep.
2023-02-07 19:28:39.977 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.4606474199527779 for sweep.
2023-02-07 19:28:39.977 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:28:39.988 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192832-c2i8t8qx/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 763, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 232, 'window': 6, 'min_count': 4, 'dm': 0, 'sample': 0.23771818112883256, 'workers': 4, 'alpha': 0.0017157845425321613, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2051, 'max_depth': 32, 'num_leaves': 151, 'reg_alpha': 0.005530427687892872, 'reg_lambda': 0.09358313316179598, 'subsample': 0.4606474199527779, 'min_child_weight': 0.09470262585489948, 'n_jobs': 4, 'learning_rate': 0.04991518256344195}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 165.64it/s]  1%|          | 36/3257 [00:00<00:18, 175.36it/s]  2%|‚ñè         | 54/3257 [00:00<00:18, 174.04it/s]  2%|‚ñè         | 74/3257 [00:00<00:17, 184.04it/s]  3%|‚ñé         | 94/3257 [00:00<00:16, 187.77it/s]  3%|‚ñé         | 113/3257 [00:00<00:17, 179.86it/s]  4%|‚ñç         | 132/3257 [00:00<00:17, 180.84it/s]  5%|‚ñç         | 154/3257 [00:00<00:16, 188.70it/s]  5%|‚ñå         | 173/3257 [00:00<00:17, 178.42it/s]  6%|‚ñå         | 193/3257 [00:01<00:16, 183.92it/s]  7%|‚ñã         | 214/3257 [00:01<00:15, 190.86it/s]  7%|‚ñã         | 236/3257 [00:01<00:15, 198.75it/s]  8%|‚ñä         | 256/3257 [00:01<00:15, 196.26it/s]  8%|‚ñä         | 276/3257 [00:01<00:15, 196.98it/s]  9%|‚ñâ         | 298/3257 [00:01<00:14, 201.22it/s] 10%|‚ñâ         | 319/3257 [00:01<00:15, 195.33it/s] 10%|‚ñà         | 339/3257 [00:01<00:22, 130.51it/s] 11%|‚ñà         | 359/3257 [00:02<00:19, 145.09it/s] 12%|‚ñà‚ñè        | 377/3257 [00:02<00:19, 147.30it/s] 12%|‚ñà‚ñè        | 396/3257 [00:02<00:18, 157.00it/s] 13%|‚ñà‚ñé        | 417/3257 [00:02<00:16, 169.97it/s] 13%|‚ñà‚ñé        | 436/3257 [00:02<00:19, 147.86it/s] 14%|‚ñà‚ñç        | 457/3257 [00:02<00:17, 162.38it/s] 15%|‚ñà‚ñç        | 476/3257 [00:02<00:16, 166.87it/s] 15%|‚ñà‚ñå        | 495/3257 [00:02<00:16, 172.12it/s] 16%|‚ñà‚ñå        | 516/3257 [00:02<00:15, 182.40it/s] 16%|‚ñà‚ñã        | 535/3257 [00:03<00:15, 180.18it/s] 17%|‚ñà‚ñã        | 555/3257 [00:03<00:14, 184.27it/s] 18%|‚ñà‚ñä        | 574/3257 [00:03<00:16, 160.07it/s] 18%|‚ñà‚ñä        | 596/3257 [00:03<00:15, 173.95it/s] 19%|‚ñà‚ñâ        | 618/3257 [00:03<00:14, 186.20it/s] 20%|‚ñà‚ñâ        | 638/3257 [00:03<00:14, 182.26it/s] 20%|‚ñà‚ñà        | 657/3257 [00:03<00:15, 164.86it/s] 21%|‚ñà‚ñà        | 677/3257 [00:03<00:14, 172.53it/s] 21%|‚ñà‚ñà‚ñè       | 695/3257 [00:04<00:15, 168.12it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:04<00:14, 178.23it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:04<00:15, 162.76it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:04<00:15, 165.85it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:04<00:14, 168.13it/s] 24%|‚ñà‚ñà‚ñç       | 791/3257 [00:04<00:14, 167.39it/s] 25%|‚ñà‚ñà‚ñç       | 808/3257 [00:04<00:14, 165.84it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:04<00:14, 164.03it/s] 26%|‚ñà‚ñà‚ñå       | 842/3257 [00:04<00:15, 159.02it/s] 26%|‚ñà‚ñà‚ñã       | 861/3257 [00:05<00:14, 165.34it/s] 27%|‚ñà‚ñà‚ñã       | 878/3257 [00:05<00:14, 160.60it/s] 28%|‚ñà‚ñà‚ñä       | 899/3257 [00:05<00:13, 173.23it/s] 28%|‚ñà‚ñà‚ñä       | 917/3257 [00:05<00:13, 174.88it/s] 29%|‚ñà‚ñà‚ñä       | 936/3257 [00:05<00:13, 177.02it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:05<00:12, 181.96it/s] 30%|‚ñà‚ñà‚ñâ       | 975/3257 [00:05<00:12, 180.04it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:05<00:13, 172.07it/s] 31%|‚ñà‚ñà‚ñà       | 1012/3257 [00:05<00:13, 166.89it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1029/3257 [00:05<00:13, 166.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:06<00:13, 161.66it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1064/3257 [00:06<00:13, 166.59it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1081/3257 [00:06<00:13, 166.45it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1098/3257 [00:06<00:12, 167.09it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:06<00:12, 170.49it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1135/3257 [00:06<00:12, 167.13it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1152/3257 [00:06<00:12, 162.71it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:06<00:12, 166.93it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:06<00:13, 151.94it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:07<00:13, 152.58it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1220/3257 [00:07<00:13, 153.84it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:07<00:11, 168.90it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1260/3257 [00:07<00:11, 167.72it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:07<00:12, 162.21it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1294/3257 [00:07<00:12, 152.05it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1312/3257 [00:07<00:12, 158.97it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1331/3257 [00:07<00:11, 164.84it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:07<00:11, 164.39it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1367/3257 [00:08<00:11, 164.00it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1384/3257 [00:08<00:11, 161.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1403/3257 [00:08<00:11, 167.52it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1425/3257 [00:08<00:10, 182.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1444/3257 [00:08<00:09, 183.80it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1466/3257 [00:08<00:09, 193.24it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1486/3257 [00:08<00:09, 190.65it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1510/3257 [00:08<00:08, 200.79it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1531/3257 [00:08<00:09, 179.70it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:09<00:09, 173.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1568/3257 [00:09<00:09, 171.79it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1586/3257 [00:09<00:16, 99.07it/s]  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1605/3257 [00:09<00:14, 115.36it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1623/3257 [00:09<00:12, 127.35it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1641/3257 [00:09<00:11, 136.71it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1658/3257 [00:09<00:11, 140.25it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:10<00:10, 144.03it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:10<00:10, 146.87it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:10<00:10, 153.64it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:10<00:09, 153.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:10<00:10, 148.42it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:10<00:09, 158.36it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1783/3257 [00:10<00:08, 169.63it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1801/3257 [00:10<00:08, 170.24it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1819/3257 [00:10<00:08, 171.20it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1837/3257 [00:11<00:08, 168.44it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1855/3257 [00:11<00:08, 170.79it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1876/3257 [00:11<00:07, 179.08it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1894/3257 [00:11<00:07, 172.44it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:11<00:07, 177.20it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:11<00:07, 182.38it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1962/3257 [00:11<00:06, 201.14it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1983/3257 [00:11<00:06, 184.16it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:11<00:06, 188.27it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2024/3257 [00:12<00:06, 189.62it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2044/3257 [00:12<00:06, 182.14it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2063/3257 [00:12<00:07, 166.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:12<00:06, 171.86it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2101/3257 [00:12<00:06, 166.16it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:12<00:06, 164.89it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:12<00:06, 165.50it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:12<00:06, 162.79it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2174/3257 [00:12<00:06, 173.11it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2192/3257 [00:13<00:06, 169.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2210/3257 [00:13<00:06, 163.03it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2230/3257 [00:13<00:06, 171.02it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2248/3257 [00:13<00:06, 165.77it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2266/3257 [00:13<00:05, 167.34it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2283/3257 [00:13<00:05, 167.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:13<00:05, 168.91it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2325/3257 [00:13<00:04, 188.03it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2347/3257 [00:13<00:04, 196.19it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2368/3257 [00:14<00:04, 198.95it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2391/3257 [00:14<00:04, 207.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2412/3257 [00:14<00:04, 194.07it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2432/3257 [00:14<00:04, 179.27it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2451/3257 [00:14<00:04, 174.64it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2474/3257 [00:14<00:04, 187.93it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2494/3257 [00:14<00:04, 184.49it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:14<00:03, 187.12it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2534/3257 [00:14<00:03, 190.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2554/3257 [00:15<00:04, 175.54it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:15<00:04, 165.95it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2589/3257 [00:15<00:04, 163.92it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:15<00:03, 185.73it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2635/3257 [00:15<00:03, 192.02it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2655/3257 [00:15<00:03, 184.04it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2674/3257 [00:15<00:03, 179.61it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:15<00:03, 178.43it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2712/3257 [00:15<00:03, 164.95it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:16<00:03, 170.64it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2754/3257 [00:16<00:02, 182.69it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2773/3257 [00:16<00:02, 173.53it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:16<00:02, 185.92it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2814/3257 [00:16<00:02, 182.42it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:16<00:02, 170.74it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:16<00:02, 176.46it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2880/3257 [00:16<00:01, 201.86it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2901/3257 [00:17<00:03, 97.94it/s]  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2922/3257 [00:17<00:02, 115.68it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2940/3257 [00:17<00:02, 127.13it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2958/3257 [00:17<00:02, 129.98it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2977/3257 [00:17<00:01, 143.02it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2995/3257 [00:17<00:01, 150.06it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:17<00:01, 162.96it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3038/3257 [00:18<00:01, 176.46it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3061/3257 [00:18<00:01, 189.53it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3081/3257 [00:18<00:00, 190.35it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3102/3257 [00:18<00:00, 194.57it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3124/3257 [00:18<00:00, 198.74it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3145/3257 [00:18<00:00, 183.86it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3164/3257 [00:18<00:00, 181.82it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:18<00:00, 173.94it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3205/3257 [00:18<00:00, 185.22it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3224/3257 [00:19<00:00, 176.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:19<00:00, 182.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 169.04it/s]
2023-02-07 19:29:00.067 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:29:00,069][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d232,n5,mc4,s0.237718,t4>', 'datetime': '2023-02-07T19:29:00.069292', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:29:00,069][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:29:00,069][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:29:00,633][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:29:00,633][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:29:00,715][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 retains 29175 unique words (68.32% of original 42701, drops 13526)', 'datetime': '2023-02-07T19:29:00.715793', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:29:00,716][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 leaves 5800681 word corpus (99.62% of original 5822992, drops 22311)', 'datetime': '2023-02-07T19:29:00.716207', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:29:00,821][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:29:00,822][gensim.models.word2vec][INFO] - sample=0.237718 downsamples 0 most-common words
[2023-02-07 19:29:00,822][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5800681 word corpus (100.0%% of prior 5800681)', 'datetime': '2023-02-07T19:29:00.822795', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:29:01,002][gensim.models.word2vec][INFO] - estimated required memory for 29175 words and 232 dimensions: 72410196 bytes
[2023-02-07 19:29:01,003][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:29:01,037][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 29175 vocabulary and 232 features, using sg=1 hs=0 sample=0.23771818112883256 negative=5 window=6 shrink_windows=True', 'datetime': '2023-02-07T19:29:01.037106', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:29:02,046][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 24.26% examples, 1381483 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:03,049][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 51.34% examples, 1507686 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:04,049][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 80.44% examples, 1556578 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:04,713][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5774537 effective words) took 3.7s, 1571581 effective words/s
[2023-02-07 19:29:05,715][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 39.09% examples, 2306818 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:06,716][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 79.49% examples, 2322524 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:07,196][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5774537 effective words) took 2.5s, 2327621 effective words/s
[2023-02-07 19:29:08,207][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 29.57% examples, 1693137 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:09,211][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 58.03% examples, 1700351 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:10,218][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 88.36% examples, 1698190 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:10,597][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5774537 effective words) took 3.4s, 1698594 effective words/s
[2023-02-07 19:29:11,603][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 38.81% examples, 2279647 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:12,603][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 78.26% examples, 2275734 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:13,133][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5774537 effective words) took 2.5s, 2279027 effective words/s
[2023-02-07 19:29:14,138][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 38.99% examples, 2293503 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:15,142][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 78.69% examples, 2288410 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:15,661][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5774537 effective words) took 2.5s, 2286740 effective words/s
[2023-02-07 19:29:16,674][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 38.99% examples, 2272184 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:17,675][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 79.28% examples, 2301326 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:18,158][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5774537 effective words) took 2.5s, 2314488 effective words/s
[2023-02-07 19:29:19,161][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.99% examples, 2295382 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:20,165][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 79.28% examples, 2309605 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:20,655][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5774537 effective words) took 2.5s, 2314037 effective words/s
[2023-02-07 19:29:21,663][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 39.36% examples, 2321403 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:22,668][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 79.95% examples, 2320656 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:23,142][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5774537 effective words) took 2.5s, 2323200 effective words/s
[2023-02-07 19:29:24,151][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 38.99% examples, 2284756 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:25,153][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 79.06% examples, 2297459 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:25,645][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5774537 effective words) took 2.5s, 2309966 effective words/s
[2023-02-07 19:29:26,650][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 39.48% examples, 2336872 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:27,657][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 81.03% examples, 2344642 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:29:28,109][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5774537 effective words) took 2.5s, 2345767 effective words/s
[2023-02-07 19:29:29,112][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 38.99% examples, 2297646 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:30,115][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 79.49% examples, 2320414 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:30,596][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5774537 effective words) took 2.5s, 2324483 effective words/s
[2023-02-07 19:29:31,606][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 39.36% examples, 2316100 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:32,607][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 80.81% examples, 2340487 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:33,059][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5774537 effective words) took 2.5s, 2345393 effective words/s
[2023-02-07 19:29:34,074][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 39.36% examples, 2305608 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:35,076][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 80.44% examples, 2324305 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:35,548][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5774537 effective words) took 2.5s, 2321544 effective words/s
[2023-02-07 19:29:36,558][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 39.36% examples, 2320154 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:37,558][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 79.40% examples, 2311896 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:38,042][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5774537 effective words) took 2.5s, 2318442 effective words/s
[2023-02-07 19:29:39,046][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 38.99% examples, 2297582 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:40,049][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 79.40% examples, 2316213 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:40,533][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5774537 effective words) took 2.5s, 2321652 effective words/s
[2023-02-07 19:29:40,534][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86618055 effective words) took 39.5s, 2193057 effective words/s', 'datetime': '2023-02-07T19:29:40.534009', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:29:40.535 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:29:44,207][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192832-c2i8t8qx/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:29:44.207399', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:29:44,208][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:29:44,316][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192832-c2i8t8qx/files/../tmp/embedding_model.pt
2023-02-07 19:29:44.317 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:29:46.049 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:29:46.664 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:29:48.347 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0354364302368098, 'test_mae': 0.7791642071736371, 'test_r2': -2.36286258904961}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.46
wandb: percentage 0.31676
wandb:   test_mae 0.77916
wandb:   test_mse 1.03544
wandb:    test_r2 -2.36286
wandb: 
wandb: üöÄ View run drawn-sweep-45 at: https://wandb.ai/xiaoqiz/mof2vec/runs/c2i8t8qx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_192832-c2i8t8qx/logs
wandb: Agent Starting Run: ds9xz7ij with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 645
wandb: 	model.gensim.alpha: 0.02350377242178959
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.47715282462778064
wandb: 	model.gensim.vector_size: 90
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.09303748272120112
wandb: 	model.sklearn.max_depth: 15
wandb: 	model.sklearn.min_child_weight: 0.06474550610424494
wandb: 	model.sklearn.n_estimators: 4389
wandb: 	model.sklearn.num_leaves: 442
wandb: 	model.sklearn.reg_alpha: 0.007691793321272736
wandb: 	model.sklearn.reg_lambda: 0.2724434806909613
wandb: 	model.sklearn.subsample: 0.784168618255858
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193007-ds9xz7ij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-46
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/ds9xz7ij
2023-02-07 19:30:16.240 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:30:16.240 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 645 for sweep.
2023-02-07 19:30:16.241 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.02350377242178959 for sweep.
2023-02-07 19:30:16.241 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:30:16.241 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 19:30:16.242 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.47715282462778064 for sweep.
2023-02-07 19:30:16.242 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 90 for sweep.
2023-02-07 19:30:16.243 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 19:30:16.243 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.09303748272120112 for sweep.
2023-02-07 19:30:16.243 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 15 for sweep.
2023-02-07 19:30:16.243 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.06474550610424494 for sweep.
2023-02-07 19:30:16.244 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4389 for sweep.
2023-02-07 19:30:16.244 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 442 for sweep.
2023-02-07 19:30:16.244 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.007691793321272736 for sweep.
2023-02-07 19:30:16.244 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.2724434806909613 for sweep.
2023-02-07 19:30:16.245 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.784168618255858 for sweep.
2023-02-07 19:30:16.245 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:30:16.252 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193007-ds9xz7ij/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 645, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 90, 'window': 8, 'min_count': 6, 'dm': 0, 'sample': 0.47715282462778064, 'workers': 4, 'alpha': 0.02350377242178959, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4389, 'max_depth': 15, 'num_leaves': 442, 'reg_alpha': 0.007691793321272736, 'reg_lambda': 0.2724434806909613, 'subsample': 0.784168618255858, 'min_child_weight': 0.06474550610424494, 'n_jobs': 4, 'learning_rate': 0.09303748272120112}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:25, 129.69it/s]  1%|          | 30/3257 [00:00<00:21, 149.00it/s]  1%|‚ñè         | 46/3257 [00:00<00:21, 152.88it/s]  2%|‚ñè         | 62/3257 [00:00<00:21, 151.42it/s]  2%|‚ñè         | 80/3257 [00:00<00:19, 160.11it/s]  3%|‚ñé         | 97/3257 [00:00<00:20, 155.15it/s]  3%|‚ñé         | 113/3257 [00:00<00:20, 151.03it/s]  4%|‚ñç         | 129/3257 [00:00<00:20, 153.44it/s]  5%|‚ñç         | 147/3257 [00:00<00:19, 159.59it/s]  5%|‚ñå         | 163/3257 [00:01<00:20, 148.03it/s]  5%|‚ñå         | 179/3257 [00:01<00:20, 151.17it/s]  6%|‚ñå         | 197/3257 [00:01<00:19, 156.54it/s]  7%|‚ñã         | 216/3257 [00:01<00:18, 163.30it/s]  7%|‚ñã         | 236/3257 [00:01<00:17, 171.60it/s]  8%|‚ñä         | 254/3257 [00:01<00:18, 161.64it/s]  8%|‚ñä         | 271/3257 [00:01<00:19, 156.99it/s]  9%|‚ñâ         | 292/3257 [00:01<00:17, 169.42it/s] 10%|‚ñâ         | 310/3257 [00:01<00:18, 163.25it/s] 10%|‚ñà         | 328/3257 [00:02<00:18, 161.62it/s] 11%|‚ñà         | 345/3257 [00:02<00:18, 156.47it/s] 11%|‚ñà         | 363/3257 [00:02<00:18, 160.47it/s] 12%|‚ñà‚ñè        | 380/3257 [00:02<00:19, 148.27it/s] 12%|‚ñà‚ñè        | 396/3257 [00:02<00:19, 146.52it/s] 13%|‚ñà‚ñé        | 414/3257 [00:02<00:18, 152.43it/s] 13%|‚ñà‚ñé        | 430/3257 [00:02<00:21, 128.68it/s] 14%|‚ñà‚ñé        | 445/3257 [00:02<00:21, 133.26it/s] 14%|‚ñà‚ñç        | 459/3257 [00:03<00:20, 134.26it/s] 15%|‚ñà‚ñç        | 475/3257 [00:03<00:20, 138.06it/s] 15%|‚ñà‚ñå        | 490/3257 [00:03<00:19, 139.99it/s] 16%|‚ñà‚ñå        | 509/3257 [00:03<00:17, 153.00it/s] 16%|‚ñà‚ñå        | 525/3257 [00:03<00:18, 146.52it/s] 17%|‚ñà‚ñã        | 540/3257 [00:03<00:18, 147.32it/s] 17%|‚ñà‚ñã        | 555/3257 [00:03<00:18, 146.25it/s] 18%|‚ñà‚ñä        | 570/3257 [00:03<00:20, 133.22it/s] 18%|‚ñà‚ñä        | 584/3257 [00:03<00:20, 128.76it/s] 18%|‚ñà‚ñä        | 600/3257 [00:04<00:19, 136.16it/s] 19%|‚ñà‚ñâ        | 619/3257 [00:04<00:17, 150.57it/s] 19%|‚ñà‚ñâ        | 635/3257 [00:04<00:17, 149.04it/s] 20%|‚ñà‚ñâ        | 651/3257 [00:04<00:18, 139.13it/s] 20%|‚ñà‚ñà        | 666/3257 [00:04<00:19, 131.71it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:19, 131.68it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:04<00:18, 135.74it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:04<00:17, 148.99it/s] 23%|‚ñà‚ñà‚ñé       | 733/3257 [00:04<00:17, 140.40it/s] 23%|‚ñà‚ñà‚ñé       | 748/3257 [00:05<00:18, 136.13it/s] 23%|‚ñà‚ñà‚ñé       | 765/3257 [00:05<00:17, 144.65it/s] 24%|‚ñà‚ñà‚ñç       | 780/3257 [00:05<00:18, 136.68it/s] 24%|‚ñà‚ñà‚ñç       | 795/3257 [00:05<00:17, 139.15it/s] 25%|‚ñà‚ñà‚ñç       | 810/3257 [00:05<00:17, 140.50it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:05<00:18, 132.78it/s] 26%|‚ñà‚ñà‚ñå       | 839/3257 [00:05<00:17, 134.53it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:05<00:18, 129.30it/s] 27%|‚ñà‚ñà‚ñã       | 869/3257 [00:05<00:17, 135.40it/s] 27%|‚ñà‚ñà‚ñã       | 883/3257 [00:06<00:17, 134.80it/s] 28%|‚ñà‚ñà‚ñä       | 898/3257 [00:06<00:17, 137.54it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:06<00:17, 136.61it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:06<00:16, 143.33it/s] 29%|‚ñà‚ñà‚ñâ       | 946/3257 [00:06<00:15, 144.67it/s] 30%|‚ñà‚ñà‚ñâ       | 961/3257 [00:06<00:15, 144.51it/s] 30%|‚ñà‚ñà‚ñà       | 978/3257 [00:06<00:15, 148.74it/s] 30%|‚ñà‚ñà‚ñà       | 993/3257 [00:06<00:16, 140.06it/s] 31%|‚ñà‚ñà‚ñà       | 1008/3257 [00:06<00:16, 135.13it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:07<00:15, 141.61it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1040/3257 [00:07<00:27, 79.89it/s]  32%|‚ñà‚ñà‚ñà‚ñè      | 1053/3257 [00:07<00:24, 88.49it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1068/3257 [00:07<00:21, 100.14it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1081/3257 [00:07<00:20, 106.73it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:07<00:19, 111.98it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1111/3257 [00:07<00:16, 126.38it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1125/3257 [00:08<00:17, 124.72it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:08<00:16, 126.49it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1153/3257 [00:08<00:16, 127.98it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:08<00:15, 136.41it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1184/3257 [00:08<00:16, 127.98it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1198/3257 [00:08<00:16, 127.58it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1211/3257 [00:08<00:16, 124.38it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1228/3257 [00:08<00:14, 136.46it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:08<00:14, 137.71it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:09<00:14, 135.67it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:09<00:14, 136.54it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1285/3257 [00:09<00:15, 124.31it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1299/3257 [00:09<00:15, 127.70it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:09<00:14, 130.54it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:09<00:14, 134.02it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1345/3257 [00:09<00:13, 143.16it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1360/3257 [00:09<00:13, 138.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1374/3257 [00:09<00:14, 133.71it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:10<00:14, 132.33it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1405/3257 [00:10<00:12, 142.61it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:10<00:12, 151.05it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:10<00:12, 151.17it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1459/3257 [00:10<00:10, 164.45it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1476/3257 [00:10<00:11, 161.04it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1493/3257 [00:10<00:10, 162.06it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:10<00:10, 166.04it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1528/3257 [00:10<00:11, 147.76it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1544/3257 [00:11<00:12, 139.97it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1559/3257 [00:11<00:12, 140.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:11<00:11, 142.97it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1589/3257 [00:11<00:11, 141.25it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1605/3257 [00:11<00:11, 145.80it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:11<00:11, 146.91it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:11<00:11, 142.26it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:11<00:11, 140.07it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1665/3257 [00:11<00:11, 138.10it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1679/3257 [00:12<00:11, 138.41it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1693/3257 [00:12<00:11, 137.68it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1709/3257 [00:12<00:10, 143.44it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1725/3257 [00:12<00:10, 146.93it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1740/3257 [00:12<00:11, 128.88it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1757/3257 [00:12<00:10, 138.30it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1774/3257 [00:12<00:10, 142.00it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:12<00:09, 149.25it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1808/3257 [00:12<00:10, 137.59it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:13<00:10, 142.98it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1843/3257 [00:13<00:09, 148.74it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1859/3257 [00:13<00:09, 144.47it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1877/3257 [00:13<00:09, 152.57it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1893/3257 [00:13<00:09, 142.07it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1911/3257 [00:13<00:08, 149.74it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1927/3257 [00:13<00:09, 143.98it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1946/3257 [00:13<00:08, 156.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:13<00:07, 164.46it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:14<00:07, 159.44it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:14<00:07, 158.51it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2015/3257 [00:14<00:07, 156.24it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:14<00:07, 162.38it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2050/3257 [00:14<00:08, 148.43it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2066/3257 [00:14<00:08, 143.42it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:14<00:08, 146.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2098/3257 [00:14<00:08, 143.50it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2116/3257 [00:14<00:07, 152.33it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:15<00:08, 137.90it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2147/3257 [00:15<00:08, 134.07it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2164/3257 [00:15<00:07, 143.23it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2180/3257 [00:15<00:07, 145.43it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2195/3257 [00:15<00:07, 146.56it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2210/3257 [00:15<00:07, 137.19it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2226/3257 [00:15<00:07, 143.29it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2241/3257 [00:15<00:07, 138.44it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2257/3257 [00:15<00:06, 143.62it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2272/3257 [00:16<00:07, 133.59it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2289/3257 [00:16<00:06, 141.31it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2304/3257 [00:16<00:06, 137.12it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2323/3257 [00:16<00:06, 150.42it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2340/3257 [00:16<00:05, 155.84it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:16<00:05, 160.71it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2377/3257 [00:16<00:05, 159.91it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2396/3257 [00:16<00:05, 167.17it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2413/3257 [00:16<00:05, 155.51it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2429/3257 [00:17<00:10, 79.91it/s]  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2442/3257 [00:17<00:09, 87.22it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2457/3257 [00:17<00:08, 98.87it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:17<00:06, 115.32it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2491/3257 [00:17<00:06, 124.26it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2510/3257 [00:17<00:05, 140.08it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2526/3257 [00:18<00:05, 143.40it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2542/3257 [00:18<00:04, 147.79it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2558/3257 [00:18<00:04, 145.89it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2574/3257 [00:18<00:04, 137.27it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2589/3257 [00:18<00:05, 133.27it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2608/3257 [00:18<00:04, 146.61it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2628/3257 [00:18<00:03, 159.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2645/3257 [00:18<00:04, 151.15it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2661/3257 [00:18<00:04, 141.40it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2677/3257 [00:19<00:03, 145.79it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:19<00:03, 144.22it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:19<00:04, 132.03it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2724/3257 [00:19<00:03, 136.56it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2744/3257 [00:19<00:03, 151.07it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2760/3257 [00:19<00:03, 151.60it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2776/3257 [00:19<00:03, 142.59it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:19<00:02, 155.31it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2811/3257 [00:19<00:02, 154.30it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2827/3257 [00:20<00:03, 142.22it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:20<00:02, 142.26it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2862/3257 [00:20<00:02, 156.34it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2882/3257 [00:20<00:02, 166.08it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2899/3257 [00:20<00:02, 151.58it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2915/3257 [00:20<00:02, 152.09it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2931/3257 [00:20<00:02, 148.46it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:20<00:02, 145.29it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2962/3257 [00:21<00:02, 141.75it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2977/3257 [00:21<00:02, 139.51it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2992/3257 [00:21<00:01, 137.80it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:21<00:01, 149.88it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3028/3257 [00:21<00:01, 148.57it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3047/3257 [00:21<00:01, 159.81it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3066/3257 [00:21<00:01, 167.03it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3083/3257 [00:21<00:01, 161.40it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3100/3257 [00:21<00:00, 158.75it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3119/3257 [00:22<00:00, 165.95it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3136/3257 [00:22<00:00, 157.80it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3152/3257 [00:22<00:00, 150.68it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3168/3257 [00:22<00:00, 152.57it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3184/3257 [00:22<00:00, 145.79it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:22<00:00, 154.76it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3219/3257 [00:22<00:00, 145.76it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3238/3257 [00:22<00:00, 157.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3254/3257 [00:22<00:00, 155.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 142.05it/s]
2023-02-07 19:30:40.174 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:30:40,176][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d90,n5,mc6,s0.477153,t4>', 'datetime': '2023-02-07T19:30:40.176200', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:30:40,176][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:30:40,176][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:30:40,811][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:30:40,812][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:30:40,880][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 20659 unique words (48.38% of original 42701, drops 22042)', 'datetime': '2023-02-07T19:30:40.880642', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:30:40,881][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 5765964 word corpus (99.02% of original 5822992, drops 57028)', 'datetime': '2023-02-07T19:30:40.881098', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:30:40,966][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:30:40,972][gensim.models.word2vec][INFO] - sample=0.477153 downsamples 0 most-common words
[2023-02-07 19:30:40,972][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5765964 word corpus (100.0%% of prior 5765964)', 'datetime': '2023-02-07T19:30:40.972881', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:30:41,111][gensim.models.word2vec][INFO] - estimated required memory for 20659 words and 90 dimensions: 27027900 bytes
[2023-02-07 19:30:41,112][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:30:41,122][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 20659 vocabulary and 90 features, using sg=1 hs=0 sample=0.47715282462778064 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T19:30:41.122159', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:30:42,125][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 42.09% examples, 2484755 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:43,125][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 87.26% examples, 2527356 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:43,391][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5739976 effective words) took 2.3s, 2532891 effective words/s
[2023-02-07 19:30:44,393][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 46.61% examples, 2716251 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:45,400][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 93.74% examples, 2691953 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:45,521][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5739976 effective words) took 2.1s, 2696251 effective words/s
[2023-02-07 19:30:46,524][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 46.64% examples, 2725138 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:47,524][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 95.00% examples, 2732558 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:47,623][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5739976 effective words) took 2.1s, 2733185 effective words/s
[2023-02-07 19:30:48,625][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 46.76% examples, 2733883 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:49,632][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 95.18% examples, 2727171 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:49,725][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5739976 effective words) took 2.1s, 2732761 effective words/s
[2023-02-07 19:30:50,732][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 47.10% examples, 2744191 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:51,738][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 96.56% examples, 2761133 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:51,801][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5739976 effective words) took 2.1s, 2767339 effective words/s
[2023-02-07 19:30:52,805][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 48.45% examples, 2835590 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:53,807][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 99.72% examples, 2853887 words/s, in_qsize 2, out_qsize 1
[2023-02-07 19:30:53,809][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5739976 effective words) took 2.0s, 2860878 effective words/s
[2023-02-07 19:30:54,812][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 48.45% examples, 2839288 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:55,813][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 99.36% examples, 2849003 words/s, in_qsize 5, out_qsize 0
[2023-02-07 19:30:55,823][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5739976 effective words) took 2.0s, 2852332 effective words/s
[2023-02-07 19:30:56,828][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 47.74% examples, 2794236 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:57,828][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 97.54% examples, 2800761 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:57,873][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5739976 effective words) took 2.0s, 2801704 effective words/s
[2023-02-07 19:30:58,875][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 48.08% examples, 2822398 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:59,878][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 98.34% examples, 2821219 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:30:59,905][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5739976 effective words) took 2.0s, 2827194 effective words/s
[2023-02-07 19:31:00,909][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 47.90% examples, 2801970 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:01,915][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 98.89% examples, 2831080 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:01,929][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5739976 effective words) took 2.0s, 2838310 effective words/s
[2023-02-07 19:31:02,934][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 48.97% examples, 2863143 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:03,931][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5739976 effective words) took 2.0s, 2871468 effective words/s
[2023-02-07 19:31:04,933][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 48.33% examples, 2831122 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:05,937][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 98.34% examples, 2817411 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:05,965][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5739976 effective words) took 2.0s, 2823190 effective words/s
[2023-02-07 19:31:06,971][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 47.90% examples, 2796141 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:31:07,975][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 97.11% examples, 2779745 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:08,027][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5739976 effective words) took 2.1s, 2786076 effective words/s
[2023-02-07 19:31:09,029][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 47.44% examples, 2782736 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:10,034][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 97.11% examples, 2784357 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:10,084][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5739976 effective words) took 2.1s, 2792373 effective words/s
[2023-02-07 19:31:11,091][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 47.90% examples, 2794103 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:12,093][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 97.67% examples, 2799780 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:12,133][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5739976 effective words) took 2.0s, 2803540 effective words/s
[2023-02-07 19:31:12,133][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86099640 effective words) took 31.0s, 2776402 effective words/s', 'datetime': '2023-02-07T19:31:12.133855', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:31:12.134 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:31:15,668][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193007-ds9xz7ij/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:31:15.668689', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:31:15,669][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:31:15,714][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193007-ds9xz7ij/files/../tmp/embedding_model.pt
2023-02-07 19:31:15.715 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:31:17.039 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:31:17.514 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:31:30.927 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0855126917851503, 'test_mae': 0.7727737588110877, 'test_r2': -2.106170929330701}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.91
wandb: percentage 0.51619
wandb:   test_mae 0.77277
wandb:   test_mse 1.08551
wandb:    test_r2 -2.10617
wandb: 
wandb: üöÄ View run cosmic-sweep-46 at: https://wandb.ai/xiaoqiz/mof2vec/runs/ds9xz7ij
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_193007-ds9xz7ij/logs
wandb: Agent Starting Run: fooi0ocn with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 815
wandb: 	model.gensim.alpha: 0.004401525741403619
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.6802881734619014
wandb: 	model.gensim.vector_size: 452
wandb: 	model.gensim.window: 4
wandb: 	model.sklearn.learning_rate: 0.11076918552990764
wandb: 	model.sklearn.max_depth: 34
wandb: 	model.sklearn.min_child_weight: 0.012399522347790674
wandb: 	model.sklearn.n_estimators: 2204
wandb: 	model.sklearn.num_leaves: 397
wandb: 	model.sklearn.reg_alpha: 0.003716648600927083
wandb: 	model.sklearn.reg_lambda: 0.2721476009055209
wandb: 	model.sklearn.subsample: 0.6684000517291377
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193142-fooi0ocn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-47
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/fooi0ocn
2023-02-07 19:31:51.176 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:31:51.177 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 815 for sweep.
2023-02-07 19:31:51.178 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.004401525741403619 for sweep.
2023-02-07 19:31:51.178 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:31:51.178 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 19:31:51.178 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6802881734619014 for sweep.
2023-02-07 19:31:51.179 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 452 for sweep.
2023-02-07 19:31:51.179 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 4 for sweep.
2023-02-07 19:31:51.179 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.11076918552990764 for sweep.
2023-02-07 19:31:51.179 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 34 for sweep.
2023-02-07 19:31:51.180 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.012399522347790674 for sweep.
2023-02-07 19:31:51.180 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2204 for sweep.
2023-02-07 19:31:51.180 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 397 for sweep.
2023-02-07 19:31:51.180 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.003716648600927083 for sweep.
2023-02-07 19:31:51.181 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.2721476009055209 for sweep.
2023-02-07 19:31:51.181 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6684000517291377 for sweep.
2023-02-07 19:31:51.181 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:31:51.189 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193142-fooi0ocn/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 815, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 452, 'window': 4, 'min_count': 6, 'dm': 0, 'sample': 0.6802881734619014, 'workers': 4, 'alpha': 0.004401525741403619, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2204, 'max_depth': 34, 'num_leaves': 397, 'reg_alpha': 0.003716648600927083, 'reg_lambda': 0.2721476009055209, 'subsample': 0.6684000517291377, 'min_child_weight': 0.012399522347790674, 'n_jobs': 4, 'learning_rate': 0.11076918552990764}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 12/3257 [00:00<00:28, 114.76it/s]  1%|          | 27/3257 [00:00<00:24, 130.05it/s]  1%|‚ñè         | 41/3257 [00:00<00:25, 127.81it/s]  2%|‚ñè         | 54/3257 [00:00<00:25, 125.60it/s]  2%|‚ñè         | 67/3257 [00:00<00:25, 126.94it/s]  3%|‚ñé         | 84/3257 [00:00<00:22, 138.77it/s]  3%|‚ñé         | 98/3257 [00:00<00:23, 132.32it/s]  3%|‚ñé         | 112/3257 [00:00<00:24, 126.88it/s]  4%|‚ñç         | 126/3257 [00:00<00:24, 128.92it/s]  4%|‚ñç         | 141/3257 [00:01<00:23, 134.74it/s]  5%|‚ñç         | 156/3257 [00:01<00:22, 138.13it/s]  5%|‚ñå         | 170/3257 [00:01<00:23, 131.39it/s]  6%|‚ñå         | 184/3257 [00:01<00:24, 126.89it/s]  6%|‚ñå         | 199/3257 [00:01<00:23, 132.16it/s]  7%|‚ñã         | 215/3257 [00:01<00:21, 139.32it/s]  7%|‚ñã         | 232/3257 [00:01<00:20, 146.03it/s]  8%|‚ñä         | 248/3257 [00:01<00:20, 149.84it/s]  8%|‚ñä         | 264/3257 [00:01<00:20, 142.74it/s]  9%|‚ñâ         | 285/3257 [00:02<00:18, 157.30it/s]  9%|‚ñâ         | 301/3257 [00:02<00:19, 148.59it/s] 10%|‚ñâ         | 316/3257 [00:02<00:19, 148.49it/s] 10%|‚ñà         | 334/3257 [00:02<00:18, 155.85it/s] 11%|‚ñà         | 350/3257 [00:02<00:19, 149.18it/s] 11%|‚ñà         | 366/3257 [00:02<00:19, 149.60it/s] 12%|‚ñà‚ñè        | 382/3257 [00:02<00:20, 140.05it/s] 12%|‚ñà‚ñè        | 397/3257 [00:02<00:20, 138.06it/s] 13%|‚ñà‚ñé        | 412/3257 [00:02<00:20, 140.50it/s] 13%|‚ñà‚ñé        | 427/3257 [00:03<00:23, 119.70it/s] 14%|‚ñà‚ñé        | 441/3257 [00:03<00:22, 123.78it/s] 14%|‚ñà‚ñç        | 456/3257 [00:03<00:21, 130.20it/s] 14%|‚ñà‚ñç        | 472/3257 [00:03<00:20, 138.19it/s] 15%|‚ñà‚ñç        | 487/3257 [00:03<00:20, 134.59it/s] 15%|‚ñà‚ñå        | 504/3257 [00:03<00:19, 144.08it/s] 16%|‚ñà‚ñå        | 522/3257 [00:03<00:18, 147.80it/s] 16%|‚ñà‚ñã        | 537/3257 [00:03<00:18, 145.79it/s] 17%|‚ñà‚ñã        | 552/3257 [00:03<00:18, 144.38it/s] 17%|‚ñà‚ñã        | 567/3257 [00:04<00:20, 129.88it/s] 18%|‚ñà‚ñä        | 581/3257 [00:04<00:21, 123.80it/s] 18%|‚ñà‚ñä        | 598/3257 [00:04<00:19, 135.66it/s] 19%|‚ñà‚ñâ        | 613/3257 [00:04<00:19, 138.96it/s] 19%|‚ñà‚ñâ        | 628/3257 [00:04<00:30, 85.22it/s]  20%|‚ñà‚ñâ        | 643/3257 [00:04<00:27, 96.77it/s] 20%|‚ñà‚ñà        | 656/3257 [00:05<00:26, 97.40it/s] 21%|‚ñà‚ñà        | 671/3257 [00:05<00:23, 109.06it/s] 21%|‚ñà‚ñà        | 684/3257 [00:05<00:23, 110.40it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:05<00:21, 117.21it/s] 22%|‚ñà‚ñà‚ñè       | 716/3257 [00:05<00:19, 131.58it/s] 22%|‚ñà‚ñà‚ñè       | 730/3257 [00:05<00:21, 118.82it/s] 23%|‚ñà‚ñà‚ñé       | 743/3257 [00:05<00:21, 119.19it/s] 23%|‚ñà‚ñà‚ñé       | 758/3257 [00:05<00:19, 127.02it/s] 24%|‚ñà‚ñà‚ñé       | 772/3257 [00:05<00:19, 128.44it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:06<00:19, 124.75it/s] 25%|‚ñà‚ñà‚ñç       | 801/3257 [00:06<00:18, 130.77it/s] 25%|‚ñà‚ñà‚ñå       | 815/3257 [00:06<00:19, 125.97it/s] 25%|‚ñà‚ñà‚ñå       | 828/3257 [00:06<00:20, 120.92it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:06<00:21, 114.85it/s] 26%|‚ñà‚ñà‚ñå       | 854/3257 [00:06<00:20, 118.10it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:06<00:19, 121.74it/s] 27%|‚ñà‚ñà‚ñã       | 881/3257 [00:06<00:19, 121.60it/s] 27%|‚ñà‚ñà‚ñã       | 895/3257 [00:06<00:18, 124.71it/s] 28%|‚ñà‚ñà‚ñä       | 912/3257 [00:07<00:17, 134.74it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:07<00:16, 138.16it/s] 29%|‚ñà‚ñà‚ñâ       | 942/3257 [00:07<00:17, 135.94it/s] 29%|‚ñà‚ñà‚ñâ       | 958/3257 [00:07<00:16, 141.27it/s] 30%|‚ñà‚ñà‚ñâ       | 973/3257 [00:07<00:16, 137.30it/s] 30%|‚ñà‚ñà‚ñà       | 987/3257 [00:07<00:17, 132.09it/s] 31%|‚ñà‚ñà‚ñà       | 1001/3257 [00:07<00:17, 131.99it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:07<00:17, 129.08it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1028/3257 [00:07<00:17, 125.15it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:08<00:18, 122.13it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1056/3257 [00:08<00:17, 126.58it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1071/3257 [00:08<00:16, 132.09it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1085/3257 [00:08<00:16, 128.66it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1098/3257 [00:08<00:16, 127.85it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1114/3257 [00:08<00:15, 135.79it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1128/3257 [00:08<00:16, 125.98it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1142/3257 [00:08<00:16, 129.17it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1157/3257 [00:08<00:15, 134.40it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:09<00:15, 133.05it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:09<00:16, 123.96it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1198/3257 [00:09<00:16, 122.81it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1211/3257 [00:09<00:17, 119.48it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1227/3257 [00:09<00:15, 129.59it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:09<00:14, 134.38it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1256/3257 [00:09<00:15, 132.76it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:09<00:14, 135.06it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1285/3257 [00:09<00:16, 122.29it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1299/3257 [00:10<00:15, 126.16it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1314/3257 [00:10<00:14, 131.63it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:10<00:14, 132.91it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1345/3257 [00:10<00:13, 141.89it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1360/3257 [00:10<00:13, 137.08it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1374/3257 [00:10<00:14, 132.13it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:10<00:14, 130.64it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1405/3257 [00:10<00:13, 140.56it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:10<00:12, 147.83it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1438/3257 [00:10<00:12, 146.06it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1458/3257 [00:11<00:11, 159.12it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:11<00:11, 156.71it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1490/3257 [00:11<00:11, 156.01it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1508/3257 [00:11<00:10, 162.64it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1525/3257 [00:11<00:12, 142.27it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1540/3257 [00:11<00:12, 139.36it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:11<00:12, 133.03it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1572/3257 [00:11<00:12, 139.99it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1587/3257 [00:12<00:12, 138.35it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1604/3257 [00:12<00:11, 146.17it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:12<00:11, 146.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:12<00:11, 140.27it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1649/3257 [00:12<00:12, 133.55it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1663/3257 [00:12<00:11, 132.97it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:12<00:12, 130.88it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:12<00:11, 130.78it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:12<00:11, 138.77it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1722/3257 [00:13<00:10, 141.62it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1737/3257 [00:13<00:12, 123.58it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1752/3257 [00:13<00:11, 129.22it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1768/3257 [00:13<00:10, 136.54it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1784/3257 [00:13<00:10, 142.65it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1799/3257 [00:13<00:10, 140.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:13<00:10, 134.77it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:13<00:10, 131.66it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1845/3257 [00:13<00:09, 141.39it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1860/3257 [00:14<00:10, 139.32it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1877/3257 [00:14<00:09, 147.85it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1892/3257 [00:14<00:09, 138.29it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1910/3257 [00:14<00:09, 147.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1925/3257 [00:14<00:09, 142.04it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1945/3257 [00:14<00:08, 154.30it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:14<00:08, 161.36it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:15<00:15, 84.81it/s]  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1998/3257 [00:15<00:12, 97.29it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2012/3257 [00:15<00:11, 104.20it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2030/3257 [00:15<00:10, 119.19it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2045/3257 [00:15<00:10, 119.68it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2059/3257 [00:15<00:10, 115.33it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2075/3257 [00:15<00:09, 126.01it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2090/3257 [00:15<00:08, 131.31it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2105/3257 [00:16<00:08, 131.41it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:16<00:08, 128.73it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:16<00:08, 128.95it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2148/3257 [00:16<00:08, 123.76it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:16<00:08, 130.55it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:16<00:08, 132.74it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2193/3257 [00:16<00:07, 135.85it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2207/3257 [00:16<00:07, 135.82it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2221/3257 [00:16<00:07, 136.78it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2235/3257 [00:16<00:07, 137.67it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2249/3257 [00:17<00:07, 131.95it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2263/3257 [00:17<00:07, 133.23it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2277/3257 [00:17<00:07, 124.39it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2295/3257 [00:17<00:06, 139.54it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2310/3257 [00:17<00:07, 133.43it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2330/3257 [00:17<00:06, 150.36it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2348/3257 [00:17<00:05, 156.96it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2364/3257 [00:17<00:05, 154.24it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2381/3257 [00:17<00:05, 156.56it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:18<00:05, 160.30it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2416/3257 [00:18<00:05, 149.65it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2432/3257 [00:18<00:05, 139.52it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2448/3257 [00:18<00:05, 137.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2467/3257 [00:18<00:05, 150.81it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2483/3257 [00:18<00:05, 149.78it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2500/3257 [00:18<00:04, 155.25it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2516/3257 [00:18<00:04, 156.24it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2532/3257 [00:18<00:04, 156.66it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2548/3257 [00:19<00:04, 152.42it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2564/3257 [00:19<00:04, 138.63it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2579/3257 [00:19<00:05, 130.62it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2593/3257 [00:19<00:05, 131.27it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:19<00:04, 150.62it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2631/3257 [00:19<00:04, 155.84it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2647/3257 [00:19<00:04, 145.72it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2662/3257 [00:19<00:04, 140.79it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2679/3257 [00:20<00:03, 147.61it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:20<00:03, 143.44it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:20<00:04, 129.62it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2724/3257 [00:20<00:03, 134.06it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2742/3257 [00:20<00:03, 146.01it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2758/3257 [00:20<00:03, 147.98it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:20<00:03, 139.71it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2794/3257 [00:20<00:02, 154.83it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2810/3257 [00:20<00:02, 150.69it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2826/3257 [00:21<00:03, 139.88it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2841/3257 [00:21<00:03, 138.14it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2862/3257 [00:21<00:02, 154.59it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2882/3257 [00:21<00:02, 165.18it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2899/3257 [00:21<00:02, 150.19it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2915/3257 [00:21<00:02, 150.79it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2931/3257 [00:21<00:02, 144.84it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2946/3257 [00:21<00:02, 139.49it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2961/3257 [00:21<00:02, 139.47it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:22<00:02, 137.44it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2990/3257 [00:22<00:01, 136.26it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:22<00:01, 154.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3027/3257 [00:22<00:01, 147.31it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3046/3257 [00:22<00:01, 158.67it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3064/3257 [00:22<00:01, 164.40it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3081/3257 [00:22<00:01, 161.13it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3098/3257 [00:22<00:01, 158.90it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:22<00:00, 166.21it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3135/3257 [00:23<00:00, 156.99it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3151/3257 [00:23<00:00, 147.25it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3167/3257 [00:23<00:00, 148.31it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3182/3257 [00:23<00:00, 139.71it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3201/3257 [00:23<00:00, 149.07it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3217/3257 [00:23<00:00, 140.39it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3236/3257 [00:23<00:00, 151.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:23<00:00, 147.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:23<00:00, 136.11it/s]
2023-02-07 19:32:16.247 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:32:16,250][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d452,n5,mc6,s0.680288,t4>', 'datetime': '2023-02-07T19:32:16.250449', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:32:16,251][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:32:16,251][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:32:16,960][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 19:32:16,961][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:32:17,046][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 25857 unique words (47.84% of original 54054, drops 28197)', 'datetime': '2023-02-07T19:32:17.046544', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:32:17,047][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 6477431 word corpus (98.88% of original 6550866, drops 73435)', 'datetime': '2023-02-07T19:32:17.047007', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:32:17,146][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 19:32:17,148][gensim.models.word2vec][INFO] - sample=0.680288 downsamples 0 most-common words
[2023-02-07 19:32:17,148][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6477431 word corpus (100.0%% of prior 6477431)', 'datetime': '2023-02-07T19:32:17.148892', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:32:17,318][gensim.models.word2vec][INFO] - estimated required memory for 25857 words and 452 dimensions: 112967468 bytes
[2023-02-07 19:32:17,318][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:32:17,372][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 25857 vocabulary and 452 features, using sg=1 hs=0 sample=0.6802881734619014 negative=5 window=4 shrink_windows=True', 'datetime': '2023-02-07T19:32:17.372069', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:32:18,379][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 22.60% examples, 1434649 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:19,382][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 44.89% examples, 1465195 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:20,392][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 68.01% examples, 1477732 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:32:21,401][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 92.91% examples, 1491711 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:21,675][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6423064 effective words) took 4.3s, 1493717 effective words/s
[2023-02-07 19:32:22,678][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 25.42% examples, 1626199 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:23,688][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 49.68% examples, 1616081 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:32:24,688][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 75.13% examples, 1626824 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:25,610][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6423064 effective words) took 3.9s, 1633162 effective words/s
[2023-02-07 19:32:26,622][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 25.36% examples, 1603370 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:32:27,627][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 49.80% examples, 1615521 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:28,628][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 74.92% examples, 1618996 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:29,590][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6423064 effective words) took 4.0s, 1614673 effective words/s
[2023-02-07 19:32:30,606][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 19.65% examples, 1213249 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:31,607][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 38.10% examples, 1238668 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:32:32,609][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 57.72% examples, 1255243 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:33,616][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 77.96% examples, 1255460 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:34,622][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 98.34% examples, 1257919 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:34,689][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6423064 effective words) took 5.1s, 1260254 effective words/s
[2023-02-07 19:32:35,699][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 25.30% examples, 1607847 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:32:36,709][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 49.68% examples, 1610897 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:32:37,709][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 74.76% examples, 1615751 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:38,655][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6423064 effective words) took 4.0s, 1620329 effective words/s
[2023-02-07 19:32:39,665][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 25.30% examples, 1609575 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:40,669][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 49.89% examples, 1624352 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:41,676][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 75.35% examples, 1629480 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:42,587][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6423064 effective words) took 3.9s, 1635088 effective words/s
[2023-02-07 19:32:43,591][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 20.29% examples, 1285106 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:44,592][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 39.12% examples, 1277817 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:32:45,595][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 58.83% examples, 1283901 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:46,597][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 79.46% examples, 1289075 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:47,388][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6423064 effective words) took 4.8s, 1338310 effective words/s
[2023-02-07 19:32:48,396][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 25.30% examples, 1612043 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:49,398][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 48.05% examples, 1570703 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:32:50,414][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 68.01% examples, 1474539 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:51,414][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 88.89% examples, 1429132 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:32:51,940][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6423064 effective words) took 4.5s, 1411978 effective words/s
[2023-02-07 19:32:52,943][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 25.30% examples, 1619539 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:53,945][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 50.17% examples, 1640280 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:32:54,948][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 75.59% examples, 1639121 words/s, in_qsize 7, out_qsize 1
[2023-02-07 19:32:55,849][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6423064 effective words) took 3.9s, 1644217 effective words/s
[2023-02-07 19:32:56,851][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 25.67% examples, 1646900 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:57,852][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 50.57% examples, 1654573 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:58,853][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 76.79% examples, 1661964 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:59,696][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6423064 effective words) took 3.8s, 1670489 effective words/s
[2023-02-07 19:33:00,701][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 26.34% examples, 1689300 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:01,701][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 51.49% examples, 1686885 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:02,703][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 77.37% examples, 1670647 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:03,541][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6423064 effective words) took 3.8s, 1671311 effective words/s
[2023-02-07 19:33:04,549][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 26.16% examples, 1676271 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:05,550][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 51.40% examples, 1680087 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:06,555][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 78.02% examples, 1680359 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:07,372][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6423064 effective words) took 3.8s, 1677746 effective words/s
[2023-02-07 19:33:08,374][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 26.16% examples, 1684478 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:09,375][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 51.27% examples, 1678923 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:10,377][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 77.25% examples, 1669490 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:11,211][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6423064 effective words) took 3.8s, 1673686 effective words/s
[2023-02-07 19:33:12,221][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 26.77% examples, 1708988 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:33:13,224][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 52.63% examples, 1715614 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:14,224][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 79.46% examples, 1715881 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:14,975][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6423064 effective words) took 3.8s, 1707357 effective words/s
[2023-02-07 19:33:15,978][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 26.56% examples, 1709330 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:16,985][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 52.23% examples, 1706750 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:17,986][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 78.88% examples, 1703870 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:18,763][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6423064 effective words) took 3.8s, 1696495 effective words/s
[2023-02-07 19:33:18,764][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (96345960 effective words) took 61.4s, 1569366 effective words/s', 'datetime': '2023-02-07T19:33:18.764184', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:33:18.764 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:33:24,890][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193142-fooi0ocn/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:33:24.889925', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:33:24,891][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193142-fooi0ocn/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 19:33:24,941][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193142-fooi0ocn/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 19:33:24,986][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:33:25,017][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193142-fooi0ocn/files/../tmp/embedding_model.pt
2023-02-07 19:33:25.018 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:33:27.751 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:33:28.691 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:33:53.821 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9865980003654822, 'test_mae': 0.7571363957838778, 'test_r2': -2.1500218566477223}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.77
wandb: percentage 0.52165
wandb:   test_mae 0.75714
wandb:   test_mse 0.9866
wandb:    test_r2 -2.15002
wandb: 
wandb: üöÄ View run tough-sweep-47 at: https://wandb.ai/xiaoqiz/mof2vec/runs/fooi0ocn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_193142-fooi0ocn/logs
wandb: Agent Starting Run: hyn95pjy with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 545
wandb: 	model.gensim.alpha: 0.018438457535606204
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.7026706209067723
wandb: 	model.gensim.vector_size: 241
wandb: 	model.gensim.window: 12
wandb: 	model.sklearn.learning_rate: 0.3009119640305091
wandb: 	model.sklearn.max_depth: 51
wandb: 	model.sklearn.min_child_weight: 0.01447278075912483
wandb: 	model.sklearn.n_estimators: 2735
wandb: 	model.sklearn.num_leaves: 368
wandb: 	model.sklearn.reg_alpha: 0.0026061368628594304
wandb: 	model.sklearn.reg_lambda: 0.00746425591492434
wandb: 	model.sklearn.subsample: 0.4556038995926015
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193404-hyn95pjy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-48
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/hyn95pjy
2023-02-07 19:34:12.755 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:34:12.756 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 545 for sweep.
2023-02-07 19:34:12.757 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.018438457535606204 for sweep.
2023-02-07 19:34:12.757 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:34:12.757 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 19:34:12.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7026706209067723 for sweep.
2023-02-07 19:34:12.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 241 for sweep.
2023-02-07 19:34:12.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 12 for sweep.
2023-02-07 19:34:12.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.3009119640305091 for sweep.
2023-02-07 19:34:12.759 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 51 for sweep.
2023-02-07 19:34:12.759 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.01447278075912483 for sweep.
2023-02-07 19:34:12.759 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2735 for sweep.
2023-02-07 19:34:12.759 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 368 for sweep.
2023-02-07 19:34:12.760 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0026061368628594304 for sweep.
2023-02-07 19:34:12.760 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.00746425591492434 for sweep.
2023-02-07 19:34:12.760 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.4556038995926015 for sweep.
2023-02-07 19:34:12.760 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:34:12.767 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193404-hyn95pjy/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 545, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 241, 'window': 12, 'min_count': 7, 'dm': 0, 'sample': 0.7026706209067723, 'workers': 4, 'alpha': 0.018438457535606204, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2735, 'max_depth': 51, 'num_leaves': 368, 'reg_alpha': 0.0026061368628594304, 'reg_lambda': 0.00746425591492434, 'subsample': 0.4556038995926015, 'min_child_weight': 0.01447278075912483, 'n_jobs': 4, 'learning_rate': 0.3009119640305091}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:25, 129.56it/s]  1%|          | 30/3257 [00:00<00:21, 151.29it/s]  1%|‚ñè         | 46/3257 [00:00<00:20, 154.28it/s]  2%|‚ñè         | 62/3257 [00:00<00:21, 150.54it/s]  2%|‚ñè         | 81/3257 [00:00<00:19, 161.67it/s]  3%|‚ñé         | 98/3257 [00:00<00:19, 159.21it/s]  4%|‚ñé         | 114/3257 [00:00<00:20, 155.10it/s]  4%|‚ñç         | 131/3257 [00:00<00:19, 159.58it/s]  5%|‚ñç         | 150/3257 [00:00<00:18, 168.71it/s]  5%|‚ñå         | 167/3257 [00:01<00:19, 159.71it/s]  6%|‚ñå         | 184/3257 [00:01<00:19, 160.34it/s]  6%|‚ñå         | 201/3257 [00:01<00:18, 161.23it/s]  7%|‚ñã         | 223/3257 [00:01<00:17, 176.93it/s]  7%|‚ñã         | 243/3257 [00:01<00:16, 179.71it/s]  8%|‚ñä         | 262/3257 [00:01<00:17, 169.81it/s]  9%|‚ñâ         | 285/3257 [00:01<00:16, 184.32it/s]  9%|‚ñâ         | 304/3257 [00:01<00:16, 177.16it/s] 10%|‚ñâ         | 325/3257 [00:01<00:15, 183.77it/s] 11%|‚ñà         | 344/3257 [00:02<00:16, 172.35it/s] 11%|‚ñà         | 363/3257 [00:02<00:16, 173.96it/s] 12%|‚ñà‚ñè        | 381/3257 [00:02<00:17, 167.22it/s] 12%|‚ñà‚ñè        | 398/3257 [00:02<00:17, 163.97it/s] 13%|‚ñà‚ñé        | 418/3257 [00:02<00:16, 171.60it/s] 13%|‚ñà‚ñé        | 436/3257 [00:02<00:19, 146.25it/s] 14%|‚ñà‚ñç        | 455/3257 [00:02<00:17, 156.45it/s] 15%|‚ñà‚ñç        | 473/3257 [00:02<00:17, 161.37it/s] 15%|‚ñà‚ñå        | 490/3257 [00:02<00:17, 160.43it/s] 16%|‚ñà‚ñå        | 511/3257 [00:03<00:16, 171.06it/s] 16%|‚ñà‚ñå        | 529/3257 [00:03<00:16, 165.91it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:16, 165.13it/s] 17%|‚ñà‚ñã        | 563/3257 [00:03<00:17, 156.34it/s] 18%|‚ñà‚ñä        | 579/3257 [00:03<00:17, 152.98it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:16, 161.40it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:16, 161.70it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:03<00:15, 167.54it/s] 20%|‚ñà‚ñà        | 656/3257 [00:04<00:16, 157.22it/s] 21%|‚ñà‚ñà        | 675/3257 [00:04<00:15, 165.58it/s] 21%|‚ñà‚ñà        | 692/3257 [00:04<00:16, 159.05it/s] 22%|‚ñà‚ñà‚ñè       | 712/3257 [00:04<00:15, 168.78it/s] 22%|‚ñà‚ñà‚ñè       | 730/3257 [00:04<00:15, 158.70it/s] 23%|‚ñà‚ñà‚ñé       | 747/3257 [00:04<00:15, 158.19it/s] 24%|‚ñà‚ñà‚ñé       | 766/3257 [00:04<00:15, 165.70it/s] 24%|‚ñà‚ñà‚ñç       | 783/3257 [00:04<00:16, 153.75it/s] 25%|‚ñà‚ñà‚ñç       | 803/3257 [00:04<00:14, 165.38it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:15, 155.87it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:05<00:16, 147.93it/s] 26%|‚ñà‚ñà‚ñå       | 852/3257 [00:05<00:16, 144.51it/s] 27%|‚ñà‚ñà‚ñã       | 869/3257 [00:05<00:16, 148.62it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:05<00:16, 147.28it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:14, 162.36it/s] 28%|‚ñà‚ñà‚ñä       | 923/3257 [00:05<00:14, 166.34it/s] 29%|‚ñà‚ñà‚ñâ       | 940/3257 [00:05<00:14, 163.31it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:05<00:13, 170.13it/s] 30%|‚ñà‚ñà‚ñâ       | 977/3257 [00:05<00:13, 170.93it/s] 31%|‚ñà‚ñà‚ñà       | 995/3257 [00:06<00:14, 156.16it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:06<00:14, 156.87it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:06<00:14, 153.04it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1043/3257 [00:06<00:14, 149.89it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1060/3257 [00:06<00:14, 154.82it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:13, 157.69it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:06<00:13, 160.46it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:06<00:12, 165.22it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1132/3257 [00:07<00:13, 154.67it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1148/3257 [00:07<00:13, 152.64it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:12, 164.31it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:07<00:13, 156.62it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1203/3257 [00:07<00:13, 147.63it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:07<00:13, 150.03it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:07<00:12, 166.68it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:08<00:20, 99.30it/s]  39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:08<00:17, 110.85it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1289/3257 [00:08<00:16, 116.48it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1307/3257 [00:08<00:14, 130.39it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1325/3257 [00:08<00:13, 140.94it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:08<00:12, 153.21it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1361/3257 [00:08<00:12, 153.03it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1378/3257 [00:08<00:12, 153.63it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1394/3257 [00:08<00:11, 155.32it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1414/3257 [00:08<00:11, 167.40it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1434/3257 [00:09<00:10, 173.57it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1455/3257 [00:09<00:09, 182.92it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1475/3257 [00:09<00:09, 184.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1494/3257 [00:09<00:09, 185.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:09<00:09, 185.32it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1532/3257 [00:09<00:10, 172.30it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:09<00:10, 165.28it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1567/3257 [00:09<00:10, 161.55it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1584/3257 [00:09<00:10, 160.05it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1604/3257 [00:10<00:09, 168.64it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1621/3257 [00:10<00:09, 168.76it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1638/3257 [00:10<00:09, 165.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1655/3257 [00:10<00:09, 162.57it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1672/3257 [00:10<00:10, 157.82it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1689/3257 [00:10<00:09, 160.67it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:10<00:09, 164.66it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1727/3257 [00:10<00:08, 171.38it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:10<00:09, 154.07it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1764/3257 [00:11<00:09, 161.94it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1784/3257 [00:11<00:08, 171.36it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:11<00:08, 172.83it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:11<00:08, 172.45it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1839/3257 [00:11<00:08, 170.31it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1857/3257 [00:11<00:08, 172.23it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1878/3257 [00:11<00:07, 182.16it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:11<00:07, 174.39it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:11<00:07, 176.79it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1936/3257 [00:12<00:07, 183.14it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1958/3257 [00:12<00:06, 193.76it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1978/3257 [00:12<00:06, 186.79it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1997/3257 [00:12<00:06, 187.15it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2016/3257 [00:12<00:06, 182.35it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2036/3257 [00:12<00:06, 186.10it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:12<00:07, 167.29it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2073/3257 [00:12<00:07, 168.11it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:12<00:06, 169.89it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2109/3257 [00:13<00:06, 167.29it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2126/3257 [00:13<00:07, 158.14it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:13<00:07, 153.00it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2162/3257 [00:13<00:06, 161.83it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:13<00:06, 165.03it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2200/3257 [00:13<00:06, 171.53it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2218/3257 [00:13<00:06, 165.12it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:13<00:06, 168.20it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2253/3257 [00:13<00:06, 166.08it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:14<00:06, 160.36it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2289/3257 [00:14<00:05, 167.22it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2306/3257 [00:14<00:05, 165.64it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2328/3257 [00:14<00:05, 181.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2351/3257 [00:14<00:04, 193.70it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2371/3257 [00:14<00:04, 187.81it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2393/3257 [00:14<00:04, 195.74it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2413/3257 [00:14<00:04, 181.35it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2432/3257 [00:14<00:04, 171.17it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2450/3257 [00:15<00:04, 168.18it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2474/3257 [00:15<00:04, 187.54it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2494/3257 [00:15<00:04, 187.70it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2516/3257 [00:15<00:03, 194.63it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2537/3257 [00:15<00:03, 197.79it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2557/3257 [00:15<00:03, 183.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2576/3257 [00:15<00:03, 171.55it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2594/3257 [00:15<00:03, 168.59it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2619/3257 [00:15<00:03, 188.33it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2639/3257 [00:16<00:06, 98.15it/s]  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:16<00:05, 106.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:16<00:04, 121.42it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2692/3257 [00:16<00:04, 136.05it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:16<00:04, 132.36it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2729/3257 [00:16<00:03, 148.06it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2749/3257 [00:16<00:03, 160.53it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2767/3257 [00:17<00:02, 164.27it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2785/3257 [00:17<00:02, 167.36it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2806/3257 [00:17<00:02, 175.08it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2825/3257 [00:17<00:02, 164.42it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2843/3257 [00:17<00:02, 167.38it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2866/3257 [00:17<00:02, 184.51it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2887/3257 [00:17<00:01, 190.17it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:17<00:01, 178.36it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:17<00:01, 182.38it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:18<00:01, 175.50it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:18<00:01, 175.94it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:18<00:01, 167.13it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:18<00:01, 175.62it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3022/3257 [00:18<00:01, 172.55it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3045/3257 [00:18<00:01, 186.86it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3066/3257 [00:18<00:00, 192.65it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3086/3257 [00:18<00:00, 186.55it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3107/3257 [00:18<00:00, 191.68it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:19<00:00, 193.26it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3147/3257 [00:19<00:00, 177.44it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:19<00:00, 175.83it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3184/3257 [00:19<00:00, 168.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3205/3257 [00:19<00:00, 179.07it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3224/3257 [00:19<00:00, 172.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3245/3257 [00:19<00:00, 182.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 164.45it/s]
2023-02-07 19:34:33.393 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:34:33,394][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d241,n5,mc7,s0.702671,t4>', 'datetime': '2023-02-07T19:34:33.394535', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:34:33,395][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:34:33,395][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:34:33,928][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:34:33,928][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:34:33,974][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 14137 unique words (44.45% of original 31803, drops 17666)', 'datetime': '2023-02-07T19:34:33.974295', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:34:33,974][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 5044802 word corpus (99.01% of original 5095118, drops 50316)', 'datetime': '2023-02-07T19:34:33.974755', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:34:34,028][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:34:34,029][gensim.models.word2vec][INFO] - sample=0.702671 downsamples 0 most-common words
[2023-02-07 19:34:34,029][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5044802 word corpus (100.0%% of prior 5044802)', 'datetime': '2023-02-07T19:34:34.029701', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:34:34,122][gensim.models.word2vec][INFO] - estimated required memory for 14137 words and 241 dimensions: 38115784 bytes
[2023-02-07 19:34:34,123][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:34:34,142][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14137 vocabulary and 241 features, using sg=1 hs=0 sample=0.7026706209067723 negative=5 window=12 shrink_windows=True', 'datetime': '2023-02-07T19:34:34.142543', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:34:35,147][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 40.84% examples, 2110345 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:36,149][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 84.28% examples, 2136909 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:36,493][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5036861 effective words) took 2.3s, 2144802 effective words/s
[2023-02-07 19:34:37,496][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 44.73% examples, 2299854 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:38,497][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 90.33% examples, 2285364 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:38,694][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5036861 effective words) took 2.2s, 2290131 effective words/s
[2023-02-07 19:34:39,698][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 45.96% examples, 2351627 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:40,699][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 92.78% examples, 2349840 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:40,843][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5036861 effective words) took 2.1s, 2345902 effective words/s
[2023-02-07 19:34:41,847][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 44.73% examples, 2299610 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:42,848][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 91.00% examples, 2306591 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:43,022][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5036861 effective words) took 2.2s, 2315269 effective words/s
[2023-02-07 19:34:44,026][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 45.96% examples, 2351418 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:45,031][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 93.74% examples, 2362175 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:45,147][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5036861 effective words) took 2.1s, 2371546 effective words/s
[2023-02-07 19:34:46,151][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 45.47% examples, 2332214 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:47,156][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 92.14% examples, 2326673 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:47,306][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5036861 effective words) took 2.2s, 2335034 effective words/s
[2023-02-07 19:34:48,309][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 46.61% examples, 2383889 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:49,310][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 94.20% examples, 2377242 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:49,422][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5036861 effective words) took 2.1s, 2383162 effective words/s
[2023-02-07 19:34:50,425][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 46.64% examples, 2389860 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:51,426][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 95.43% examples, 2403394 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:51,513][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5036861 effective words) took 2.1s, 2410575 effective words/s
[2023-02-07 19:34:52,524][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 47.71% examples, 2439929 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:53,530][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 97.36% examples, 2438675 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:53,574][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5036861 effective words) took 2.1s, 2447974 effective words/s
[2023-02-07 19:34:54,577][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 47.90% examples, 2464100 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:55,578][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 97.36% examples, 2451544 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:55,622][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5036861 effective words) took 2.0s, 2461837 effective words/s
[2023-02-07 19:34:56,630][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 47.71% examples, 2444462 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:57,632][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 96.04% examples, 2411510 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:57,709][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5036861 effective words) took 2.1s, 2417145 effective words/s
[2023-02-07 19:34:58,713][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 47.41% examples, 2429880 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:59,722][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 96.62% examples, 2423832 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:59,785][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5036861 effective words) took 2.1s, 2430920 effective words/s
[2023-02-07 19:35:00,786][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 46.61% examples, 2386066 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:01,789][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 94.90% examples, 2393953 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:01,886][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5036861 effective words) took 2.1s, 2397889 effective words/s
[2023-02-07 19:35:02,889][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 46.64% examples, 2390381 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:03,890][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 94.60% examples, 2386411 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:35:03,991][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5036861 effective words) took 2.1s, 2395088 effective words/s
[2023-02-07 19:35:04,995][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 45.69% examples, 2340585 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:05,997][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 92.78% examples, 2348110 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:06,132][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5036861 effective words) took 2.1s, 2354658 effective words/s
[2023-02-07 19:35:06,132][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75552915 effective words) took 32.0s, 2361782 effective words/s', 'datetime': '2023-02-07T19:35:06.132870', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:35:06.133 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:35:09,345][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193404-hyn95pjy/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:35:09.345002', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:35:09,345][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:35:09,402][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193404-hyn95pjy/files/../tmp/embedding_model.pt
2023-02-07 19:35:09.402 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:35:11.318 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:35:11.989 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:35:17.059 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0306936336061607, 'test_mae': 0.7772513427343105, 'test_r2': -2.608001505056821}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.92
wandb: percentage 0.55548
wandb:   test_mae 0.77725
wandb:   test_mse 1.03069
wandb:    test_r2 -2.608
wandb: 
wandb: üöÄ View run gentle-sweep-48 at: https://wandb.ai/xiaoqiz/mof2vec/runs/hyn95pjy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_193404-hyn95pjy/logs
wandb: Agent Starting Run: v7mj84ga with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 436
wandb: 	model.gensim.alpha: 0.007924151145158858
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.4425788991510313
wandb: 	model.gensim.vector_size: 198
wandb: 	model.gensim.window: 10
wandb: 	model.sklearn.learning_rate: 0.1635578498508614
wandb: 	model.sklearn.max_depth: 88
wandb: 	model.sklearn.min_child_weight: 0.037543037573330496
wandb: 	model.sklearn.n_estimators: 2645
wandb: 	model.sklearn.num_leaves: 427
wandb: 	model.sklearn.reg_alpha: 0.009388341818487474
wandb: 	model.sklearn.reg_lambda: 0.06344857956726552
wandb: 	model.sklearn.subsample: 0.4948122587067772
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193529-v7mj84ga
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-49
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/v7mj84ga
2023-02-07 19:35:38.478 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 19:35:38.479 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 436 for sweep.
2023-02-07 19:35:38.479 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.007924151145158858 for sweep.
2023-02-07 19:35:38.479 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:35:38.479 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 19:35:38.480 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4425788991510313 for sweep.
2023-02-07 19:35:38.480 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 198 for sweep.
2023-02-07 19:35:38.480 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 10 for sweep.
2023-02-07 19:35:38.481 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.1635578498508614 for sweep.
2023-02-07 19:35:38.481 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 88 for sweep.
2023-02-07 19:35:38.481 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.037543037573330496 for sweep.
2023-02-07 19:35:38.481 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2645 for sweep.
2023-02-07 19:35:38.482 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 427 for sweep.
2023-02-07 19:35:38.482 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.009388341818487474 for sweep.
2023-02-07 19:35:38.482 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.06344857956726552 for sweep.
2023-02-07 19:35:38.482 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.4948122587067772 for sweep.
2023-02-07 19:35:38.483 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:35:38.488 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193529-v7mj84ga/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 436, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 198, 'window': 10, 'min_count': 3, 'dm': 0, 'sample': 0.4425788991510313, 'workers': 4, 'alpha': 0.007924151145158858, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2645, 'max_depth': 88, 'num_leaves': 427, 'reg_alpha': 0.009388341818487474, 'reg_lambda': 0.06344857956726552, 'subsample': 0.4948122587067772, 'min_child_weight': 0.037543037573330496, 'n_jobs': 4, 'learning_rate': 0.1635578498508614}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 169.00it/s]  1%|          | 37/3257 [00:00<00:17, 182.85it/s]  2%|‚ñè         | 57/3257 [00:00<00:16, 188.45it/s]  2%|‚ñè         | 79/3257 [00:00<00:15, 199.34it/s]  3%|‚ñé         | 99/3257 [00:00<00:16, 194.58it/s]  4%|‚ñé         | 119/3257 [00:00<00:16, 191.47it/s]  4%|‚ñç         | 140/3257 [00:00<00:15, 196.37it/s]  5%|‚ñç         | 161/3257 [00:00<00:15, 197.99it/s]  6%|‚ñå         | 181/3257 [00:00<00:15, 194.44it/s]  6%|‚ñå         | 202/3257 [00:01<00:15, 199.07it/s]  7%|‚ñã         | 228/3257 [00:01<00:13, 216.63it/s]  8%|‚ñä         | 250/3257 [00:01<00:14, 213.97it/s]  8%|‚ñä         | 272/3257 [00:01<00:14, 213.18it/s]  9%|‚ñâ         | 297/3257 [00:01<00:13, 222.23it/s] 10%|‚ñâ         | 320/3257 [00:01<00:13, 218.32it/s] 11%|‚ñà         | 342/3257 [00:01<00:13, 212.14it/s] 11%|‚ñà         | 364/3257 [00:01<00:13, 214.35it/s] 12%|‚ñà‚ñè        | 386/3257 [00:01<00:14, 201.58it/s] 13%|‚ñà‚ñé        | 408/3257 [00:01<00:13, 206.52it/s] 13%|‚ñà‚ñé        | 429/3257 [00:02<00:15, 187.02it/s] 14%|‚ñà‚ñç        | 449/3257 [00:02<00:14, 188.21it/s] 14%|‚ñà‚ñç        | 471/3257 [00:02<00:14, 194.86it/s] 15%|‚ñà‚ñå        | 492/3257 [00:02<00:14, 196.55it/s] 16%|‚ñà‚ñå        | 516/3257 [00:02<00:13, 208.09it/s] 16%|‚ñà‚ñã        | 537/3257 [00:02<00:13, 207.35it/s] 17%|‚ñà‚ñã        | 558/3257 [00:02<00:13, 198.11it/s] 18%|‚ñà‚ñä        | 578/3257 [00:02<00:14, 190.12it/s] 18%|‚ñà‚ñä        | 602/3257 [00:02<00:13, 202.92it/s] 19%|‚ñà‚ñâ        | 623/3257 [00:03<00:13, 197.87it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:13, 200.55it/s] 20%|‚ñà‚ñà        | 666/3257 [00:03<00:13, 191.19it/s] 21%|‚ñà‚ñà        | 686/3257 [00:03<00:13, 192.70it/s] 22%|‚ñà‚ñà‚ñè       | 709/3257 [00:03<00:12, 201.68it/s] 22%|‚ñà‚ñà‚ñè       | 730/3257 [00:03<00:20, 124.01it/s] 23%|‚ñà‚ñà‚ñé       | 750/3257 [00:03<00:18, 138.75it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:04<00:15, 157.96it/s] 24%|‚ñà‚ñà‚ñç       | 793/3257 [00:04<00:14, 167.75it/s] 25%|‚ñà‚ñà‚ñç       | 814/3257 [00:04<00:13, 176.21it/s] 26%|‚ñà‚ñà‚ñå       | 834/3257 [00:04<00:13, 178.36it/s] 26%|‚ñà‚ñà‚ñå       | 854/3257 [00:04<00:13, 175.73it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:04<00:13, 181.31it/s] 28%|‚ñà‚ñà‚ñä       | 896/3257 [00:04<00:12, 188.04it/s] 28%|‚ñà‚ñà‚ñä       | 918/3257 [00:04<00:11, 195.56it/s] 29%|‚ñà‚ñà‚ñâ       | 938/3257 [00:04<00:11, 196.68it/s] 30%|‚ñà‚ñà‚ñâ       | 961/3257 [00:05<00:11, 203.54it/s] 30%|‚ñà‚ñà‚ñà       | 982/3257 [00:05<00:11, 199.47it/s] 31%|‚ñà‚ñà‚ñà       | 1003/3257 [00:05<00:11, 198.73it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:05<00:11, 198.09it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1045/3257 [00:05<00:11, 187.81it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:05<00:11, 193.71it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:05<00:11, 196.46it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1108/3257 [00:05<00:10, 196.88it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1128/3257 [00:05<00:11, 189.25it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1148/3257 [00:05<00:11, 188.70it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:06<00:10, 199.36it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1192/3257 [00:06<00:11, 184.52it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1211/3257 [00:06<00:11, 181.64it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1234/3257 [00:06<00:10, 193.15it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1254/3257 [00:06<00:10, 193.65it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1274/3257 [00:06<00:10, 193.52it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1294/3257 [00:06<00:10, 181.59it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1314/3257 [00:06<00:10, 185.97it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1338/3257 [00:06<00:09, 200.22it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1359/3257 [00:07<00:09, 193.32it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1379/3257 [00:07<00:09, 191.42it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1400/3257 [00:07<00:09, 195.76it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1424/3257 [00:07<00:08, 205.50it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1446/3257 [00:07<00:08, 209.10it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1471/3257 [00:07<00:08, 220.77it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1494/3257 [00:07<00:07, 221.09it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1517/3257 [00:07<00:07, 222.72it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1540/3257 [00:07<00:08, 204.61it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1561/3257 [00:08<00:08, 199.94it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1582/3257 [00:08<00:08, 197.04it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1605/3257 [00:08<00:08, 205.84it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1630/3257 [00:08<00:07, 216.32it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1652/3257 [00:08<00:07, 201.67it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1673/3257 [00:08<00:08, 194.68it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1693/3257 [00:08<00:08, 193.36it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:08<00:07, 197.63it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1735/3257 [00:08<00:08, 184.58it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1759/3257 [00:09<00:07, 198.13it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1780/3257 [00:09<00:07, 201.32it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1802/3257 [00:09<00:07, 206.36it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1823/3257 [00:09<00:07, 203.56it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1844/3257 [00:09<00:06, 202.03it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1868/3257 [00:09<00:06, 210.31it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1890/3257 [00:09<00:06, 207.76it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1914/3257 [00:09<00:06, 215.03it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1936/3257 [00:10<00:10, 125.96it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1964/3257 [00:10<00:08, 155.12it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1985/3257 [00:10<00:07, 162.67it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:10<00:07, 177.36it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2031/3257 [00:10<00:06, 190.10it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2053/3257 [00:10<00:06, 182.04it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2073/3257 [00:10<00:06, 184.84it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2094/3257 [00:10<00:06, 191.26it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2115/3257 [00:10<00:05, 194.44it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:11<00:06, 184.99it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2156/3257 [00:11<00:05, 184.98it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:11<00:05, 193.58it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2201/3257 [00:11<00:05, 201.31it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2222/3257 [00:11<00:05, 199.36it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2243/3257 [00:11<00:05, 191.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2266/3257 [00:11<00:04, 201.01it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2287/3257 [00:11<00:04, 200.75it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2308/3257 [00:11<00:04, 197.35it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2335/3257 [00:12<00:04, 216.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:12<00:04, 222.62it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2384/3257 [00:12<00:03, 227.34it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2407/3257 [00:12<00:03, 222.34it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2430/3257 [00:12<00:03, 220.14it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2453/3257 [00:12<00:03, 209.79it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2479/3257 [00:12<00:03, 222.09it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2506/3257 [00:12<00:03, 235.04it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2530/3257 [00:12<00:03, 235.28it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2554/3257 [00:13<00:03, 227.91it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2577/3257 [00:13<00:03, 216.50it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2599/3257 [00:13<00:03, 213.95it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2629/3257 [00:13<00:02, 236.58it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2653/3257 [00:13<00:02, 222.15it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2676/3257 [00:13<00:02, 222.98it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2699/3257 [00:13<00:02, 209.36it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2721/3257 [00:13<00:02, 202.30it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2747/3257 [00:13<00:02, 216.51it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2769/3257 [00:14<00:02, 208.46it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:14<00:02, 220.20it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2818/3257 [00:14<00:02, 211.36it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2840/3257 [00:14<00:02, 208.31it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2869/3257 [00:14<00:01, 229.95it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2893/3257 [00:14<00:01, 220.84it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:14<00:01, 220.60it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2939/3257 [00:14<00:01, 223.14it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2962/3257 [00:14<00:01, 213.36it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:15<00:01, 205.26it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:15<00:01, 220.04it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3034/3257 [00:15<00:01, 218.65it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3060/3257 [00:15<00:00, 229.37it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3084/3257 [00:15<00:00, 230.92it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3109/3257 [00:15<00:00, 235.40it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3133/3257 [00:15<00:00, 233.73it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3157/3257 [00:15<00:00, 224.21it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3180/3257 [00:15<00:00, 218.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:16<00:00, 227.34it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3230/3257 [00:16<00:00, 224.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:16<00:00, 225.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 200.55it/s]
2023-02-07 19:35:55.315 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:35:55,317][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d198,n5,mc3,s0.442579,t4>', 'datetime': '2023-02-07T19:35:55.317072', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:35:55,317][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:35:55,317][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:35:55,693][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 19:35:55,694][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:35:55,721][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 9372 unique words (71.76% of original 13061, drops 3689)', 'datetime': '2023-02-07T19:35:55.721581', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:35:55,723][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 3633898 word corpus (99.85% of original 3639370, drops 5472)', 'datetime': '2023-02-07T19:35:55.723488', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:35:55,758][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 19:35:55,758][gensim.models.word2vec][INFO] - sample=0.442579 downsamples 0 most-common words
[2023-02-07 19:35:55,758][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3633898 word corpus (100.0%% of prior 3633898)', 'datetime': '2023-02-07T19:35:55.758926', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:35:55,820][gensim.models.word2vec][INFO] - estimated required memory for 9372 words and 198 dimensions: 22762192 bytes
[2023-02-07 19:35:55,820][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:35:55,833][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 9372 vocabulary and 198 features, using sg=1 hs=0 sample=0.4425788991510313 negative=5 window=10 shrink_windows=True', 'datetime': '2023-02-07T19:35:55.833114', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:35:56,840][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 63.68% examples, 2345464 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:57,351][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3637155 effective words) took 1.5s, 2398894 effective words/s
[2023-02-07 19:35:58,354][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 64.75% examples, 2397900 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:58,944][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3637155 effective words) took 1.6s, 2287007 effective words/s
[2023-02-07 19:35:59,947][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 71.45% examples, 2648108 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:00,312][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3637155 effective words) took 1.4s, 2661897 effective words/s
[2023-02-07 19:36:01,314][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 72.64% examples, 2683190 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:36:01,664][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3637155 effective words) took 1.3s, 2694477 effective words/s
[2023-02-07 19:36:02,667][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 72.64% examples, 2680520 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:03,015][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3637155 effective words) took 1.3s, 2694248 effective words/s
[2023-02-07 19:36:04,018][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 74.30% examples, 2741279 words/s, in_qsize 7, out_qsize 1
[2023-02-07 19:36:04,334][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3637155 effective words) took 1.3s, 2760970 effective words/s
[2023-02-07 19:36:05,337][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 74.95% examples, 2770668 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:05,648][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3637155 effective words) took 1.3s, 2770722 effective words/s
[2023-02-07 19:36:06,656][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 76.24% examples, 2798482 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:06,949][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3637155 effective words) took 1.3s, 2802710 effective words/s
[2023-02-07 19:36:07,955][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 75.68% examples, 2780644 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:08,265][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3637155 effective words) took 1.3s, 2766560 effective words/s
[2023-02-07 19:36:09,268][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 75.25% examples, 2779177 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:09,565][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3637155 effective words) took 1.3s, 2799914 effective words/s
[2023-02-07 19:36:10,574][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 76.24% examples, 2793292 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:10,866][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3637155 effective words) took 1.3s, 2800567 effective words/s
[2023-02-07 19:36:11,871][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 76.57% examples, 2812416 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:12,165][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3637155 effective words) took 1.3s, 2804005 effective words/s
[2023-02-07 19:36:13,173][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 51.37% examples, 1900528 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:14,049][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3637155 effective words) took 1.9s, 1932303 effective words/s
[2023-02-07 19:36:15,053][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 75.99% examples, 2800910 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:15,349][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3637155 effective words) took 1.3s, 2803537 effective words/s
[2023-02-07 19:36:16,357][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 52.38% examples, 1942604 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:17,213][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3637155 effective words) took 1.9s, 1957207 effective words/s
[2023-02-07 19:36:17,214][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54557325 effective words) took 21.4s, 2551728 effective words/s', 'datetime': '2023-02-07T19:36:17.214244', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:36:17.214 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:36:19,514][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193529-v7mj84ga/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:36:19.514169', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:36:19,514][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:36:19,552][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193529-v7mj84ga/files/../tmp/embedding_model.pt
2023-02-07 19:36:19.553 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:36:21.244 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:36:21.873 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:36:50.009 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.049868310485365, 'test_mae': 0.7727392685651048, 'test_r2': -1.8170668177282678}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.012 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.012 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.81
wandb: percentage 0.28244
wandb:   test_mae 0.77274
wandb:   test_mse 1.04987
wandb:    test_r2 -1.81707
wandb: 
wandb: üöÄ View run still-sweep-49 at: https://wandb.ai/xiaoqiz/mof2vec/runs/v7mj84ga
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_193529-v7mj84ga/logs
wandb: Agent Starting Run: jzsu3kfj with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 834
wandb: 	model.gensim.alpha: 0.11209013828120833
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.4591220446410141
wandb: 	model.gensim.vector_size: 270
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.04771264662325098
wandb: 	model.sklearn.max_depth: 19
wandb: 	model.sklearn.min_child_weight: 0.005216185974214908
wandb: 	model.sklearn.n_estimators: 491
wandb: 	model.sklearn.num_leaves: 325
wandb: 	model.sklearn.reg_alpha: 0.004972357397002045
wandb: 	model.sklearn.reg_lambda: 0.864919286496796
wandb: 	model.sklearn.subsample: 0.5260466004151456
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193659-jzsu3kfj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-50
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/jzsu3kfj
2023-02-07 19:37:07.538 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 19:37:07.539 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 834 for sweep.
2023-02-07 19:37:07.540 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.11209013828120833 for sweep.
2023-02-07 19:37:07.540 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:37:07.540 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 19:37:07.540 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4591220446410141 for sweep.
2023-02-07 19:37:07.541 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 270 for sweep.
2023-02-07 19:37:07.541 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 19:37:07.541 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.04771264662325098 for sweep.
2023-02-07 19:37:07.541 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 19 for sweep.
2023-02-07 19:37:07.542 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.005216185974214908 for sweep.
2023-02-07 19:37:07.542 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 491 for sweep.
2023-02-07 19:37:07.542 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 325 for sweep.
2023-02-07 19:37:07.543 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004972357397002045 for sweep.
2023-02-07 19:37:07.543 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.864919286496796 for sweep.
2023-02-07 19:37:07.544 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5260466004151456 for sweep.
2023-02-07 19:37:07.544 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:37:07.552 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193659-jzsu3kfj/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 834, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 270, 'window': 8, 'min_count': 5, 'dm': 1, 'sample': 0.4591220446410141, 'workers': 4, 'alpha': 0.11209013828120833, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 491, 'max_depth': 19, 'num_leaves': 325, 'reg_alpha': 0.004972357397002045, 'reg_lambda': 0.864919286496796, 'subsample': 0.5260466004151456, 'min_child_weight': 0.005216185974214908, 'n_jobs': 4, 'learning_rate': 0.04771264662325098}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 20/3257 [00:00<00:16, 198.44it/s]  1%|‚ñè         | 41/3257 [00:00<00:29, 110.63it/s]  2%|‚ñè         | 62/3257 [00:00<00:22, 140.73it/s]  3%|‚ñé         | 85/3257 [00:00<00:18, 167.53it/s]  3%|‚ñé         | 105/3257 [00:00<00:18, 172.86it/s]  4%|‚ñç         | 124/3257 [00:00<00:17, 174.64it/s]  5%|‚ñç         | 149/3257 [00:00<00:16, 194.09it/s]  5%|‚ñå         | 170/3257 [00:00<00:15, 194.28it/s]  6%|‚ñå         | 192/3257 [00:01<00:15, 199.37it/s]  7%|‚ñã         | 214/3257 [00:01<00:14, 204.85it/s]  7%|‚ñã         | 238/3257 [00:01<00:14, 213.85it/s]  8%|‚ñä         | 260/3257 [00:01<00:13, 214.89it/s]  9%|‚ñâ         | 287/3257 [00:01<00:12, 229.65it/s] 10%|‚ñâ         | 311/3257 [00:01<00:13, 223.62it/s] 10%|‚ñà         | 334/3257 [00:01<00:13, 220.99it/s] 11%|‚ñà         | 357/3257 [00:01<00:13, 221.56it/s] 12%|‚ñà‚ñè        | 380/3257 [00:01<00:14, 204.93it/s] 12%|‚ñà‚ñè        | 401/3257 [00:02<00:13, 205.02it/s] 13%|‚ñà‚ñé        | 422/3257 [00:02<00:13, 203.62it/s] 14%|‚ñà‚ñé        | 443/3257 [00:02<00:15, 180.28it/s] 14%|‚ñà‚ñç        | 466/3257 [00:02<00:14, 192.78it/s] 15%|‚ñà‚ñç        | 486/3257 [00:02<00:14, 193.66it/s] 16%|‚ñà‚ñå        | 511/3257 [00:02<00:13, 208.70it/s] 16%|‚ñà‚ñã        | 533/3257 [00:02<00:13, 202.40it/s] 17%|‚ñà‚ñã        | 556/3257 [00:02<00:12, 209.50it/s] 18%|‚ñà‚ñä        | 578/3257 [00:02<00:14, 187.41it/s] 18%|‚ñà‚ñä        | 602/3257 [00:03<00:13, 199.60it/s] 19%|‚ñà‚ñâ        | 623/3257 [00:03<00:13, 195.60it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:13, 199.25it/s] 20%|‚ñà‚ñà        | 666/3257 [00:03<00:13, 194.69it/s] 21%|‚ñà‚ñà        | 686/3257 [00:03<00:13, 194.77it/s] 22%|‚ñà‚ñà‚ñè       | 710/3257 [00:03<00:12, 206.19it/s] 22%|‚ñà‚ñà‚ñè       | 731/3257 [00:03<00:12, 198.49it/s] 23%|‚ñà‚ñà‚ñé       | 751/3257 [00:03<00:12, 196.10it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:03<00:12, 202.12it/s] 24%|‚ñà‚ñà‚ñç       | 794/3257 [00:04<00:12, 203.48it/s] 25%|‚ñà‚ñà‚ñå       | 815/3257 [00:04<00:11, 204.12it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:04<00:12, 198.81it/s] 26%|‚ñà‚ñà‚ñã       | 856/3257 [00:04<00:12, 193.81it/s] 27%|‚ñà‚ñà‚ñã       | 876/3257 [00:04<00:12, 195.53it/s] 28%|‚ñà‚ñà‚ñä       | 898/3257 [00:04<00:11, 201.63it/s] 28%|‚ñà‚ñà‚ñä       | 920/3257 [00:04<00:11, 206.75it/s] 29%|‚ñà‚ñà‚ñâ       | 941/3257 [00:04<00:11, 207.50it/s] 30%|‚ñà‚ñà‚ñâ       | 965/3257 [00:04<00:10, 216.82it/s] 30%|‚ñà‚ñà‚ñà       | 987/3257 [00:04<00:10, 208.53it/s] 31%|‚ñà‚ñà‚ñà       | 1008/3257 [00:05<00:11, 203.27it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1029/3257 [00:05<00:11, 199.69it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1050/3257 [00:05<00:11, 192.83it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1074/3257 [00:05<00:10, 204.57it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1095/3257 [00:05<00:11, 194.43it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:05<00:10, 198.04it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1137/3257 [00:05<00:10, 196.29it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1157/3257 [00:05<00:10, 195.58it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1177/3257 [00:05<00:10, 194.16it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1197/3257 [00:06<00:11, 183.02it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1216/3257 [00:06<00:11, 181.07it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:06<00:10, 199.44it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1263/3257 [00:06<00:09, 201.36it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1284/3257 [00:06<00:15, 127.58it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1305/3257 [00:06<00:13, 144.05it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:06<00:12, 159.56it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:07<00:11, 170.12it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:07<00:10, 176.03it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1390/3257 [00:07<00:10, 178.19it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1419/3257 [00:07<00:08, 207.27it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1441/3257 [00:07<00:08, 201.85it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1466/3257 [00:07<00:08, 214.71it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1489/3257 [00:07<00:08, 217.95it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:07<00:07, 222.15it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1536/3257 [00:07<00:08, 203.13it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1557/3257 [00:08<00:08, 199.81it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1578/3257 [00:08<00:08, 200.19it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1602/3257 [00:08<00:07, 209.91it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1624/3257 [00:08<00:07, 212.45it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1646/3257 [00:08<00:07, 207.95it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1667/3257 [00:08<00:08, 196.32it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1687/3257 [00:08<00:08, 193.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1709/3257 [00:08<00:07, 199.36it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1730/3257 [00:08<00:07, 191.60it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1750/3257 [00:08<00:07, 193.07it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1772/3257 [00:09<00:07, 199.65it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1794/3257 [00:09<00:07, 201.63it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1815/3257 [00:09<00:07, 192.68it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1835/3257 [00:09<00:07, 194.36it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1857/3257 [00:09<00:07, 199.82it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1880/3257 [00:09<00:06, 205.52it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1902/3257 [00:09<00:06, 208.73it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1923/3257 [00:09<00:06, 203.91it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1952/3257 [00:09<00:05, 227.37it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1976/3257 [00:10<00:05, 228.90it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:10<00:05, 220.46it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:10<00:05, 221.14it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2045/3257 [00:10<00:05, 212.67it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2067/3257 [00:10<00:06, 194.99it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2088/3257 [00:10<00:05, 198.99it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2109/3257 [00:10<00:05, 195.68it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2129/3257 [00:10<00:06, 183.38it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2148/3257 [00:10<00:06, 182.99it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2173/3257 [00:11<00:05, 199.35it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2194/3257 [00:11<00:05, 200.16it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2215/3257 [00:11<00:05, 197.38it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:11<00:05, 202.85it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2258/3257 [00:11<00:04, 203.26it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2279/3257 [00:11<00:05, 188.63it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:11<00:04, 195.16it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2327/3257 [00:11<00:04, 212.05it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2354/3257 [00:11<00:03, 227.57it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2377/3257 [00:12<00:04, 218.83it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2403/3257 [00:12<00:03, 227.67it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2426/3257 [00:12<00:03, 215.74it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2448/3257 [00:12<00:04, 197.92it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2474/3257 [00:12<00:03, 212.82it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2496/3257 [00:12<00:03, 212.31it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2519/3257 [00:12<00:03, 214.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2541/3257 [00:12<00:03, 214.79it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2563/3257 [00:12<00:03, 209.33it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2585/3257 [00:13<00:03, 196.50it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2610/3257 [00:13<00:03, 208.82it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:13<00:02, 216.85it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:13<00:02, 209.09it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2678/3257 [00:13<00:02, 201.01it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2699/3257 [00:13<00:04, 114.20it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2717/3257 [00:13<00:04, 125.71it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2744/3257 [00:14<00:03, 154.37it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2766/3257 [00:14<00:02, 168.21it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2787/3257 [00:14<00:02, 178.04it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2809/3257 [00:14<00:02, 188.41it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2830/3257 [00:14<00:02, 181.79it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2851/3257 [00:14<00:02, 188.06it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2878/3257 [00:14<00:01, 209.49it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2900/3257 [00:14<00:01, 194.25it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2924/3257 [00:14<00:01, 205.70it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2946/3257 [00:15<00:01, 194.45it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2967/3257 [00:15<00:01, 197.72it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2988/3257 [00:15<00:01, 190.34it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:15<00:01, 202.10it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3036/3257 [00:15<00:01, 210.53it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3061/3257 [00:15<00:00, 220.74it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3084/3257 [00:15<00:00, 221.24it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3109/3257 [00:15<00:00, 225.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3132/3257 [00:15<00:00, 221.77it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3155/3257 [00:16<00:00, 211.90it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3177/3257 [00:16<00:00, 204.79it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3200/3257 [00:16<00:00, 209.75it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3222/3257 [00:16<00:00, 197.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3248/3257 [00:16<00:00, 213.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 197.06it/s]
2023-02-07 19:37:24.677 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:37:24,679][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d270,n5,w8,mc5,s0.459122,t4>', 'datetime': '2023-02-07T19:37:24.679578', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:37:24,680][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:37:24,680][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:37:25,095][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 19:37:25,096][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:37:25,129][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11219 unique words (51.70% of original 21699, drops 10480)', 'datetime': '2023-02-07T19:37:25.128980', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:37:25,129][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 4341582 word corpus (99.41% of original 4367244, drops 25662)', 'datetime': '2023-02-07T19:37:25.129437', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:37:25,169][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 19:37:25,170][gensim.models.word2vec][INFO] - sample=0.459122 downsamples 0 most-common words
[2023-02-07 19:37:25,170][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4341582 word corpus (100.0%% of prior 4341582)', 'datetime': '2023-02-07T19:37:25.170462', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:37:25,240][gensim.models.word2vec][INFO] - estimated required memory for 11219 words and 270 dimensions: 34011500 bytes
[2023-02-07 19:37:25,240][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:37:25,256][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11219 vocabulary and 270 features, using sg=0 hs=0 sample=0.4591220446410141 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T19:37:25.256788', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:37:26,259][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 36.60% examples, 1631196 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:27,261][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 78.35% examples, 1715518 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:27,761][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4343128 effective words) took 2.5s, 1735645 effective words/s
[2023-02-07 19:37:28,765][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 40.22% examples, 1794805 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:29,765][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 82.41% examples, 1801041 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:30,182][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4343128 effective words) took 2.4s, 1794886 effective words/s
[2023-02-07 19:37:31,192][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 40.01% examples, 1776313 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:32,193][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 82.74% examples, 1804722 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:32,592][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4343128 effective words) took 2.4s, 1803229 effective words/s
[2023-02-07 19:37:33,596][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 39.30% examples, 1751525 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:34,596][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 78.81% examples, 1728169 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:35,107][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4343128 effective words) took 2.5s, 1728374 effective words/s
[2023-02-07 19:37:36,117][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 33.22% examples, 1447766 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:37,119][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 66.66% examples, 1470606 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:37:38,055][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4343128 effective words) took 2.9s, 1474062 effective words/s
[2023-02-07 19:37:39,061][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 38.84% examples, 1724194 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:40,065][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 80.32% examples, 1754011 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:37:40,520][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4343128 effective words) took 2.5s, 1763274 effective words/s
[2023-02-07 19:37:41,525][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 39.18% examples, 1743137 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:42,540][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 80.87% examples, 1754402 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:37:43,012][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4343128 effective words) took 2.5s, 1744548 effective words/s
[2023-02-07 19:37:44,015][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 39.18% examples, 1744356 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:45,017][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 79.03% examples, 1730916 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:45,510][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4343128 effective words) took 2.5s, 1740040 effective words/s
[2023-02-07 19:37:46,516][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 39.30% examples, 1747325 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:47,519][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 80.66% examples, 1758722 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:47,978][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4343128 effective words) took 2.5s, 1760941 effective words/s
[2023-02-07 19:37:48,981][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 38.72% examples, 1718858 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:37:49,982][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 79.46% examples, 1744783 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:50,457][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4343128 effective words) took 2.5s, 1752766 effective words/s
[2023-02-07 19:37:51,464][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 38.72% examples, 1713405 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:37:52,470][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 79.71% examples, 1741989 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:52,952][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4343128 effective words) took 2.5s, 1742176 effective words/s
[2023-02-07 19:37:53,957][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 38.72% examples, 1716281 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:37:54,958][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 78.94% examples, 1731205 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:55,440][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4343128 effective words) took 2.5s, 1747167 effective words/s
[2023-02-07 19:37:56,450][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 40.01% examples, 1774875 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:37:57,453][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 79.71% examples, 1741440 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:57,932][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4343128 effective words) took 2.5s, 1743661 effective words/s
[2023-02-07 19:37:58,935][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 38.29% examples, 1701597 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:59,936][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 78.94% examples, 1732366 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:00,428][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4343128 effective words) took 2.5s, 1741493 effective words/s
[2023-02-07 19:38:01,430][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 38.84% examples, 1728608 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:02,430][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 80.04% examples, 1755658 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:02,899][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4343128 effective words) took 2.5s, 1758650 effective words/s
[2023-02-07 19:38:02,899][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65146920 effective words) took 37.6s, 1730668 effective words/s', 'datetime': '2023-02-07T19:38:02.899911', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:38:02.900 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:38:06,103][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193659-jzsu3kfj/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:38:06.103073', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:38:06,104][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:38:06,155][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193659-jzsu3kfj/files/../tmp/embedding_model.pt
2023-02-07 19:38:06.155 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:38:08.126 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:38:08.792 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:38:10.867 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.167195557876626, 'test_mae': 0.8464417754232518, 'test_r2': -4.209895774165152}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.0
wandb: percentage 0.48297
wandb:   test_mae 0.84644
wandb:   test_mse 1.1672
wandb:    test_r2 -4.2099
wandb: 
wandb: üöÄ View run polar-sweep-50 at: https://wandb.ai/xiaoqiz/mof2vec/runs/jzsu3kfj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_193659-jzsu3kfj/logs
wandb: Agent Starting Run: seg9iep0 with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 808
wandb: 	model.gensim.alpha: 0.005822659389770743
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.4114223679609322
wandb: 	model.gensim.vector_size: 242
wandb: 	model.gensim.window: 12
wandb: 	model.sklearn.learning_rate: 0.03710537279530137
wandb: 	model.sklearn.max_depth: 54
wandb: 	model.sklearn.min_child_weight: 0.09143586007116256
wandb: 	model.sklearn.n_estimators: 1747
wandb: 	model.sklearn.num_leaves: 459
wandb: 	model.sklearn.reg_alpha: 0.014099614180734271
wandb: 	model.sklearn.reg_lambda: 0.10277473266885556
wandb: 	model.sklearn.subsample: 0.34152204071580905
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193823-seg9iep0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-51
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/seg9iep0
2023-02-07 19:38:32.267 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 19:38:32.267 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 808 for sweep.
2023-02-07 19:38:32.268 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.005822659389770743 for sweep.
2023-02-07 19:38:32.268 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:38:32.268 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 19:38:32.269 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4114223679609322 for sweep.
2023-02-07 19:38:32.269 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 242 for sweep.
2023-02-07 19:38:32.269 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 12 for sweep.
2023-02-07 19:38:32.269 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.03710537279530137 for sweep.
2023-02-07 19:38:32.270 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 54 for sweep.
2023-02-07 19:38:32.270 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09143586007116256 for sweep.
2023-02-07 19:38:32.270 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1747 for sweep.
2023-02-07 19:38:32.270 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 459 for sweep.
2023-02-07 19:38:32.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.014099614180734271 for sweep.
2023-02-07 19:38:32.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.10277473266885556 for sweep.
2023-02-07 19:38:32.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.34152204071580905 for sweep.
2023-02-07 19:38:32.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:38:32.283 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193823-seg9iep0/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 808, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 242, 'window': 12, 'min_count': 2, 'dm': 0, 'sample': 0.4114223679609322, 'workers': 4, 'alpha': 0.005822659389770743, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1747, 'max_depth': 54, 'num_leaves': 459, 'reg_alpha': 0.014099614180734271, 'reg_lambda': 0.10277473266885556, 'subsample': 0.34152204071580905, 'min_child_weight': 0.09143586007116256, 'n_jobs': 4, 'learning_rate': 0.03710537279530137}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:19, 170.32it/s]  1%|          | 39/3257 [00:00<00:16, 192.26it/s]  2%|‚ñè         | 59/3257 [00:00<00:17, 187.98it/s]  3%|‚ñé         | 82/3257 [00:00<00:15, 202.17it/s]  3%|‚ñé         | 103/3257 [00:00<00:16, 196.10it/s]  4%|‚ñç         | 123/3257 [00:00<00:17, 181.02it/s]  4%|‚ñç         | 145/3257 [00:00<00:16, 191.41it/s]  5%|‚ñå         | 165/3257 [00:00<00:17, 181.85it/s]  6%|‚ñå         | 184/3257 [00:00<00:16, 184.06it/s]  6%|‚ñã         | 204/3257 [00:01<00:16, 187.32it/s]  7%|‚ñã         | 230/3257 [00:01<00:14, 205.46it/s]  8%|‚ñä         | 251/3257 [00:01<00:14, 203.01it/s]  8%|‚ñä         | 272/3257 [00:01<00:14, 199.13it/s]  9%|‚ñâ         | 296/3257 [00:01<00:14, 208.60it/s] 10%|‚ñâ         | 317/3257 [00:01<00:14, 201.06it/s] 10%|‚ñà         | 338/3257 [00:01<00:14, 201.70it/s] 11%|‚ñà         | 360/3257 [00:01<00:14, 204.81it/s] 12%|‚ñà‚ñè        | 381/3257 [00:01<00:14, 192.69it/s] 12%|‚ñà‚ñè        | 402/3257 [00:02<00:14, 196.12it/s] 13%|‚ñà‚ñé        | 422/3257 [00:02<00:14, 195.21it/s] 14%|‚ñà‚ñé        | 442/3257 [00:02<00:16, 174.83it/s] 14%|‚ñà‚ñç        | 464/3257 [00:02<00:14, 186.65it/s] 15%|‚ñà‚ñç        | 484/3257 [00:02<00:14, 186.25it/s] 16%|‚ñà‚ñå        | 509/3257 [00:02<00:13, 202.96it/s] 16%|‚ñà‚ñã        | 530/3257 [00:02<00:14, 194.56it/s] 17%|‚ñà‚ñã        | 550/3257 [00:02<00:13, 193.43it/s] 18%|‚ñà‚ñä        | 570/3257 [00:02<00:14, 185.53it/s] 18%|‚ñà‚ñä        | 589/3257 [00:03<00:15, 177.71it/s] 19%|‚ñà‚ñâ        | 612/3257 [00:03<00:13, 191.59it/s] 19%|‚ñà‚ñâ        | 633/3257 [00:03<00:13, 194.80it/s] 20%|‚ñà‚ñà        | 653/3257 [00:03<00:14, 185.37it/s] 21%|‚ñà‚ñà        | 672/3257 [00:03<00:14, 179.55it/s] 21%|‚ñà‚ñà        | 691/3257 [00:03<00:14, 173.14it/s] 22%|‚ñà‚ñà‚ñè       | 713/3257 [00:03<00:13, 184.14it/s] 22%|‚ñà‚ñà‚ñè       | 732/3257 [00:03<00:14, 176.00it/s] 23%|‚ñà‚ñà‚ñé       | 750/3257 [00:03<00:14, 171.65it/s] 24%|‚ñà‚ñà‚ñé       | 771/3257 [00:04<00:13, 182.10it/s] 24%|‚ñà‚ñà‚ñç       | 790/3257 [00:04<00:13, 177.64it/s] 25%|‚ñà‚ñà‚ñç       | 808/3257 [00:04<00:13, 178.17it/s] 25%|‚ñà‚ñà‚ñå       | 826/3257 [00:04<00:13, 176.57it/s] 26%|‚ñà‚ñà‚ñå       | 844/3257 [00:04<00:14, 171.41it/s] 26%|‚ñà‚ñà‚ñã       | 862/3257 [00:04<00:21, 111.73it/s] 27%|‚ñà‚ñà‚ñã       | 877/3257 [00:04<00:19, 119.34it/s] 28%|‚ñà‚ñà‚ñä       | 897/3257 [00:04<00:17, 137.45it/s] 28%|‚ñà‚ñà‚ñä       | 916/3257 [00:05<00:15, 149.74it/s] 29%|‚ñà‚ñà‚ñâ       | 937/3257 [00:05<00:14, 163.61it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:05<00:13, 175.49it/s] 30%|‚ñà‚ñà‚ñà       | 978/3257 [00:05<00:12, 179.13it/s] 31%|‚ñà‚ñà‚ñà       | 997/3257 [00:05<00:13, 168.20it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:05<00:13, 167.54it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1033/3257 [00:05<00:13, 165.91it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1050/3257 [00:05<00:13, 164.24it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1070/3257 [00:05<00:12, 173.44it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:06<00:12, 168.90it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1106/3257 [00:06<00:12, 170.00it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:06<00:12, 167.69it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1141/3257 [00:06<00:12, 164.46it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1160/3257 [00:06<00:12, 171.34it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1178/3257 [00:06<00:12, 163.93it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1195/3257 [00:06<00:12, 159.92it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1212/3257 [00:06<00:13, 154.78it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:06<00:12, 168.46it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1251/3257 [00:07<00:12, 167.12it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:07<00:11, 173.46it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1289/3257 [00:07<00:12, 159.24it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:07<00:11, 166.52it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:07<00:11, 171.43it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1347/3257 [00:07<00:10, 176.56it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1365/3257 [00:07<00:10, 174.32it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1383/3257 [00:07<00:10, 172.31it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1404/3257 [00:07<00:10, 182.47it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1429/3257 [00:08<00:09, 200.15it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1450/3257 [00:08<00:08, 202.75it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1472/3257 [00:08<00:08, 206.53it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1494/3257 [00:08<00:08, 206.39it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1515/3257 [00:08<00:08, 206.29it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1536/3257 [00:08<00:09, 184.93it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:08<00:09, 172.40it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:08<00:09, 176.03it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1592/3257 [00:08<00:09, 176.61it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1613/3257 [00:09<00:08, 185.69it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:09<00:09, 177.68it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1653/3257 [00:09<00:09, 176.90it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1671/3257 [00:09<00:09, 172.28it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:09<00:08, 175.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1711/3257 [00:09<00:08, 185.09it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1730/3257 [00:09<00:08, 173.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1748/3257 [00:09<00:08, 173.82it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1767/3257 [00:09<00:08, 177.86it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1788/3257 [00:10<00:07, 185.73it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1807/3257 [00:10<00:08, 176.87it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:10<00:07, 183.25it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:10<00:07, 183.48it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1868/3257 [00:10<00:07, 193.08it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1888/3257 [00:10<00:07, 185.09it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1909/3257 [00:10<00:07, 190.59it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1929/3257 [00:10<00:07, 184.60it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1958/3257 [00:10<00:06, 212.76it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1980/3257 [00:11<00:06, 201.34it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2001/3257 [00:11<00:06, 200.85it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:11<00:06, 195.80it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2042/3257 [00:11<00:06, 189.36it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2062/3257 [00:11<00:06, 178.56it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:11<00:06, 184.67it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2102/3257 [00:11<00:06, 178.01it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:11<00:06, 174.36it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2141/3257 [00:11<00:06, 180.31it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2160/3257 [00:12<00:06, 179.90it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2180/3257 [00:12<00:10, 104.25it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2199/3257 [00:12<00:08, 119.37it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2215/3257 [00:12<00:08, 125.86it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2234/3257 [00:12<00:07, 139.40it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2251/3257 [00:12<00:07, 143.13it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2269/3257 [00:12<00:06, 151.01it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2287/3257 [00:13<00:06, 158.20it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2304/3257 [00:13<00:05, 158.86it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2326/3257 [00:13<00:05, 175.35it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2350/3257 [00:13<00:04, 191.86it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2370/3257 [00:13<00:04, 192.27it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2392/3257 [00:13<00:04, 199.81it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2413/3257 [00:13<00:04, 187.68it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2433/3257 [00:13<00:04, 181.05it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2452/3257 [00:13<00:04, 181.93it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:13<00:03, 196.04it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2498/3257 [00:14<00:03, 202.61it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2522/3257 [00:14<00:03, 211.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2544/3257 [00:14<00:03, 210.53it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2566/3257 [00:14<00:03, 196.68it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:14<00:03, 186.33it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2609/3257 [00:14<00:03, 197.51it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:14<00:02, 208.78it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:14<00:02, 201.44it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2677/3257 [00:14<00:02, 195.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2697/3257 [00:15<00:02, 194.76it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2717/3257 [00:15<00:03, 177.36it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2742/3257 [00:15<00:02, 195.14it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2762/3257 [00:15<00:02, 192.23it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2782/3257 [00:15<00:02, 193.96it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2806/3257 [00:15<00:02, 202.43it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2827/3257 [00:15<00:02, 190.08it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2847/3257 [00:15<00:02, 190.73it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2873/3257 [00:15<00:01, 209.96it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2895/3257 [00:16<00:01, 197.81it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:16<00:01, 200.85it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2937/3257 [00:16<00:01, 200.63it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2958/3257 [00:16<00:01, 186.67it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2979/3257 [00:16<00:01, 191.98it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3002/3257 [00:16<00:01, 199.83it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3023/3257 [00:16<00:01, 194.20it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3047/3257 [00:16<00:01, 206.49it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3070/3257 [00:16<00:00, 212.67it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3092/3257 [00:17<00:00, 208.11it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:17<00:00, 218.20it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3140/3257 [00:17<00:00, 206.00it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3161/3257 [00:17<00:00, 198.43it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3181/3257 [00:17<00:00, 184.33it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:17<00:00, 191.37it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3223/3257 [00:17<00:00, 183.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3245/3257 [00:17<00:00, 193.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 181.53it/s]
2023-02-07 19:38:50.895 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:38:50,896][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d242,n5,mc2,s0.411422,t4>', 'datetime': '2023-02-07T19:38:50.896648', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:38:50,897][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:38:50,897][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:38:51,333][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 19:38:51,333][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:38:51,385][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 18495 unique words (85.23% of original 21699, drops 3204)', 'datetime': '2023-02-07T19:38:51.385618', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:38:51,386][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 4364040 word corpus (99.93% of original 4367244, drops 3204)', 'datetime': '2023-02-07T19:38:51.386246', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:38:51,459][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 19:38:51,460][gensim.models.word2vec][INFO] - sample=0.411422 downsamples 0 most-common words
[2023-02-07 19:38:51,460][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4364040 word corpus (100.0%% of prior 4364040)', 'datetime': '2023-02-07T19:38:51.460812', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:38:51,585][gensim.models.word2vec][INFO] - estimated required memory for 18495 words and 242 dimensions: 48857996 bytes
[2023-02-07 19:38:51,586][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:38:51,616][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18495 vocabulary and 242 features, using sg=1 hs=0 sample=0.4114223679609322 negative=5 window=12 shrink_windows=True', 'datetime': '2023-02-07T19:38:51.616360', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:38:52,619][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 45.81% examples, 2035129 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:38:53,619][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 94.38% examples, 2065898 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:53,727][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4365521 effective words) took 2.1s, 2070228 effective words/s
[2023-02-07 19:38:54,732][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 39.64% examples, 1775870 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:55,733][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 81.03% examples, 1779724 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:56,099][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4365521 effective words) took 2.4s, 1841764 effective words/s
[2023-02-07 19:38:57,108][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 51.64% examples, 2295322 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:57,985][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4365521 effective words) took 1.9s, 2319442 effective words/s
[2023-02-07 19:38:58,987][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 51.64% examples, 2304885 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:59,858][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4365521 effective words) took 1.9s, 2332502 effective words/s
[2023-02-07 19:39:00,860][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 50.88% examples, 2268980 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:01,727][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4365521 effective words) took 1.9s, 2338115 effective words/s
[2023-02-07 19:39:02,736][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 53.21% examples, 2365906 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:03,555][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4365521 effective words) took 1.8s, 2389330 effective words/s
[2023-02-07 19:39:04,561][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 54.10% examples, 2412932 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:05,372][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4365521 effective words) took 1.8s, 2405167 effective words/s
[2023-02-07 19:39:06,374][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 54.50% examples, 2437659 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:07,178][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4365521 effective words) took 1.8s, 2418754 effective words/s
[2023-02-07 19:39:08,182][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 53.67% examples, 2399777 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:08,999][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4365521 effective words) took 1.8s, 2399921 effective words/s
[2023-02-07 19:39:10,004][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 52.32% examples, 2333687 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:10,843][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4365521 effective words) took 1.8s, 2372226 effective words/s
[2023-02-07 19:39:11,847][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 54.10% examples, 2415315 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:12,663][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4365521 effective words) took 1.8s, 2401271 effective words/s
[2023-02-07 19:39:13,665][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 52.32% examples, 2336530 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:14,504][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4365521 effective words) took 1.8s, 2373415 effective words/s
[2023-02-07 19:39:15,509][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 53.05% examples, 2368204 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:16,354][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4365521 effective words) took 1.8s, 2361225 effective words/s
[2023-02-07 19:39:17,357][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 39.02% examples, 1753108 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:18,358][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 92.14% examples, 2023217 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:39:18,485][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4365521 effective words) took 2.1s, 2050777 effective words/s
[2023-02-07 19:39:19,490][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 53.85% examples, 2411862 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:20,285][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4365521 effective words) took 1.8s, 2430163 effective words/s
[2023-02-07 19:39:20,286][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65482815 effective words) took 28.7s, 2284056 effective words/s', 'datetime': '2023-02-07T19:39:20.286415', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:39:20.286 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:39:23,032][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193823-seg9iep0/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:39:23.032164', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:39:23,033][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:39:23,116][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193823-seg9iep0/files/../tmp/embedding_model.pt
2023-02-07 19:39:23.117 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:39:24.916 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:39:25.569 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:39:27.987 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9623837773832792, 'test_mae': 0.7517542254431117, 'test_r2': -1.8747329767733008}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.74
wandb: percentage 0.14766
wandb:   test_mae 0.75175
wandb:   test_mse 0.96238
wandb:    test_r2 -1.87473
wandb: 
wandb: üöÄ View run honest-sweep-51 at: https://wandb.ai/xiaoqiz/mof2vec/runs/seg9iep0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_193823-seg9iep0/logs
wandb: Agent Starting Run: av8a1laf with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 493
wandb: 	model.gensim.alpha: 0.03595715578301699
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.50989846485778
wandb: 	model.gensim.vector_size: 197
wandb: 	model.gensim.window: 7
wandb: 	model.sklearn.learning_rate: 0.4916952219539749
wandb: 	model.sklearn.max_depth: 30
wandb: 	model.sklearn.min_child_weight: 0.048161787075019155
wandb: 	model.sklearn.n_estimators: 1848
wandb: 	model.sklearn.num_leaves: 259
wandb: 	model.sklearn.reg_alpha: 0.008424631699341451
wandb: 	model.sklearn.reg_lambda: 0.17117487482183855
wandb: 	model.sklearn.subsample: 0.3459673207238979
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193937-av8a1laf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-52
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/av8a1laf
2023-02-07 19:39:45.974 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:39:45.974 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 493 for sweep.
2023-02-07 19:39:45.975 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.03595715578301699 for sweep.
2023-02-07 19:39:45.975 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:39:45.975 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 19:39:45.976 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.50989846485778 for sweep.
2023-02-07 19:39:45.976 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 197 for sweep.
2023-02-07 19:39:45.976 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 7 for sweep.
2023-02-07 19:39:45.976 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.4916952219539749 for sweep.
2023-02-07 19:39:45.977 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 30 for sweep.
2023-02-07 19:39:45.977 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.048161787075019155 for sweep.
2023-02-07 19:39:45.977 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1848 for sweep.
2023-02-07 19:39:45.977 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 259 for sweep.
2023-02-07 19:39:45.978 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.008424631699341451 for sweep.
2023-02-07 19:39:45.978 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.17117487482183855 for sweep.
2023-02-07 19:39:45.978 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3459673207238979 for sweep.
2023-02-07 19:39:45.978 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:39:45.986 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193937-av8a1laf/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 493, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 197, 'window': 7, 'min_count': 2, 'dm': 0, 'sample': 0.50989846485778, 'workers': 4, 'alpha': 0.03595715578301699, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1848, 'max_depth': 30, 'num_leaves': 259, 'reg_alpha': 0.008424631699341451, 'reg_lambda': 0.17117487482183855, 'subsample': 0.3459673207238979, 'min_child_weight': 0.048161787075019155, 'n_jobs': 4, 'learning_rate': 0.4916952219539749}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:21, 148.51it/s]  1%|          | 34/3257 [00:00<00:19, 162.38it/s]  2%|‚ñè         | 52/3257 [00:00<00:19, 167.86it/s]  2%|‚ñè         | 69/3257 [00:00<00:20, 159.31it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 168.75it/s]  3%|‚ñé         | 107/3257 [00:00<00:19, 159.28it/s]  4%|‚ñç         | 124/3257 [00:00<00:19, 162.32it/s]  4%|‚ñç         | 146/3257 [00:00<00:17, 177.03it/s]  5%|‚ñå         | 164/3257 [00:00<00:18, 167.05it/s]  6%|‚ñå         | 182/3257 [00:01<00:18, 170.65it/s]  6%|‚ñå         | 201/3257 [00:01<00:17, 174.21it/s]  7%|‚ñã         | 222/3257 [00:01<00:16, 183.23it/s]  7%|‚ñã         | 243/3257 [00:01<00:15, 189.36it/s]  8%|‚ñä         | 263/3257 [00:01<00:16, 178.68it/s]  9%|‚ñâ         | 285/3257 [00:01<00:15, 189.91it/s]  9%|‚ñâ         | 305/3257 [00:01<00:16, 183.23it/s] 10%|‚ñâ         | 324/3257 [00:01<00:15, 183.96it/s] 11%|‚ñà         | 343/3257 [00:02<00:25, 114.76it/s] 11%|‚ñà         | 363/3257 [00:02<00:21, 131.64it/s] 12%|‚ñà‚ñè        | 380/3257 [00:02<00:20, 137.05it/s] 12%|‚ñà‚ñè        | 397/3257 [00:02<00:20, 142.63it/s] 13%|‚ñà‚ñé        | 416/3257 [00:02<00:18, 153.00it/s] 13%|‚ñà‚ñé        | 433/3257 [00:02<00:20, 136.91it/s] 14%|‚ñà‚ñç        | 450/3257 [00:02<00:19, 144.20it/s] 14%|‚ñà‚ñç        | 470/3257 [00:02<00:17, 157.15it/s] 15%|‚ñà‚ñç        | 487/3257 [00:03<00:17, 157.36it/s] 16%|‚ñà‚ñå        | 508/3257 [00:03<00:16, 170.87it/s] 16%|‚ñà‚ñå        | 526/3257 [00:03<00:16, 166.12it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:16, 169.42it/s] 17%|‚ñà‚ñã        | 564/3257 [00:03<00:16, 161.15it/s] 18%|‚ñà‚ñä        | 581/3257 [00:03<00:16, 158.70it/s] 18%|‚ñà‚ñä        | 601/3257 [00:03<00:15, 168.41it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:15, 165.21it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:03<00:15, 173.05it/s] 20%|‚ñà‚ñà        | 658/3257 [00:04<00:16, 157.98it/s] 21%|‚ñà‚ñà        | 677/3257 [00:04<00:15, 164.62it/s] 21%|‚ñà‚ñà‚ñè       | 694/3257 [00:04<00:15, 163.23it/s] 22%|‚ñà‚ñà‚ñè       | 713/3257 [00:04<00:14, 170.01it/s] 22%|‚ñà‚ñà‚ñè       | 731/3257 [00:04<00:15, 160.75it/s] 23%|‚ñà‚ñà‚ñé       | 748/3257 [00:04<00:15, 159.43it/s] 24%|‚ñà‚ñà‚ñé       | 768/3257 [00:04<00:14, 169.02it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:04<00:15, 161.46it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:04<00:14, 166.25it/s] 25%|‚ñà‚ñà‚ñå       | 821/3257 [00:05<00:14, 165.18it/s] 26%|‚ñà‚ñà‚ñå       | 838/3257 [00:05<00:15, 158.38it/s] 26%|‚ñà‚ñà‚ñå       | 854/3257 [00:05<00:15, 153.20it/s] 27%|‚ñà‚ñà‚ñã       | 873/3257 [00:05<00:14, 160.65it/s] 27%|‚ñà‚ñà‚ñã       | 890/3257 [00:05<00:14, 161.18it/s] 28%|‚ñà‚ñà‚ñä       | 909/3257 [00:05<00:14, 167.27it/s] 29%|‚ñà‚ñà‚ñä       | 929/3257 [00:05<00:13, 174.51it/s] 29%|‚ñà‚ñà‚ñâ       | 947/3257 [00:05<00:13, 169.12it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:05<00:13, 173.09it/s] 30%|‚ñà‚ñà‚ñà       | 984/3257 [00:06<00:13, 167.41it/s] 31%|‚ñà‚ñà‚ñà       | 1001/3257 [00:06<00:13, 164.94it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1018/3257 [00:06<00:13, 165.21it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1035/3257 [00:06<00:14, 158.24it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:06<00:14, 153.97it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1070/3257 [00:06<00:13, 163.80it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1087/3257 [00:06<00:13, 162.54it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:06<00:13, 163.27it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:06<00:12, 164.36it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1140/3257 [00:07<00:13, 160.86it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1158/3257 [00:07<00:12, 165.52it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:07<00:12, 163.38it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1192/3257 [00:07<00:13, 150.06it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1208/3257 [00:07<00:14, 145.49it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1228/3257 [00:07<00:12, 159.79it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:07<00:12, 159.08it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:07<00:12, 161.11it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1279/3257 [00:07<00:12, 152.17it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1295/3257 [00:08<00:13, 149.95it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:08<00:12, 156.36it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1331/3257 [00:08<00:12, 159.74it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:08<00:11, 159.85it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1367/3257 [00:08<00:11, 159.41it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1383/3257 [00:08<00:12, 153.78it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:08<00:11, 162.34it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1419/3257 [00:08<00:17, 106.16it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1435/3257 [00:09<00:15, 116.13it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1456/3257 [00:09<00:13, 136.53it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1475/3257 [00:09<00:12, 147.39it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1495/3257 [00:09<00:11, 159.80it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1515/3257 [00:09<00:10, 169.40it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1534/3257 [00:09<00:10, 159.33it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1551/3257 [00:09<00:10, 161.48it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1569/3257 [00:09<00:10, 165.45it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1587/3257 [00:09<00:09, 167.81it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1608/3257 [00:10<00:09, 179.41it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1630/3257 [00:10<00:08, 189.76it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:10<00:09, 174.70it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:10<00:09, 175.78it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1688/3257 [00:10<00:08, 182.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1709/3257 [00:10<00:08, 189.14it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:10<00:08, 186.28it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1749/3257 [00:10<00:07, 188.82it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:10<00:07, 196.76it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1795/3257 [00:11<00:07, 208.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1816/3257 [00:11<00:07, 204.83it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1839/3257 [00:11<00:06, 210.17it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1863/3257 [00:11<00:06, 218.13it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1885/3257 [00:11<00:06, 215.34it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1910/3257 [00:11<00:06, 224.07it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1933/3257 [00:11<00:06, 219.33it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:11<00:05, 236.29it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1985/3257 [00:11<00:05, 221.57it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:11<00:05, 223.46it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:12<00:05, 227.63it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2056/3257 [00:12<00:05, 208.07it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2078/3257 [00:12<00:05, 208.06it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:12<00:05, 202.87it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:12<00:05, 199.91it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:12<00:05, 196.09it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:12<00:05, 209.87it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2190/3257 [00:12<00:05, 210.21it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2212/3257 [00:12<00:05, 204.09it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:13<00:04, 212.93it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2258/3257 [00:13<00:04, 209.32it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2280/3257 [00:13<00:04, 198.35it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2303/3257 [00:13<00:04, 206.88it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2331/3257 [00:13<00:04, 227.08it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:13<00:03, 236.54it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2386/3257 [00:13<00:03, 242.54it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2411/3257 [00:13<00:03, 232.06it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2435/3257 [00:13<00:03, 220.95it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2458/3257 [00:14<00:03, 222.14it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2483/3257 [00:14<00:03, 229.18it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2512/3257 [00:14<00:03, 243.54it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2537/3257 [00:14<00:02, 241.15it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2562/3257 [00:14<00:03, 224.54it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2585/3257 [00:14<00:03, 212.06it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2607/3257 [00:14<00:03, 213.08it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2629/3257 [00:14<00:02, 214.01it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2651/3257 [00:14<00:03, 190.12it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2671/3257 [00:15<00:03, 185.59it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:15<00:03, 185.91it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:15<00:03, 159.45it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2728/3257 [00:15<00:03, 165.93it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2748/3257 [00:15<00:02, 173.37it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2766/3257 [00:15<00:02, 172.77it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2784/3257 [00:15<00:02, 172.49it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2805/3257 [00:15<00:02, 179.75it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2824/3257 [00:16<00:02, 164.44it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2841/3257 [00:16<00:02, 165.88it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2864/3257 [00:16<00:02, 181.26it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:16<00:01, 186.86it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2905/3257 [00:16<00:03, 93.19it/s]  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2926/3257 [00:16<00:02, 112.24it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2943/3257 [00:17<00:02, 117.29it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2963/3257 [00:17<00:02, 133.69it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2980/3257 [00:17<00:01, 139.36it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3001/3257 [00:17<00:01, 155.33it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3019/3257 [00:17<00:01, 157.05it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3041/3257 [00:17<00:01, 171.39it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3062/3257 [00:17<00:01, 181.06it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:17<00:00, 176.65it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3101/3257 [00:17<00:00, 177.24it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3123/3257 [00:17<00:00, 186.22it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3142/3257 [00:18<00:00, 179.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3161/3257 [00:18<00:00, 174.54it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3179/3257 [00:18<00:00, 162.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3201/3257 [00:18<00:00, 175.89it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3219/3257 [00:18<00:00, 171.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3242/3257 [00:18<00:00, 186.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 173.63it/s]
2023-02-07 19:40:05.500 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:40:05,501][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d197,n5,mc2,s0.509898,t4>', 'datetime': '2023-02-07T19:40:05.501591', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:40:05,502][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:40:05,502][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:40:06,058][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:40:06,059][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:40:06,140][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 27186 unique words (85.48% of original 31803, drops 4617)', 'datetime': '2023-02-07T19:40:06.140299', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:40:06,140][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5090501 word corpus (99.91% of original 5095118, drops 4617)', 'datetime': '2023-02-07T19:40:06.140747', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:40:06,248][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:40:06,249][gensim.models.word2vec][INFO] - sample=0.509898 downsamples 0 most-common words
[2023-02-07 19:40:06,249][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5090501 word corpus (100.0%% of prior 5090501)', 'datetime': '2023-02-07T19:40:06.249401', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:40:06,428][gensim.models.word2vec][INFO] - estimated required memory for 27186 words and 197 dimensions: 59656052 bytes
[2023-02-07 19:40:06,429][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:40:06,462][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 27186 vocabulary and 197 features, using sg=1 hs=0 sample=0.50989846485778 negative=5 window=7 shrink_windows=True', 'datetime': '2023-02-07T19:40:06.462066', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:40:07,465][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 56.83% examples, 2954131 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:40:08,180][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5082292 effective words) took 1.7s, 2961246 effective words/s
[2023-02-07 19:40:09,184][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 66.47% examples, 3436542 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:40:09,691][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5082292 effective words) took 1.5s, 3364568 effective words/s
[2023-02-07 19:40:10,694][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 53.18% examples, 2768909 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:40:11,667][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5082292 effective words) took 2.0s, 2574089 effective words/s
[2023-02-07 19:40:12,671][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 54.44% examples, 2825529 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:40:13,585][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5082292 effective words) took 1.9s, 2652485 effective words/s
[2023-02-07 19:40:14,592][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 51.21% examples, 2645417 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:40:15,375][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5082292 effective words) took 1.8s, 2840766 effective words/s
[2023-02-07 19:40:16,382][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 65.86% examples, 3403192 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:40:16,864][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5082292 effective words) took 1.5s, 3417282 effective words/s
[2023-02-07 19:40:17,868][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 70.06% examples, 3629459 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:40:18,264][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5082292 effective words) took 1.4s, 3632806 effective words/s
[2023-02-07 19:40:19,268][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 63.56% examples, 3281167 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:40:19,878][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5082292 effective words) took 1.6s, 3152706 effective words/s
[2023-02-07 19:40:20,883][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 56.65% examples, 2938246 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:40:21,629][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5082292 effective words) took 1.7s, 2904972 effective words/s
[2023-02-07 19:40:22,635][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 55.23% examples, 2857352 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:40:23,400][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5082292 effective words) took 1.8s, 2871928 effective words/s
[2023-02-07 19:40:24,403][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 55.11% examples, 2860786 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:40:25,178][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5082292 effective words) took 1.8s, 2860331 effective words/s
[2023-02-07 19:40:26,181][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 56.37% examples, 2937077 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:40:26,909][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5082292 effective words) took 1.7s, 2940092 effective words/s
[2023-02-07 19:40:27,911][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 56.65% examples, 2947346 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:40:28,653][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5082292 effective words) took 1.7s, 2915807 effective words/s
[2023-02-07 19:40:29,655][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 55.30% examples, 2876784 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:40:30,424][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5082292 effective words) took 1.8s, 2872596 effective words/s
[2023-02-07 19:40:31,426][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 54.99% examples, 2855645 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:40:32,203][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5082292 effective words) took 1.8s, 2859660 effective words/s
[2023-02-07 19:40:32,204][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76234380 effective words) took 25.7s, 2961490 effective words/s', 'datetime': '2023-02-07T19:40:32.204392', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:40:32.204 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:40:34,908][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193937-av8a1laf/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:40:34.908652', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:40:34,909][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:40:34,991][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193937-av8a1laf/files/../tmp/embedding_model.pt
2023-02-07 19:40:34.991 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:40:36.607 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:40:37.191 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:41:02.945 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0175007740611213, 'test_mae': 0.7881991446840982, 'test_r2': -2.34621378401683}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.98
wandb: percentage 0.14517
wandb:   test_mae 0.7882
wandb:   test_mse 1.0175
wandb:    test_r2 -2.34621
wandb: 
wandb: üöÄ View run lilac-sweep-52 at: https://wandb.ai/xiaoqiz/mof2vec/runs/av8a1laf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_193937-av8a1laf/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: e17242s0 with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 850
wandb: 	model.gensim.alpha: 0.006369972868652229
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.409276747955752
wandb: 	model.gensim.vector_size: 398
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.0024978779131622692
wandb: 	model.sklearn.max_depth: 23
wandb: 	model.sklearn.min_child_weight: 0.0497158059480628
wandb: 	model.sklearn.n_estimators: 1325
wandb: 	model.sklearn.num_leaves: 423
wandb: 	model.sklearn.reg_alpha: 0.0030045164481100894
wandb: 	model.sklearn.reg_lambda: 0.010839139067852678
wandb: 	model.sklearn.subsample: 0.30845305385899957
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194122-e17242s0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-53
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/e17242s0
2023-02-07 19:41:30.417 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:41:30.418 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 850 for sweep.
2023-02-07 19:41:30.418 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.006369972868652229 for sweep.
2023-02-07 19:41:30.419 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:41:30.419 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 19:41:30.419 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.409276747955752 for sweep.
2023-02-07 19:41:30.420 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 398 for sweep.
2023-02-07 19:41:30.420 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 19:41:30.420 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0024978779131622692 for sweep.
2023-02-07 19:41:30.420 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 23 for sweep.
2023-02-07 19:41:30.421 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0497158059480628 for sweep.
2023-02-07 19:41:30.421 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1325 for sweep.
2023-02-07 19:41:30.422 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 423 for sweep.
2023-02-07 19:41:30.422 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0030045164481100894 for sweep.
2023-02-07 19:41:30.422 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.010839139067852678 for sweep.
2023-02-07 19:41:30.422 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.30845305385899957 for sweep.
2023-02-07 19:41:30.423 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:41:30.430 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194122-e17242s0/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 850, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 398, 'window': 2, 'min_count': 1, 'dm': 0, 'sample': 0.409276747955752, 'workers': 4, 'alpha': 0.006369972868652229, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1325, 'max_depth': 23, 'num_leaves': 423, 'reg_alpha': 0.0030045164481100894, 'reg_lambda': 0.010839139067852678, 'subsample': 0.30845305385899957, 'min_child_weight': 0.0497158059480628, 'n_jobs': 4, 'learning_rate': 0.0024978779131622692}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:24, 132.97it/s]  1%|          | 31/3257 [00:00<00:21, 152.24it/s]  1%|‚ñè         | 47/3257 [00:00<00:21, 150.45it/s]  2%|‚ñè         | 63/3257 [00:00<00:21, 148.49it/s]  2%|‚ñè         | 79/3257 [00:00<00:21, 150.05it/s]  3%|‚ñé         | 95/3257 [00:00<00:21, 149.51it/s]  3%|‚ñé         | 110/3257 [00:00<00:22, 139.19it/s]  4%|‚ñç         | 125/3257 [00:00<00:22, 141.02it/s]  4%|‚ñç         | 144/3257 [00:00<00:20, 154.93it/s]  5%|‚ñç         | 160/3257 [00:01<00:21, 147.17it/s]  5%|‚ñå         | 175/3257 [00:01<00:21, 142.04it/s]  6%|‚ñå         | 192/3257 [00:01<00:20, 147.90it/s]  6%|‚ñã         | 207/3257 [00:01<00:20, 147.33it/s]  7%|‚ñã         | 227/3257 [00:01<00:18, 160.77it/s]  7%|‚ñã         | 244/3257 [00:01<00:18, 159.47it/s]  8%|‚ñä         | 261/3257 [00:01<00:19, 152.31it/s]  9%|‚ñä         | 282/3257 [00:01<00:18, 164.71it/s]  9%|‚ñâ         | 299/3257 [00:01<00:18, 161.84it/s] 10%|‚ñâ         | 316/3257 [00:02<00:18, 156.02it/s] 10%|‚ñà         | 334/3257 [00:02<00:18, 161.73it/s] 11%|‚ñà         | 351/3257 [00:02<00:18, 158.10it/s] 11%|‚ñà‚ñè        | 367/3257 [00:02<00:18, 157.03it/s] 12%|‚ñà‚ñè        | 383/3257 [00:02<00:19, 149.81it/s] 12%|‚ñà‚ñè        | 399/3257 [00:02<00:19, 144.74it/s] 13%|‚ñà‚ñé        | 416/3257 [00:02<00:18, 151.53it/s] 13%|‚ñà‚ñé        | 432/3257 [00:02<00:21, 129.57it/s] 14%|‚ñà‚ñé        | 446/3257 [00:03<00:21, 131.89it/s] 14%|‚ñà‚ñç        | 461/3257 [00:03<00:20, 136.21it/s] 15%|‚ñà‚ñç        | 476/3257 [00:03<00:19, 139.63it/s] 15%|‚ñà‚ñå        | 491/3257 [00:03<00:19, 140.81it/s] 16%|‚ñà‚ñå        | 509/3257 [00:03<00:18, 151.33it/s] 16%|‚ñà‚ñå        | 525/3257 [00:03<00:18, 146.05it/s] 17%|‚ñà‚ñã        | 541/3257 [00:03<00:18, 148.83it/s] 17%|‚ñà‚ñã        | 557/3257 [00:03<00:18, 145.58it/s] 18%|‚ñà‚ñä        | 572/3257 [00:03<00:21, 122.17it/s] 18%|‚ñà‚ñä        | 589/3257 [00:04<00:20, 130.90it/s] 19%|‚ñà‚ñä        | 605/3257 [00:04<00:19, 136.91it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:04<00:19, 137.53it/s] 20%|‚ñà‚ñâ        | 638/3257 [00:04<00:17, 147.33it/s] 20%|‚ñà‚ñà        | 654/3257 [00:04<00:18, 137.54it/s] 21%|‚ñà‚ñà        | 669/3257 [00:04<00:19, 133.36it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:19, 129.30it/s] 21%|‚ñà‚ñà‚ñè       | 697/3257 [00:04<00:19, 131.11it/s] 22%|‚ñà‚ñà‚ñè       | 716/3257 [00:04<00:17, 145.13it/s] 22%|‚ñà‚ñà‚ñè       | 731/3257 [00:05<00:19, 132.21it/s] 23%|‚ñà‚ñà‚ñé       | 745/3257 [00:05<00:19, 130.25it/s] 23%|‚ñà‚ñà‚ñé       | 762/3257 [00:05<00:17, 139.11it/s] 24%|‚ñà‚ñà‚ñç       | 777/3257 [00:05<00:18, 135.68it/s] 24%|‚ñà‚ñà‚ñç       | 792/3257 [00:05<00:17, 137.89it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:05<00:18, 135.23it/s] 25%|‚ñà‚ñà‚ñå       | 821/3257 [00:05<00:17, 138.96it/s] 26%|‚ñà‚ñà‚ñå       | 835/3257 [00:05<00:18, 133.46it/s] 26%|‚ñà‚ñà‚ñå       | 849/3257 [00:05<00:19, 124.86it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:06<00:18, 130.84it/s] 27%|‚ñà‚ñà‚ñã       | 878/3257 [00:06<00:18, 128.84it/s] 27%|‚ñà‚ñà‚ñã       | 894/3257 [00:06<00:17, 135.41it/s] 28%|‚ñà‚ñà‚ñä       | 911/3257 [00:06<00:16, 144.95it/s] 28%|‚ñà‚ñà‚ñä       | 926/3257 [00:06<00:27, 84.63it/s]  29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:06<00:25, 92.44it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:06<00:21, 107.92it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:07<00:20, 114.31it/s] 30%|‚ñà‚ñà‚ñà       | 984/3257 [00:07<00:18, 119.64it/s] 31%|‚ñà‚ñà‚ñà       | 998/3257 [00:07<00:18, 121.61it/s] 31%|‚ñà‚ñà‚ñà       | 1012/3257 [00:07<00:18, 122.70it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:07<00:17, 124.65it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:07<00:17, 123.83it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1057/3257 [00:07<00:16, 130.97it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1075/3257 [00:07<00:15, 142.40it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1090/3257 [00:07<00:16, 135.26it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:08<00:15, 135.04it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1119/3257 [00:08<00:16, 133.05it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1133/3257 [00:08<00:15, 134.88it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1147/3257 [00:08<00:15, 133.69it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1165/3257 [00:08<00:14, 146.63it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1180/3257 [00:08<00:15, 134.56it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:08<00:16, 127.52it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:08<00:16, 126.08it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1222/3257 [00:08<00:15, 130.80it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:09<00:14, 143.78it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1256/3257 [00:09<00:14, 139.02it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:09<00:13, 142.36it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1287/3257 [00:09<00:15, 130.76it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1302/3257 [00:09<00:14, 132.45it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1318/3257 [00:09<00:13, 139.42it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1334/3257 [00:09<00:13, 144.24it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:09<00:13, 138.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1365/3257 [00:09<00:13, 140.88it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1380/3257 [00:10<00:13, 142.25it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1395/3257 [00:10<00:13, 138.03it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1411/3257 [00:10<00:12, 143.24it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1427/3257 [00:10<00:12, 147.41it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1442/3257 [00:10<00:12, 142.78it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1461/3257 [00:10<00:11, 154.46it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:10<00:11, 152.67it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1494/3257 [00:10<00:11, 154.69it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1512/3257 [00:10<00:11, 157.71it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1528/3257 [00:11<00:12, 141.38it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1543/3257 [00:11<00:12, 141.76it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1558/3257 [00:11<00:12, 135.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:11<00:11, 141.18it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1589/3257 [00:11<00:11, 141.84it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1605/3257 [00:11<00:11, 145.93it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:11<00:11, 146.94it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:11<00:11, 141.10it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:11<00:11, 138.27it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1664/3257 [00:12<00:11, 135.43it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1678/3257 [00:12<00:11, 133.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:12<00:11, 133.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:12<00:11, 139.73it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1724/3257 [00:12<00:10, 144.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1739/3257 [00:12<00:11, 128.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1755/3257 [00:12<00:11, 135.11it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:12<00:10, 141.43it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1788/3257 [00:12<00:09, 147.58it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:13<00:09, 147.03it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1818/3257 [00:13<00:09, 144.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1833/3257 [00:13<00:10, 138.04it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1848/3257 [00:13<00:10, 139.55it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1865/3257 [00:13<00:09, 146.27it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1880/3257 [00:13<00:09, 143.07it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:13<00:09, 139.23it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1912/3257 [00:13<00:09, 146.59it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1927/3257 [00:13<00:09, 141.94it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1947/3257 [00:14<00:08, 156.77it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:14<00:08, 161.13it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:14<00:08, 155.22it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:14<00:08, 156.04it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2015/3257 [00:14<00:08, 152.60it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:14<00:07, 156.31it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2049/3257 [00:14<00:08, 144.01it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2064/3257 [00:14<00:08, 138.60it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2079/3257 [00:14<00:08, 141.18it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2094/3257 [00:15<00:08, 143.43it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2109/3257 [00:15<00:08, 138.93it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2123/3257 [00:15<00:08, 127.72it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2139/3257 [00:15<00:08, 133.91it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2153/3257 [00:15<00:08, 131.72it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:15<00:08, 135.94it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2183/3257 [00:15<00:07, 135.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2201/3257 [00:15<00:07, 145.67it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2216/3257 [00:15<00:07, 141.01it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2232/3257 [00:16<00:07, 144.57it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2247/3257 [00:16<00:07, 138.94it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2262/3257 [00:16<00:07, 139.27it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:16<00:07, 132.05it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2296/3257 [00:16<00:06, 149.18it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2312/3257 [00:16<00:06, 146.61it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2333/3257 [00:16<00:05, 162.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2353/3257 [00:16<00:05, 171.78it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2371/3257 [00:17<00:10, 84.09it/s]  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2390/3257 [00:17<00:08, 100.92it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2405/3257 [00:17<00:07, 107.98it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:17<00:07, 118.76it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2437/3257 [00:17<00:06, 119.87it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2452/3257 [00:17<00:06, 123.94it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2473/3257 [00:17<00:05, 143.63it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2489/3257 [00:18<00:05, 146.25it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2508/3257 [00:18<00:04, 157.82it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2525/3257 [00:18<00:04, 159.62it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2542/3257 [00:18<00:04, 158.47it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2559/3257 [00:18<00:04, 149.93it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2575/3257 [00:18<00:04, 143.38it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2590/3257 [00:18<00:04, 138.40it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2610/3257 [00:18<00:04, 153.13it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2629/3257 [00:18<00:03, 162.89it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2646/3257 [00:19<00:03, 154.28it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2662/3257 [00:19<00:04, 146.96it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2679/3257 [00:19<00:03, 152.78it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2695/3257 [00:19<00:03, 145.23it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2710/3257 [00:19<00:04, 133.27it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2726/3257 [00:19<00:03, 139.62it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2744/3257 [00:19<00:03, 149.17it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:19<00:03, 147.69it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2776/3257 [00:19<00:03, 143.74it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:20<00:02, 155.47it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2811/3257 [00:20<00:02, 156.49it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2827/3257 [00:20<00:02, 144.82it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:20<00:02, 143.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2862/3257 [00:20<00:02, 156.99it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2882/3257 [00:20<00:02, 167.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2899/3257 [00:20<00:02, 154.82it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2915/3257 [00:20<00:02, 155.84it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2931/3257 [00:20<00:02, 152.77it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:21<00:02, 148.12it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2963/3257 [00:21<00:01, 150.09it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2979/3257 [00:21<00:01, 144.58it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2994/3257 [00:21<00:01, 145.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:21<00:01, 154.82it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3028/3257 [00:21<00:01, 153.57it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3047/3257 [00:21<00:01, 163.49it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3066/3257 [00:21<00:01, 168.87it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3083/3257 [00:21<00:01, 166.34it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3100/3257 [00:22<00:00, 164.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3120/3257 [00:22<00:00, 173.17it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3138/3257 [00:22<00:00, 162.54it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3155/3257 [00:22<00:00, 151.73it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3171/3257 [00:22<00:00, 151.80it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3187/3257 [00:22<00:00, 145.20it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3204/3257 [00:22<00:00, 150.43it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3220/3257 [00:22<00:00, 144.54it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:22<00:00, 156.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3255/3257 [00:23<00:00, 155.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:23<00:00, 141.38it/s]
2023-02-07 19:41:54.561 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:41:54,562][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d398,n5,s0.409277,t4>', 'datetime': '2023-02-07T19:41:54.562546', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:41:54,563][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:41:54,563][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:41:55,218][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 19:41:55,218][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:41:55,364][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 54054 unique words (100.00% of original 54054, drops 0)', 'datetime': '2023-02-07T19:41:55.364368', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:41:55,364][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 6550866 word corpus (100.00% of original 6550866, drops 0)', 'datetime': '2023-02-07T19:41:55.364832', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:41:55,556][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 19:41:55,558][gensim.models.word2vec][INFO] - sample=0.409277 downsamples 0 most-common words
[2023-02-07 19:41:55,558][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6550866 word corpus (100.0%% of prior 6550866)', 'datetime': '2023-02-07T19:41:55.558553', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:41:55,893][gensim.models.word2vec][INFO] - estimated required memory for 54054 words and 398 dimensions: 204971480 bytes
[2023-02-07 19:41:55,893][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:41:55,991][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 54054 vocabulary and 398 features, using sg=1 hs=0 sample=0.409276747955752 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T19:41:55.991714', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:41:56,995][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 22.57% examples, 1442634 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:58,003][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 45.47% examples, 1497660 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:59,004][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 68.84% examples, 1517292 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:00,014][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 94.32% examples, 1528192 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:00,231][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6494971 effective words) took 4.2s, 1532738 effective words/s
[2023-02-07 19:42:01,245][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 25.79% examples, 1652756 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:02,250][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 50.45% examples, 1655295 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:03,252][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 76.17% examples, 1661272 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:04,124][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6494971 effective words) took 3.9s, 1669433 effective words/s
[2023-02-07 19:42:05,125][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 26.16% examples, 1701896 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:06,128][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 51.15% examples, 1693038 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:07,129][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 77.06% examples, 1684890 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:07,966][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6494971 effective words) took 3.8s, 1690981 effective words/s
[2023-02-07 19:42:08,972][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 26.07% examples, 1691554 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:09,973][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 51.27% examples, 1694723 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:10,976][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 77.96% examples, 1697982 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:11,791][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6494971 effective words) took 3.8s, 1698907 effective words/s
[2023-02-07 19:42:12,795][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 26.34% examples, 1707657 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:42:13,805][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 51.89% examples, 1712074 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:42:14,805][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 78.81% examples, 1717666 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:15,556][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6494971 effective words) took 3.8s, 1725669 effective words/s
[2023-02-07 19:42:16,563][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 26.77% examples, 1733077 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:17,563][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 52.63% examples, 1740109 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:18,566][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 79.46% examples, 1737178 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:19,294][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6494971 effective words) took 3.7s, 1738549 effective words/s
[2023-02-07 19:42:20,311][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 27.33% examples, 1748820 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:21,314][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.05% examples, 1746069 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:22,326][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 80.66% examples, 1742631 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:42:22,990][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6494971 effective words) took 3.7s, 1758590 effective words/s
[2023-02-07 19:42:23,997][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 27.85% examples, 1802188 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:42:25,000][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 54.65% examples, 1805992 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:26,005][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 82.84% examples, 1803951 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:26,590][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6494971 effective words) took 3.6s, 1804471 effective words/s
[2023-02-07 19:42:27,598][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 27.85% examples, 1802761 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:42:28,601][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 54.47% examples, 1800782 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:29,608][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 82.71% examples, 1797441 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:30,192][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6494971 effective words) took 3.6s, 1804332 effective words/s
[2023-02-07 19:42:31,197][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 28.55% examples, 1848439 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:32,203][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 56.09% examples, 1855299 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:33,207][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 84.71% examples, 1841931 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:33,726][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6494971 effective words) took 3.5s, 1838776 effective words/s
[2023-02-07 19:42:34,740][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 27.85% examples, 1790388 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:42:35,742][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 55.20% examples, 1818148 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:36,743][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 83.36% examples, 1817526 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:42:37,297][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6494971 effective words) took 3.6s, 1819645 effective words/s
[2023-02-07 19:42:38,301][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 22.72% examples, 1461201 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:39,308][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 44.21% examples, 1464287 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:42:40,308][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 68.62% examples, 1509849 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:41,312][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 95.98% examples, 1553303 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:42:41,576][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6494971 effective words) took 4.3s, 1518626 effective words/s
[2023-02-07 19:42:42,582][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 27.33% examples, 1770480 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:43,582][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 52.69% examples, 1746904 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:42:44,591][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 79.77% examples, 1741467 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:45,310][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6494971 effective words) took 3.7s, 1741664 effective words/s
[2023-02-07 19:42:46,312][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 26.83% examples, 1746899 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:42:47,313][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 52.87% examples, 1751221 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:48,317][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 79.58% examples, 1741087 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:49,049][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6494971 effective words) took 3.7s, 1737704 effective words/s
[2023-02-07 19:42:50,054][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 26.99% examples, 1753701 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:42:51,058][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 53.30% examples, 1767882 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:52,063][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 81.15% examples, 1764701 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:52,730][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6494971 effective words) took 3.7s, 1765440 effective words/s
[2023-02-07 19:42:52,731][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (97424565 effective words) took 56.7s, 1717065 effective words/s', 'datetime': '2023-02-07T19:42:52.731223', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:42:52.732 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:42:58,480][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194122-e17242s0/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:42:58.480421', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:42:58,481][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194122-e17242s0/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 19:42:58,560][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194122-e17242s0/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 19:42:58,634][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:42:58,670][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194122-e17242s0/files/../tmp/embedding_model.pt
2023-02-07 19:42:58.670 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:43:01.050 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:43:01.859 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:43:41.608 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9021622206149338, 'test_mae': 0.724684641816499, 'test_r2': -2.121208709440825}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.81
wandb: percentage 0.0
wandb:   test_mae 0.72468
wandb:   test_mse 0.90216
wandb:    test_r2 -2.12121
wandb: 
wandb: üöÄ View run fluent-sweep-53 at: https://wandb.ai/xiaoqiz/mof2vec/runs/e17242s0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_194122-e17242s0/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: krpjr2km with config:
wandb: 	data.data.wl_step: 2
wandb: 	data.nn.batch_size: 686
wandb: 	model.gensim.alpha: 0.001692001701336952
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.3305987922112391
wandb: 	model.gensim.vector_size: 409
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.027254175447275597
wandb: 	model.sklearn.max_depth: 36
wandb: 	model.sklearn.min_child_weight: 0.0738545035293881
wandb: 	model.sklearn.n_estimators: 3015
wandb: 	model.sklearn.num_leaves: 415
wandb: 	model.sklearn.reg_alpha: 0.00525515444443469
wandb: 	model.sklearn.reg_lambda: 0.0182283410749177
wandb: 	model.sklearn.subsample: 0.35240524195494755
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194412-krpjr2km
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-54
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/krpjr2km
2023-02-07 19:44:21.276 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 2 for sweep.
2023-02-07 19:44:21.278 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 686 for sweep.
2023-02-07 19:44:21.278 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.001692001701336952 for sweep.
2023-02-07 19:44:21.279 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:44:21.279 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 19:44:21.279 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.3305987922112391 for sweep.
2023-02-07 19:44:21.279 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 409 for sweep.
2023-02-07 19:44:21.280 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 19:44:21.280 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.027254175447275597 for sweep.
2023-02-07 19:44:21.280 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 36 for sweep.
2023-02-07 19:44:21.280 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0738545035293881 for sweep.
2023-02-07 19:44:21.281 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3015 for sweep.
2023-02-07 19:44:21.281 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 415 for sweep.
2023-02-07 19:44:21.281 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.00525515444443469 for sweep.
2023-02-07 19:44:21.281 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0182283410749177 for sweep.
2023-02-07 19:44:21.282 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.35240524195494755 for sweep.
2023-02-07 19:44:21.282 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:44:21.291 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 2}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194412-krpjr2km/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 686, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 409, 'window': 8, 'min_count': 1, 'dm': 0, 'sample': 0.3305987922112391, 'workers': 4, 'alpha': 0.001692001701336952, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3015, 'max_depth': 36, 'num_leaves': 415, 'reg_alpha': 0.00525515444443469, 'reg_lambda': 0.0182283410749177, 'subsample': 0.35240524195494755, 'min_child_weight': 0.0738545035293881, 'n_jobs': 4, 'learning_rate': 0.027254175447275597}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 22/3257 [00:00<00:14, 218.84it/s]  2%|‚ñè         | 49/3257 [00:00<00:13, 244.84it/s]  2%|‚ñè         | 74/3257 [00:00<00:13, 243.10it/s]  3%|‚ñé         | 102/3257 [00:00<00:12, 255.80it/s]  4%|‚ñç         | 128/3257 [00:00<00:12, 250.23it/s]  5%|‚ñç         | 158/3257 [00:00<00:11, 259.85it/s]  6%|‚ñå         | 184/3257 [00:00<00:11, 256.14it/s]  7%|‚ñã         | 213/3257 [00:00<00:11, 266.50it/s]  7%|‚ñã         | 243/3257 [00:00<00:10, 276.46it/s]  8%|‚ñä         | 271/3257 [00:01<00:11, 270.54it/s]  9%|‚ñâ         | 300/3257 [00:01<00:10, 275.73it/s] 10%|‚ñà         | 331/3257 [00:01<00:10, 282.63it/s] 11%|‚ñà         | 360/3257 [00:01<00:10, 277.93it/s] 12%|‚ñà‚ñè        | 388/3257 [00:01<00:10, 263.50it/s] 13%|‚ñà‚ñé        | 419/3257 [00:01<00:10, 274.86it/s] 14%|‚ñà‚ñé        | 447/3257 [00:01<00:11, 252.97it/s] 15%|‚ñà‚ñç        | 475/3257 [00:01<00:10, 258.59it/s] 15%|‚ñà‚ñå        | 504/3257 [00:01<00:10, 265.34it/s] 16%|‚ñà‚ñã        | 532/3257 [00:02<00:10, 267.51it/s] 17%|‚ñà‚ñã        | 559/3257 [00:02<00:15, 176.59it/s] 18%|‚ñà‚ñä        | 582/3257 [00:02<00:14, 187.33it/s] 19%|‚ñà‚ñâ        | 611/3257 [00:02<00:12, 209.96it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:02<00:11, 225.61it/s] 20%|‚ñà‚ñà        | 664/3257 [00:02<00:11, 225.94it/s] 21%|‚ñà‚ñà        | 690/3257 [00:02<00:11, 232.88it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:02<00:10, 242.75it/s] 23%|‚ñà‚ñà‚ñé       | 744/3257 [00:03<00:10, 235.09it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:03<00:10, 245.57it/s] 25%|‚ñà‚ñà‚ñç       | 801/3257 [00:03<00:09, 255.06it/s] 25%|‚ñà‚ñà‚ñå       | 827/3257 [00:03<00:09, 247.75it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:03<00:09, 242.27it/s] 27%|‚ñà‚ñà‚ñã       | 878/3257 [00:03<00:09, 243.29it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:03<00:09, 254.90it/s] 29%|‚ñà‚ñà‚ñä       | 933/3257 [00:03<00:09, 255.43it/s] 30%|‚ñà‚ñà‚ñâ       | 961/3257 [00:03<00:08, 260.22it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:03<00:08, 258.07it/s] 31%|‚ñà‚ñà‚ñà       | 1014/3257 [00:04<00:08, 255.14it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1040/3257 [00:04<00:08, 250.71it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1066/3257 [00:04<00:08, 250.14it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1092/3257 [00:04<00:08, 245.71it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1119/3257 [00:04<00:08, 247.52it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1145/3257 [00:04<00:08, 246.89it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1172/3257 [00:04<00:08, 252.70it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1198/3257 [00:04<00:08, 234.77it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1222/3257 [00:04<00:08, 230.99it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1249/3257 [00:05<00:08, 237.76it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:05<00:08, 242.84it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1300/3257 [00:05<00:08, 237.70it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:05<00:07, 243.89it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1355/3257 [00:05<00:07, 249.26it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1381/3257 [00:05<00:07, 249.61it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1410/3257 [00:05<00:07, 259.66it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1438/3257 [00:05<00:06, 261.73it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1471/3257 [00:05<00:06, 279.07it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1501/3257 [00:06<00:06, 282.73it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:06<00:06, 270.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1558/3257 [00:06<00:06, 260.87it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1585/3257 [00:06<00:06, 262.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:06<00:06, 272.41it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1643/3257 [00:06<00:06, 258.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1670/3257 [00:06<00:06, 250.16it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1696/3257 [00:06<00:06, 241.93it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:06<00:06, 247.02it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1748/3257 [00:07<00:06, 242.00it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1776/3257 [00:07<00:05, 249.11it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:07<00:05, 254.25it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1829/3257 [00:07<00:05, 251.13it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1857/3257 [00:07<00:05, 258.41it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1885/3257 [00:07<00:05, 262.59it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:07<00:05, 266.99it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1947/3257 [00:07<00:04, 278.72it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1977/3257 [00:07<00:04, 281.42it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2006/3257 [00:08<00:06, 180.43it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2034/3257 [00:08<00:06, 200.90it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2059/3257 [00:08<00:05, 206.92it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2087/3257 [00:08<00:05, 223.43it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2115/3257 [00:08<00:04, 237.29it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2141/3257 [00:08<00:04, 236.30it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:08<00:04, 243.07it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2198/3257 [00:08<00:04, 256.61it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2225/3257 [00:08<00:04, 253.83it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2252/3257 [00:09<00:03, 256.84it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2279/3257 [00:09<00:03, 254.22it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2308/3257 [00:09<00:03, 263.23it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2340/3257 [00:09<00:03, 277.75it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2368/3257 [00:09<00:03, 278.01it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2396/3257 [00:09<00:03, 278.07it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2424/3257 [00:09<00:03, 267.56it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2451/3257 [00:09<00:03, 253.42it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:09<00:02, 264.82it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2509/3257 [00:10<00:02, 268.81it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:10<00:02, 276.44it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2568/3257 [00:10<00:02, 259.52it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2595/3257 [00:10<00:02, 250.29it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2626/3257 [00:10<00:02, 265.37it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2653/3257 [00:10<00:02, 248.75it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2679/3257 [00:10<00:02, 247.85it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2705/3257 [00:10<00:02, 231.90it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2731/3257 [00:10<00:02, 238.70it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:11<00:02, 244.29it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2783/3257 [00:11<00:01, 248.34it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2810/3257 [00:11<00:01, 252.85it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2836/3257 [00:11<00:01, 243.57it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2867/3257 [00:11<00:01, 261.71it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2894/3257 [00:11<00:01, 257.94it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2921/3257 [00:11<00:01, 260.83it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2948/3257 [00:11<00:01, 254.44it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:11<00:01, 254.62it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:12<00:00, 260.90it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3031/3257 [00:12<00:00, 257.97it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3062/3257 [00:12<00:00, 272.53it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3090/3257 [00:12<00:00, 269.68it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3121/3257 [00:12<00:00, 277.84it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3149/3257 [00:12<00:00, 263.14it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3176/3257 [00:12<00:00, 258.34it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3202/3257 [00:12<00:00, 256.81it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3228/3257 [00:12<00:00, 255.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:12<00:00, 264.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:12<00:00, 251.27it/s]
2023-02-07 19:44:34.575 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:44:34,576][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d409,n5,s0.330599,t4>', 'datetime': '2023-02-07T19:44:34.576612', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:44:34,577][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:44:34,577][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:44:34,789][gensim.models.doc2vec][INFO] - collected 2819 word types and 3257 unique tags from a corpus of 3257 examples and 2183622 words
[2023-02-07 19:44:34,790][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:44:34,798][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 2819 unique words (100.00% of original 2819, drops 0)', 'datetime': '2023-02-07T19:44:34.798270', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:44:34,798][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 2183622 word corpus (100.00% of original 2183622, drops 0)', 'datetime': '2023-02-07T19:44:34.798677', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:44:34,808][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 2819 items
[2023-02-07 19:44:34,809][gensim.models.word2vec][INFO] - sample=0.330599 downsamples 0 most-common words
[2023-02-07 19:44:34,809][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2183622 word corpus (100.0%% of prior 2183622)', 'datetime': '2023-02-07T19:44:34.809464', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:44:34,826][gensim.models.word2vec][INFO] - estimated required memory for 2819 words and 409 dimensions: 16613120 bytes
[2023-02-07 19:44:34,827][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:44:34,837][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 2819 vocabulary and 409 features, using sg=1 hs=0 sample=0.3305987922112391 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T19:44:34.837616', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:44:35,842][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 61.28% examples, 1358067 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:36,420][gensim.models.word2vec][INFO] - EPOCH 0: training on 2183622 raw words (2186879 effective words) took 1.6s, 1384177 effective words/s
[2023-02-07 19:44:37,425][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 67.39% examples, 1499221 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:37,874][gensim.models.word2vec][INFO] - EPOCH 1: training on 2183622 raw words (2186879 effective words) took 1.5s, 1505733 effective words/s
[2023-02-07 19:44:38,882][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 66.07% examples, 1468237 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:39,351][gensim.models.word2vec][INFO] - EPOCH 2: training on 2183622 raw words (2186879 effective words) took 1.5s, 1482482 effective words/s
[2023-02-07 19:44:40,356][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 66.53% examples, 1482643 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:40,814][gensim.models.word2vec][INFO] - EPOCH 3: training on 2183622 raw words (2186879 effective words) took 1.5s, 1497412 effective words/s
[2023-02-07 19:44:41,821][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 66.53% examples, 1479023 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:42,277][gensim.models.word2vec][INFO] - EPOCH 4: training on 2183622 raw words (2186879 effective words) took 1.5s, 1496542 effective words/s
[2023-02-07 19:44:43,284][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 66.53% examples, 1478200 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:43,735][gensim.models.word2vec][INFO] - EPOCH 5: training on 2183622 raw words (2186879 effective words) took 1.5s, 1501829 effective words/s
[2023-02-07 19:44:44,749][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 68.25% examples, 1506273 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:45,173][gensim.models.word2vec][INFO] - EPOCH 6: training on 2183622 raw words (2186879 effective words) took 1.4s, 1523463 effective words/s
[2023-02-07 19:44:46,175][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 66.53% examples, 1485492 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:44:46,632][gensim.models.word2vec][INFO] - EPOCH 7: training on 2183622 raw words (2186879 effective words) took 1.5s, 1500178 effective words/s
[2023-02-07 19:44:47,639][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 66.53% examples, 1478219 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:48,097][gensim.models.word2vec][INFO] - EPOCH 8: training on 2183622 raw words (2186879 effective words) took 1.5s, 1494707 effective words/s
[2023-02-07 19:44:49,099][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 66.53% examples, 1485218 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:49,554][gensim.models.word2vec][INFO] - EPOCH 9: training on 2183622 raw words (2186879 effective words) took 1.5s, 1502959 effective words/s
[2023-02-07 19:44:50,558][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 66.53% examples, 1482909 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:51,017][gensim.models.word2vec][INFO] - EPOCH 10: training on 2183622 raw words (2186879 effective words) took 1.5s, 1497482 effective words/s
[2023-02-07 19:44:52,023][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 49.12% examples, 1091402 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:44:52,883][gensim.models.word2vec][INFO] - EPOCH 11: training on 2183622 raw words (2186879 effective words) took 1.9s, 1173167 effective words/s
[2023-02-07 19:44:53,887][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 65.70% examples, 1465673 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:54,361][gensim.models.word2vec][INFO] - EPOCH 12: training on 2183622 raw words (2186879 effective words) took 1.5s, 1482488 effective words/s
[2023-02-07 19:44:55,371][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 66.53% examples, 1473813 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:55,819][gensim.models.word2vec][INFO] - EPOCH 13: training on 2183622 raw words (2186879 effective words) took 1.5s, 1501663 effective words/s
[2023-02-07 19:44:56,821][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 67.79% examples, 1513563 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:57,263][gensim.models.word2vec][INFO] - EPOCH 14: training on 2183622 raw words (2186879 effective words) took 1.4s, 1516094 effective words/s
[2023-02-07 19:44:57,264][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 32754330 raw words (32803185 effective words) took 22.4s, 1462702 effective words/s', 'datetime': '2023-02-07T19:44:57.264517', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:44:57.266 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:44:58,914][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194412-krpjr2km/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:44:58.914549', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:44:58,915][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:44:58,945][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194412-krpjr2km/files/../tmp/embedding_model.pt
2023-02-07 19:44:58.946 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:45:01.339 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:45:02.177 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:45:28.215 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0375383181111584, 'test_mae': 0.7766174308818542, 'test_r2': -2.629358563780292}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.28
wandb: percentage 0.0
wandb:   test_mae 0.77662
wandb:   test_mse 1.03754
wandb:    test_r2 -2.62936
wandb: 
wandb: üöÄ View run fragrant-sweep-54 at: https://wandb.ai/xiaoqiz/mof2vec/runs/krpjr2km
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_194412-krpjr2km/logs
wandb: Agent Starting Run: wdwo7u9t with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 976
wandb: 	model.gensim.alpha: 0.035548947342653785
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.4135691225311524
wandb: 	model.gensim.vector_size: 142
wandb: 	model.gensim.window: 4
wandb: 	model.sklearn.learning_rate: 0.0004934089317267028
wandb: 	model.sklearn.max_depth: 47
wandb: 	model.sklearn.min_child_weight: 0.08084651437071916
wandb: 	model.sklearn.n_estimators: 46
wandb: 	model.sklearn.num_leaves: 290
wandb: 	model.sklearn.reg_alpha: 0.01827182972636798
wandb: 	model.sklearn.reg_lambda: 0.004310844798886715
wandb: 	model.sklearn.subsample: 0.40191525094771585
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194538-wdwo7u9t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-55
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/wdwo7u9t
2023-02-07 19:45:49.282 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:45:49.283 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 976 for sweep.
2023-02-07 19:45:49.283 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.035548947342653785 for sweep.
2023-02-07 19:45:49.284 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:45:49.284 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 19:45:49.284 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4135691225311524 for sweep.
2023-02-07 19:45:49.284 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 142 for sweep.
2023-02-07 19:45:49.285 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 4 for sweep.
2023-02-07 19:45:49.285 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0004934089317267028 for sweep.
2023-02-07 19:45:49.285 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 47 for sweep.
2023-02-07 19:45:49.285 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08084651437071916 for sweep.
2023-02-07 19:45:49.286 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 46 for sweep.
2023-02-07 19:45:49.286 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 290 for sweep.
2023-02-07 19:45:49.286 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.01827182972636798 for sweep.
2023-02-07 19:45:49.286 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.004310844798886715 for sweep.
2023-02-07 19:45:49.287 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.40191525094771585 for sweep.
2023-02-07 19:45:49.287 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:45:49.295 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194538-wdwo7u9t/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 976, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 142, 'window': 4, 'min_count': 1, 'dm': 1, 'sample': 0.4135691225311524, 'workers': 4, 'alpha': 0.035548947342653785, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 46, 'max_depth': 47, 'num_leaves': 290, 'reg_alpha': 0.01827182972636798, 'reg_lambda': 0.004310844798886715, 'subsample': 0.40191525094771585, 'min_child_weight': 0.08084651437071916, 'n_jobs': 4, 'learning_rate': 0.0004934089317267028}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:25, 127.64it/s]  1%|          | 29/3257 [00:00<00:22, 145.31it/s]  1%|‚ñè         | 44/3257 [00:00<00:22, 145.52it/s]  2%|‚ñè         | 59/3257 [00:00<00:36, 87.97it/s]   2%|‚ñè         | 77/3257 [00:00<00:28, 109.85it/s]  3%|‚ñé         | 93/3257 [00:00<00:25, 122.12it/s]  3%|‚ñé         | 108/3257 [00:00<00:25, 122.84it/s]  4%|‚ñç         | 124/3257 [00:01<00:24, 129.48it/s]  4%|‚ñç         | 143/3257 [00:01<00:21, 144.82it/s]  5%|‚ñç         | 159/3257 [00:01<00:21, 143.52it/s]  5%|‚ñå         | 174/3257 [00:01<00:21, 142.47it/s]  6%|‚ñå         | 192/3257 [00:01<00:20, 151.28it/s]  6%|‚ñã         | 208/3257 [00:01<00:19, 152.60it/s]  7%|‚ñã         | 230/3257 [00:01<00:18, 166.61it/s]  8%|‚ñä         | 247/3257 [00:01<00:18, 167.09it/s]  8%|‚ñä         | 264/3257 [00:01<00:18, 160.64it/s]  9%|‚ñâ         | 286/3257 [00:01<00:16, 175.91it/s]  9%|‚ñâ         | 304/3257 [00:02<00:17, 169.03it/s] 10%|‚ñâ         | 324/3257 [00:02<00:16, 176.87it/s] 11%|‚ñà         | 342/3257 [00:02<00:17, 166.68it/s] 11%|‚ñà         | 360/3257 [00:02<00:17, 168.93it/s] 12%|‚ñà‚ñè        | 378/3257 [00:02<00:18, 156.02it/s] 12%|‚ñà‚ñè        | 394/3257 [00:02<00:18, 155.66it/s] 13%|‚ñà‚ñé        | 412/3257 [00:02<00:17, 160.46it/s] 13%|‚ñà‚ñé        | 429/3257 [00:02<00:20, 140.41it/s] 14%|‚ñà‚ñé        | 445/3257 [00:03<00:19, 144.00it/s] 14%|‚ñà‚ñç        | 462/3257 [00:03<00:18, 149.99it/s] 15%|‚ñà‚ñç        | 478/3257 [00:03<00:18, 152.68it/s] 15%|‚ñà‚ñå        | 495/3257 [00:03<00:17, 156.55it/s] 16%|‚ñà‚ñå        | 513/3257 [00:03<00:17, 161.14it/s] 16%|‚ñà‚ñã        | 530/3257 [00:03<00:17, 159.17it/s] 17%|‚ñà‚ñã        | 547/3257 [00:03<00:17, 155.45it/s] 17%|‚ñà‚ñã        | 563/3257 [00:03<00:18, 144.88it/s] 18%|‚ñà‚ñä        | 578/3257 [00:03<00:18, 141.24it/s] 18%|‚ñà‚ñä        | 597/3257 [00:04<00:17, 153.58it/s] 19%|‚ñà‚ñâ        | 615/3257 [00:04<00:16, 158.76it/s] 19%|‚ñà‚ñâ        | 632/3257 [00:04<00:16, 158.93it/s] 20%|‚ñà‚ñâ        | 649/3257 [00:04<00:17, 148.58it/s] 20%|‚ñà‚ñà        | 665/3257 [00:04<00:18, 139.38it/s] 21%|‚ñà‚ñà        | 682/3257 [00:04<00:17, 145.61it/s] 21%|‚ñà‚ñà‚ñè       | 697/3257 [00:04<00:18, 138.56it/s] 22%|‚ñà‚ñà‚ñè       | 716/3257 [00:04<00:16, 151.58it/s] 22%|‚ñà‚ñà‚ñè       | 732/3257 [00:04<00:17, 141.12it/s] 23%|‚ñà‚ñà‚ñé       | 747/3257 [00:05<00:18, 138.34it/s] 24%|‚ñà‚ñà‚ñé       | 766/3257 [00:05<00:16, 150.43it/s] 24%|‚ñà‚ñà‚ñç       | 782/3257 [00:05<00:17, 142.34it/s] 25%|‚ñà‚ñà‚ñç       | 799/3257 [00:05<00:16, 148.67it/s] 25%|‚ñà‚ñà‚ñå       | 815/3257 [00:05<00:16, 148.37it/s] 25%|‚ñà‚ñà‚ñå       | 830/3257 [00:05<00:17, 142.56it/s] 26%|‚ñà‚ñà‚ñå       | 845/3257 [00:05<00:17, 135.97it/s] 26%|‚ñà‚ñà‚ñã       | 861/3257 [00:05<00:16, 141.25it/s] 27%|‚ñà‚ñà‚ñã       | 876/3257 [00:05<00:17, 139.04it/s] 27%|‚ñà‚ñà‚ñã       | 892/3257 [00:06<00:16, 142.98it/s] 28%|‚ñà‚ñà‚ñä       | 909/3257 [00:06<00:15, 149.35it/s] 28%|‚ñà‚ñà‚ñä       | 925/3257 [00:06<00:15, 149.95it/s] 29%|‚ñà‚ñà‚ñâ       | 941/3257 [00:06<00:16, 143.76it/s] 29%|‚ñà‚ñà‚ñâ       | 958/3257 [00:06<00:15, 149.96it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:06<00:15, 148.83it/s] 30%|‚ñà‚ñà‚ñà       | 989/3257 [00:06<00:15, 142.95it/s] 31%|‚ñà‚ñà‚ñà       | 1004/3257 [00:06<00:15, 144.37it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1019/3257 [00:06<00:15, 142.99it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1034/3257 [00:07<00:16, 134.86it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1048/3257 [00:07<00:16, 133.80it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1064/3257 [00:07<00:15, 140.51it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:15, 139.08it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1095/3257 [00:07<00:15, 141.34it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:07<00:14, 147.54it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1127/3257 [00:07<00:15, 139.07it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1142/3257 [00:07<00:15, 140.84it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1158/3257 [00:07<00:14, 144.63it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:08<00:24, 86.02it/s]  36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:08<00:22, 90.91it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1199/3257 [00:08<00:20, 98.98it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1212/3257 [00:08<00:19, 104.52it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:08<00:16, 124.52it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1246/3257 [00:08<00:15, 128.33it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:08<00:14, 134.93it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:09<00:14, 132.28it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:09<00:15, 128.85it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1305/3257 [00:09<00:14, 131.68it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:09<00:14, 136.22it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:09<00:13, 145.98it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:09<00:13, 138.93it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:09<00:13, 141.69it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:09<00:13, 139.85it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:09<00:12, 145.92it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:10<00:11, 160.97it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:10<00:11, 152.53it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1459/3257 [00:10<00:10, 164.96it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1476/3257 [00:10<00:10, 161.95it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1493/3257 [00:10<00:10, 163.16it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:10<00:10, 167.10it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1528/3257 [00:10<00:11, 151.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1544/3257 [00:10<00:11, 144.61it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1560/3257 [00:10<00:11, 148.55it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1576/3257 [00:11<00:11, 146.47it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:11<00:10, 154.28it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1612/3257 [00:11<00:10, 159.89it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1629/3257 [00:11<00:10, 161.10it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1646/3257 [00:11<00:10, 149.40it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:11<00:11, 139.44it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:11<00:11, 136.02it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:11<00:11, 135.55it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:11<00:10, 141.44it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1725/3257 [00:12<00:10, 149.15it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1741/3257 [00:12<00:11, 129.43it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1759/3257 [00:12<00:10, 141.94it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1774/3257 [00:12<00:10, 143.29it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:12<00:09, 149.77it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1808/3257 [00:12<00:10, 138.15it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:12<00:09, 143.83it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1843/3257 [00:12<00:09, 150.59it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1859/3257 [00:12<00:09, 149.25it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1878/3257 [00:13<00:08, 160.20it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:13<00:08, 151.39it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1914/3257 [00:13<00:08, 161.69it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:13<00:08, 152.08it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:13<00:07, 170.24it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1972/3257 [00:13<00:07, 172.18it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1990/3257 [00:13<00:07, 160.41it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2007/3257 [00:13<00:07, 157.63it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2024/3257 [00:13<00:07, 159.70it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2041/3257 [00:14<00:08, 151.51it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2057/3257 [00:14<00:08, 144.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2072/3257 [00:14<00:08, 143.86it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2087/3257 [00:14<00:08, 141.65it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2102/3257 [00:14<00:08, 138.68it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2119/3257 [00:14<00:07, 146.82it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:14<00:08, 133.88it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2148/3257 [00:14<00:08, 130.02it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2165/3257 [00:15<00:07, 140.50it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2180/3257 [00:15<00:07, 142.90it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2196/3257 [00:15<00:07, 145.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2211/3257 [00:15<00:07, 136.69it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2228/3257 [00:15<00:07, 143.41it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2243/3257 [00:15<00:07, 138.53it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:15<00:06, 142.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:15<00:07, 135.18it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2295/3257 [00:15<00:06, 152.32it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2311/3257 [00:16<00:06, 148.47it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2332/3257 [00:16<00:05, 163.63it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2352/3257 [00:16<00:05, 172.61it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2370/3257 [00:16<00:05, 166.41it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2387/3257 [00:16<00:05, 166.61it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:16<00:05, 166.59it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2421/3257 [00:16<00:05, 152.79it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2437/3257 [00:17<00:10, 76.91it/s]  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2450/3257 [00:17<00:09, 85.22it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2470/3257 [00:17<00:07, 106.43it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2485/3257 [00:17<00:06, 113.20it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:17<00:05, 134.50it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:17<00:05, 142.09it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2541/3257 [00:17<00:04, 144.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2557/3257 [00:17<00:04, 141.34it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:18<00:05, 135.15it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2588/3257 [00:18<00:04, 133.93it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2606/3257 [00:18<00:04, 145.15it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2627/3257 [00:18<00:03, 161.00it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2644/3257 [00:18<00:04, 150.71it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2660/3257 [00:18<00:04, 142.70it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2677/3257 [00:18<00:03, 145.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:18<00:03, 144.52it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:18<00:04, 132.93it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2725/3257 [00:19<00:03, 139.25it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2742/3257 [00:19<00:03, 147.36it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2758/3257 [00:19<00:03, 147.98it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2773/3257 [00:19<00:03, 143.67it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:19<00:03, 153.93it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2808/3257 [00:19<00:02, 152.76it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2824/3257 [00:19<00:03, 141.11it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2839/3257 [00:19<00:02, 140.56it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2856/3257 [00:19<00:02, 148.58it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2880/3257 [00:20<00:02, 171.59it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2898/3257 [00:20<00:02, 152.60it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2915/3257 [00:20<00:02, 155.46it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2931/3257 [00:20<00:02, 148.27it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:20<00:02, 143.69it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2962/3257 [00:20<00:02, 145.07it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2977/3257 [00:20<00:01, 141.78it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2992/3257 [00:20<00:01, 140.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:20<00:01, 151.97it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3028/3257 [00:21<00:01, 149.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3047/3257 [00:21<00:01, 158.64it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3065/3257 [00:21<00:01, 164.04it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:21<00:01, 157.85it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3098/3257 [00:21<00:01, 158.08it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:21<00:00, 166.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3135/3257 [00:21<00:00, 155.77it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3151/3257 [00:21<00:00, 149.43it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3167/3257 [00:21<00:00, 151.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:22<00:00, 144.09it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3201/3257 [00:22<00:00, 152.27it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3217/3257 [00:22<00:00, 143.24it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3236/3257 [00:22<00:00, 155.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:22<00:00, 153.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 144.26it/s]
2023-02-07 19:46:12.912 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:46:12,914][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d142,n5,w4,s0.413569,t4>', 'datetime': '2023-02-07T19:46:12.913969', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:46:12,914][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:46:12,914][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:46:13,589][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 19:46:13,589][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:46:13,735][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 54054 unique words (100.00% of original 54054, drops 0)', 'datetime': '2023-02-07T19:46:13.735493', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:46:13,736][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 6550866 word corpus (100.00% of original 6550866, drops 0)', 'datetime': '2023-02-07T19:46:13.735983', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:46:13,924][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 19:46:13,926][gensim.models.word2vec][INFO] - sample=0.413569 downsamples 0 most-common words
[2023-02-07 19:46:13,926][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6550866 word corpus (100.0%% of prior 6550866)', 'datetime': '2023-02-07T19:46:13.926754', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:46:14,248][gensim.models.word2vec][INFO] - estimated required memory for 54054 words and 142 dimensions: 90933720 bytes
[2023-02-07 19:46:14,249][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:46:14,293][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 54054 vocabulary and 142 features, using sg=0 hs=0 sample=0.4135691225311524 negative=5 window=4 shrink_windows=True', 'datetime': '2023-02-07T19:46:14.293346', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:46:15,295][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 31.44% examples, 2046165 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:16,298][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 62.67% examples, 2062950 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:17,300][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 96.19% examples, 2080714 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:17,411][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6494971 effective words) took 3.1s, 2084243 effective words/s
[2023-02-07 19:46:18,415][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 33.16% examples, 2168931 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:19,416][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 65.98% examples, 2183369 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:20,359][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6494971 effective words) took 2.9s, 2204231 effective words/s
[2023-02-07 19:46:21,362][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 36.94% examples, 2448050 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:22,365][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 79.28% examples, 2598813 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:22,823][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6494971 effective words) took 2.5s, 2637232 effective words/s
[2023-02-07 19:46:23,825][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 35.92% examples, 2361267 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:24,830][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 71.66% examples, 2362751 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:25,557][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6494971 effective words) took 2.7s, 2376674 effective words/s
[2023-02-07 19:46:26,560][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 31.99% examples, 2098448 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:27,561][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 63.06% examples, 2079138 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:28,561][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 95.27% examples, 2064538 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:28,705][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6494971 effective words) took 3.1s, 2064774 effective words/s
[2023-02-07 19:46:29,711][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 35.06% examples, 2291094 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:30,719][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 69.88% examples, 2307332 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:31,491][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6494971 effective words) took 2.8s, 2332570 effective words/s
[2023-02-07 19:46:32,494][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 36.23% examples, 2387897 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:33,499][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 71.81% examples, 2366847 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:34,226][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6494971 effective words) took 2.7s, 2376450 effective words/s
[2023-02-07 19:46:35,232][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 36.48% examples, 2407288 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:36,235][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 72.46% examples, 2382381 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:36,950][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6494971 effective words) took 2.7s, 2386056 effective words/s
[2023-02-07 19:46:37,954][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 35.92% examples, 2355680 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:38,957][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 72.46% examples, 2384084 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:39,661][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6494971 effective words) took 2.7s, 2397056 effective words/s
[2023-02-07 19:46:40,666][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.44% examples, 2399506 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:41,666][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 71.48% examples, 2360854 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:42,419][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6494971 effective words) took 2.8s, 2355901 effective words/s
[2023-02-07 19:46:43,424][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 34.33% examples, 2242343 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:44,425][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 67.70% examples, 2235777 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:45,337][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6494971 effective words) took 2.9s, 2226966 effective words/s
[2023-02-07 19:46:46,339][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 33.34% examples, 2183681 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:47,341][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 66.63% examples, 2204435 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:48,261][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6494971 effective words) took 2.9s, 2222456 effective words/s
[2023-02-07 19:46:49,270][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 34.45% examples, 2243025 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:50,275][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 67.70% examples, 2227732 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:51,178][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6494971 effective words) took 2.9s, 2227924 effective words/s
[2023-02-07 19:46:52,180][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 33.74% examples, 2213438 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:46:53,181][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 66.84% examples, 2210567 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:54,139][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6494971 effective words) took 3.0s, 2194841 effective words/s
[2023-02-07 19:46:55,142][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 32.27% examples, 2118002 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:56,144][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 65.09% examples, 2150012 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:57,146][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 99.26% examples, 2146982 words/s, in_qsize 6, out_qsize 0
[2023-02-07 19:46:57,166][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6494971 effective words) took 3.0s, 2147131 effective words/s
[2023-02-07 19:46:57,166][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (97424565 effective words) took 42.9s, 2272396 effective words/s', 'datetime': '2023-02-07T19:46:57.166921', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:46:57.167 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:47:02,380][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194538-wdwo7u9t/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:47:02.380326', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:47:02,381][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:47:02,510][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194538-wdwo7u9t/files/../tmp/embedding_model.pt
2023-02-07 19:47:02.510 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:47:04.018 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:47:04.535 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:47:06.396 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0104581202842362, 'test_mae': 0.7639020480718349, 'test_r2': -2.753302281938648}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.89
wandb: percentage 0.0
wandb:   test_mae 0.7639
wandb:   test_mse 1.01046
wandb:    test_r2 -2.7533
wandb: 
wandb: üöÄ View run quiet-sweep-55 at: https://wandb.ai/xiaoqiz/mof2vec/runs/wdwo7u9t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_194538-wdwo7u9t/logs
wandb: Agent Starting Run: 3iv5gfxr with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 855
wandb: 	model.gensim.alpha: 0.0032165396921527943
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.5686297339640933
wandb: 	model.gensim.vector_size: 345
wandb: 	model.gensim.window: 6
wandb: 	model.sklearn.learning_rate: 0.0019217465914699995
wandb: 	model.sklearn.max_depth: 64
wandb: 	model.sklearn.min_child_weight: 0.046534821658059694
wandb: 	model.sklearn.n_estimators: 128
wandb: 	model.sklearn.num_leaves: 225
wandb: 	model.sklearn.reg_alpha: 0.006055402400363129
wandb: 	model.sklearn.reg_lambda: 0.009006390363424774
wandb: 	model.sklearn.subsample: 0.32214781264433684
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194719-3iv5gfxr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-56
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/3iv5gfxr
2023-02-07 19:47:27.049 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 19:47:27.049 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 855 for sweep.
2023-02-07 19:47:27.049 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0032165396921527943 for sweep.
2023-02-07 19:47:27.050 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:47:27.050 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 19:47:27.050 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5686297339640933 for sweep.
2023-02-07 19:47:27.050 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 345 for sweep.
2023-02-07 19:47:27.051 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 6 for sweep.
2023-02-07 19:47:27.051 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0019217465914699995 for sweep.
2023-02-07 19:47:27.051 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 64 for sweep.
2023-02-07 19:47:27.051 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.046534821658059694 for sweep.
2023-02-07 19:47:27.051 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 128 for sweep.
2023-02-07 19:47:27.052 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 225 for sweep.
2023-02-07 19:47:27.052 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.006055402400363129 for sweep.
2023-02-07 19:47:27.053 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.009006390363424774 for sweep.
2023-02-07 19:47:27.053 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.32214781264433684 for sweep.
2023-02-07 19:47:27.053 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:47:27.059 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194719-3iv5gfxr/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 855, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 345, 'window': 6, 'min_count': 1, 'dm': 0, 'sample': 0.5686297339640933, 'workers': 4, 'alpha': 0.0032165396921527943, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 128, 'max_depth': 64, 'num_leaves': 225, 'reg_alpha': 0.006055402400363129, 'reg_lambda': 0.009006390363424774, 'subsample': 0.32214781264433684, 'min_child_weight': 0.046534821658059694, 'n_jobs': 4, 'learning_rate': 0.0019217465914699995}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 21/3257 [00:00<00:15, 209.07it/s]  1%|‚ñè         | 44/3257 [00:00<00:14, 220.33it/s]  2%|‚ñè         | 67/3257 [00:00<00:14, 214.99it/s]  3%|‚ñé         | 91/3257 [00:00<00:14, 223.37it/s]  4%|‚ñé         | 114/3257 [00:00<00:14, 211.18it/s]  4%|‚ñç         | 137/3257 [00:00<00:14, 216.37it/s]  5%|‚ñç         | 159/3257 [00:00<00:14, 215.65it/s]  6%|‚ñå         | 181/3257 [00:00<00:14, 213.16it/s]  6%|‚ñã         | 205/3257 [00:00<00:13, 219.89it/s]  7%|‚ñã         | 232/3257 [00:01<00:12, 234.61it/s]  8%|‚ñä         | 256/3257 [00:01<00:12, 232.20it/s]  9%|‚ñä         | 282/3257 [00:01<00:12, 238.19it/s]  9%|‚ñâ         | 306/3257 [00:01<00:12, 234.51it/s] 10%|‚ñà         | 332/3257 [00:01<00:12, 240.02it/s] 11%|‚ñà         | 357/3257 [00:01<00:12, 239.31it/s] 12%|‚ñà‚ñè        | 381/3257 [00:01<00:12, 225.21it/s] 12%|‚ñà‚ñè        | 404/3257 [00:01<00:12, 224.88it/s] 13%|‚ñà‚ñé        | 427/3257 [00:01<00:13, 204.88it/s] 14%|‚ñà‚ñç        | 448/3257 [00:02<00:13, 204.66it/s] 15%|‚ñà‚ñç        | 474/3257 [00:02<00:12, 215.84it/s] 15%|‚ñà‚ñå        | 500/3257 [00:02<00:12, 225.90it/s] 16%|‚ñà‚ñå        | 526/3257 [00:02<00:11, 231.04it/s] 17%|‚ñà‚ñã        | 550/3257 [00:02<00:16, 166.04it/s] 18%|‚ñà‚ñä        | 571/3257 [00:02<00:15, 170.43it/s] 18%|‚ñà‚ñä        | 599/3257 [00:02<00:13, 193.83it/s] 19%|‚ñà‚ñâ        | 623/3257 [00:02<00:12, 204.54it/s] 20%|‚ñà‚ñâ        | 649/3257 [00:03<00:12, 216.17it/s] 21%|‚ñà‚ñà        | 673/3257 [00:03<00:11, 221.44it/s] 21%|‚ñà‚ñà‚ñè       | 697/3257 [00:03<00:11, 217.91it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:03<00:11, 224.92it/s] 23%|‚ñà‚ñà‚ñé       | 745/3257 [00:03<00:11, 223.59it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:03<00:10, 234.33it/s] 25%|‚ñà‚ñà‚ñç       | 799/3257 [00:03<00:10, 239.46it/s] 25%|‚ñà‚ñà‚ñå       | 824/3257 [00:03<00:10, 232.76it/s] 26%|‚ñà‚ñà‚ñå       | 848/3257 [00:03<00:10, 225.21it/s] 27%|‚ñà‚ñà‚ñã       | 873/3257 [00:03<00:10, 230.70it/s] 28%|‚ñà‚ñà‚ñä       | 897/3257 [00:04<00:10, 232.54it/s] 28%|‚ñà‚ñà‚ñä       | 924/3257 [00:04<00:09, 240.35it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:04<00:09, 235.75it/s] 30%|‚ñà‚ñà‚ñâ       | 973/3257 [00:04<00:09, 234.38it/s] 31%|‚ñà‚ñà‚ñà       | 997/3257 [00:04<00:09, 230.71it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1022/3257 [00:04<00:09, 234.82it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:04<00:10, 219.00it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1071/3257 [00:04<00:09, 227.14it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:04<00:10, 216.16it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1119/3257 [00:05<00:09, 220.00it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1142/3257 [00:05<00:09, 221.64it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:05<00:09, 229.98it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:05<00:09, 213.88it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1216/3257 [00:05<00:09, 211.73it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:05<00:08, 225.98it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1269/3257 [00:05<00:08, 233.80it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1293/3257 [00:05<00:10, 194.15it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1314/3257 [00:06<00:10, 193.07it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1336/3257 [00:06<00:09, 199.16it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1357/3257 [00:06<00:09, 195.25it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1377/3257 [00:06<00:09, 191.98it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1397/3257 [00:06<00:09, 191.06it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:06<00:09, 203.80it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1443/3257 [00:06<00:09, 197.77it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1467/3257 [00:06<00:08, 208.20it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1488/3257 [00:06<00:08, 204.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:06<00:08, 211.18it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1533/3257 [00:07<00:08, 193.15it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1553/3257 [00:07<00:09, 186.04it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:07<00:08, 190.27it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:07<00:08, 191.54it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1616/3257 [00:07<00:08, 198.10it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1636/3257 [00:07<00:08, 187.35it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1655/3257 [00:07<00:08, 182.24it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:07<00:08, 175.99it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:08<00:09, 172.34it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1713/3257 [00:08<00:08, 180.80it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1732/3257 [00:08<00:09, 168.27it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1750/3257 [00:08<00:14, 103.45it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:08<00:12, 121.80it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:08<00:10, 139.03it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1809/3257 [00:08<00:10, 142.04it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:09<00:09, 151.89it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:09<00:08, 164.40it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1870/3257 [00:09<00:07, 175.10it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1889/3257 [00:09<00:07, 177.32it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1910/3257 [00:09<00:07, 185.02it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1930/3257 [00:09<00:07, 181.40it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1957/3257 [00:09<00:06, 204.83it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1978/3257 [00:09<00:06, 194.43it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:09<00:06, 195.90it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2019/3257 [00:09<00:06, 195.25it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2039/3257 [00:10<00:06, 192.64it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2059/3257 [00:10<00:06, 175.72it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2079/3257 [00:10<00:06, 181.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2098/3257 [00:10<00:06, 175.92it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2119/3257 [00:10<00:06, 185.19it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2138/3257 [00:10<00:06, 169.97it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2156/3257 [00:10<00:06, 169.78it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2177/3257 [00:10<00:06, 179.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2196/3257 [00:10<00:06, 173.14it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2214/3257 [00:11<00:06, 167.00it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2235/3257 [00:11<00:05, 177.72it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2253/3257 [00:11<00:05, 174.05it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2271/3257 [00:11<00:05, 167.95it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2292/3257 [00:11<00:05, 178.98it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2311/3257 [00:11<00:05, 179.36it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2335/3257 [00:11<00:04, 195.76it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:11<00:04, 202.47it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2382/3257 [00:11<00:04, 204.48it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:12<00:04, 208.09it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2425/3257 [00:12<00:04, 196.36it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2445/3257 [00:12<00:04, 184.70it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2467/3257 [00:12<00:04, 194.11it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2488/3257 [00:12<00:03, 197.51it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2512/3257 [00:12<00:03, 208.06it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2535/3257 [00:12<00:03, 212.71it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2557/3257 [00:12<00:03, 197.68it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2578/3257 [00:12<00:03, 192.92it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2598/3257 [00:13<00:03, 189.78it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2625/3257 [00:13<00:02, 210.90it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2647/3257 [00:13<00:03, 196.77it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2668/3257 [00:13<00:03, 195.60it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2688/3257 [00:13<00:02, 194.49it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2708/3257 [00:13<00:03, 177.60it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2729/3257 [00:13<00:02, 185.01it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2751/3257 [00:13<00:02, 192.04it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2771/3257 [00:13<00:02, 187.46it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2794/3257 [00:14<00:02, 198.47it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2815/3257 [00:14<00:02, 193.71it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2835/3257 [00:14<00:02, 185.23it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2858/3257 [00:14<00:02, 197.21it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2884/3257 [00:14<00:01, 214.47it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:14<00:01, 193.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:14<00:01, 197.55it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2949/3257 [00:14<00:01, 184.31it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:15<00:01, 187.40it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2989/3257 [00:15<00:01, 181.70it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:15<00:01, 189.80it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3032/3257 [00:15<00:01, 191.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3054/3257 [00:15<00:01, 197.94it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3078/3257 [00:15<00:00, 208.80it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3100/3257 [00:15<00:00, 205.46it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3124/3257 [00:15<00:00, 212.38it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3146/3257 [00:16<00:01, 109.98it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:16<00:00, 123.02it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:16<00:00, 132.75it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3204/3257 [00:16<00:00, 149.33it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3223/3257 [00:16<00:00, 155.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3247/3257 [00:16<00:00, 175.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 194.33it/s]
2023-02-07 19:47:44.462 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:47:44,463][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d345,n5,s0.56863,t4>', 'datetime': '2023-02-07T19:47:44.463289', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:47:44,463][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:47:44,463][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:47:44,892][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 19:47:44,892][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:47:44,949][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 21699 unique words (100.00% of original 21699, drops 0)', 'datetime': '2023-02-07T19:47:44.949341', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:47:44,949][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 4367244 word corpus (100.00% of original 4367244, drops 0)', 'datetime': '2023-02-07T19:47:44.949754', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:47:45,026][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 19:47:45,027][gensim.models.word2vec][INFO] - sample=0.56863 downsamples 0 most-common words
[2023-02-07 19:47:45,027][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4367244 word corpus (100.0%% of prior 4367244)', 'datetime': '2023-02-07T19:47:45.027571', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:47:45,164][gensim.models.word2vec][INFO] - estimated required memory for 21699 words and 345 dimensions: 75884800 bytes
[2023-02-07 19:47:45,165][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:47:45,204][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 21699 vocabulary and 345 features, using sg=1 hs=0 sample=0.5686297339640933 negative=5 window=6 shrink_windows=True', 'datetime': '2023-02-07T19:47:45.204719', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:47:46,208][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 24.90% examples, 1079172 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:47,208][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 62.85% examples, 1395042 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:48,124][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4368669 effective words) took 2.9s, 1497477 effective words/s
[2023-02-07 19:47:49,129][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 40.01% examples, 1797369 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:50,133][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 82.47% examples, 1814112 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:50,527][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4368669 effective words) took 2.4s, 1820434 effective words/s
[2023-02-07 19:47:51,531][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 40.01% examples, 1797109 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:47:52,532][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 82.41% examples, 1811468 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:52,938][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4368669 effective words) took 2.4s, 1813166 effective words/s
[2023-02-07 19:47:53,944][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 40.22% examples, 1803831 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:54,946][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 82.84% examples, 1823639 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:55,336][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4368669 effective words) took 2.4s, 1823180 effective words/s
[2023-02-07 19:47:56,340][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 40.22% examples, 1806262 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:57,342][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 82.68% examples, 1815646 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:57,734][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4368669 effective words) took 2.4s, 1823190 effective words/s
[2023-02-07 19:47:58,750][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 40.93% examples, 1813282 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:59,751][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 83.24% examples, 1822653 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:00,138][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4368669 effective words) took 2.4s, 1819207 effective words/s
[2023-02-07 19:48:01,144][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 40.01% examples, 1792185 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:02,151][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 82.84% examples, 1818156 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:02,532][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4368669 effective words) took 2.4s, 1826200 effective words/s
[2023-02-07 19:48:03,546][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 40.93% examples, 1816503 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:04,555][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 83.51% examples, 1825567 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:04,925][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4368669 effective words) took 2.4s, 1827160 effective words/s
[2023-02-07 19:48:05,930][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 40.22% examples, 1802071 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:06,932][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 82.28% examples, 1807078 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:07,345][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4368669 effective words) took 2.4s, 1806410 effective words/s
[2023-02-07 19:48:08,347][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 40.44% examples, 1818792 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:09,357][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 83.51% examples, 1836068 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:09,717][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4368669 effective words) took 2.4s, 1843248 effective words/s
[2023-02-07 19:48:10,723][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 41.17% examples, 1838278 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:11,723][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 84.37% examples, 1855264 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:12,082][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4368669 effective words) took 2.4s, 1848839 effective words/s
[2023-02-07 19:48:13,092][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 40.01% examples, 1786162 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:14,098][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 82.47% examples, 1806842 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:48:14,485][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4368669 effective words) took 2.4s, 1819707 effective words/s
[2023-02-07 19:48:15,490][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 40.93% examples, 1831094 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:16,496][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 83.51% examples, 1836651 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:16,850][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4368669 effective words) took 2.4s, 1848027 effective words/s
[2023-02-07 19:48:17,859][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 41.73% examples, 1861821 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:18,870][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 85.23% examples, 1864173 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:19,197][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4368669 effective words) took 2.3s, 1863047 effective words/s
[2023-02-07 19:48:20,208][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 40.93% examples, 1822132 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:48:21,216][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 83.85% examples, 1834596 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:21,572][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4368669 effective words) took 2.4s, 1840665 effective words/s
[2023-02-07 19:48:21,573][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65530035 effective words) took 36.4s, 1801838 effective words/s', 'datetime': '2023-02-07T19:48:21.573637', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:48:21.573 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:48:24,994][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194719-3iv5gfxr/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:48:24.994480', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:48:24,995][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:48:25,109][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194719-3iv5gfxr/files/../tmp/embedding_model.pt
2023-02-07 19:48:25.110 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:48:27.297 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:48:28.058 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:48:36.887 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9975876798942648, 'test_mae': 0.7389702870527659, 'test_r2': -2.146994045261865}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.6
wandb: percentage 0.0
wandb:   test_mae 0.73897
wandb:   test_mse 0.99759
wandb:    test_r2 -2.14699
wandb: 
wandb: üöÄ View run eager-sweep-56 at: https://wandb.ai/xiaoqiz/mof2vec/runs/3iv5gfxr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_194719-3iv5gfxr/logs
wandb: Agent Starting Run: 3a25pmim with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 1005
wandb: 	model.gensim.alpha: 0.04282332009941221
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.32049902708993677
wandb: 	model.gensim.vector_size: 105
wandb: 	model.gensim.window: 6
wandb: 	model.sklearn.learning_rate: 0.02760380702843988
wandb: 	model.sklearn.max_depth: 34
wandb: 	model.sklearn.min_child_weight: 0.09095527187696588
wandb: 	model.sklearn.n_estimators: 1194
wandb: 	model.sklearn.num_leaves: 440
wandb: 	model.sklearn.reg_alpha: 0.03689962398933295
wandb: 	model.sklearn.reg_lambda: 0.05720063506863791
wandb: 	model.sklearn.subsample: 0.2871645442993064
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194849-3a25pmim
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-57
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/3a25pmim
2023-02-07 19:48:57.869 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:48:57.869 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 1005 for sweep.
2023-02-07 19:48:57.870 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.04282332009941221 for sweep.
2023-02-07 19:48:57.870 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:48:57.870 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 19:48:57.870 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.32049902708993677 for sweep.
2023-02-07 19:48:57.871 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 105 for sweep.
2023-02-07 19:48:57.871 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 6 for sweep.
2023-02-07 19:48:57.871 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.02760380702843988 for sweep.
2023-02-07 19:48:57.871 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 34 for sweep.
2023-02-07 19:48:57.872 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09095527187696588 for sweep.
2023-02-07 19:48:57.872 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1194 for sweep.
2023-02-07 19:48:57.872 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 440 for sweep.
2023-02-07 19:48:57.872 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.03689962398933295 for sweep.
2023-02-07 19:48:57.873 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.05720063506863791 for sweep.
2023-02-07 19:48:57.873 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2871645442993064 for sweep.
2023-02-07 19:48:57.873 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:48:57.878 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194849-3a25pmim/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 1005, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 105, 'window': 6, 'min_count': 1, 'dm': 1, 'sample': 0.32049902708993677, 'workers': 4, 'alpha': 0.04282332009941221, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1194, 'max_depth': 34, 'num_leaves': 440, 'reg_alpha': 0.03689962398933295, 'reg_lambda': 0.05720063506863791, 'subsample': 0.2871645442993064, 'min_child_weight': 0.09095527187696588, 'n_jobs': 4, 'learning_rate': 0.02760380702843988}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:20, 157.48it/s]  1%|          | 34/3257 [00:00<00:19, 161.64it/s]  2%|‚ñè         | 53/3257 [00:00<00:19, 163.59it/s]  2%|‚ñè         | 71/3257 [00:00<00:18, 169.49it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 174.89it/s]  3%|‚ñé         | 108/3257 [00:00<00:19, 165.55it/s]  4%|‚ñç         | 125/3257 [00:00<00:18, 165.18it/s]  4%|‚ñç         | 146/3257 [00:00<00:17, 177.67it/s]  5%|‚ñå         | 164/3257 [00:00<00:18, 168.40it/s]  6%|‚ñå         | 182/3257 [00:01<00:17, 171.29it/s]  6%|‚ñå         | 201/3257 [00:01<00:17, 171.29it/s]  7%|‚ñã         | 223/3257 [00:01<00:16, 184.14it/s]  7%|‚ñã         | 243/3257 [00:01<00:16, 187.36it/s]  8%|‚ñä         | 262/3257 [00:01<00:16, 177.94it/s]  9%|‚ñâ         | 285/3257 [00:01<00:15, 190.38it/s]  9%|‚ñâ         | 305/3257 [00:01<00:16, 183.65it/s] 10%|‚ñà         | 326/3257 [00:01<00:15, 189.70it/s] 11%|‚ñà         | 346/3257 [00:01<00:16, 177.19it/s] 11%|‚ñà         | 364/3257 [00:02<00:16, 177.36it/s] 12%|‚ñà‚ñè        | 382/3257 [00:02<00:16, 170.75it/s] 12%|‚ñà‚ñè        | 400/3257 [00:02<00:17, 167.19it/s] 13%|‚ñà‚ñé        | 419/3257 [00:02<00:16, 173.44it/s] 13%|‚ñà‚ñé        | 437/3257 [00:02<00:18, 149.37it/s] 14%|‚ñà‚ñç        | 456/3257 [00:02<00:17, 159.36it/s] 15%|‚ñà‚ñç        | 474/3257 [00:02<00:17, 162.15it/s] 15%|‚ñà‚ñå        | 492/3257 [00:02<00:16, 166.03it/s] 16%|‚ñà‚ñå        | 512/3257 [00:02<00:15, 174.57it/s] 16%|‚ñà‚ñã        | 530/3257 [00:03<00:15, 171.74it/s] 17%|‚ñà‚ñã        | 548/3257 [00:03<00:16, 169.14it/s] 17%|‚ñà‚ñã        | 566/3257 [00:03<00:16, 158.60it/s] 18%|‚ñà‚ñä        | 583/3257 [00:03<00:17, 154.07it/s] 18%|‚ñà‚ñä        | 601/3257 [00:03<00:16, 160.50it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:16, 160.92it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:03<00:15, 169.28it/s] 20%|‚ñà‚ñà        | 658/3257 [00:03<00:16, 156.00it/s] 21%|‚ñà‚ñà        | 677/3257 [00:03<00:15, 164.61it/s] 21%|‚ñà‚ñà‚ñè       | 694/3257 [00:04<00:16, 159.67it/s] 22%|‚ñà‚ñà‚ñè       | 711/3257 [00:04<00:15, 161.36it/s] 22%|‚ñà‚ñà‚ñè       | 728/3257 [00:04<00:16, 154.67it/s] 23%|‚ñà‚ñà‚ñé       | 744/3257 [00:04<00:16, 151.07it/s] 23%|‚ñà‚ñà‚ñé       | 763/3257 [00:04<00:15, 161.17it/s] 24%|‚ñà‚ñà‚ñç       | 780/3257 [00:04<00:15, 156.35it/s] 25%|‚ñà‚ñà‚ñç       | 799/3257 [00:04<00:15, 163.18it/s] 25%|‚ñà‚ñà‚ñå       | 816/3257 [00:04<00:14, 163.86it/s] 26%|‚ñà‚ñà‚ñå       | 833/3257 [00:04<00:15, 156.67it/s] 26%|‚ñà‚ñà‚ñå       | 849/3257 [00:05<00:15, 152.07it/s] 27%|‚ñà‚ñà‚ñã       | 867/3257 [00:05<00:15, 158.82it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:05<00:15, 154.53it/s] 28%|‚ñà‚ñà‚ñä       | 906/3257 [00:05<00:13, 168.66it/s] 28%|‚ñà‚ñà‚ñä       | 925/3257 [00:05<00:13, 173.17it/s] 29%|‚ñà‚ñà‚ñâ       | 943/3257 [00:05<00:13, 170.33it/s] 30%|‚ñà‚ñà‚ñâ       | 962/3257 [00:05<00:13, 175.06it/s] 30%|‚ñà‚ñà‚ñà       | 980/3257 [00:05<00:13, 167.11it/s] 31%|‚ñà‚ñà‚ñà       | 997/3257 [00:05<00:13, 165.64it/s] 31%|‚ñà‚ñà‚ñà       | 1014/3257 [00:06<00:13, 163.76it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1031/3257 [00:06<00:13, 162.51it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1048/3257 [00:06<00:13, 158.22it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:06<00:13, 163.24it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1084/3257 [00:06<00:13, 163.46it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1102/3257 [00:06<00:12, 165.93it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1119/3257 [00:06<00:13, 164.25it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1137/3257 [00:06<00:12, 167.81it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1154/3257 [00:06<00:12, 164.10it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:07<00:12, 171.52it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:07<00:13, 154.62it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:07<00:22, 90.89it/s]  38%|‚ñà‚ñà‚ñà‚ñä      | 1226/3257 [00:07<00:18, 108.54it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:07<00:16, 123.11it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1264/3257 [00:07<00:14, 137.68it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1281/3257 [00:07<00:14, 133.83it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1297/3257 [00:08<00:14, 138.52it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1317/3257 [00:08<00:12, 152.76it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1334/3257 [00:08<00:12, 156.87it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1351/3257 [00:08<00:12, 157.06it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1369/3257 [00:08<00:11, 162.41it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:08<00:11, 156.23it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1406/3257 [00:08<00:11, 167.36it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1426/3257 [00:08<00:10, 176.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1444/3257 [00:08<00:10, 176.56it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1465/3257 [00:09<00:09, 185.42it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1484/3257 [00:09<00:09, 181.98it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1505/3257 [00:09<00:09, 187.95it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1524/3257 [00:09<00:10, 169.41it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1542/3257 [00:09<00:10, 167.04it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1559/3257 [00:09<00:10, 160.97it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1576/3257 [00:09<00:10, 160.76it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:09<00:09, 168.70it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1616/3257 [00:09<00:09, 177.38it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:10<00:09, 166.93it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1651/3257 [00:10<00:09, 164.80it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:10<00:09, 163.11it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1685/3257 [00:10<00:09, 159.82it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1704/3257 [00:10<00:09, 167.40it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:10<00:08, 170.67it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1741/3257 [00:10<00:09, 154.83it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1762/3257 [00:10<00:08, 168.35it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1780/3257 [00:10<00:08, 170.70it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1799/3257 [00:11<00:08, 173.53it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1817/3257 [00:11<00:08, 170.53it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1835/3257 [00:11<00:08, 167.96it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1854/3257 [00:11<00:08, 173.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1874/3257 [00:11<00:07, 179.15it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1892/3257 [00:11<00:07, 170.89it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1914/3257 [00:11<00:07, 183.41it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1933/3257 [00:11<00:07, 178.92it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1957/3257 [00:11<00:06, 194.37it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1977/3257 [00:12<00:06, 189.18it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1997/3257 [00:12<00:06, 186.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2016/3257 [00:12<00:06, 183.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:12<00:06, 183.65it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2054/3257 [00:12<00:07, 170.19it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2072/3257 [00:12<00:07, 167.40it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:12<00:06, 171.14it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2109/3257 [00:12<00:06, 170.03it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2127/3257 [00:12<00:07, 160.70it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2144/3257 [00:13<00:07, 157.50it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:13<00:06, 165.77it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:13<00:06, 168.78it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2201/3257 [00:13<00:06, 175.22it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:13<00:06, 170.12it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:13<00:06, 169.88it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2255/3257 [00:13<00:05, 167.30it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2272/3257 [00:13<00:06, 158.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2293/3257 [00:13<00:05, 172.65it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2311/3257 [00:14<00:05, 170.18it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2333/3257 [00:14<00:05, 183.88it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2355/3257 [00:14<00:04, 192.87it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2375/3257 [00:14<00:04, 184.57it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2396/3257 [00:14<00:04, 190.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2416/3257 [00:14<00:04, 174.67it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2434/3257 [00:14<00:04, 165.84it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2451/3257 [00:14<00:04, 161.74it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2473/3257 [00:14<00:04, 176.52it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2491/3257 [00:15<00:04, 175.45it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2512/3257 [00:15<00:04, 183.78it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2531/3257 [00:15<00:03, 185.46it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2550/3257 [00:15<00:03, 181.93it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2569/3257 [00:15<00:04, 164.46it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:15<00:04, 164.38it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2605/3257 [00:15<00:03, 171.31it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2628/3257 [00:15<00:03, 186.65it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2647/3257 [00:15<00:03, 177.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2666/3257 [00:16<00:06, 91.29it/s]  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2686/3257 [00:16<00:05, 108.88it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2702/3257 [00:16<00:05, 109.69it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2717/3257 [00:16<00:04, 116.95it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2738/3257 [00:16<00:03, 137.31it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:16<00:03, 147.18it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2773/3257 [00:16<00:03, 149.55it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2794/3257 [00:17<00:02, 165.36it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2812/3257 [00:17<00:02, 168.52it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2830/3257 [00:17<00:02, 155.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2850/3257 [00:17<00:02, 165.19it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:17<00:02, 179.74it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2891/3257 [00:17<00:02, 178.52it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2910/3257 [00:17<00:02, 169.69it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:17<00:01, 171.57it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2946/3257 [00:18<00:01, 164.29it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2964/3257 [00:18<00:01, 167.89it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2981/3257 [00:18<00:01, 158.76it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3002/3257 [00:18<00:01, 170.64it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3020/3257 [00:18<00:01, 165.58it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3041/3257 [00:18<00:01, 174.87it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:18<00:01, 184.31it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:18<00:00, 182.10it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3101/3257 [00:18<00:00, 183.98it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3122/3257 [00:18<00:00, 188.70it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3141/3257 [00:19<00:00, 177.65it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3159/3257 [00:19<00:00, 172.67it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3177/3257 [00:19<00:00, 165.86it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3197/3257 [00:19<00:00, 172.26it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3215/3257 [00:19<00:00, 165.68it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3236/3257 [00:19<00:00, 176.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3254/3257 [00:19<00:00, 171.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 164.66it/s]
2023-02-07 19:49:18.382 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:49:18,384][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d105,n5,w6,s0.320499,t4>', 'datetime': '2023-02-07T19:49:18.384879', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:49:18,385][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:49:18,385][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:49:18,905][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:49:18,906][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:49:18,990][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 31803 unique words (100.00% of original 31803, drops 0)', 'datetime': '2023-02-07T19:49:18.990442', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:49:18,990][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 5095118 word corpus (100.00% of original 5095118, drops 0)', 'datetime': '2023-02-07T19:49:18.990909', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:49:19,102][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:49:19,103][gensim.models.word2vec][INFO] - sample=0.320499 downsamples 0 most-common words
[2023-02-07 19:49:19,104][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5095118 word corpus (100.0%% of prior 5095118)', 'datetime': '2023-02-07T19:49:19.104270', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:49:19,296][gensim.models.word2vec][INFO] - estimated required memory for 31803 words and 105 dimensions: 44635360 bytes
[2023-02-07 19:49:19,296][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:49:19,313][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 31803 vocabulary and 105 features, using sg=0 hs=0 sample=0.32049902708993677 negative=5 window=6 shrink_windows=True', 'datetime': '2023-02-07T19:49:19.313680', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:49:20,319][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 43.02% examples, 2245106 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:21,320][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 89.22% examples, 2279872 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:21,536][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5086629 effective words) took 2.2s, 2290842 effective words/s
[2023-02-07 19:49:22,541][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 45.47% examples, 2352699 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:23,543][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 91.80% examples, 2347300 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:23,704][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5086629 effective words) took 2.2s, 2348272 effective words/s
[2023-02-07 19:49:24,706][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 46.27% examples, 2389543 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:25,709][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 93.80% examples, 2388586 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:25,827][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5086629 effective words) took 2.1s, 2396721 effective words/s
[2023-02-07 19:49:26,830][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 45.96% examples, 2377018 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:27,833][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 94.60% examples, 2406503 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:27,935][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5086629 effective words) took 2.1s, 2415214 effective words/s
[2023-02-07 19:49:28,941][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 46.64% examples, 2404706 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:29,944][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 94.44% examples, 2399119 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:30,054][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5086629 effective words) took 2.1s, 2401476 effective words/s
[2023-02-07 19:49:31,063][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 46.79% examples, 2408486 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:32,068][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 96.59% examples, 2444146 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:32,132][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5086629 effective words) took 2.1s, 2449070 effective words/s
[2023-02-07 19:49:33,139][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 46.64% examples, 2404623 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:34,142][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 94.60% examples, 2402393 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:34,242][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5086629 effective words) took 2.1s, 2412245 effective words/s
[2023-02-07 19:49:35,246][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 47.37% examples, 2454913 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:36,247][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 96.96% examples, 2466133 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:49:36,304][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5086629 effective words) took 2.1s, 2469592 effective words/s
[2023-02-07 19:49:37,306][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 48.57% examples, 2525708 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:38,301][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5086629 effective words) took 2.0s, 2548458 effective words/s
[2023-02-07 19:49:39,309][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 47.71% examples, 2466670 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:40,310][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 98.13% examples, 2488092 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:40,341][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5086629 effective words) took 2.0s, 2495365 effective words/s
[2023-02-07 19:49:41,345][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 49.25% examples, 2547456 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:42,326][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5086629 effective words) took 2.0s, 2564312 effective words/s
[2023-02-07 19:49:43,330][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 49.25% examples, 2547952 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:44,331][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 99.97% examples, 2533775 words/s, in_qsize 1, out_qsize 1
[2023-02-07 19:49:44,332][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5086629 effective words) took 2.0s, 2537055 effective words/s
[2023-02-07 19:49:45,340][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 48.36% examples, 2500046 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:46,336][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5086629 effective words) took 2.0s, 2539797 effective words/s
[2023-02-07 19:49:47,338][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 49.46% examples, 2563085 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:48,326][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5086629 effective words) took 2.0s, 2557621 effective words/s
[2023-02-07 19:49:49,332][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 51.21% examples, 2652035 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:50,145][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5086629 effective words) took 1.8s, 2798410 effective words/s
[2023-02-07 19:49:50,146][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76299435 effective words) took 30.8s, 2474691 effective words/s', 'datetime': '2023-02-07T19:49:50.146049', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:49:50.146 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:49:52,842][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194849-3a25pmim/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:49:52.841900', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:49:52,843][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:49:52,928][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194849-3a25pmim/files/../tmp/embedding_model.pt
2023-02-07 19:49:52.928 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:49:54.226 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:49:54.698 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:49:59.152 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1594287691820173, 'test_mae': 0.8251415063724196, 'test_r2': -3.417720768277329}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.84
wandb: percentage 0.0
wandb:   test_mae 0.82514
wandb:   test_mse 1.15943
wandb:    test_r2 -3.41772
wandb: 
wandb: üöÄ View run easy-sweep-57 at: https://wandb.ai/xiaoqiz/mof2vec/runs/3a25pmim
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_194849-3a25pmim/logs
wandb: Agent Starting Run: xy091oz6 with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 537
wandb: 	model.gensim.alpha: 0.003385460023882399
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.6903633113566299
wandb: 	model.gensim.vector_size: 214
wandb: 	model.gensim.window: 14
wandb: 	model.sklearn.learning_rate: 0.018017569947017455
wandb: 	model.sklearn.max_depth: 38
wandb: 	model.sklearn.min_child_weight: 0.06953685366384289
wandb: 	model.sklearn.n_estimators: 2870
wandb: 	model.sklearn.num_leaves: 326
wandb: 	model.sklearn.reg_alpha: 0.00559538405816801
wandb: 	model.sklearn.reg_lambda: 0.3326787145647219
wandb: 	model.sklearn.subsample: 0.28492120926742104
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195009-xy091oz6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-58
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/xy091oz6
2023-02-07 19:50:18.142 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 19:50:18.143 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 537 for sweep.
2023-02-07 19:50:18.143 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.003385460023882399 for sweep.
2023-02-07 19:50:18.144 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:50:18.144 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 19:50:18.144 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6903633113566299 for sweep.
2023-02-07 19:50:18.144 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 214 for sweep.
2023-02-07 19:50:18.145 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 14 for sweep.
2023-02-07 19:50:18.145 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.018017569947017455 for sweep.
2023-02-07 19:50:18.145 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 38 for sweep.
2023-02-07 19:50:18.145 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.06953685366384289 for sweep.
2023-02-07 19:50:18.146 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2870 for sweep.
2023-02-07 19:50:18.147 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 326 for sweep.
2023-02-07 19:50:18.147 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.00559538405816801 for sweep.
2023-02-07 19:50:18.147 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.3326787145647219 for sweep.
2023-02-07 19:50:18.147 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.28492120926742104 for sweep.
2023-02-07 19:50:18.148 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:50:18.155 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195009-xy091oz6/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 537, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 214, 'window': 14, 'min_count': 8, 'dm': 0, 'sample': 0.6903633113566299, 'workers': 4, 'alpha': 0.003385460023882399, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2870, 'max_depth': 38, 'num_leaves': 326, 'reg_alpha': 0.00559538405816801, 'reg_lambda': 0.3326787145647219, 'subsample': 0.28492120926742104, 'min_child_weight': 0.06953685366384289, 'n_jobs': 4, 'learning_rate': 0.018017569947017455}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 171.09it/s]  1%|          | 38/3257 [00:00<00:17, 186.21it/s]  2%|‚ñè         | 57/3257 [00:00<00:17, 177.99it/s]  2%|‚ñè         | 79/3257 [00:00<00:16, 190.09it/s]  3%|‚ñé         | 99/3257 [00:00<00:17, 185.62it/s]  4%|‚ñé         | 118/3257 [00:00<00:17, 179.40it/s]  4%|‚ñç         | 137/3257 [00:00<00:17, 182.44it/s]  5%|‚ñç         | 158/3257 [00:00<00:16, 188.61it/s]  5%|‚ñå         | 177/3257 [00:00<00:16, 185.84it/s]  6%|‚ñå         | 197/3257 [00:01<00:16, 188.36it/s]  7%|‚ñã         | 219/3257 [00:01<00:15, 195.62it/s]  7%|‚ñã         | 242/3257 [00:01<00:14, 205.51it/s]  8%|‚ñä         | 263/3257 [00:01<00:15, 196.56it/s]  9%|‚ñâ         | 287/3257 [00:01<00:14, 207.44it/s]  9%|‚ñâ         | 308/3257 [00:01<00:14, 200.15it/s] 10%|‚ñà         | 329/3257 [00:01<00:14, 201.65it/s] 11%|‚ñà         | 350/3257 [00:01<00:14, 194.20it/s] 11%|‚ñà‚ñè        | 373/3257 [00:01<00:14, 201.35it/s] 12%|‚ñà‚ñè        | 394/3257 [00:02<00:15, 184.68it/s] 13%|‚ñà‚ñé        | 416/3257 [00:02<00:14, 191.75it/s] 13%|‚ñà‚ñé        | 436/3257 [00:02<00:16, 166.92it/s] 14%|‚ñà‚ñç        | 457/3257 [00:02<00:15, 176.75it/s] 15%|‚ñà‚ñç        | 477/3257 [00:02<00:15, 182.49it/s] 15%|‚ñà‚ñå        | 499/3257 [00:02<00:14, 190.50it/s] 16%|‚ñà‚ñå        | 521/3257 [00:02<00:13, 197.50it/s] 17%|‚ñà‚ñã        | 542/3257 [00:02<00:13, 196.26it/s] 17%|‚ñà‚ñã        | 562/3257 [00:02<00:14, 184.41it/s] 18%|‚ñà‚ñä        | 581/3257 [00:03<00:15, 176.02it/s] 18%|‚ñà‚ñä        | 602/3257 [00:03<00:14, 183.26it/s] 19%|‚ñà‚ñâ        | 621/3257 [00:03<00:14, 183.33it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:03<00:13, 187.10it/s] 20%|‚ñà‚ñà        | 660/3257 [00:03<00:14, 174.36it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:14, 178.84it/s] 22%|‚ñà‚ñà‚ñè       | 703/3257 [00:03<00:13, 184.49it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:03<00:13, 183.58it/s] 23%|‚ñà‚ñà‚ñé       | 741/3257 [00:03<00:14, 176.59it/s] 23%|‚ñà‚ñà‚ñé       | 765/3257 [00:04<00:12, 192.80it/s] 24%|‚ñà‚ñà‚ñç       | 785/3257 [00:04<00:13, 184.66it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:13, 187.58it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:04<00:12, 187.25it/s] 26%|‚ñà‚ñà‚ñå       | 844/3257 [00:04<00:20, 115.69it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:04<00:18, 130.21it/s] 27%|‚ñà‚ñà‚ñã       | 882/3257 [00:04<00:16, 140.56it/s] 28%|‚ñà‚ñà‚ñä       | 903/3257 [00:05<00:15, 156.32it/s] 28%|‚ñà‚ñà‚ñä       | 921/3257 [00:05<00:14, 161.88it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:05<00:13, 165.76it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:05<00:13, 175.10it/s] 30%|‚ñà‚ñà‚ñà       | 978/3257 [00:05<00:12, 177.82it/s] 31%|‚ñà‚ñà‚ñà       | 997/3257 [00:05<00:13, 169.38it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:05<00:13, 168.57it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1033/3257 [00:05<00:13, 163.52it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1050/3257 [00:05<00:13, 162.89it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1071/3257 [00:06<00:12, 173.29it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1089/3257 [00:06<00:12, 171.93it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1107/3257 [00:06<00:12, 172.37it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1125/3257 [00:06<00:12, 172.43it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:06<00:12, 172.41it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1163/3257 [00:06<00:11, 177.94it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1181/3257 [00:06<00:12, 167.63it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1198/3257 [00:06<00:12, 165.47it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1215/3257 [00:06<00:12, 158.85it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1237/3257 [00:06<00:11, 175.39it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1255/3257 [00:07<00:11, 173.70it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:07<00:11, 173.59it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1293/3257 [00:07<00:11, 167.37it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:07<00:11, 173.19it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1333/3257 [00:07<00:10, 180.40it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1352/3257 [00:07<00:10, 179.43it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1371/3257 [00:07<00:10, 174.59it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1389/3257 [00:07<00:10, 170.36it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:07<00:09, 186.98it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:08<00:09, 186.53it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:08<00:09, 189.03it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1473/3257 [00:08<00:09, 194.54it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1493/3257 [00:08<00:09, 194.66it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1514/3257 [00:08<00:08, 199.07it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1534/3257 [00:08<00:09, 181.74it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1553/3257 [00:08<00:09, 177.79it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1573/3257 [00:08<00:09, 182.53it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1592/3257 [00:08<00:09, 177.78it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1613/3257 [00:09<00:08, 185.35it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1633/3257 [00:09<00:08, 187.32it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1652/3257 [00:09<00:09, 168.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1670/3257 [00:09<00:09, 166.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1688/3257 [00:09<00:09, 169.73it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:09<00:08, 173.62it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1727/3257 [00:09<00:08, 178.36it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:09<00:09, 161.20it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1766/3257 [00:09<00:08, 173.61it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1788/3257 [00:10<00:08, 182.96it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1807/3257 [00:10<00:08, 175.62it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:10<00:07, 179.68it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:10<00:07, 184.57it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1871/3257 [00:10<00:07, 193.34it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1891/3257 [00:10<00:07, 187.92it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1913/3257 [00:10<00:06, 196.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1933/3257 [00:10<00:06, 192.89it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1958/3257 [00:10<00:06, 208.85it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1980/3257 [00:11<00:06, 198.69it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2001/3257 [00:11<00:06, 199.67it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:11<00:06, 197.61it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2042/3257 [00:11<00:06, 189.49it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2062/3257 [00:11<00:06, 179.69it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:11<00:06, 184.73it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2102/3257 [00:11<00:06, 180.88it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:11<00:06, 176.84it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2141/3257 [00:11<00:06, 181.09it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2160/3257 [00:12<00:06, 180.22it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:12<00:05, 185.26it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2202/3257 [00:12<00:08, 125.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:12<00:07, 133.70it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:12<00:07, 143.79it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2256/3257 [00:12<00:06, 152.55it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2273/3257 [00:12<00:06, 152.63it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2296/3257 [00:12<00:05, 172.46it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:13<00:05, 173.44it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2338/3257 [00:13<00:04, 189.02it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:13<00:04, 197.66it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2382/3257 [00:13<00:04, 202.69it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2405/3257 [00:13<00:04, 200.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2426/3257 [00:13<00:04, 193.61it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2446/3257 [00:13<00:04, 184.27it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2465/3257 [00:13<00:04, 183.21it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2484/3257 [00:13<00:04, 184.51it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2508/3257 [00:14<00:03, 198.22it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2529/3257 [00:14<00:03, 199.54it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2550/3257 [00:14<00:03, 197.58it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2570/3257 [00:14<00:03, 183.30it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2589/3257 [00:14<00:03, 178.90it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:14<00:03, 196.19it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2635/3257 [00:14<00:03, 199.70it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:14<00:03, 192.17it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2676/3257 [00:14<00:03, 188.45it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2695/3257 [00:15<00:03, 182.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2714/3257 [00:15<00:03, 173.78it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2735/3257 [00:15<00:02, 183.31it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:15<00:02, 192.30it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2777/3257 [00:15<00:02, 185.61it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2801/3257 [00:15<00:02, 200.15it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2822/3257 [00:15<00:02, 192.52it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:15<00:02, 184.08it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2868/3257 [00:15<00:01, 204.10it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2889/3257 [00:16<00:01, 202.80it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2910/3257 [00:16<00:01, 191.49it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2930/3257 [00:16<00:01, 191.37it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:16<00:01, 186.80it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2971/3257 [00:16<00:01, 192.83it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2991/3257 [00:16<00:01, 180.53it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3014/3257 [00:16<00:01, 192.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3036/3257 [00:16<00:01, 199.73it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3059/3257 [00:16<00:00, 207.78it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3081/3257 [00:16<00:00, 210.64it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3103/3257 [00:17<00:00, 208.91it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3124/3257 [00:17<00:00, 207.43it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3145/3257 [00:17<00:00, 194.39it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:17<00:00, 192.92it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:17<00:00, 190.53it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:17<00:00, 196.04it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3227/3257 [00:17<00:00, 192.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3252/3257 [00:17<00:00, 206.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 181.97it/s]
2023-02-07 19:50:36.629 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:50:36,630][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d214,n5,mc8,s0.690363,t4>', 'datetime': '2023-02-07T19:50:36.630414', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:50:36,630][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:50:36,630][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:50:37,046][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 19:50:37,046][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:50:37,076][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 9584 unique words (44.17% of original 21699, drops 12115)', 'datetime': '2023-02-07T19:50:37.076823', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:50:37,077][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 4331919 word corpus (99.19% of original 4367244, drops 35325)', 'datetime': '2023-02-07T19:50:37.077333', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:50:37,110][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 19:50:37,111][gensim.models.word2vec][INFO] - sample=0.690363 downsamples 0 most-common words
[2023-02-07 19:50:37,111][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4331919 word corpus (100.0%% of prior 4331919)', 'datetime': '2023-02-07T19:50:37.111397', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:50:37,169][gensim.models.word2vec][INFO] - estimated required memory for 9584 words and 214 dimensions: 24639200 bytes
[2023-02-07 19:50:37,171][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:50:37,182][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 9584 vocabulary and 214 features, using sg=1 hs=0 sample=0.6903633113566299 negative=5 window=14 shrink_windows=True', 'datetime': '2023-02-07T19:50:37.182531', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:50:38,187][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 48.33% examples, 2136515 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:39,177][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4333519 effective words) took 2.0s, 2176215 effective words/s
[2023-02-07 19:50:40,183][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 51.43% examples, 2270432 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:50:41,061][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4333519 effective words) took 1.9s, 2301592 effective words/s
[2023-02-07 19:50:42,064][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 52.44% examples, 2326542 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:50:42,913][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4333519 effective words) took 1.9s, 2341706 effective words/s
[2023-02-07 19:50:43,922][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 52.44% examples, 2314770 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:50:44,641][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4333519 effective words) took 1.7s, 2510895 effective words/s
[2023-02-07 19:50:45,643][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 63.06% examples, 2778422 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:50:46,214][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4333519 effective words) took 1.6s, 2757569 effective words/s
[2023-02-07 19:50:47,218][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 55.20% examples, 2443522 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:50:47,938][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4333519 effective words) took 1.7s, 2515193 effective words/s
[2023-02-07 19:50:48,942][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 65.09% examples, 2871754 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:50:49,463][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4333519 effective words) took 1.5s, 2843727 effective words/s
[2023-02-07 19:50:50,467][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 58.46% examples, 2584680 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:50:51,197][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4333519 effective words) took 1.7s, 2501124 effective words/s
[2023-02-07 19:50:52,199][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 55.39% examples, 2458093 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:50:52,942][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4333519 effective words) took 1.7s, 2485497 effective words/s
[2023-02-07 19:50:53,944][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 50.29% examples, 2215043 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:50:54,770][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4333519 effective words) took 1.8s, 2372422 effective words/s
[2023-02-07 19:50:55,771][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 63.99% examples, 2824316 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:50:56,308][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4333519 effective words) took 1.5s, 2819841 effective words/s
[2023-02-07 19:50:57,309][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 63.99% examples, 2823595 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:50:57,833][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4333519 effective words) took 1.5s, 2841793 effective words/s
[2023-02-07 19:50:58,843][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 61.68% examples, 2696681 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:50:59,494][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4333519 effective words) took 1.7s, 2611653 effective words/s
[2023-02-07 19:51:00,496][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 54.10% examples, 2402837 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:51:01,295][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4333519 effective words) took 1.8s, 2408370 effective words/s
[2023-02-07 19:51:02,298][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 55.02% examples, 2438524 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:51:03,062][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4333519 effective words) took 1.8s, 2455503 effective words/s
[2023-02-07 19:51:03,063][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65002785 effective words) took 25.9s, 2511695 effective words/s', 'datetime': '2023-02-07T19:51:03.063032', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:51:03.063 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:51:05,499][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195009-xy091oz6/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:51:05.499221', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:51:05,499][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:51:05,530][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195009-xy091oz6/files/../tmp/embedding_model.pt
2023-02-07 19:51:05.531 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:51:07.112 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:51:07.699 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:51:11.893 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0100827537861892, 'test_mae': 0.7703583734624225, 'test_r2': -1.962030331043449}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.71
wandb: percentage 0.55832
wandb:   test_mae 0.77036
wandb:   test_mse 1.01008
wandb:    test_r2 -1.96203
wandb: 
wandb: üöÄ View run dulcet-sweep-58 at: https://wandb.ai/xiaoqiz/mof2vec/runs/xy091oz6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195009-xy091oz6/logs
wandb: Agent Starting Run: u6g6toik with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 570
wandb: 	model.gensim.alpha: 0.0011814712882272066
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.5107122309330776
wandb: 	model.gensim.vector_size: 100
wandb: 	model.gensim.window: 5
wandb: 	model.sklearn.learning_rate: 0.0017174846397395437
wandb: 	model.sklearn.max_depth: 43
wandb: 	model.sklearn.min_child_weight: 0.04028729833610328
wandb: 	model.sklearn.n_estimators: 1356
wandb: 	model.sklearn.num_leaves: 391
wandb: 	model.sklearn.reg_alpha: 0.002905213903884403
wandb: 	model.sklearn.reg_lambda: 0.009550480154849642
wandb: 	model.sklearn.subsample: 0.20106180726864809
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195122-u6g6toik
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-59
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/u6g6toik
2023-02-07 19:51:31.531 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:51:31.531 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 570 for sweep.
2023-02-07 19:51:31.532 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0011814712882272066 for sweep.
2023-02-07 19:51:31.532 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:51:31.532 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 19:51:31.533 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5107122309330776 for sweep.
2023-02-07 19:51:31.533 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 100 for sweep.
2023-02-07 19:51:31.533 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 5 for sweep.
2023-02-07 19:51:31.533 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0017174846397395437 for sweep.
2023-02-07 19:51:31.534 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 43 for sweep.
2023-02-07 19:51:31.534 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.04028729833610328 for sweep.
2023-02-07 19:51:31.534 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1356 for sweep.
2023-02-07 19:51:31.534 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 391 for sweep.
2023-02-07 19:51:31.535 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.002905213903884403 for sweep.
2023-02-07 19:51:31.535 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.009550480154849642 for sweep.
2023-02-07 19:51:31.535 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.20106180726864809 for sweep.
2023-02-07 19:51:31.535 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:51:31.541 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195122-u6g6toik/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 570, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 100, 'window': 5, 'min_count': 3, 'dm': 1, 'sample': 0.5107122309330776, 'workers': 4, 'alpha': 0.0011814712882272066, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1356, 'max_depth': 43, 'num_leaves': 391, 'reg_alpha': 0.002905213903884403, 'reg_lambda': 0.009550480154849642, 'subsample': 0.20106180726864809, 'min_child_weight': 0.04028729833610328, 'n_jobs': 4, 'learning_rate': 0.0017174846397395437}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:20, 155.06it/s]  1%|          | 34/3257 [00:00<00:20, 157.33it/s]  2%|‚ñè         | 52/3257 [00:00<00:19, 165.60it/s]  2%|‚ñè         | 69/3257 [00:00<00:20, 159.03it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 168.89it/s]  3%|‚ñé         | 107/3257 [00:00<00:19, 158.25it/s]  4%|‚ñç         | 124/3257 [00:00<00:19, 158.71it/s]  4%|‚ñç         | 145/3257 [00:00<00:18, 171.02it/s]  5%|‚ñå         | 163/3257 [00:01<00:18, 163.72it/s]  6%|‚ñå         | 180/3257 [00:01<00:18, 164.82it/s]  6%|‚ñå         | 199/3257 [00:01<00:17, 171.99it/s]  7%|‚ñã         | 218/3257 [00:01<00:17, 176.69it/s]  7%|‚ñã         | 237/3257 [00:01<00:16, 180.36it/s]  8%|‚ñä         | 256/3257 [00:01<00:16, 182.42it/s]  8%|‚ñä         | 275/3257 [00:01<00:16, 180.25it/s]  9%|‚ñâ         | 296/3257 [00:01<00:15, 187.99it/s] 10%|‚ñâ         | 315/3257 [00:01<00:16, 178.36it/s] 10%|‚ñà         | 335/3257 [00:01<00:15, 183.86it/s] 11%|‚ñà         | 354/3257 [00:02<00:16, 180.76it/s] 11%|‚ñà‚ñè        | 373/3257 [00:02<00:16, 179.68it/s] 12%|‚ñà‚ñè        | 392/3257 [00:02<00:25, 112.60it/s] 13%|‚ñà‚ñé        | 412/3257 [00:02<00:22, 129.18it/s] 13%|‚ñà‚ñé        | 428/3257 [00:02<00:22, 125.58it/s] 14%|‚ñà‚ñé        | 446/3257 [00:02<00:20, 136.58it/s] 14%|‚ñà‚ñç        | 465/3257 [00:02<00:18, 147.62it/s] 15%|‚ñà‚ñç        | 482/3257 [00:03<00:18, 150.67it/s] 15%|‚ñà‚ñå        | 502/3257 [00:03<00:16, 162.96it/s] 16%|‚ñà‚ñå        | 522/3257 [00:03<00:16, 167.72it/s] 17%|‚ñà‚ñã        | 542/3257 [00:03<00:15, 173.42it/s] 17%|‚ñà‚ñã        | 560/3257 [00:03<00:16, 160.32it/s] 18%|‚ñà‚ñä        | 577/3257 [00:03<00:17, 154.18it/s] 18%|‚ñà‚ñä        | 598/3257 [00:03<00:15, 168.58it/s] 19%|‚ñà‚ñâ        | 617/3257 [00:03<00:15, 173.35it/s] 19%|‚ñà‚ñâ        | 635/3257 [00:03<00:15, 171.68it/s] 20%|‚ñà‚ñà        | 653/3257 [00:04<00:16, 162.18it/s] 21%|‚ñà‚ñà        | 670/3257 [00:04<00:16, 157.08it/s] 21%|‚ñà‚ñà        | 686/3257 [00:04<00:16, 152.51it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:04<00:15, 159.61it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:04<00:15, 159.93it/s] 23%|‚ñà‚ñà‚ñé       | 739/3257 [00:04<00:16, 153.73it/s] 23%|‚ñà‚ñà‚ñé       | 759/3257 [00:04<00:15, 163.24it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:04<00:15, 159.80it/s] 24%|‚ñà‚ñà‚ñç       | 795/3257 [00:04<00:14, 167.98it/s] 25%|‚ñà‚ñà‚ñç       | 813/3257 [00:05<00:14, 170.75it/s] 26%|‚ñà‚ñà‚ñå       | 831/3257 [00:05<00:14, 162.10it/s] 26%|‚ñà‚ñà‚ñå       | 848/3257 [00:05<00:15, 156.79it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:05<00:14, 160.08it/s] 27%|‚ñà‚ñà‚ñã       | 883/3257 [00:05<00:14, 162.22it/s] 28%|‚ñà‚ñà‚ñä       | 902/3257 [00:05<00:13, 169.07it/s] 28%|‚ñà‚ñà‚ñä       | 919/3257 [00:05<00:14, 166.49it/s] 29%|‚ñà‚ñà‚ñä       | 936/3257 [00:05<00:13, 166.06it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:05<00:13, 174.92it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:05<00:13, 171.27it/s] 30%|‚ñà‚ñà‚ñà       | 992/3257 [00:06<00:13, 166.56it/s] 31%|‚ñà‚ñà‚ñà       | 1009/3257 [00:06<00:13, 162.96it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:06<00:13, 163.08it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1044/3257 [00:06<00:13, 161.68it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1061/3257 [00:06<00:13, 163.43it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:13, 162.72it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:06<00:13, 164.75it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1116/3257 [00:06<00:12, 171.56it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1134/3257 [00:06<00:13, 160.56it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1151/3257 [00:07<00:13, 156.32it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:07<00:12, 165.92it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:07<00:13, 152.98it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:07<00:13, 155.22it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1223/3257 [00:07<00:12, 161.81it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:07<00:11, 171.26it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1261/3257 [00:07<00:11, 171.13it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1279/3257 [00:07<00:12, 160.28it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1296/3257 [00:07<00:12, 159.20it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1316/3257 [00:08<00:11, 169.66it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1335/3257 [00:08<00:11, 173.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1353/3257 [00:08<00:11, 169.35it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1371/3257 [00:08<00:11, 166.29it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:08<00:11, 162.92it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1409/3257 [00:08<00:10, 173.89it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1430/3257 [00:08<00:09, 183.13it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1449/3257 [00:08<00:09, 184.15it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1471/3257 [00:08<00:09, 190.83it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1491/3257 [00:09<00:09, 186.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:09<00:09, 189.97it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1531/3257 [00:09<00:15, 109.23it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:09<00:14, 114.76it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1565/3257 [00:09<00:13, 129.29it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1582/3257 [00:09<00:12, 138.44it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1603/3257 [00:09<00:10, 154.21it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1621/3257 [00:10<00:10, 158.05it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:10<00:10, 160.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:10<00:10, 158.80it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:10<00:09, 161.05it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:10<00:09, 161.73it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1711/3257 [00:10<00:08, 172.12it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:10<00:09, 163.39it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1746/3257 [00:10<00:09, 162.88it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1765/3257 [00:10<00:08, 168.42it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1785/3257 [00:11<00:08, 176.47it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:11<00:08, 177.14it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:11<00:08, 174.68it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1839/3257 [00:11<00:08, 172.82it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1858/3257 [00:11<00:08, 173.30it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:11<00:07, 182.48it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1898/3257 [00:11<00:07, 179.52it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:11<00:07, 178.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:11<00:07, 185.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:11<00:06, 199.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:12<00:06, 190.50it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2002/3257 [00:12<00:06, 191.77it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:12<00:06, 191.71it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2042/3257 [00:12<00:06, 181.19it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2061/3257 [00:12<00:07, 166.38it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2082/3257 [00:12<00:06, 176.14it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:12<00:06, 170.21it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:12<00:06, 171.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2138/3257 [00:12<00:06, 171.60it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2156/3257 [00:13<00:06, 169.52it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2177/3257 [00:13<00:05, 180.33it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2196/3257 [00:13<00:05, 178.83it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2214/3257 [00:13<00:06, 171.69it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2235/3257 [00:13<00:05, 180.88it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2254/3257 [00:13<00:05, 175.86it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2272/3257 [00:13<00:05, 165.28it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2293/3257 [00:13<00:05, 176.06it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2311/3257 [00:13<00:05, 175.89it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2335/3257 [00:14<00:04, 193.18it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:14<00:04, 200.48it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2381/3257 [00:14<00:04, 200.19it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2403/3257 [00:14<00:04, 203.31it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2424/3257 [00:14<00:04, 190.26it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2444/3257 [00:14<00:04, 174.16it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2464/3257 [00:14<00:04, 179.47it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2483/3257 [00:14<00:04, 181.77it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2506/3257 [00:14<00:03, 194.34it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2526/3257 [00:15<00:03, 192.68it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2546/3257 [00:15<00:03, 194.28it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2566/3257 [00:15<00:03, 180.48it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2585/3257 [00:15<00:03, 173.55it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2605/3257 [00:15<00:03, 180.63it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2629/3257 [00:15<00:03, 196.40it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2649/3257 [00:15<00:03, 188.43it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2669/3257 [00:15<00:03, 186.22it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:15<00:02, 191.01it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2710/3257 [00:16<00:03, 168.30it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2731/3257 [00:16<00:02, 178.01it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2752/3257 [00:16<00:02, 184.69it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2771/3257 [00:16<00:02, 178.48it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:16<00:02, 186.52it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2811/3257 [00:16<00:02, 185.25it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2830/3257 [00:16<00:02, 172.87it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2848/3257 [00:17<00:03, 106.25it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2873/3257 [00:17<00:02, 132.97it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2893/3257 [00:17<00:02, 141.99it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2913/3257 [00:17<00:02, 154.85it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2931/3257 [00:17<00:02, 159.92it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2949/3257 [00:17<00:01, 158.42it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:17<00:01, 166.53it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2987/3257 [00:17<00:01, 161.96it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:17<00:01, 179.90it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3030/3257 [00:18<00:01, 177.73it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3051/3257 [00:18<00:01, 185.99it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:18<00:00, 196.79it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3095/3257 [00:18<00:00, 192.61it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:18<00:00, 200.79it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3139/3257 [00:18<00:00, 194.75it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3159/3257 [00:18<00:00, 186.28it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3178/3257 [00:18<00:00, 175.46it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3200/3257 [00:18<00:00, 187.19it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3219/3257 [00:19<00:00, 178.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3242/3257 [00:19<00:00, 191.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 168.93it/s]
2023-02-07 19:51:51.543 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:51:51,545][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w5,mc3,s0.510712,t4>', 'datetime': '2023-02-07T19:51:51.544968', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:51:51,545][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:51:51,545][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:51:52,061][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:51:52,061][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:51:52,129][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 22723 unique words (71.45% of original 31803, drops 9080)', 'datetime': '2023-02-07T19:51:52.129122', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:51:52,129][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 5081575 word corpus (99.73% of original 5095118, drops 13543)', 'datetime': '2023-02-07T19:51:52.129526', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:51:52,211][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:51:52,212][gensim.models.word2vec][INFO] - sample=0.510712 downsamples 0 most-common words
[2023-02-07 19:51:52,212][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5081575 word corpus (100.0%% of prior 5081575)', 'datetime': '2023-02-07T19:51:52.212898', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:51:52,353][gensim.models.word2vec][INFO] - estimated required memory for 22723 words and 100 dimensions: 31494100 bytes
[2023-02-07 19:51:52,354][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:51:52,366][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 22723 vocabulary and 100 features, using sg=0 hs=0 sample=0.5107122309330776 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-07T19:51:52.366067', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:51:53,370][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 40.50% examples, 2106349 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:51:54,377][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 85.39% examples, 2176398 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:51:54,682][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5073452 effective words) took 2.3s, 2192638 effective words/s
[2023-02-07 19:51:55,685][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 44.43% examples, 2305163 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:51:56,687][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 90.85% examples, 2317624 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:51:56,863][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5073452 effective words) took 2.2s, 2327075 effective words/s
[2023-02-07 19:51:57,865][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 45.69% examples, 2362716 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:51:58,869][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 94.20% examples, 2391507 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:51:58,979][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5073452 effective words) took 2.1s, 2400023 effective words/s
[2023-02-07 19:51:59,985][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 46.79% examples, 2407421 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:00,986][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 94.01% examples, 2385136 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:01,101][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5073452 effective words) took 2.1s, 2391253 effective words/s
[2023-02-07 19:52:02,104][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 45.29% examples, 2342627 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:03,107][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 92.78% examples, 2365368 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:03,242][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5073452 effective words) took 2.1s, 2371899 effective words/s
[2023-02-07 19:52:04,248][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 47.22% examples, 2433792 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:05,248][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 96.96% examples, 2456439 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:05,305][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5073452 effective words) took 2.1s, 2460146 effective words/s
[2023-02-07 19:52:06,312][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 47.71% examples, 2461466 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:07,315][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 97.36% examples, 2462443 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:07,360][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5073452 effective words) took 2.1s, 2470557 effective words/s
[2023-02-07 19:52:08,363][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 47.71% examples, 2471075 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:09,364][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 98.86% examples, 2509774 words/s, in_qsize 6, out_qsize 0
[2023-02-07 19:52:09,377][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5073452 effective words) took 2.0s, 2517079 effective words/s
[2023-02-07 19:52:10,380][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 49.46% examples, 2553391 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:11,382][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 99.69% examples, 2523195 words/s, in_qsize 2, out_qsize 1
[2023-02-07 19:52:11,385][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5073452 effective words) took 2.0s, 2528708 effective words/s
[2023-02-07 19:52:12,387][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 47.71% examples, 2471817 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:52:13,388][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 97.36% examples, 2469653 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:13,433][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5073452 effective words) took 2.0s, 2478040 effective words/s
[2023-02-07 19:52:14,436][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 47.07% examples, 2432022 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:15,438][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 96.59% examples, 2449696 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:15,499][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5073452 effective words) took 2.1s, 2457632 effective words/s
[2023-02-07 19:52:16,503][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 49.00% examples, 2537222 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:17,504][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 99.69% examples, 2524905 words/s, in_qsize 1, out_qsize 3
[2023-02-07 19:52:17,504][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5073452 effective words) took 2.0s, 2533817 effective words/s
[2023-02-07 19:52:18,513][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 49.25% examples, 2528481 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:19,495][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5073452 effective words) took 2.0s, 2549865 effective words/s
[2023-02-07 19:52:20,496][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 49.25% examples, 2548542 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:21,491][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5073452 effective words) took 2.0s, 2543420 effective words/s
[2023-02-07 19:52:22,492][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 49.25% examples, 2548827 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:23,482][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5073452 effective words) took 2.0s, 2549548 effective words/s
[2023-02-07 19:52:23,483][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76101780 effective words) took 31.1s, 2445700 effective words/s', 'datetime': '2023-02-07T19:52:23.483088', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:52:23.483 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:52:26,861][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195122-u6g6toik/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:52:26.861836', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:52:26,862][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:52:26,910][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195122-u6g6toik/files/../tmp/embedding_model.pt
2023-02-07 19:52:26.910 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:52:28.223 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:52:28.711 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:52:39.544 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.2390646685834548, 'test_mae': 0.8623344361142147, 'test_r2': -3.3372097605731597}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.18
wandb: percentage 0.28551
wandb:   test_mae 0.86233
wandb:   test_mse 1.23906
wandb:    test_r2 -3.33721
wandb: 
wandb: üöÄ View run dashing-sweep-59 at: https://wandb.ai/xiaoqiz/mof2vec/runs/u6g6toik
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195122-u6g6toik/logs
wandb: Agent Starting Run: mj1i5zug with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 892
wandb: 	model.gensim.alpha: 0.019967025645368345
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.7330346485903212
wandb: 	model.gensim.vector_size: 406
wandb: 	model.gensim.window: 13
wandb: 	model.sklearn.learning_rate: 0.8380421445799353
wandb: 	model.sklearn.max_depth: 65
wandb: 	model.sklearn.min_child_weight: 0.05000547630582836
wandb: 	model.sklearn.n_estimators: 1631
wandb: 	model.sklearn.num_leaves: 305
wandb: 	model.sklearn.reg_alpha: 0.0030145375904130117
wandb: 	model.sklearn.reg_lambda: 0.17252952702245894
wandb: 	model.sklearn.subsample: 0.2796182144279864
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195253-mj1i5zug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-60
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/mj1i5zug
2023-02-07 19:53:02.132 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:53:02.133 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 892 for sweep.
2023-02-07 19:53:02.133 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.019967025645368345 for sweep.
2023-02-07 19:53:02.133 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:53:02.134 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 19:53:02.134 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7330346485903212 for sweep.
2023-02-07 19:53:02.134 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 406 for sweep.
2023-02-07 19:53:02.134 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 13 for sweep.
2023-02-07 19:53:02.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.8380421445799353 for sweep.
2023-02-07 19:53:02.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 65 for sweep.
2023-02-07 19:53:02.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05000547630582836 for sweep.
2023-02-07 19:53:02.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1631 for sweep.
2023-02-07 19:53:02.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 305 for sweep.
2023-02-07 19:53:02.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0030145375904130117 for sweep.
2023-02-07 19:53:02.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.17252952702245894 for sweep.
2023-02-07 19:53:02.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2796182144279864 for sweep.
2023-02-07 19:53:02.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:53:02.141 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195253-mj1i5zug/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 892, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 406, 'window': 13, 'min_count': 6, 'dm': 0, 'sample': 0.7330346485903212, 'workers': 4, 'alpha': 0.019967025645368345, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1631, 'max_depth': 65, 'num_leaves': 305, 'reg_alpha': 0.0030145375904130117, 'reg_lambda': 0.17252952702245894, 'subsample': 0.2796182144279864, 'min_child_weight': 0.05000547630582836, 'n_jobs': 4, 'learning_rate': 0.8380421445799353}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:26, 121.83it/s]  1%|          | 30/3257 [00:00<00:21, 146.99it/s]  1%|‚ñè         | 46/3257 [00:00<00:21, 151.65it/s]  2%|‚ñè         | 62/3257 [00:00<00:21, 147.43it/s]  2%|‚ñè         | 80/3257 [00:00<00:20, 157.25it/s]  3%|‚ñé         | 96/3257 [00:00<00:20, 155.55it/s]  3%|‚ñé         | 112/3257 [00:00<00:20, 150.28it/s]  4%|‚ñç         | 128/3257 [00:00<00:20, 152.40it/s]  5%|‚ñç         | 147/3257 [00:00<00:19, 162.51it/s]  5%|‚ñå         | 164/3257 [00:01<00:20, 149.45it/s]  6%|‚ñå         | 180/3257 [00:01<00:20, 150.46it/s]  6%|‚ñå         | 197/3257 [00:01<00:19, 155.81it/s]  7%|‚ñã         | 215/3257 [00:01<00:18, 162.27it/s]  7%|‚ñã         | 232/3257 [00:01<00:18, 161.45it/s]  8%|‚ñä         | 249/3257 [00:01<00:18, 162.21it/s]  8%|‚ñä         | 266/3257 [00:01<00:19, 154.97it/s]  9%|‚ñâ         | 287/3257 [00:01<00:17, 166.78it/s]  9%|‚ñâ         | 304/3257 [00:01<00:18, 161.81it/s] 10%|‚ñâ         | 323/3257 [00:02<00:17, 169.54it/s] 10%|‚ñà         | 341/3257 [00:02<00:18, 161.87it/s] 11%|‚ñà         | 359/3257 [00:02<00:17, 165.25it/s] 12%|‚ñà‚ñè        | 376/3257 [00:02<00:18, 158.24it/s] 12%|‚ñà‚ñè        | 392/3257 [00:02<00:18, 153.00it/s] 13%|‚ñà‚ñé        | 410/3257 [00:02<00:17, 159.32it/s] 13%|‚ñà‚ñé        | 427/3257 [00:02<00:20, 139.52it/s] 14%|‚ñà‚ñé        | 443/3257 [00:02<00:19, 142.32it/s] 14%|‚ñà‚ñç        | 460/3257 [00:02<00:18, 148.63it/s] 15%|‚ñà‚ñç        | 477/3257 [00:03<00:18, 154.11it/s] 15%|‚ñà‚ñå        | 495/3257 [00:03<00:17, 159.62it/s] 16%|‚ñà‚ñå        | 514/3257 [00:03<00:16, 167.01it/s] 16%|‚ñà‚ñã        | 531/3257 [00:03<00:16, 163.07it/s] 17%|‚ñà‚ñã        | 548/3257 [00:03<00:16, 162.02it/s] 17%|‚ñà‚ñã        | 565/3257 [00:03<00:17, 150.67it/s] 18%|‚ñà‚ñä        | 581/3257 [00:03<00:18, 144.93it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:17, 152.90it/s] 19%|‚ñà‚ñâ        | 619/3257 [00:03<00:16, 164.70it/s] 20%|‚ñà‚ñâ        | 636/3257 [00:04<00:16, 160.05it/s] 20%|‚ñà‚ñà        | 653/3257 [00:04<00:17, 148.25it/s] 21%|‚ñà‚ñà        | 669/3257 [00:04<00:17, 144.57it/s] 21%|‚ñà‚ñà        | 684/3257 [00:04<00:18, 142.12it/s] 21%|‚ñà‚ñà‚ñè       | 699/3257 [00:04<00:18, 141.71it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:04<00:16, 151.57it/s] 23%|‚ñà‚ñà‚ñé       | 733/3257 [00:04<00:17, 146.21it/s] 23%|‚ñà‚ñà‚ñé       | 748/3257 [00:04<00:17, 144.30it/s] 23%|‚ñà‚ñà‚ñé       | 763/3257 [00:05<00:26, 92.42it/s]  24%|‚ñà‚ñà‚ñç       | 777/3257 [00:05<00:24, 101.72it/s] 24%|‚ñà‚ñà‚ñç       | 793/3257 [00:05<00:21, 114.52it/s] 25%|‚ñà‚ñà‚ñç       | 810/3257 [00:05<00:19, 127.35it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:05<00:18, 128.86it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:05<00:18, 130.07it/s] 26%|‚ñà‚ñà‚ñã       | 858/3257 [00:05<00:17, 140.18it/s] 27%|‚ñà‚ñà‚ñã       | 873/3257 [00:05<00:16, 141.82it/s] 27%|‚ñà‚ñà‚ñã       | 888/3257 [00:06<00:16, 142.79it/s] 28%|‚ñà‚ñà‚ñä       | 906/3257 [00:06<00:15, 151.82it/s] 28%|‚ñà‚ñà‚ñä       | 924/3257 [00:06<00:14, 158.37it/s] 29%|‚ñà‚ñà‚ñâ       | 941/3257 [00:06<00:15, 154.30it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:06<00:14, 159.19it/s] 30%|‚ñà‚ñà‚ñâ       | 976/3257 [00:06<00:14, 160.92it/s] 30%|‚ñà‚ñà‚ñà       | 993/3257 [00:06<00:14, 151.93it/s] 31%|‚ñà‚ñà‚ñà       | 1009/3257 [00:06<00:15, 147.93it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1026/3257 [00:06<00:14, 153.32it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1042/3257 [00:07<00:15, 141.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1058/3257 [00:07<00:15, 145.97it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1078/3257 [00:07<00:13, 159.53it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1095/3257 [00:07<00:14, 147.77it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1113/3257 [00:07<00:13, 156.09it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1129/3257 [00:07<00:14, 146.38it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1145/3257 [00:07<00:14, 147.30it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1163/3257 [00:07<00:13, 154.32it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1179/3257 [00:07<00:14, 144.58it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:08<00:14, 137.91it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1208/3257 [00:08<00:15, 134.92it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1225/3257 [00:08<00:14, 143.47it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:08<00:13, 149.71it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:08<00:13, 148.36it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:08<00:13, 148.98it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:08<00:13, 143.62it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:08<00:12, 150.49it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:08<00:12, 160.44it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1349/3257 [00:09<00:11, 172.12it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1367/3257 [00:09<00:11, 169.60it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:09<00:11, 166.31it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1407/3257 [00:09<00:10, 180.54it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1429/3257 [00:09<00:09, 191.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1449/3257 [00:09<00:09, 192.46it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1473/3257 [00:09<00:08, 204.08it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1494/3257 [00:09<00:08, 205.64it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1517/3257 [00:09<00:08, 209.51it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1538/3257 [00:10<00:09, 187.93it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1558/3257 [00:10<00:09, 184.25it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1577/3257 [00:10<00:09, 184.11it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1600/3257 [00:10<00:08, 196.08it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:10<00:08, 196.22it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1640/3257 [00:10<00:08, 192.42it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1660/3257 [00:10<00:08, 181.15it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1679/3257 [00:10<00:09, 167.66it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1698/3257 [00:10<00:09, 172.59it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1716/3257 [00:11<00:09, 166.13it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1733/3257 [00:11<00:09, 160.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1750/3257 [00:11<00:09, 159.52it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1767/3257 [00:11<00:09, 162.07it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1786/3257 [00:11<00:08, 167.17it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:11<00:08, 163.89it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1820/3257 [00:11<00:08, 161.67it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1837/3257 [00:11<00:09, 153.80it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1853/3257 [00:11<00:09, 155.48it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1872/3257 [00:11<00:08, 164.35it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1889/3257 [00:12<00:08, 164.78it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1908/3257 [00:12<00:07, 171.39it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1926/3257 [00:12<00:08, 165.68it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1949/3257 [00:12<00:07, 182.05it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1971/3257 [00:12<00:06, 191.13it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1991/3257 [00:12<00:07, 178.70it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2010/3257 [00:12<00:07, 175.64it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2031/3257 [00:12<00:06, 184.88it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2050/3257 [00:13<00:07, 164.18it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2067/3257 [00:13<00:07, 159.81it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:13<00:07, 163.29it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2102/3257 [00:13<00:07, 162.31it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:13<00:07, 160.20it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:13<00:06, 161.35it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:13<00:06, 158.10it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2170/3257 [00:13<00:10, 102.38it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:14<00:09, 111.02it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:14<00:08, 127.58it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:14<00:07, 132.48it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:14<00:07, 141.81it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2253/3257 [00:14<00:06, 146.41it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2269/3257 [00:14<00:06, 149.53it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2285/3257 [00:14<00:06, 152.28it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:14<00:06, 150.28it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2321/3257 [00:14<00:05, 162.47it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2342/3257 [00:14<00:05, 174.60it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2363/3257 [00:15<00:04, 183.35it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2383/3257 [00:15<00:04, 186.09it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:15<00:04, 190.10it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2424/3257 [00:15<00:04, 176.31it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2442/3257 [00:15<00:04, 164.30it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2461/3257 [00:15<00:04, 171.00it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:15<00:04, 175.03it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2503/3257 [00:15<00:04, 186.60it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2522/3257 [00:15<00:03, 186.22it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2541/3257 [00:16<00:03, 181.89it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2560/3257 [00:16<00:03, 174.43it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2578/3257 [00:16<00:04, 166.55it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2595/3257 [00:16<00:04, 161.15it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2617/3257 [00:16<00:03, 175.89it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2636/3257 [00:16<00:03, 177.99it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:16<00:03, 168.06it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2672/3257 [00:16<00:03, 171.08it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:16<00:03, 173.27it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2708/3257 [00:17<00:03, 152.39it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2724/3257 [00:17<00:03, 153.34it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2746/3257 [00:17<00:03, 168.46it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2764/3257 [00:17<00:02, 165.95it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2781/3257 [00:17<00:02, 165.23it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:17<00:02, 176.76it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2821/3257 [00:17<00:02, 170.81it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2839/3257 [00:17<00:02, 160.23it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2862/3257 [00:18<00:02, 177.66it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2885/3257 [00:18<00:01, 191.19it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2905/3257 [00:18<00:02, 168.24it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2927/3257 [00:18<00:01, 181.32it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2946/3257 [00:18<00:01, 163.19it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2964/3257 [00:18<00:01, 165.03it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2982/3257 [00:18<00:01, 155.24it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3003/3257 [00:18<00:01, 167.33it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3021/3257 [00:18<00:01, 164.64it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3041/3257 [00:19<00:01, 172.00it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:19<00:01, 182.50it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:19<00:00, 182.94it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3101/3257 [00:19<00:00, 183.76it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3122/3257 [00:19<00:00, 190.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3142/3257 [00:19<00:00, 178.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3161/3257 [00:19<00:00, 172.99it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3179/3257 [00:19<00:00, 160.69it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3200/3257 [00:19<00:00, 172.47it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3218/3257 [00:20<00:00, 162.46it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:20<00:00, 174.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 174.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 160.41it/s]
2023-02-07 19:53:23.284 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:53:23,285][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d406,n5,mc6,s0.733035,t4>', 'datetime': '2023-02-07T19:53:23.285166', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:53:23,285][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:53:23,285][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:53:23,873][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:53:23,874][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:53:23,936][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 20659 unique words (48.38% of original 42701, drops 22042)', 'datetime': '2023-02-07T19:53:23.936029', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:53:23,936][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 5765964 word corpus (99.02% of original 5822992, drops 57028)', 'datetime': '2023-02-07T19:53:23.936506', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:53:24,008][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:53:24,009][gensim.models.word2vec][INFO] - sample=0.733035 downsamples 0 most-common words
[2023-02-07 19:53:24,010][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5765964 word corpus (100.0%% of prior 5765964)', 'datetime': '2023-02-07T19:53:24.010249', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:53:24,135][gensim.models.word2vec][INFO] - estimated required memory for 20659 words and 406 dimensions: 83370700 bytes
[2023-02-07 19:53:24,135][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:53:24,173][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 20659 vocabulary and 406 features, using sg=1 hs=0 sample=0.7330346485903212 negative=5 window=13 shrink_windows=True', 'datetime': '2023-02-07T19:53:24.173303', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:53:25,178][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 27.11% examples, 1563773 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:26,184][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 55.39% examples, 1619409 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:27,187][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 85.32% examples, 1643042 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:27,663][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5739976 effective words) took 3.5s, 1646827 effective words/s
[2023-02-07 19:53:28,665][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 30.55% examples, 1761643 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:29,666][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 60.39% examples, 1758102 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:30,671][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 91.34% examples, 1755334 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:30,928][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5739976 effective words) took 3.3s, 1758661 effective words/s
[2023-02-07 19:53:31,934][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 30.92% examples, 1783219 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:32,939][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 62.11% examples, 1800701 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:33,940][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 93.55% examples, 1792692 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:34,135][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5739976 effective words) took 3.2s, 1791345 effective words/s
[2023-02-07 19:53:35,136][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 30.89% examples, 1780246 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:36,144][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 61.01% examples, 1772811 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:37,148][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 92.94% examples, 1783070 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:37,351][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5739976 effective words) took 3.2s, 1785797 effective words/s
[2023-02-07 19:53:38,356][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 31.26% examples, 1802513 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:39,356][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 62.82% examples, 1825535 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:40,366][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 95.18% examples, 1816118 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:40,502][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5739976 effective words) took 3.1s, 1822293 effective words/s
[2023-02-07 19:53:41,506][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 32.36% examples, 1875845 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:42,508][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 64.23% examples, 1873318 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:43,519][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 91.62% examples, 1757717 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:43,816][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5739976 effective words) took 3.3s, 1732843 effective words/s
[2023-02-07 19:53:44,820][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 31.81% examples, 1842098 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:45,822][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 63.89% examples, 1861244 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:46,824][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 97.21% examples, 1859377 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:46,900][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5739976 effective words) took 3.1s, 1862781 effective words/s
[2023-02-07 19:53:47,909][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 31.81% examples, 1831736 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:53:48,914][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 63.99% examples, 1857058 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:49,917][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 97.11% examples, 1851651 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:49,996][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5739976 effective words) took 3.1s, 1854884 effective words/s
[2023-02-07 19:53:51,004][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 32.02% examples, 1851566 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:52,005][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 63.99% examples, 1862581 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:53,008][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 97.21% examples, 1856926 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:53,084][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5739976 effective words) took 3.1s, 1859911 effective words/s
[2023-02-07 19:53:54,087][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 32.12% examples, 1860220 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:53:55,090][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 64.63% examples, 1886480 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:56,101][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 98.89% examples, 1885862 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:56,120][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5739976 effective words) took 3.0s, 1891543 effective words/s
[2023-02-07 19:53:57,123][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 32.88% examples, 1906112 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:58,123][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 65.24% examples, 1905185 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:53:59,127][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 98.89% examples, 1892358 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:59,147][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5739976 effective words) took 3.0s, 1897528 effective words/s
[2023-02-07 19:54:00,153][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 32.36% examples, 1871620 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:01,155][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 64.63% examples, 1883113 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:54:02,167][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 98.89% examples, 1883971 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:02,191][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5739976 effective words) took 3.0s, 1887806 effective words/s
[2023-02-07 19:54:03,200][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 31.53% examples, 1815942 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:54:04,202][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 65.46% examples, 1907168 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:54:05,040][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5739976 effective words) took 2.8s, 2016080 effective words/s
[2023-02-07 19:54:06,052][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 39.94% examples, 2331991 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:07,054][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 74.95% examples, 2170879 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:54:07,670][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5739976 effective words) took 2.6s, 2183309 effective words/s
[2023-02-07 19:54:08,680][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 38.99% examples, 2264558 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:54:09,684][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 78.05% examples, 2248293 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:10,264][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5739976 effective words) took 2.6s, 2214421 effective words/s
[2023-02-07 19:54:10,264][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86099640 effective words) took 46.1s, 1868138 effective words/s', 'datetime': '2023-02-07T19:54:10.264531', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:54:10.264 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:54:14,187][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195253-mj1i5zug/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:54:14.187431', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:54:14,188][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:54:14,302][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195253-mj1i5zug/files/../tmp/embedding_model.pt
2023-02-07 19:54:14.303 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:54:16.529 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:54:17.328 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:54:20.405 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9501923990314353, 'test_mae': 0.7322161497971031, 'test_r2': -1.9278597941167495}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.88
wandb: percentage 0.51619
wandb:   test_mae 0.73222
wandb:   test_mse 0.95019
wandb:    test_r2 -1.92786
wandb: 
wandb: üöÄ View run brisk-sweep-60 at: https://wandb.ai/xiaoqiz/mof2vec/runs/mj1i5zug
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195253-mj1i5zug/logs
wandb: Agent Starting Run: 653f0hx4 with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 873
wandb: 	model.gensim.alpha: 0.06830477796809965
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.41727946160019513
wandb: 	model.gensim.vector_size: 315
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.05671202836896536
wandb: 	model.sklearn.max_depth: 63
wandb: 	model.sklearn.min_child_weight: 0.05831372030072581
wandb: 	model.sklearn.n_estimators: 2148
wandb: 	model.sklearn.num_leaves: 419
wandb: 	model.sklearn.reg_alpha: 0.005123438266875646
wandb: 	model.sklearn.reg_lambda: 0.0026131844394215687
wandb: 	model.sklearn.subsample: 0.32274810851716906
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195431-653f0hx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-61
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/653f0hx4
2023-02-07 19:54:39.737 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 19:54:39.738 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 873 for sweep.
2023-02-07 19:54:39.738 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.06830477796809965 for sweep.
2023-02-07 19:54:39.739 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:54:39.739 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 19:54:39.739 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.41727946160019513 for sweep.
2023-02-07 19:54:39.739 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 315 for sweep.
2023-02-07 19:54:39.740 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 19:54:39.740 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.05671202836896536 for sweep.
2023-02-07 19:54:39.740 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 63 for sweep.
2023-02-07 19:54:39.740 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05831372030072581 for sweep.
2023-02-07 19:54:39.741 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2148 for sweep.
2023-02-07 19:54:39.741 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 419 for sweep.
2023-02-07 19:54:39.741 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.005123438266875646 for sweep.
2023-02-07 19:54:39.741 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0026131844394215687 for sweep.
2023-02-07 19:54:39.742 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.32274810851716906 for sweep.
2023-02-07 19:54:39.742 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:54:39.750 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195431-653f0hx4/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 873, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 315, 'window': 2, 'min_count': 2, 'dm': 0, 'sample': 0.41727946160019513, 'workers': 4, 'alpha': 0.06830477796809965, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2148, 'max_depth': 63, 'num_leaves': 419, 'reg_alpha': 0.005123438266875646, 'reg_lambda': 0.0026131844394215687, 'subsample': 0.32274810851716906, 'min_child_weight': 0.05831372030072581, 'n_jobs': 4, 'learning_rate': 0.05671202836896536}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 171.26it/s]  1%|          | 39/3257 [00:00<00:16, 192.45it/s]  2%|‚ñè         | 59/3257 [00:00<00:17, 182.53it/s]  2%|‚ñè         | 81/3257 [00:00<00:16, 194.54it/s]  3%|‚ñé         | 101/3257 [00:00<00:16, 195.76it/s]  4%|‚ñé         | 121/3257 [00:00<00:16, 187.56it/s]  4%|‚ñç         | 143/3257 [00:00<00:15, 196.18it/s]  5%|‚ñå         | 163/3257 [00:00<00:16, 189.89it/s]  6%|‚ñå         | 183/3257 [00:01<00:23, 129.61it/s]  6%|‚ñå         | 202/3257 [00:01<00:21, 142.08it/s]  7%|‚ñã         | 227/3257 [00:01<00:18, 167.66it/s]  8%|‚ñä         | 248/3257 [00:01<00:16, 177.53it/s]  8%|‚ñä         | 268/3257 [00:01<00:16, 175.91it/s]  9%|‚ñâ         | 294/3257 [00:01<00:14, 198.26it/s] 10%|‚ñâ         | 315/3257 [00:01<00:15, 194.35it/s] 10%|‚ñà         | 336/3257 [00:01<00:14, 197.36it/s] 11%|‚ñà         | 359/3257 [00:01<00:14, 202.19it/s] 12%|‚ñà‚ñè        | 380/3257 [00:02<00:15, 191.16it/s] 12%|‚ñà‚ñè        | 400/3257 [00:02<00:15, 190.23it/s] 13%|‚ñà‚ñé        | 420/3257 [00:02<00:14, 192.67it/s] 14%|‚ñà‚ñé        | 440/3257 [00:02<00:16, 172.33it/s] 14%|‚ñà‚ñç        | 461/3257 [00:02<00:15, 181.64it/s] 15%|‚ñà‚ñç        | 480/3257 [00:02<00:15, 180.17it/s] 15%|‚ñà‚ñå        | 502/3257 [00:02<00:14, 190.41it/s] 16%|‚ñà‚ñå        | 522/3257 [00:02<00:14, 191.11it/s] 17%|‚ñà‚ñã        | 543/3257 [00:02<00:13, 194.48it/s] 17%|‚ñà‚ñã        | 563/3257 [00:03<00:14, 179.85it/s] 18%|‚ñà‚ñä        | 582/3257 [00:03<00:15, 177.64it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:14, 187.85it/s] 19%|‚ñà‚ñâ        | 624/3257 [00:03<00:14, 187.79it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:13, 188.36it/s] 20%|‚ñà‚ñà        | 664/3257 [00:03<00:14, 182.46it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:14, 179.53it/s] 22%|‚ñà‚ñà‚ñè       | 702/3257 [00:03<00:14, 179.49it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:03<00:14, 180.19it/s] 23%|‚ñà‚ñà‚ñé       | 741/3257 [00:04<00:14, 173.01it/s] 23%|‚ñà‚ñà‚ñé       | 762/3257 [00:04<00:13, 183.16it/s] 24%|‚ñà‚ñà‚ñç       | 781/3257 [00:04<00:13, 179.90it/s] 25%|‚ñà‚ñà‚ñç       | 803/3257 [00:04<00:12, 189.85it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:04<00:13, 174.78it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:04<00:14, 169.20it/s] 26%|‚ñà‚ñà‚ñã       | 860/3257 [00:04<00:13, 174.12it/s] 27%|‚ñà‚ñà‚ñã       | 878/3257 [00:04<00:13, 170.24it/s] 28%|‚ñà‚ñà‚ñä       | 900/3257 [00:04<00:12, 183.29it/s] 28%|‚ñà‚ñà‚ñä       | 919/3257 [00:05<00:12, 180.73it/s] 29%|‚ñà‚ñà‚ñâ       | 938/3257 [00:05<00:12, 179.04it/s] 29%|‚ñà‚ñà‚ñâ       | 958/3257 [00:05<00:12, 184.03it/s] 30%|‚ñà‚ñà‚ñâ       | 977/3257 [00:05<00:12, 182.89it/s] 31%|‚ñà‚ñà‚ñà       | 996/3257 [00:05<00:13, 173.14it/s] 31%|‚ñà‚ñà‚ñà       | 1014/3257 [00:05<00:12, 174.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1033/3257 [00:05<00:12, 174.27it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:05<00:12, 173.29it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1071/3257 [00:05<00:12, 179.76it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1090/3257 [00:06<00:12, 175.39it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1110/3257 [00:06<00:11, 181.67it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1129/3257 [00:06<00:12, 176.38it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1147/3257 [00:06<00:12, 173.45it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:06<00:11, 184.01it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1189/3257 [00:06<00:12, 165.43it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:06<00:12, 168.81it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1228/3257 [00:06<00:11, 179.79it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:06<00:11, 182.21it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1268/3257 [00:07<00:10, 189.44it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:07<00:11, 171.80it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:07<00:11, 176.12it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:07<00:10, 182.33it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1348/3257 [00:07<00:10, 185.48it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1367/3257 [00:07<00:10, 175.57it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:07<00:10, 174.68it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1405/3257 [00:07<00:10, 180.99it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1427/3257 [00:07<00:09, 190.68it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1448/3257 [00:08<00:09, 194.34it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1471/3257 [00:08<00:08, 202.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1492/3257 [00:08<00:08, 202.70it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:08<00:08, 201.96it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1534/3257 [00:08<00:09, 185.43it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1553/3257 [00:08<00:09, 181.00it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1573/3257 [00:08<00:09, 185.96it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1592/3257 [00:08<00:14, 113.95it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:09<00:12, 135.16it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:09<00:11, 141.45it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1652/3257 [00:09<00:10, 149.71it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1670/3257 [00:09<00:10, 156.50it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1688/3257 [00:09<00:09, 161.47it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:09<00:09, 169.32it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:09<00:08, 170.45it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1746/3257 [00:09<00:08, 169.69it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1766/3257 [00:09<00:08, 177.60it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1787/3257 [00:10<00:07, 185.12it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1806/3257 [00:10<00:07, 183.32it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1825/3257 [00:10<00:07, 182.15it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1844/3257 [00:10<00:07, 183.65it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1865/3257 [00:10<00:07, 189.64it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1885/3257 [00:10<00:07, 186.20it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1905/3257 [00:10<00:07, 190.04it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1925/3257 [00:10<00:07, 186.94it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1951/3257 [00:10<00:06, 207.05it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:11<00:06, 209.52it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1996/3257 [00:11<00:06, 203.98it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2017/3257 [00:11<00:06, 199.71it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2038/3257 [00:11<00:06, 200.48it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2059/3257 [00:11<00:06, 183.24it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2081/3257 [00:11<00:06, 191.77it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2101/3257 [00:11<00:06, 183.01it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:11<00:06, 180.86it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2141/3257 [00:11<00:06, 185.58it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2160/3257 [00:12<00:05, 184.31it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:12<00:05, 187.36it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2203/3257 [00:12<00:05, 196.26it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2223/3257 [00:12<00:05, 193.77it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2243/3257 [00:12<00:05, 185.06it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2265/3257 [00:12<00:05, 192.17it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2285/3257 [00:12<00:05, 191.29it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2305/3257 [00:12<00:04, 190.57it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2330/3257 [00:12<00:04, 205.16it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2355/3257 [00:12<00:04, 217.82it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2377/3257 [00:13<00:04, 210.53it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2401/3257 [00:13<00:03, 218.45it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2423/3257 [00:13<00:04, 204.71it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2444/3257 [00:13<00:04, 192.49it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2467/3257 [00:13<00:03, 202.11it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2489/3257 [00:13<00:03, 203.64it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:13<00:03, 214.44it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2537/3257 [00:13<00:03, 216.70it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2559/3257 [00:13<00:03, 203.87it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2580/3257 [00:14<00:03, 193.76it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:14<00:03, 194.59it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2627/3257 [00:14<00:02, 214.77it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2649/3257 [00:14<00:02, 203.43it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2670/3257 [00:14<00:02, 202.51it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2691/3257 [00:14<00:02, 203.40it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2712/3257 [00:14<00:02, 182.90it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2734/3257 [00:14<00:02, 190.84it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:14<00:02, 200.55it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2778/3257 [00:15<00:02, 195.72it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:15<00:02, 207.55it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2824/3257 [00:15<00:02, 192.67it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2844/3257 [00:15<00:02, 193.23it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:15<00:01, 215.19it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2894/3257 [00:15<00:01, 202.53it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:15<00:01, 204.25it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2937/3257 [00:15<00:01, 204.28it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2958/3257 [00:16<00:02, 116.55it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2978/3257 [00:16<00:02, 130.66it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3000/3257 [00:16<00:01, 148.56it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3019/3257 [00:16<00:01, 156.13it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3042/3257 [00:16<00:01, 173.97it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3066/3257 [00:16<00:01, 190.14it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3087/3257 [00:16<00:00, 191.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3111/3257 [00:16<00:00, 204.03it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3133/3257 [00:17<00:00, 206.97it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3155/3257 [00:17<00:00, 198.86it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3176/3257 [00:17<00:00, 197.21it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3197/3257 [00:17<00:00, 198.87it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3218/3257 [00:17<00:00, 195.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:17<00:00, 208.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 184.19it/s]
2023-02-07 19:54:58.034 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:54:58,035][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d315,n5,mc2,s0.417279,t4>', 'datetime': '2023-02-07T19:54:58.035467', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:54:58,035][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:54:58,035][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:54:58,467][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 19:54:58,467][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:54:58,517][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 18495 unique words (85.23% of original 21699, drops 3204)', 'datetime': '2023-02-07T19:54:58.516975', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:54:58,517][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 4364040 word corpus (99.93% of original 4367244, drops 3204)', 'datetime': '2023-02-07T19:54:58.517926', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:54:58,583][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 19:54:58,583][gensim.models.word2vec][INFO] - sample=0.417279 downsamples 0 most-common words
[2023-02-07 19:54:58,584][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4364040 word corpus (100.0%% of prior 4364040)', 'datetime': '2023-02-07T19:54:58.584164', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:54:58,700][gensim.models.word2vec][INFO] - estimated required memory for 18495 words and 315 dimensions: 60610120 bytes
[2023-02-07 19:54:58,700][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:54:58,733][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18495 vocabulary and 315 features, using sg=1 hs=0 sample=0.41727946160019513 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T19:54:58.733388', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:54:59,738][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 43.87% examples, 1960340 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:00,743][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 90.08% examples, 1970954 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:00,947][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4365521 effective words) took 2.2s, 1974773 effective words/s
[2023-02-07 19:55:01,952][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 47.68% examples, 2121068 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:02,957][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 96.81% examples, 2107406 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:03,014][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4365521 effective words) took 2.1s, 2113319 effective words/s
[2023-02-07 19:55:04,017][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 47.22% examples, 2107385 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:05,022][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 96.81% examples, 2109571 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:05,079][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4365521 effective words) took 2.1s, 2115744 effective words/s
[2023-02-07 19:55:06,083][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 48.08% examples, 2141433 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:07,091][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 98.62% examples, 2144063 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:07,114][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4365521 effective words) took 2.0s, 2146885 effective words/s
[2023-02-07 19:55:08,116][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 47.68% examples, 2126714 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:09,116][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 97.27% examples, 2124178 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:09,169][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4365521 effective words) took 2.1s, 2125525 effective words/s
[2023-02-07 19:55:10,176][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 47.68% examples, 2118388 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:11,178][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 97.48% examples, 2122735 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:11,229][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4365521 effective words) took 2.1s, 2120771 effective words/s
[2023-02-07 19:55:12,235][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 48.08% examples, 2136827 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:13,245][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 97.76% examples, 2123075 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:13,282][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4365521 effective words) took 2.1s, 2128033 effective words/s
[2023-02-07 19:55:14,290][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 47.22% examples, 2097500 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:55:15,293][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 85.02% examples, 1865992 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:15,674][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4365521 effective words) took 2.4s, 1826354 effective words/s
[2023-02-07 19:55:16,681][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 33.13% examples, 1450224 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:17,687][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 66.66% examples, 1477114 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:18,568][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4365521 effective words) took 2.9s, 1509465 effective words/s
[2023-02-07 19:55:19,576][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 47.22% examples, 2097077 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:20,577][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 96.10% examples, 2091137 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:20,651][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4365521 effective words) took 2.1s, 2097367 effective words/s
[2023-02-07 19:55:21,661][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 47.22% examples, 2092402 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:22,662][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 96.81% examples, 2106341 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:22,720][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4365521 effective words) took 2.1s, 2111873 effective words/s
[2023-02-07 19:55:23,729][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 48.08% examples, 2128653 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:24,734][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 97.76% examples, 2125083 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:24,767][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4365521 effective words) took 2.0s, 2133198 effective words/s
[2023-02-07 19:55:25,770][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 47.68% examples, 2126607 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:26,776][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 97.76% examples, 2130365 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:26,811][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4365521 effective words) took 2.0s, 2137150 effective words/s
[2023-02-07 19:55:27,814][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 47.93% examples, 2136691 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:28,821][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 97.54% examples, 2124993 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:28,865][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4365521 effective words) took 2.1s, 2127638 effective words/s
[2023-02-07 19:55:29,876][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 46.70% examples, 2051444 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:30,876][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 93.92% examples, 2047361 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:31,000][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4365521 effective words) took 2.1s, 2045613 effective words/s
[2023-02-07 19:55:31,001][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65482815 effective words) took 32.3s, 2029394 effective words/s', 'datetime': '2023-02-07T19:55:31.001035', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:55:31.001 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:55:34,170][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195431-653f0hx4/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:55:34.170342', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:55:34,171][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:55:34,260][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195431-653f0hx4/files/../tmp/embedding_model.pt
2023-02-07 19:55:34.261 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:55:36.293 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:55:36.993 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:55:40.954 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0798548429685726, 'test_mae': 0.7932698163975236, 'test_r2': -2.3204889636065493}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.95
wandb: percentage 0.14766
wandb:   test_mae 0.79327
wandb:   test_mse 1.07985
wandb:    test_r2 -2.32049
wandb: 
wandb: üöÄ View run vocal-sweep-61 at: https://wandb.ai/xiaoqiz/mof2vec/runs/653f0hx4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195431-653f0hx4/logs
wandb: Agent Starting Run: 5rfluvi3 with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 887
wandb: 	model.gensim.alpha: 0.005869617529344579
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.4755120809089164
wandb: 	model.gensim.vector_size: 234
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.000814203769589158
wandb: 	model.sklearn.max_depth: 60
wandb: 	model.sklearn.min_child_weight: 0.03606476674879165
wandb: 	model.sklearn.n_estimators: 413
wandb: 	model.sklearn.num_leaves: 291
wandb: 	model.sklearn.reg_alpha: 0.003787748067211872
wandb: 	model.sklearn.reg_lambda: 0.33964920645355523
wandb: 	model.sklearn.subsample: 0.30844840048630806
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195556-5rfluvi3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-62
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/5rfluvi3
2023-02-07 19:56:04.663 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:56:04.663 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 887 for sweep.
2023-02-07 19:56:04.664 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.005869617529344579 for sweep.
2023-02-07 19:56:04.664 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:56:04.664 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 19:56:04.665 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4755120809089164 for sweep.
2023-02-07 19:56:04.665 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 234 for sweep.
2023-02-07 19:56:04.665 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 19:56:04.665 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.000814203769589158 for sweep.
2023-02-07 19:56:04.666 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 60 for sweep.
2023-02-07 19:56:04.666 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03606476674879165 for sweep.
2023-02-07 19:56:04.666 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 413 for sweep.
2023-02-07 19:56:04.666 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 291 for sweep.
2023-02-07 19:56:04.667 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.003787748067211872 for sweep.
2023-02-07 19:56:04.667 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.33964920645355523 for sweep.
2023-02-07 19:56:04.667 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.30844840048630806 for sweep.
2023-02-07 19:56:04.667 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:56:04.671 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195556-5rfluvi3/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 887, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 234, 'window': 11, 'min_count': 2, 'dm': 0, 'sample': 0.4755120809089164, 'workers': 4, 'alpha': 0.005869617529344579, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 413, 'max_depth': 60, 'num_leaves': 291, 'reg_alpha': 0.003787748067211872, 'reg_lambda': 0.33964920645355523, 'subsample': 0.30844840048630806, 'min_child_weight': 0.03606476674879165, 'n_jobs': 4, 'learning_rate': 0.000814203769589158}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:25, 128.84it/s]  1%|          | 30/3257 [00:00<00:21, 148.43it/s]  1%|‚ñè         | 45/3257 [00:00<00:21, 146.73it/s]  2%|‚ñè         | 60/3257 [00:00<00:22, 144.33it/s]  2%|‚ñè         | 78/3257 [00:00<00:20, 155.35it/s]  3%|‚ñé         | 94/3257 [00:00<00:20, 153.61it/s]  3%|‚ñé         | 110/3257 [00:00<00:21, 143.72it/s]  4%|‚ñç         | 127/3257 [00:00<00:20, 149.99it/s]  4%|‚ñç         | 145/3257 [00:00<00:19, 158.03it/s]  5%|‚ñç         | 161/3257 [00:01<00:20, 150.62it/s]  5%|‚ñå         | 177/3257 [00:01<00:20, 146.73it/s]  6%|‚ñå         | 195/3257 [00:01<00:19, 154.16it/s]  7%|‚ñã         | 212/3257 [00:01<00:19, 157.27it/s]  7%|‚ñã         | 232/3257 [00:01<00:17, 168.63it/s]  8%|‚ñä         | 249/3257 [00:01<00:17, 167.49it/s]  8%|‚ñä         | 266/3257 [00:01<00:18, 160.12it/s]  9%|‚ñâ         | 287/3257 [00:01<00:17, 172.88it/s]  9%|‚ñâ         | 305/3257 [00:01<00:17, 166.61it/s] 10%|‚ñâ         | 323/3257 [00:02<00:17, 168.78it/s] 10%|‚ñà         | 340/3257 [00:02<00:18, 159.70it/s] 11%|‚ñà         | 357/3257 [00:02<00:17, 162.33it/s] 11%|‚ñà‚ñè        | 374/3257 [00:02<00:18, 156.57it/s] 12%|‚ñà‚ñè        | 390/3257 [00:02<00:20, 143.08it/s] 12%|‚ñà‚ñè        | 407/3257 [00:02<00:19, 148.58it/s] 13%|‚ñà‚ñé        | 423/3257 [00:02<00:19, 147.35it/s] 13%|‚ñà‚ñé        | 438/3257 [00:02<00:21, 129.19it/s] 14%|‚ñà‚ñç        | 454/3257 [00:02<00:20, 136.69it/s] 14%|‚ñà‚ñç        | 472/3257 [00:03<00:18, 147.52it/s] 15%|‚ñà‚ñç        | 488/3257 [00:03<00:18, 146.81it/s] 16%|‚ñà‚ñå        | 506/3257 [00:03<00:17, 155.70it/s] 16%|‚ñà‚ñå        | 522/3257 [00:03<00:17, 156.80it/s] 17%|‚ñà‚ñã        | 539/3257 [00:03<00:17, 157.16it/s] 17%|‚ñà‚ñã        | 555/3257 [00:03<00:17, 157.44it/s] 18%|‚ñà‚ñä        | 571/3257 [00:03<00:20, 132.34it/s] 18%|‚ñà‚ñä        | 588/3257 [00:03<00:18, 141.34it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:18, 145.60it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:04<00:18, 146.31it/s] 20%|‚ñà‚ñâ        | 638/3257 [00:04<00:16, 155.61it/s] 20%|‚ñà‚ñà        | 654/3257 [00:04<00:17, 147.14it/s] 21%|‚ñà‚ñà        | 670/3257 [00:04<00:17, 144.23it/s] 21%|‚ñà‚ñà        | 685/3257 [00:04<00:18, 138.60it/s] 22%|‚ñà‚ñà‚ñè       | 701/3257 [00:04<00:17, 144.10it/s] 22%|‚ñà‚ñà‚ñè       | 719/3257 [00:04<00:16, 152.62it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:04<00:17, 148.27it/s] 23%|‚ñà‚ñà‚ñé       | 750/3257 [00:04<00:18, 139.23it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:05<00:16, 150.26it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:05<00:16, 145.50it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:16, 150.23it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:16, 148.61it/s] 26%|‚ñà‚ñà‚ñå       | 835/3257 [00:05<00:16, 143.27it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:05<00:18, 131.80it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:05<00:17, 137.96it/s] 27%|‚ñà‚ñà‚ñã       | 881/3257 [00:05<00:17, 139.47it/s] 28%|‚ñà‚ñà‚ñä       | 897/3257 [00:06<00:16, 143.66it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:06<00:16, 144.56it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:06<00:15, 149.94it/s] 29%|‚ñà‚ñà‚ñâ       | 947/3257 [00:06<00:15, 151.74it/s] 30%|‚ñà‚ñà‚ñâ       | 963/3257 [00:06<00:14, 153.94it/s] 30%|‚ñà‚ñà‚ñà       | 979/3257 [00:06<00:15, 147.50it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:06<00:15, 144.52it/s] 31%|‚ñà‚ñà‚ñà       | 1009/3257 [00:07<00:27, 82.58it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:07<00:23, 96.58it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1038/3257 [00:07<00:21, 101.27it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:07<00:20, 107.31it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:07<00:18, 118.79it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1081/3257 [00:07<00:17, 123.28it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1096/3257 [00:07<00:16, 128.94it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1113/3257 [00:07<00:15, 138.44it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1128/3257 [00:07<00:16, 130.43it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:07<00:15, 134.33it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1158/3257 [00:08<00:15, 137.28it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1174/3257 [00:08<00:14, 141.53it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1189/3257 [00:08<00:16, 123.14it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1203/3257 [00:08<00:16, 126.77it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1217/3257 [00:08<00:15, 129.74it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1235/3257 [00:08<00:14, 143.05it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1250/3257 [00:08<00:14, 138.30it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1268/3257 [00:08<00:13, 148.31it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1284/3257 [00:09<00:15, 130.77it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1298/3257 [00:09<00:14, 130.93it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1314/3257 [00:09<00:14, 137.00it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1329/3257 [00:09<00:13, 140.09it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:09<00:13, 145.30it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1361/3257 [00:09<00:13, 143.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1376/3257 [00:09<00:13, 138.00it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1390/3257 [00:09<00:13, 134.66it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1409/3257 [00:09<00:12, 149.27it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1426/3257 [00:10<00:11, 152.98it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1442/3257 [00:10<00:11, 153.38it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1462/3257 [00:10<00:10, 165.16it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1479/3257 [00:10<00:10, 162.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:10<00:10, 163.88it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:10<00:10, 163.18it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:10<00:11, 148.62it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:10<00:12, 141.10it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1563/3257 [00:10<00:11, 148.00it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1579/3257 [00:11<00:11, 144.36it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:11<00:11, 147.52it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:11<00:10, 156.42it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1631/3257 [00:11<00:10, 154.69it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1647/3257 [00:11<00:11, 141.64it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:11<00:11, 136.91it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:11<00:11, 136.64it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:11<00:11, 137.68it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:11<00:10, 144.58it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1724/3257 [00:12<00:10, 147.87it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1739/3257 [00:12<00:11, 131.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1755/3257 [00:12<00:10, 137.13it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1773/3257 [00:12<00:09, 148.51it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:12<00:09, 154.23it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1806/3257 [00:12<00:09, 146.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1823/3257 [00:12<00:09, 149.38it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1839/3257 [00:12<00:09, 145.90it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1855/3257 [00:12<00:09, 147.40it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1873/3257 [00:13<00:08, 155.89it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1889/3257 [00:13<00:08, 152.19it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1905/3257 [00:13<00:08, 153.42it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1921/3257 [00:13<00:08, 148.99it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1941/3257 [00:13<00:08, 162.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:13<00:07, 171.64it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1979/3257 [00:13<00:07, 162.71it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1997/3257 [00:13<00:07, 164.81it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2014/3257 [00:13<00:07, 160.02it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:14<00:07, 165.12it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2050/3257 [00:14<00:07, 151.26it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2066/3257 [00:14<00:08, 146.73it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:14<00:07, 148.60it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2098/3257 [00:14<00:07, 145.59it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2116/3257 [00:14<00:07, 155.01it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:14<00:08, 139.19it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2147/3257 [00:14<00:08, 135.23it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:14<00:07, 147.11it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:15<00:07, 146.82it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2199/3257 [00:15<00:06, 153.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2215/3257 [00:15<00:12, 86.28it/s]  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2231/3257 [00:15<00:10, 99.66it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2245/3257 [00:15<00:09, 106.25it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2261/3257 [00:15<00:08, 117.58it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:15<00:08, 118.07it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2294/3257 [00:16<00:07, 135.69it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2309/3257 [00:16<00:06, 136.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2330/3257 [00:16<00:06, 154.40it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2350/3257 [00:16<00:05, 165.96it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2368/3257 [00:16<00:05, 163.54it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2387/3257 [00:16<00:05, 169.00it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2405/3257 [00:16<00:05, 160.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:16<00:05, 160.21it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2439/3257 [00:16<00:05, 151.07it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2455/3257 [00:17<00:05, 147.92it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:17<00:04, 160.01it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2492/3257 [00:17<00:04, 162.46it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2512/3257 [00:17<00:04, 170.56it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2530/3257 [00:17<00:04, 167.17it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2547/3257 [00:17<00:04, 161.91it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2564/3257 [00:17<00:04, 153.40it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2580/3257 [00:17<00:04, 145.78it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2595/3257 [00:17<00:04, 146.67it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2617/3257 [00:18<00:03, 165.53it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2635/3257 [00:18<00:03, 168.49it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2652/3257 [00:18<00:03, 155.39it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2669/3257 [00:18<00:03, 158.07it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:18<00:03, 160.93it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:18<00:03, 142.06it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:18<00:03, 139.78it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2740/3257 [00:18<00:03, 157.28it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:18<00:03, 159.08it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:19<00:03, 151.82it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:19<00:02, 166.74it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:19<00:02, 163.31it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2830/3257 [00:19<00:02, 151.37it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2848/3257 [00:19<00:02, 158.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2871/3257 [00:19<00:02, 177.62it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2890/3257 [00:19<00:02, 172.12it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2908/3257 [00:19<00:02, 162.13it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:20<00:02, 164.05it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2945/3257 [00:20<00:02, 153.85it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2961/3257 [00:20<00:01, 155.35it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2977/3257 [00:20<00:01, 152.10it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2993/3257 [00:20<00:01, 150.35it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:20<00:01, 161.11it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3029/3257 [00:20<00:01, 161.89it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:20<00:01, 167.77it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3071/3257 [00:20<00:01, 179.98it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3090/3257 [00:21<00:00, 175.00it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:21<00:00, 180.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3129/3257 [00:21<00:00, 180.51it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3148/3257 [00:21<00:00, 168.50it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:21<00:00, 168.25it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:21<00:00, 162.83it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3206/3257 [00:21<00:00, 180.03it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3225/3257 [00:21<00:00, 176.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3250/3257 [00:21<00:00, 196.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 148.45it/s]
2023-02-07 19:56:27.440 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:56:27,440][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d234,n5,mc2,s0.475512,t4>', 'datetime': '2023-02-07T19:56:27.440885', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:56:27,441][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:56:27,441][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:56:28,006][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 19:56:28,006][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:56:28,120][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 46469 unique words (85.97% of original 54054, drops 7585)', 'datetime': '2023-02-07T19:56:28.120535', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:56:28,121][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 6543281 word corpus (99.88% of original 6550866, drops 7585)', 'datetime': '2023-02-07T19:56:28.121282', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:56:28,271][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 19:56:28,272][gensim.models.word2vec][INFO] - sample=0.475512 downsamples 0 most-common words
[2023-02-07 19:56:28,272][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6543281 word corpus (100.0%% of prior 6543281)', 'datetime': '2023-02-07T19:56:28.272893', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:56:28,545][gensim.models.word2vec][INFO] - estimated required memory for 46469 words and 234 dimensions: 113924420 bytes
[2023-02-07 19:56:28,545][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:56:28,588][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 46469 vocabulary and 234 features, using sg=1 hs=0 sample=0.4755120809089164 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T19:56:28.588896', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:56:29,593][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 31.44% examples, 2039430 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:30,594][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 62.67% examples, 2059710 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:31,595][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 94.75% examples, 2051538 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:31,749][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6488146 effective words) took 3.2s, 2053915 effective words/s
[2023-02-07 19:56:32,757][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 32.55% examples, 2121128 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:33,762][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 64.91% examples, 2130284 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:34,764][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 99.42% examples, 2142014 words/s, in_qsize 5, out_qsize 0
[2023-02-07 19:56:34,779][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6488146 effective words) took 3.0s, 2142465 effective words/s
[2023-02-07 19:56:35,782][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 32.15% examples, 2105789 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:36,789][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 64.42% examples, 2115490 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:37,791][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 97.67% examples, 2110180 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:37,848][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6488146 effective words) took 3.1s, 2115182 effective words/s
[2023-02-07 19:56:38,855][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 31.81% examples, 2069854 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:39,856][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 63.99% examples, 2103954 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:40,860][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 96.93% examples, 2091848 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:40,975][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6488146 effective words) took 3.1s, 2076163 effective words/s
[2023-02-07 19:56:41,988][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 32.55% examples, 2114712 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:42,991][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 64.91% examples, 2130120 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:43,995][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 98.34% examples, 2119234 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:44,034][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6488146 effective words) took 3.1s, 2123776 effective words/s
[2023-02-07 19:56:45,040][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 33.13% examples, 2155174 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:46,044][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 65.58% examples, 2162045 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:47,014][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6488146 effective words) took 3.0s, 2178689 effective words/s
[2023-02-07 19:56:48,020][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 33.28% examples, 2172157 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:49,021][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 66.38% examples, 2190843 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:49,950][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6488146 effective words) took 2.9s, 2211060 effective words/s
[2023-02-07 19:56:50,953][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 34.69% examples, 2273515 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:51,954][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 69.17% examples, 2290797 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:52,792][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6488146 effective words) took 2.8s, 2284477 effective words/s
[2023-02-07 19:56:53,794][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 34.94% examples, 2290705 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:54,797][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 68.99% examples, 2281326 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:55,636][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6488146 effective words) took 2.8s, 2281980 effective words/s
[2023-02-07 19:56:56,639][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 34.45% examples, 2254302 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:57,640][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 68.44% examples, 2262542 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:58,518][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6488146 effective words) took 2.9s, 2252789 effective words/s
[2023-02-07 19:56:59,519][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 33.68% examples, 2207218 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:57:00,526][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 67.09% examples, 2214454 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:57:01,423][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6488146 effective words) took 2.9s, 2234633 effective words/s
[2023-02-07 19:57:02,424][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 34.57% examples, 2267283 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:57:03,429][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 68.84% examples, 2275888 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:57:04,298][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6488146 effective words) took 2.9s, 2257748 effective words/s
[2023-02-07 19:57:05,302][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 34.33% examples, 2241326 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:57:06,303][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 67.82% examples, 2242887 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:57:07,184][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6488146 effective words) took 2.9s, 2249064 effective words/s
[2023-02-07 19:57:08,188][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 34.33% examples, 2244303 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:57:09,195][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 67.70% examples, 2228095 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:57:10,093][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6488146 effective words) took 2.9s, 2232022 effective words/s
[2023-02-07 19:57:11,095][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 34.33% examples, 2247272 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:57:12,101][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 68.10% examples, 2249067 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:57:12,970][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6488146 effective words) took 2.9s, 2256461 effective words/s
[2023-02-07 19:57:12,970][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (97322190 effective words) took 44.4s, 2192881 effective words/s', 'datetime': '2023-02-07T19:57:12.970830', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:57:12.971 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:57:17,850][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195556-5rfluvi3/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:57:17.850207', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:57:17,851][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195556-5rfluvi3/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 19:57:17,892][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195556-5rfluvi3/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 19:57:17,932][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:57:17,956][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195556-5rfluvi3/files/../tmp/embedding_model.pt
2023-02-07 19:57:17.956 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:57:19.469 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:57:20.067 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:57:29.027 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0456314465590921, 'test_mae': 0.7839630180798425, 'test_r2': -2.038292380930038}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.79
wandb: percentage 0.14032
wandb:   test_mae 0.78396
wandb:   test_mse 1.04563
wandb:    test_r2 -2.03829
wandb: 
wandb: üöÄ View run valiant-sweep-62 at: https://wandb.ai/xiaoqiz/mof2vec/runs/5rfluvi3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195556-5rfluvi3/logs
wandb: Agent Starting Run: q1ajzob6 with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 594
wandb: 	model.gensim.alpha: 0.008972100469117558
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.5690277870533749
wandb: 	model.gensim.vector_size: 388
wandb: 	model.gensim.window: 12
wandb: 	model.sklearn.learning_rate: 0.47194028736060784
wandb: 	model.sklearn.max_depth: 6
wandb: 	model.sklearn.min_child_weight: 0.026567671697975494
wandb: 	model.sklearn.n_estimators: 953
wandb: 	model.sklearn.num_leaves: 417
wandb: 	model.sklearn.reg_alpha: 0.005420117175283372
wandb: 	model.sklearn.reg_lambda: 0.4614968351005
wandb: 	model.sklearn.subsample: 0.5202215184406889
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195749-q1ajzob6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-63
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/q1ajzob6
2023-02-07 19:57:57.718 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:57:57.719 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 594 for sweep.
2023-02-07 19:57:57.719 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.008972100469117558 for sweep.
2023-02-07 19:57:57.719 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:57:57.719 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 19:57:57.720 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5690277870533749 for sweep.
2023-02-07 19:57:57.720 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 388 for sweep.
2023-02-07 19:57:57.721 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 12 for sweep.
2023-02-07 19:57:57.721 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.47194028736060784 for sweep.
2023-02-07 19:57:57.721 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 6 for sweep.
2023-02-07 19:57:57.721 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.026567671697975494 for sweep.
2023-02-07 19:57:57.722 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 953 for sweep.
2023-02-07 19:57:57.722 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 417 for sweep.
2023-02-07 19:57:57.722 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.005420117175283372 for sweep.
2023-02-07 19:57:57.722 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.4614968351005 for sweep.
2023-02-07 19:57:57.723 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5202215184406889 for sweep.
2023-02-07 19:57:57.723 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:57:57.732 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195749-q1ajzob6/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 594, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 388, 'window': 12, 'min_count': 5, 'dm': 0, 'sample': 0.5690277870533749, 'workers': 4, 'alpha': 0.008972100469117558, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 953, 'max_depth': 6, 'num_leaves': 417, 'reg_alpha': 0.005420117175283372, 'reg_lambda': 0.4614968351005, 'subsample': 0.5202215184406889, 'min_child_weight': 0.026567671697975494, 'n_jobs': 4, 'learning_rate': 0.47194028736060784}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 139.87it/s]  1%|          | 32/3257 [00:00<00:19, 161.44it/s]  2%|‚ñè         | 49/3257 [00:00<00:20, 158.04it/s]  2%|‚ñè         | 66/3257 [00:00<00:19, 161.96it/s]  3%|‚ñé         | 83/3257 [00:00<00:19, 162.04it/s]  3%|‚ñé         | 100/3257 [00:00<00:19, 158.44it/s]  4%|‚ñé         | 116/3257 [00:00<00:20, 150.27it/s]  4%|‚ñç         | 132/3257 [00:00<00:20, 152.63it/s]  5%|‚ñç         | 151/3257 [00:00<00:19, 160.28it/s]  5%|‚ñå         | 168/3257 [00:01<00:20, 151.28it/s]  6%|‚ñå         | 184/3257 [00:01<00:20, 148.86it/s]  6%|‚ñå         | 201/3257 [00:01<00:20, 148.69it/s]  7%|‚ñã         | 220/3257 [00:01<00:19, 158.85it/s]  7%|‚ñã         | 237/3257 [00:01<00:18, 161.32it/s]  8%|‚ñä         | 255/3257 [00:01<00:18, 166.39it/s]  8%|‚ñä         | 272/3257 [00:01<00:18, 161.45it/s]  9%|‚ñâ         | 292/3257 [00:01<00:17, 171.67it/s] 10%|‚ñâ         | 310/3257 [00:01<00:17, 165.07it/s] 10%|‚ñà         | 328/3257 [00:02<00:17, 164.12it/s] 11%|‚ñà         | 345/3257 [00:02<00:18, 157.24it/s] 11%|‚ñà         | 362/3257 [00:02<00:18, 158.38it/s] 12%|‚ñà‚ñè        | 378/3257 [00:02<00:19, 147.54it/s] 12%|‚ñà‚ñè        | 393/3257 [00:02<00:28, 100.15it/s] 13%|‚ñà‚ñé        | 410/3257 [00:02<00:24, 114.41it/s] 13%|‚ñà‚ñé        | 424/3257 [00:02<00:24, 117.88it/s] 13%|‚ñà‚ñé        | 438/3257 [00:03<00:25, 111.90it/s] 14%|‚ñà‚ñç        | 454/3257 [00:03<00:22, 123.09it/s] 14%|‚ñà‚ñç        | 472/3257 [00:03<00:20, 137.36it/s] 15%|‚ñà‚ñç        | 487/3257 [00:03<00:19, 139.89it/s] 16%|‚ñà‚ñå        | 505/3257 [00:03<00:18, 147.77it/s] 16%|‚ñà‚ñå        | 522/3257 [00:03<00:17, 153.82it/s] 17%|‚ñà‚ñã        | 538/3257 [00:03<00:18, 148.19it/s] 17%|‚ñà‚ñã        | 554/3257 [00:03<00:18, 148.02it/s] 18%|‚ñà‚ñä        | 570/3257 [00:03<00:19, 140.37it/s] 18%|‚ñà‚ñä        | 585/3257 [00:04<00:19, 136.33it/s] 18%|‚ñà‚ñä        | 601/3257 [00:04<00:18, 142.63it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:04<00:18, 144.07it/s] 20%|‚ñà‚ñâ        | 638/3257 [00:04<00:17, 153.64it/s] 20%|‚ñà‚ñà        | 654/3257 [00:04<00:17, 147.93it/s] 21%|‚ñà‚ñà        | 669/3257 [00:04<00:17, 145.28it/s] 21%|‚ñà‚ñà        | 684/3257 [00:04<00:18, 142.62it/s] 21%|‚ñà‚ñà‚ñè       | 699/3257 [00:04<00:17, 143.98it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:16, 157.00it/s] 23%|‚ñà‚ñà‚ñé       | 734/3257 [00:05<00:16, 149.44it/s] 23%|‚ñà‚ñà‚ñé       | 750/3257 [00:05<00:17, 142.88it/s] 24%|‚ñà‚ñà‚ñé       | 769/3257 [00:05<00:16, 155.22it/s] 24%|‚ñà‚ñà‚ñç       | 785/3257 [00:05<00:17, 143.64it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:16, 152.53it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:15, 152.63it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:05<00:16, 145.07it/s] 26%|‚ñà‚ñà‚ñå       | 851/3257 [00:05<00:17, 140.87it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:05<00:16, 146.11it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:06<00:16, 144.60it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:06<00:14, 158.84it/s] 28%|‚ñà‚ñà‚ñä       | 922/3257 [00:06<00:14, 161.22it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:06<00:14, 157.12it/s] 29%|‚ñà‚ñà‚ñâ       | 957/3257 [00:06<00:14, 160.93it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:06<00:14, 159.29it/s] 30%|‚ñà‚ñà‚ñà       | 990/3257 [00:06<00:14, 152.94it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:06<00:15, 147.65it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:06<00:14, 156.21it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:07<00:15, 143.11it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1057/3257 [00:07<00:14, 147.48it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1077/3257 [00:07<00:13, 161.40it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:07<00:14, 147.41it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:07<00:13, 155.70it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1128/3257 [00:07<00:14, 147.54it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:07<00:14, 150.22it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1161/3257 [00:07<00:13, 153.62it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1177/3257 [00:07<00:13, 150.27it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1193/3257 [00:08<00:14, 138.11it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1208/3257 [00:08<00:15, 136.16it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1227/3257 [00:08<00:13, 148.87it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:08<00:13, 150.41it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1259/3257 [00:08<00:13, 151.13it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:08<00:13, 149.31it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:08<00:13, 144.61it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:08<00:13, 148.01it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1326/3257 [00:08<00:12, 156.68it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1343/3257 [00:09<00:12, 158.87it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1359/3257 [00:09<00:12, 152.99it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1375/3257 [00:09<00:12, 150.46it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1391/3257 [00:09<00:12, 148.96it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:09<00:11, 163.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:09<00:10, 166.26it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1450/3257 [00:09<00:10, 169.79it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1470/3257 [00:09<00:10, 177.97it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1488/3257 [00:09<00:10, 173.22it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1509/3257 [00:10<00:09, 182.67it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1528/3257 [00:10<00:10, 161.98it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1545/3257 [00:10<00:11, 153.76it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1563/3257 [00:10<00:10, 159.01it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1580/3257 [00:10<00:10, 156.07it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1598/3257 [00:10<00:10, 160.98it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:10<00:09, 165.24it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:10<00:10, 156.91it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:10<00:10, 153.97it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1666/3257 [00:11<00:17, 89.44it/s]  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1681/3257 [00:11<00:15, 100.16it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1699/3257 [00:11<00:13, 116.12it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:11<00:12, 125.33it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1730/3257 [00:11<00:12, 126.22it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:11<00:11, 130.00it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:11<00:10, 141.74it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1783/3257 [00:12<00:09, 155.45it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1800/3257 [00:12<00:09, 155.05it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1817/3257 [00:12<00:09, 152.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1833/3257 [00:12<00:09, 149.79it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1850/3257 [00:12<00:09, 154.52it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:12<00:08, 161.96it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1886/3257 [00:12<00:08, 161.97it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1903/3257 [00:12<00:08, 162.84it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1920/3257 [00:12<00:08, 156.67it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1941/3257 [00:13<00:07, 170.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1963/3257 [00:13<00:07, 181.27it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:13<00:07, 169.18it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2001/3257 [00:13<00:07, 172.78it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2019/3257 [00:13<00:07, 171.62it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2037/3257 [00:13<00:07, 170.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:13<00:07, 153.68it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2071/3257 [00:13<00:07, 151.49it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2087/3257 [00:13<00:07, 153.54it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2103/3257 [00:14<00:07, 152.52it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:14<00:07, 151.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:14<00:07, 152.08it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2152/3257 [00:14<00:07, 151.02it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2170/3257 [00:14<00:06, 158.16it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2186/3257 [00:14<00:06, 156.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:14<00:06, 161.91it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2221/3257 [00:14<00:06, 160.30it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:14<00:06, 152.92it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2255/3257 [00:15<00:06, 155.63it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2271/3257 [00:15<00:06, 148.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2291/3257 [00:15<00:06, 158.87it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2307/3257 [00:15<00:05, 159.02it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2328/3257 [00:15<00:05, 173.23it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2348/3257 [00:15<00:05, 178.77it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2367/3257 [00:15<00:05, 177.66it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2387/3257 [00:15<00:04, 182.44it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2406/3257 [00:15<00:04, 171.25it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2424/3257 [00:16<00:04, 171.55it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2442/3257 [00:16<00:05, 158.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2460/3257 [00:16<00:04, 163.87it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2478/3257 [00:16<00:04, 168.26it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2498/3257 [00:16<00:04, 174.19it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2518/3257 [00:16<00:04, 180.84it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2537/3257 [00:16<00:03, 180.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2556/3257 [00:16<00:04, 165.84it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:16<00:04, 158.51it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2590/3257 [00:17<00:04, 151.65it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2610/3257 [00:17<00:03, 164.39it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2631/3257 [00:17<00:03, 173.49it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2649/3257 [00:17<00:03, 163.99it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2666/3257 [00:17<00:03, 161.77it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2685/3257 [00:17<00:03, 169.04it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2703/3257 [00:17<00:03, 148.53it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:17<00:03, 145.94it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:17<00:03, 161.58it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2759/3257 [00:18<00:03, 165.51it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2776/3257 [00:18<00:03, 157.09it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2798/3257 [00:18<00:02, 172.37it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2816/3257 [00:18<00:02, 163.35it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:18<00:02, 158.04it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2851/3257 [00:18<00:02, 163.90it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2873/3257 [00:18<00:02, 178.33it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2892/3257 [00:18<00:02, 176.74it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2910/3257 [00:18<00:02, 165.13it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:19<00:01, 167.53it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2945/3257 [00:19<00:01, 159.84it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2963/3257 [00:19<00:01, 164.31it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2980/3257 [00:19<00:01, 158.22it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2997/3257 [00:19<00:01, 161.32it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3015/3257 [00:19<00:01, 166.08it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3033/3257 [00:19<00:01, 169.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3052/3257 [00:19<00:01, 174.39it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3072/3257 [00:19<00:01, 181.33it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3091/3257 [00:20<00:01, 101.44it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3112/3257 [00:20<00:01, 120.97it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3130/3257 [00:20<00:00, 132.94it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3147/3257 [00:20<00:00, 135.44it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:20<00:00, 142.93it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3182/3257 [00:20<00:00, 142.57it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:20<00:00, 156.85it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3220/3257 [00:21<00:00, 153.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3241/3257 [00:21<00:00, 166.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 153.19it/s]
2023-02-07 19:58:19.826 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:58:19,828][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d388,n5,mc5,s0.569028,t4>', 'datetime': '2023-02-07T19:58:19.828514', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:58:19,828][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:58:19,829][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:58:20,414][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:58:20,414][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:58:20,477][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 21312 unique words (49.91% of original 42701, drops 21389)', 'datetime': '2023-02-07T19:58:20.477064', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:58:20,477][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5769229 word corpus (99.08% of original 5822992, drops 53763)', 'datetime': '2023-02-07T19:58:20.477478', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:58:20,552][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:58:20,553][gensim.models.word2vec][INFO] - sample=0.569028 downsamples 0 most-common words
[2023-02-07 19:58:20,553][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5769229 word corpus (100.0%% of prior 5769229)', 'datetime': '2023-02-07T19:58:20.553587', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:58:20,683][gensim.models.word2vec][INFO] - estimated required memory for 21312 words and 388 dimensions: 82514712 bytes
[2023-02-07 19:58:20,684][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:58:20,726][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 21312 vocabulary and 388 features, using sg=1 hs=0 sample=0.5690277870533749 negative=5 window=12 shrink_windows=True', 'datetime': '2023-02-07T19:58:20.726209', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:58:21,731][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 28.34% examples, 1625724 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:22,734][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 56.74% examples, 1662347 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:23,741][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 87.07% examples, 1676328 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:24,140][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5743174 effective words) took 3.4s, 1683426 effective words/s
[2023-02-07 19:58:25,144][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 32.91% examples, 1912840 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:26,145][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 64.84% examples, 1892100 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:27,152][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 98.34% examples, 1877519 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:27,192][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5743174 effective words) took 3.1s, 1882279 effective words/s
[2023-02-07 19:58:28,198][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 32.36% examples, 1874781 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:29,205][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 65.34% examples, 1901944 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:30,197][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5743174 effective words) took 3.0s, 1912453 effective words/s
[2023-02-07 19:58:31,206][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 33.25% examples, 1920803 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:32,212][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 66.04% examples, 1923552 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:33,155][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5743174 effective words) took 3.0s, 1942566 effective words/s
[2023-02-07 19:58:34,161][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 33.71% examples, 1953858 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:35,162][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 66.69% examples, 1951239 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:58:36,101][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5743174 effective words) took 2.9s, 1950853 effective words/s
[2023-02-07 19:58:37,103][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 34.20% examples, 1982904 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:38,106][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 67.67% examples, 1977958 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:39,010][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5743174 effective words) took 2.9s, 1975289 effective words/s
[2023-02-07 19:58:40,016][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 34.33% examples, 1986887 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:41,018][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 67.79% examples, 1979556 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:41,898][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5743174 effective words) took 2.9s, 1989957 effective words/s
[2023-02-07 19:58:42,902][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 34.85% examples, 2024025 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:43,907][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 69.14% examples, 2020267 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:44,743][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5743174 effective words) took 2.8s, 2019308 effective words/s
[2023-02-07 19:58:45,745][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 34.85% examples, 2028879 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:58:46,747][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 69.14% examples, 2025691 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:47,593][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5743174 effective words) took 2.8s, 2016292 effective words/s
[2023-02-07 19:58:48,599][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 34.45% examples, 1993915 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:49,599][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 68.84% examples, 2015436 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:50,448][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5743174 effective words) took 2.9s, 2012996 effective words/s
[2023-02-07 19:58:51,450][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 34.69% examples, 2017482 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:52,453][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 69.14% examples, 2024223 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:53,283][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5743174 effective words) took 2.8s, 2026790 effective words/s
[2023-02-07 19:58:54,290][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 34.97% examples, 2026716 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:58:55,291][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 69.76% examples, 2044088 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:58:56,093][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5743174 effective words) took 2.8s, 2044346 effective words/s
[2023-02-07 19:58:57,101][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 35.71% examples, 2064675 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:58,101][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 71.26% examples, 2081369 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:58,859][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5743174 effective words) took 2.8s, 2077353 effective words/s
[2023-02-07 19:58:59,866][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 35.31% examples, 2047993 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:59:00,868][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 69.88% examples, 2048262 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:59:01,659][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5743174 effective words) took 2.8s, 2052279 effective words/s
[2023-02-07 19:59:02,662][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 35.92% examples, 2092839 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:59:03,662][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 72.43% examples, 2109044 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:59:04,388][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5743174 effective words) took 2.7s, 2106042 effective words/s
[2023-02-07 19:59:04,389][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86147610 effective words) took 43.7s, 1973046 effective words/s', 'datetime': '2023-02-07T19:59:04.389025', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:59:04.389 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:59:08,709][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195749-q1ajzob6/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:59:08.709811', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:59:08,710][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:59:08,818][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195749-q1ajzob6/files/../tmp/embedding_model.pt
2023-02-07 19:59:08.819 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:59:11.039 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:59:11.836 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:59:17.057 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9933829828419704, 'test_mae': 0.7633687444716875, 'test_r2': -1.9259284439894202}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.81
wandb: percentage 0.5009
wandb:   test_mae 0.76337
wandb:   test_mse 0.99338
wandb:    test_r2 -1.92593
wandb: 
wandb: üöÄ View run upbeat-sweep-63 at: https://wandb.ai/xiaoqiz/mof2vec/runs/q1ajzob6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195749-q1ajzob6/logs
wandb: Agent Starting Run: sptk1m5z with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 801
wandb: 	model.gensim.alpha: 0.008305394386945494
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.6261172597784209
wandb: 	model.gensim.vector_size: 405
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.005518885901862214
wandb: 	model.sklearn.max_depth: 17
wandb: 	model.sklearn.min_child_weight: 0.04744424309329693
wandb: 	model.sklearn.n_estimators: 2160
wandb: 	model.sklearn.num_leaves: 464
wandb: 	model.sklearn.reg_alpha: 0.03659381797682351
wandb: 	model.sklearn.reg_lambda: 0.1466128536795684
wandb: 	model.sklearn.subsample: 0.43901420549021186
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195930-sptk1m5z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-64
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/sptk1m5z
2023-02-07 19:59:38.820 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:59:38.821 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 801 for sweep.
2023-02-07 19:59:38.821 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.008305394386945494 for sweep.
2023-02-07 19:59:38.822 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:59:38.822 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 19:59:38.822 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6261172597784209 for sweep.
2023-02-07 19:59:38.823 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 405 for sweep.
2023-02-07 19:59:38.823 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 19:59:38.823 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.005518885901862214 for sweep.
2023-02-07 19:59:38.823 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 17 for sweep.
2023-02-07 19:59:38.824 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.04744424309329693 for sweep.
2023-02-07 19:59:38.824 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2160 for sweep.
2023-02-07 19:59:38.824 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 464 for sweep.
2023-02-07 19:59:38.824 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.03659381797682351 for sweep.
2023-02-07 19:59:38.824 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.1466128536795684 for sweep.
2023-02-07 19:59:38.825 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.43901420549021186 for sweep.
2023-02-07 19:59:38.825 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:59:38.834 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195930-sptk1m5z/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 801, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 405, 'window': 11, 'min_count': 9, 'dm': 0, 'sample': 0.6261172597784209, 'workers': 4, 'alpha': 0.008305394386945494, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2160, 'max_depth': 17, 'num_leaves': 464, 'reg_alpha': 0.03659381797682351, 'reg_lambda': 0.1466128536795684, 'subsample': 0.43901420549021186, 'min_child_weight': 0.04744424309329693, 'n_jobs': 4, 'learning_rate': 0.005518885901862214}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:26, 124.26it/s]  1%|          | 30/3257 [00:00<00:22, 144.59it/s]  1%|‚ñè         | 45/3257 [00:00<00:21, 146.76it/s]  2%|‚ñè         | 60/3257 [00:00<00:22, 140.96it/s]  2%|‚ñè         | 78/3257 [00:00<00:20, 153.07it/s]  3%|‚ñé         | 94/3257 [00:00<00:21, 150.40it/s]  3%|‚ñé         | 110/3257 [00:00<00:23, 136.15it/s]  4%|‚ñç         | 125/3257 [00:00<00:22, 139.99it/s]  4%|‚ñç         | 143/3257 [00:00<00:20, 150.21it/s]  5%|‚ñç         | 159/3257 [00:01<00:21, 144.70it/s]  5%|‚ñå         | 174/3257 [00:01<00:21, 140.36it/s]  6%|‚ñå         | 190/3257 [00:01<00:21, 145.29it/s]  6%|‚ñã         | 205/3257 [00:01<00:21, 142.24it/s]  7%|‚ñã         | 225/3257 [00:01<00:19, 158.47it/s]  7%|‚ñã         | 242/3257 [00:01<00:18, 161.63it/s]  8%|‚ñä         | 259/3257 [00:01<00:19, 154.72it/s]  9%|‚ñä         | 278/3257 [00:01<00:18, 164.15it/s]  9%|‚ñâ         | 296/3257 [00:01<00:17, 165.71it/s] 10%|‚ñâ         | 313/3257 [00:02<00:18, 155.40it/s] 10%|‚ñà         | 331/3257 [00:02<00:18, 161.97it/s] 11%|‚ñà         | 348/3257 [00:02<00:18, 153.57it/s] 11%|‚ñà         | 366/3257 [00:02<00:18, 158.45it/s] 12%|‚ñà‚ñè        | 383/3257 [00:02<00:18, 152.48it/s] 12%|‚ñà‚ñè        | 399/3257 [00:02<00:19, 145.66it/s] 13%|‚ñà‚ñé        | 417/3257 [00:02<00:18, 154.00it/s] 13%|‚ñà‚ñé        | 433/3257 [00:02<00:22, 128.14it/s] 14%|‚ñà‚ñç        | 448/3257 [00:03<00:21, 132.40it/s] 14%|‚ñà‚ñç        | 466/3257 [00:03<00:19, 143.06it/s] 15%|‚ñà‚ñç        | 481/3257 [00:03<00:20, 138.71it/s] 15%|‚ñà‚ñå        | 500/3257 [00:03<00:18, 149.47it/s] 16%|‚ñà‚ñå        | 516/3257 [00:03<00:18, 152.02it/s] 16%|‚ñà‚ñã        | 532/3257 [00:03<00:18, 146.38it/s] 17%|‚ñà‚ñã        | 547/3257 [00:03<00:18, 146.63it/s] 17%|‚ñà‚ñã        | 562/3257 [00:03<00:19, 139.10it/s] 18%|‚ñà‚ñä        | 577/3257 [00:03<00:20, 129.15it/s] 18%|‚ñà‚ñä        | 595/3257 [00:04<00:18, 141.24it/s] 19%|‚ñà‚ñâ        | 612/3257 [00:04<00:17, 148.90it/s] 19%|‚ñà‚ñâ        | 628/3257 [00:04<00:18, 144.30it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:04<00:17, 145.71it/s] 20%|‚ñà‚ñà        | 659/3257 [00:04<00:19, 132.93it/s] 21%|‚ñà‚ñà        | 676/3257 [00:04<00:18, 142.52it/s] 21%|‚ñà‚ñà        | 691/3257 [00:04<00:18, 138.51it/s] 22%|‚ñà‚ñà‚ñè       | 706/3257 [00:04<00:18, 141.52it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:04<00:17, 141.16it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:05<00:18, 133.16it/s] 23%|‚ñà‚ñà‚ñé       | 751/3257 [00:05<00:18, 136.75it/s] 24%|‚ñà‚ñà‚ñé       | 769/3257 [00:05<00:16, 148.34it/s] 24%|‚ñà‚ñà‚ñç       | 785/3257 [00:05<00:18, 136.67it/s] 25%|‚ñà‚ñà‚ñç       | 803/3257 [00:05<00:16, 147.46it/s] 25%|‚ñà‚ñà‚ñå       | 819/3257 [00:05<00:17, 142.68it/s] 26%|‚ñà‚ñà‚ñå       | 834/3257 [00:05<00:17, 137.16it/s] 26%|‚ñà‚ñà‚ñå       | 848/3257 [00:05<00:18, 128.99it/s] 26%|‚ñà‚ñà‚ñã       | 863/3257 [00:05<00:17, 133.43it/s] 27%|‚ñà‚ñà‚ñã       | 877/3257 [00:06<00:18, 128.73it/s] 27%|‚ñà‚ñà‚ñã       | 894/3257 [00:06<00:17, 136.45it/s] 28%|‚ñà‚ñà‚ñä       | 911/3257 [00:06<00:16, 145.33it/s] 28%|‚ñà‚ñà‚ñä       | 927/3257 [00:06<00:15, 148.92it/s] 29%|‚ñà‚ñà‚ñâ       | 943/3257 [00:06<00:16, 143.89it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:06<00:15, 147.12it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:06<00:15, 146.72it/s] 30%|‚ñà‚ñà‚ñà       | 989/3257 [00:06<00:15, 142.08it/s] 31%|‚ñà‚ñà‚ñà       | 1004/3257 [00:06<00:15, 143.08it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1019/3257 [00:07<00:15, 143.69it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1034/3257 [00:07<00:16, 134.37it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1048/3257 [00:07<00:16, 133.83it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1064/3257 [00:07<00:15, 139.08it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:26, 82.52it/s]  34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:07<00:23, 92.57it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1111/3257 [00:07<00:19, 108.68it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1125/3257 [00:08<00:18, 113.29it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:08<00:17, 117.82it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1153/3257 [00:08<00:17, 121.46it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:08<00:15, 131.71it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1184/3257 [00:08<00:16, 124.33it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1198/3257 [00:08<00:16, 125.07it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1211/3257 [00:08<00:16, 120.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1229/3257 [00:08<00:14, 135.46it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1244/3257 [00:08<00:14, 136.77it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:09<00:14, 134.29it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1274/3257 [00:09<00:14, 141.42it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1289/3257 [00:09<00:15, 128.35it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1303/3257 [00:09<00:14, 130.35it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1318/3257 [00:09<00:14, 134.92it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1333/3257 [00:09<00:13, 137.88it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1349/3257 [00:09<00:13, 142.39it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:09<00:13, 137.48it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1378/3257 [00:09<00:13, 135.20it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1392/3257 [00:10<00:14, 132.70it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1410/3257 [00:10<00:12, 145.32it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1427/3257 [00:10<00:12, 151.71it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1443/3257 [00:10<00:12, 150.23it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:10<00:11, 161.75it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1480/3257 [00:10<00:11, 161.30it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1497/3257 [00:10<00:10, 162.98it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1514/3257 [00:10<00:10, 162.66it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1531/3257 [00:10<00:11, 145.90it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:11<00:12, 136.36it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1562/3257 [00:11<00:11, 141.91it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1577/3257 [00:11<00:12, 139.23it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1593/3257 [00:11<00:11, 144.37it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1610/3257 [00:11<00:10, 150.06it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1626/3257 [00:11<00:10, 149.02it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1642/3257 [00:11<00:11, 139.09it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:11<00:11, 137.11it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1671/3257 [00:11<00:11, 134.05it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1685/3257 [00:12<00:11, 134.09it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1701/3257 [00:12<00:11, 140.15it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1716/3257 [00:12<00:11, 138.72it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1730/3257 [00:12<00:11, 133.30it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:12<00:11, 131.03it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1761/3257 [00:12<00:10, 141.59it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1776/3257 [00:12<00:10, 141.49it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:12<00:10, 146.08it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1807/3257 [00:12<00:10, 132.67it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1825/3257 [00:13<00:09, 144.70it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1840/3257 [00:13<00:09, 141.71it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1855/3257 [00:13<00:09, 141.56it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1872/3257 [00:13<00:09, 147.83it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1887/3257 [00:13<00:09, 143.42it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1904/3257 [00:13<00:09, 148.55it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1919/3257 [00:13<00:09, 146.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1941/3257 [00:13<00:07, 165.75it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1964/3257 [00:13<00:07, 183.45it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1983/3257 [00:14<00:07, 171.18it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:14<00:06, 180.59it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2025/3257 [00:14<00:06, 187.92it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2044/3257 [00:14<00:06, 179.12it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2063/3257 [00:14<00:07, 163.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:14<00:06, 169.58it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2101/3257 [00:14<00:07, 164.09it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:14<00:06, 166.10it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2138/3257 [00:14<00:06, 167.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2155/3257 [00:15<00:06, 164.76it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2177/3257 [00:15<00:06, 176.72it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2195/3257 [00:15<00:06, 175.94it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2213/3257 [00:15<00:09, 111.78it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2230/3257 [00:15<00:08, 123.60it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2245/3257 [00:15<00:08, 124.33it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:15<00:07, 130.31it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:16<00:07, 126.98it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2295/3257 [00:16<00:06, 145.40it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2311/3257 [00:16<00:06, 147.63it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2335/3257 [00:16<00:05, 171.85it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2357/3257 [00:16<00:04, 183.66it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2376/3257 [00:16<00:04, 178.56it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:16<00:04, 192.10it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2419/3257 [00:16<00:04, 182.87it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2438/3257 [00:16<00:04, 178.22it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2457/3257 [00:16<00:04, 179.01it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2478/3257 [00:17<00:04, 186.52it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2502/3257 [00:17<00:03, 199.70it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2523/3257 [00:17<00:03, 201.53it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2544/3257 [00:17<00:03, 199.86it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2565/3257 [00:17<00:03, 185.79it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2584/3257 [00:17<00:03, 178.22it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2604/3257 [00:17<00:03, 183.51it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2629/3257 [00:17<00:03, 199.53it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2650/3257 [00:17<00:03, 186.48it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2669/3257 [00:18<00:03, 186.25it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:18<00:02, 190.92it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2710/3257 [00:18<00:03, 164.09it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:18<00:03, 173.17it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2754/3257 [00:18<00:02, 185.25it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:18<00:02, 174.94it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2798/3257 [00:18<00:02, 191.04it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2818/3257 [00:18<00:02, 180.44it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:19<00:02, 176.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2861/3257 [00:19<00:02, 192.24it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:19<00:01, 197.64it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:19<00:01, 185.33it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:19<00:01, 189.21it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2948/3257 [00:19<00:01, 178.58it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2967/3257 [00:19<00:01, 181.55it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2986/3257 [00:19<00:01, 170.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3010/3257 [00:19<00:01, 188.96it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3030/3257 [00:20<00:01, 182.88it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3053/3257 [00:20<00:01, 194.04it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3077/3257 [00:20<00:00, 206.19it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3098/3257 [00:20<00:00, 199.00it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3122/3257 [00:20<00:00, 207.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3143/3257 [00:20<00:00, 190.75it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3163/3257 [00:20<00:00, 190.48it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:20<00:00, 179.45it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3205/3257 [00:20<00:00, 190.04it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3225/3257 [00:21<00:00, 182.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3249/3257 [00:21<00:00, 197.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 153.44it/s]
2023-02-07 20:00:00.862 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:00:00,862][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d405,n5,mc9,s0.626117,t4>', 'datetime': '2023-02-07T20:00:00.862909', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:00:00,863][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:00:00,863][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:00:01,420][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:00:01,420][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:00:01,475][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 18315 unique words (33.88% of original 54054, drops 35739)', 'datetime': '2023-02-07T20:00:01.475233', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:00:01,475][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 6422560 word corpus (98.04% of original 6550866, drops 128306)', 'datetime': '2023-02-07T20:00:01.475504', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:00:01,534][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:00:01,535][gensim.models.word2vec][INFO] - sample=0.626117 downsamples 0 most-common words
[2023-02-07 20:00:01,535][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6422560 word corpus (100.0%% of prior 6422560)', 'datetime': '2023-02-07T20:00:01.535736', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:00:01,639][gensim.models.word2vec][INFO] - estimated required memory for 18315 words and 405 dimensions: 74425840 bytes
[2023-02-07 20:00:01,639][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:00:01,673][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18315 vocabulary and 405 features, using sg=1 hs=0 sample=0.6261172597784209 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T20:00:01.673532', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:00:02,679][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 31.99% examples, 2054391 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:03,682][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 64.66% examples, 2087888 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:04,685][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 99.85% examples, 2110777 words/s, in_qsize 2, out_qsize 1
[2023-02-07 20:00:04,693][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6368654 effective words) took 3.0s, 2110438 effective words/s
[2023-02-07 20:00:05,694][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 35.95% examples, 2321941 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:00:06,700][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 70.43% examples, 2283961 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:07,516][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6368654 effective words) took 2.8s, 2256740 effective words/s
[2023-02-07 20:00:08,520][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 31.50% examples, 2011961 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:09,527][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 63.89% examples, 2058399 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:10,528][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 98.10% examples, 2076485 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:10,582][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6368654 effective words) took 3.1s, 2077965 effective words/s
[2023-02-07 20:00:11,587][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 31.93% examples, 2046529 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:12,589][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 64.35% examples, 2081856 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:00:13,590][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 98.68% examples, 2095537 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:13,621][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6368654 effective words) took 3.0s, 2096733 effective words/s
[2023-02-07 20:00:14,627][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 32.55% examples, 2087099 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:15,631][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 65.12% examples, 2102861 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:16,631][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 99.85% examples, 2111294 words/s, in_qsize 2, out_qsize 1
[2023-02-07 20:00:16,638][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6368654 effective words) took 3.0s, 2111896 effective words/s
[2023-02-07 20:00:17,640][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 33.16% examples, 2132284 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:18,645][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 66.38% examples, 2151128 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:19,593][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6368654 effective words) took 3.0s, 2155861 effective words/s
[2023-02-07 20:00:20,597][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 33.13% examples, 2119350 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:21,602][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 65.80% examples, 2133362 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:00:22,553][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6368654 effective words) took 3.0s, 2152035 effective words/s
[2023-02-07 20:00:23,557][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 33.68% examples, 2163510 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:24,558][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 66.66% examples, 2161796 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:00:25,511][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6368654 effective words) took 3.0s, 2153989 effective words/s
[2023-02-07 20:00:26,515][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 33.34% examples, 2140038 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:27,517][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 65.80% examples, 2136777 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:28,481][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6368654 effective words) took 3.0s, 2145420 effective words/s
[2023-02-07 20:00:29,484][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 33.53% examples, 2159360 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:30,485][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 66.87% examples, 2171068 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:31,405][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6368654 effective words) took 2.9s, 2179595 effective words/s
[2023-02-07 20:00:32,407][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 34.26% examples, 2201740 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:33,408][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 67.79% examples, 2201360 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:34,294][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6368654 effective words) took 2.9s, 2205795 effective words/s
[2023-02-07 20:00:35,298][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 34.45% examples, 2212396 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:36,301][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 68.99% examples, 2238021 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:37,125][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6368654 effective words) took 2.8s, 2250612 effective words/s
[2023-02-07 20:00:38,129][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 28.06% examples, 1795669 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:39,134][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 52.69% examples, 1709417 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:40,135][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 78.02% examples, 1668137 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:00:40,851][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6368654 effective words) took 3.7s, 1709904 effective words/s
[2023-02-07 20:00:41,859][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 29.66% examples, 1877383 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:00:42,866][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 58.80% examples, 1896975 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:43,868][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 88.89% examples, 1891554 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:00:44,223][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6368654 effective words) took 3.4s, 1889790 effective words/s
[2023-02-07 20:00:45,227][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 29.75% examples, 1892736 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:00:46,227][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 58.27% examples, 1892889 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:00:47,234][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 88.82% examples, 1892721 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:47,585][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6368654 effective words) took 3.4s, 1895127 effective words/s
[2023-02-07 20:00:47,586][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (95529810 effective words) took 45.9s, 2080714 effective words/s', 'datetime': '2023-02-07T20:00:47.585980', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:00:47.586 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:00:52,781][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195930-sptk1m5z/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:00:52.780907', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:00:52,782][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:00:52,885][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195930-sptk1m5z/files/../tmp/embedding_model.pt
2023-02-07 20:00:52.885 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:00:54.998 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:00:55.753 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:01:08.372 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9087049408210396, 'test_mae': 0.7297157312920488, 'test_r2': -2.005522156566591}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.84
wandb: percentage 0.66117
wandb:   test_mae 0.72972
wandb:   test_mse 0.9087
wandb:    test_r2 -2.00552
wandb: 
wandb: üöÄ View run absurd-sweep-64 at: https://wandb.ai/xiaoqiz/mof2vec/runs/sptk1m5z
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195930-sptk1m5z/logs
wandb: Agent Starting Run: rbwfgzga with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 732
wandb: 	model.gensim.alpha: 0.006133463020673187
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.7668287057433532
wandb: 	model.gensim.vector_size: 191
wandb: 	model.gensim.window: 12
wandb: 	model.sklearn.learning_rate: 0.9194940781815648
wandb: 	model.sklearn.max_depth: 8
wandb: 	model.sklearn.min_child_weight: 0.05284410004543357
wandb: 	model.sklearn.n_estimators: 1624
wandb: 	model.sklearn.num_leaves: 430
wandb: 	model.sklearn.reg_alpha: 0.06986377075008834
wandb: 	model.sklearn.reg_lambda: 0.580111140279747
wandb: 	model.sklearn.subsample: 0.4615438199054622
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200125-rbwfgzga
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-65
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/rbwfgzga
2023-02-07 20:01:34.221 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 20:01:34.222 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 732 for sweep.
2023-02-07 20:01:34.222 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.006133463020673187 for sweep.
2023-02-07 20:01:34.223 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:01:34.223 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 20:01:34.223 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7668287057433532 for sweep.
2023-02-07 20:01:34.223 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 191 for sweep.
2023-02-07 20:01:34.224 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 12 for sweep.
2023-02-07 20:01:34.224 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.9194940781815648 for sweep.
2023-02-07 20:01:34.224 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 8 for sweep.
2023-02-07 20:01:34.224 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05284410004543357 for sweep.
2023-02-07 20:01:34.225 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1624 for sweep.
2023-02-07 20:01:34.225 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 430 for sweep.
2023-02-07 20:01:34.225 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.06986377075008834 for sweep.
2023-02-07 20:01:34.226 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.580111140279747 for sweep.
2023-02-07 20:01:34.226 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.4615438199054622 for sweep.
2023-02-07 20:01:34.226 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:01:34.235 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200125-rbwfgzga/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 732, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 191, 'window': 12, 'min_count': 8, 'dm': 0, 'sample': 0.7668287057433532, 'workers': 4, 'alpha': 0.006133463020673187, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1624, 'max_depth': 8, 'num_leaves': 430, 'reg_alpha': 0.06986377075008834, 'reg_lambda': 0.580111140279747, 'subsample': 0.4615438199054622, 'min_child_weight': 0.05284410004543357, 'n_jobs': 4, 'learning_rate': 0.9194940781815648}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:20, 154.55it/s]  1%|          | 33/3257 [00:00<00:19, 163.19it/s]  2%|‚ñè         | 50/3257 [00:00<00:19, 163.05it/s]  2%|‚ñè         | 67/3257 [00:00<00:19, 160.80it/s]  3%|‚ñé         | 88/3257 [00:00<00:17, 176.58it/s]  3%|‚ñé         | 106/3257 [00:00<00:20, 153.69it/s]  4%|‚ñç         | 123/3257 [00:00<00:19, 157.27it/s]  4%|‚ñç         | 142/3257 [00:00<00:18, 166.27it/s]  5%|‚ñç         | 159/3257 [00:00<00:18, 164.76it/s]  5%|‚ñå         | 176/3257 [00:01<00:19, 158.56it/s]  6%|‚ñå         | 195/3257 [00:01<00:18, 166.72it/s]  7%|‚ñã         | 213/3257 [00:01<00:17, 169.87it/s]  7%|‚ñã         | 234/3257 [00:01<00:16, 181.16it/s]  8%|‚ñä         | 253/3257 [00:01<00:17, 176.56it/s]  8%|‚ñä         | 271/3257 [00:01<00:17, 172.42it/s]  9%|‚ñâ         | 294/3257 [00:01<00:15, 187.33it/s] 10%|‚ñâ         | 313/3257 [00:01<00:16, 174.04it/s] 10%|‚ñà         | 334/3257 [00:01<00:16, 180.59it/s] 11%|‚ñà         | 353/3257 [00:02<00:16, 176.70it/s] 11%|‚ñà‚ñè        | 372/3257 [00:02<00:15, 180.32it/s] 12%|‚ñà‚ñè        | 391/3257 [00:02<00:25, 112.59it/s] 13%|‚ñà‚ñé        | 409/3257 [00:02<00:22, 125.72it/s] 13%|‚ñà‚ñé        | 425/3257 [00:02<00:22, 127.60it/s] 14%|‚ñà‚ñé        | 440/3257 [00:02<00:21, 129.48it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:19, 141.82it/s] 15%|‚ñà‚ñç        | 478/3257 [00:03<00:18, 152.31it/s] 15%|‚ñà‚ñå        | 497/3257 [00:03<00:17, 161.91it/s] 16%|‚ñà‚ñå        | 517/3257 [00:03<00:16, 169.42it/s] 16%|‚ñà‚ñã        | 535/3257 [00:03<00:16, 167.99it/s] 17%|‚ñà‚ñã        | 553/3257 [00:03<00:15, 170.54it/s] 18%|‚ñà‚ñä        | 571/3257 [00:03<00:17, 151.94it/s] 18%|‚ñà‚ñä        | 589/3257 [00:03<00:16, 158.25it/s] 19%|‚ñà‚ñä        | 609/3257 [00:03<00:15, 168.84it/s] 19%|‚ñà‚ñâ        | 627/3257 [00:03<00:15, 165.44it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:04<00:15, 165.25it/s] 20%|‚ñà‚ñà        | 662/3257 [00:04<00:16, 155.58it/s] 21%|‚ñà‚ñà        | 682/3257 [00:04<00:15, 166.99it/s] 21%|‚ñà‚ñà‚ñè       | 699/3257 [00:04<00:16, 156.90it/s] 22%|‚ñà‚ñà‚ñè       | 719/3257 [00:04<00:15, 168.04it/s] 23%|‚ñà‚ñà‚ñé       | 737/3257 [00:04<00:16, 155.53it/s] 23%|‚ñà‚ñà‚ñé       | 755/3257 [00:04<00:15, 161.24it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:04<00:15, 163.95it/s] 24%|‚ñà‚ñà‚ñç       | 790/3257 [00:04<00:15, 164.08it/s] 25%|‚ñà‚ñà‚ñç       | 807/3257 [00:05<00:15, 161.95it/s] 25%|‚ñà‚ñà‚ñå       | 824/3257 [00:05<00:15, 159.09it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:05<00:15, 158.16it/s] 26%|‚ñà‚ñà‚ñã       | 856/3257 [00:05<00:15, 155.24it/s] 27%|‚ñà‚ñà‚ñã       | 874/3257 [00:05<00:14, 160.73it/s] 27%|‚ñà‚ñà‚ñã       | 891/3257 [00:05<00:14, 159.99it/s] 28%|‚ñà‚ñà‚ñä       | 911/3257 [00:05<00:13, 169.87it/s] 29%|‚ñà‚ñà‚ñä       | 929/3257 [00:05<00:13, 172.35it/s] 29%|‚ñà‚ñà‚ñâ       | 947/3257 [00:05<00:13, 171.00it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:05<00:13, 174.97it/s] 30%|‚ñà‚ñà‚ñà       | 984/3257 [00:06<00:13, 166.98it/s] 31%|‚ñà‚ñà‚ñà       | 1001/3257 [00:06<00:13, 163.14it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1018/3257 [00:06<00:13, 164.89it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1035/3257 [00:06<00:14, 154.42it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:06<00:14, 150.48it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1068/3257 [00:06<00:14, 155.06it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1084/3257 [00:06<00:13, 155.82it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1101/3257 [00:06<00:13, 158.66it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1118/3257 [00:06<00:13, 159.68it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1135/3257 [00:07<00:13, 157.98it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1151/3257 [00:07<00:13, 155.07it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:07<00:12, 163.94it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:07<00:13, 148.55it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:07<00:13, 149.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1220/3257 [00:07<00:13, 151.96it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:07<00:12, 167.81it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:07<00:12, 161.25it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:07<00:12, 159.41it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:08<00:12, 153.05it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:08<00:12, 154.11it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:08<00:12, 160.00it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1347/3257 [00:08<00:11, 166.35it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:08<00:11, 162.71it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1381/3257 [00:08<00:12, 154.76it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1400/3257 [00:08<00:11, 163.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1421/3257 [00:08<00:10, 175.54it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:08<00:10, 167.42it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1461/3257 [00:09<00:09, 181.11it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1480/3257 [00:09<00:09, 180.20it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1501/3257 [00:09<00:09, 186.68it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1520/3257 [00:09<00:10, 171.74it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1538/3257 [00:09<00:10, 167.66it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:09<00:10, 164.03it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:09<00:09, 168.74it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1592/3257 [00:09<00:09, 169.53it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1611/3257 [00:09<00:09, 174.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1629/3257 [00:10<00:14, 115.18it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1644/3257 [00:10<00:13, 118.84it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:10<00:12, 126.13it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1678/3257 [00:10<00:11, 135.36it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1696/3257 [00:10<00:10, 146.19it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:10<00:09, 155.89it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1732/3257 [00:10<00:10, 150.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1750/3257 [00:10<00:09, 157.44it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1770/3257 [00:11<00:08, 167.27it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:11<00:08, 174.24it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1808/3257 [00:11<00:08, 164.41it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:11<00:08, 170.13it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:11<00:08, 173.12it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1868/3257 [00:11<00:07, 184.68it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1887/3257 [00:11<00:07, 176.79it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1908/3257 [00:11<00:07, 184.32it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1927/3257 [00:11<00:07, 178.35it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1952/3257 [00:12<00:06, 196.52it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:12<00:06, 196.90it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1994/3257 [00:12<00:06, 191.90it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2014/3257 [00:12<00:06, 184.89it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:12<00:06, 189.67it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:12<00:06, 172.19it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2073/3257 [00:12<00:06, 172.04it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:12<00:06, 173.46it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2109/3257 [00:12<00:06, 172.02it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2127/3257 [00:13<00:06, 163.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2144/3257 [00:13<00:07, 157.52it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:13<00:06, 164.97it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:13<00:06, 166.94it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2201/3257 [00:13<00:06, 174.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:13<00:06, 167.26it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:13<00:06, 166.20it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2253/3257 [00:13<00:06, 162.63it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:13<00:06, 156.39it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2289/3257 [00:14<00:05, 162.21it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2306/3257 [00:14<00:05, 159.25it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2328/3257 [00:14<00:05, 174.70it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2347/3257 [00:14<00:05, 178.60it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2366/3257 [00:14<00:04, 181.74it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2385/3257 [00:14<00:04, 180.30it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2405/3257 [00:14<00:04, 175.17it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2424/3257 [00:14<00:04, 176.74it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2442/3257 [00:14<00:04, 163.81it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2462/3257 [00:15<00:04, 171.77it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:15<00:04, 175.80it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2502/3257 [00:15<00:04, 183.91it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2521/3257 [00:15<00:04, 183.59it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:15<00:03, 185.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2559/3257 [00:15<00:03, 175.57it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2577/3257 [00:15<00:04, 168.29it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2594/3257 [00:15<00:04, 162.93it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2617/3257 [00:15<00:03, 180.89it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2637/3257 [00:16<00:03, 185.59it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:16<00:03, 172.63it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2674/3257 [00:16<00:03, 166.70it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:16<00:03, 166.17it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2711/3257 [00:16<00:03, 157.33it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:16<00:03, 166.27it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2754/3257 [00:16<00:02, 179.24it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2773/3257 [00:16<00:02, 171.49it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:16<00:02, 182.28it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2814/3257 [00:17<00:02, 181.32it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:17<00:02, 171.43it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:17<00:02, 176.29it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2879/3257 [00:17<00:01, 199.25it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2900/3257 [00:17<00:01, 178.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:17<00:01, 182.71it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2939/3257 [00:17<00:01, 180.65it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2958/3257 [00:17<00:01, 164.90it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:18<00:01, 167.38it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2994/3257 [00:18<00:01, 166.39it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3014/3257 [00:18<00:01, 174.23it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3032/3257 [00:18<00:01, 175.18it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3052/3257 [00:18<00:01, 182.18it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:18<00:00, 192.15it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3095/3257 [00:18<00:00, 188.56it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:18<00:00, 197.35it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3138/3257 [00:18<00:00, 190.94it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3158/3257 [00:18<00:00, 181.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3177/3257 [00:19<00:00, 173.89it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3195/3257 [00:19<00:00, 100.93it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3211/3257 [00:19<00:00, 110.93it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3229/3257 [00:19<00:00, 124.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3252/3257 [00:19<00:00, 147.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 164.21it/s]
2023-02-07 20:01:54.806 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:01:54,808][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d191,n5,mc8,s0.766829,t4>', 'datetime': '2023-02-07T20:01:54.808121', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:01:54,808][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:01:54,808][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:01:55,330][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 20:01:55,330][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:01:55,375][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 13798 unique words (43.39% of original 31803, drops 18005)', 'datetime': '2023-02-07T20:01:55.375702', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:01:55,376][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 5042429 word corpus (98.97% of original 5095118, drops 52689)', 'datetime': '2023-02-07T20:01:55.376250', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:01:55,425][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 20:01:55,427][gensim.models.word2vec][INFO] - sample=0.766829 downsamples 0 most-common words
[2023-02-07 20:01:55,427][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5042429 word corpus (100.0%% of prior 5042429)', 'datetime': '2023-02-07T20:01:55.427758', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:01:55,510][gensim.models.word2vec][INFO] - estimated required memory for 13798 words and 191 dimensions: 31122092 bytes
[2023-02-07 20:01:55,510][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:01:55,526][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 13798 vocabulary and 191 features, using sg=1 hs=0 sample=0.7668287057433532 negative=5 window=12 shrink_windows=True', 'datetime': '2023-02-07T20:01:55.526053', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:01:56,533][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 39.21% examples, 2012775 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:01:57,535][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 70.46% examples, 1809732 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:01:58,415][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5034594 effective words) took 2.9s, 1744066 effective words/s
[2023-02-07 20:01:59,425][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 42.40% examples, 2183966 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:00,426][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 86.49% examples, 2185471 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:00,712][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5034594 effective words) took 2.3s, 2193757 effective words/s
[2023-02-07 20:02:01,714][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 43.66% examples, 2252503 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:02,716][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 89.62% examples, 2266606 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:02,929][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5034594 effective words) took 2.2s, 2272290 effective words/s
[2023-02-07 20:02:03,932][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 43.84% examples, 2260120 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:04,932][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 89.62% examples, 2267239 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:05,147][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5034594 effective words) took 2.2s, 2271262 effective words/s
[2023-02-07 20:02:06,149][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 43.84% examples, 2262221 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:07,151][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 89.62% examples, 2267163 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:07,363][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5034594 effective words) took 2.2s, 2274111 effective words/s
[2023-02-07 20:02:08,368][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 44.58% examples, 2289657 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:09,370][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 91.80% examples, 2322525 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:09,530][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5034594 effective words) took 2.2s, 2324022 effective words/s
[2023-02-07 20:02:10,532][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 44.43% examples, 2290805 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:11,534][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 90.33% examples, 2283548 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:11,734][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5034594 effective words) took 2.2s, 2286274 effective words/s
[2023-02-07 20:02:12,739][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 44.00% examples, 2265921 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:13,744][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 89.62% examples, 2260229 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:13,958][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5034594 effective words) took 2.2s, 2265684 effective words/s
[2023-02-07 20:02:14,961][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 44.00% examples, 2269792 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:15,962][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 90.36% examples, 2287934 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:16,154][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5034594 effective words) took 2.2s, 2293774 effective words/s
[2023-02-07 20:02:17,157][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 45.13% examples, 2316832 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:18,163][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 91.65% examples, 2317469 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:18,326][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5034594 effective words) took 2.2s, 2320591 effective words/s
[2023-02-07 20:02:19,328][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 44.73% examples, 2298634 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:20,333][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 90.67% examples, 2293008 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:20,517][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5034594 effective words) took 2.2s, 2299052 effective words/s
[2023-02-07 20:02:21,521][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 45.13% examples, 2312715 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:22,523][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 92.14% examples, 2329699 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:22,672][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5034594 effective words) took 2.2s, 2338009 effective words/s
[2023-02-07 20:02:23,674][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 45.47% examples, 2336193 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:24,675][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 92.35% examples, 2338650 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:24,823][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5034594 effective words) took 2.1s, 2343459 effective words/s
[2023-02-07 20:02:25,827][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 45.47% examples, 2330391 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:26,829][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 92.48% examples, 2338242 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:26,975][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5034594 effective words) took 2.2s, 2340143 effective words/s
[2023-02-07 20:02:27,977][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 46.61% examples, 2384764 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:28,978][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 94.75% examples, 2390783 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:29,082][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5034594 effective words) took 2.1s, 2391132 effective words/s
[2023-02-07 20:02:29,083][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75518910 effective words) took 33.6s, 2250465 effective words/s', 'datetime': '2023-02-07T20:02:29.083582', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:02:29.083 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:02:32,616][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200125-rbwfgzga/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:02:32.616218', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:02:32,617][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:02:32,668][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200125-rbwfgzga/files/../tmp/embedding_model.pt
2023-02-07 20:02:32.668 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:02:34.236 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:02:34.831 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:02:36.215 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9873726481337386, 'test_mae': 0.7528861940729837, 'test_r2': -1.825128573007131}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.79
wandb: percentage 0.56614
wandb:   test_mae 0.75289
wandb:   test_mse 0.98737
wandb:    test_r2 -1.82513
wandb: 
wandb: üöÄ View run dark-sweep-65 at: https://wandb.ai/xiaoqiz/mof2vec/runs/rbwfgzga
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_200125-rbwfgzga/logs
wandb: Agent Starting Run: 1fe1xwmb with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 780
wandb: 	model.gensim.alpha: 0.005693238167391113
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.3409515206941818
wandb: 	model.gensim.vector_size: 306
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.12652271800907067
wandb: 	model.sklearn.max_depth: 55
wandb: 	model.sklearn.min_child_weight: 0.08096431792785344
wandb: 	model.sklearn.n_estimators: 3697
wandb: 	model.sklearn.num_leaves: 485
wandb: 	model.sklearn.reg_alpha: 0.002548209995713581
wandb: 	model.sklearn.reg_lambda: 0.09905729688832376
wandb: 	model.sklearn.subsample: 0.24041050660840055
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200244-1fe1xwmb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-66
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/1fe1xwmb
2023-02-07 20:02:52.439 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:02:52.440 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 780 for sweep.
2023-02-07 20:02:52.440 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.005693238167391113 for sweep.
2023-02-07 20:02:52.440 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:02:52.441 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 20:02:52.441 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.3409515206941818 for sweep.
2023-02-07 20:02:52.441 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 306 for sweep.
2023-02-07 20:02:52.441 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 20:02:52.442 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.12652271800907067 for sweep.
2023-02-07 20:02:52.442 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 55 for sweep.
2023-02-07 20:02:52.442 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08096431792785344 for sweep.
2023-02-07 20:02:52.442 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3697 for sweep.
2023-02-07 20:02:52.442 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 485 for sweep.
2023-02-07 20:02:52.443 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.002548209995713581 for sweep.
2023-02-07 20:02:52.443 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.09905729688832376 for sweep.
2023-02-07 20:02:52.443 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.24041050660840055 for sweep.
2023-02-07 20:02:52.443 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:02:52.448 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200244-1fe1xwmb/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 780, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 306, 'window': 2, 'min_count': 9, 'dm': 0, 'sample': 0.3409515206941818, 'workers': 4, 'alpha': 0.005693238167391113, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3697, 'max_depth': 55, 'num_leaves': 485, 'reg_alpha': 0.002548209995713581, 'reg_lambda': 0.09905729688832376, 'subsample': 0.24041050660840055, 'min_child_weight': 0.08096431792785344, 'n_jobs': 4, 'learning_rate': 0.12652271800907067}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 12/3257 [00:00<00:27, 119.13it/s]  1%|          | 29/3257 [00:00<00:22, 143.59it/s]  1%|‚ñè         | 44/3257 [00:00<00:23, 138.18it/s]  2%|‚ñè         | 58/3257 [00:00<00:23, 133.66it/s]  2%|‚ñè         | 72/3257 [00:00<00:23, 135.13it/s]  3%|‚ñé         | 89/3257 [00:00<00:21, 146.12it/s]  3%|‚ñé         | 104/3257 [00:00<00:22, 141.47it/s]  4%|‚ñé         | 119/3257 [00:00<00:22, 136.78it/s]  4%|‚ñç         | 134/3257 [00:00<00:22, 138.75it/s]  5%|‚ñç         | 151/3257 [00:01<00:21, 144.66it/s]  5%|‚ñå         | 166/3257 [00:01<00:22, 137.98it/s]  6%|‚ñå         | 180/3257 [00:01<00:22, 136.99it/s]  6%|‚ñå         | 197/3257 [00:01<00:21, 144.23it/s]  7%|‚ñã         | 216/3257 [00:01<00:19, 153.01it/s]  7%|‚ñã         | 235/3257 [00:01<00:18, 162.33it/s]  8%|‚ñä         | 252/3257 [00:01<00:19, 155.05it/s]  8%|‚ñä         | 268/3257 [00:01<00:20, 148.20it/s]  9%|‚ñâ         | 290/3257 [00:01<00:17, 165.33it/s]  9%|‚ñâ         | 307/3257 [00:02<00:18, 156.13it/s] 10%|‚ñà         | 326/3257 [00:02<00:17, 164.03it/s] 11%|‚ñà         | 343/3257 [00:02<00:19, 152.18it/s] 11%|‚ñà         | 360/3257 [00:02<00:18, 155.77it/s] 12%|‚ñà‚ñè        | 376/3257 [00:02<00:19, 148.24it/s] 12%|‚ñà‚ñè        | 392/3257 [00:02<00:20, 142.77it/s] 13%|‚ñà‚ñé        | 409/3257 [00:02<00:19, 148.54it/s] 13%|‚ñà‚ñé        | 425/3257 [00:02<00:21, 134.37it/s] 13%|‚ñà‚ñé        | 439/3257 [00:03<00:22, 127.86it/s] 14%|‚ñà‚ñç        | 456/3257 [00:03<00:20, 137.85it/s] 14%|‚ñà‚ñç        | 472/3257 [00:03<00:19, 142.77it/s] 15%|‚ñà‚ñç        | 487/3257 [00:03<00:20, 138.36it/s] 15%|‚ñà‚ñå        | 504/3257 [00:03<00:19, 143.13it/s] 16%|‚ñà‚ñå        | 519/3257 [00:03<00:19, 143.99it/s] 16%|‚ñà‚ñã        | 534/3257 [00:03<00:19, 138.54it/s] 17%|‚ñà‚ñã        | 548/3257 [00:03<00:19, 138.93it/s] 17%|‚ñà‚ñã        | 562/3257 [00:03<00:20, 131.67it/s] 18%|‚ñà‚ñä        | 576/3257 [00:04<00:21, 124.33it/s] 18%|‚ñà‚ñä        | 590/3257 [00:04<00:20, 128.33it/s] 19%|‚ñà‚ñä        | 604/3257 [00:04<00:20, 130.14it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:04<00:20, 129.59it/s] 20%|‚ñà‚ñâ        | 637/3257 [00:04<00:18, 140.42it/s] 20%|‚ñà‚ñà        | 652/3257 [00:04<00:19, 133.40it/s] 20%|‚ñà‚ñà        | 666/3257 [00:04<00:20, 128.43it/s] 21%|‚ñà‚ñà        | 682/3257 [00:04<00:18, 136.13it/s] 21%|‚ñà‚ñà‚ñè       | 696/3257 [00:04<00:19, 128.98it/s] 22%|‚ñà‚ñà‚ñè       | 714/3257 [00:05<00:17, 141.63it/s] 22%|‚ñà‚ñà‚ñè       | 729/3257 [00:05<00:19, 130.78it/s] 23%|‚ñà‚ñà‚ñé       | 743/3257 [00:05<00:19, 129.06it/s] 23%|‚ñà‚ñà‚ñé       | 759/3257 [00:05<00:18, 135.57it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:05<00:18, 136.75it/s] 24%|‚ñà‚ñà‚ñç       | 787/3257 [00:05<00:17, 137.44it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:17, 139.85it/s] 25%|‚ñà‚ñà‚ñå       | 819/3257 [00:05<00:17, 142.40it/s] 26%|‚ñà‚ñà‚ñå       | 834/3257 [00:05<00:18, 134.04it/s] 26%|‚ñà‚ñà‚ñå       | 848/3257 [00:06<00:18, 127.54it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:06<00:18, 130.67it/s] 27%|‚ñà‚ñà‚ñã       | 878/3257 [00:06<00:18, 129.09it/s] 27%|‚ñà‚ñà‚ñã       | 894/3257 [00:06<00:17, 135.20it/s] 28%|‚ñà‚ñà‚ñä       | 911/3257 [00:06<00:16, 143.02it/s] 28%|‚ñà‚ñà‚ñä       | 927/3257 [00:06<00:15, 146.10it/s] 29%|‚ñà‚ñà‚ñâ       | 942/3257 [00:06<00:16, 139.57it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:06<00:15, 144.88it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:06<00:15, 145.09it/s] 30%|‚ñà‚ñà‚ñà       | 989/3257 [00:07<00:16, 140.85it/s] 31%|‚ñà‚ñà‚ñà       | 1004/3257 [00:07<00:15, 141.84it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1019/3257 [00:07<00:15, 141.47it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1034/3257 [00:07<00:16, 133.29it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1048/3257 [00:07<00:16, 132.02it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:07<00:27, 79.38it/s]  33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:23, 93.31it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1095/3257 [00:08<00:20, 104.37it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:08<00:18, 116.84it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1126/3257 [00:08<00:17, 119.56it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1140/3257 [00:08<00:17, 123.29it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1154/3257 [00:08<00:16, 126.70it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:08<00:15, 133.58it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1184/3257 [00:08<00:16, 126.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1198/3257 [00:08<00:16, 125.96it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1211/3257 [00:08<00:16, 124.48it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1227/3257 [00:09<00:15, 133.91it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:09<00:14, 137.91it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:09<00:14, 136.02it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1273/3257 [00:09<00:13, 142.49it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:09<00:15, 128.94it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1302/3257 [00:09<00:14, 131.19it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1318/3257 [00:09<00:14, 137.89it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1333/3257 [00:09<00:13, 140.53it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1349/3257 [00:09<00:13, 144.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:10<00:13, 138.51it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1378/3257 [00:10<00:13, 138.30it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1392/3257 [00:10<00:13, 133.90it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1410/3257 [00:10<00:12, 144.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1427/3257 [00:10<00:12, 150.37it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1443/3257 [00:10<00:12, 147.55it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1462/3257 [00:10<00:11, 158.88it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1478/3257 [00:10<00:11, 156.48it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:10<00:10, 161.15it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:11<00:10, 161.97it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:11<00:11, 147.68it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:11<00:12, 139.47it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1561/3257 [00:11<00:12, 140.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1576/3257 [00:11<00:11, 140.47it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:11<00:11, 149.59it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1611/3257 [00:11<00:10, 154.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1627/3257 [00:11<00:10, 155.87it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1643/3257 [00:11<00:11, 145.03it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1658/3257 [00:12<00:11, 141.90it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1673/3257 [00:12<00:11, 140.90it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1688/3257 [00:12<00:10, 143.31it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1703/3257 [00:12<00:10, 144.94it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1718/3257 [00:12<00:10, 146.35it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1733/3257 [00:12<00:11, 132.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1749/3257 [00:12<00:10, 139.32it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1765/3257 [00:12<00:10, 143.39it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1783/3257 [00:12<00:09, 152.33it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1799/3257 [00:13<00:09, 149.63it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1815/3257 [00:13<00:09, 145.07it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1830/3257 [00:13<00:10, 141.77it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:13<00:09, 144.16it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1864/3257 [00:13<00:09, 153.87it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1880/3257 [00:13<00:09, 151.71it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1896/3257 [00:13<00:09, 151.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1914/3257 [00:13<00:08, 159.30it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:13<00:08, 150.41it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:13<00:07, 169.05it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1973/3257 [00:14<00:07, 173.58it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1991/3257 [00:14<00:07, 161.11it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:14<00:07, 157.47it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2025/3257 [00:14<00:07, 158.30it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2041/3257 [00:14<00:08, 148.36it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2056/3257 [00:14<00:08, 141.00it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2071/3257 [00:14<00:08, 141.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2086/3257 [00:14<00:08, 142.45it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2101/3257 [00:15<00:08, 138.33it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:15<00:08, 139.75it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2135/3257 [00:15<00:08, 139.82it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2150/3257 [00:15<00:08, 135.99it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:15<00:07, 144.42it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2183/3257 [00:15<00:07, 137.94it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2199/3257 [00:15<00:07, 143.47it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2214/3257 [00:15<00:07, 136.95it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2230/3257 [00:15<00:07, 141.93it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2245/3257 [00:16<00:07, 137.48it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:16<00:07, 140.70it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:16<00:07, 133.48it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2296/3257 [00:16<00:06, 151.18it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2312/3257 [00:16<00:06, 149.39it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2333/3257 [00:16<00:05, 163.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2353/3257 [00:16<00:05, 173.23it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2371/3257 [00:16<00:05, 166.74it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2390/3257 [00:16<00:05, 171.97it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2408/3257 [00:17<00:05, 160.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2425/3257 [00:17<00:05, 159.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2442/3257 [00:17<00:05, 147.42it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2458/3257 [00:17<00:08, 88.89it/s]  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:17<00:07, 104.72it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2495/3257 [00:17<00:06, 120.74it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:17<00:05, 134.29it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2533/3257 [00:18<00:04, 146.78it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2550/3257 [00:18<00:04, 148.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2567/3257 [00:18<00:04, 139.14it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2582/3257 [00:18<00:04, 136.98it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2597/3257 [00:18<00:04, 138.25it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2619/3257 [00:18<00:04, 158.02it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2637/3257 [00:18<00:03, 162.38it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:18<00:03, 152.99it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2670/3257 [00:18<00:03, 153.94it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:19<00:03, 158.34it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:19<00:03, 141.25it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:19<00:03, 138.06it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2739/3257 [00:19<00:03, 153.92it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:19<00:03, 155.54it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2772/3257 [00:19<00:03, 148.28it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:19<00:02, 161.11it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2809/3257 [00:19<00:02, 159.07it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2826/3257 [00:20<00:02, 149.46it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:20<00:02, 146.38it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2862/3257 [00:20<00:02, 159.21it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2882/3257 [00:20<00:02, 169.52it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2900/3257 [00:20<00:02, 151.70it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:20<00:02, 151.53it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2932/3257 [00:20<00:02, 151.41it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2948/3257 [00:20<00:02, 142.15it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2965/3257 [00:20<00:01, 148.56it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2981/3257 [00:21<00:01, 138.48it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3001/3257 [00:21<00:01, 153.64it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3017/3257 [00:21<00:01, 150.70it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3035/3257 [00:21<00:01, 158.39it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3053/3257 [00:21<00:01, 162.30it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3073/3257 [00:21<00:01, 171.54it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3091/3257 [00:21<00:01, 164.38it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:21<00:00, 171.03it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3128/3257 [00:21<00:00, 171.88it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3146/3257 [00:22<00:00, 159.54it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3163/3257 [00:22<00:00, 159.74it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3180/3257 [00:22<00:00, 150.45it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3199/3257 [00:22<00:00, 159.52it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3216/3257 [00:22<00:00, 150.31it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3235/3257 [00:22<00:00, 159.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:22<00:00, 157.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 143.06it/s]
2023-02-07 20:03:16.204 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:03:16,205][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d306,n5,mc9,s0.340952,t4>', 'datetime': '2023-02-07T20:03:16.205719', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:03:16,206][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:03:16,206][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:03:16,884][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:03:16,884][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:03:16,944][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 18315 unique words (33.88% of original 54054, drops 35739)', 'datetime': '2023-02-07T20:03:16.944533', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:03:16,945][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 6422560 word corpus (98.04% of original 6550866, drops 128306)', 'datetime': '2023-02-07T20:03:16.945007', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:03:17,010][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:03:17,012][gensim.models.word2vec][INFO] - sample=0.340952 downsamples 0 most-common words
[2023-02-07 20:03:17,012][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6422560 word corpus (100.0%% of prior 6422560)', 'datetime': '2023-02-07T20:03:17.012419', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:03:17,126][gensim.models.word2vec][INFO] - estimated required memory for 18315 words and 306 dimensions: 58630588 bytes
[2023-02-07 20:03:17,126][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:03:17,156][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18315 vocabulary and 306 features, using sg=1 hs=0 sample=0.3409515206941818 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T20:03:17.156677', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:03:18,167][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 18.24% examples, 1131019 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:19,170][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 36.08% examples, 1158087 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:20,173][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 54.19% examples, 1172365 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:21,180][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 73.10% examples, 1174895 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:22,194][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 92.54% examples, 1177965 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:22,533][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6368654 effective words) took 5.4s, 1185048 effective words/s
[2023-02-07 20:03:23,536][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 31.53% examples, 2025027 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:03:24,540][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 62.85% examples, 2029683 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:25,544][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 96.19% examples, 2037637 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:25,659][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6368654 effective words) took 3.1s, 2038419 effective words/s
[2023-02-07 20:03:26,665][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 31.44% examples, 2000994 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:27,669][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 63.22% examples, 2041172 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:28,669][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 96.65% examples, 2049089 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:28,765][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6368654 effective words) took 3.1s, 2051135 effective words/s
[2023-02-07 20:03:29,769][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 31.81% examples, 2042157 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:30,770][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 63.22% examples, 2047789 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:31,772][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 96.93% examples, 2058158 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:31,860][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6368654 effective words) took 3.1s, 2060000 effective words/s
[2023-02-07 20:03:32,867][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 33.13% examples, 2115348 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:33,869][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 65.43% examples, 2117451 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:34,873][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 100.00% examples, 2115138 words/s, in_qsize 0, out_qsize 1
[2023-02-07 20:03:34,873][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6368654 effective words) took 3.0s, 2114837 effective words/s
[2023-02-07 20:03:35,874][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 32.27% examples, 2080558 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:36,875][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 64.81% examples, 2099971 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:37,876][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 99.85% examples, 2116340 words/s, in_qsize 2, out_qsize 1
[2023-02-07 20:03:37,882][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6368654 effective words) took 3.0s, 2117473 effective words/s
[2023-02-07 20:03:38,890][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 33.68% examples, 2155548 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:39,891][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 67.09% examples, 2172356 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:40,801][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6368654 effective words) took 2.9s, 2183074 effective words/s
[2023-02-07 20:03:41,802][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 36.14% examples, 2335478 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:42,804][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 78.63% examples, 2526608 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:43,276][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6368654 effective words) took 2.5s, 2574349 effective words/s
[2023-02-07 20:03:44,279][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 35.06% examples, 2255066 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:03:45,281][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 67.45% examples, 2184687 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:46,231][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6368654 effective words) took 3.0s, 2155960 effective words/s
[2023-02-07 20:03:47,241][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 32.55% examples, 2079782 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:48,241][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 65.12% examples, 2102962 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:49,249][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 98.83% examples, 2091698 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:49,272][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6368654 effective words) took 3.0s, 2095703 effective words/s
[2023-02-07 20:03:50,281][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 24.29% examples, 1526641 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:51,283][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 47.41% examples, 1536172 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:52,286][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 74.52% examples, 1597767 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:53,193][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6368654 effective words) took 3.9s, 1625518 effective words/s
[2023-02-07 20:03:54,195][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 32.73% examples, 2104239 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:55,198][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 64.91% examples, 2099970 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:56,198][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 99.26% examples, 2105993 words/s, in_qsize 6, out_qsize 0
[2023-02-07 20:03:56,215][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6368654 effective words) took 3.0s, 2108168 effective words/s
[2023-02-07 20:03:57,218][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 33.13% examples, 2124810 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:58,219][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 65.43% examples, 2123523 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:59,222][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 100.00% examples, 2119953 words/s, in_qsize 0, out_qsize 1
[2023-02-07 20:03:59,222][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6368654 effective words) took 3.0s, 2119628 effective words/s
[2023-02-07 20:04:00,224][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 32.55% examples, 2096113 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:04:01,228][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 65.34% examples, 2115574 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:04:02,208][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6368654 effective words) took 3.0s, 2133571 effective words/s
[2023-02-07 20:04:03,215][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 33.34% examples, 2133821 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:04:04,219][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 65.80% examples, 2132728 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:04:05,198][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6368654 effective words) took 3.0s, 2132038 effective words/s
[2023-02-07 20:04:05,198][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (95529810 effective words) took 48.0s, 1988486 effective words/s', 'datetime': '2023-02-07T20:04:05.198665', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:04:05.198 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:04:10,370][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200244-1fe1xwmb/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:04:10.370627', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:04:10,371][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:04:10,490][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200244-1fe1xwmb/files/../tmp/embedding_model.pt
2023-02-07 20:04:10.490 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:04:12.587 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:04:13.306 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:04:19.253 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9518320099778222, 'test_mae': 0.7617898543645267, 'test_r2': -1.9947444004630883}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.83
wandb: percentage 0.66117
wandb:   test_mae 0.76179
wandb:   test_mse 0.95183
wandb:    test_r2 -1.99474
wandb: 
wandb: üöÄ View run upbeat-sweep-66 at: https://wandb.ai/xiaoqiz/mof2vec/runs/1fe1xwmb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_200244-1fe1xwmb/logs
wandb: Agent Starting Run: 63dizi1i with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 793
wandb: 	model.gensim.alpha: 0.029524517112492637
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.406434441260074
wandb: 	model.gensim.vector_size: 436
wandb: 	model.gensim.window: 18
wandb: 	model.sklearn.learning_rate: 0.011301254138312776
wandb: 	model.sklearn.max_depth: 34
wandb: 	model.sklearn.min_child_weight: 0.08190646419215263
wandb: 	model.sklearn.n_estimators: 890
wandb: 	model.sklearn.num_leaves: 322
wandb: 	model.sklearn.reg_alpha: 0.00412154670706359
wandb: 	model.sklearn.reg_lambda: 0.059088197712178235
wandb: 	model.sklearn.subsample: 0.3332389840993346
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200430-63dizi1i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-67
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/63dizi1i
2023-02-07 20:04:39.462 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 20:04:39.463 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 793 for sweep.
2023-02-07 20:04:39.463 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.029524517112492637 for sweep.
2023-02-07 20:04:39.464 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:04:39.464 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 20:04:39.464 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.406434441260074 for sweep.
2023-02-07 20:04:39.465 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 436 for sweep.
2023-02-07 20:04:39.465 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 18 for sweep.
2023-02-07 20:04:39.465 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.011301254138312776 for sweep.
2023-02-07 20:04:39.465 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 34 for sweep.
2023-02-07 20:04:39.466 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08190646419215263 for sweep.
2023-02-07 20:04:39.466 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 890 for sweep.
2023-02-07 20:04:39.466 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 322 for sweep.
2023-02-07 20:04:39.466 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.00412154670706359 for sweep.
2023-02-07 20:04:39.467 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.059088197712178235 for sweep.
2023-02-07 20:04:39.467 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3332389840993346 for sweep.
2023-02-07 20:04:39.467 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:04:39.477 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200430-63dizi1i/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 793, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 436, 'window': 18, 'min_count': 3, 'dm': 0, 'sample': 0.406434441260074, 'workers': 4, 'alpha': 0.029524517112492637, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 890, 'max_depth': 34, 'num_leaves': 322, 'reg_alpha': 0.00412154670706359, 'reg_lambda': 0.059088197712178235, 'subsample': 0.3332389840993346, 'min_child_weight': 0.08190646419215263, 'n_jobs': 4, 'learning_rate': 0.011301254138312776}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 136.90it/s]  1%|          | 32/3257 [00:00<00:20, 158.96it/s]  1%|‚ñè         | 48/3257 [00:00<00:20, 156.40it/s]  2%|‚ñè         | 64/3257 [00:00<00:20, 156.75it/s]  2%|‚ñè         | 81/3257 [00:00<00:19, 159.06it/s]  3%|‚ñé         | 97/3257 [00:00<00:20, 156.36it/s]  3%|‚ñé         | 113/3257 [00:00<00:20, 154.55it/s]  4%|‚ñç         | 131/3257 [00:00<00:19, 160.03it/s]  5%|‚ñç         | 151/3257 [00:00<00:18, 168.69it/s]  5%|‚ñå         | 169/3257 [00:01<00:18, 170.69it/s]  6%|‚ñå         | 187/3257 [00:01<00:17, 173.37it/s]  6%|‚ñã         | 205/3257 [00:01<00:17, 174.39it/s]  7%|‚ñã         | 228/3257 [00:01<00:15, 189.68it/s]  8%|‚ñä         | 247/3257 [00:01<00:16, 185.74it/s]  8%|‚ñä         | 266/3257 [00:01<00:16, 178.02it/s]  9%|‚ñâ         | 290/3257 [00:01<00:15, 192.77it/s] 10%|‚ñâ         | 310/3257 [00:01<00:15, 188.13it/s] 10%|‚ñà         | 329/3257 [00:01<00:15, 186.85it/s] 11%|‚ñà         | 348/3257 [00:02<00:15, 182.81it/s] 11%|‚ñà‚ñè        | 369/3257 [00:02<00:15, 190.06it/s] 12%|‚ñà‚ñè        | 389/3257 [00:02<00:16, 175.13it/s] 13%|‚ñà‚ñé        | 411/3257 [00:02<00:15, 183.11it/s] 13%|‚ñà‚ñé        | 430/3257 [00:02<00:17, 163.21it/s] 14%|‚ñà‚ñé        | 447/3257 [00:02<00:17, 164.01it/s] 14%|‚ñà‚ñç        | 468/3257 [00:02<00:15, 174.77it/s] 15%|‚ñà‚ñç        | 486/3257 [00:02<00:16, 169.41it/s] 16%|‚ñà‚ñå        | 507/3257 [00:02<00:15, 179.44it/s] 16%|‚ñà‚ñå        | 526/3257 [00:03<00:15, 174.65it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:15, 176.13it/s] 17%|‚ñà‚ñã        | 564/3257 [00:03<00:24, 108.04it/s] 18%|‚ñà‚ñä        | 581/3257 [00:03<00:22, 118.44it/s] 18%|‚ñà‚ñä        | 602/3257 [00:03<00:19, 136.74it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:18, 143.39it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:03<00:16, 156.76it/s] 20%|‚ñà‚ñà        | 658/3257 [00:04<00:17, 152.64it/s] 21%|‚ñà‚ñà        | 678/3257 [00:04<00:15, 163.48it/s] 21%|‚ñà‚ñà‚ñè       | 696/3257 [00:04<00:15, 161.68it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:14, 174.77it/s] 23%|‚ñà‚ñà‚ñé       | 737/3257 [00:04<00:15, 164.26it/s] 23%|‚ñà‚ñà‚ñé       | 757/3257 [00:04<00:14, 171.46it/s] 24%|‚ñà‚ñà‚ñç       | 775/3257 [00:04<00:14, 173.64it/s] 24%|‚ñà‚ñà‚ñç       | 793/3257 [00:04<00:14, 173.65it/s] 25%|‚ñà‚ñà‚ñç       | 813/3257 [00:04<00:13, 180.86it/s] 26%|‚ñà‚ñà‚ñå       | 832/3257 [00:05<00:13, 177.42it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:05<00:14, 171.91it/s] 27%|‚ñà‚ñà‚ñã       | 873/3257 [00:05<00:12, 186.47it/s] 27%|‚ñà‚ñà‚ñã       | 894/3257 [00:05<00:12, 190.53it/s] 28%|‚ñà‚ñà‚ñä       | 918/3257 [00:05<00:11, 203.31it/s] 29%|‚ñà‚ñà‚ñâ       | 941/3257 [00:05<00:11, 209.52it/s] 30%|‚ñà‚ñà‚ñâ       | 967/3257 [00:05<00:10, 218.63it/s] 30%|‚ñà‚ñà‚ñà       | 989/3257 [00:05<00:10, 214.31it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:05<00:10, 209.64it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1033/3257 [00:05<00:10, 208.00it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1055/3257 [00:06<00:10, 209.01it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:10, 210.53it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1103/3257 [00:06<00:09, 215.99it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1125/3257 [00:06<00:09, 214.03it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1147/3257 [00:06<00:10, 209.07it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:06<00:09, 217.70it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1193/3257 [00:06<00:10, 193.00it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1213/3257 [00:06<00:10, 190.43it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:06<00:09, 211.26it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1263/3257 [00:07<00:09, 213.14it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1285/3257 [00:07<00:10, 188.54it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:07<00:09, 196.48it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1332/3257 [00:07<00:09, 207.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:07<00:09, 205.09it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1377/3257 [00:07<00:08, 211.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1399/3257 [00:07<00:08, 213.49it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1425/3257 [00:07<00:08, 226.01it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1451/3257 [00:07<00:07, 234.59it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1476/3257 [00:08<00:07, 237.48it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1503/3257 [00:08<00:07, 245.92it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1528/3257 [00:08<00:07, 227.90it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1552/3257 [00:08<00:07, 218.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:08<00:07, 217.19it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1601/3257 [00:08<00:07, 227.23it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1624/3257 [00:08<00:07, 219.16it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1647/3257 [00:08<00:07, 211.91it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1669/3257 [00:08<00:07, 209.74it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:09<00:07, 204.29it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1714/3257 [00:09<00:07, 210.98it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1736/3257 [00:09<00:10, 138.52it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1760/3257 [00:09<00:09, 158.93it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1784/3257 [00:09<00:08, 175.41it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1805/3257 [00:09<00:08, 179.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:09<00:07, 184.21it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1848/3257 [00:09<00:07, 193.27it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1872/3257 [00:10<00:06, 204.47it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1894/3257 [00:10<00:06, 202.80it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:10<00:06, 206.90it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1942/3257 [00:10<00:05, 221.27it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1971/3257 [00:10<00:05, 237.65it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1996/3257 [00:10<00:05, 229.96it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2020/3257 [00:10<00:05, 227.50it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2043/3257 [00:10<00:05, 218.66it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2066/3257 [00:10<00:05, 203.01it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2089/3257 [00:11<00:05, 209.46it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2111/3257 [00:11<00:05, 210.13it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2133/3257 [00:11<00:05, 192.97it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2153/3257 [00:11<00:05, 190.21it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2176/3257 [00:11<00:05, 200.53it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2197/3257 [00:11<00:05, 196.99it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2217/3257 [00:11<00:05, 189.21it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:11<00:05, 191.41it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:11<00:05, 195.89it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2280/3257 [00:12<00:04, 195.94it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2303/3257 [00:12<00:04, 204.56it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2331/3257 [00:12<00:04, 224.38it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:12<00:03, 231.61it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2386/3257 [00:12<00:03, 239.61it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2411/3257 [00:12<00:03, 229.24it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2435/3257 [00:12<00:03, 217.12it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2457/3257 [00:12<00:03, 215.43it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:12<00:03, 221.17it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:13<00:03, 231.15it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2531/3257 [00:13<00:03, 232.29it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2555/3257 [00:13<00:03, 219.35it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2578/3257 [00:13<00:03, 211.13it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:13<00:03, 206.44it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2629/3257 [00:13<00:02, 227.32it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2652/3257 [00:13<00:02, 221.57it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2675/3257 [00:13<00:02, 220.33it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2698/3257 [00:13<00:02, 201.62it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:14<00:02, 196.28it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2745/3257 [00:14<00:02, 213.38it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2768/3257 [00:14<00:02, 210.34it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:14<00:02, 225.02it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2818/3257 [00:14<00:01, 221.19it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2841/3257 [00:14<00:01, 218.32it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2873/3257 [00:14<00:01, 245.36it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2898/3257 [00:14<00:01, 234.00it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2925/3257 [00:14<00:01, 242.46it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:15<00:01, 222.14it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:15<00:01, 223.33it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3002/3257 [00:15<00:01, 232.38it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:15<00:01, 230.44it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3054/3257 [00:15<00:00, 242.29it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3081/3257 [00:15<00:00, 247.82it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3109/3257 [00:15<00:00, 252.25it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3135/3257 [00:15<00:00, 246.06it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3160/3257 [00:16<00:00, 151.80it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3180/3257 [00:16<00:00, 158.91it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:16<00:00, 179.49it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3231/3257 [00:16<00:00, 193.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3255/3257 [00:16<00:00, 204.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 196.84it/s]
2023-02-07 20:04:56.730 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:04:56,731][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d436,n5,mc3,s0.406434,t4>', 'datetime': '2023-02-07T20:04:56.731091', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:04:56,732][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:04:56,732][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:04:57,189][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 20:04:57,190][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:04:57,245][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 22723 unique words (71.45% of original 31803, drops 9080)', 'datetime': '2023-02-07T20:04:57.245892', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:04:57,246][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 5081575 word corpus (99.73% of original 5095118, drops 13543)', 'datetime': '2023-02-07T20:04:57.246150', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:04:57,321][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 20:04:57,323][gensim.models.word2vec][INFO] - sample=0.406434 downsamples 0 most-common words
[2023-02-07 20:04:57,324][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5081575 word corpus (100.0%% of prior 5081575)', 'datetime': '2023-02-07T20:04:57.324275', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:04:57,462][gensim.models.word2vec][INFO] - estimated required memory for 22723 words and 436 dimensions: 96950932 bytes
[2023-02-07 20:04:57,462][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:04:57,513][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 22723 vocabulary and 436 features, using sg=1 hs=0 sample=0.406434441260074 negative=5 window=18 shrink_windows=True', 'datetime': '2023-02-07T20:04:57.512969', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:04:58,519][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 23.40% examples, 1174708 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:04:59,521][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 47.47% examples, 1226488 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:00,529][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 72.52% examples, 1241480 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:01,532][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 99.11% examples, 1254088 words/s, in_qsize 5, out_qsize 0
[2023-02-07 20:05:01,556][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5073452 effective words) took 4.0s, 1256261 effective words/s
[2023-02-07 20:05:02,558][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 33.13% examples, 1693121 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:05:03,562][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 64.35% examples, 1659684 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:04,564][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 97.36% examples, 1644503 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:04,636][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5073452 effective words) took 3.1s, 1648003 effective words/s
[2023-02-07 20:05:05,641][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 33.47% examples, 1713262 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:06,642][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 66.47% examples, 1716958 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:07,583][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5073452 effective words) took 2.9s, 1722310 effective words/s
[2023-02-07 20:05:08,587][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 33.16% examples, 1700412 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:09,591][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 65.86% examples, 1702470 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:10,565][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5073452 effective words) took 3.0s, 1702325 effective words/s
[2023-02-07 20:05:11,575][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 33.59% examples, 1713593 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:12,577][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 66.66% examples, 1716042 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:13,524][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5073452 effective words) took 3.0s, 1715036 effective words/s
[2023-02-07 20:05:14,529][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 33.16% examples, 1701749 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:15,532][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 66.04% examples, 1707808 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:16,473][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5073452 effective words) took 2.9s, 1722369 effective words/s
[2023-02-07 20:05:17,476][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 35.19% examples, 1814580 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:18,477][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 70.06% examples, 1813378 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:05:19,290][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5073452 effective words) took 2.8s, 1801999 effective words/s
[2023-02-07 20:05:20,297][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 34.48% examples, 1760114 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:21,297][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 69.36% examples, 1792526 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:22,109][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5073452 effective words) took 2.8s, 1800484 effective words/s
[2023-02-07 20:05:23,115][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 35.06% examples, 1800017 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:05:24,118][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 70.06% examples, 1809552 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:24,915][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5073452 effective words) took 2.8s, 1809142 effective words/s
[2023-02-07 20:05:25,918][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 35.19% examples, 1814861 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:26,918][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 70.56% examples, 1827389 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:27,685][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5073452 effective words) took 2.8s, 1832869 effective words/s
[2023-02-07 20:05:28,690][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 35.06% examples, 1799361 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:29,694][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 70.06% examples, 1808530 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:30,488][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5073452 effective words) took 2.8s, 1810829 effective words/s
[2023-02-07 20:05:31,491][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 35.65% examples, 1834343 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:32,495][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 70.56% examples, 1824435 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:33,271][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5073452 effective words) took 2.8s, 1824430 effective words/s
[2023-02-07 20:05:34,282][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 35.06% examples, 1794760 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:35,283][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 62.85% examples, 1614882 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:05:36,291][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 91.40% examples, 1547488 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:36,566][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5073452 effective words) took 3.3s, 1541781 effective words/s
[2023-02-07 20:05:37,568][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 33.77% examples, 1737189 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:05:38,569][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 67.79% examples, 1753834 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:39,442][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5073452 effective words) took 2.9s, 1764555 effective words/s
[2023-02-07 20:05:40,447][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 35.06% examples, 1800313 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:41,453][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 69.67% examples, 1798390 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:42,259][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5073452 effective words) took 2.8s, 1801908 effective words/s
[2023-02-07 20:05:42,260][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76101780 effective words) took 44.7s, 1700724 effective words/s', 'datetime': '2023-02-07T20:05:42.260083', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:05:42.260 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:05:46,476][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200430-63dizi1i/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:05:46.476551', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:05:46,477][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:05:46,588][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200430-63dizi1i/files/../tmp/embedding_model.pt
2023-02-07 20:05:46.588 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:05:49.012 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:05:49.844 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:06:25.235 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9799716116989131, 'test_mae': 0.7615090353083025, 'test_r2': -2.5596911956447883}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.94
wandb: percentage 0.28551
wandb:   test_mae 0.76151
wandb:   test_mse 0.97997
wandb:    test_r2 -2.55969
wandb: 
wandb: üöÄ View run fresh-sweep-67 at: https://wandb.ai/xiaoqiz/mof2vec/runs/63dizi1i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_200430-63dizi1i/logs
wandb: Agent Starting Run: 7prxrimr with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 512
wandb: 	model.gensim.alpha: 0.07582709795803408
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.5068713099564321
wandb: 	model.gensim.vector_size: 320
wandb: 	model.gensim.window: 9
wandb: 	model.sklearn.learning_rate: 0.24915566053677193
wandb: 	model.sklearn.max_depth: 57
wandb: 	model.sklearn.min_child_weight: 0.08929457036020436
wandb: 	model.sklearn.n_estimators: 302
wandb: 	model.sklearn.num_leaves: 366
wandb: 	model.sklearn.reg_alpha: 0.005876533690035625
wandb: 	model.sklearn.reg_lambda: 0.2812112099293151
wandb: 	model.sklearn.subsample: 0.29564993524615163
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200636-7prxrimr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-68
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/7prxrimr
2023-02-07 20:06:44.570 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 20:06:44.571 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 512 for sweep.
2023-02-07 20:06:44.571 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.07582709795803408 for sweep.
2023-02-07 20:06:44.571 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:06:44.572 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 20:06:44.572 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5068713099564321 for sweep.
2023-02-07 20:06:44.572 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 320 for sweep.
2023-02-07 20:06:44.572 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 9 for sweep.
2023-02-07 20:06:44.573 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.24915566053677193 for sweep.
2023-02-07 20:06:44.573 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 57 for sweep.
2023-02-07 20:06:44.573 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08929457036020436 for sweep.
2023-02-07 20:06:44.573 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 302 for sweep.
2023-02-07 20:06:44.574 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 366 for sweep.
2023-02-07 20:06:44.574 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.005876533690035625 for sweep.
2023-02-07 20:06:44.574 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.2812112099293151 for sweep.
2023-02-07 20:06:44.574 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.29564993524615163 for sweep.
2023-02-07 20:06:44.574 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:06:44.583 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200636-7prxrimr/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 512, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 320, 'window': 9, 'min_count': 8, 'dm': 0, 'sample': 0.5068713099564321, 'workers': 4, 'alpha': 0.07582709795803408, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 302, 'max_depth': 57, 'num_leaves': 366, 'reg_alpha': 0.005876533690035625, 'reg_lambda': 0.2812112099293151, 'subsample': 0.29564993524615163, 'min_child_weight': 0.08929457036020436, 'n_jobs': 4, 'learning_rate': 0.24915566053677193}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:20, 159.43it/s]  1%|          | 34/3257 [00:00<00:19, 165.13it/s]  2%|‚ñè         | 53/3257 [00:00<00:18, 170.17it/s]  2%|‚ñè         | 72/3257 [00:00<00:18, 175.94it/s]  3%|‚ñé         | 91/3257 [00:00<00:17, 176.91it/s]  3%|‚ñé         | 109/3257 [00:00<00:18, 167.10it/s]  4%|‚ñç         | 127/3257 [00:00<00:18, 169.64it/s]  5%|‚ñç         | 148/3257 [00:00<00:17, 179.89it/s]  5%|‚ñå         | 167/3257 [00:00<00:17, 172.04it/s]  6%|‚ñå         | 185/3257 [00:01<00:17, 173.97it/s]  6%|‚ñå         | 203/3257 [00:01<00:17, 173.23it/s]  7%|‚ñã         | 227/3257 [00:01<00:15, 192.59it/s]  8%|‚ñä         | 247/3257 [00:01<00:15, 192.84it/s]  8%|‚ñä         | 267/3257 [00:01<00:16, 181.96it/s]  9%|‚ñâ         | 292/3257 [00:01<00:14, 199.69it/s] 10%|‚ñâ         | 313/3257 [00:01<00:15, 187.44it/s] 10%|‚ñà         | 334/3257 [00:01<00:15, 192.74it/s] 11%|‚ñà         | 354/3257 [00:01<00:15, 188.96it/s] 11%|‚ñà‚ñè        | 374/3257 [00:02<00:15, 188.80it/s] 12%|‚ñà‚ñè        | 394/3257 [00:02<00:16, 174.14it/s] 13%|‚ñà‚ñé        | 415/3257 [00:02<00:15, 182.06it/s] 13%|‚ñà‚ñé        | 434/3257 [00:02<00:17, 159.12it/s] 14%|‚ñà‚ñç        | 454/3257 [00:02<00:16, 167.94it/s] 15%|‚ñà‚ñç        | 474/3257 [00:02<00:16, 172.75it/s] 15%|‚ñà‚ñå        | 493/3257 [00:02<00:15, 176.15it/s] 16%|‚ñà‚ñå        | 513/3257 [00:02<00:15, 181.13it/s] 16%|‚ñà‚ñã        | 532/3257 [00:02<00:15, 176.30it/s] 17%|‚ñà‚ñã        | 551/3257 [00:03<00:15, 179.34it/s] 18%|‚ñà‚ñä        | 570/3257 [00:03<00:15, 168.88it/s] 18%|‚ñà‚ñä        | 588/3257 [00:03<00:16, 163.31it/s] 19%|‚ñà‚ñä        | 608/3257 [00:03<00:15, 173.17it/s] 19%|‚ñà‚ñâ        | 626/3257 [00:03<00:15, 171.20it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:15, 170.40it/s] 20%|‚ñà‚ñà        | 663/3257 [00:03<00:15, 163.80it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:15, 166.21it/s] 21%|‚ñà‚ñà‚ñè       | 700/3257 [00:03<00:15, 165.31it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:04<00:14, 171.75it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:04<00:15, 161.73it/s] 23%|‚ñà‚ñà‚ñé       | 758/3257 [00:04<00:14, 170.78it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:04<00:15, 164.21it/s] 24%|‚ñà‚ñà‚ñç       | 795/3257 [00:04<00:14, 169.56it/s] 25%|‚ñà‚ñà‚ñç       | 814/3257 [00:04<00:14, 170.88it/s] 26%|‚ñà‚ñà‚ñå       | 832/3257 [00:04<00:14, 166.47it/s] 26%|‚ñà‚ñà‚ñå       | 849/3257 [00:04<00:15, 159.21it/s] 27%|‚ñà‚ñà‚ñã       | 867/3257 [00:04<00:14, 164.18it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:05<00:14, 158.83it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:13, 171.64it/s] 28%|‚ñà‚ñà‚ñä       | 924/3257 [00:05<00:13, 175.55it/s] 29%|‚ñà‚ñà‚ñâ       | 942/3257 [00:05<00:13, 172.58it/s] 30%|‚ñà‚ñà‚ñâ       | 961/3257 [00:05<00:12, 177.27it/s] 30%|‚ñà‚ñà‚ñà       | 979/3257 [00:05<00:13, 174.97it/s] 31%|‚ñà‚ñà‚ñà       | 997/3257 [00:05<00:13, 172.08it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:05<00:13, 172.11it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1033/3257 [00:05<00:13, 164.78it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1050/3257 [00:06<00:13, 162.45it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:06<00:21, 104.25it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1084/3257 [00:06<00:18, 117.53it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1102/3257 [00:06<00:16, 131.29it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1119/3257 [00:06<00:15, 137.99it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1136/3257 [00:06<00:14, 145.88it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1152/3257 [00:06<00:14, 148.65it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:07<00:13, 157.84it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:07<00:14, 146.94it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:07<00:13, 150.60it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1224/3257 [00:07<00:12, 160.63it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1244/3257 [00:07<00:11, 169.78it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:07<00:11, 172.41it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1280/3257 [00:07<00:12, 163.38it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1297/3257 [00:07<00:12, 159.41it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1317/3257 [00:07<00:11, 169.90it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1336/3257 [00:07<00:10, 175.33it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:08<00:11, 168.26it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1372/3257 [00:08<00:11, 167.74it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1389/3257 [00:08<00:11, 165.89it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1411/3257 [00:08<00:10, 181.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:08<00:09, 185.44it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1453/3257 [00:08<00:09, 190.27it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1475/3257 [00:08<00:09, 197.58it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1495/3257 [00:08<00:08, 196.67it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1516/3257 [00:08<00:08, 200.16it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1537/3257 [00:09<00:09, 177.44it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1556/3257 [00:09<00:09, 173.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:09<00:09, 170.98it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1595/3257 [00:09<00:09, 178.39it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:09<00:08, 183.48it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:09<00:09, 171.72it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1652/3257 [00:09<00:09, 169.35it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1670/3257 [00:09<00:09, 167.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1687/3257 [00:09<00:09, 163.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1706/3257 [00:10<00:09, 170.42it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1724/3257 [00:10<00:08, 173.05it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1742/3257 [00:10<00:09, 155.31it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:10<00:08, 166.98it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1783/3257 [00:10<00:08, 175.82it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1801/3257 [00:10<00:08, 176.00it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1819/3257 [00:10<00:08, 176.69it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1837/3257 [00:10<00:08, 174.67it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1856/3257 [00:10<00:07, 177.20it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1877/3257 [00:11<00:07, 184.74it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1896/3257 [00:11<00:07, 177.63it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:11<00:07, 180.40it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:11<00:07, 185.81it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1962/3257 [00:11<00:06, 202.95it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1983/3257 [00:11<00:06, 187.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:11<00:06, 191.95it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2024/3257 [00:11<00:06, 192.50it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2044/3257 [00:11<00:06, 185.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2063/3257 [00:12<00:07, 170.33it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:12<00:06, 175.67it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2101/3257 [00:12<00:06, 170.30it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:12<00:06, 171.56it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2138/3257 [00:12<00:06, 170.17it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2156/3257 [00:12<00:06, 167.38it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2177/3257 [00:12<00:06, 176.69it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2195/3257 [00:12<00:06, 174.41it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2213/3257 [00:12<00:06, 164.89it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2233/3257 [00:13<00:05, 174.32it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2251/3257 [00:13<00:05, 171.17it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2269/3257 [00:13<00:05, 172.37it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2288/3257 [00:13<00:05, 175.36it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2306/3257 [00:13<00:05, 175.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2329/3257 [00:13<00:04, 189.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2353/3257 [00:13<00:04, 200.91it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2374/3257 [00:13<00:07, 126.14it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:14<00:05, 147.06it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2416/3257 [00:14<00:05, 152.31it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2434/3257 [00:14<00:05, 154.02it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2452/3257 [00:14<00:05, 158.48it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:14<00:04, 177.01it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2498/3257 [00:14<00:04, 187.13it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2520/3257 [00:14<00:03, 195.36it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2541/3257 [00:14<00:03, 193.73it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2561/3257 [00:14<00:03, 186.60it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2581/3257 [00:15<00:03, 178.67it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:15<00:03, 180.87it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2625/3257 [00:15<00:03, 199.97it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2646/3257 [00:15<00:03, 190.73it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2666/3257 [00:15<00:03, 184.92it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:15<00:02, 190.52it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2707/3257 [00:15<00:03, 172.15it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2725/3257 [00:15<00:03, 173.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2747/3257 [00:15<00:02, 185.96it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2767/3257 [00:16<00:02, 188.81it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2787/3257 [00:16<00:02, 188.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:16<00:02, 189.17it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2827/3257 [00:16<00:02, 179.81it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2846/3257 [00:16<00:02, 180.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:16<00:01, 201.54it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2893/3257 [00:16<00:01, 192.82it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2914/3257 [00:16<00:01, 196.28it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2934/3257 [00:16<00:01, 188.72it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2954/3257 [00:17<00:01, 179.73it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2975/3257 [00:17<00:01, 186.43it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2994/3257 [00:17<00:01, 178.31it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:17<00:01, 185.82it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3038/3257 [00:17<00:01, 194.02it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3061/3257 [00:17<00:00, 203.53it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:17<00:00, 202.42it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3104/3257 [00:17<00:00, 204.17it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:17<00:00, 205.74it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3148/3257 [00:18<00:00, 190.82it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3168/3257 [00:18<00:00, 191.65it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3188/3257 [00:18<00:00, 186.30it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3208/3257 [00:18<00:00, 187.13it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3227/3257 [00:18<00:00, 187.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3251/3257 [00:18<00:00, 201.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 174.78it/s]
2023-02-07 20:07:03.926 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:07:03,927][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d320,n5,mc8,s0.506871,t4>', 'datetime': '2023-02-07T20:07:03.927453', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:07:03,927][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:07:03,928][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:07:04,415][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 20:07:04,415][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:07:04,457][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 13798 unique words (43.39% of original 31803, drops 18005)', 'datetime': '2023-02-07T20:07:04.457010', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:07:04,457][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 5042429 word corpus (98.97% of original 5095118, drops 52689)', 'datetime': '2023-02-07T20:07:04.457452', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:07:04,503][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 20:07:04,504][gensim.models.word2vec][INFO] - sample=0.506871 downsamples 0 most-common words
[2023-02-07 20:07:04,504][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5042429 word corpus (100.0%% of prior 5042429)', 'datetime': '2023-02-07T20:07:04.504778', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:07:04,584][gensim.models.word2vec][INFO] - estimated required memory for 13798 words and 320 dimensions: 47042240 bytes
[2023-02-07 20:07:04,585][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:07:04,611][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 13798 vocabulary and 320 features, using sg=1 hs=0 sample=0.5068713099564321 negative=5 window=9 shrink_windows=True', 'datetime': '2023-02-07T20:07:04.611236', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:07:05,616][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 45.69% examples, 2343004 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:06,617][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 91.37% examples, 2313919 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:06,794][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5034594 effective words) took 2.2s, 2309711 effective words/s
[2023-02-07 20:07:07,797][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 47.90% examples, 2460647 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:08,800][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 97.14% examples, 2443388 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:08,851][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5034594 effective words) took 2.1s, 2448586 effective words/s
[2023-02-07 20:07:09,853][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 48.57% examples, 2500835 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:07:10,851][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5034594 effective words) took 2.0s, 2519568 effective words/s
[2023-02-07 20:07:11,856][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 49.25% examples, 2519984 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:12,846][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5034594 effective words) took 2.0s, 2524521 effective words/s
[2023-02-07 20:07:13,848][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 49.25% examples, 2529549 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:14,833][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5034594 effective words) took 2.0s, 2536278 effective words/s
[2023-02-07 20:07:15,834][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 49.62% examples, 2548682 words/s, in_qsize 6, out_qsize 1
[2023-02-07 20:07:16,789][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5034594 effective words) took 2.0s, 2575577 effective words/s
[2023-02-07 20:07:17,792][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 50.14% examples, 2564059 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:18,744][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5034594 effective words) took 2.0s, 2576773 effective words/s
[2023-02-07 20:07:19,749][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 49.46% examples, 2530396 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:20,735][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5034594 effective words) took 2.0s, 2530012 effective words/s
[2023-02-07 20:07:21,744][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 49.25% examples, 2511038 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:22,747][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 99.48% examples, 2491184 words/s, in_qsize 3, out_qsize 1
[2023-02-07 20:07:22,751][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5034594 effective words) took 2.0s, 2500097 effective words/s
[2023-02-07 20:07:23,754][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 48.57% examples, 2495674 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:24,755][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 100.00% examples, 2513116 words/s, in_qsize 0, out_qsize 1
[2023-02-07 20:07:24,756][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5034594 effective words) took 2.0s, 2512436 effective words/s
[2023-02-07 20:07:25,761][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 48.57% examples, 2491339 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:26,755][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5034594 effective words) took 2.0s, 2520358 effective words/s
[2023-02-07 20:07:27,764][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 50.14% examples, 2549823 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:28,714][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5034594 effective words) took 2.0s, 2571717 effective words/s
[2023-02-07 20:07:29,718][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 49.86% examples, 2562757 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:07:30,702][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5034594 effective words) took 2.0s, 2535095 effective words/s
[2023-02-07 20:07:31,703][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 49.25% examples, 2529739 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:32,677][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5034594 effective words) took 2.0s, 2550207 effective words/s
[2023-02-07 20:07:33,680][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 49.46% examples, 2535030 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:34,677][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5034594 effective words) took 2.0s, 2519583 effective words/s
[2023-02-07 20:07:34,677][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75518910 effective words) took 30.1s, 2511759 effective words/s', 'datetime': '2023-02-07T20:07:34.677888', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:07:34.678 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:07:37,797][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200636-7prxrimr/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:07:37.797764', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:07:37,798][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:07:37,863][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200636-7prxrimr/files/../tmp/embedding_model.pt
2023-02-07 20:07:37.864 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:07:39.835 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:07:40.551 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:07:44.840 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.090708264069212, 'test_mae': 0.7981077784135298, 'test_r2': -2.514147232649285}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.95
wandb: percentage 0.56614
wandb:   test_mae 0.79811
wandb:   test_mse 1.09071
wandb:    test_r2 -2.51415
wandb: 
wandb: üöÄ View run grateful-sweep-68 at: https://wandb.ai/xiaoqiz/mof2vec/runs/7prxrimr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_200636-7prxrimr/logs
wandb: Agent Starting Run: s744i9ks with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 319
wandb: 	model.gensim.alpha: 0.005116569529375071
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.42860954547027674
wandb: 	model.gensim.vector_size: 496
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.008359061743700925
wandb: 	model.sklearn.max_depth: 10
wandb: 	model.sklearn.min_child_weight: 0.06079618596287381
wandb: 	model.sklearn.n_estimators: 2565
wandb: 	model.sklearn.num_leaves: 214
wandb: 	model.sklearn.reg_alpha: 0.0031751439520270605
wandb: 	model.sklearn.reg_lambda: 0.14982233895287184
wandb: 	model.sklearn.subsample: 0.42947043174593685
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200756-s744i9ks
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-69
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/s744i9ks
2023-02-07 20:08:05.386 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:08:05.387 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 319 for sweep.
2023-02-07 20:08:05.387 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.005116569529375071 for sweep.
2023-02-07 20:08:05.387 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:08:05.388 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 20:08:05.388 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.42860954547027674 for sweep.
2023-02-07 20:08:05.388 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 496 for sweep.
2023-02-07 20:08:05.388 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 20:08:05.389 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.008359061743700925 for sweep.
2023-02-07 20:08:05.389 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 10 for sweep.
2023-02-07 20:08:05.389 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.06079618596287381 for sweep.
2023-02-07 20:08:05.389 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2565 for sweep.
2023-02-07 20:08:05.390 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 214 for sweep.
2023-02-07 20:08:05.390 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0031751439520270605 for sweep.
2023-02-07 20:08:05.390 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.14982233895287184 for sweep.
2023-02-07 20:08:05.390 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.42947043174593685 for sweep.
2023-02-07 20:08:05.391 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:08:05.397 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200756-s744i9ks/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 319, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 496, 'window': 11, 'min_count': 7, 'dm': 0, 'sample': 0.42860954547027674, 'workers': 4, 'alpha': 0.005116569529375071, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2565, 'max_depth': 10, 'num_leaves': 214, 'reg_alpha': 0.0031751439520270605, 'reg_lambda': 0.14982233895287184, 'subsample': 0.42947043174593685, 'min_child_weight': 0.06079618596287381, 'n_jobs': 4, 'learning_rate': 0.008359061743700925}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 135.37it/s]  1%|          | 31/3257 [00:00<00:20, 154.01it/s]  1%|‚ñè         | 47/3257 [00:00<00:20, 154.39it/s]  2%|‚ñè         | 63/3257 [00:00<00:21, 151.81it/s]  2%|‚ñè         | 80/3257 [00:00<00:20, 156.01it/s]  3%|‚ñé         | 96/3257 [00:00<00:21, 149.23it/s]  3%|‚ñé         | 111/3257 [00:00<00:21, 143.50it/s]  4%|‚ñç         | 127/3257 [00:00<00:21, 147.29it/s]  4%|‚ñç         | 146/3257 [00:00<00:19, 159.43it/s]  5%|‚ñå         | 163/3257 [00:01<00:20, 148.18it/s]  6%|‚ñå         | 180/3257 [00:01<00:20, 152.03it/s]  6%|‚ñå         | 198/3257 [00:01<00:19, 159.53it/s]  7%|‚ñã         | 216/3257 [00:01<00:18, 164.83it/s]  7%|‚ñã         | 236/3257 [00:01<00:17, 173.42it/s]  8%|‚ñä         | 254/3257 [00:01<00:17, 170.47it/s]  8%|‚ñä         | 272/3257 [00:01<00:17, 167.75it/s]  9%|‚ñâ         | 294/3257 [00:01<00:16, 182.28it/s] 10%|‚ñâ         | 313/3257 [00:01<00:17, 169.12it/s] 10%|‚ñà         | 332/3257 [00:02<00:16, 174.46it/s] 11%|‚ñà         | 350/3257 [00:02<00:17, 165.82it/s] 11%|‚ñà‚ñè        | 367/3257 [00:02<00:17, 164.98it/s] 12%|‚ñà‚ñè        | 384/3257 [00:02<00:17, 160.11it/s] 12%|‚ñà‚ñè        | 401/3257 [00:02<00:18, 156.54it/s] 13%|‚ñà‚ñé        | 418/3257 [00:02<00:17, 160.25it/s] 13%|‚ñà‚ñé        | 435/3257 [00:02<00:31, 89.92it/s]  14%|‚ñà‚ñç        | 452/3257 [00:03<00:26, 104.50it/s] 14%|‚ñà‚ñç        | 471/3257 [00:03<00:22, 121.52it/s] 15%|‚ñà‚ñç        | 487/3257 [00:03<00:21, 128.00it/s] 15%|‚ñà‚ñå        | 504/3257 [00:03<00:20, 137.54it/s] 16%|‚ñà‚ñå        | 522/3257 [00:03<00:18, 146.37it/s] 17%|‚ñà‚ñã        | 539/3257 [00:03<00:18, 146.95it/s] 17%|‚ñà‚ñã        | 555/3257 [00:03<00:17, 150.16it/s] 18%|‚ñà‚ñä        | 571/3257 [00:03<00:20, 133.77it/s] 18%|‚ñà‚ñä        | 589/3257 [00:03<00:18, 143.36it/s] 19%|‚ñà‚ñä        | 607/3257 [00:04<00:17, 152.95it/s] 19%|‚ñà‚ñâ        | 623/3257 [00:04<00:17, 151.20it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:04<00:16, 156.81it/s] 20%|‚ñà‚ñà        | 657/3257 [00:04<00:17, 145.29it/s] 21%|‚ñà‚ñà        | 675/3257 [00:04<00:16, 154.59it/s] 21%|‚ñà‚ñà        | 691/3257 [00:04<00:17, 149.32it/s] 22%|‚ñà‚ñà‚ñè       | 707/3257 [00:04<00:16, 152.03it/s] 22%|‚ñà‚ñà‚ñè       | 723/3257 [00:04<00:17, 147.37it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:04<00:17, 142.82it/s] 23%|‚ñà‚ñà‚ñé       | 756/3257 [00:05<00:16, 151.25it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:05<00:16, 151.93it/s] 24%|‚ñà‚ñà‚ñç       | 789/3257 [00:05<00:16, 149.94it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:05<00:16, 149.33it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:05<00:16, 148.42it/s] 26%|‚ñà‚ñà‚ñå       | 839/3257 [00:05<00:16, 150.06it/s] 26%|‚ñà‚ñà‚ñã       | 855/3257 [00:05<00:16, 144.40it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:05<00:16, 147.79it/s] 27%|‚ñà‚ñà‚ñã       | 886/3257 [00:05<00:16, 145.32it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:06<00:15, 154.13it/s] 28%|‚ñà‚ñà‚ñä       | 922/3257 [00:06<00:14, 157.41it/s] 29%|‚ñà‚ñà‚ñâ       | 938/3257 [00:06<00:15, 154.48it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:06<00:14, 159.52it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:06<00:14, 154.89it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:06<00:14, 151.54it/s] 31%|‚ñà‚ñà‚ñà       | 1005/3257 [00:06<00:14, 155.56it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1021/3257 [00:06<00:14, 152.30it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1037/3257 [00:06<00:15, 145.32it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1052/3257 [00:07<00:15, 142.91it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1070/3257 [00:07<00:14, 153.18it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1086/3257 [00:07<00:14, 150.13it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1102/3257 [00:07<00:14, 150.36it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1118/3257 [00:07<00:14, 148.53it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1133/3257 [00:07<00:14, 143.21it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1148/3257 [00:07<00:15, 140.31it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1167/3257 [00:07<00:13, 153.15it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1183/3257 [00:07<00:14, 144.16it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1198/3257 [00:08<00:14, 140.28it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1213/3257 [00:08<00:15, 134.28it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:08<00:13, 150.70it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1249/3257 [00:08<00:13, 147.10it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1268/3257 [00:08<00:12, 157.26it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1284/3257 [00:08<00:14, 139.77it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1299/3257 [00:08<00:13, 141.86it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1316/3257 [00:08<00:13, 148.80it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1332/3257 [00:08<00:12, 151.11it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:09<00:12, 151.16it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1366/3257 [00:09<00:12, 153.24it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1382/3257 [00:09<00:12, 148.67it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1401/3257 [00:09<00:11, 158.38it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1421/3257 [00:09<00:10, 170.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:09<00:11, 160.80it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:09<00:10, 171.90it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1478/3257 [00:09<00:10, 171.47it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:09<00:10, 173.83it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1514/3257 [00:10<00:09, 174.59it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1532/3257 [00:10<00:10, 158.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1549/3257 [00:10<00:11, 149.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1565/3257 [00:10<00:11, 149.52it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1581/3257 [00:10<00:11, 148.57it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1598/3257 [00:10<00:10, 153.59it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:10<00:10, 159.48it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:10<00:10, 151.76it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:10<00:10, 148.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1665/3257 [00:11<00:10, 146.68it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1680/3257 [00:11<00:10, 146.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1695/3257 [00:11<00:10, 145.33it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1713/3257 [00:11<00:10, 154.33it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:11<00:10, 143.70it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:11<00:10, 140.94it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1759/3257 [00:11<00:17, 87.09it/s]  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1776/3257 [00:12<00:14, 101.80it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1794/3257 [00:12<00:12, 118.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1809/3257 [00:12<00:12, 120.43it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:12<00:11, 129.84it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1843/3257 [00:12<00:10, 139.52it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1859/3257 [00:12<00:09, 141.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1878/3257 [00:12<00:08, 154.19it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:12<00:09, 147.83it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1914/3257 [00:12<00:08, 159.17it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:13<00:08, 150.07it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:13<00:07, 171.30it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:13<00:07, 173.17it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1992/3257 [00:13<00:07, 168.44it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2010/3257 [00:13<00:07, 165.41it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2029/3257 [00:13<00:07, 170.48it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2047/3257 [00:13<00:07, 153.83it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2063/3257 [00:13<00:08, 146.14it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2080/3257 [00:13<00:07, 152.14it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2096/3257 [00:14<00:07, 145.27it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2113/3257 [00:14<00:07, 151.68it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2129/3257 [00:14<00:07, 141.17it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2144/3257 [00:14<00:08, 139.01it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2161/3257 [00:14<00:07, 146.75it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:14<00:07, 153.12it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2194/3257 [00:14<00:06, 154.76it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2210/3257 [00:14<00:07, 146.46it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2228/3257 [00:14<00:06, 153.53it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2244/3257 [00:15<00:06, 148.31it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:15<00:06, 151.24it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:15<00:06, 142.50it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2297/3257 [00:15<00:06, 159.77it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2314/3257 [00:15<00:05, 160.69it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2335/3257 [00:15<00:05, 172.01it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2357/3257 [00:15<00:04, 185.22it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2376/3257 [00:15<00:05, 172.01it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:15<00:04, 180.46it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2416/3257 [00:16<00:05, 167.97it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2434/3257 [00:16<00:05, 158.34it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2451/3257 [00:16<00:05, 153.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2473/3257 [00:16<00:04, 169.29it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2491/3257 [00:16<00:04, 168.22it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2511/3257 [00:16<00:04, 175.53it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2529/3257 [00:16<00:04, 176.43it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2547/3257 [00:16<00:04, 172.15it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2565/3257 [00:17<00:04, 157.30it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2582/3257 [00:17<00:04, 149.39it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2598/3257 [00:17<00:04, 146.90it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2619/3257 [00:17<00:03, 163.10it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2637/3257 [00:17<00:03, 166.83it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:17<00:03, 155.00it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2670/3257 [00:17<00:03, 155.34it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:17<00:03, 159.22it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:17<00:03, 141.16it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:18<00:03, 140.01it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2740/3257 [00:18<00:03, 157.36it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:18<00:03, 159.27it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:18<00:03, 150.27it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:18<00:02, 165.67it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2812/3257 [00:18<00:02, 166.58it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2829/3257 [00:18<00:02, 151.77it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2847/3257 [00:18<00:02, 158.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:18<00:02, 178.44it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2891/3257 [00:19<00:02, 176.89it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2909/3257 [00:19<00:02, 165.60it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:19<00:01, 167.94it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2945/3257 [00:19<00:01, 159.39it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2962/3257 [00:19<00:01, 161.97it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2979/3257 [00:19<00:01, 157.12it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2996/3257 [00:19<00:01, 159.54it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3015/3257 [00:19<00:01, 166.31it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3032/3257 [00:19<00:01, 165.14it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:20<00:01, 166.19it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3071/3257 [00:20<00:01, 179.16it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3089/3257 [00:20<00:00, 172.55it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3109/3257 [00:20<00:00, 179.77it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3128/3257 [00:20<00:00, 178.47it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3146/3257 [00:20<00:00, 164.66it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3163/3257 [00:20<00:00, 165.23it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3180/3257 [00:20<00:00, 154.36it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3199/3257 [00:20<00:00, 163.43it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3216/3257 [00:21<00:00, 155.93it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3237/3257 [00:21<00:00, 168.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3255/3257 [00:21<00:00, 167.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 153.14it/s]
2023-02-07 20:08:27.598 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:08:27,599][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d496,n5,mc7,s0.42861,t4>', 'datetime': '2023-02-07T20:08:27.599354', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:08:27,599][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:08:27,599][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:08:28,179][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:08:28,180][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:08:28,238][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 18716 unique words (43.83% of original 42701, drops 23985)', 'datetime': '2023-02-07T20:08:28.238405', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:08:28,238][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 5754306 word corpus (98.82% of original 5822992, drops 68686)', 'datetime': '2023-02-07T20:08:28.238845', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:08:28,303][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:08:28,305][gensim.models.word2vec][INFO] - sample=0.42861 downsamples 0 most-common words
[2023-02-07 20:08:28,305][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5754306 word corpus (100.0%% of prior 5754306)', 'datetime': '2023-02-07T20:08:28.305679', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:08:28,420][gensim.models.word2vec][INFO] - estimated required memory for 18716 words and 496 dimensions: 90736376 bytes
[2023-02-07 20:08:28,420][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:08:28,470][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18716 vocabulary and 496 features, using sg=1 hs=0 sample=0.42860954547027674 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T20:08:28.470484', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:08:29,474][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 22.90% examples, 1303802 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:08:30,476][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 45.90% examples, 1336791 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:31,482][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 69.39% examples, 1351429 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:32,491][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 95.18% examples, 1360092 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:32,672][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5728381 effective words) took 4.2s, 1364681 effective words/s
[2023-02-07 20:08:33,677][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 26.01% examples, 1491653 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:08:34,677][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 51.06% examples, 1490665 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:35,684][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 78.05% examples, 1499243 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:36,470][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5728381 effective words) took 3.8s, 1508593 effective words/s
[2023-02-07 20:08:37,475][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 26.59% examples, 1527434 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:38,483][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 52.78% examples, 1535137 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:39,495][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 79.95% examples, 1531952 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:08:40,216][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5728381 effective words) took 3.7s, 1530544 effective words/s
[2023-02-07 20:08:41,220][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 26.01% examples, 1495324 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:42,225][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 52.04% examples, 1521016 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:43,230][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 79.40% examples, 1528209 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:43,953][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5728381 effective words) took 3.7s, 1533996 effective words/s
[2023-02-07 20:08:44,955][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 27.42% examples, 1579407 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:45,961][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 59.69% examples, 1735261 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:46,966][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 95.18% examples, 1813608 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:47,113][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5728381 effective words) took 3.2s, 1813628 effective words/s
[2023-02-07 20:08:48,116][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 33.25% examples, 1927142 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:49,116][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 66.99% examples, 1958159 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:50,120][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 99.72% examples, 1899293 words/s, in_qsize 2, out_qsize 1
[2023-02-07 20:08:50,126][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5728381 effective words) took 3.0s, 1901536 effective words/s
[2023-02-07 20:08:51,130][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 29.81% examples, 1707850 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:52,141][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 58.21% examples, 1691558 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:53,142][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 89.50% examples, 1711286 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:53,496][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5728381 effective words) took 3.4s, 1700664 effective words/s
[2023-02-07 20:08:54,514][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 30.92% examples, 1757661 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:08:55,517][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 63.37% examples, 1830157 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:08:56,519][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 97.67% examples, 1855718 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:56,575][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5728381 effective words) took 3.1s, 1861624 effective words/s
[2023-02-07 20:08:57,578][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 33.90% examples, 1960273 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:58,578][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 65.64% examples, 1915922 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:59,580][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 96.07% examples, 1832782 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:59,707][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5728381 effective words) took 3.1s, 1829366 effective words/s
[2023-02-07 20:09:00,716][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 29.26% examples, 1668214 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:01,718][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 56.83% examples, 1659101 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:02,725][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 86.58% examples, 1657554 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:03,162][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5728381 effective words) took 3.5s, 1658734 effective words/s
[2023-02-07 20:09:04,169][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 28.34% examples, 1619504 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:09:05,172][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 56.03% examples, 1635970 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:06,178][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 85.60% examples, 1639817 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:06,645][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5728381 effective words) took 3.5s, 1645725 effective words/s
[2023-02-07 20:09:07,660][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 29.57% examples, 1671816 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:08,661][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 57.88% examples, 1682948 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:09,663][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 87.07% examples, 1669473 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:09:10,077][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5728381 effective words) took 3.4s, 1669573 effective words/s
[2023-02-07 20:09:11,080][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 28.34% examples, 1625632 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:12,081][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 55.63% examples, 1631045 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:09:13,082][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 84.89% examples, 1633548 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:09:13,567][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5728381 effective words) took 3.5s, 1641921 effective words/s
[2023-02-07 20:09:14,571][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 22.78% examples, 1294540 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:15,580][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 44.86% examples, 1305878 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:16,583][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 67.45% examples, 1307933 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:17,584][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 91.13% examples, 1309041 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:09:17,941][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5728381 effective words) took 4.4s, 1310568 effective words/s
[2023-02-07 20:09:18,951][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 29.23% examples, 1665102 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:19,961][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 57.48% examples, 1667332 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:09:20,969][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 87.07% examples, 1664546 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:09:21,387][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5728381 effective words) took 3.4s, 1663184 effective words/s
[2023-02-07 20:09:21,388][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85925715 effective words) took 52.9s, 1623838 effective words/s', 'datetime': '2023-02-07T20:09:21.387977', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:09:21.388 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:09:26,972][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200756-s744i9ks/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:09:26.972066', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:09:26,973][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:09:27,097][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200756-s744i9ks/files/../tmp/embedding_model.pt
2023-02-07 20:09:27.098 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:09:29.823 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:09:30.748 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:09:34.174 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9167501880548451, 'test_mae': 0.7321247166376904, 'test_r2': -1.685378835900428}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.77
wandb: percentage 0.5617
wandb:   test_mae 0.73212
wandb:   test_mse 0.91675
wandb:    test_r2 -1.68538
wandb: 
wandb: üöÄ View run fancy-sweep-69 at: https://wandb.ai/xiaoqiz/mof2vec/runs/s744i9ks
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_200756-s744i9ks/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: c4lnqtwz with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 798
wandb: 	model.gensim.alpha: 0.001198693070202292
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.5873642904622025
wandb: 	model.gensim.vector_size: 473
wandb: 	model.gensim.window: 7
wandb: 	model.sklearn.learning_rate: 0.004068517784004413
wandb: 	model.sklearn.max_depth: 13
wandb: 	model.sklearn.min_child_weight: 0.05901748811084264
wandb: 	model.sklearn.n_estimators: 31
wandb: 	model.sklearn.num_leaves: 158
wandb: 	model.sklearn.reg_alpha: 0.003819084067164968
wandb: 	model.sklearn.reg_lambda: 0.0347583829655274
wandb: 	model.sklearn.subsample: 0.4023037837319959
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200953-c4lnqtwz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-70
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/c4lnqtwz
2023-02-07 20:10:02.049 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:10:02.049 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 798 for sweep.
2023-02-07 20:10:02.050 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.001198693070202292 for sweep.
2023-02-07 20:10:02.050 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:10:02.050 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 20:10:02.051 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5873642904622025 for sweep.
2023-02-07 20:10:02.051 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 473 for sweep.
2023-02-07 20:10:02.051 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 7 for sweep.
2023-02-07 20:10:02.051 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.004068517784004413 for sweep.
2023-02-07 20:10:02.052 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 13 for sweep.
2023-02-07 20:10:02.052 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05901748811084264 for sweep.
2023-02-07 20:10:02.052 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 31 for sweep.
2023-02-07 20:10:02.052 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 158 for sweep.
2023-02-07 20:10:02.053 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.003819084067164968 for sweep.
2023-02-07 20:10:02.053 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0347583829655274 for sweep.
2023-02-07 20:10:02.053 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.4023037837319959 for sweep.
2023-02-07 20:10:02.053 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:10:02.062 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200953-c4lnqtwz/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 798, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 473, 'window': 7, 'min_count': 9, 'dm': 0, 'sample': 0.5873642904622025, 'workers': 4, 'alpha': 0.001198693070202292, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 31, 'max_depth': 13, 'num_leaves': 158, 'reg_alpha': 0.003819084067164968, 'reg_lambda': 0.0347583829655274, 'subsample': 0.4023037837319959, 'min_child_weight': 0.05901748811084264, 'n_jobs': 4, 'learning_rate': 0.004068517784004413}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 12/3257 [00:00<00:27, 118.13it/s]  1%|          | 28/3257 [00:00<00:23, 140.34it/s]  1%|‚ñè         | 43/3257 [00:00<00:23, 139.05it/s]  2%|‚ñè         | 57/3257 [00:00<00:23, 138.51it/s]  2%|‚ñè         | 73/3257 [00:00<00:21, 145.64it/s]  3%|‚ñé         | 90/3257 [00:00<00:21, 150.32it/s]  3%|‚ñé         | 106/3257 [00:00<00:22, 142.24it/s]  4%|‚ñé         | 122/3257 [00:00<00:21, 146.36it/s]  4%|‚ñç         | 140/3257 [00:00<00:19, 156.09it/s]  5%|‚ñç         | 157/3257 [00:01<00:19, 158.47it/s]  5%|‚ñå         | 173/3257 [00:01<00:20, 147.49it/s]  6%|‚ñå         | 192/3257 [00:01<00:19, 156.61it/s]  6%|‚ñã         | 208/3257 [00:01<00:19, 155.96it/s]  7%|‚ñã         | 230/3257 [00:01<00:18, 167.69it/s]  8%|‚ñä         | 247/3257 [00:01<00:17, 168.21it/s]  8%|‚ñä         | 264/3257 [00:01<00:18, 159.23it/s]  9%|‚ñâ         | 285/3257 [00:01<00:17, 170.14it/s]  9%|‚ñâ         | 303/3257 [00:01<00:17, 165.48it/s] 10%|‚ñâ         | 320/3257 [00:02<00:17, 165.63it/s] 10%|‚ñà         | 337/3257 [00:02<00:18, 160.18it/s] 11%|‚ñà         | 355/3257 [00:02<00:17, 164.37it/s] 11%|‚ñà‚ñè        | 372/3257 [00:02<00:17, 162.91it/s] 12%|‚ñà‚ñè        | 389/3257 [00:02<00:19, 145.14it/s] 12%|‚ñà‚ñè        | 407/3257 [00:02<00:18, 152.18it/s] 13%|‚ñà‚ñé        | 423/3257 [00:02<00:18, 151.06it/s] 13%|‚ñà‚ñé        | 439/3257 [00:02<00:21, 129.44it/s] 14%|‚ñà‚ñç        | 456/3257 [00:03<00:20, 138.47it/s] 15%|‚ñà‚ñç        | 473/3257 [00:03<00:19, 145.96it/s] 15%|‚ñà‚ñå        | 489/3257 [00:03<00:19, 141.16it/s] 16%|‚ñà‚ñå        | 505/3257 [00:03<00:18, 145.38it/s] 16%|‚ñà‚ñå        | 522/3257 [00:03<00:18, 147.70it/s] 16%|‚ñà‚ñã        | 537/3257 [00:03<00:18, 145.98it/s] 17%|‚ñà‚ñã        | 553/3257 [00:03<00:18, 148.10it/s] 17%|‚ñà‚ñã        | 568/3257 [00:03<00:19, 140.18it/s] 18%|‚ñà‚ñä        | 583/3257 [00:03<00:19, 134.55it/s] 18%|‚ñà‚ñä        | 599/3257 [00:04<00:18, 140.22it/s] 19%|‚ñà‚ñâ        | 618/3257 [00:04<00:17, 151.70it/s] 19%|‚ñà‚ñâ        | 634/3257 [00:04<00:17, 149.14it/s] 20%|‚ñà‚ñâ        | 650/3257 [00:04<00:18, 139.85it/s] 20%|‚ñà‚ñà        | 665/3257 [00:04<00:19, 131.45it/s] 21%|‚ñà‚ñà        | 682/3257 [00:04<00:18, 141.05it/s] 21%|‚ñà‚ñà‚ñè       | 697/3257 [00:04<00:19, 131.95it/s] 22%|‚ñà‚ñà‚ñè       | 714/3257 [00:04<00:17, 141.77it/s] 22%|‚ñà‚ñà‚ñè       | 729/3257 [00:04<00:19, 129.21it/s] 23%|‚ñà‚ñà‚ñé       | 743/3257 [00:05<00:19, 129.29it/s] 23%|‚ñà‚ñà‚ñé       | 759/3257 [00:05<00:18, 137.00it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:05<00:18, 135.89it/s] 24%|‚ñà‚ñà‚ñç       | 787/3257 [00:05<00:18, 134.65it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:17, 137.96it/s] 25%|‚ñà‚ñà‚ñå       | 818/3257 [00:05<00:17, 137.05it/s] 26%|‚ñà‚ñà‚ñå       | 832/3257 [00:05<00:18, 131.63it/s] 26%|‚ñà‚ñà‚ñå       | 846/3257 [00:05<00:19, 125.70it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:05<00:17, 134.17it/s] 27%|‚ñà‚ñà‚ñã       | 878/3257 [00:06<00:17, 132.73it/s] 27%|‚ñà‚ñà‚ñã       | 893/3257 [00:06<00:17, 137.39it/s] 28%|‚ñà‚ñà‚ñä       | 910/3257 [00:06<00:16, 146.43it/s] 28%|‚ñà‚ñà‚ñä       | 926/3257 [00:06<00:15, 149.99it/s] 29%|‚ñà‚ñà‚ñâ       | 942/3257 [00:06<00:16, 143.21it/s] 29%|‚ñà‚ñà‚ñâ       | 958/3257 [00:06<00:15, 146.18it/s] 30%|‚ñà‚ñà‚ñâ       | 973/3257 [00:06<00:16, 141.28it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:06<00:16, 137.12it/s] 31%|‚ñà‚ñà‚ñà       | 1002/3257 [00:06<00:16, 136.96it/s] 31%|‚ñà‚ñà‚ñà       | 1016/3257 [00:07<00:16, 136.12it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1030/3257 [00:07<00:16, 132.44it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1044/3257 [00:07<00:17, 129.94it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1058/3257 [00:07<00:16, 132.67it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1076/3257 [00:07<00:14, 145.86it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:07<00:16, 133.42it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1108/3257 [00:07<00:15, 141.73it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:07<00:15, 139.86it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1138/3257 [00:07<00:15, 140.86it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1153/3257 [00:08<00:15, 135.92it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:08<00:14, 141.18it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:08<00:15, 130.93it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1199/3257 [00:08<00:16, 127.64it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1212/3257 [00:08<00:16, 124.32it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:08<00:14, 139.63it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:08<00:14, 138.29it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:08<00:14, 141.11it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:08<00:14, 133.38it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:09<00:15, 127.65it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1305/3257 [00:09<00:15, 129.95it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1319/3257 [00:09<00:24, 78.93it/s]  41%|‚ñà‚ñà‚ñà‚ñà      | 1335/3257 [00:09<00:20, 94.09it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:09<00:18, 101.33it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1365/3257 [00:09<00:17, 111.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1380/3257 [00:09<00:15, 119.75it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1394/3257 [00:10<00:15, 121.98it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1410/3257 [00:10<00:14, 131.78it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1427/3257 [00:10<00:13, 140.36it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1442/3257 [00:10<00:12, 140.85it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1461/3257 [00:10<00:11, 153.19it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:10<00:11, 152.53it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1494/3257 [00:10<00:11, 154.85it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1512/3257 [00:10<00:11, 158.21it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1528/3257 [00:10<00:12, 143.42it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1543/3257 [00:11<00:12, 141.32it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1558/3257 [00:11<00:12, 134.32it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:11<00:12, 138.40it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1589/3257 [00:11<00:12, 137.72it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1605/3257 [00:11<00:11, 139.33it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:11<00:11, 142.03it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:11<00:11, 135.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1649/3257 [00:11<00:12, 132.59it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1663/3257 [00:11<00:11, 134.29it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:12<00:11, 133.13it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:12<00:11, 132.10it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:12<00:11, 138.48it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:12<00:10, 141.67it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1738/3257 [00:12<00:12, 125.70it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1754/3257 [00:12<00:11, 133.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:12<00:10, 141.51it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1788/3257 [00:12<00:09, 147.10it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:12<00:10, 144.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1818/3257 [00:13<00:10, 140.35it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1833/3257 [00:13<00:10, 134.86it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:13<00:10, 139.68it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1868/3257 [00:13<00:09, 151.56it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1884/3257 [00:13<00:09, 142.96it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:13<00:09, 139.86it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:13<00:09, 141.32it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:13<00:09, 142.59it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1952/3257 [00:13<00:08, 160.38it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1969/3257 [00:14<00:07, 162.13it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1986/3257 [00:14<00:08, 150.23it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2003/3257 [00:14<00:08, 154.63it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2019/3257 [00:14<00:08, 154.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:14<00:08, 151.60it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2051/3257 [00:14<00:08, 138.18it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2066/3257 [00:14<00:08, 134.99it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2082/3257 [00:14<00:08, 140.87it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2097/3257 [00:14<00:08, 134.25it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2114/3257 [00:15<00:07, 143.52it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2129/3257 [00:15<00:08, 128.93it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:15<00:08, 126.94it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2160/3257 [00:15<00:08, 135.34it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2177/3257 [00:15<00:07, 143.05it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2192/3257 [00:15<00:07, 140.53it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2207/3257 [00:15<00:07, 140.12it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2222/3257 [00:15<00:07, 142.05it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:16<00:07, 138.96it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2251/3257 [00:16<00:07, 135.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2265/3257 [00:16<00:07, 135.99it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2279/3257 [00:16<00:07, 129.85it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2296/3257 [00:16<00:06, 138.97it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2310/3257 [00:16<00:06, 135.84it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2330/3257 [00:16<00:06, 151.78it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2348/3257 [00:16<00:05, 159.12it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2366/3257 [00:16<00:05, 162.30it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2383/3257 [00:16<00:05, 159.65it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2401/3257 [00:17<00:05, 164.32it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2418/3257 [00:17<00:05, 149.92it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2434/3257 [00:17<00:05, 140.34it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2449/3257 [00:17<00:05, 138.26it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2469/3257 [00:17<00:05, 153.21it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2485/3257 [00:17<00:05, 147.46it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2504/3257 [00:17<00:04, 158.39it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2521/3257 [00:17<00:04, 155.64it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2539/3257 [00:17<00:04, 160.95it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2556/3257 [00:18<00:04, 146.33it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2571/3257 [00:18<00:04, 138.78it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:18<00:04, 137.81it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2602/3257 [00:18<00:04, 143.12it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2623/3257 [00:18<00:03, 160.50it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2640/3257 [00:18<00:03, 158.45it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2657/3257 [00:18<00:04, 146.99it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:18<00:03, 149.45it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:19<00:03, 152.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2706/3257 [00:19<00:04, 136.73it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2721/3257 [00:19<00:04, 131.33it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:19<00:03, 147.22it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:19<00:03, 150.31it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2773/3257 [00:19<00:03, 142.85it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2791/3257 [00:19<00:03, 151.76it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:20<00:06, 72.97it/s]  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2821/3257 [00:20<00:05, 83.46it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2834/3257 [00:20<00:04, 89.95it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2851/3257 [00:20<00:03, 104.82it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:20<00:03, 125.47it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2888/3257 [00:20<00:02, 131.32it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:20<00:02, 127.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2919/3257 [00:21<00:02, 134.99it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2934/3257 [00:21<00:02, 132.85it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2949/3257 [00:21<00:02, 127.25it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:21<00:02, 136.06it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2981/3257 [00:21<00:02, 127.94it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2996/3257 [00:21<00:01, 133.41it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:21<00:01, 139.53it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3027/3257 [00:21<00:01, 136.74it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3044/3257 [00:21<00:01, 145.84it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:22<00:01, 154.42it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3079/3257 [00:22<00:01, 155.23it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3095/3257 [00:22<00:01, 148.45it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3112/3257 [00:22<00:00, 154.31it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3128/3257 [00:22<00:00, 155.02it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3144/3257 [00:22<00:00, 144.40it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3159/3257 [00:22<00:00, 144.65it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3174/3257 [00:22<00:00, 144.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3189/3257 [00:22<00:00, 138.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3204/3257 [00:23<00:00, 141.13it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3219/3257 [00:23<00:00, 134.80it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3237/3257 [00:23<00:00, 146.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:23<00:00, 148.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:23<00:00, 139.47it/s]
2023-02-07 20:10:26.365 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:10:26,366][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d473,n5,mc9,s0.587364,t4>', 'datetime': '2023-02-07T20:10:26.366749', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:10:26,367][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:10:26,367][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:10:27,038][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:10:27,038][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:10:27,097][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 18315 unique words (33.88% of original 54054, drops 35739)', 'datetime': '2023-02-07T20:10:27.097511', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:10:27,098][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 6422560 word corpus (98.04% of original 6550866, drops 128306)', 'datetime': '2023-02-07T20:10:27.098027', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:10:27,163][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:10:27,165][gensim.models.word2vec][INFO] - sample=0.587364 downsamples 0 most-common words
[2023-02-07 20:10:27,165][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6422560 word corpus (100.0%% of prior 6422560)', 'datetime': '2023-02-07T20:10:27.165627', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:10:27,277][gensim.models.word2vec][INFO] - estimated required memory for 18315 words and 473 dimensions: 85275104 bytes
[2023-02-07 20:10:27,277][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:10:27,322][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18315 vocabulary and 473 features, using sg=1 hs=0 sample=0.5873642904622025 negative=5 window=7 shrink_windows=True', 'datetime': '2023-02-07T20:10:27.322824', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:10:28,327][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 20.97% examples, 1318545 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:29,332][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 41.30% examples, 1344032 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:30,334][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 61.50% examples, 1321784 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:31,337][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 78.02% examples, 1251074 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:32,345][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 95.18% examples, 1210320 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:32,616][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6368654 effective words) took 5.3s, 1203792 effective words/s
[2023-02-07 20:10:33,623][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 21.55% examples, 1348032 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:34,626][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 41.82% examples, 1360664 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:35,627][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 63.68% examples, 1370828 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:10:36,632][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 85.78% examples, 1372342 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:37,267][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6368654 effective words) took 4.6s, 1369868 effective words/s
[2023-02-07 20:10:38,271][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 21.55% examples, 1354087 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:10:39,271][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 41.42% examples, 1351848 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:40,279][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 62.91% examples, 1351288 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:41,284][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 84.59% examples, 1353949 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:41,973][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6368654 effective words) took 4.7s, 1354418 effective words/s
[2023-02-07 20:10:42,982][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 21.55% examples, 1342903 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:10:43,995][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 41.82% examples, 1352688 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:45,005][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 63.40% examples, 1355190 words/s, in_qsize 6, out_qsize 1
[2023-02-07 20:10:46,009][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 85.39% examples, 1360850 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:46,657][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6368654 effective words) took 4.7s, 1360113 effective words/s
[2023-02-07 20:10:47,666][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 21.37% examples, 1334162 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:48,678][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 41.82% examples, 1353232 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:49,679][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 63.68% examples, 1365581 words/s, in_qsize 6, out_qsize 0
[2023-02-07 20:10:50,684][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 85.66% examples, 1366179 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:10:51,312][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6368654 effective words) took 4.7s, 1368397 effective words/s
[2023-02-07 20:10:52,319][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 22.04% examples, 1373786 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:53,322][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 41.88% examples, 1364217 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:54,333][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 63.40% examples, 1359970 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:55,334][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 85.08% examples, 1361331 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:55,983][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6368654 effective words) took 4.7s, 1364028 effective words/s
[2023-02-07 20:10:56,986][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 21.55% examples, 1352947 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:57,991][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 41.82% examples, 1362028 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:58,996][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 63.40% examples, 1363928 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:00,001][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 85.20% examples, 1365140 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:00,654][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6368654 effective words) took 4.7s, 1363987 effective words/s
[2023-02-07 20:11:01,661][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 21.77% examples, 1356878 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:02,667][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 39.42% examples, 1279717 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:03,681][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 55.97% examples, 1206255 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:04,685][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 72.77% examples, 1167640 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:05,690][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 89.90% examples, 1144708 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:06,254][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6368654 effective words) took 5.6s, 1137554 effective words/s
[2023-02-07 20:11:07,256][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 21.95% examples, 1371326 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:08,264][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 42.22% examples, 1376856 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:09,264][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 63.99% examples, 1378551 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:10,265][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 86.18% examples, 1380419 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:10,864][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6368654 effective words) took 4.6s, 1382029 effective words/s
[2023-02-07 20:11:11,866][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 21.95% examples, 1372105 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:12,866][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 42.09% examples, 1377984 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:13,867][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 63.49% examples, 1371774 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:14,880][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 85.78% examples, 1371867 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:15,501][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6368654 effective words) took 4.6s, 1374000 effective words/s
[2023-02-07 20:11:16,505][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 21.55% examples, 1350412 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:17,507][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 41.82% examples, 1362794 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:18,520][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 63.89% examples, 1371012 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:19,523][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 86.34% examples, 1378080 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:20,124][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6368654 effective words) took 4.6s, 1377947 effective words/s
[2023-02-07 20:11:21,134][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 15.41% examples, 949968 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:22,145][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 30.52% examples, 968927 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:23,152][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 45.04% examples, 967538 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:24,159][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 60.18% examples, 965375 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:25,169][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 75.07% examples, 961954 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:26,174][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 92.29% examples, 978126 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:26,589][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6368654 effective words) took 6.5s, 985574 effective words/s
[2023-02-07 20:11:27,598][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 22.20% examples, 1387885 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:28,604][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 42.80% examples, 1395255 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:29,612][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 64.66% examples, 1388216 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:30,616][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 86.80% examples, 1384608 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:31,190][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6368654 effective words) took 4.6s, 1385178 effective words/s
[2023-02-07 20:11:32,195][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 22.11% examples, 1385052 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:33,197][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 42.80% examples, 1399596 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:34,197][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 64.91% examples, 1400006 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:35,205][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 88.42% examples, 1410095 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:35,662][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6368654 effective words) took 4.5s, 1424875 effective words/s
[2023-02-07 20:11:36,667][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 26.68% examples, 1700397 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:37,672][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 50.72% examples, 1637451 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:38,674][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 73.47% examples, 1574449 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:39,683][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 96.19% examples, 1525200 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:39,852][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6368654 effective words) took 4.2s, 1520287 effective words/s
[2023-02-07 20:11:39,852][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (95529810 effective words) took 72.5s, 1317116 effective words/s', 'datetime': '2023-02-07T20:11:39.852832', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:11:39.853 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:11:46,941][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200953-c4lnqtwz/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:11:46.941151', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:11:46,942][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:11:47,058][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200953-c4lnqtwz/files/../tmp/embedding_model.pt
2023-02-07 20:11:47.058 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:11:49.742 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:11:50.638 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:11:56.054 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.050731868797578, 'test_mae': 0.7809539807080491, 'test_r2': -2.1806229591167234}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.035 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.42
wandb: percentage 0.66117
wandb:   test_mae 0.78095
wandb:   test_mse 1.05073
wandb:    test_r2 -2.18062
wandb: 
wandb: üöÄ View run neat-sweep-70 at: https://wandb.ai/xiaoqiz/mof2vec/runs/c4lnqtwz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_200953-c4lnqtwz/logs
wandb: Agent Starting Run: 8k1e4j0o with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 839
wandb: 	model.gensim.alpha: 0.003122304134119929
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.7753963807498907
wandb: 	model.gensim.vector_size: 265
wandb: 	model.gensim.window: 18
wandb: 	model.sklearn.learning_rate: 0.002959583622387276
wandb: 	model.sklearn.max_depth: 27
wandb: 	model.sklearn.min_child_weight: 0.02678254680140527
wandb: 	model.sklearn.n_estimators: 1219
wandb: 	model.sklearn.num_leaves: 355
wandb: 	model.sklearn.reg_alpha: 0.015009676461208089
wandb: 	model.sklearn.reg_lambda: 0.11811877272354128
wandb: 	model.sklearn.subsample: 0.5395217662164138
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201205-8k1e4j0o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-71
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/8k1e4j0o
2023-02-07 20:12:13.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:12:13.550 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 839 for sweep.
2023-02-07 20:12:13.550 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.003122304134119929 for sweep.
2023-02-07 20:12:13.551 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:12:13.551 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 20:12:13.551 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7753963807498907 for sweep.
2023-02-07 20:12:13.551 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 265 for sweep.
2023-02-07 20:12:13.552 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 18 for sweep.
2023-02-07 20:12:13.552 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.002959583622387276 for sweep.
2023-02-07 20:12:13.552 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 27 for sweep.
2023-02-07 20:12:13.552 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.02678254680140527 for sweep.
2023-02-07 20:12:13.553 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1219 for sweep.
2023-02-07 20:12:13.553 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 355 for sweep.
2023-02-07 20:12:13.553 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.015009676461208089 for sweep.
2023-02-07 20:12:13.553 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.11811877272354128 for sweep.
2023-02-07 20:12:13.553 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5395217662164138 for sweep.
2023-02-07 20:12:13.554 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:12:13.559 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201205-8k1e4j0o/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 839, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 265, 'window': 18, 'min_count': 10, 'dm': 0, 'sample': 0.7753963807498907, 'workers': 4, 'alpha': 0.003122304134119929, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1219, 'max_depth': 27, 'num_leaves': 355, 'reg_alpha': 0.015009676461208089, 'reg_lambda': 0.11811877272354128, 'subsample': 0.5395217662164138, 'min_child_weight': 0.02678254680140527, 'n_jobs': 4, 'learning_rate': 0.002959583622387276}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:24, 133.95it/s]  1%|          | 32/3257 [00:00<00:20, 156.35it/s]  1%|‚ñè         | 48/3257 [00:00<00:20, 156.69it/s]  2%|‚ñè         | 64/3257 [00:00<00:20, 155.73it/s]  2%|‚ñè         | 80/3257 [00:00<00:20, 156.79it/s]  3%|‚ñé         | 96/3257 [00:00<00:20, 151.14it/s]  3%|‚ñé         | 112/3257 [00:00<00:21, 145.51it/s]  4%|‚ñç         | 128/3257 [00:00<00:20, 149.28it/s]  5%|‚ñç         | 147/3257 [00:00<00:19, 158.90it/s]  5%|‚ñå         | 163/3257 [00:01<00:20, 148.03it/s]  5%|‚ñå         | 179/3257 [00:01<00:20, 151.06it/s]  6%|‚ñå         | 197/3257 [00:01<00:19, 155.35it/s]  7%|‚ñã         | 216/3257 [00:01<00:18, 160.73it/s]  7%|‚ñã         | 236/3257 [00:01<00:18, 167.57it/s]  8%|‚ñä         | 253/3257 [00:01<00:18, 162.92it/s]  8%|‚ñä         | 270/3257 [00:01<00:18, 158.24it/s]  9%|‚ñâ         | 291/3257 [00:01<00:17, 170.75it/s]  9%|‚ñâ         | 309/3257 [00:01<00:17, 164.18it/s] 10%|‚ñà         | 328/3257 [00:02<00:17, 167.12it/s] 11%|‚ñà         | 345/3257 [00:02<00:18, 159.38it/s] 11%|‚ñà         | 362/3257 [00:02<00:18, 160.04it/s] 12%|‚ñà‚ñè        | 379/3257 [00:02<00:19, 148.98it/s] 12%|‚ñà‚ñè        | 395/3257 [00:02<00:19, 148.60it/s] 13%|‚ñà‚ñé        | 413/3257 [00:02<00:18, 156.73it/s] 13%|‚ñà‚ñé        | 429/3257 [00:02<00:20, 135.61it/s] 14%|‚ñà‚ñé        | 444/3257 [00:02<00:20, 138.80it/s] 14%|‚ñà‚ñç        | 460/3257 [00:02<00:19, 144.40it/s] 15%|‚ñà‚ñç        | 476/3257 [00:03<00:18, 147.28it/s] 15%|‚ñà‚ñå        | 493/3257 [00:03<00:18, 150.72it/s] 16%|‚ñà‚ñå        | 512/3257 [00:03<00:17, 159.57it/s] 16%|‚ñà‚ñå        | 529/3257 [00:03<00:17, 155.03it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:17, 152.64it/s] 17%|‚ñà‚ñã        | 562/3257 [00:03<00:18, 145.43it/s] 18%|‚ñà‚ñä        | 577/3257 [00:03<00:19, 137.12it/s] 18%|‚ñà‚ñä        | 595/3257 [00:03<00:18, 147.36it/s] 19%|‚ñà‚ñâ        | 611/3257 [00:03<00:17, 150.54it/s] 19%|‚ñà‚ñâ        | 627/3257 [00:04<00:17, 146.75it/s] 20%|‚ñà‚ñâ        | 643/3257 [00:04<00:17, 149.40it/s] 20%|‚ñà‚ñà        | 659/3257 [00:04<00:18, 136.95it/s] 21%|‚ñà‚ñà        | 676/3257 [00:04<00:17, 145.56it/s] 21%|‚ñà‚ñà        | 691/3257 [00:04<00:18, 137.90it/s] 22%|‚ñà‚ñà‚ñè       | 706/3257 [00:04<00:18, 140.35it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:04<00:17, 142.89it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:04<00:18, 139.36it/s] 23%|‚ñà‚ñà‚ñé       | 753/3257 [00:04<00:17, 146.07it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:05<00:16, 150.88it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:05<00:17, 143.55it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:16, 149.44it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:16, 147.64it/s] 26%|‚ñà‚ñà‚ñå       | 835/3257 [00:05<00:16, 142.60it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:05<00:27, 86.17it/s]  27%|‚ñà‚ñà‚ñã       | 866/3257 [00:06<00:23, 99.68it/s] 27%|‚ñà‚ñà‚ñã       | 880/3257 [00:06<00:22, 107.27it/s] 28%|‚ñà‚ñà‚ñä       | 896/3257 [00:06<00:19, 119.33it/s] 28%|‚ñà‚ñà‚ñä       | 913/3257 [00:06<00:17, 131.91it/s] 29%|‚ñà‚ñà‚ñä       | 929/3257 [00:06<00:16, 138.06it/s] 29%|‚ñà‚ñà‚ñâ       | 944/3257 [00:06<00:16, 140.70it/s] 30%|‚ñà‚ñà‚ñâ       | 961/3257 [00:06<00:15, 148.33it/s] 30%|‚ñà‚ñà‚ñà       | 978/3257 [00:06<00:15, 151.89it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:06<00:15, 145.64it/s] 31%|‚ñà‚ñà‚ñà       | 1009/3257 [00:06<00:15, 144.09it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:07<00:15, 145.18it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1042/3257 [00:07<00:15, 139.64it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1058/3257 [00:07<00:15, 143.93it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1076/3257 [00:07<00:14, 152.72it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1092/3257 [00:07<00:15, 141.46it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1108/3257 [00:07<00:14, 145.05it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:07<00:14, 143.65it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1138/3257 [00:07<00:14, 145.34it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1153/3257 [00:07<00:14, 141.10it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:08<00:14, 147.70it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:08<00:15, 136.58it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1199/3257 [00:08<00:15, 133.17it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1213/3257 [00:08<00:15, 128.34it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:08<00:14, 144.26it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:08<00:13, 144.13it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:08<00:13, 145.61it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:08<00:14, 139.89it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:08<00:14, 136.11it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:09<00:13, 141.14it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1324/3257 [00:09<00:13, 146.29it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1341/3257 [00:09<00:12, 152.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1357/3257 [00:09<00:13, 144.90it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1372/3257 [00:09<00:13, 142.06it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1387/3257 [00:09<00:13, 142.64it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1403/3257 [00:09<00:12, 147.46it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:09<00:11, 157.62it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:09<00:11, 155.83it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:10<00:10, 167.06it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:10<00:10, 164.55it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1495/3257 [00:10<00:10, 168.79it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1512/3257 [00:10<00:10, 168.05it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1529/3257 [00:10<00:11, 151.25it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1545/3257 [00:10<00:12, 141.65it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1561/3257 [00:10<00:11, 144.60it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1576/3257 [00:10<00:11, 142.90it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1593/3257 [00:10<00:11, 149.49it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1610/3257 [00:11<00:10, 154.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1626/3257 [00:11<00:10, 155.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1642/3257 [00:11<00:11, 144.88it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:11<00:11, 143.75it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1672/3257 [00:11<00:11, 141.28it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1687/3257 [00:11<00:11, 142.07it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1703/3257 [00:11<00:10, 145.58it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1718/3257 [00:11<00:10, 145.39it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1733/3257 [00:11<00:11, 134.89it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1749/3257 [00:12<00:10, 140.86it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1765/3257 [00:12<00:10, 144.20it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1782/3257 [00:12<00:09, 150.91it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1798/3257 [00:12<00:09, 151.24it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:12<00:10, 143.62it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1829/3257 [00:12<00:10, 141.19it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:12<00:09, 146.95it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1865/3257 [00:12<00:08, 158.43it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1881/3257 [00:12<00:08, 156.92it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:12<00:08, 154.14it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:13<00:08, 157.83it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1933/3257 [00:13<00:08, 160.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1955/3257 [00:13<00:07, 176.97it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1973/3257 [00:13<00:07, 177.24it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1991/3257 [00:13<00:07, 165.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:13<00:07, 162.07it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2026/3257 [00:13<00:07, 166.70it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2043/3257 [00:13<00:07, 156.56it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2059/3257 [00:14<00:08, 144.30it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2076/3257 [00:14<00:07, 149.53it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2092/3257 [00:14<00:07, 150.55it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2108/3257 [00:14<00:12, 91.96it/s]  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:14<00:11, 97.31it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2138/3257 [00:14<00:10, 111.44it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2153/3257 [00:14<00:09, 118.94it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:14<00:08, 127.54it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2184/3257 [00:15<00:08, 129.65it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2202/3257 [00:15<00:07, 140.08it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2217/3257 [00:15<00:07, 139.95it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2234/3257 [00:15<00:06, 147.42it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2250/3257 [00:15<00:07, 142.93it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2265/3257 [00:15<00:06, 143.09it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2280/3257 [00:15<00:06, 139.64it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2298/3257 [00:15<00:06, 150.71it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2314/3257 [00:15<00:06, 152.87it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2334/3257 [00:16<00:05, 164.63it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2355/3257 [00:16<00:05, 175.63it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2373/3257 [00:16<00:05, 166.54it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2394/3257 [00:16<00:04, 177.85it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2412/3257 [00:16<00:05, 165.50it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2429/3257 [00:16<00:05, 161.77it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2446/3257 [00:16<00:05, 155.38it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2463/3257 [00:16<00:05, 158.41it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:16<00:04, 161.91it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2501/3257 [00:17<00:04, 171.88it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2519/3257 [00:17<00:04, 172.15it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2537/3257 [00:17<00:04, 173.91it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2555/3257 [00:17<00:04, 159.96it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:17<00:04, 147.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2588/3257 [00:17<00:04, 144.80it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2607/3257 [00:17<00:04, 156.38it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2628/3257 [00:17<00:03, 169.41it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2646/3257 [00:17<00:03, 158.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2663/3257 [00:18<00:03, 150.11it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2680/3257 [00:18<00:03, 152.69it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2696/3257 [00:18<00:03, 146.59it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2711/3257 [00:18<00:03, 136.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2727/3257 [00:18<00:03, 142.54it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2744/3257 [00:18<00:03, 149.99it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:18<00:03, 149.51it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2777/3257 [00:18<00:03, 144.81it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2797/3257 [00:18<00:02, 159.07it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2814/3257 [00:19<00:02, 154.84it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2830/3257 [00:19<00:02, 144.15it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2846/3257 [00:19<00:02, 147.32it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2866/3257 [00:19<00:02, 159.34it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2885/3257 [00:19<00:02, 165.91it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2902/3257 [00:19<00:02, 145.62it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2919/3257 [00:19<00:02, 150.74it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2935/3257 [00:19<00:02, 148.21it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2951/3257 [00:20<00:02, 138.32it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2967/3257 [00:20<00:02, 142.70it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2982/3257 [00:20<00:02, 136.24it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3000/3257 [00:20<00:01, 147.68it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:20<00:01, 145.60it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3033/3257 [00:20<00:01, 151.26it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:20<00:01, 151.23it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3068/3257 [00:20<00:01, 159.49it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3085/3257 [00:20<00:01, 158.78it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3102/3257 [00:21<00:00, 161.95it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3120/3257 [00:21<00:00, 166.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3137/3257 [00:21<00:00, 158.68it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3153/3257 [00:21<00:00, 153.12it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3169/3257 [00:21<00:00, 153.20it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:21<00:00, 146.76it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:21<00:00, 155.79it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3219/3257 [00:21<00:00, 149.15it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:21<00:00, 160.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3256/3257 [00:22<00:00, 161.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 147.96it/s]
2023-02-07 20:12:36.471 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:12:36,473][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d265,n5,mc10,s0.775396,t4>', 'datetime': '2023-02-07T20:12:36.473170', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:12:36,473][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:12:36,473][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:12:37,050][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:12:37,051][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:12:37,098][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 14497 unique words (33.95% of original 42701, drops 28204)', 'datetime': '2023-02-07T20:12:37.098313', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:12:37,098][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 5720668 word corpus (98.24% of original 5822992, drops 102324)', 'datetime': '2023-02-07T20:12:37.098785', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:12:37,149][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:12:37,150][gensim.models.word2vec][INFO] - sample=0.775396 downsamples 0 most-common words
[2023-02-07 20:12:37,151][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5720668 word corpus (100.0%% of prior 5720668)', 'datetime': '2023-02-07T20:12:37.151152', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:12:37,241][gensim.models.word2vec][INFO] - estimated required memory for 14497 words and 265 dimensions: 42085960 bytes
[2023-02-07 20:12:37,242][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:12:37,264][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14497 vocabulary and 265 features, using sg=1 hs=0 sample=0.7753963807498907 negative=5 window=18 shrink_windows=True', 'datetime': '2023-02-07T20:12:37.264260', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:12:38,279][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 36.14% examples, 2069260 words/s, in_qsize 8, out_qsize 2
[2023-02-07 20:12:39,285][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 79.95% examples, 2281418 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:39,706][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5694995 effective words) took 2.4s, 2335099 effective words/s
[2023-02-07 20:12:40,710][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 46.76% examples, 2707016 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:41,711][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 94.53% examples, 2693603 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:41,814][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5694995 effective words) took 2.1s, 2703960 effective words/s
[2023-02-07 20:12:42,818][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 45.38% examples, 2625664 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:43,820][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 89.01% examples, 2545068 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:44,098][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5694995 effective words) took 2.3s, 2494118 effective words/s
[2023-02-07 20:12:45,101][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 40.56% examples, 2368848 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:46,105][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 82.38% examples, 2357553 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:46,512][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5694995 effective words) took 2.4s, 2361059 effective words/s
[2023-02-07 20:12:47,517][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 36.44% examples, 2110545 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:48,517][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 82.68% examples, 2368212 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:48,872][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5694995 effective words) took 2.4s, 2415211 effective words/s
[2023-02-07 20:12:49,877][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 45.69% examples, 2643840 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:50,885][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 95.18% examples, 2698819 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:50,974][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5694995 effective words) took 2.1s, 2711180 effective words/s
[2023-02-07 20:12:51,977][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 44.43% examples, 2584248 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:52,980][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 84.89% examples, 2432551 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:53,333][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5694995 effective words) took 2.4s, 2414531 effective words/s
[2023-02-07 20:12:54,334][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 38.44% examples, 2240615 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:55,336][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 78.26% examples, 2247654 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:55,861][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5694995 effective words) took 2.5s, 2254204 effective words/s
[2023-02-07 20:12:56,864][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 38.44% examples, 2235159 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:57,868][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 78.05% examples, 2237341 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:58,405][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5694995 effective words) took 2.5s, 2239713 effective words/s
[2023-02-07 20:12:59,406][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 38.29% examples, 2230836 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:13:00,407][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 78.78% examples, 2265376 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:13:00,904][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5694995 effective words) took 2.5s, 2279911 effective words/s
[2023-02-07 20:13:01,905][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 39.36% examples, 2304373 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:13:02,909][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 80.23% examples, 2301509 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:13:03,383][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5694995 effective words) took 2.5s, 2298962 effective words/s
[2023-02-07 20:13:04,388][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 38.99% examples, 2258647 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:13:05,390][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 78.63% examples, 2256061 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:13:05,914][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5694995 effective words) took 2.5s, 2251318 effective words/s
[2023-02-07 20:13:06,919][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 38.99% examples, 2258650 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:13:07,923][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 79.28% examples, 2274668 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:13:08,414][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5694995 effective words) took 2.5s, 2279195 effective words/s
[2023-02-07 20:13:09,426][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 38.99% examples, 2245077 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:13:10,429][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 79.40% examples, 2272948 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:13:10,920][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5694995 effective words) took 2.5s, 2273831 effective words/s
[2023-02-07 20:13:11,922][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 38.99% examples, 2267238 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:13:12,923][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 78.54% examples, 2257104 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:13:13,445][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5694995 effective words) took 2.5s, 2257186 effective words/s
[2023-02-07 20:13:13,445][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85424925 effective words) took 36.2s, 2361041 effective words/s', 'datetime': '2023-02-07T20:13:13.445792', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:13:13.446 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:13:17,046][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201205-8k1e4j0o/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:13:17.045984', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:13:17,046][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:13:17,103][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201205-8k1e4j0o/files/../tmp/embedding_model.pt
2023-02-07 20:13:17.103 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:13:18.928 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:13:19.583 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:13:21.961 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9237443942045414, 'test_mae': 0.7236351894180467, 'test_r2': -1.6250797493607232}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.75
wandb: percentage 0.6605
wandb:   test_mae 0.72364
wandb:   test_mse 0.92374
wandb:    test_r2 -1.62508
wandb: 
wandb: üöÄ View run lemon-sweep-71 at: https://wandb.ai/xiaoqiz/mof2vec/runs/8k1e4j0o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_201205-8k1e4j0o/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: eoxtomyo with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 1005
wandb: 	model.gensim.alpha: 0.00038574517951205615
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.764091124587573
wandb: 	model.gensim.vector_size: 455
wandb: 	model.gensim.window: 13
wandb: 	model.sklearn.learning_rate: 0.03141868302276826
wandb: 	model.sklearn.max_depth: 42
wandb: 	model.sklearn.min_child_weight: 0.031074686270820592
wandb: 	model.sklearn.n_estimators: 2182
wandb: 	model.sklearn.num_leaves: 432
wandb: 	model.sklearn.reg_alpha: 0.030415926227942557
wandb: 	model.sklearn.reg_lambda: 0.053286889301577545
wandb: 	model.sklearn.subsample: 0.31756222814708074
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201341-eoxtomyo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-72
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/eoxtomyo
2023-02-07 20:13:49.922 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:13:49.923 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 1005 for sweep.
2023-02-07 20:13:49.923 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.00038574517951205615 for sweep.
2023-02-07 20:13:49.924 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:13:49.924 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 20:13:49.924 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.764091124587573 for sweep.
2023-02-07 20:13:49.924 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 455 for sweep.
2023-02-07 20:13:49.925 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 13 for sweep.
2023-02-07 20:13:49.925 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.03141868302276826 for sweep.
2023-02-07 20:13:49.926 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 42 for sweep.
2023-02-07 20:13:49.926 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.031074686270820592 for sweep.
2023-02-07 20:13:49.926 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2182 for sweep.
2023-02-07 20:13:49.926 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 432 for sweep.
2023-02-07 20:13:49.927 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.030415926227942557 for sweep.
2023-02-07 20:13:49.927 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.053286889301577545 for sweep.
2023-02-07 20:13:49.927 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.31756222814708074 for sweep.
2023-02-07 20:13:49.927 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:13:49.935 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201341-eoxtomyo/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 1005, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 455, 'window': 13, 'min_count': 5, 'dm': 0, 'sample': 0.764091124587573, 'workers': 4, 'alpha': 0.00038574517951205615, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2182, 'max_depth': 42, 'num_leaves': 432, 'reg_alpha': 0.030415926227942557, 'reg_lambda': 0.053286889301577545, 'subsample': 0.31756222814708074, 'min_child_weight': 0.031074686270820592, 'n_jobs': 4, 'learning_rate': 0.03141868302276826}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:26, 121.86it/s]  1%|          | 29/3257 [00:00<00:23, 138.30it/s]  1%|‚ñè         | 43/3257 [00:00<00:23, 135.50it/s]  2%|‚ñè         | 57/3257 [00:00<00:23, 135.53it/s]  2%|‚ñè         | 72/3257 [00:00<00:22, 140.31it/s]  3%|‚ñé         | 90/3257 [00:00<00:21, 146.33it/s]  3%|‚ñé         | 105/3257 [00:00<00:21, 143.66it/s]  4%|‚ñé         | 120/3257 [00:00<00:21, 143.04it/s]  4%|‚ñç         | 135/3257 [00:00<00:21, 144.49it/s]  5%|‚ñç         | 152/3257 [00:01<00:20, 149.99it/s]  5%|‚ñå         | 167/3257 [00:01<00:21, 143.31it/s]  6%|‚ñå         | 182/3257 [00:01<00:21, 144.25it/s]  6%|‚ñå         | 198/3257 [00:01<00:20, 147.65it/s]  7%|‚ñã         | 216/3257 [00:01<00:19, 153.14it/s]  7%|‚ñã         | 232/3257 [00:01<00:29, 101.62it/s]  8%|‚ñä         | 249/3257 [00:01<00:26, 114.72it/s]  8%|‚ñä         | 263/3257 [00:01<00:25, 119.63it/s]  9%|‚ñä         | 282/3257 [00:02<00:21, 136.04it/s]  9%|‚ñâ         | 298/3257 [00:02<00:21, 138.97it/s] 10%|‚ñâ         | 313/3257 [00:02<00:21, 137.68it/s] 10%|‚ñà         | 331/3257 [00:02<00:19, 146.74it/s] 11%|‚ñà         | 347/3257 [00:02<00:20, 142.17it/s] 11%|‚ñà         | 364/3257 [00:02<00:19, 147.03it/s] 12%|‚ñà‚ñè        | 380/3257 [00:02<00:20, 141.22it/s] 12%|‚ñà‚ñè        | 395/3257 [00:02<00:20, 141.49it/s] 13%|‚ñà‚ñé        | 411/3257 [00:02<00:19, 146.40it/s] 13%|‚ñà‚ñé        | 426/3257 [00:03<00:21, 129.00it/s] 14%|‚ñà‚ñé        | 440/3257 [00:03<00:21, 131.66it/s] 14%|‚ñà‚ñç        | 456/3257 [00:03<00:20, 139.26it/s] 15%|‚ñà‚ñç        | 474/3257 [00:03<00:19, 145.54it/s] 15%|‚ñà‚ñå        | 489/3257 [00:03<00:18, 146.37it/s] 16%|‚ñà‚ñå        | 505/3257 [00:03<00:18, 149.67it/s] 16%|‚ñà‚ñå        | 522/3257 [00:03<00:18, 149.81it/s] 17%|‚ñà‚ñã        | 538/3257 [00:03<00:18, 150.08it/s] 17%|‚ñà‚ñã        | 554/3257 [00:03<00:18, 148.62it/s] 17%|‚ñà‚ñã        | 569/3257 [00:04<00:19, 137.01it/s] 18%|‚ñà‚ñä        | 583/3257 [00:04<00:20, 130.94it/s] 18%|‚ñà‚ñä        | 600/3257 [00:04<00:19, 139.45it/s] 19%|‚ñà‚ñâ        | 619/3257 [00:04<00:17, 152.82it/s] 19%|‚ñà‚ñâ        | 635/3257 [00:04<00:17, 150.07it/s] 20%|‚ñà‚ñâ        | 651/3257 [00:04<00:18, 139.47it/s] 20%|‚ñà‚ñà        | 666/3257 [00:04<00:19, 136.03it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:18, 136.73it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:05<00:18, 139.59it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:05<00:16, 149.84it/s] 23%|‚ñà‚ñà‚ñé       | 733/3257 [00:05<00:17, 140.47it/s] 23%|‚ñà‚ñà‚ñé       | 748/3257 [00:05<00:18, 137.59it/s] 23%|‚ñà‚ñà‚ñé       | 765/3257 [00:05<00:17, 145.69it/s] 24%|‚ñà‚ñà‚ñç       | 780/3257 [00:05<00:17, 138.20it/s] 24%|‚ñà‚ñà‚ñç       | 797/3257 [00:05<00:16, 145.25it/s] 25%|‚ñà‚ñà‚ñç       | 812/3257 [00:05<00:17, 142.61it/s] 25%|‚ñà‚ñà‚ñå       | 827/3257 [00:05<00:17, 135.37it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:06<00:19, 125.49it/s] 26%|‚ñà‚ñà‚ñã       | 856/3257 [00:06<00:18, 130.21it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:06<00:17, 133.91it/s] 27%|‚ñà‚ñà‚ñã       | 885/3257 [00:06<00:18, 131.51it/s] 28%|‚ñà‚ñà‚ñä       | 904/3257 [00:06<00:15, 147.53it/s] 28%|‚ñà‚ñà‚ñä       | 919/3257 [00:06<00:16, 138.74it/s] 29%|‚ñà‚ñà‚ñä       | 934/3257 [00:06<00:16, 138.58it/s] 29%|‚ñà‚ñà‚ñâ       | 950/3257 [00:06<00:16, 143.39it/s] 30%|‚ñà‚ñà‚ñâ       | 967/3257 [00:06<00:15, 148.11it/s] 30%|‚ñà‚ñà‚ñà       | 982/3257 [00:07<00:15, 145.11it/s] 31%|‚ñà‚ñà‚ñà       | 997/3257 [00:07<00:16, 141.05it/s] 31%|‚ñà‚ñà‚ñà       | 1012/3257 [00:07<00:16, 137.58it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:07<00:16, 135.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:07<00:16, 132.86it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1057/3257 [00:07<00:15, 137.79it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1075/3257 [00:07<00:14, 149.16it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:07<00:15, 137.14it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1108/3257 [00:07<00:14, 145.81it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:08<00:15, 141.61it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1138/3257 [00:08<00:14, 141.38it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1153/3257 [00:08<00:15, 135.49it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:08<00:14, 142.24it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:08<00:15, 132.27it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1199/3257 [00:08<00:15, 128.88it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1213/3257 [00:08<00:16, 123.85it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:08<00:14, 140.14it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:08<00:14, 137.48it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:09<00:14, 138.51it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1276/3257 [00:09<00:14, 133.73it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:09<00:15, 128.58it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1304/3257 [00:09<00:14, 131.60it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:09<00:13, 138.71it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:09<00:13, 146.68it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:09<00:13, 138.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:09<00:13, 140.40it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:09<00:13, 139.15it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:10<00:12, 144.44it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:10<00:11, 159.31it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:10<00:12, 150.77it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1459/3257 [00:10<00:11, 162.27it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1476/3257 [00:10<00:11, 159.77it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1493/3257 [00:10<00:10, 161.97it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1510/3257 [00:10<00:18, 95.46it/s]  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1523/3257 [00:11<00:17, 99.37it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1537/3257 [00:11<00:16, 106.27it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1552/3257 [00:11<00:14, 114.75it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1567/3257 [00:11<00:13, 123.16it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1581/3257 [00:11<00:13, 126.02it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1599/3257 [00:11<00:11, 138.77it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:11<00:11, 146.65it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:11<00:11, 140.43it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1649/3257 [00:11<00:11, 138.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1664/3257 [00:12<00:11, 139.18it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1679/3257 [00:12<00:11, 139.83it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1694/3257 [00:12<00:11, 138.10it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1711/3257 [00:12<00:10, 146.94it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1727/3257 [00:12<00:10, 148.76it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1742/3257 [00:12<00:11, 126.93it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1760/3257 [00:12<00:10, 140.04it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1776/3257 [00:12<00:10, 142.28it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1793/3257 [00:12<00:09, 148.65it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1809/3257 [00:13<00:10, 138.06it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1825/3257 [00:13<00:09, 143.31it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1840/3257 [00:13<00:09, 142.60it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1855/3257 [00:13<00:09, 144.34it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1872/3257 [00:13<00:09, 151.09it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1888/3257 [00:13<00:09, 149.07it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1904/3257 [00:13<00:09, 149.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1920/3257 [00:13<00:09, 145.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1938/3257 [00:13<00:08, 154.80it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1958/3257 [00:14<00:07, 166.47it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1975/3257 [00:14<00:07, 164.20it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1992/3257 [00:14<00:08, 157.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:14<00:08, 151.48it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2024/3257 [00:14<00:08, 152.92it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2040/3257 [00:14<00:08, 146.09it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:14<00:08, 140.86it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2070/3257 [00:14<00:08, 137.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:14<00:08, 138.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2099/3257 [00:15<00:08, 136.59it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:15<00:07, 144.26it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:15<00:08, 133.36it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2146/3257 [00:15<00:08, 130.38it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:15<00:07, 139.16it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2179/3257 [00:15<00:07, 143.96it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2194/3257 [00:15<00:07, 145.47it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:15<00:07, 138.84it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2225/3257 [00:15<00:07, 140.94it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2240/3257 [00:16<00:07, 135.39it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2257/3257 [00:16<00:06, 143.45it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2272/3257 [00:16<00:07, 134.70it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2290/3257 [00:16<00:06, 145.90it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2305/3257 [00:16<00:06, 146.07it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2324/3257 [00:16<00:05, 157.26it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2342/3257 [00:16<00:05, 162.36it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:16<00:05, 166.11it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2377/3257 [00:16<00:05, 164.49it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:17<00:05, 171.93it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2415/3257 [00:17<00:05, 157.37it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2432/3257 [00:17<00:05, 146.81it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2448/3257 [00:17<00:05, 144.65it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2468/3257 [00:17<00:04, 158.30it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2485/3257 [00:17<00:05, 153.36it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2506/3257 [00:17<00:04, 167.85it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:17<00:04, 161.54it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2541/3257 [00:17<00:04, 160.04it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2558/3257 [00:18<00:04, 155.53it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2574/3257 [00:18<00:04, 143.30it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2589/3257 [00:18<00:04, 138.35it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2608/3257 [00:18<00:04, 149.89it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2628/3257 [00:18<00:03, 162.71it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2645/3257 [00:18<00:03, 155.23it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2661/3257 [00:18<00:04, 145.92it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2678/3257 [00:18<00:03, 151.36it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:19<00:03, 146.19it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:19<00:04, 133.40it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2723/3257 [00:19<00:07, 69.15it/s]  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2743/3257 [00:19<00:05, 89.66it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2758/3257 [00:19<00:04, 100.45it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2772/3257 [00:19<00:04, 106.72it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2791/3257 [00:20<00:03, 124.84it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:20<00:03, 130.47it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2822/3257 [00:20<00:03, 132.45it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:20<00:03, 127.87it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:20<00:02, 135.42it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2875/3257 [00:20<00:02, 156.97it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2892/3257 [00:20<00:02, 155.36it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2909/3257 [00:20<00:02, 144.33it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:20<00:02, 147.87it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2944/3257 [00:21<00:02, 137.53it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2959/3257 [00:21<00:02, 135.12it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:21<00:02, 137.66it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2990/3257 [00:21<00:01, 136.44it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:21<00:01, 152.57it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3027/3257 [00:21<00:01, 147.82it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3046/3257 [00:21<00:01, 156.50it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3064/3257 [00:21<00:01, 162.77it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3081/3257 [00:21<00:01, 160.07it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3098/3257 [00:22<00:01, 157.62it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3116/3257 [00:22<00:00, 163.07it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3133/3257 [00:22<00:00, 155.43it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3149/3257 [00:22<00:00, 149.39it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:22<00:00, 148.03it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3180/3257 [00:22<00:00, 142.05it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3198/3257 [00:22<00:00, 151.91it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3214/3257 [00:22<00:00, 142.00it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3232/3257 [00:23<00:00, 151.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3250/3257 [00:23<00:00, 158.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:23<00:00, 140.60it/s]
2023-02-07 20:14:14.084 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:14:14,085][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d455,n5,mc5,s0.764091,t4>', 'datetime': '2023-02-07T20:14:14.085364', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:14:14,085][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:14:14,086][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:14:14,768][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:14:14,769][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:14:14,851][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 26649 unique words (49.30% of original 54054, drops 27405)', 'datetime': '2023-02-07T20:14:14.851736', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:14:14,852][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 6481391 word corpus (98.94% of original 6550866, drops 69475)', 'datetime': '2023-02-07T20:14:14.852192', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:14:14,946][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:14:14,947][gensim.models.word2vec][INFO] - sample=0.764091 downsamples 0 most-common words
[2023-02-07 20:14:14,948][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6481391 word corpus (100.0%% of prior 6481391)', 'datetime': '2023-02-07T20:14:14.948209', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:14:15,113][gensim.models.word2vec][INFO] - estimated required memory for 26649 words and 455 dimensions: 116906000 bytes
[2023-02-07 20:14:15,113][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:14:15,175][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 26649 vocabulary and 455 features, using sg=1 hs=0 sample=0.764091124587573 negative=5 window=13 shrink_windows=True', 'datetime': '2023-02-07T20:14:15.175597', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:14:16,182][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 21.55% examples, 1361399 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:17,184][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 42.09% examples, 1386404 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:18,185][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 63.99% examples, 1391659 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:19,185][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 86.67% examples, 1401707 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:19,760][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6426944 effective words) took 4.6s, 1402765 effective words/s
[2023-02-07 20:14:20,762][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 22.20% examples, 1406566 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:21,768][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 43.11% examples, 1419331 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:22,774][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 65.34% examples, 1420397 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:23,781][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 88.42% examples, 1420460 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:24,282][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6426944 effective words) took 4.5s, 1421800 effective words/s
[2023-02-07 20:14:25,285][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 22.14% examples, 1396720 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:26,292][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 42.62% examples, 1404706 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:27,300][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 64.91% examples, 1406926 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:28,305][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 88.09% examples, 1416263 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:28,815][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6426944 effective words) took 4.5s, 1418212 effective words/s
[2023-02-07 20:14:29,819][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 16.95% examples, 1049401 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:30,823][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 32.73% examples, 1058829 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:31,824][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 48.76% examples, 1063969 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:32,830][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 65.09% examples, 1062351 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:33,851][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 82.16% examples, 1057160 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:34,859][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 99.42% examples, 1057861 words/s, in_qsize 5, out_qsize 0
[2023-02-07 20:14:34,890][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6426944 effective words) took 6.1s, 1058247 effective words/s
[2023-02-07 20:14:35,898][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 14.61% examples, 913077 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:36,899][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 28.62% examples, 919996 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:37,901][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 48.91% examples, 1066280 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:38,904][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 69.76% examples, 1144106 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:39,914][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 92.54% examples, 1191643 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:40,228][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6426944 effective words) took 5.3s, 1204476 effective words/s
[2023-02-07 20:14:41,233][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 21.55% examples, 1361661 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:42,235][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 41.82% examples, 1374933 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:43,236][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 63.40% examples, 1377879 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:44,237][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 85.08% examples, 1377920 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:44,880][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6426944 effective words) took 4.6s, 1382152 effective words/s
[2023-02-07 20:14:45,884][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 21.74% examples, 1370519 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:46,885][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 42.09% examples, 1388061 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:47,892][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 63.89% examples, 1386349 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:48,895][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 82.53% examples, 1330677 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:49,906][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 99.42% examples, 1271988 words/s, in_qsize 5, out_qsize 0
[2023-02-07 20:14:49,939][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6426944 effective words) took 5.1s, 1270644 effective words/s
[2023-02-07 20:14:50,943][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 21.74% examples, 1370579 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:51,944][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 42.09% examples, 1388053 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:52,950][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 63.89% examples, 1387128 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:53,950][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 85.78% examples, 1385997 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:54,580][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6426944 effective words) took 4.6s, 1385367 effective words/s
[2023-02-07 20:14:55,586][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 21.74% examples, 1368818 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:14:56,598][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 41.63% examples, 1365865 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:14:57,606][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 63.22% examples, 1367405 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:58,611][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 84.99% examples, 1368544 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:59,273][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6426944 effective words) took 4.7s, 1369919 effective words/s
[2023-02-07 20:15:00,277][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 21.55% examples, 1363192 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:15:01,281][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 41.94% examples, 1381716 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:15:02,286][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 63.89% examples, 1386209 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:03,290][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 85.97% examples, 1386535 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:03,914][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6426944 effective words) took 4.6s, 1385420 effective words/s
[2023-02-07 20:15:04,919][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 21.74% examples, 1369451 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:15:05,928][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 42.25% examples, 1385506 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:06,933][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 63.99% examples, 1386663 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:07,936][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 85.97% examples, 1384730 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:08,544][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6426944 effective words) took 4.6s, 1388598 effective words/s
[2023-02-07 20:15:09,551][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 22.04% examples, 1384856 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:10,557][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 42.25% examples, 1386194 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:11,557][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 63.99% examples, 1389175 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:12,560][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 86.40% examples, 1394589 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:13,144][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6426944 effective words) took 4.6s, 1397704 effective words/s
[2023-02-07 20:15:14,148][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 21.74% examples, 1371085 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:15:15,148][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 41.82% examples, 1376554 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:16,149][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 63.37% examples, 1379822 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:17,154][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 86.40% examples, 1395538 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:17,723][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6426944 effective words) took 4.6s, 1404055 effective words/s
[2023-02-07 20:15:18,726][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 22.26% examples, 1413695 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:15:19,732][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 42.62% examples, 1405392 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:20,739][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 64.66% examples, 1402621 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:21,741][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 87.17% examples, 1408474 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:22,281][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6426944 effective words) took 4.6s, 1410609 effective words/s
[2023-02-07 20:15:23,289][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 22.38% examples, 1414544 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:24,293][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 42.22% examples, 1387145 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:25,296][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 59.59% examples, 1293305 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:26,304][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 78.48% examples, 1265269 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:27,288][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6426944 effective words) took 5.0s, 1283770 effective words/s
[2023-02-07 20:15:27,289][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (96404160 effective words) took 72.1s, 1336844 effective words/s', 'datetime': '2023-02-07T20:15:27.289363', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:15:27.289 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:15:33,537][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201341-eoxtomyo/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:15:33.537079', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:15:33,538][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201341-eoxtomyo/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 20:15:33,575][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201341-eoxtomyo/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 20:15:33,606][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:15:33,649][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201341-eoxtomyo/files/../tmp/embedding_model.pt
2023-02-07 20:15:33.649 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:15:36.280 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:15:37.143 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:15:40.040 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1260271678355143, 'test_mae': 0.8059308375774717, 'test_r2': -3.1146205858484235}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.1
wandb: percentage 0.50699
wandb:   test_mae 0.80593
wandb:   test_mse 1.12603
wandb:    test_r2 -3.11462
wandb: 
wandb: üöÄ View run rose-sweep-72 at: https://wandb.ai/xiaoqiz/mof2vec/runs/eoxtomyo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_201341-eoxtomyo/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mg4t7wm7 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 753
wandb: 	model.gensim.alpha: 0.007947516321329322
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.4424987231516445
wandb: 	model.gensim.vector_size: 295
wandb: 	model.gensim.window: 18
wandb: 	model.sklearn.learning_rate: 0.0003767075950203875
wandb: 	model.sklearn.max_depth: 12
wandb: 	model.sklearn.min_child_weight: 0.05203483815872291
wandb: 	model.sklearn.n_estimators: 1881
wandb: 	model.sklearn.num_leaves: 316
wandb: 	model.sklearn.reg_alpha: 0.020490791020452696
wandb: 	model.sklearn.reg_lambda: 0.4353913162418547
wandb: 	model.sklearn.subsample: 0.6449675967663332
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201559-mg4t7wm7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-73
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/mg4t7wm7
2023-02-07 20:16:08.137 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 20:16:08.138 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 753 for sweep.
2023-02-07 20:16:08.138 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.007947516321329322 for sweep.
2023-02-07 20:16:08.139 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:16:08.139 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 20:16:08.139 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4424987231516445 for sweep.
2023-02-07 20:16:08.139 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 295 for sweep.
2023-02-07 20:16:08.140 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 18 for sweep.
2023-02-07 20:16:08.140 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0003767075950203875 for sweep.
2023-02-07 20:16:08.140 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 12 for sweep.
2023-02-07 20:16:08.140 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05203483815872291 for sweep.
2023-02-07 20:16:08.141 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1881 for sweep.
2023-02-07 20:16:08.141 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 316 for sweep.
2023-02-07 20:16:08.142 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.020490791020452696 for sweep.
2023-02-07 20:16:08.142 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.4353913162418547 for sweep.
2023-02-07 20:16:08.142 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6449675967663332 for sweep.
2023-02-07 20:16:08.142 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:16:08.151 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201559-mg4t7wm7/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 753, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 295, 'window': 18, 'min_count': 10, 'dm': 0, 'sample': 0.4424987231516445, 'workers': 4, 'alpha': 0.007947516321329322, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1881, 'max_depth': 12, 'num_leaves': 316, 'reg_alpha': 0.020490791020452696, 'reg_lambda': 0.4353913162418547, 'subsample': 0.6449675967663332, 'min_child_weight': 0.05203483815872291, 'n_jobs': 4, 'learning_rate': 0.0003767075950203875}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:22, 146.39it/s]  1%|          | 33/3257 [00:00<00:19, 165.04it/s]  2%|‚ñè         | 50/3257 [00:00<00:19, 163.15it/s]  2%|‚ñè         | 67/3257 [00:00<00:20, 158.37it/s]  3%|‚ñé         | 88/3257 [00:00<00:18, 174.26it/s]  3%|‚ñé         | 106/3257 [00:00<00:20, 155.25it/s]  4%|‚ñç         | 123/3257 [00:00<00:19, 159.25it/s]  4%|‚ñç         | 141/3257 [00:00<00:18, 165.06it/s]  5%|‚ñç         | 159/3257 [00:00<00:18, 167.52it/s]  5%|‚ñå         | 176/3257 [00:01<00:18, 164.73it/s]  6%|‚ñå         | 196/3257 [00:01<00:17, 173.33it/s]  7%|‚ñã         | 216/3257 [00:01<00:17, 177.29it/s]  7%|‚ñã         | 237/3257 [00:01<00:16, 183.12it/s]  8%|‚ñä         | 257/3257 [00:01<00:16, 186.42it/s]  8%|‚ñä         | 276/3257 [00:01<00:16, 184.28it/s]  9%|‚ñâ         | 297/3257 [00:01<00:15, 187.79it/s] 10%|‚ñâ         | 316/3257 [00:01<00:16, 178.96it/s] 10%|‚ñà         | 336/3257 [00:01<00:16, 181.53it/s] 11%|‚ñà         | 355/3257 [00:02<00:15, 183.24it/s] 11%|‚ñà‚ñè        | 374/3257 [00:02<00:15, 182.24it/s] 12%|‚ñà‚ñè        | 393/3257 [00:02<00:17, 167.11it/s] 13%|‚ñà‚ñé        | 413/3257 [00:02<00:16, 175.41it/s] 13%|‚ñà‚ñé        | 431/3257 [00:02<00:18, 155.01it/s] 14%|‚ñà‚ñç        | 448/3257 [00:02<00:17, 156.71it/s] 14%|‚ñà‚ñç        | 469/3257 [00:02<00:16, 169.53it/s] 15%|‚ñà‚ñç        | 487/3257 [00:02<00:16, 165.29it/s] 16%|‚ñà‚ñå        | 508/3257 [00:02<00:15, 175.89it/s] 16%|‚ñà‚ñå        | 526/3257 [00:03<00:16, 167.89it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:16, 168.43it/s] 17%|‚ñà‚ñã        | 564/3257 [00:03<00:16, 160.77it/s] 18%|‚ñà‚ñä        | 581/3257 [00:03<00:17, 156.88it/s] 18%|‚ñà‚ñä        | 601/3257 [00:03<00:15, 166.78it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:16, 163.61it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:03<00:15, 169.57it/s] 20%|‚ñà‚ñà        | 657/3257 [00:03<00:16, 155.84it/s] 21%|‚ñà‚ñà        | 676/3257 [00:04<00:15, 163.65it/s] 21%|‚ñà‚ñà‚ñè       | 693/3257 [00:04<00:15, 161.19it/s] 22%|‚ñà‚ñà‚ñè       | 712/3257 [00:04<00:15, 169.01it/s] 22%|‚ñà‚ñà‚ñè       | 730/3257 [00:04<00:16, 156.54it/s] 23%|‚ñà‚ñà‚ñé       | 747/3257 [00:04<00:15, 159.93it/s] 24%|‚ñà‚ñà‚ñé       | 768/3257 [00:04<00:14, 171.56it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:04<00:15, 163.98it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:14, 166.34it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:04<00:14, 163.21it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:05<00:15, 160.23it/s] 26%|‚ñà‚ñà‚ñã       | 857/3257 [00:05<00:25, 95.29it/s]  27%|‚ñà‚ñà‚ñã       | 874/3257 [00:05<00:21, 109.05it/s] 27%|‚ñà‚ñà‚ñã       | 891/3257 [00:05<00:19, 120.27it/s] 28%|‚ñà‚ñà‚ñä       | 911/3257 [00:05<00:17, 137.79it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:05<00:16, 145.07it/s] 29%|‚ñà‚ñà‚ñâ       | 945/3257 [00:05<00:15, 149.75it/s] 30%|‚ñà‚ñà‚ñâ       | 964/3257 [00:05<00:14, 157.55it/s] 30%|‚ñà‚ñà‚ñà       | 981/3257 [00:06<00:14, 155.41it/s] 31%|‚ñà‚ñà‚ñà       | 998/3257 [00:06<00:14, 157.64it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:06<00:14, 157.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1032/3257 [00:06<00:14, 155.14it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1048/3257 [00:06<00:14, 153.64it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1066/3257 [00:06<00:13, 160.72it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1083/3257 [00:06<00:13, 156.70it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1100/3257 [00:06<00:13, 159.99it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:06<00:13, 162.73it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1134/3257 [00:07<00:13, 157.73it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1150/3257 [00:07<00:13, 154.38it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:12, 164.88it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:07<00:13, 157.02it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1203/3257 [00:07<00:14, 146.48it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:07<00:13, 148.67it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:07<00:12, 167.49it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:07<00:12, 161.13it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:07<00:12, 160.31it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:08<00:12, 152.33it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:08<00:12, 153.68it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:08<00:12, 158.94it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1347/3257 [00:08<00:11, 165.55it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:08<00:11, 160.23it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1381/3257 [00:08<00:12, 153.68it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1399/3257 [00:08<00:11, 160.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1420/3257 [00:08<00:10, 172.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1438/3257 [00:08<00:10, 166.13it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:09<00:10, 179.30it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1479/3257 [00:09<00:09, 178.31it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1500/3257 [00:09<00:09, 184.98it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1519/3257 [00:09<00:09, 174.47it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1537/3257 [00:09<00:10, 164.61it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1554/3257 [00:09<00:10, 162.86it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1573/3257 [00:09<00:09, 169.11it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:09<00:10, 163.53it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1611/3257 [00:09<00:09, 171.74it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1630/3257 [00:10<00:09, 175.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1648/3257 [00:10<00:10, 158.28it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1665/3257 [00:10<00:10, 157.57it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1681/3257 [00:10<00:09, 157.84it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:10<00:09, 165.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1717/3257 [00:10<00:09, 163.83it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1734/3257 [00:10<00:10, 149.92it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1753/3257 [00:10<00:09, 158.90it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1773/3257 [00:10<00:08, 168.80it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:11<00:08, 172.73it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1810/3257 [00:11<00:08, 164.16it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:11<00:08, 162.83it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1845/3257 [00:11<00:08, 166.16it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1863/3257 [00:11<00:08, 169.57it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1881/3257 [00:11<00:08, 169.55it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:11<00:08, 166.42it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1917/3257 [00:11<00:07, 168.47it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:11<00:07, 174.18it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:12<00:06, 190.66it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1981/3257 [00:12<00:07, 179.55it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2000/3257 [00:12<00:06, 180.48it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2019/3257 [00:12<00:06, 181.26it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2038/3257 [00:12<00:06, 179.83it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2057/3257 [00:12<00:07, 163.36it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2075/3257 [00:12<00:07, 164.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2092/3257 [00:12<00:07, 165.75it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2109/3257 [00:12<00:07, 163.52it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2126/3257 [00:13<00:07, 155.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:13<00:07, 153.07it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:13<00:06, 165.28it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:13<00:06, 167.77it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2198/3257 [00:13<00:10, 104.83it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2212/3257 [00:13<00:09, 110.96it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2231/3257 [00:13<00:07, 128.29it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2247/3257 [00:14<00:07, 134.11it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2265/3257 [00:14<00:06, 143.27it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2281/3257 [00:14<00:06, 145.72it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:14<00:06, 154.78it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2320/3257 [00:14<00:05, 169.32it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2341/3257 [00:14<00:05, 179.43it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2362/3257 [00:14<00:04, 186.79it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2382/3257 [00:14<00:04, 188.61it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2403/3257 [00:14<00:04, 194.65it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2423/3257 [00:14<00:04, 181.00it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2442/3257 [00:15<00:04, 167.15it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2462/3257 [00:15<00:04, 174.14it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2482/3257 [00:15<00:04, 178.86it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2504/3257 [00:15<00:03, 189.33it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:15<00:03, 188.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2544/3257 [00:15<00:03, 186.16it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2563/3257 [00:15<00:03, 178.58it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2581/3257 [00:15<00:03, 169.28it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2599/3257 [00:15<00:03, 169.81it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2623/3257 [00:16<00:03, 188.66it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2643/3257 [00:16<00:03, 183.26it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2662/3257 [00:16<00:03, 175.00it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2683/3257 [00:16<00:03, 183.38it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2702/3257 [00:16<00:03, 161.91it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:16<00:03, 160.40it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:16<00:02, 173.68it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2760/3257 [00:16<00:02, 177.29it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:17<00:02, 166.95it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2801/3257 [00:17<00:02, 179.72it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2820/3257 [00:17<00:02, 172.04it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2838/3257 [00:17<00:02, 166.02it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2859/3257 [00:17<00:02, 176.37it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2882/3257 [00:17<00:01, 189.07it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2902/3257 [00:17<00:02, 173.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2924/3257 [00:17<00:01, 184.43it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2943/3257 [00:17<00:01, 168.62it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2961/3257 [00:18<00:01, 170.27it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2979/3257 [00:18<00:01, 165.38it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2998/3257 [00:18<00:01, 171.77it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:18<00:01, 173.22it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3035/3257 [00:18<00:01, 177.48it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3055/3257 [00:18<00:01, 183.08it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3077/3257 [00:18<00:00, 192.02it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3097/3257 [00:18<00:00, 185.25it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3120/3257 [00:18<00:00, 197.83it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3140/3257 [00:19<00:00, 186.53it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3159/3257 [00:19<00:00, 181.72it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3178/3257 [00:19<00:00, 176.62it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:19<00:00, 195.99it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3223/3257 [00:19<00:00, 193.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3252/3257 [00:19<00:00, 218.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 166.34it/s]
2023-02-07 20:16:28.466 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:16:28,468][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d295,n5,mc10,s0.442499,t4>', 'datetime': '2023-02-07T20:16:28.468134', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:16:28,468][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:16:28,468][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:16:28,927][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 20:16:28,928][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:16:28,960][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 11126 unique words (34.98% of original 31803, drops 20677)', 'datetime': '2023-02-07T20:16:28.960423', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:16:28,960][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 5020792 word corpus (98.54% of original 5095118, drops 74326)', 'datetime': '2023-02-07T20:16:28.960627', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:16:29,000][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 20:16:29,001][gensim.models.word2vec][INFO] - sample=0.442499 downsamples 0 most-common words
[2023-02-07 20:16:29,001][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5020792 word corpus (100.0%% of prior 5020792)', 'datetime': '2023-02-07T20:16:29.001445', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:16:29,065][gensim.models.word2vec][INFO] - estimated required memory for 11126 words and 295 dimensions: 36315020 bytes
[2023-02-07 20:16:29,066][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:16:29,083][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11126 vocabulary and 295 features, using sg=1 hs=0 sample=0.4424987231516445 negative=5 window=18 shrink_windows=True', 'datetime': '2023-02-07T20:16:29.083027', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:16:30,090][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 47.22% examples, 2402380 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:31,091][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 99.11% examples, 2478985 words/s, in_qsize 5, out_qsize 0
[2023-02-07 20:16:31,103][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5012991 effective words) took 2.0s, 2484139 effective words/s
[2023-02-07 20:16:32,108][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 55.76% examples, 2852645 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:32,917][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5012991 effective words) took 1.8s, 2764345 effective words/s
[2023-02-07 20:16:33,921][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 51.21% examples, 2616912 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:16:34,820][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5012991 effective words) took 1.9s, 2635101 effective words/s
[2023-02-07 20:16:35,824][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 53.18% examples, 2729477 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:36,695][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5012991 effective words) took 1.9s, 2676074 effective words/s
[2023-02-07 20:16:37,697][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 54.10% examples, 2776528 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:38,458][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5012991 effective words) took 1.8s, 2846079 effective words/s
[2023-02-07 20:16:39,460][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 59.20% examples, 3032203 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:16:40,096][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5012991 effective words) took 1.6s, 3063197 effective words/s
[2023-02-07 20:16:41,098][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 57.66% examples, 2953158 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:41,874][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5012991 effective words) took 1.8s, 2821278 effective words/s
[2023-02-07 20:16:42,876][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 49.46% examples, 2526110 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:43,857][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5012991 effective words) took 2.0s, 2529120 effective words/s
[2023-02-07 20:16:44,861][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 49.25% examples, 2514565 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:45,828][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5012991 effective words) took 2.0s, 2545404 effective words/s
[2023-02-07 20:16:46,835][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 49.86% examples, 2545437 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:16:47,802][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5012991 effective words) took 2.0s, 2542055 effective words/s
[2023-02-07 20:16:48,812][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 50.63% examples, 2574190 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:49,738][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5012991 effective words) took 1.9s, 2593901 effective words/s
[2023-02-07 20:16:50,742][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 50.97% examples, 2598816 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:16:51,672][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5012991 effective words) took 1.9s, 2592725 effective words/s
[2023-02-07 20:16:52,678][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 50.63% examples, 2581451 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:53,619][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5012991 effective words) took 1.9s, 2576562 effective words/s
[2023-02-07 20:16:54,622][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 50.38% examples, 2573154 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:55,557][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5012991 effective words) took 1.9s, 2588133 effective words/s
[2023-02-07 20:16:56,559][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 46.95% examples, 2399503 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:16:57,561][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 97.88% examples, 2455299 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:57,594][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5012991 effective words) took 2.0s, 2463100 effective words/s
[2023-02-07 20:16:57,595][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75194865 effective words) took 28.5s, 2637314 effective words/s', 'datetime': '2023-02-07T20:16:57.595230', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:16:57.595 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:17:00,773][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201559-mg4t7wm7/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:17:00.773679', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:17:00,778][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:17:00,843][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201559-mg4t7wm7/files/../tmp/embedding_model.pt
2023-02-07 20:17:00.843 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:17:02.822 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:17:03.501 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:17:17.315 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0287126755230351, 'test_mae': 0.7676148780741574, 'test_r2': -1.8550496332686186}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.81
wandb: percentage 0.65016
wandb:   test_mae 0.76761
wandb:   test_mse 1.02871
wandb:    test_r2 -1.85505
wandb: 
wandb: üöÄ View run cosmic-sweep-73 at: https://wandb.ai/xiaoqiz/mof2vec/runs/mg4t7wm7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_201559-mg4t7wm7/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: bn9ksocu with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 340
wandb: 	model.gensim.alpha: 0.003579092791452275
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.2626987311752556
wandb: 	model.gensim.vector_size: 68
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.003885213728688052
wandb: 	model.sklearn.max_depth: 49
wandb: 	model.sklearn.min_child_weight: 0.0955460714875995
wandb: 	model.sklearn.n_estimators: 320
wandb: 	model.sklearn.num_leaves: 328
wandb: 	model.sklearn.reg_alpha: 0.0026071774656070937
wandb: 	model.sklearn.reg_lambda: 0.02246599736855466
wandb: 	model.sklearn.subsample: 0.23785974725007444
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201735-bn9ksocu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-74
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/bn9ksocu
2023-02-07 20:17:44.138 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:17:44.139 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 340 for sweep.
2023-02-07 20:17:44.139 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.003579092791452275 for sweep.
2023-02-07 20:17:44.140 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:17:44.140 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 20:17:44.140 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2626987311752556 for sweep.
2023-02-07 20:17:44.140 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 68 for sweep.
2023-02-07 20:17:44.141 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 20:17:44.141 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.003885213728688052 for sweep.
2023-02-07 20:17:44.141 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 49 for sweep.
2023-02-07 20:17:44.141 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0955460714875995 for sweep.
2023-02-07 20:17:44.142 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 320 for sweep.
2023-02-07 20:17:44.142 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 328 for sweep.
2023-02-07 20:17:44.142 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0026071774656070937 for sweep.
2023-02-07 20:17:44.142 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.02246599736855466 for sweep.
2023-02-07 20:17:44.143 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.23785974725007444 for sweep.
2023-02-07 20:17:44.143 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:17:44.150 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201735-bn9ksocu/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 340, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 68, 'window': 11, 'min_count': 2, 'dm': 0, 'sample': 0.2626987311752556, 'workers': 4, 'alpha': 0.003579092791452275, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 320, 'max_depth': 49, 'num_leaves': 328, 'reg_alpha': 0.0026071774656070937, 'reg_lambda': 0.02246599736855466, 'subsample': 0.23785974725007444, 'min_child_weight': 0.0955460714875995, 'n_jobs': 4, 'learning_rate': 0.003885213728688052}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:25, 128.58it/s]  1%|          | 30/3257 [00:00<00:21, 147.45it/s]  1%|‚ñè         | 46/3257 [00:00<00:21, 149.48it/s]  2%|‚ñè         | 61/3257 [00:00<00:22, 144.41it/s]  2%|‚ñè         | 78/3257 [00:00<00:20, 152.89it/s]  3%|‚ñé         | 94/3257 [00:00<00:20, 153.02it/s]  3%|‚ñé         | 110/3257 [00:00<00:22, 142.28it/s]  4%|‚ñç         | 126/3257 [00:00<00:21, 145.53it/s]  4%|‚ñç         | 145/3257 [00:00<00:19, 155.60it/s]  5%|‚ñç         | 161/3257 [00:01<00:20, 151.63it/s]  5%|‚ñå         | 177/3257 [00:01<00:20, 148.02it/s]  6%|‚ñå         | 195/3257 [00:01<00:19, 156.51it/s]  6%|‚ñã         | 211/3257 [00:01<00:19, 156.67it/s]  7%|‚ñã         | 230/3257 [00:01<00:18, 162.47it/s]  8%|‚ñä         | 247/3257 [00:01<00:19, 157.81it/s]  8%|‚ñä         | 263/3257 [00:01<00:19, 154.81it/s]  9%|‚ñä         | 283/3257 [00:01<00:17, 167.41it/s]  9%|‚ñâ         | 300/3257 [00:01<00:18, 160.80it/s] 10%|‚ñâ         | 317/3257 [00:02<00:18, 160.55it/s] 10%|‚ñà         | 335/3257 [00:02<00:17, 164.54it/s] 11%|‚ñà         | 352/3257 [00:02<00:27, 105.89it/s] 11%|‚ñà‚ñè        | 368/3257 [00:02<00:24, 116.19it/s] 12%|‚ñà‚ñè        | 382/3257 [00:02<00:23, 120.68it/s] 12%|‚ñà‚ñè        | 397/3257 [00:02<00:22, 126.37it/s] 13%|‚ñà‚ñé        | 415/3257 [00:02<00:20, 139.57it/s] 13%|‚ñà‚ñé        | 431/3257 [00:03<00:22, 126.86it/s] 14%|‚ñà‚ñé        | 446/3257 [00:03<00:21, 132.39it/s] 14%|‚ñà‚ñç        | 464/3257 [00:03<00:19, 143.01it/s] 15%|‚ñà‚ñç        | 479/3257 [00:03<00:19, 140.67it/s] 15%|‚ñà‚ñå        | 498/3257 [00:03<00:18, 152.86it/s] 16%|‚ñà‚ñå        | 516/3257 [00:03<00:17, 158.81it/s] 16%|‚ñà‚ñã        | 533/3257 [00:03<00:17, 154.12it/s] 17%|‚ñà‚ñã        | 549/3257 [00:03<00:17, 155.52it/s] 17%|‚ñà‚ñã        | 565/3257 [00:03<00:18, 143.85it/s] 18%|‚ñà‚ñä        | 580/3257 [00:04<00:18, 141.22it/s] 18%|‚ñà‚ñä        | 598/3257 [00:04<00:17, 151.14it/s] 19%|‚ñà‚ñâ        | 615/3257 [00:04<00:17, 153.51it/s] 19%|‚ñà‚ñâ        | 631/3257 [00:04<00:17, 152.33it/s] 20%|‚ñà‚ñâ        | 647/3257 [00:04<00:17, 148.51it/s] 20%|‚ñà‚ñà        | 662/3257 [00:04<00:18, 139.86it/s] 21%|‚ñà‚ñà        | 681/3257 [00:04<00:16, 153.26it/s] 21%|‚ñà‚ñà‚ñè       | 697/3257 [00:04<00:17, 144.79it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:04<00:16, 155.87it/s] 23%|‚ñà‚ñà‚ñé       | 733/3257 [00:05<00:16, 150.40it/s] 23%|‚ñà‚ñà‚ñé       | 749/3257 [00:05<00:17, 146.29it/s] 24%|‚ñà‚ñà‚ñé       | 769/3257 [00:05<00:15, 159.83it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:05<00:16, 151.27it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:15, 154.79it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:15, 153.09it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:05<00:16, 145.01it/s] 26%|‚ñà‚ñà‚ñå       | 851/3257 [00:05<00:17, 139.35it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:05<00:16, 144.06it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:06<00:16, 142.68it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:06<00:14, 158.64it/s] 28%|‚ñà‚ñà‚ñä       | 922/3257 [00:06<00:14, 160.08it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:06<00:14, 157.47it/s] 29%|‚ñà‚ñà‚ñâ       | 957/3257 [00:06<00:14, 163.33it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:06<00:14, 160.97it/s] 30%|‚ñà‚ñà‚ñà       | 991/3257 [00:06<00:14, 151.43it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:06<00:15, 147.34it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:06<00:14, 155.24it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:07<00:15, 141.71it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1058/3257 [00:07<00:14, 148.24it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1078/3257 [00:07<00:13, 161.73it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1095/3257 [00:07<00:14, 148.19it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1113/3257 [00:07<00:13, 154.47it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1129/3257 [00:07<00:14, 146.94it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1145/3257 [00:07<00:14, 147.76it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1163/3257 [00:07<00:13, 155.63it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1179/3257 [00:07<00:14, 146.38it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:08<00:14, 140.55it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1209/3257 [00:08<00:14, 138.85it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1229/3257 [00:08<00:13, 154.54it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:08<00:13, 152.14it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:08<00:12, 156.23it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1278/3257 [00:08<00:13, 146.60it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1293/3257 [00:08<00:13, 144.69it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:08<00:13, 144.90it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:08<00:12, 152.39it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:09<00:12, 158.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1362/3257 [00:09<00:12, 151.75it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1378/3257 [00:09<00:12, 148.66it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1393/3257 [00:09<00:12, 145.14it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:09<00:11, 155.90it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1431/3257 [00:09<00:11, 164.61it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1448/3257 [00:09<00:11, 161.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1465/3257 [00:10<00:17, 101.01it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1482/3257 [00:10<00:15, 113.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1502/3257 [00:10<00:13, 131.96it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1519/3257 [00:10<00:12, 134.76it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1535/3257 [00:10<00:12, 134.57it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1552/3257 [00:10<00:12, 138.95it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1568/3257 [00:10<00:11, 144.35it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1584/3257 [00:10<00:11, 145.97it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1602/3257 [00:10<00:10, 154.10it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:11<00:10, 155.97it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:11<00:10, 152.40it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1651/3257 [00:11<00:10, 149.00it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1667/3257 [00:11<00:11, 143.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1682/3257 [00:11<00:10, 144.17it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1699/3257 [00:11<00:10, 148.90it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:11<00:10, 149.94it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:11<00:10, 139.80it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1746/3257 [00:11<00:10, 139.72it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:12<00:10, 145.07it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:12<00:09, 148.08it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:12<00:09, 153.26it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1812/3257 [00:12<00:09, 148.08it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:12<00:09, 146.50it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1845/3257 [00:12<00:09, 151.94it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1861/3257 [00:12<00:09, 154.07it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:12<00:08, 158.72it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:12<00:08, 155.68it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1914/3257 [00:12<00:08, 164.56it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:13<00:08, 156.04it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:13<00:07, 175.48it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1973/3257 [00:13<00:07, 178.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1992/3257 [00:13<00:07, 167.52it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2009/3257 [00:13<00:07, 163.45it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2029/3257 [00:13<00:07, 170.77it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2047/3257 [00:13<00:07, 154.46it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2063/3257 [00:13<00:08, 148.74it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2082/3257 [00:14<00:07, 156.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2098/3257 [00:14<00:07, 150.30it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:14<00:07, 158.47it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:14<00:07, 144.91it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2149/3257 [00:14<00:07, 141.49it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:14<00:07, 151.09it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2184/3257 [00:14<00:07, 149.46it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2203/3257 [00:14<00:06, 158.91it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2220/3257 [00:14<00:06, 152.15it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:15<00:06, 153.51it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2253/3257 [00:15<00:06, 153.65it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2269/3257 [00:15<00:06, 153.25it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2285/3257 [00:15<00:06, 154.40it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:15<00:06, 150.99it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2322/3257 [00:15<00:05, 166.02it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2342/3257 [00:15<00:05, 174.81it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2361/3257 [00:15<00:05, 178.06it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2380/3257 [00:15<00:04, 180.99it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2400/3257 [00:15<00:04, 184.14it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2419/3257 [00:16<00:04, 170.07it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2437/3257 [00:16<00:05, 162.65it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2454/3257 [00:16<00:05, 160.52it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:16<00:04, 173.72it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2493/3257 [00:16<00:04, 175.41it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:16<00:04, 180.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2535/3257 [00:16<00:03, 186.34it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2554/3257 [00:16<00:04, 171.18it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:17<00:04, 159.25it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2589/3257 [00:17<00:04, 153.43it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2610/3257 [00:17<00:03, 168.17it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2631/3257 [00:17<00:03, 177.80it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2650/3257 [00:17<00:03, 166.81it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2668/3257 [00:17<00:03, 168.37it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:17<00:03, 171.17it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2705/3257 [00:17<00:03, 153.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2721/3257 [00:17<00:03, 149.10it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2737/3257 [00:18<00:06, 80.71it/s]  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:18<00:05, 98.04it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2770/3257 [00:18<00:04, 105.58it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2791/3257 [00:18<00:03, 125.74it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2808/3257 [00:18<00:03, 135.03it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2824/3257 [00:18<00:03, 134.96it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2840/3257 [00:19<00:02, 140.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2862/3257 [00:19<00:02, 160.42it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2885/3257 [00:19<00:02, 177.76it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2904/3257 [00:19<00:02, 158.07it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2925/3257 [00:19<00:01, 170.49it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2943/3257 [00:19<00:02, 154.32it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2960/3257 [00:19<00:01, 156.53it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2977/3257 [00:19<00:01, 155.02it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2993/3257 [00:19<00:01, 153.18it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3013/3257 [00:20<00:01, 164.35it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3030/3257 [00:20<00:01, 165.13it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:20<00:01, 171.62it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3071/3257 [00:20<00:01, 185.53it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3090/3257 [00:20<00:00, 179.31it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:20<00:00, 184.31it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3129/3257 [00:20<00:00, 180.47it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3148/3257 [00:20<00:00, 167.61it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:20<00:00, 166.14it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:21<00:00, 157.60it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:21<00:00, 166.79it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3220/3257 [00:21<00:00, 159.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3241/3257 [00:21<00:00, 172.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 151.63it/s]
2023-02-07 20:18:06.524 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:18:06,525][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d68,n5,mc2,s0.262699,t4>', 'datetime': '2023-02-07T20:18:06.525138', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:18:06,525][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:18:06,525][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:18:07,100][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:18:07,101][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:18:07,200][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 36619 unique words (85.76% of original 42701, drops 6082)', 'datetime': '2023-02-07T20:18:07.200909', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:18:07,201][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5816910 word corpus (99.90% of original 5822992, drops 6082)', 'datetime': '2023-02-07T20:18:07.201370', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:18:07,330][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:18:07,332][gensim.models.word2vec][INFO] - sample=0.262699 downsamples 0 most-common words
[2023-02-07 20:18:07,332][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5816910 word corpus (100.0%% of prior 5816910)', 'datetime': '2023-02-07T20:18:07.332420', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:18:07,553][gensim.models.word2vec][INFO] - estimated required memory for 36619 words and 68 dimensions: 39767540 bytes
[2023-02-07 20:18:07,554][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:18:07,567][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 36619 vocabulary and 68 features, using sg=1 hs=0 sample=0.2626987311752556 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T20:18:07.567873', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:18:08,572][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 50.17% examples, 2960119 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:09,513][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5790320 effective words) took 1.9s, 2981301 effective words/s
[2023-02-07 20:18:10,515][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 52.93% examples, 3122417 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:11,358][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5790320 effective words) took 1.8s, 3141254 effective words/s
[2023-02-07 20:18:12,361][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 53.09% examples, 3134595 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:13,194][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5790320 effective words) took 1.8s, 3155828 effective words/s
[2023-02-07 20:18:14,198][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 53.45% examples, 3167650 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:15,032][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5790320 effective words) took 1.8s, 3153866 effective words/s
[2023-02-07 20:18:16,033][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 52.59% examples, 3109642 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:16,876][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5790320 effective words) took 1.8s, 3142900 effective words/s
[2023-02-07 20:18:17,881][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 53.33% examples, 3155407 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:18,712][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5790320 effective words) took 1.8s, 3155348 effective words/s
[2023-02-07 20:18:19,717][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.45% examples, 3165655 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:20,540][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5790320 effective words) took 1.8s, 3171550 effective words/s
[2023-02-07 20:18:21,544][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 53.70% examples, 3176345 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:22,370][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5790320 effective words) took 1.8s, 3166063 effective words/s
[2023-02-07 20:18:23,374][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 53.33% examples, 3158490 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:24,198][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5790320 effective words) took 1.8s, 3170529 effective words/s
[2023-02-07 20:18:25,200][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 53.33% examples, 3162912 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:26,019][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5790320 effective words) took 1.8s, 3182122 effective words/s
[2023-02-07 20:18:27,022][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 54.04% examples, 3196769 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:27,840][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5790320 effective words) took 1.8s, 3182525 effective words/s
[2023-02-07 20:18:28,843][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 54.04% examples, 3198301 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:29,646][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5790320 effective words) took 1.8s, 3207389 effective words/s
[2023-02-07 20:18:30,649][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 53.21% examples, 3154195 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:31,482][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5790320 effective words) took 1.8s, 3156478 effective words/s
[2023-02-07 20:18:32,484][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 53.58% examples, 3182528 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:33,309][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5790320 effective words) took 1.8s, 3171292 effective words/s
[2023-02-07 20:18:34,312][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 53.70% examples, 3181609 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:18:35,133][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5790320 effective words) took 1.8s, 3176947 effective words/s
[2023-02-07 20:18:35,134][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86854800 effective words) took 27.6s, 3150780 effective words/s', 'datetime': '2023-02-07T20:18:35.134451', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:18:35.134 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:18:38,045][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201735-bn9ksocu/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:18:38.044946', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:18:38,046][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:18:38,101][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201735-bn9ksocu/files/../tmp/embedding_model.pt
2023-02-07 20:18:38.101 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:18:39.249 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:18:39.694 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:18:40.438 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9750000069579603, 'test_mae': 0.7660012326083301, 'test_r2': -1.7989670053985627}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.72
wandb: percentage 0.14243
wandb:   test_mae 0.766
wandb:   test_mse 0.975
wandb:    test_r2 -1.79897
wandb: 
wandb: üöÄ View run ancient-sweep-74 at: https://wandb.ai/xiaoqiz/mof2vec/runs/bn9ksocu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_201735-bn9ksocu/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: w67argfs with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 615
wandb: 	model.gensim.alpha: 0.015636040856223565
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.6680838815310481
wandb: 	model.gensim.vector_size: 304
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.17101776598230678
wandb: 	model.sklearn.max_depth: 42
wandb: 	model.sklearn.min_child_weight: 0.05846064800387956
wandb: 	model.sklearn.n_estimators: 2651
wandb: 	model.sklearn.num_leaves: 404
wandb: 	model.sklearn.reg_alpha: 0.004056811510060662
wandb: 	model.sklearn.reg_lambda: 0.11196969069250884
wandb: 	model.sklearn.subsample: 0.48046056003314463
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201859-w67argfs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-75
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/w67argfs
2023-02-07 20:19:07.794 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 20:19:07.795 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 615 for sweep.
2023-02-07 20:19:07.795 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.015636040856223565 for sweep.
2023-02-07 20:19:07.795 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:19:07.796 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 20:19:07.796 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6680838815310481 for sweep.
2023-02-07 20:19:07.796 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 304 for sweep.
2023-02-07 20:19:07.796 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 20:19:07.797 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.17101776598230678 for sweep.
2023-02-07 20:19:07.797 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 42 for sweep.
2023-02-07 20:19:07.797 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05846064800387956 for sweep.
2023-02-07 20:19:07.797 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2651 for sweep.
2023-02-07 20:19:07.797 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 404 for sweep.
2023-02-07 20:19:07.798 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004056811510060662 for sweep.
2023-02-07 20:19:07.798 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.11196969069250884 for sweep.
2023-02-07 20:19:07.798 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.48046056003314463 for sweep.
2023-02-07 20:19:07.799 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:19:07.804 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201859-w67argfs/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 615, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 304, 'window': 11, 'min_count': 8, 'dm': 0, 'sample': 0.6680838815310481, 'workers': 4, 'alpha': 0.015636040856223565, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2651, 'max_depth': 42, 'num_leaves': 404, 'reg_alpha': 0.004056811510060662, 'reg_lambda': 0.11196969069250884, 'subsample': 0.48046056003314463, 'min_child_weight': 0.05846064800387956, 'n_jobs': 4, 'learning_rate': 0.17101776598230678}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 179.75it/s]  1%|          | 40/3257 [00:00<00:16, 200.80it/s]  2%|‚ñè         | 61/3257 [00:00<00:16, 194.30it/s]  3%|‚ñé         | 84/3257 [00:00<00:15, 206.59it/s]  3%|‚ñé         | 105/3257 [00:00<00:15, 203.67it/s]  4%|‚ñç         | 126/3257 [00:00<00:15, 199.94it/s]  5%|‚ñç         | 150/3257 [00:00<00:14, 210.35it/s]  5%|‚ñå         | 172/3257 [00:00<00:15, 202.74it/s]  6%|‚ñå         | 195/3257 [00:00<00:14, 208.36it/s]  7%|‚ñã         | 218/3257 [00:01<00:14, 212.87it/s]  7%|‚ñã         | 243/3257 [00:01<00:13, 222.84it/s]  8%|‚ñä         | 266/3257 [00:01<00:13, 215.46it/s]  9%|‚ñâ         | 292/3257 [00:01<00:13, 227.53it/s] 10%|‚ñâ         | 315/3257 [00:01<00:13, 220.28it/s] 10%|‚ñà         | 338/3257 [00:01<00:13, 220.61it/s] 11%|‚ñà         | 362/3257 [00:01<00:13, 221.21it/s] 12%|‚ñà‚ñè        | 385/3257 [00:01<00:13, 212.68it/s] 12%|‚ñà‚ñè        | 407/3257 [00:01<00:13, 211.23it/s] 13%|‚ñà‚ñé        | 429/3257 [00:02<00:14, 192.40it/s] 14%|‚ñà‚ñç        | 450/3257 [00:02<00:14, 194.36it/s] 15%|‚ñà‚ñç        | 474/3257 [00:02<00:13, 205.22it/s] 15%|‚ñà‚ñå        | 496/3257 [00:02<00:13, 209.32it/s] 16%|‚ñà‚ñå        | 518/3257 [00:02<00:12, 211.32it/s] 17%|‚ñà‚ñã        | 541/3257 [00:02<00:12, 214.77it/s] 17%|‚ñà‚ñã        | 563/3257 [00:02<00:13, 199.26it/s] 18%|‚ñà‚ñä        | 584/3257 [00:02<00:13, 200.34it/s] 19%|‚ñà‚ñä        | 607/3257 [00:02<00:12, 208.65it/s] 19%|‚ñà‚ñâ        | 629/3257 [00:03<00:12, 209.15it/s] 20%|‚ñà‚ñâ        | 651/3257 [00:03<00:12, 204.16it/s] 21%|‚ñà‚ñà        | 672/3257 [00:03<00:12, 202.51it/s] 21%|‚ñà‚ñà‚ñè       | 693/3257 [00:03<00:12, 197.48it/s] 22%|‚ñà‚ñà‚ñè       | 714/3257 [00:03<00:12, 200.43it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:03<00:12, 196.86it/s] 23%|‚ñà‚ñà‚ñé       | 755/3257 [00:03<00:13, 191.73it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:03<00:12, 195.29it/s] 25%|‚ñà‚ñà‚ñç       | 799/3257 [00:03<00:12, 201.29it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:04<00:18, 128.63it/s] 26%|‚ñà‚ñà‚ñå       | 837/3257 [00:04<00:17, 137.07it/s] 26%|‚ñà‚ñà‚ñã       | 856/3257 [00:04<00:16, 148.32it/s] 27%|‚ñà‚ñà‚ñã       | 877/3257 [00:04<00:14, 160.49it/s] 28%|‚ñà‚ñà‚ñä       | 902/3257 [00:04<00:12, 182.46it/s] 28%|‚ñà‚ñà‚ñä       | 924/3257 [00:04<00:12, 191.83it/s] 29%|‚ñà‚ñà‚ñâ       | 945/3257 [00:04<00:11, 196.75it/s] 30%|‚ñà‚ñà‚ñâ       | 968/3257 [00:04<00:11, 205.11it/s] 30%|‚ñà‚ñà‚ñà       | 990/3257 [00:05<00:11, 202.16it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:05<00:11, 203.38it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1032/3257 [00:05<00:10, 202.65it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1053/3257 [00:05<00:10, 201.03it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1079/3257 [00:05<00:10, 215.93it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1101/3257 [00:05<00:10, 204.08it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:05<00:10, 207.00it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1145/3257 [00:05<00:10, 209.55it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:05<00:09, 221.58it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:05<00:09, 218.55it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:06<00:08, 227.47it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1248/3257 [00:06<00:08, 242.24it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1273/3257 [00:06<00:08, 238.44it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1297/3257 [00:06<00:08, 227.30it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1327/3257 [00:06<00:07, 246.53it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1353/3257 [00:06<00:07, 248.88it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1379/3257 [00:06<00:07, 251.23it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1407/3257 [00:06<00:07, 258.03it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1436/3257 [00:06<00:06, 266.79it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1468/3257 [00:07<00:06, 282.05it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1500/3257 [00:07<00:06, 290.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:07<00:06, 270.12it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1558/3257 [00:07<00:06, 259.72it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1585/3257 [00:07<00:06, 259.98it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1614/3257 [00:07<00:06, 267.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1641/3257 [00:07<00:06, 241.81it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1666/3257 [00:07<00:07, 226.35it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:07<00:07, 218.00it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:08<00:06, 226.25it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1738/3257 [00:08<00:07, 210.05it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1761/3257 [00:08<00:07, 213.14it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1783/3257 [00:08<00:06, 214.07it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1805/3257 [00:08<00:07, 207.36it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:08<00:07, 202.09it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1847/3257 [00:08<00:06, 203.42it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1870/3257 [00:08<00:06, 210.23it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1892/3257 [00:08<00:06, 206.60it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:09<00:06, 210.53it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1940/3257 [00:09<00:06, 217.93it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1966/3257 [00:09<00:05, 229.12it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1989/3257 [00:09<00:05, 219.01it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2012/3257 [00:09<00:05, 218.90it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:09<00:05, 220.92it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2058/3257 [00:09<00:05, 201.20it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2079/3257 [00:09<00:08, 131.71it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2098/3257 [00:10<00:08, 142.33it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:10<00:07, 155.28it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2139/3257 [00:10<00:06, 161.76it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2159/3257 [00:10<00:06, 170.26it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2180/3257 [00:10<00:05, 180.54it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2202/3257 [00:10<00:05, 188.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2222/3257 [00:10<00:05, 190.63it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2242/3257 [00:10<00:05, 188.37it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2264/3257 [00:10<00:05, 197.17it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2286/3257 [00:11<00:04, 201.83it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2307/3257 [00:11<00:04, 202.57it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2334/3257 [00:11<00:04, 220.78it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:11<00:03, 228.71it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2384/3257 [00:11<00:03, 230.82it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2408/3257 [00:11<00:03, 224.77it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2431/3257 [00:11<00:03, 216.14it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2453/3257 [00:11<00:03, 213.52it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2478/3257 [00:11<00:03, 222.04it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2505/3257 [00:11<00:03, 235.00it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2529/3257 [00:12<00:03, 226.70it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2552/3257 [00:12<00:03, 221.48it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2575/3257 [00:12<00:03, 201.31it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2596/3257 [00:12<00:03, 195.91it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2623/3257 [00:12<00:02, 213.65it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2645/3257 [00:12<00:02, 209.78it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2667/3257 [00:12<00:02, 205.05it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2691/3257 [00:12<00:02, 211.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2713/3257 [00:13<00:02, 191.68it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2735/3257 [00:13<00:02, 198.45it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2758/3257 [00:13<00:02, 204.51it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:13<00:02, 199.04it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2805/3257 [00:13<00:02, 214.29it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2827/3257 [00:13<00:02, 202.39it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2850/3257 [00:13<00:01, 209.22it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2875/3257 [00:13<00:01, 220.06it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2898/3257 [00:13<00:01, 210.91it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2921/3257 [00:14<00:01, 214.61it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2943/3257 [00:14<00:01, 205.62it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:14<00:01, 212.14it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2988/3257 [00:14<00:01, 204.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:14<00:01, 212.18it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3035/3257 [00:14<00:01, 215.71it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3061/3257 [00:14<00:00, 227.30it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3084/3257 [00:14<00:00, 224.11it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3108/3257 [00:14<00:00, 226.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3131/3257 [00:14<00:00, 221.13it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3154/3257 [00:15<00:00, 209.48it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3176/3257 [00:15<00:00, 208.24it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3198/3257 [00:15<00:00, 211.14it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3220/3257 [00:15<00:00, 207.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3246/3257 [00:15<00:00, 220.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:15<00:00, 209.12it/s]
2023-02-07 20:19:23.870 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:19:23,871][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d304,n5,mc8,s0.668084,t4>', 'datetime': '2023-02-07T20:19:23.871544', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:19:23,872][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:19:23,872][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:19:24,221][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 20:19:24,221][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:19:24,240][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 5936 unique words (45.45% of original 13061, drops 7125)', 'datetime': '2023-02-07T20:19:24.240168', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:19:24,240][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 3618620 word corpus (99.43% of original 3639370, drops 20750)', 'datetime': '2023-02-07T20:19:24.240607', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:19:24,261][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 20:19:24,261][gensim.models.word2vec][INFO] - sample=0.668084 downsamples 0 most-common words
[2023-02-07 20:19:24,262][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3618620 word corpus (100.0%% of prior 3618620)', 'datetime': '2023-02-07T20:19:24.262080', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:19:24,298][gensim.models.word2vec][INFO] - estimated required memory for 5936 words and 304 dimensions: 22016264 bytes
[2023-02-07 20:19:24,298][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:19:24,311][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 5936 vocabulary and 304 features, using sg=1 hs=0 sample=0.6680838815310481 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T20:19:24.311932', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:19:25,319][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 61.34% examples, 2251081 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:25,886][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3621877 effective words) took 1.6s, 2305195 effective words/s
[2023-02-07 20:19:26,889][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 69.70% examples, 2583993 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:27,311][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3621877 effective words) took 1.4s, 2546058 effective words/s
[2023-02-07 20:19:28,314][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 67.58% examples, 2501568 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:28,756][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3621877 effective words) took 1.4s, 2511238 effective words/s
[2023-02-07 20:19:29,761][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 69.05% examples, 2546718 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:30,173][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3621877 effective words) took 1.4s, 2558109 effective words/s
[2023-02-07 20:19:31,179][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 69.05% examples, 2545713 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:31,585][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3621877 effective words) took 1.4s, 2567323 effective words/s
[2023-02-07 20:19:32,594][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 71.05% examples, 2611681 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:32,972][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3621877 effective words) took 1.4s, 2614671 effective words/s
[2023-02-07 20:19:33,980][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 69.85% examples, 2578899 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:34,365][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3621877 effective words) took 1.4s, 2602748 effective words/s
[2023-02-07 20:19:35,375][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 72.64% examples, 2650608 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:35,730][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3621877 effective words) took 1.4s, 2657630 effective words/s
[2023-02-07 20:19:36,738][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 71.05% examples, 2611025 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:37,114][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3621877 effective words) took 1.4s, 2619154 effective words/s
[2023-02-07 20:19:38,118][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 71.32% examples, 2634390 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:38,488][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3621877 effective words) took 1.4s, 2640240 effective words/s
[2023-02-07 20:19:39,492][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 71.32% examples, 2632424 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:39,857][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3621877 effective words) took 1.4s, 2647909 effective words/s
[2023-02-07 20:19:40,868][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 53.70% examples, 1983499 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:41,685][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3621877 effective words) took 1.8s, 1984743 effective words/s
[2023-02-07 20:19:42,691][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 72.64% examples, 2661967 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:43,047][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3621877 effective words) took 1.4s, 2661973 effective words/s
[2023-02-07 20:19:44,060][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 71.05% examples, 2602723 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:44,428][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3621877 effective words) took 1.4s, 2626384 effective words/s
[2023-02-07 20:19:45,431][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 72.18% examples, 2654089 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:45,802][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3621877 effective words) took 1.4s, 2639518 effective words/s
[2023-02-07 20:19:45,802][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54328155 effective words) took 21.5s, 2528036 effective words/s', 'datetime': '2023-02-07T20:19:45.802729', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:19:45.803 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:19:47,835][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201859-w67argfs/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:19:47.834984', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:19:47,835][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:19:47,869][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201859-w67argfs/files/../tmp/embedding_model.pt
2023-02-07 20:19:47.870 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:19:49.833 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:19:50.544 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:19:53.207 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0131869893136454, 'test_mae': 0.7648294030980098, 'test_r2': -2.0357579516238373}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.8
wandb: percentage 0.54552
wandb:   test_mae 0.76483
wandb:   test_mse 1.01319
wandb:    test_r2 -2.03576
wandb: 
wandb: üöÄ View run radiant-sweep-75 at: https://wandb.ai/xiaoqiz/mof2vec/runs/w67argfs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_201859-w67argfs/logs
wandb: Agent Starting Run: viymrlb0 with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 346
wandb: 	model.gensim.alpha: 0.006149816499792803
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 4
wandb: 	model.gensim.sample: 0.49734289418959066
wandb: 	model.gensim.vector_size: 285
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.0021014177206119295
wandb: 	model.sklearn.max_depth: 38
wandb: 	model.sklearn.min_child_weight: 0.09840946272352386
wandb: 	model.sklearn.n_estimators: 94
wandb: 	model.sklearn.num_leaves: 239
wandb: 	model.sklearn.reg_alpha: 0.004957127036085677
wandb: 	model.sklearn.reg_lambda: 0.009425688012204418
wandb: 	model.sklearn.subsample: 0.6928993897907838
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202003-viymrlb0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-76
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/viymrlb0
2023-02-07 20:20:11.960 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:20:11.961 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 346 for sweep.
2023-02-07 20:20:11.961 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.006149816499792803 for sweep.
2023-02-07 20:20:11.962 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:20:11.962 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 4 for sweep.
2023-02-07 20:20:11.962 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.49734289418959066 for sweep.
2023-02-07 20:20:11.962 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 285 for sweep.
2023-02-07 20:20:11.963 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 20:20:11.963 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0021014177206119295 for sweep.
2023-02-07 20:20:11.963 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 38 for sweep.
2023-02-07 20:20:11.964 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09840946272352386 for sweep.
2023-02-07 20:20:11.964 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 94 for sweep.
2023-02-07 20:20:11.964 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 239 for sweep.
2023-02-07 20:20:11.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004957127036085677 for sweep.
2023-02-07 20:20:11.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.009425688012204418 for sweep.
2023-02-07 20:20:11.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6928993897907838 for sweep.
2023-02-07 20:20:11.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:20:11.971 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202003-viymrlb0/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 346, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 285, 'window': 11, 'min_count': 4, 'dm': 0, 'sample': 0.49734289418959066, 'workers': 4, 'alpha': 0.006149816499792803, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 94, 'max_depth': 38, 'num_leaves': 239, 'reg_alpha': 0.004957127036085677, 'reg_lambda': 0.009425688012204418, 'subsample': 0.6928993897907838, 'min_child_weight': 0.09840946272352386, 'n_jobs': 4, 'learning_rate': 0.0021014177206119295}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 12/3257 [00:00<00:27, 119.38it/s]  1%|          | 28/3257 [00:00<00:22, 142.84it/s]  1%|‚ñè         | 43/3257 [00:00<00:23, 139.73it/s]  2%|‚ñè         | 57/3257 [00:00<00:23, 139.09it/s]  2%|‚ñè         | 73/3257 [00:00<00:21, 146.14it/s]  3%|‚ñé         | 90/3257 [00:00<00:21, 150.74it/s]  3%|‚ñé         | 106/3257 [00:00<00:22, 142.46it/s]  4%|‚ñé         | 121/3257 [00:00<00:21, 143.25it/s]  4%|‚ñç         | 137/3257 [00:00<00:21, 147.22it/s]  5%|‚ñç         | 154/3257 [00:01<00:20, 150.49it/s]  5%|‚ñå         | 170/3257 [00:01<00:20, 148.20it/s]  6%|‚ñå         | 185/3257 [00:01<00:20, 148.23it/s]  6%|‚ñå         | 200/3257 [00:01<00:31, 98.42it/s]   7%|‚ñã         | 217/3257 [00:01<00:26, 112.97it/s]  7%|‚ñã         | 236/3257 [00:01<00:23, 130.77it/s]  8%|‚ñä         | 251/3257 [00:01<00:22, 135.24it/s]  8%|‚ñä         | 266/3257 [00:01<00:22, 135.79it/s]  9%|‚ñâ         | 287/3257 [00:02<00:19, 153.54it/s]  9%|‚ñâ         | 304/3257 [00:02<00:19, 153.08it/s] 10%|‚ñâ         | 323/3257 [00:02<00:18, 161.36it/s] 10%|‚ñà         | 340/3257 [00:02<00:19, 152.28it/s] 11%|‚ñà         | 359/3257 [00:02<00:18, 157.23it/s] 12%|‚ñà‚ñè        | 376/3257 [00:02<00:18, 151.77it/s] 12%|‚ñà‚ñè        | 392/3257 [00:02<00:19, 149.56it/s] 13%|‚ñà‚ñé        | 412/3257 [00:02<00:17, 162.29it/s] 13%|‚ñà‚ñé        | 429/3257 [00:02<00:19, 147.29it/s] 14%|‚ñà‚ñé        | 447/3257 [00:03<00:18, 152.33it/s] 14%|‚ñà‚ñç        | 469/3257 [00:03<00:16, 169.39it/s] 15%|‚ñà‚ñç        | 487/3257 [00:03<00:16, 167.79it/s] 16%|‚ñà‚ñå        | 510/3257 [00:03<00:15, 181.41it/s] 16%|‚ñà‚ñå        | 529/3257 [00:03<00:15, 176.74it/s] 17%|‚ñà‚ñã        | 547/3257 [00:03<00:15, 175.96it/s] 17%|‚ñà‚ñã        | 565/3257 [00:03<00:15, 169.80it/s] 18%|‚ñà‚ñä        | 583/3257 [00:03<00:16, 166.11it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:15, 173.94it/s] 19%|‚ñà‚ñâ        | 622/3257 [00:04<00:15, 172.89it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:04<00:14, 183.31it/s] 20%|‚ñà‚ñà        | 663/3257 [00:04<00:15, 167.16it/s] 21%|‚ñà‚ñà        | 682/3257 [00:04<00:14, 172.44it/s] 21%|‚ñà‚ñà‚ñè       | 700/3257 [00:04<00:15, 163.06it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:04<00:14, 171.68it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:04<00:15, 162.07it/s] 23%|‚ñà‚ñà‚ñé       | 755/3257 [00:04<00:15, 163.81it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:04<00:15, 165.48it/s] 24%|‚ñà‚ñà‚ñç       | 791/3257 [00:05<00:14, 168.56it/s] 25%|‚ñà‚ñà‚ñç       | 809/3257 [00:05<00:14, 169.29it/s] 25%|‚ñà‚ñà‚ñå       | 827/3257 [00:05<00:14, 167.71it/s] 26%|‚ñà‚ñà‚ñå       | 844/3257 [00:05<00:14, 161.18it/s] 26%|‚ñà‚ñà‚ñã       | 863/3257 [00:05<00:14, 168.97it/s] 27%|‚ñà‚ñà‚ñã       | 881/3257 [00:05<00:14, 164.58it/s] 28%|‚ñà‚ñà‚ñä       | 902/3257 [00:05<00:13, 175.43it/s] 28%|‚ñà‚ñà‚ñä       | 920/3257 [00:05<00:13, 175.97it/s] 29%|‚ñà‚ñà‚ñâ       | 938/3257 [00:05<00:13, 175.78it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:06<00:12, 182.25it/s] 30%|‚ñà‚ñà‚ñà       | 979/3257 [00:06<00:12, 179.22it/s] 31%|‚ñà‚ñà‚ñà       | 997/3257 [00:06<00:13, 169.45it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:06<00:13, 169.89it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1033/3257 [00:06<00:13, 162.72it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1050/3257 [00:06<00:13, 159.96it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1068/3257 [00:06<00:13, 165.24it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1086/3257 [00:06<00:12, 167.64it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1103/3257 [00:06<00:12, 167.26it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1120/3257 [00:07<00:12, 164.54it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1138/3257 [00:07<00:12, 166.76it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1155/3257 [00:07<00:12, 162.38it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1172/3257 [00:07<00:12, 164.30it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1189/3257 [00:07<00:14, 145.03it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:07<00:13, 148.36it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1223/3257 [00:07<00:12, 156.55it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:07<00:12, 166.34it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1260/3257 [00:07<00:11, 166.93it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:08<00:12, 158.54it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1294/3257 [00:08<00:12, 155.15it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1311/3257 [00:08<00:12, 159.02it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:08<00:11, 160.89it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:08<00:11, 165.88it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1363/3257 [00:08<00:11, 161.91it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1380/3257 [00:08<00:12, 156.38it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1396/3257 [00:08<00:12, 150.75it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1413/3257 [00:08<00:11, 155.83it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:09<00:11, 160.90it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1451/3257 [00:09<00:10, 168.10it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1471/3257 [00:09<00:10, 174.94it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1489/3257 [00:09<00:10, 170.52it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:09<00:09, 183.79it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:09<00:10, 168.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1548/3257 [00:09<00:15, 108.00it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1566/3257 [00:09<00:13, 121.04it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1582/3257 [00:10<00:12, 129.21it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1602/3257 [00:10<00:11, 145.35it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:10<00:10, 151.99it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1637/3257 [00:10<00:10, 152.42it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:10<00:10, 154.23it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1671/3257 [00:10<00:10, 150.27it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1688/3257 [00:10<00:10, 155.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1706/3257 [00:10<00:09, 160.36it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:10<00:09, 161.37it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1740/3257 [00:11<00:10, 144.69it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1761/3257 [00:11<00:09, 160.49it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:11<00:09, 163.36it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1797/3257 [00:11<00:08, 165.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:11<00:09, 159.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1831/3257 [00:11<00:08, 158.80it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1850/3257 [00:11<00:08, 167.21it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1870/3257 [00:11<00:07, 175.49it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1888/3257 [00:11<00:07, 175.98it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1908/3257 [00:12<00:07, 182.01it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1927/3257 [00:12<00:07, 177.28it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1953/3257 [00:12<00:06, 200.21it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:12<00:06, 198.56it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1994/3257 [00:12<00:06, 194.66it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2014/3257 [00:12<00:06, 185.32it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:12<00:06, 191.28it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:12<00:06, 172.64it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2073/3257 [00:12<00:06, 169.49it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:13<00:07, 165.52it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2108/3257 [00:13<00:07, 160.72it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2125/3257 [00:13<00:07, 149.17it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2141/3257 [00:13<00:07, 150.29it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2157/3257 [00:13<00:07, 149.39it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2175/3257 [00:13<00:06, 157.67it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2191/3257 [00:13<00:07, 150.45it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2207/3257 [00:13<00:06, 150.45it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2223/3257 [00:13<00:06, 149.98it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2239/3257 [00:14<00:07, 140.63it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2256/3257 [00:14<00:06, 147.55it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2271/3257 [00:14<00:07, 138.04it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2289/3257 [00:14<00:06, 147.91it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2305/3257 [00:14<00:06, 147.58it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2324/3257 [00:14<00:05, 158.50it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2341/3257 [00:14<00:05, 161.39it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:14<00:05, 168.14it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2377/3257 [00:14<00:05, 167.07it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:15<00:04, 173.16it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2415/3257 [00:15<00:05, 156.13it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2431/3257 [00:15<00:05, 145.14it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2447/3257 [00:15<00:05, 146.19it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2464/3257 [00:15<00:05, 151.78it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:15<00:05, 153.60it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2500/3257 [00:15<00:04, 163.12it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2518/3257 [00:15<00:04, 166.88it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2536/3257 [00:15<00:04, 169.49it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2554/3257 [00:16<00:04, 156.29it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2570/3257 [00:16<00:04, 144.64it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2585/3257 [00:16<00:04, 144.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2602/3257 [00:16<00:04, 150.68it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2624/3257 [00:16<00:03, 168.46it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2642/3257 [00:16<00:03, 161.79it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2659/3257 [00:16<00:04, 148.36it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2676/3257 [00:16<00:03, 153.18it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2692/3257 [00:16<00:03, 152.55it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2708/3257 [00:17<00:04, 132.23it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2722/3257 [00:17<00:04, 131.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:17<00:03, 144.96it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:17<00:03, 145.92it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2772/3257 [00:17<00:03, 139.36it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2791/3257 [00:17<00:03, 152.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:17<00:02, 151.25it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:18<00:05, 74.09it/s]  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2835/3257 [00:18<00:05, 81.08it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:18<00:04, 98.37it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2875/3257 [00:18<00:03, 122.96it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2891/3257 [00:18<00:02, 130.85it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:18<00:02, 129.46it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2927/3257 [00:18<00:02, 146.67it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2944/3257 [00:19<00:02, 134.18it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2959/3257 [00:19<00:02, 137.21it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:19<00:01, 140.51it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2991/3257 [00:19<00:01, 139.37it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:19<00:01, 151.42it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3028/3257 [00:19<00:01, 151.01it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:19<00:01, 159.86it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3067/3257 [00:19<00:01, 167.49it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3084/3257 [00:19<00:01, 164.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3101/3257 [00:20<00:00, 163.40it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3120/3257 [00:20<00:00, 168.90it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3137/3257 [00:20<00:00, 159.94it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3154/3257 [00:20<00:00, 153.32it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3170/3257 [00:20<00:00, 153.19it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3186/3257 [00:20<00:00, 146.80it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3204/3257 [00:20<00:00, 153.95it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3220/3257 [00:20<00:00, 145.98it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:20<00:00, 155.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3255/3257 [00:21<00:00, 153.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 154.52it/s]
2023-02-07 20:20:34.023 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:20:34,024][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d285,n5,mc4,s0.497343,t4>', 'datetime': '2023-02-07T20:20:34.024552', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:20:34,024][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:20:34,025][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:20:34,685][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:20:34,685][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:20:34,793][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 retains 36921 unique words (68.30% of original 54054, drops 17133)', 'datetime': '2023-02-07T20:20:34.793567', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:20:34,794][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 leaves 6522479 word corpus (99.57% of original 6550866, drops 28387)', 'datetime': '2023-02-07T20:20:34.793995', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:20:34,928][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:20:34,929][gensim.models.word2vec][INFO] - sample=0.497343 downsamples 0 most-common words
[2023-02-07 20:20:34,929][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6522479 word corpus (100.0%% of prior 6522479)', 'datetime': '2023-02-07T20:20:34.929889', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:20:35,166][gensim.models.word2vec][INFO] - estimated required memory for 36921 words and 285 dimensions: 107004760 bytes
[2023-02-07 20:20:35,167][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:20:35,214][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 36921 vocabulary and 285 features, using sg=1 hs=0 sample=0.49734289418959066 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T20:20:35.214836', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:20:36,220][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 25.79% examples, 1659546 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:37,233][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 51.89% examples, 1701605 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:38,238][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 79.24% examples, 1715769 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:38,960][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6467889 effective words) took 3.7s, 1727672 effective words/s
[2023-02-07 20:20:39,968][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 29.66% examples, 1905353 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:40,970][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 57.84% examples, 1903357 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:41,973][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 85.78% examples, 1857719 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:42,461][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6467889 effective words) took 3.5s, 1848281 effective words/s
[2023-02-07 20:20:43,473][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 28.55% examples, 1831189 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:44,474][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 56.09% examples, 1847151 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:45,477][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 84.99% examples, 1841854 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:45,970][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6467889 effective words) took 3.5s, 1844280 effective words/s
[2023-02-07 20:20:46,973][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 28.89% examples, 1871767 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:47,977][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 57.35% examples, 1888597 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:48,977][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 86.95% examples, 1888656 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:20:49,386][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6467889 effective words) took 3.4s, 1894184 effective words/s
[2023-02-07 20:20:50,393][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 29.23% examples, 1887531 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:51,394][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 58.21% examples, 1919381 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:52,395][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 88.82% examples, 1924247 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:52,749][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6467889 effective words) took 3.4s, 1925261 effective words/s
[2023-02-07 20:20:53,753][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 29.75% examples, 1920536 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:54,761][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 58.80% examples, 1928572 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:55,764][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 88.67% examples, 1914109 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:56,131][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6467889 effective words) took 3.4s, 1913354 effective words/s
[2023-02-07 20:20:57,135][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 29.90% examples, 1931080 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:58,136][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 58.80% examples, 1936175 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:59,142][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 89.41% examples, 1934418 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:59,475][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6467889 effective words) took 3.3s, 1935935 effective words/s
[2023-02-07 20:21:00,481][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 29.08% examples, 1875462 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:21:01,484][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 57.14% examples, 1881195 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:02,487][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 87.57% examples, 1898114 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:02,876][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6467889 effective words) took 3.4s, 1902519 effective words/s
[2023-02-07 20:21:03,881][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 29.66% examples, 1912527 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:04,882][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 58.83% examples, 1939333 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:05,884][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 89.16% examples, 1932683 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:21:06,224][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6467889 effective words) took 3.3s, 1933328 effective words/s
[2023-02-07 20:21:07,228][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 29.66% examples, 1911521 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:21:08,229][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 58.27% examples, 1920361 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:09,232][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 88.82% examples, 1923746 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:09,583][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6467889 effective words) took 3.4s, 1926044 effective words/s
[2023-02-07 20:21:10,586][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 29.75% examples, 1922578 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:11,590][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 54.19% examples, 1788632 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:12,591][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 83.82% examples, 1821720 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:13,110][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6467889 effective words) took 3.5s, 1834595 effective words/s
[2023-02-07 20:21:14,115][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 29.08% examples, 1877769 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:15,116][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 57.45% examples, 1894233 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:16,121][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 87.35% examples, 1895891 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:16,514][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6467889 effective words) took 3.4s, 1901352 effective words/s
[2023-02-07 20:21:17,522][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 29.66% examples, 1904546 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:18,522][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 58.21% examples, 1916578 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:21:19,526][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 88.58% examples, 1911444 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:19,892][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6467889 effective words) took 3.4s, 1915712 effective words/s
[2023-02-07 20:21:20,896][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 30.03% examples, 1938127 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:21,896][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 58.92% examples, 1944899 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:22,901][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 89.41% examples, 1934999 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:23,233][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6467889 effective words) took 3.3s, 1936795 effective words/s
[2023-02-07 20:21:24,235][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 29.23% examples, 1891652 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:25,241][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 57.84% examples, 1904915 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:26,245][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 88.42% examples, 1908574 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:26,615][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6467889 effective words) took 3.4s, 1913207 effective words/s
[2023-02-07 20:21:26,616][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (97018335 effective words) took 51.4s, 1887488 effective words/s', 'datetime': '2023-02-07T20:21:26.616093', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:21:26.616 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:21:32,706][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202003-viymrlb0/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:21:32.706330', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:21:32,707][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202003-viymrlb0/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 20:21:32,748][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202003-viymrlb0/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 20:21:32,788][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:21:32,834][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202003-viymrlb0/files/../tmp/embedding_model.pt
2023-02-07 20:21:32.834 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:21:34.849 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:21:35.539 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:21:50.569 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9742734028014052, 'test_mae': 0.7368584341523837, 'test_r2': -1.8646727113334922}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.85
wandb: percentage 0.31696
wandb:   test_mae 0.73686
wandb:   test_mse 0.97427
wandb:    test_r2 -1.86467
wandb: 
wandb: üöÄ View run twilight-sweep-76 at: https://wandb.ai/xiaoqiz/mof2vec/runs/viymrlb0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_202003-viymrlb0/logs
wandb: Agent Starting Run: d7txvkx9 with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 908
wandb: 	model.gensim.alpha: 0.005325156600319271
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.7648070337035908
wandb: 	model.gensim.vector_size: 147
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.0071287790055670885
wandb: 	model.sklearn.max_depth: 43
wandb: 	model.sklearn.min_child_weight: 0.08621716063323676
wandb: 	model.sklearn.n_estimators: 821
wandb: 	model.sklearn.num_leaves: 341
wandb: 	model.sklearn.reg_alpha: 0.004087553875555666
wandb: 	model.sklearn.reg_lambda: 0.021625402341577404
wandb: 	model.sklearn.subsample: 0.7057217008063712
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202204-d7txvkx9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-77
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/d7txvkx9
2023-02-07 20:22:12.536 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:22:12.537 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 908 for sweep.
2023-02-07 20:22:12.537 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.005325156600319271 for sweep.
2023-02-07 20:22:12.538 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:22:12.538 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 20:22:12.538 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7648070337035908 for sweep.
2023-02-07 20:22:12.538 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 147 for sweep.
2023-02-07 20:22:12.539 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 20:22:12.539 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0071287790055670885 for sweep.
2023-02-07 20:22:12.540 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 43 for sweep.
2023-02-07 20:22:12.540 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08621716063323676 for sweep.
2023-02-07 20:22:12.540 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 821 for sweep.
2023-02-07 20:22:12.541 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 341 for sweep.
2023-02-07 20:22:12.541 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004087553875555666 for sweep.
2023-02-07 20:22:12.541 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.021625402341577404 for sweep.
2023-02-07 20:22:12.541 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7057217008063712 for sweep.
2023-02-07 20:22:12.542 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:22:12.548 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202204-d7txvkx9/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 908, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 147, 'window': 2, 'min_count': 2, 'dm': 0, 'sample': 0.7648070337035908, 'workers': 4, 'alpha': 0.005325156600319271, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 821, 'max_depth': 43, 'num_leaves': 341, 'reg_alpha': 0.004087553875555666, 'reg_lambda': 0.021625402341577404, 'subsample': 0.7057217008063712, 'min_child_weight': 0.08621716063323676, 'n_jobs': 4, 'learning_rate': 0.0071287790055670885}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 137.20it/s]  1%|          | 30/3257 [00:00<00:21, 148.13it/s]  1%|‚ñè         | 45/3257 [00:00<00:21, 147.48it/s]  2%|‚ñè         | 60/3257 [00:00<00:22, 140.30it/s]  2%|‚ñè         | 77/3257 [00:00<00:21, 150.10it/s]  3%|‚ñé         | 93/3257 [00:00<00:20, 150.90it/s]  3%|‚ñé         | 109/3257 [00:00<00:22, 141.25it/s]  4%|‚ñç         | 125/3257 [00:00<00:21, 144.18it/s]  4%|‚ñç         | 144/3257 [00:00<00:19, 157.22it/s]  5%|‚ñç         | 160/3257 [00:01<00:20, 151.87it/s]  5%|‚ñå         | 176/3257 [00:01<00:20, 148.79it/s]  6%|‚ñå         | 195/3257 [00:01<00:19, 157.73it/s]  7%|‚ñã         | 213/3257 [00:01<00:18, 162.79it/s]  7%|‚ñã         | 233/3257 [00:01<00:17, 172.48it/s]  8%|‚ñä         | 251/3257 [00:01<00:17, 169.57it/s]  8%|‚ñä         | 269/3257 [00:01<00:18, 160.42it/s]  9%|‚ñâ         | 292/3257 [00:01<00:16, 179.09it/s] 10%|‚ñâ         | 311/3257 [00:01<00:16, 174.02it/s] 10%|‚ñà         | 329/3257 [00:02<00:17, 172.20it/s] 11%|‚ñà         | 347/3257 [00:02<00:17, 166.87it/s] 11%|‚ñà         | 366/3257 [00:02<00:17, 168.89it/s] 12%|‚ñà‚ñè        | 383/3257 [00:02<00:17, 159.92it/s] 12%|‚ñà‚ñè        | 400/3257 [00:02<00:18, 156.01it/s] 13%|‚ñà‚ñé        | 418/3257 [00:02<00:17, 162.14it/s] 13%|‚ñà‚ñé        | 435/3257 [00:02<00:21, 132.96it/s] 14%|‚ñà‚ñç        | 453/3257 [00:02<00:19, 143.28it/s] 14%|‚ñà‚ñç        | 472/3257 [00:03<00:18, 154.26it/s] 15%|‚ñà‚ñå        | 489/3257 [00:03<00:18, 152.10it/s] 16%|‚ñà‚ñå        | 508/3257 [00:03<00:16, 162.26it/s] 16%|‚ñà‚ñå        | 525/3257 [00:03<00:17, 159.65it/s] 17%|‚ñà‚ñã        | 543/3257 [00:03<00:16, 163.00it/s] 17%|‚ñà‚ñã        | 560/3257 [00:03<00:17, 150.35it/s] 18%|‚ñà‚ñä        | 576/3257 [00:03<00:19, 140.94it/s] 18%|‚ñà‚ñä        | 595/3257 [00:03<00:17, 152.12it/s] 19%|‚ñà‚ñâ        | 613/3257 [00:03<00:16, 159.27it/s] 19%|‚ñà‚ñâ        | 630/3257 [00:04<00:16, 155.54it/s] 20%|‚ñà‚ñâ        | 646/3257 [00:04<00:17, 149.74it/s] 20%|‚ñà‚ñà        | 662/3257 [00:04<00:18, 142.96it/s] 21%|‚ñà‚ñà        | 682/3257 [00:04<00:16, 156.52it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:04<00:17, 147.68it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:16, 158.64it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:04<00:16, 154.35it/s] 23%|‚ñà‚ñà‚ñé       | 751/3257 [00:04<00:16, 147.49it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:04<00:15, 155.89it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:05<00:16, 149.66it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:15, 155.08it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:15, 153.12it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:05<00:16, 145.89it/s] 26%|‚ñà‚ñà‚ñå       | 851/3257 [00:05<00:16, 142.92it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:05<00:16, 148.32it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:05<00:16, 144.95it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:14, 158.77it/s] 28%|‚ñà‚ñà‚ñä       | 921/3257 [00:05<00:14, 157.83it/s] 29%|‚ñà‚ñà‚ñâ       | 937/3257 [00:06<00:14, 156.08it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:06<00:14, 162.03it/s] 30%|‚ñà‚ñà‚ñâ       | 973/3257 [00:06<00:23, 99.15it/s]  30%|‚ñà‚ñà‚ñà       | 988/3257 [00:06<00:21, 107.52it/s] 31%|‚ñà‚ñà‚ñà       | 1005/3257 [00:06<00:18, 120.49it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1020/3257 [00:06<00:17, 126.18it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1035/3257 [00:06<00:17, 125.73it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1049/3257 [00:07<00:17, 127.89it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1066/3257 [00:07<00:15, 138.20it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1081/3257 [00:07<00:15, 138.05it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:07<00:15, 141.58it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:07<00:14, 149.48it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1131/3257 [00:07<00:15, 140.82it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1146/3257 [00:07<00:14, 141.72it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1165/3257 [00:07<00:13, 154.76it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1181/3257 [00:07<00:14, 141.94it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1196/3257 [00:08<00:15, 136.29it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:08<00:15, 133.25it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1229/3257 [00:08<00:13, 147.96it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:08<00:13, 146.14it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:08<00:13, 150.55it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1278/3257 [00:08<00:14, 140.27it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1293/3257 [00:08<00:14, 138.04it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:08<00:13, 140.57it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1325/3257 [00:08<00:13, 148.50it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1342/3257 [00:09<00:12, 152.16it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1358/3257 [00:09<00:12, 147.17it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1373/3257 [00:09<00:13, 142.80it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:09<00:13, 143.00it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1406/3257 [00:09<00:12, 152.56it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1425/3257 [00:09<00:11, 161.51it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1442/3257 [00:09<00:11, 161.96it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1462/3257 [00:09<00:10, 170.57it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1480/3257 [00:09<00:10, 166.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1499/3257 [00:10<00:10, 173.29it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1517/3257 [00:10<00:10, 168.88it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1534/3257 [00:10<00:11, 147.63it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:10<00:11, 146.66it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1565/3257 [00:10<00:11, 144.33it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1580/3257 [00:10<00:11, 143.01it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:10<00:11, 144.81it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1614/3257 [00:10<00:10, 154.24it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1630/3257 [00:10<00:10, 154.49it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1646/3257 [00:11<00:11, 145.70it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:11<00:11, 139.29it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:11<00:11, 141.08it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:11<00:10, 142.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:11<00:10, 147.10it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1724/3257 [00:11<00:10, 150.23it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1740/3257 [00:11<00:11, 134.27it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1759/3257 [00:11<00:10, 147.33it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1775/3257 [00:11<00:09, 150.21it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1793/3257 [00:12<00:09, 156.48it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1809/3257 [00:12<00:09, 146.15it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:12<00:09, 147.86it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1844/3257 [00:12<00:09, 155.02it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1860/3257 [00:12<00:09, 153.28it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1878/3257 [00:12<00:08, 160.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:12<00:08, 152.65it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1914/3257 [00:12<00:08, 161.59it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:12<00:08, 153.47it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:13<00:07, 172.46it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1973/3257 [00:13<00:07, 175.25it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1991/3257 [00:13<00:07, 164.68it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:13<00:07, 160.98it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2027/3257 [00:13<00:07, 168.42it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2045/3257 [00:13<00:07, 159.29it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2062/3257 [00:13<00:08, 142.59it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2079/3257 [00:13<00:07, 149.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2095/3257 [00:13<00:07, 150.49it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2111/3257 [00:14<00:07, 149.53it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2127/3257 [00:14<00:08, 139.78it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2142/3257 [00:14<00:07, 140.13it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2157/3257 [00:14<00:12, 86.34it/s]  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2176/3257 [00:14<00:10, 105.48it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2190/3257 [00:14<00:09, 111.90it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:14<00:08, 124.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2229/3257 [00:15<00:07, 141.99it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2245/3257 [00:15<00:06, 146.44it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2263/3257 [00:15<00:06, 155.16it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2280/3257 [00:15<00:06, 155.79it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:15<00:05, 164.60it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2322/3257 [00:15<00:05, 182.15it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2346/3257 [00:15<00:04, 197.23it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2367/3257 [00:15<00:04, 198.86it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2390/3257 [00:15<00:04, 207.23it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2411/3257 [00:16<00:04, 194.73it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2431/3257 [00:16<00:04, 184.93it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2450/3257 [00:16<00:04, 177.25it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:16<00:04, 194.43it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2495/3257 [00:16<00:03, 191.85it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2515/3257 [00:16<00:03, 191.40it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2536/3257 [00:16<00:03, 193.76it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2556/3257 [00:16<00:04, 174.37it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2574/3257 [00:16<00:04, 162.07it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2591/3257 [00:17<00:04, 153.86it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2613/3257 [00:17<00:03, 169.70it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2631/3257 [00:17<00:03, 172.38it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2649/3257 [00:17<00:03, 158.70it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2666/3257 [00:17<00:03, 154.82it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2684/3257 [00:17<00:03, 158.94it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2701/3257 [00:17<00:04, 138.86it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2716/3257 [00:17<00:03, 136.93it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2737/3257 [00:18<00:03, 153.09it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2754/3257 [00:18<00:03, 156.87it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2771/3257 [00:18<00:03, 148.66it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2791/3257 [00:18<00:02, 159.55it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2808/3257 [00:18<00:02, 155.75it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2824/3257 [00:18<00:02, 145.96it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2839/3257 [00:18<00:02, 145.10it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2858/3257 [00:18<00:02, 156.37it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2880/3257 [00:18<00:02, 171.83it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2898/3257 [00:19<00:02, 152.23it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2914/3257 [00:19<00:02, 152.98it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2930/3257 [00:19<00:02, 146.06it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2945/3257 [00:19<00:02, 140.15it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2960/3257 [00:19<00:02, 138.85it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:19<00:02, 139.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2991/3257 [00:19<00:01, 135.52it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:19<00:01, 151.61it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3027/3257 [00:19<00:01, 145.36it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3045/3257 [00:20<00:01, 153.62it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:20<00:01, 159.97it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3080/3257 [00:20<00:01, 158.55it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3096/3257 [00:20<00:01, 153.89it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3116/3257 [00:20<00:00, 166.81it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3133/3257 [00:20<00:00, 158.30it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3150/3257 [00:20<00:00, 148.51it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:20<00:00, 149.24it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3182/3257 [00:20<00:00, 141.48it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3199/3257 [00:21<00:00, 146.77it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3214/3257 [00:21<00:00, 136.94it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3232/3257 [00:21<00:00, 147.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3250/3257 [00:21<00:00, 155.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 151.57it/s]
2023-02-07 20:22:35.033 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:22:35,035][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d147,n5,mc2,s0.764807,t4>', 'datetime': '2023-02-07T20:22:35.035190', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:22:35,037][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:22:35,037][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:22:35,707][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:22:35,707][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:22:35,840][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 46469 unique words (85.97% of original 54054, drops 7585)', 'datetime': '2023-02-07T20:22:35.840095', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:22:35,840][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 6543281 word corpus (99.88% of original 6550866, drops 7585)', 'datetime': '2023-02-07T20:22:35.840553', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:22:36,011][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:22:36,013][gensim.models.word2vec][INFO] - sample=0.764807 downsamples 0 most-common words
[2023-02-07 20:22:36,013][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6543281 word corpus (100.0%% of prior 6543281)', 'datetime': '2023-02-07T20:22:36.013712', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:22:36,297][gensim.models.word2vec][INFO] - estimated required memory for 46469 words and 147 dimensions: 80448560 bytes
[2023-02-07 20:22:36,297][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:22:36,331][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 46469 vocabulary and 147 features, using sg=1 hs=0 sample=0.7648070337035908 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T20:22:36.331409', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:22:37,336][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 23.00% examples, 1479864 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:38,340][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 45.59% examples, 1504066 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:39,344][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 68.65% examples, 1511016 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:40,347][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 96.19% examples, 1557196 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:40,487][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6488146 effective words) took 4.2s, 1562877 effective words/s
[2023-02-07 20:22:41,494][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 35.19% examples, 2304439 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:42,501][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 69.85% examples, 2305574 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:43,288][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6488146 effective words) took 2.8s, 2317091 effective words/s
[2023-02-07 20:22:44,293][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 35.55% examples, 2329245 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:45,298][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 70.56% examples, 2328495 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:46,084][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6488146 effective words) took 2.8s, 2321676 effective words/s
[2023-02-07 20:22:47,090][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 35.55% examples, 2327444 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:48,092][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 69.76% examples, 2308261 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:48,893][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6488146 effective words) took 2.8s, 2311158 effective words/s
[2023-02-07 20:22:49,898][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 34.33% examples, 2243349 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:50,900][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 68.99% examples, 2282044 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:51,702][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6488146 effective words) took 2.8s, 2312719 effective words/s
[2023-02-07 20:22:52,708][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 35.19% examples, 2307194 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:53,709][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 70.59% examples, 2331505 words/s, in_qsize 6, out_qsize 1
[2023-02-07 20:22:54,468][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6488146 effective words) took 2.8s, 2346625 effective words/s
[2023-02-07 20:22:55,472][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 36.08% examples, 2364413 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:56,473][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 71.48% examples, 2359144 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:57,205][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6488146 effective words) took 2.7s, 2372370 effective words/s
[2023-02-07 20:22:58,208][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 36.17% examples, 2377592 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:59,208][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 72.64% examples, 2391051 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:59,917][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6488146 effective words) took 2.7s, 2394372 effective words/s
[2023-02-07 20:23:00,920][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 36.17% examples, 2374521 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:01,921][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 72.46% examples, 2384608 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:02,631][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6488146 effective words) took 2.7s, 2391735 effective words/s
[2023-02-07 20:23:03,633][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.29% examples, 2385922 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:04,635][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 71.81% examples, 2369427 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:05,376][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6488146 effective words) took 2.7s, 2365069 effective words/s
[2023-02-07 20:23:06,381][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 35.92% examples, 2354301 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:07,382][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 71.81% examples, 2367265 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:08,102][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6488146 effective words) took 2.7s, 2381751 effective words/s
[2023-02-07 20:23:09,106][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 36.17% examples, 2372885 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:10,108][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 72.77% examples, 2390658 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:23:10,801][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6488146 effective words) took 2.7s, 2404960 effective words/s
[2023-02-07 20:23:11,804][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 36.23% examples, 2388179 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:12,806][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 73.10% examples, 2403259 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:13,499][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6488146 effective words) took 2.7s, 2407225 effective words/s
[2023-02-07 20:23:14,502][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 36.94% examples, 2444895 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:15,503][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 73.84% examples, 2426919 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:16,161][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6488146 effective words) took 2.7s, 2438150 effective words/s
[2023-02-07 20:23:17,163][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 36.57% examples, 2410653 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:18,165][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 73.84% examples, 2427324 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:18,842][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6488146 effective words) took 2.7s, 2421615 effective words/s
[2023-02-07 20:23:18,842][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (97322190 effective words) took 42.5s, 2289363 effective words/s', 'datetime': '2023-02-07T20:23:18.842512', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:23:18.842 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:23:22,129][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202204-d7txvkx9/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:23:22.129114', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:23:22,129][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:23:22,230][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202204-d7txvkx9/files/../tmp/embedding_model.pt
2023-02-07 20:23:22.231 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:23:23.486 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:23:23.938 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:23:33.236 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9642858440890544, 'test_mae': 0.7586926792753986, 'test_r2': -1.6636856312061372}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.79
wandb: percentage 0.14032
wandb:   test_mae 0.75869
wandb:   test_mse 0.96429
wandb:    test_r2 -1.66369
wandb: 
wandb: üöÄ View run logical-sweep-77 at: https://wandb.ai/xiaoqiz/mof2vec/runs/d7txvkx9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_202204-d7txvkx9/logs
wandb: Agent Starting Run: dfp9z53y with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 689
wandb: 	model.gensim.alpha: 0.001243065903350752
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.2754164747432076
wandb: 	model.gensim.vector_size: 379
wandb: 	model.gensim.window: 13
wandb: 	model.sklearn.learning_rate: 0.2185363570671595
wandb: 	model.sklearn.max_depth: 22
wandb: 	model.sklearn.min_child_weight: 0.06365307593874654
wandb: 	model.sklearn.n_estimators: 2204
wandb: 	model.sklearn.num_leaves: 287
wandb: 	model.sklearn.reg_alpha: 0.03624178331147256
wandb: 	model.sklearn.reg_lambda: 0.048980820627870285
wandb: 	model.sklearn.subsample: 0.4520885038997416
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202344-dfp9z53y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-78
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/dfp9z53y
2023-02-07 20:23:52.292 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:23:52.293 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 689 for sweep.
2023-02-07 20:23:52.293 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.001243065903350752 for sweep.
2023-02-07 20:23:52.293 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:23:52.293 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 20:23:52.294 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2754164747432076 for sweep.
2023-02-07 20:23:52.294 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 379 for sweep.
2023-02-07 20:23:52.294 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 13 for sweep.
2023-02-07 20:23:52.294 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.2185363570671595 for sweep.
2023-02-07 20:23:52.295 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 22 for sweep.
2023-02-07 20:23:52.295 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.06365307593874654 for sweep.
2023-02-07 20:23:52.295 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2204 for sweep.
2023-02-07 20:23:52.295 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 287 for sweep.
2023-02-07 20:23:52.296 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.03624178331147256 for sweep.
2023-02-07 20:23:52.296 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.048980820627870285 for sweep.
2023-02-07 20:23:52.296 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.4520885038997416 for sweep.
2023-02-07 20:23:52.296 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:23:52.304 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202344-dfp9z53y/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 689, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 379, 'window': 13, 'min_count': 9, 'dm': 0, 'sample': 0.2754164747432076, 'workers': 4, 'alpha': 0.001243065903350752, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2204, 'max_depth': 22, 'num_leaves': 287, 'reg_alpha': 0.03624178331147256, 'reg_lambda': 0.048980820627870285, 'subsample': 0.4520885038997416, 'min_child_weight': 0.06365307593874654, 'n_jobs': 4, 'learning_rate': 0.2185363570671595}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 137.34it/s]  1%|          | 32/3257 [00:00<00:20, 160.68it/s]  2%|‚ñè         | 49/3257 [00:00<00:20, 159.32it/s]  2%|‚ñè         | 65/3257 [00:00<00:20, 155.72it/s]  2%|‚ñè         | 81/3257 [00:00<00:20, 151.30it/s]  3%|‚ñé         | 97/3257 [00:00<00:20, 151.13it/s]  3%|‚ñé         | 113/3257 [00:00<00:20, 150.28it/s]  4%|‚ñç         | 131/3257 [00:00<00:19, 157.00it/s]  5%|‚ñç         | 151/3257 [00:00<00:18, 164.96it/s]  5%|‚ñå         | 168/3257 [00:01<00:19, 161.99it/s]  6%|‚ñå         | 185/3257 [00:01<00:18, 162.18it/s]  6%|‚ñå         | 202/3257 [00:01<00:18, 161.84it/s]  7%|‚ñã         | 224/3257 [00:01<00:17, 178.27it/s]  7%|‚ñã         | 243/3257 [00:01<00:16, 180.65it/s]  8%|‚ñä         | 262/3257 [00:01<00:17, 173.59it/s]  9%|‚ñâ         | 285/3257 [00:01<00:15, 189.31it/s]  9%|‚ñâ         | 305/3257 [00:01<00:16, 182.34it/s] 10%|‚ñà         | 326/3257 [00:01<00:15, 187.34it/s] 11%|‚ñà         | 345/3257 [00:02<00:23, 124.79it/s] 11%|‚ñà         | 364/3257 [00:02<00:20, 137.99it/s] 12%|‚ñà‚ñè        | 381/3257 [00:02<00:20, 140.81it/s] 12%|‚ñà‚ñè        | 398/3257 [00:02<00:19, 144.30it/s] 13%|‚ñà‚ñé        | 417/3257 [00:02<00:18, 155.79it/s] 13%|‚ñà‚ñé        | 434/3257 [00:02<00:20, 136.09it/s] 14%|‚ñà‚ñç        | 452/3257 [00:02<00:19, 146.28it/s] 14%|‚ñà‚ñç        | 472/3257 [00:03<00:17, 157.80it/s] 15%|‚ñà‚ñå        | 489/3257 [00:03<00:17, 160.09it/s] 16%|‚ñà‚ñå        | 510/3257 [00:03<00:16, 171.57it/s] 16%|‚ñà‚ñå        | 528/3257 [00:03<00:16, 166.38it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:16, 168.54it/s] 17%|‚ñà‚ñã        | 564/3257 [00:03<00:17, 155.70it/s] 18%|‚ñà‚ñä        | 580/3257 [00:03<00:17, 154.40it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:16, 162.15it/s] 19%|‚ñà‚ñâ        | 619/3257 [00:03<00:15, 172.29it/s] 20%|‚ñà‚ñâ        | 637/3257 [00:03<00:15, 166.16it/s] 20%|‚ñà‚ñà        | 654/3257 [00:04<00:16, 159.75it/s] 21%|‚ñà‚ñà        | 671/3257 [00:04<00:16, 157.68it/s] 21%|‚ñà‚ñà        | 687/3257 [00:04<00:16, 153.94it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:04<00:16, 157.38it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:04<00:16, 158.07it/s] 23%|‚ñà‚ñà‚ñé       | 737/3257 [00:04<00:16, 151.51it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:04<00:16, 154.23it/s] 24%|‚ñà‚ñà‚ñé       | 772/3257 [00:04<00:15, 160.54it/s] 24%|‚ñà‚ñà‚ñç       | 789/3257 [00:04<00:15, 156.24it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:05<00:15, 156.25it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:05<00:16, 151.85it/s] 26%|‚ñà‚ñà‚ñå       | 839/3257 [00:05<00:16, 150.90it/s] 26%|‚ñà‚ñà‚ñã       | 855/3257 [00:05<00:16, 144.89it/s] 27%|‚ñà‚ñà‚ñã       | 872/3257 [00:05<00:15, 151.55it/s] 27%|‚ñà‚ñà‚ñã       | 888/3257 [00:05<00:15, 151.44it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:05<00:14, 160.19it/s] 28%|‚ñà‚ñà‚ñä       | 926/3257 [00:05<00:13, 168.65it/s] 29%|‚ñà‚ñà‚ñâ       | 943/3257 [00:05<00:14, 162.51it/s] 30%|‚ñà‚ñà‚ñâ       | 961/3257 [00:06<00:13, 167.31it/s] 30%|‚ñà‚ñà‚ñà       | 979/3257 [00:06<00:13, 163.85it/s] 31%|‚ñà‚ñà‚ñà       | 996/3257 [00:06<00:14, 158.54it/s] 31%|‚ñà‚ñà‚ñà       | 1012/3257 [00:06<00:14, 157.54it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1028/3257 [00:06<00:14, 153.71it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1044/3257 [00:06<00:14, 151.72it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1061/3257 [00:06<00:14, 153.37it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:14, 154.51it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:06<00:13, 157.73it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:07<00:13, 160.82it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1132/3257 [00:07<00:14, 151.19it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1148/3257 [00:07<00:14, 148.97it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:13, 160.17it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:07<00:13, 150.33it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1203/3257 [00:07<00:14, 141.94it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:07<00:14, 143.22it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1240/3257 [00:07<00:12, 162.02it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:08<00:12, 155.26it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:08<00:12, 153.05it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:08<00:13, 145.95it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1307/3257 [00:08<00:13, 149.29it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1324/3257 [00:08<00:12, 154.54it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1342/3257 [00:08<00:11, 161.27it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1359/3257 [00:08<00:12, 156.90it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1375/3257 [00:08<00:12, 153.42it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1391/3257 [00:08<00:12, 151.51it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1411/3257 [00:08<00:11, 164.57it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1431/3257 [00:09<00:10, 174.29it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1449/3257 [00:09<00:10, 171.83it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1467/3257 [00:09<00:16, 108.52it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1484/3257 [00:09<00:14, 119.65it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1506/3257 [00:09<00:12, 141.12it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1523/3257 [00:09<00:12, 138.45it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1539/3257 [00:09<00:12, 139.32it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:10<00:12, 140.31it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:10<00:11, 149.69it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:10<00:10, 152.62it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1611/3257 [00:10<00:10, 163.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1630/3257 [00:10<00:09, 170.00it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1648/3257 [00:10<00:10, 154.96it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1664/3257 [00:10<00:10, 154.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1681/3257 [00:10<00:10, 155.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:10<00:09, 162.62it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1717/3257 [00:11<00:09, 154.63it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1733/3257 [00:11<00:11, 137.49it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1748/3257 [00:11<00:10, 137.35it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:11<00:10, 139.60it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:11<00:10, 141.49it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1795/3257 [00:11<00:10, 144.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1810/3257 [00:11<00:10, 134.13it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1825/3257 [00:11<00:10, 135.28it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1839/3257 [00:11<00:10, 133.68it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1853/3257 [00:12<00:10, 132.79it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:12<00:10, 137.30it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1884/3257 [00:12<00:09, 139.25it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1898/3257 [00:12<00:10, 135.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1915/3257 [00:12<00:09, 144.05it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1930/3257 [00:12<00:10, 130.54it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1949/3257 [00:12<00:08, 146.26it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:12<00:08, 149.94it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1981/3257 [00:12<00:08, 145.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1997/3257 [00:13<00:08, 149.04it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2013/3257 [00:13<00:08, 145.31it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2031/3257 [00:13<00:08, 153.24it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2047/3257 [00:13<00:09, 134.04it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2061/3257 [00:13<00:09, 125.33it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2078/3257 [00:13<00:08, 131.50it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2093/3257 [00:13<00:08, 134.37it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2107/3257 [00:13<00:08, 131.03it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:14<00:09, 121.49it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:14<00:08, 127.47it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2149/3257 [00:14<00:08, 123.76it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:14<00:08, 133.76it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2180/3257 [00:14<00:08, 134.61it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2194/3257 [00:14<00:07, 135.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2208/3257 [00:14<00:07, 133.55it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2222/3257 [00:14<00:07, 134.33it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:14<00:07, 134.96it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2250/3257 [00:15<00:07, 129.92it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2264/3257 [00:15<00:07, 131.81it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2278/3257 [00:15<00:07, 123.78it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2296/3257 [00:15<00:07, 136.47it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2310/3257 [00:15<00:07, 133.07it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2329/3257 [00:15<00:06, 147.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2346/3257 [00:15<00:06, 151.41it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2362/3257 [00:15<00:05, 152.83it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2378/3257 [00:15<00:05, 151.57it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2396/3257 [00:16<00:05, 156.92it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2412/3257 [00:16<00:05, 145.25it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2427/3257 [00:16<00:05, 145.81it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2442/3257 [00:16<00:06, 132.42it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2458/3257 [00:16<00:05, 138.14it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:16<00:05, 144.03it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2490/3257 [00:16<00:05, 144.17it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2508/3257 [00:16<00:04, 152.56it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:16<00:04, 153.74it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:16<00:04, 153.16it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2556/3257 [00:17<00:04, 145.11it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2571/3257 [00:17<00:05, 135.39it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2585/3257 [00:17<00:05, 133.76it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2599/3257 [00:17<00:04, 135.17it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2619/3257 [00:17<00:04, 150.20it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2636/3257 [00:17<00:04, 154.84it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2652/3257 [00:17<00:04, 141.50it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2667/3257 [00:17<00:04, 143.56it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2684/3257 [00:18<00:03, 148.78it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2700/3257 [00:18<00:04, 127.61it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2715/3257 [00:18<00:04, 125.71it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:18<00:07, 74.62it/s]  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2751/3257 [00:18<00:05, 92.55it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2766/3257 [00:18<00:04, 102.80it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2780/3257 [00:19<00:04, 108.43it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2798/3257 [00:19<00:03, 123.74it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:19<00:03, 126.16it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2828/3257 [00:19<00:03, 124.68it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:19<00:03, 126.55it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2861/3257 [00:19<00:02, 142.60it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2881/3257 [00:19<00:02, 154.49it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2897/3257 [00:19<00:02, 140.88it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2913/3257 [00:19<00:02, 145.65it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2929/3257 [00:20<00:02, 142.36it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2944/3257 [00:20<00:02, 134.58it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2958/3257 [00:20<00:02, 134.50it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2975/3257 [00:20<00:01, 142.41it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2990/3257 [00:20<00:01, 133.64it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3010/3257 [00:20<00:01, 151.03it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:20<00:01, 144.32it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3045/3257 [00:20<00:01, 156.13it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:20<00:01, 162.46it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3080/3257 [00:21<00:01, 162.40it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3097/3257 [00:21<00:01, 156.48it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:21<00:00, 166.14it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3135/3257 [00:21<00:00, 156.05it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3151/3257 [00:21<00:00, 147.78it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:21<00:00, 146.61it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3181/3257 [00:21<00:00, 138.09it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3198/3257 [00:21<00:00, 145.14it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:22<00:00, 137.60it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3230/3257 [00:22<00:00, 145.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3248/3257 [00:22<00:00, 155.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 146.23it/s]
2023-02-07 20:24:15.602 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:24:15,604][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d379,n5,mc9,s0.275416,t4>', 'datetime': '2023-02-07T20:24:15.604440', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:24:15,605][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:24:15,605][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:24:16,213][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:24:16,213][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:24:16,275][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 18315 unique words (33.88% of original 54054, drops 35739)', 'datetime': '2023-02-07T20:24:16.275905', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:24:16,276][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 6422560 word corpus (98.04% of original 6550866, drops 128306)', 'datetime': '2023-02-07T20:24:16.276309', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:24:16,339][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:24:16,340][gensim.models.word2vec][INFO] - sample=0.275416 downsamples 0 most-common words
[2023-02-07 20:24:16,341][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6422560 word corpus (100.0%% of prior 6422560)', 'datetime': '2023-02-07T20:24:16.341073', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:24:16,444][gensim.models.word2vec][INFO] - estimated required memory for 18315 words and 379 dimensions: 70277592 bytes
[2023-02-07 20:24:16,444][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:24:16,480][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18315 vocabulary and 379 features, using sg=1 hs=0 sample=0.2754164747432076 negative=5 window=13 shrink_windows=True', 'datetime': '2023-02-07T20:24:16.479969', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:24:17,485][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 30.12% examples, 1923374 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:18,490][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 57.51% examples, 1861159 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:19,493][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 81.27% examples, 1733430 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:20,233][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6368654 effective words) took 3.8s, 1697691 effective words/s
[2023-02-07 20:24:21,235][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 26.56% examples, 1697287 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:22,239][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 50.94% examples, 1650018 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:23,242][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 79.15% examples, 1695136 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:23,899][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6368654 effective words) took 3.7s, 1737837 effective words/s
[2023-02-07 20:24:24,907][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 30.12% examples, 1917576 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:25,908][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 60.58% examples, 1949633 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:26,911][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 91.86% examples, 1958863 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:27,219][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6368654 effective words) took 3.3s, 1918896 effective words/s
[2023-02-07 20:24:28,229][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 25.79% examples, 1628632 words/s, in_qsize 6, out_qsize 1
[2023-02-07 20:24:29,232][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 50.45% examples, 1627862 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:30,233][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 75.16% examples, 1615474 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:31,168][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6368654 effective words) took 3.9s, 1613244 effective words/s
[2023-02-07 20:24:32,171][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 25.18% examples, 1591854 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:33,175][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 48.42% examples, 1572102 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:34,176][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 73.10% examples, 1571304 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:35,181][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 99.97% examples, 1585194 words/s, in_qsize 1, out_qsize 1
[2023-02-07 20:24:35,185][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6368654 effective words) took 4.0s, 1585926 effective words/s
[2023-02-07 20:24:36,189][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 25.42% examples, 1613555 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:37,190][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 49.89% examples, 1616926 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:38,190][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 75.16% examples, 1620529 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:39,116][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6368654 effective words) took 3.9s, 1620989 effective words/s
[2023-02-07 20:24:40,126][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 25.30% examples, 1595023 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:24:41,127][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 50.14% examples, 1616159 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:42,130][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 75.16% examples, 1615584 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:43,064][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6368654 effective words) took 3.9s, 1614004 effective words/s
[2023-02-07 20:24:44,073][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 25.30% examples, 1595073 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:45,073][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 49.80% examples, 1607850 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:46,076][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 74.92% examples, 1607952 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:47,040][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6368654 effective words) took 4.0s, 1602077 effective words/s
[2023-02-07 20:24:48,052][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 24.78% examples, 1554375 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:49,061][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 48.42% examples, 1561009 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:50,064][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 73.10% examples, 1562738 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:51,064][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 98.83% examples, 1568204 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:51,096][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6368654 effective words) took 4.1s, 1570911 effective words/s
[2023-02-07 20:24:52,104][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 24.78% examples, 1559458 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:53,105][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 48.42% examples, 1569807 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:54,112][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 73.84% examples, 1582585 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:55,105][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6368654 effective words) took 4.0s, 1589025 effective words/s
[2023-02-07 20:24:56,108][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 24.78% examples, 1567992 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:57,114][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 48.42% examples, 1570726 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:58,114][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 73.47% examples, 1576691 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:59,120][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 99.85% examples, 1583329 words/s, in_qsize 2, out_qsize 1
[2023-02-07 20:24:59,128][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6368654 effective words) took 4.0s, 1583736 effective words/s
[2023-02-07 20:25:00,129][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 25.30% examples, 1607082 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:25:01,137][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 49.71% examples, 1604027 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:25:02,141][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 74.64% examples, 1603166 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:25:03,105][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6368654 effective words) took 4.0s, 1601904 effective words/s
[2023-02-07 20:25:04,109][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 24.78% examples, 1568183 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:25:05,124][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 49.09% examples, 1580781 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:25:06,127][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 74.52% examples, 1593103 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:25:07,098][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6368654 effective words) took 4.0s, 1595778 effective words/s
[2023-02-07 20:25:08,109][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 25.36% examples, 1591115 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:25:09,113][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 49.68% examples, 1601223 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:25:10,113][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 74.36% examples, 1593306 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:25:11,112][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6368654 effective words) took 4.0s, 1587376 effective words/s
[2023-02-07 20:25:12,130][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 25.30% examples, 1581515 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:25:13,132][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 49.25% examples, 1584959 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:25:14,133][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 74.52% examples, 1593541 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:25:15,103][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6368654 effective words) took 4.0s, 1596464 effective words/s
[2023-02-07 20:25:15,104][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (95529810 effective words) took 58.6s, 1629539 effective words/s', 'datetime': '2023-02-07T20:25:15.104170', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:25:15.104 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:25:20,635][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202344-dfp9z53y/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:25:20.635762', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:25:20,636][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:25:20,728][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202344-dfp9z53y/files/../tmp/embedding_model.pt
2023-02-07 20:25:20.728 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:25:23.017 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:25:23.809 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:26:26.478 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0788525471589792, 'test_mae': 0.7974602496422873, 'test_r2': -2.878195308562948}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.033 MB uploaded (0.000 MB deduped)wandb: | 0.033 MB of 0.033 MB uploaded (0.000 MB deduped)wandb: / 0.033 MB of 0.033 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.41
wandb: percentage 0.66117
wandb:   test_mae 0.79746
wandb:   test_mse 1.07885
wandb:    test_r2 -2.8782
wandb: 
wandb: üöÄ View run fast-sweep-78 at: https://wandb.ai/xiaoqiz/mof2vec/runs/dfp9z53y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_202344-dfp9z53y/logs
wandb: Agent Starting Run: 26k101j5 with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 423
wandb: 	model.gensim.alpha: 0.08436683008243331
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.6742595286481061
wandb: 	model.gensim.vector_size: 197
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.00590976653687376
wandb: 	model.sklearn.max_depth: 16
wandb: 	model.sklearn.min_child_weight: 0.034379731796537104
wandb: 	model.sklearn.n_estimators: 780
wandb: 	model.sklearn.num_leaves: 475
wandb: 	model.sklearn.reg_alpha: 0.006949456086989741
wandb: 	model.sklearn.reg_lambda: 0.4004477372022321
wandb: 	model.sklearn.subsample: 0.7583234853095357
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202638-26k101j5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-79
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/26k101j5
2023-02-07 20:26:46.545 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:26:46.546 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 423 for sweep.
2023-02-07 20:26:46.546 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.08436683008243331 for sweep.
2023-02-07 20:26:46.546 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:26:46.547 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 20:26:46.547 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6742595286481061 for sweep.
2023-02-07 20:26:46.547 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 197 for sweep.
2023-02-07 20:26:46.547 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 20:26:46.548 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.00590976653687376 for sweep.
2023-02-07 20:26:46.548 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 16 for sweep.
2023-02-07 20:26:46.548 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.034379731796537104 for sweep.
2023-02-07 20:26:46.548 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 780 for sweep.
2023-02-07 20:26:46.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 475 for sweep.
2023-02-07 20:26:46.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.006949456086989741 for sweep.
2023-02-07 20:26:46.550 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.4004477372022321 for sweep.
2023-02-07 20:26:46.550 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7583234853095357 for sweep.
2023-02-07 20:26:46.550 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:26:46.556 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202638-26k101j5/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 423, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 197, 'window': 2, 'min_count': 10, 'dm': 0, 'sample': 0.6742595286481061, 'workers': 4, 'alpha': 0.08436683008243331, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 780, 'max_depth': 16, 'num_leaves': 475, 'reg_alpha': 0.006949456086989741, 'reg_lambda': 0.4004477372022321, 'subsample': 0.7583234853095357, 'min_child_weight': 0.034379731796537104, 'n_jobs': 4, 'learning_rate': 0.00590976653687376}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 138.58it/s]  1%|          | 31/3257 [00:00<00:20, 156.26it/s]  1%|‚ñè         | 47/3257 [00:00<00:20, 154.06it/s]  2%|‚ñè         | 63/3257 [00:00<00:20, 152.83it/s]  2%|‚ñè         | 80/3257 [00:00<00:20, 157.00it/s]  3%|‚ñé         | 96/3257 [00:00<00:20, 154.93it/s]  3%|‚ñé         | 112/3257 [00:00<00:21, 149.26it/s]  4%|‚ñç         | 131/3257 [00:00<00:19, 157.13it/s]  5%|‚ñç         | 149/3257 [00:00<00:19, 163.56it/s]  5%|‚ñå         | 166/3257 [00:01<00:19, 155.50it/s]  6%|‚ñå         | 182/3257 [00:01<00:19, 155.69it/s]  6%|‚ñå         | 201/3257 [00:01<00:19, 157.89it/s]  7%|‚ñã         | 221/3257 [00:01<00:18, 168.65it/s]  7%|‚ñã         | 241/3257 [00:01<00:16, 177.53it/s]  8%|‚ñä         | 259/3257 [00:01<00:17, 168.92it/s]  9%|‚ñä         | 279/3257 [00:01<00:16, 177.51it/s]  9%|‚ñâ         | 297/3257 [00:01<00:16, 176.77it/s] 10%|‚ñâ         | 315/3257 [00:01<00:17, 170.59it/s] 10%|‚ñà         | 334/3257 [00:02<00:16, 175.00it/s] 11%|‚ñà         | 352/3257 [00:02<00:17, 168.11it/s] 11%|‚ñà‚ñè        | 370/3257 [00:02<00:16, 170.47it/s] 12%|‚ñà‚ñè        | 388/3257 [00:02<00:18, 152.68it/s] 12%|‚ñà‚ñè        | 405/3257 [00:02<00:18, 153.71it/s] 13%|‚ñà‚ñé        | 421/3257 [00:02<00:18, 152.66it/s] 13%|‚ñà‚ñé        | 437/3257 [00:02<00:21, 131.88it/s] 14%|‚ñà‚ñç        | 453/3257 [00:02<00:20, 138.38it/s] 14%|‚ñà‚ñç        | 471/3257 [00:02<00:18, 148.45it/s] 15%|‚ñà‚ñç        | 487/3257 [00:03<00:18, 147.05it/s] 16%|‚ñà‚ñå        | 505/3257 [00:03<00:17, 155.64it/s] 16%|‚ñà‚ñå        | 522/3257 [00:03<00:17, 158.41it/s] 17%|‚ñà‚ñã        | 539/3257 [00:03<00:16, 160.27it/s] 17%|‚ñà‚ñã        | 556/3257 [00:03<00:16, 160.44it/s] 18%|‚ñà‚ñä        | 573/3257 [00:03<00:19, 137.50it/s] 18%|‚ñà‚ñä        | 591/3257 [00:03<00:18, 147.62it/s] 19%|‚ñà‚ñä        | 609/3257 [00:03<00:17, 155.09it/s] 19%|‚ñà‚ñâ        | 626/3257 [00:03<00:17, 152.66it/s] 20%|‚ñà‚ñâ        | 643/3257 [00:04<00:16, 155.12it/s] 20%|‚ñà‚ñà        | 659/3257 [00:04<00:18, 141.21it/s] 21%|‚ñà‚ñà        | 678/3257 [00:04<00:16, 151.83it/s] 21%|‚ñà‚ñà‚ñè       | 694/3257 [00:04<00:26, 97.79it/s]  22%|‚ñà‚ñà‚ñè       | 710/3257 [00:04<00:23, 109.69it/s] 22%|‚ñà‚ñà‚ñè       | 724/3257 [00:04<00:22, 113.38it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:04<00:21, 118.92it/s] 23%|‚ñà‚ñà‚ñé       | 756/3257 [00:05<00:18, 132.84it/s] 24%|‚ñà‚ñà‚ñé       | 772/3257 [00:05<00:17, 138.85it/s] 24%|‚ñà‚ñà‚ñç       | 787/3257 [00:05<00:17, 139.54it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:16, 144.48it/s] 25%|‚ñà‚ñà‚ñå       | 819/3257 [00:05<00:16, 143.77it/s] 26%|‚ñà‚ñà‚ñå       | 834/3257 [00:05<00:17, 137.61it/s] 26%|‚ñà‚ñà‚ñå       | 849/3257 [00:05<00:18, 130.64it/s] 27%|‚ñà‚ñà‚ñã       | 865/3257 [00:05<00:17, 137.05it/s] 27%|‚ñà‚ñà‚ñã       | 879/3257 [00:05<00:17, 134.89it/s] 27%|‚ñà‚ñà‚ñã       | 894/3257 [00:06<00:17, 138.95it/s] 28%|‚ñà‚ñà‚ñä       | 911/3257 [00:06<00:15, 147.73it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:06<00:15, 152.46it/s] 29%|‚ñà‚ñà‚ñâ       | 944/3257 [00:06<00:15, 148.52it/s] 29%|‚ñà‚ñà‚ñâ       | 960/3257 [00:06<00:15, 150.74it/s] 30%|‚ñà‚ñà‚ñâ       | 976/3257 [00:06<00:14, 153.14it/s] 30%|‚ñà‚ñà‚ñà       | 992/3257 [00:06<00:15, 143.04it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:06<00:16, 138.56it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:06<00:15, 146.49it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1040/3257 [00:07<00:15, 138.93it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1055/3257 [00:07<00:15, 137.87it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1071/3257 [00:07<00:15, 142.40it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1086/3257 [00:07<00:15, 139.89it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1101/3257 [00:07<00:15, 142.15it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:07<00:14, 143.96it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1132/3257 [00:07<00:15, 138.70it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1146/3257 [00:07<00:15, 137.17it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1164/3257 [00:07<00:14, 147.51it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1179/3257 [00:08<00:15, 136.24it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1193/3257 [00:08<00:15, 132.17it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:08<00:15, 130.10it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1222/3257 [00:08<00:15, 135.10it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:08<00:13, 149.01it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:08<00:13, 144.08it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:08<00:13, 145.50it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1287/3257 [00:08<00:14, 133.97it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1302/3257 [00:08<00:14, 136.13it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1319/3257 [00:09<00:13, 143.83it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1336/3257 [00:09<00:12, 150.52it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1352/3257 [00:09<00:13, 146.09it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1367/3257 [00:09<00:13, 145.01it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1382/3257 [00:09<00:13, 139.09it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1399/3257 [00:09<00:12, 147.25it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1419/3257 [00:09<00:11, 161.94it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1436/3257 [00:09<00:11, 153.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1453/3257 [00:09<00:11, 158.24it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1472/3257 [00:10<00:10, 162.75it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1489/3257 [00:10<00:10, 163.30it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1509/3257 [00:10<00:10, 171.08it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1527/3257 [00:10<00:11, 151.69it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1543/3257 [00:10<00:11, 148.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1559/3257 [00:10<00:11, 143.86it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:10<00:11, 144.05it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:10<00:11, 148.14it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1608/3257 [00:10<00:10, 153.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1625/3257 [00:11<00:10, 156.64it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1641/3257 [00:11<00:10, 153.36it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:11<00:10, 148.44it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1672/3257 [00:11<00:10, 145.99it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:11<00:10, 150.60it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1709/3257 [00:11<00:09, 161.04it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:11<00:09, 156.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:11<00:09, 153.11it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:11<00:09, 159.66it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1784/3257 [00:12<00:08, 171.74it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:12<00:08, 173.40it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:12<00:11, 120.80it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1837/3257 [00:12<00:11, 129.03it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1856/3257 [00:12<00:09, 142.49it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1876/3257 [00:12<00:08, 156.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1894/3257 [00:12<00:08, 157.71it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:12<00:07, 167.63it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:13<00:07, 176.70it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1963/3257 [00:13<00:06, 197.08it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1984/3257 [00:13<00:07, 172.00it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2003/3257 [00:13<00:07, 170.63it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:13<00:07, 172.25it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2040/3257 [00:13<00:07, 161.58it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2057/3257 [00:13<00:07, 156.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2073/3257 [00:13<00:07, 155.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2089/3257 [00:13<00:07, 152.55it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2105/3257 [00:14<00:07, 148.06it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:14<00:08, 142.02it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2135/3257 [00:14<00:07, 141.25it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2150/3257 [00:14<00:08, 137.51it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:14<00:07, 144.90it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2183/3257 [00:14<00:07, 139.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2201/3257 [00:14<00:07, 150.42it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2217/3257 [00:14<00:07, 143.68it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2233/3257 [00:14<00:07, 146.09it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2248/3257 [00:15<00:07, 139.64it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2263/3257 [00:15<00:07, 140.43it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2278/3257 [00:15<00:07, 133.53it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2296/3257 [00:15<00:06, 144.70it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2311/3257 [00:15<00:06, 143.57it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2331/3257 [00:15<00:05, 158.98it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2351/3257 [00:15<00:05, 170.53it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2369/3257 [00:15<00:05, 164.39it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2387/3257 [00:15<00:05, 168.21it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2405/3257 [00:16<00:05, 159.41it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:16<00:05, 157.78it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2438/3257 [00:16<00:05, 146.06it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2453/3257 [00:16<00:05, 142.87it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2473/3257 [00:16<00:04, 157.95it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2490/3257 [00:16<00:04, 155.46it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2509/3257 [00:16<00:04, 164.60it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2526/3257 [00:16<00:04, 163.80it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2543/3257 [00:16<00:04, 162.74it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2560/3257 [00:17<00:04, 151.86it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2576/3257 [00:17<00:04, 141.04it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2591/3257 [00:17<00:04, 137.49it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2611/3257 [00:17<00:04, 153.07it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2631/3257 [00:17<00:03, 161.53it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2648/3257 [00:17<00:04, 151.46it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2664/3257 [00:17<00:04, 146.74it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2679/3257 [00:17<00:03, 147.50it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:18<00:04, 140.67it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:18<00:04, 127.59it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2723/3257 [00:18<00:04, 130.43it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2742/3257 [00:18<00:03, 144.08it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:18<00:03, 145.20it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2772/3257 [00:18<00:03, 138.41it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2791/3257 [00:18<00:03, 148.88it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:18<00:03, 144.35it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2822/3257 [00:18<00:03, 138.95it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2836/3257 [00:19<00:03, 130.52it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:19<00:02, 137.75it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2874/3257 [00:19<00:02, 155.64it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2890/3257 [00:19<00:02, 153.39it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:19<00:02, 141.53it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2924/3257 [00:19<00:02, 150.63it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2940/3257 [00:19<00:02, 144.50it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2955/3257 [00:19<00:02, 135.08it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2971/3257 [00:19<00:02, 140.46it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2986/3257 [00:20<00:02, 131.19it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:20<00:01, 142.71it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3019/3257 [00:20<00:01, 139.55it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3036/3257 [00:20<00:01, 147.62it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3052/3257 [00:20<00:01, 150.26it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3070/3257 [00:20<00:01, 156.72it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3086/3257 [00:20<00:01, 150.13it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3103/3257 [00:20<00:00, 154.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3120/3257 [00:20<00:00, 157.21it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3136/3257 [00:21<00:00, 146.38it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3151/3257 [00:21<00:00, 140.22it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:21<00:00, 139.93it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3181/3257 [00:21<00:00, 135.38it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3199/3257 [00:21<00:00, 145.60it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3214/3257 [00:21<00:00, 138.72it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3233/3257 [00:21<00:00, 152.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3252/3257 [00:21<00:00, 162.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 148.51it/s]
2023-02-07 20:27:09.543 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:27:09,544][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d197,n5,mc10,s0.67426,t4>', 'datetime': '2023-02-07T20:27:09.544622', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:27:09,545][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:27:09,545][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:27:10,215][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:27:10,216][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:27:10,276][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 17915 unique words (33.14% of original 54054, drops 36139)', 'datetime': '2023-02-07T20:27:10.276696', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:27:10,277][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 6418960 word corpus (97.99% of original 6550866, drops 131906)', 'datetime': '2023-02-07T20:27:10.277177', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:27:10,340][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:27:10,341][gensim.models.word2vec][INFO] - sample=0.67426 downsamples 0 most-common words
[2023-02-07 20:27:10,342][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6418960 word corpus (100.0%% of prior 6418960)', 'datetime': '2023-02-07T20:27:10.342063', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:27:10,452][gensim.models.word2vec][INFO] - estimated required memory for 17915 words and 197 dimensions: 40409456 bytes
[2023-02-07 20:27:10,453][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:27:10,475][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 17915 vocabulary and 197 features, using sg=1 hs=0 sample=0.6742595286481061 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T20:27:10.475552', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:27:11,481][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 40.84% examples, 2661725 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:12,483][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 84.28% examples, 2700782 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:12,824][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6365106 effective words) took 2.3s, 2713488 effective words/s
[2023-02-07 20:27:13,827][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 45.47% examples, 2947013 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:14,827][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 91.59% examples, 2936270 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:14,993][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6365106 effective words) took 2.2s, 2937158 effective words/s
[2023-02-07 20:27:16,002][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 46.70% examples, 3006123 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:17,003][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 95.03% examples, 3018600 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:17,099][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6365106 effective words) took 2.1s, 3023742 effective words/s
[2023-02-07 20:27:18,101][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 47.62% examples, 3090805 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:19,103][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 95.03% examples, 3028262 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:27:19,198][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6365106 effective words) took 2.1s, 3034774 effective words/s
[2023-02-07 20:27:20,201][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 46.61% examples, 3008889 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:21,206][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 95.61% examples, 3036520 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:21,291][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6365106 effective words) took 2.1s, 3044631 effective words/s
[2023-02-07 20:27:22,292][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 47.07% examples, 3053669 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:23,294][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 94.87% examples, 3024851 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:23,392][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6365106 effective words) took 2.1s, 3030884 effective words/s
[2023-02-07 20:27:24,395][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 46.76% examples, 3029187 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:25,401][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 95.61% examples, 3034280 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:25,485][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6365106 effective words) took 2.1s, 3043642 effective words/s
[2023-02-07 20:27:26,491][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 47.37% examples, 3059496 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:27,493][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 96.65% examples, 3071683 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:27,555][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6365106 effective words) took 2.1s, 3077366 effective words/s
[2023-02-07 20:27:28,558][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 47.13% examples, 3053046 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:29,561][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 96.78% examples, 3079509 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:29,619][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6365106 effective words) took 2.1s, 3086681 effective words/s
[2023-02-07 20:27:30,621][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 46.76% examples, 3028775 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:31,622][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 94.14% examples, 3004577 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:31,744][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6365106 effective words) took 2.1s, 2998547 effective words/s
[2023-02-07 20:27:32,747][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 47.37% examples, 3067624 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:33,750][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 96.19% examples, 3056009 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:33,825][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6365106 effective words) took 2.1s, 3060444 effective words/s
[2023-02-07 20:27:34,827][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 46.61% examples, 3011240 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:35,827][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 93.58% examples, 2992099 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:35,947][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6365106 effective words) took 2.1s, 3000570 effective words/s
[2023-02-07 20:27:36,949][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 46.05% examples, 2977766 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:37,949][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 92.75% examples, 2971284 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:38,087][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6365106 effective words) took 2.1s, 2976481 effective words/s
[2023-02-07 20:27:39,091][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 45.47% examples, 2945772 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:40,091][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 92.14% examples, 2948686 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:40,244][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6365106 effective words) took 2.2s, 2954281 effective words/s
[2023-02-07 20:27:41,248][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 45.04% examples, 2922292 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:42,249][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 91.37% examples, 2927196 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:42,416][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6365106 effective words) took 2.2s, 2934404 effective words/s
[2023-02-07 20:27:42,417][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (95476590 effective words) took 31.9s, 2989155 effective words/s', 'datetime': '2023-02-07T20:27:42.417115', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:27:42.417 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:27:45,631][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202638-26k101j5/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:27:45.631433', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:27:45,632][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:27:45,691][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202638-26k101j5/files/../tmp/embedding_model.pt
2023-02-07 20:27:45.692 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:27:47.338 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:27:47.946 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:28:00.954 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0812474007437363, 'test_mae': 0.7937731948092671, 'test_r2': -2.569043485694334}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.93
wandb: percentage 0.66857
wandb:   test_mae 0.79377
wandb:   test_mse 1.08125
wandb:    test_r2 -2.56904
wandb: 
wandb: üöÄ View run hardy-sweep-79 at: https://wandb.ai/xiaoqiz/mof2vec/runs/26k101j5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_202638-26k101j5/logs
wandb: Agent Starting Run: xtl7lsp9 with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 539
wandb: 	model.gensim.alpha: 0.09930786334041856
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.4858540269863661
wandb: 	model.gensim.vector_size: 469
wandb: 	model.gensim.window: 14
wandb: 	model.sklearn.learning_rate: 0.12377762301248428
wandb: 	model.sklearn.max_depth: 20
wandb: 	model.sklearn.min_child_weight: 0.04639587099368585
wandb: 	model.sklearn.n_estimators: 1879
wandb: 	model.sklearn.num_leaves: 416
wandb: 	model.sklearn.reg_alpha: 0.0070311064176818054
wandb: 	model.sklearn.reg_lambda: 0.7841895381934392
wandb: 	model.sklearn.subsample: 0.2286237047983619
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202812-xtl7lsp9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-80
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/xtl7lsp9
2023-02-07 20:28:21.644 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:28:21.645 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 539 for sweep.
2023-02-07 20:28:21.645 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.09930786334041856 for sweep.
2023-02-07 20:28:21.645 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:28:21.645 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 20:28:21.646 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4858540269863661 for sweep.
2023-02-07 20:28:21.646 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 469 for sweep.
2023-02-07 20:28:21.646 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 14 for sweep.
2023-02-07 20:28:21.646 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.12377762301248428 for sweep.
2023-02-07 20:28:21.647 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 20 for sweep.
2023-02-07 20:28:21.647 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.04639587099368585 for sweep.
2023-02-07 20:28:21.647 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1879 for sweep.
2023-02-07 20:28:21.647 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 416 for sweep.
2023-02-07 20:28:21.648 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0070311064176818054 for sweep.
2023-02-07 20:28:21.648 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.7841895381934392 for sweep.
2023-02-07 20:28:21.648 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2286237047983619 for sweep.
2023-02-07 20:28:21.648 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:28:21.654 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202812-xtl7lsp9/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 539, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 469, 'window': 14, 'min_count': 7, 'dm': 0, 'sample': 0.4858540269863661, 'workers': 4, 'alpha': 0.09930786334041856, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1879, 'max_depth': 20, 'num_leaves': 416, 'reg_alpha': 0.0070311064176818054, 'reg_lambda': 0.7841895381934392, 'subsample': 0.2286237047983619, 'min_child_weight': 0.04639587099368585, 'n_jobs': 4, 'learning_rate': 0.12377762301248428}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:24, 134.34it/s]  1%|          | 28/3257 [00:00<00:41, 78.38it/s]   1%|‚ñè         | 42/3257 [00:00<00:33, 96.97it/s]  2%|‚ñè         | 56/3257 [00:00<00:29, 109.23it/s]  2%|‚ñè         | 74/3257 [00:00<00:24, 128.90it/s]  3%|‚ñé         | 90/3257 [00:00<00:23, 137.47it/s]  3%|‚ñé         | 106/3257 [00:00<00:23, 136.29it/s]  4%|‚ñé         | 122/3257 [00:00<00:22, 141.75it/s]  4%|‚ñç         | 139/3257 [00:01<00:20, 148.97it/s]  5%|‚ñç         | 155/3257 [00:01<00:20, 151.38it/s]  5%|‚ñå         | 171/3257 [00:01<00:20, 148.52it/s]  6%|‚ñå         | 188/3257 [00:01<00:20, 153.08it/s]  6%|‚ñã         | 204/3257 [00:01<00:20, 152.13it/s]  7%|‚ñã         | 226/3257 [00:01<00:17, 169.88it/s]  7%|‚ñã         | 244/3257 [00:01<00:17, 169.95it/s]  8%|‚ñä         | 262/3257 [00:01<00:18, 162.81it/s]  9%|‚ñä         | 284/3257 [00:01<00:16, 177.74it/s]  9%|‚ñâ         | 302/3257 [00:02<00:17, 169.94it/s] 10%|‚ñâ         | 320/3257 [00:02<00:17, 171.38it/s] 10%|‚ñà         | 338/3257 [00:02<00:17, 169.18it/s] 11%|‚ñà         | 356/3257 [00:02<00:17, 170.33it/s] 11%|‚ñà‚ñè        | 374/3257 [00:02<00:17, 164.21it/s] 12%|‚ñà‚ñè        | 391/3257 [00:02<00:18, 151.94it/s] 13%|‚ñà‚ñé        | 408/3257 [00:02<00:18, 154.43it/s] 13%|‚ñà‚ñé        | 424/3257 [00:02<00:18, 152.56it/s] 14%|‚ñà‚ñé        | 440/3257 [00:02<00:21, 133.15it/s] 14%|‚ñà‚ñç        | 457/3257 [00:03<00:19, 140.52it/s] 15%|‚ñà‚ñç        | 474/3257 [00:03<00:19, 146.41it/s] 15%|‚ñà‚ñå        | 491/3257 [00:03<00:18, 150.22it/s] 16%|‚ñà‚ñå        | 510/3257 [00:03<00:17, 159.07it/s] 16%|‚ñà‚ñå        | 527/3257 [00:03<00:18, 151.56it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:17, 153.48it/s] 17%|‚ñà‚ñã        | 562/3257 [00:03<00:18, 147.12it/s] 18%|‚ñà‚ñä        | 577/3257 [00:03<00:19, 139.80it/s] 18%|‚ñà‚ñä        | 595/3257 [00:04<00:17, 148.81it/s] 19%|‚ñà‚ñâ        | 613/3257 [00:04<00:16, 156.48it/s] 19%|‚ñà‚ñâ        | 629/3257 [00:04<00:17, 151.62it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:04<00:17, 145.34it/s] 20%|‚ñà‚ñà        | 660/3257 [00:04<00:19, 135.94it/s] 21%|‚ñà‚ñà        | 677/3257 [00:04<00:17, 144.40it/s] 21%|‚ñà‚ñà        | 692/3257 [00:04<00:18, 141.21it/s] 22%|‚ñà‚ñà‚ñè       | 709/3257 [00:04<00:17, 148.77it/s] 22%|‚ñà‚ñà‚ñè       | 725/3257 [00:04<00:17, 141.37it/s] 23%|‚ñà‚ñà‚ñé       | 740/3257 [00:05<00:18, 136.34it/s] 23%|‚ñà‚ñà‚ñé       | 758/3257 [00:05<00:17, 146.74it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:05<00:17, 144.80it/s] 24%|‚ñà‚ñà‚ñç       | 788/3257 [00:05<00:17, 143.69it/s] 25%|‚ñà‚ñà‚ñç       | 805/3257 [00:05<00:16, 149.62it/s] 25%|‚ñà‚ñà‚ñå       | 821/3257 [00:05<00:17, 142.96it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:05<00:17, 136.36it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:05<00:18, 131.47it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:05<00:17, 136.25it/s] 27%|‚ñà‚ñà‚ñã       | 880/3257 [00:06<00:17, 136.75it/s] 27%|‚ñà‚ñà‚ñã       | 895/3257 [00:06<00:16, 139.16it/s] 28%|‚ñà‚ñà‚ñä       | 912/3257 [00:06<00:16, 145.79it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:06<00:15, 146.29it/s] 29%|‚ñà‚ñà‚ñâ       | 943/3257 [00:06<00:16, 139.11it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:06<00:16, 142.38it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:06<00:16, 139.24it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:06<00:16, 134.57it/s] 31%|‚ñà‚ñà‚ñà       | 1003/3257 [00:06<00:16, 137.63it/s] 31%|‚ñà‚ñà‚ñà       | 1017/3257 [00:07<00:16, 136.28it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1031/3257 [00:07<00:16, 132.76it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1045/3257 [00:07<00:17, 127.77it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1059/3257 [00:07<00:17, 128.91it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1076/3257 [00:07<00:15, 139.85it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:07<00:16, 127.56it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1107/3257 [00:07<00:15, 134.88it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1121/3257 [00:07<00:16, 133.34it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1135/3257 [00:07<00:16, 131.70it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1149/3257 [00:08<00:16, 127.10it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1167/3257 [00:08<00:14, 141.28it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1182/3257 [00:08<00:15, 130.06it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1196/3257 [00:08<00:16, 124.42it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1209/3257 [00:08<00:16, 120.80it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1225/3257 [00:08<00:15, 130.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:08<00:14, 138.79it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:08<00:14, 137.24it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1273/3257 [00:09<00:21, 91.64it/s]  39%|‚ñà‚ñà‚ñà‚ñâ      | 1285/3257 [00:09<00:21, 92.50it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1299/3257 [00:09<00:19, 102.41it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:09<00:17, 111.14it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:09<00:16, 119.97it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1343/3257 [00:09<00:14, 127.84it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1357/3257 [00:09<00:15, 124.03it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:09<00:15, 124.77it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1383/3257 [00:09<00:14, 125.42it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1400/3257 [00:10<00:13, 137.18it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1419/3257 [00:10<00:12, 150.12it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1435/3257 [00:10<00:12, 143.87it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:10<00:11, 150.46it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1469/3257 [00:10<00:11, 155.89it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1485/3257 [00:10<00:11, 149.88it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1505/3257 [00:10<00:10, 162.32it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1522/3257 [00:10<00:11, 147.29it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1538/3257 [00:11<00:12, 141.78it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1553/3257 [00:11<00:12, 139.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1569/3257 [00:11<00:11, 145.09it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1584/3257 [00:11<00:11, 142.55it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1601/3257 [00:11<00:11, 148.11it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:11<00:10, 149.99it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:11<00:11, 141.72it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1649/3257 [00:11<00:11, 139.20it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1664/3257 [00:11<00:11, 137.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1678/3257 [00:11<00:11, 136.03it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:12<00:11, 136.64it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:12<00:10, 141.13it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:12<00:10, 141.14it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1738/3257 [00:12<00:12, 123.10it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1753/3257 [00:12<00:11, 129.77it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1770/3257 [00:12<00:10, 140.13it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1786/3257 [00:12<00:10, 144.77it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1801/3257 [00:12<00:10, 142.69it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1816/3257 [00:12<00:10, 137.64it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1830/3257 [00:13<00:10, 133.07it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:13<00:10, 139.16it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1863/3257 [00:13<00:09, 146.22it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:13<00:09, 149.58it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:13<00:09, 146.03it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1912/3257 [00:13<00:08, 152.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1928/3257 [00:13<00:09, 144.93it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1948/3257 [00:13<00:08, 157.61it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:13<00:08, 160.54it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:14<00:08, 155.50it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:14<00:08, 155.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2015/3257 [00:14<00:08, 153.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:14<00:07, 156.96it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2049/3257 [00:14<00:08, 143.71it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2064/3257 [00:14<00:08, 138.59it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2080/3257 [00:14<00:08, 143.70it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2095/3257 [00:14<00:08, 141.20it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2110/3257 [00:14<00:08, 138.98it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2124/3257 [00:15<00:08, 127.79it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2139/3257 [00:15<00:08, 132.73it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2153/3257 [00:15<00:08, 131.00it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:15<00:08, 135.90it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2183/3257 [00:15<00:07, 136.13it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2201/3257 [00:15<00:07, 146.25it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2216/3257 [00:15<00:07, 139.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2231/3257 [00:15<00:07, 140.42it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2246/3257 [00:15<00:07, 133.81it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:16<00:07, 135.06it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2274/3257 [00:16<00:07, 129.22it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2293/3257 [00:16<00:06, 144.02it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2308/3257 [00:16<00:06, 140.42it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2328/3257 [00:16<00:06, 154.79it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2345/3257 [00:16<00:05, 158.51it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2362/3257 [00:16<00:05, 159.88it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2379/3257 [00:16<00:05, 161.32it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:16<00:05, 164.01it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2414/3257 [00:17<00:05, 154.48it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2430/3257 [00:17<00:05, 147.95it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2445/3257 [00:17<00:05, 142.25it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2462/3257 [00:17<00:05, 147.74it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2478/3257 [00:17<00:05, 150.42it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2496/3257 [00:17<00:04, 156.31it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:17<00:04, 161.66it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2532/3257 [00:17<00:04, 166.56it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2549/3257 [00:17<00:04, 162.06it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2566/3257 [00:18<00:04, 146.76it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2581/3257 [00:18<00:04, 141.31it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2596/3257 [00:18<00:04, 139.66it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2616/3257 [00:18<00:04, 153.80it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:18<00:03, 158.83it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2651/3257 [00:18<00:04, 146.95it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2666/3257 [00:18<00:04, 144.91it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2684/3257 [00:18<00:03, 150.61it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2700/3257 [00:19<00:04, 129.62it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2715/3257 [00:19<00:04, 127.79it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2734/3257 [00:19<00:03, 141.77it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2751/3257 [00:19<00:03, 148.03it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2767/3257 [00:19<00:03, 150.33it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2783/3257 [00:19<00:06, 76.38it/s]  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2800/3257 [00:20<00:05, 90.92it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2814/3257 [00:20<00:04, 99.64it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2828/3257 [00:20<00:04, 103.65it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2841/3257 [00:20<00:03, 109.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2860/3257 [00:20<00:03, 127.85it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2880/3257 [00:20<00:02, 145.70it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2897/3257 [00:20<00:02, 134.48it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2914/3257 [00:20<00:02, 142.13it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2930/3257 [00:20<00:02, 138.89it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2945/3257 [00:21<00:02, 135.91it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2960/3257 [00:21<00:02, 137.45it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:21<00:02, 137.98it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2991/3257 [00:21<00:01, 135.97it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:21<00:01, 152.47it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3027/3257 [00:21<00:01, 145.37it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3046/3257 [00:21<00:01, 155.49it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3065/3257 [00:21<00:01, 163.97it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:21<00:01, 162.06it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3099/3257 [00:22<00:00, 162.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:22<00:00, 168.51it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3135/3257 [00:22<00:00, 159.05it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3152/3257 [00:22<00:00, 149.52it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3168/3257 [00:22<00:00, 148.67it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3184/3257 [00:22<00:00, 140.98it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3201/3257 [00:22<00:00, 146.73it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3216/3257 [00:22<00:00, 139.31it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3234/3257 [00:22<00:00, 148.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:23<00:00, 146.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:23<00:00, 140.84it/s]
2023-02-07 20:28:45.686 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:28:45,688][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d469,n5,mc7,s0.485854,t4>', 'datetime': '2023-02-07T20:28:45.687924', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:28:45,688][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:28:45,688][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:28:46,355][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:28:46,355][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:28:46,429][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 23400 unique words (43.29% of original 54054, drops 30654)', 'datetime': '2023-02-07T20:28:46.429576', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:28:46,430][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 6462689 word corpus (98.65% of original 6550866, drops 88177)', 'datetime': '2023-02-07T20:28:46.430037', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:28:46,514][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:28:46,516][gensim.models.word2vec][INFO] - sample=0.485854 downsamples 0 most-common words
[2023-02-07 20:28:46,516][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6462689 word corpus (100.0%% of prior 6462689)', 'datetime': '2023-02-07T20:28:46.516531', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:28:46,662][gensim.models.word2vec][INFO] - estimated required memory for 23400 words and 469 dimensions: 106258332 bytes
[2023-02-07 20:28:46,663][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:28:46,716][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 23400 vocabulary and 469 features, using sg=1 hs=0 sample=0.4858540269863661 negative=5 window=14 shrink_windows=True', 'datetime': '2023-02-07T20:28:46.716498', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:28:47,720][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 25.15% examples, 1598358 words/s, in_qsize 6, out_qsize 0
[2023-02-07 20:28:48,721][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 49.68% examples, 1619573 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:49,723][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 74.92% examples, 1621627 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:50,648][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6408417 effective words) took 3.9s, 1630900 effective words/s
[2023-02-07 20:28:51,662][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 27.79% examples, 1767997 words/s, in_qsize 6, out_qsize 1
[2023-02-07 20:28:52,667][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 54.47% examples, 1770863 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:53,670][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 82.71% examples, 1770458 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:54,286][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6408417 effective words) took 3.6s, 1762389 effective words/s
[2023-02-07 20:28:55,296][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 27.79% examples, 1778889 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:56,304][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 53.91% examples, 1756315 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:57,307][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 81.58% examples, 1747069 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:57,949][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6408417 effective words) took 3.7s, 1751190 effective words/s
[2023-02-07 20:28:58,951][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 27.11% examples, 1744554 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:59,954][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 53.30% examples, 1748225 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:00,967][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 81.76% examples, 1750145 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:01,607][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6408417 effective words) took 3.7s, 1752460 effective words/s
[2023-02-07 20:29:02,618][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 27.17% examples, 1742094 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:03,625][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 53.91% examples, 1756785 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:04,628][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 81.76% examples, 1750114 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:05,269][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6408417 effective words) took 3.7s, 1751970 effective words/s
[2023-02-07 20:29:06,275][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 27.17% examples, 1746266 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:07,280][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 53.61% examples, 1751300 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:08,289][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 81.76% examples, 1748916 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:08,926][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6408417 effective words) took 3.7s, 1753043 effective words/s
[2023-02-07 20:29:09,929][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 27.57% examples, 1771505 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:10,932][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 54.19% examples, 1774117 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:11,933][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 82.32% examples, 1770257 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:12,557][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6408417 effective words) took 3.6s, 1766339 effective words/s
[2023-02-07 20:29:13,567][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 27.17% examples, 1740196 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:14,568][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 53.21% examples, 1737808 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:15,575][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 80.66% examples, 1726766 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:16,262][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6408417 effective words) took 3.7s, 1730462 effective words/s
[2023-02-07 20:29:17,278][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 27.33% examples, 1726979 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:18,281][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 53.30% examples, 1735268 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:19,283][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 81.15% examples, 1736229 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:19,952][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6408417 effective words) took 3.7s, 1737485 effective words/s
[2023-02-07 20:29:20,960][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 27.85% examples, 1778943 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:21,971][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 54.47% examples, 1769909 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:22,975][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 82.38% examples, 1760237 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:23,591][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6408417 effective words) took 3.6s, 1761497 effective words/s
[2023-02-07 20:29:24,610][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 27.33% examples, 1722592 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:25,616][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 53.42% examples, 1735348 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:26,631][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 81.76% examples, 1737505 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:27,267][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6408417 effective words) took 3.7s, 1744070 effective words/s
[2023-02-07 20:29:28,276][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 27.17% examples, 1741872 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:29,277][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 53.30% examples, 1743750 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:30,277][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 80.66% examples, 1731144 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:30,968][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6408417 effective words) took 3.7s, 1732133 effective words/s
[2023-02-07 20:29:31,971][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 26.96% examples, 1734302 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:32,977][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 53.02% examples, 1728236 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:33,977][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 79.46% examples, 1714348 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:34,719][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6408417 effective words) took 3.7s, 1709128 effective words/s
[2023-02-07 20:29:35,726][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 26.16% examples, 1674142 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:36,730][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 51.27% examples, 1669312 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:37,736][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 77.80% examples, 1668655 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:38,561][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6408417 effective words) took 3.8s, 1668808 effective words/s
[2023-02-07 20:29:39,567][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 26.31% examples, 1686531 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:40,570][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 51.89% examples, 1694622 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:41,572][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 78.63% examples, 1691454 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:42,351][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6408417 effective words) took 3.8s, 1691806 effective words/s
[2023-02-07 20:29:42,352][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (96126255 effective words) took 55.6s, 1727787 effective words/s', 'datetime': '2023-02-07T20:29:42.352442', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:29:42.352 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:29:48,237][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202812-xtl7lsp9/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:29:48.237760', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:29:48,238][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202812-xtl7lsp9/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 20:29:48,282][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202812-xtl7lsp9/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 20:29:48,324][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:29:48,352][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202812-xtl7lsp9/files/../tmp/embedding_model.pt
2023-02-07 20:29:48.352 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:29:50.896 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:29:51.773 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:30:44.702 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1206851591700242, 'test_mae': 0.8148274604985319, 'test_r2': -3.2056810530098554}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.92
wandb: percentage 0.5671
wandb:   test_mae 0.81483
wandb:   test_mse 1.12069
wandb:    test_r2 -3.20568
wandb: 
wandb: üöÄ View run hopeful-sweep-80 at: https://wandb.ai/xiaoqiz/mof2vec/runs/xtl7lsp9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_202812-xtl7lsp9/logs
wandb: Agent Starting Run: n9fk2auw with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 593
wandb: 	model.gensim.alpha: 0.00802487084232258
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.396387619402819
wandb: 	model.gensim.vector_size: 486
wandb: 	model.gensim.window: 6
wandb: 	model.sklearn.learning_rate: 0.03401994111651135
wandb: 	model.sklearn.max_depth: 36
wandb: 	model.sklearn.min_child_weight: 0.08893218790781227
wandb: 	model.sklearn.n_estimators: 3676
wandb: 	model.sklearn.num_leaves: 351
wandb: 	model.sklearn.reg_alpha: 0.0070395937609220765
wandb: 	model.sklearn.reg_lambda: 0.004435238255322519
wandb: 	model.sklearn.subsample: 0.3192288169127799
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203056-n9fk2auw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-81
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/n9fk2auw
2023-02-07 20:31:04.892 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 20:31:04.893 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 593 for sweep.
2023-02-07 20:31:04.893 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.00802487084232258 for sweep.
2023-02-07 20:31:04.893 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:31:04.894 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 20:31:04.894 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.396387619402819 for sweep.
2023-02-07 20:31:04.894 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 486 for sweep.
2023-02-07 20:31:04.894 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 6 for sweep.
2023-02-07 20:31:04.895 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.03401994111651135 for sweep.
2023-02-07 20:31:04.895 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 36 for sweep.
2023-02-07 20:31:04.895 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08893218790781227 for sweep.
2023-02-07 20:31:04.895 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3676 for sweep.
2023-02-07 20:31:04.896 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 351 for sweep.
2023-02-07 20:31:04.896 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0070395937609220765 for sweep.
2023-02-07 20:31:04.896 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.004435238255322519 for sweep.
2023-02-07 20:31:04.896 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3192288169127799 for sweep.
2023-02-07 20:31:04.896 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:31:04.905 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203056-n9fk2auw/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 593, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 486, 'window': 6, 'min_count': 1, 'dm': 0, 'sample': 0.396387619402819, 'workers': 4, 'alpha': 0.00802487084232258, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3676, 'max_depth': 36, 'num_leaves': 351, 'reg_alpha': 0.0070395937609220765, 'reg_lambda': 0.004435238255322519, 'subsample': 0.3192288169127799, 'min_child_weight': 0.08893218790781227, 'n_jobs': 4, 'learning_rate': 0.03401994111651135}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:22, 145.41it/s]  1%|          | 33/3257 [00:00<00:19, 164.81it/s]  2%|‚ñè         | 50/3257 [00:00<00:19, 163.71it/s]  2%|‚ñè         | 67/3257 [00:00<00:19, 160.30it/s]  3%|‚ñé         | 88/3257 [00:00<00:18, 175.52it/s]  3%|‚ñé         | 106/3257 [00:00<00:19, 159.28it/s]  4%|‚ñç         | 123/3257 [00:00<00:19, 160.51it/s]  4%|‚ñç         | 141/3257 [00:00<00:18, 166.25it/s]  5%|‚ñç         | 159/3257 [00:00<00:18, 169.43it/s]  5%|‚ñå         | 177/3257 [00:01<00:18, 165.77it/s]  6%|‚ñå         | 197/3257 [00:01<00:17, 172.93it/s]  7%|‚ñã         | 217/3257 [00:01<00:16, 179.72it/s]  7%|‚ñã         | 237/3257 [00:01<00:16, 182.48it/s]  8%|‚ñä         | 256/3257 [00:01<00:16, 182.13it/s]  8%|‚ñä         | 275/3257 [00:01<00:16, 179.74it/s]  9%|‚ñâ         | 297/3257 [00:01<00:15, 188.16it/s] 10%|‚ñâ         | 316/3257 [00:01<00:16, 174.34it/s] 10%|‚ñà         | 334/3257 [00:01<00:16, 175.84it/s] 11%|‚ñà         | 352/3257 [00:02<00:17, 169.84it/s] 11%|‚ñà‚ñè        | 371/3257 [00:02<00:16, 175.34it/s] 12%|‚ñà‚ñè        | 389/3257 [00:02<00:18, 158.41it/s] 13%|‚ñà‚ñé        | 408/3257 [00:02<00:17, 164.22it/s] 13%|‚ñà‚ñé        | 425/3257 [00:02<00:18, 153.11it/s] 14%|‚ñà‚ñé        | 441/3257 [00:02<00:18, 149.95it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:17, 156.81it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:16, 163.59it/s] 15%|‚ñà‚ñå        | 500/3257 [00:02<00:15, 176.04it/s] 16%|‚ñà‚ñå        | 520/3257 [00:03<00:15, 180.13it/s] 17%|‚ñà‚ñã        | 539/3257 [00:03<00:15, 179.51it/s] 17%|‚ñà‚ñã        | 558/3257 [00:03<00:15, 172.84it/s] 18%|‚ñà‚ñä        | 576/3257 [00:03<00:16, 160.66it/s] 18%|‚ñà‚ñä        | 596/3257 [00:03<00:15, 170.56it/s] 19%|‚ñà‚ñâ        | 615/3257 [00:03<00:15, 174.71it/s] 19%|‚ñà‚ñâ        | 633/3257 [00:03<00:14, 175.84it/s] 20%|‚ñà‚ñâ        | 651/3257 [00:03<00:15, 165.61it/s] 21%|‚ñà‚ñà        | 668/3257 [00:03<00:16, 158.90it/s] 21%|‚ñà‚ñà        | 685/3257 [00:04<00:16, 158.78it/s] 22%|‚ñà‚ñà‚ñè       | 702/3257 [00:04<00:15, 161.76it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:04<00:15, 164.86it/s] 23%|‚ñà‚ñà‚ñé       | 737/3257 [00:04<00:15, 157.81it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:04<00:15, 160.55it/s] 24%|‚ñà‚ñà‚ñé       | 772/3257 [00:04<00:15, 165.04it/s] 24%|‚ñà‚ñà‚ñç       | 789/3257 [00:04<00:15, 159.56it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:15, 159.50it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:04<00:15, 160.12it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:05<00:15, 158.83it/s] 26%|‚ñà‚ñà‚ñã       | 856/3257 [00:05<00:15, 156.79it/s] 27%|‚ñà‚ñà‚ñã       | 874/3257 [00:05<00:14, 162.49it/s] 27%|‚ñà‚ñà‚ñã       | 891/3257 [00:05<00:22, 104.84it/s] 28%|‚ñà‚ñà‚ñä       | 911/3257 [00:05<00:18, 124.55it/s] 29%|‚ñà‚ñà‚ñä       | 930/3257 [00:05<00:16, 138.08it/s] 29%|‚ñà‚ñà‚ñâ       | 947/3257 [00:05<00:16, 143.51it/s] 30%|‚ñà‚ñà‚ñâ       | 964/3257 [00:05<00:15, 150.04it/s] 30%|‚ñà‚ñà‚ñà       | 981/3257 [00:06<00:15, 151.18it/s] 31%|‚ñà‚ñà‚ñà       | 998/3257 [00:06<00:14, 152.61it/s] 31%|‚ñà‚ñà‚ñà       | 1014/3257 [00:06<00:14, 153.59it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1030/3257 [00:06<00:14, 152.25it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:06<00:14, 151.25it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1063/3257 [00:06<00:14, 156.31it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:13, 156.97it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1098/3257 [00:06<00:13, 162.33it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1116/3257 [00:06<00:12, 167.01it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1133/3257 [00:07<00:13, 161.06it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1150/3257 [00:07<00:13, 158.08it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:12, 166.29it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:07<00:13, 158.41it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1203/3257 [00:07<00:13, 148.75it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:07<00:13, 151.38it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:07<00:12, 167.62it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:07<00:12, 160.42it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:07<00:12, 160.13it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:08<00:12, 152.30it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:08<00:12, 156.44it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:08<00:11, 163.92it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1347/3257 [00:08<00:11, 169.22it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1365/3257 [00:08<00:11, 162.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1382/3257 [00:08<00:11, 158.55it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1401/3257 [00:08<00:11, 165.61it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:08<00:10, 177.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1440/3257 [00:08<00:10, 170.00it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1462/3257 [00:09<00:09, 182.88it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1481/3257 [00:09<00:09, 180.59it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1501/3257 [00:09<00:09, 185.33it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1520/3257 [00:09<00:10, 171.89it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1538/3257 [00:09<00:10, 165.28it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:09<00:10, 162.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:09<00:09, 168.33it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:09<00:10, 165.09it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1609/3257 [00:09<00:09, 168.36it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1627/3257 [00:09<00:09, 170.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1645/3257 [00:10<00:09, 161.76it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:10<00:10, 154.71it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1678/3257 [00:10<00:10, 153.98it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1694/3257 [00:10<00:10, 155.20it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1714/3257 [00:10<00:09, 165.59it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:10<00:09, 153.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1747/3257 [00:10<00:09, 153.00it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:10<00:09, 153.43it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1780/3257 [00:10<00:09, 157.81it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1797/3257 [00:11<00:09, 160.67it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:11<00:09, 156.53it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1830/3257 [00:11<00:09, 155.28it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:11<00:08, 163.51it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:11<00:08, 169.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1886/3257 [00:11<00:08, 165.31it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1904/3257 [00:11<00:08, 166.65it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1921/3257 [00:11<00:08, 159.79it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1943/3257 [00:11<00:07, 175.85it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:12<00:07, 182.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1984/3257 [00:12<00:07, 173.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:12<00:07, 176.68it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2023/3257 [00:12<00:06, 179.28it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2042/3257 [00:12<00:07, 170.36it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2060/3257 [00:12<00:07, 155.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2080/3257 [00:12<00:07, 166.18it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2097/3257 [00:12<00:07, 160.16it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:12<00:06, 166.48it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:13<00:07, 152.51it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2150/3257 [00:13<00:07, 151.86it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:13<00:06, 158.68it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2186/3257 [00:13<00:06, 157.52it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2206/3257 [00:13<00:06, 165.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2223/3257 [00:13<00:06, 165.17it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2240/3257 [00:13<00:06, 156.10it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:13<00:06, 164.00it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:14<00:10, 97.56it/s]  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2298/3257 [00:14<00:07, 120.86it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:14<00:07, 129.78it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2338/3257 [00:14<00:06, 152.31it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:14<00:05, 166.40it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2380/3257 [00:14<00:05, 173.80it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:14<00:04, 177.77it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2418/3257 [00:14<00:04, 168.18it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2436/3257 [00:15<00:05, 161.58it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2453/3257 [00:15<00:05, 160.23it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:15<00:04, 175.48it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2494/3257 [00:15<00:04, 178.20it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2515/3257 [00:15<00:03, 185.77it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2536/3257 [00:15<00:03, 190.09it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2556/3257 [00:15<00:03, 177.49it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2575/3257 [00:15<00:04, 169.25it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2593/3257 [00:16<00:04, 165.78it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2615/3257 [00:16<00:03, 178.03it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:16<00:03, 179.89it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2653/3257 [00:16<00:03, 171.36it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:16<00:03, 175.21it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2692/3257 [00:16<00:03, 177.60it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2710/3257 [00:16<00:03, 155.66it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2731/3257 [00:16<00:03, 168.10it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2751/3257 [00:16<00:02, 175.65it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2769/3257 [00:17<00:02, 168.57it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2791/3257 [00:17<00:02, 180.43it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2810/3257 [00:17<00:02, 177.78it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2828/3257 [00:17<00:02, 168.17it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2846/3257 [00:17<00:02, 167.06it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2870/3257 [00:17<00:02, 186.65it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2889/3257 [00:17<00:01, 184.20it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2908/3257 [00:17<00:01, 174.82it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:17<00:01, 178.75it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:18<00:01, 171.77it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:18<00:01, 173.65it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:18<00:01, 164.17it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3007/3257 [00:18<00:01, 180.40it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:18<00:01, 173.57it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:18<00:01, 182.69it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3069/3257 [00:18<00:00, 188.21it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3088/3257 [00:18<00:00, 184.65it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:18<00:00, 192.98it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3130/3257 [00:19<00:00, 194.71it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3150/3257 [00:19<00:00, 178.31it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3169/3257 [00:19<00:00, 179.40it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3188/3257 [00:19<00:00, 175.62it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:19<00:00, 176.44it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3225/3257 [00:19<00:00, 170.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:19<00:00, 175.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 164.88it/s]
2023-02-07 20:31:25.469 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:31:25,471][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d486,n5,s0.396388,t4>', 'datetime': '2023-02-07T20:31:25.471145', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:31:25,471][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:31:25,471][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:31:25,978][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 20:31:25,978][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:31:26,066][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 31803 unique words (100.00% of original 31803, drops 0)', 'datetime': '2023-02-07T20:31:26.066054', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:31:26,066][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 5095118 word corpus (100.00% of original 5095118, drops 0)', 'datetime': '2023-02-07T20:31:26.066510', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:31:26,179][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 20:31:26,181][gensim.models.word2vec][INFO] - sample=0.396388 downsamples 0 most-common words
[2023-02-07 20:31:26,181][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5095118 word corpus (100.0%% of prior 5095118)', 'datetime': '2023-02-07T20:31:26.181439', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:31:26,376][gensim.models.word2vec][INFO] - estimated required memory for 31803 words and 486 dimensions: 146534572 bytes
[2023-02-07 20:31:26,376][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:31:26,451][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 31803 vocabulary and 486 features, using sg=1 hs=0 sample=0.396387619402819 negative=5 window=6 shrink_windows=True', 'datetime': '2023-02-07T20:31:26.451912', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:31:27,457][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 26.87% examples, 1371643 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:31:28,459][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 54.44% examples, 1414030 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:29,459][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 84.46% examples, 1442894 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:29,947][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5086629 effective words) took 3.5s, 1456439 effective words/s
[2023-02-07 20:31:30,958][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 25.30% examples, 1275081 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:31,961][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 49.28% examples, 1270684 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:31:32,981][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 74.03% examples, 1260768 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:33,981][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 99.39% examples, 1256367 words/s, in_qsize 2, out_qsize 3
[2023-02-07 20:31:33,985][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5086629 effective words) took 4.0s, 1260577 effective words/s
[2023-02-07 20:31:34,992][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 31.50% examples, 1603663 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:35,992][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 62.60% examples, 1610707 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:31:36,994][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 94.90% examples, 1609914 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:37,137][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5086629 effective words) took 3.2s, 1614277 effective words/s
[2023-02-07 20:31:38,145][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 32.36% examples, 1656669 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:39,151][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 63.92% examples, 1643695 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:40,153][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 97.14% examples, 1641746 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:40,234][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5086629 effective words) took 3.1s, 1643590 effective words/s
[2023-02-07 20:31:41,244][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 32.36% examples, 1654075 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:31:42,247][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 64.35% examples, 1658091 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:43,256][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 97.88% examples, 1651006 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:43,310][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5086629 effective words) took 3.1s, 1654497 effective words/s
[2023-02-07 20:31:44,319][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 32.55% examples, 1663936 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:45,322][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 65.64% examples, 1695792 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:46,301][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5086629 effective words) took 3.0s, 1702314 effective words/s
[2023-02-07 20:31:47,304][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 33.22% examples, 1704268 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:48,306][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 66.56% examples, 1726676 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:31:49,224][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5086629 effective words) took 2.9s, 1741423 effective words/s
[2023-02-07 20:31:50,238][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 34.48% examples, 1751840 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:31:51,238][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 68.28% examples, 1762582 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:52,122][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5086629 effective words) took 2.9s, 1755927 effective words/s
[2023-02-07 20:31:53,127][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 34.02% examples, 1750080 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:54,132][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 67.06% examples, 1736719 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:55,056][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5086629 effective words) took 2.9s, 1735826 effective words/s
[2023-02-07 20:31:56,059][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 33.13% examples, 1695851 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:57,063][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 66.04% examples, 1711080 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:57,952][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5086629 effective words) took 2.9s, 1757244 effective words/s
[2023-02-07 20:31:58,954][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 39.70% examples, 2077279 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:59,956][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 81.58% examples, 2089663 words/s, in_qsize 7, out_qsize 1
[2023-02-07 20:32:00,399][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5086629 effective words) took 2.4s, 2080200 effective words/s
[2023-02-07 20:32:01,402][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 41.39% examples, 2156300 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:02,404][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 80.38% examples, 2057664 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:32:02,937][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5086629 effective words) took 2.5s, 2004991 effective words/s
[2023-02-07 20:32:03,944][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 37.21% examples, 1933171 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:04,947][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 70.56% examples, 1826495 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:05,660][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5086629 effective words) took 2.7s, 1869128 effective words/s
[2023-02-07 20:32:06,663][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 38.47% examples, 2001005 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:07,665][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 76.54% examples, 1968815 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:08,201][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5086629 effective words) took 2.5s, 2002940 effective words/s
[2023-02-07 20:32:09,214][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 40.50% examples, 2093273 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:10,217][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 83.39% examples, 2131878 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:10,576][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5086629 effective words) took 2.4s, 2143095 effective words/s
[2023-02-07 20:32:10,576][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76299435 effective words) took 44.1s, 1729213 effective words/s', 'datetime': '2023-02-07T20:32:10.576944', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:32:10.577 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:32:15,036][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203056-n9fk2auw/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:32:15.036561', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:32:15,037][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203056-n9fk2auw/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 20:32:15,102][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203056-n9fk2auw/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 20:32:15,162][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:32:15,207][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203056-n9fk2auw/files/../tmp/embedding_model.pt
2023-02-07 20:32:15.207 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:32:18.002 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:32:18.907 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:32:32.188 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9980510738556548, 'test_mae': 0.759004104768206, 'test_r2': -1.9065115072335064}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.8
wandb: percentage 0.0
wandb:   test_mae 0.759
wandb:   test_mse 0.99805
wandb:    test_r2 -1.90651
wandb: 
wandb: üöÄ View run efficient-sweep-81 at: https://wandb.ai/xiaoqiz/mof2vec/runs/n9fk2auw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_203056-n9fk2auw/logs
wandb: Agent Starting Run: ovypnzko with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 692
wandb: 	model.gensim.alpha: 0.01030795766188243
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.2467480317423405
wandb: 	model.gensim.vector_size: 36
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.006298578039911371
wandb: 	model.sklearn.max_depth: 27
wandb: 	model.sklearn.min_child_weight: 0.07065721212183985
wandb: 	model.sklearn.n_estimators: 1350
wandb: 	model.sklearn.num_leaves: 304
wandb: 	model.sklearn.reg_alpha: 0.0035008027832142143
wandb: 	model.sklearn.reg_lambda: 0.2331583166966671
wandb: 	model.sklearn.subsample: 0.3699368833387613
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203243-ovypnzko
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-82
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/ovypnzko
2023-02-07 20:32:51.882 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:32:51.883 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 692 for sweep.
2023-02-07 20:32:51.883 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.01030795766188243 for sweep.
2023-02-07 20:32:51.884 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:32:51.884 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 20:32:51.884 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2467480317423405 for sweep.
2023-02-07 20:32:51.884 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 36 for sweep.
2023-02-07 20:32:51.885 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 20:32:51.885 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.006298578039911371 for sweep.
2023-02-07 20:32:51.885 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 27 for sweep.
2023-02-07 20:32:51.885 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.07065721212183985 for sweep.
2023-02-07 20:32:51.886 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1350 for sweep.
2023-02-07 20:32:51.886 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 304 for sweep.
2023-02-07 20:32:51.886 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0035008027832142143 for sweep.
2023-02-07 20:32:51.886 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.2331583166966671 for sweep.
2023-02-07 20:32:51.887 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3699368833387613 for sweep.
2023-02-07 20:32:51.887 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:32:51.892 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203243-ovypnzko/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 692, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 36, 'window': 8, 'min_count': 3, 'dm': 0, 'sample': 0.2467480317423405, 'workers': 4, 'alpha': 0.01030795766188243, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1350, 'max_depth': 27, 'num_leaves': 304, 'reg_alpha': 0.0035008027832142143, 'reg_lambda': 0.2331583166966671, 'subsample': 0.3699368833387613, 'min_child_weight': 0.07065721212183985, 'n_jobs': 4, 'learning_rate': 0.006298578039911371}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:26, 124.19it/s]  1%|          | 29/3257 [00:00<00:22, 141.14it/s]  1%|‚ñè         | 44/3257 [00:00<00:22, 142.12it/s]  2%|‚ñè         | 59/3257 [00:00<00:22, 141.15it/s]  2%|‚ñè         | 77/3257 [00:00<00:20, 152.73it/s]  3%|‚ñé         | 93/3257 [00:00<00:20, 153.96it/s]  3%|‚ñé         | 109/3257 [00:00<00:22, 142.99it/s]  4%|‚ñç         | 125/3257 [00:00<00:21, 146.58it/s]  4%|‚ñç         | 145/3257 [00:00<00:19, 157.93it/s]  5%|‚ñç         | 161/3257 [00:01<00:20, 150.86it/s]  5%|‚ñå         | 177/3257 [00:01<00:21, 143.81it/s]  6%|‚ñå         | 195/3257 [00:01<00:20, 152.62it/s]  7%|‚ñã         | 212/3257 [00:01<00:19, 155.55it/s]  7%|‚ñã         | 230/3257 [00:01<00:18, 162.37it/s]  8%|‚ñä         | 247/3257 [00:01<00:18, 160.79it/s]  8%|‚ñä         | 264/3257 [00:01<00:19, 151.06it/s]  9%|‚ñâ         | 285/3257 [00:01<00:17, 165.32it/s]  9%|‚ñâ         | 302/3257 [00:01<00:18, 159.79it/s] 10%|‚ñâ         | 319/3257 [00:02<00:18, 159.84it/s] 10%|‚ñà         | 336/3257 [00:02<00:18, 156.94it/s] 11%|‚ñà         | 352/3257 [00:02<00:18, 153.31it/s] 11%|‚ñà‚ñè        | 368/3257 [00:02<00:19, 151.18it/s] 12%|‚ñà‚ñè        | 384/3257 [00:02<00:30, 93.49it/s]  12%|‚ñà‚ñè        | 397/3257 [00:02<00:28, 100.28it/s] 13%|‚ñà‚ñé        | 412/3257 [00:02<00:25, 110.85it/s] 13%|‚ñà‚ñé        | 426/3257 [00:03<00:26, 105.02it/s] 14%|‚ñà‚ñé        | 440/3257 [00:03<00:24, 112.99it/s] 14%|‚ñà‚ñç        | 456/3257 [00:03<00:22, 123.83it/s] 14%|‚ñà‚ñç        | 472/3257 [00:03<00:21, 131.32it/s] 15%|‚ñà‚ñç        | 486/3257 [00:03<00:21, 130.53it/s] 15%|‚ñà‚ñå        | 503/3257 [00:03<00:19, 140.30it/s] 16%|‚ñà‚ñå        | 520/3257 [00:03<00:18, 147.28it/s] 16%|‚ñà‚ñã        | 536/3257 [00:03<00:18, 146.20it/s] 17%|‚ñà‚ñã        | 551/3257 [00:03<00:18, 146.80it/s] 17%|‚ñà‚ñã        | 566/3257 [00:04<00:19, 136.05it/s] 18%|‚ñà‚ñä        | 580/3257 [00:04<00:20, 128.58it/s] 18%|‚ñà‚ñä        | 596/3257 [00:04<00:19, 136.67it/s] 19%|‚ñà‚ñâ        | 611/3257 [00:04<00:18, 140.05it/s] 19%|‚ñà‚ñâ        | 626/3257 [00:04<00:19, 136.71it/s] 20%|‚ñà‚ñâ        | 642/3257 [00:04<00:18, 141.73it/s] 20%|‚ñà‚ñà        | 657/3257 [00:04<00:20, 128.65it/s] 21%|‚ñà‚ñà        | 674/3257 [00:04<00:18, 138.24it/s] 21%|‚ñà‚ñà        | 689/3257 [00:04<00:19, 132.53it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:05<00:18, 135.91it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:05<00:18, 139.38it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:05<00:18, 138.19it/s] 23%|‚ñà‚ñà‚ñé       | 749/3257 [00:05<00:18, 132.70it/s] 24%|‚ñà‚ñà‚ñé       | 768/3257 [00:05<00:17, 145.41it/s] 24%|‚ñà‚ñà‚ñç       | 783/3257 [00:05<00:18, 133.37it/s] 25%|‚ñà‚ñà‚ñç       | 800/3257 [00:05<00:17, 142.31it/s] 25%|‚ñà‚ñà‚ñå       | 815/3257 [00:05<00:17, 138.93it/s] 25%|‚ñà‚ñà‚ñå       | 830/3257 [00:06<00:18, 132.52it/s] 26%|‚ñà‚ñà‚ñå       | 844/3257 [00:06<00:18, 127.08it/s] 26%|‚ñà‚ñà‚ñã       | 859/3257 [00:06<00:18, 131.68it/s] 27%|‚ñà‚ñà‚ñã       | 873/3257 [00:06<00:17, 133.89it/s] 27%|‚ñà‚ñà‚ñã       | 887/3257 [00:06<00:17, 134.60it/s] 28%|‚ñà‚ñà‚ñä       | 904/3257 [00:06<00:16, 143.53it/s] 28%|‚ñà‚ñà‚ñä       | 919/3257 [00:06<00:16, 139.33it/s] 29%|‚ñà‚ñà‚ñä       | 934/3257 [00:06<00:16, 137.23it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:06<00:16, 139.99it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:06<00:15, 146.62it/s] 30%|‚ñà‚ñà‚ñà       | 981/3257 [00:07<00:16, 140.71it/s] 31%|‚ñà‚ñà‚ñà       | 996/3257 [00:07<00:16, 138.18it/s] 31%|‚ñà‚ñà‚ñà       | 1010/3257 [00:07<00:16, 138.67it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:07<00:16, 137.79it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:07<00:16, 133.13it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1056/3257 [00:07<00:16, 136.89it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1073/3257 [00:07<00:14, 145.62it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:07<00:15, 140.15it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1103/3257 [00:07<00:15, 141.15it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1118/3257 [00:08<00:15, 142.08it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1133/3257 [00:08<00:15, 137.72it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1147/3257 [00:08<00:15, 136.47it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1164/3257 [00:08<00:14, 145.76it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1179/3257 [00:08<00:15, 135.43it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1193/3257 [00:08<00:15, 130.26it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:08<00:16, 127.55it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1222/3257 [00:08<00:15, 133.37it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:08<00:13, 146.48it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1256/3257 [00:09<00:14, 141.08it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:09<00:13, 144.12it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1287/3257 [00:09<00:15, 129.42it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1302/3257 [00:09<00:14, 130.84it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1318/3257 [00:09<00:14, 136.74it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1334/3257 [00:09<00:13, 141.09it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:09<00:13, 137.89it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1365/3257 [00:09<00:13, 139.26it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1380/3257 [00:09<00:13, 140.56it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1395/3257 [00:10<00:13, 136.60it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:10<00:12, 144.62it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1429/3257 [00:10<00:12, 149.38it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1445/3257 [00:10<00:12, 147.74it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:10<00:11, 152.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1479/3257 [00:10<00:11, 152.90it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:10<00:11, 155.75it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:10<00:11, 155.67it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1529/3257 [00:10<00:12, 141.59it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1544/3257 [00:11<00:22, 77.30it/s]  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1559/3257 [00:11<00:19, 88.97it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:11<00:16, 99.39it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:11<00:15, 110.75it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1606/3257 [00:11<00:14, 117.89it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1621/3257 [00:11<00:13, 124.29it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:12<00:13, 124.05it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1649/3257 [00:12<00:12, 125.68it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1663/3257 [00:12<00:12, 127.70it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:12<00:12, 125.96it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:12<00:12, 126.72it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:12<00:11, 134.04it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1721/3257 [00:12<00:11, 134.96it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1735/3257 [00:12<00:12, 119.48it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1751/3257 [00:12<00:11, 129.51it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1766/3257 [00:13<00:11, 132.49it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1781/3257 [00:13<00:10, 136.48it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:13<00:10, 138.40it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1811/3257 [00:13<00:10, 132.31it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:13<00:10, 134.66it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1843/3257 [00:13<00:09, 143.50it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1858/3257 [00:13<00:09, 140.99it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1876/3257 [00:13<00:09, 149.69it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1892/3257 [00:13<00:09, 142.14it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1910/3257 [00:14<00:08, 151.30it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1926/3257 [00:14<00:09, 143.80it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1946/3257 [00:14<00:08, 157.62it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:14<00:08, 160.83it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:14<00:08, 153.35it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:14<00:08, 152.35it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2015/3257 [00:14<00:08, 149.76it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2032/3257 [00:14<00:07, 155.00it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2048/3257 [00:14<00:08, 138.66it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2063/3257 [00:15<00:08, 133.91it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2079/3257 [00:15<00:08, 140.03it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2094/3257 [00:15<00:08, 141.93it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2109/3257 [00:15<00:08, 137.58it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2123/3257 [00:15<00:08, 126.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2139/3257 [00:15<00:08, 134.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2153/3257 [00:15<00:08, 134.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:15<00:07, 138.57it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2183/3257 [00:15<00:07, 136.94it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2201/3257 [00:16<00:07, 145.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2216/3257 [00:16<00:07, 139.36it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2231/3257 [00:16<00:07, 139.71it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2246/3257 [00:16<00:07, 133.61it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:16<00:07, 134.33it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2274/3257 [00:16<00:07, 128.03it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2292/3257 [00:16<00:06, 142.19it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2307/3257 [00:16<00:06, 139.65it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2326/3257 [00:16<00:06, 151.24it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2343/3257 [00:17<00:05, 155.70it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2361/3257 [00:17<00:05, 161.28it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2378/3257 [00:17<00:05, 157.25it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2396/3257 [00:17<00:05, 163.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2413/3257 [00:17<00:05, 148.75it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2429/3257 [00:17<00:05, 147.41it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2444/3257 [00:17<00:05, 140.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2460/3257 [00:17<00:05, 144.18it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:17<00:05, 147.75it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2491/3257 [00:18<00:05, 145.99it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2508/3257 [00:18<00:05, 149.78it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:18<00:04, 149.31it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:18<00:04, 146.69it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2555/3257 [00:18<00:04, 140.45it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2570/3257 [00:18<00:05, 131.82it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2584/3257 [00:18<00:05, 132.07it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2598/3257 [00:18<00:05, 130.38it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2616/3257 [00:18<00:04, 141.99it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2632/3257 [00:19<00:04, 144.28it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2647/3257 [00:19<00:04, 136.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2661/3257 [00:19<00:04, 132.26it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2676/3257 [00:19<00:04, 135.58it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2691/3257 [00:19<00:04, 135.62it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2705/3257 [00:19<00:04, 120.33it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2718/3257 [00:19<00:04, 117.39it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2737/3257 [00:19<00:03, 133.77it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2752/3257 [00:20<00:03, 137.84it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2767/3257 [00:20<00:03, 139.89it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2782/3257 [00:20<00:03, 134.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2796/3257 [00:20<00:06, 68.62it/s]  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2810/3257 [00:20<00:05, 80.19it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:20<00:04, 89.44it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2835/3257 [00:21<00:04, 93.20it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2851/3257 [00:21<00:03, 107.49it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:21<00:02, 129.22it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2887/3257 [00:21<00:02, 133.15it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2902/3257 [00:21<00:02, 127.30it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2917/3257 [00:21<00:02, 132.39it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2931/3257 [00:21<00:02, 131.75it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2945/3257 [00:21<00:02, 128.03it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2959/3257 [00:21<00:02, 129.15it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:22<00:02, 133.62it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2990/3257 [00:22<00:02, 132.92it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3010/3257 [00:22<00:01, 150.61it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:22<00:01, 142.83it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3045/3257 [00:22<00:01, 154.63it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:22<00:01, 160.75it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3080/3257 [00:22<00:01, 159.43it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3097/3257 [00:22<00:01, 152.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:22<00:00, 162.70it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3135/3257 [00:23<00:00, 152.56it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3151/3257 [00:23<00:00, 146.04it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:23<00:00, 145.79it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3181/3257 [00:23<00:00, 139.26it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3198/3257 [00:23<00:00, 146.69it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:23<00:00, 139.93it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3230/3257 [00:23<00:00, 148.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3250/3257 [00:23<00:00, 161.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:23<00:00, 136.49it/s]
2023-02-07 20:33:16.733 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:33:16,734][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d36,n5,mc3,s0.246748,t4>', 'datetime': '2023-02-07T20:33:16.734395', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:33:16,734][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:33:16,734][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:33:17,445][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:33:17,446][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:33:17,564][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 38627 unique words (71.46% of original 54054, drops 15427)', 'datetime': '2023-02-07T20:33:17.564061', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:33:17,564][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 6527597 word corpus (99.64% of original 6550866, drops 23269)', 'datetime': '2023-02-07T20:33:17.564525', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:33:17,702][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:33:17,703][gensim.models.word2vec][INFO] - sample=0.246748 downsamples 0 most-common words
[2023-02-07 20:33:17,703][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6527597 word corpus (100.0%% of prior 6527597)', 'datetime': '2023-02-07T20:33:17.703888', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:33:17,942][gensim.models.word2vec][INFO] - estimated required memory for 38627 words and 36 dimensions: 31558484 bytes
[2023-02-07 20:33:17,943][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:33:17,951][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 38627 vocabulary and 36 features, using sg=1 hs=0 sample=0.2467480317423405 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T20:33:17.951156', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:33:18,953][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 48.91% examples, 3230288 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:19,952][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6472763 effective words) took 2.0s, 3238465 effective words/s
[2023-02-07 20:33:20,960][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 43.66% examples, 2889132 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:21,964][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 88.46% examples, 2870619 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:22,216][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6472763 effective words) took 2.3s, 2868138 effective words/s
[2023-02-07 20:33:23,219][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 51.89% examples, 3429595 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:24,094][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6472763 effective words) took 1.9s, 3448712 effective words/s
[2023-02-07 20:33:25,099][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 53.02% examples, 3491384 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:25,954][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6472763 effective words) took 1.9s, 3483646 effective words/s
[2023-02-07 20:33:26,956][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 53.12% examples, 3516145 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:27,804][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6472763 effective words) took 1.8s, 3501812 effective words/s
[2023-02-07 20:33:28,805][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 54.19% examples, 3588719 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:29,599][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6472763 effective words) took 1.8s, 3609283 effective words/s
[2023-02-07 20:33:30,602][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.91% examples, 3566278 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:31,417][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6472763 effective words) took 1.8s, 3563265 effective words/s
[2023-02-07 20:33:32,425][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 54.47% examples, 3583673 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:33,226][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6472763 effective words) took 1.8s, 3580840 effective words/s
[2023-02-07 20:33:34,230][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 55.08% examples, 3630061 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:35,002][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6472763 effective words) took 1.8s, 3647787 effective words/s
[2023-02-07 20:33:36,004][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 55.48% examples, 3676204 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:36,762][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6472763 effective words) took 1.8s, 3679764 effective words/s
[2023-02-07 20:33:37,764][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 55.70% examples, 3688776 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:38,522][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6472763 effective words) took 1.8s, 3680925 effective words/s
[2023-02-07 20:33:39,524][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 55.20% examples, 3648094 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:40,293][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6472763 effective words) took 1.8s, 3656981 effective words/s
[2023-02-07 20:33:41,296][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 55.70% examples, 3687892 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:33:42,050][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6472763 effective words) took 1.8s, 3687888 effective words/s
[2023-02-07 20:33:43,052][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 55.20% examples, 3649921 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:43,828][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6472763 effective words) took 1.8s, 3643650 effective words/s
[2023-02-07 20:33:44,833][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 55.48% examples, 3666142 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:45,596][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6472763 effective words) took 1.8s, 3664972 effective words/s
[2023-02-07 20:33:45,596][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (97091445 effective words) took 27.6s, 3512092 effective words/s', 'datetime': '2023-02-07T20:33:45.596594', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:33:45.596 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:33:48,243][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203243-ovypnzko/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:33:48.243635', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:33:48,244][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:33:48,285][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203243-ovypnzko/files/../tmp/embedding_model.pt
2023-02-07 20:33:48.285 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:33:49.339 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:33:49.741 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:33:58.071 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.108999831512741, 'test_mae': 0.7979855336751674, 'test_r2': -2.608765913457668}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.79
wandb: percentage 0.2854
wandb:   test_mae 0.79799
wandb:   test_mse 1.109
wandb:    test_r2 -2.60877
wandb: 
wandb: üöÄ View run confused-sweep-82 at: https://wandb.ai/xiaoqiz/mof2vec/runs/ovypnzko
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_203243-ovypnzko/logs
wandb: Agent Starting Run: l05pk34q with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 424
wandb: 	model.gensim.alpha: 0.00971112764642025
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.3123045865978263
wandb: 	model.gensim.vector_size: 398
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.01736018947602566
wandb: 	model.sklearn.max_depth: 37
wandb: 	model.sklearn.min_child_weight: 0.07621233963279911
wandb: 	model.sklearn.n_estimators: 1072
wandb: 	model.sklearn.num_leaves: 316
wandb: 	model.sklearn.reg_alpha: 0.004384238313928779
wandb: 	model.sklearn.reg_lambda: 0.07016624309408356
wandb: 	model.sklearn.subsample: 0.515533723683904
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203408-l05pk34q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-83
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/l05pk34q
2023-02-07 20:34:16.754 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 20:34:16.755 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 424 for sweep.
2023-02-07 20:34:16.756 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.00971112764642025 for sweep.
2023-02-07 20:34:16.756 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:34:16.756 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 20:34:16.756 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.3123045865978263 for sweep.
2023-02-07 20:34:16.756 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 398 for sweep.
2023-02-07 20:34:16.757 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 20:34:16.757 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.01736018947602566 for sweep.
2023-02-07 20:34:16.757 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 37 for sweep.
2023-02-07 20:34:16.757 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.07621233963279911 for sweep.
2023-02-07 20:34:16.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1072 for sweep.
2023-02-07 20:34:16.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 316 for sweep.
2023-02-07 20:34:16.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004384238313928779 for sweep.
2023-02-07 20:34:16.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.07016624309408356 for sweep.
2023-02-07 20:34:16.759 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.515533723683904 for sweep.
2023-02-07 20:34:16.759 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:34:16.768 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203408-l05pk34q/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 424, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 398, 'window': 2, 'min_count': 2, 'dm': 0, 'sample': 0.3123045865978263, 'workers': 4, 'alpha': 0.00971112764642025, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1072, 'max_depth': 37, 'num_leaves': 316, 'reg_alpha': 0.004384238313928779, 'reg_lambda': 0.07016624309408356, 'subsample': 0.515533723683904, 'min_child_weight': 0.07621233963279911, 'n_jobs': 4, 'learning_rate': 0.01736018947602566}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 21/3257 [00:00<00:15, 204.22it/s]  1%|‚ñè         | 42/3257 [00:00<00:15, 206.10it/s]  2%|‚ñè         | 67/3257 [00:00<00:15, 209.91it/s]  3%|‚ñé         | 91/3257 [00:00<00:14, 219.52it/s]  3%|‚ñé         | 113/3257 [00:00<00:14, 209.93it/s]  4%|‚ñç         | 136/3257 [00:00<00:14, 214.34it/s]  5%|‚ñç         | 160/3257 [00:00<00:13, 221.49it/s]  6%|‚ñå         | 183/3257 [00:00<00:14, 217.95it/s]  6%|‚ñã         | 205/3257 [00:00<00:14, 217.65it/s]  7%|‚ñã         | 232/3257 [00:01<00:13, 232.64it/s]  8%|‚ñä         | 256/3257 [00:01<00:13, 229.77it/s]  9%|‚ñä         | 282/3257 [00:01<00:12, 235.53it/s]  9%|‚ñâ         | 306/3257 [00:01<00:13, 224.23it/s] 10%|‚ñà         | 329/3257 [00:01<00:12, 225.65it/s] 11%|‚ñà         | 352/3257 [00:01<00:13, 221.96it/s] 12%|‚ñà‚ñè        | 375/3257 [00:01<00:13, 219.42it/s] 12%|‚ñà‚ñè        | 397/3257 [00:01<00:13, 215.16it/s] 13%|‚ñà‚ñé        | 421/3257 [00:01<00:13, 218.05it/s] 14%|‚ñà‚ñé        | 443/3257 [00:02<00:13, 201.61it/s] 14%|‚ñà‚ñç        | 467/3257 [00:02<00:13, 210.34it/s] 15%|‚ñà‚ñå        | 489/3257 [00:02<00:13, 211.62it/s] 16%|‚ñà‚ñå        | 515/3257 [00:02<00:12, 223.63it/s] 17%|‚ñà‚ñã        | 538/3257 [00:02<00:12, 222.52it/s] 17%|‚ñà‚ñã        | 561/3257 [00:02<00:12, 211.60it/s] 18%|‚ñà‚ñä        | 583/3257 [00:02<00:12, 207.14it/s] 19%|‚ñà‚ñä        | 607/3257 [00:02<00:12, 216.22it/s] 19%|‚ñà‚ñâ        | 631/3257 [00:02<00:11, 222.69it/s] 20%|‚ñà‚ñà        | 654/3257 [00:03<00:12, 214.77it/s] 21%|‚ñà‚ñà        | 676/3257 [00:03<00:12, 213.19it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:03<00:12, 207.62it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:03<00:11, 211.47it/s] 23%|‚ñà‚ñà‚ñé       | 743/3257 [00:03<00:12, 204.98it/s] 24%|‚ñà‚ñà‚ñé       | 768/3257 [00:03<00:11, 215.75it/s] 24%|‚ñà‚ñà‚ñç       | 790/3257 [00:03<00:12, 204.50it/s] 25%|‚ñà‚ñà‚ñç       | 812/3257 [00:03<00:11, 206.00it/s] 26%|‚ñà‚ñà‚ñå       | 833/3257 [00:03<00:11, 202.42it/s] 26%|‚ñà‚ñà‚ñå       | 854/3257 [00:04<00:12, 193.47it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:04<00:12, 197.24it/s] 27%|‚ñà‚ñà‚ñã       | 895/3257 [00:04<00:19, 124.25it/s] 28%|‚ñà‚ñà‚ñä       | 916/3257 [00:04<00:16, 140.87it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:04<00:14, 160.62it/s] 30%|‚ñà‚ñà‚ñâ       | 962/3257 [00:04<00:12, 177.27it/s] 30%|‚ñà‚ñà‚ñà       | 983/3257 [00:04<00:12, 181.73it/s] 31%|‚ñà‚ñà‚ñà       | 1004/3257 [00:04<00:12, 187.27it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:05<00:11, 191.83it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:05<00:11, 186.15it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:05<00:11, 192.18it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:05<00:11, 196.76it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1111/3257 [00:05<00:10, 203.93it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1132/3257 [00:05<00:10, 195.13it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1153/3257 [00:05<00:10, 198.52it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:05<00:10, 203.34it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1196/3257 [00:05<00:10, 188.20it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1216/3257 [00:06<00:10, 188.02it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:06<00:09, 204.22it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:06<00:09, 202.94it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1283/3257 [00:06<00:10, 195.27it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1303/3257 [00:06<00:10, 194.24it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1325/3257 [00:06<00:09, 200.70it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1347/3257 [00:06<00:09, 204.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1368/3257 [00:06<00:09, 198.71it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:06<00:09, 191.79it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:06<00:09, 204.46it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1435/3257 [00:07<00:08, 209.19it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:07<00:08, 218.28it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1482/3257 [00:07<00:08, 216.61it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1507/3257 [00:07<00:07, 223.58it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:07<00:08, 206.23it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1551/3257 [00:07<00:08, 202.62it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1572/3257 [00:07<00:08, 198.21it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1592/3257 [00:07<00:08, 198.05it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:07<00:07, 207.00it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1636/3257 [00:08<00:08, 198.81it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:08<00:08, 197.57it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:08<00:08, 193.66it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1699/3257 [00:08<00:07, 200.53it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1720/3257 [00:08<00:07, 198.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1740/3257 [00:08<00:08, 186.07it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:08<00:07, 197.35it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1786/3257 [00:08<00:07, 206.06it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1807/3257 [00:08<00:07, 197.05it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:09<00:07, 197.20it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1847/3257 [00:09<00:07, 196.45it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:09<00:06, 201.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1890/3257 [00:09<00:06, 202.24it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1911/3257 [00:09<00:06, 203.43it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1932/3257 [00:09<00:06, 201.33it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1959/3257 [00:09<00:05, 220.95it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:09<00:06, 209.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:09<00:05, 210.69it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2026/3257 [00:09<00:05, 211.77it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2048/3257 [00:10<00:06, 196.40it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2068/3257 [00:10<00:06, 192.57it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2089/3257 [00:10<00:05, 196.40it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2109/3257 [00:10<00:05, 194.63it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2129/3257 [00:10<00:06, 184.62it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2148/3257 [00:10<00:06, 182.18it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2170/3257 [00:10<00:05, 192.05it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2190/3257 [00:10<00:05, 193.08it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2210/3257 [00:10<00:05, 189.36it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2233/3257 [00:11<00:05, 200.02it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2254/3257 [00:11<00:07, 125.72it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2271/3257 [00:11<00:07, 134.62it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2296/3257 [00:11<00:06, 159.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2319/3257 [00:11<00:05, 175.75it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2345/3257 [00:11<00:04, 196.05it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2369/3257 [00:11<00:04, 206.80it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2394/3257 [00:12<00:03, 216.29it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2417/3257 [00:12<00:04, 207.55it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2439/3257 [00:12<00:04, 201.98it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2461/3257 [00:12<00:03, 206.51it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2484/3257 [00:12<00:03, 209.76it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2509/3257 [00:12<00:03, 220.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2532/3257 [00:12<00:03, 222.96it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2555/3257 [00:12<00:03, 210.26it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2577/3257 [00:12<00:03, 205.15it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2598/3257 [00:12<00:03, 202.27it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2624/3257 [00:13<00:02, 217.04it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2646/3257 [00:13<00:02, 208.46it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2668/3257 [00:13<00:02, 200.92it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2691/3257 [00:13<00:02, 205.27it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2712/3257 [00:13<00:02, 188.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2734/3257 [00:13<00:02, 195.80it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:13<00:02, 203.98it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2778/3257 [00:13<00:02, 199.68it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:13<00:02, 212.18it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2825/3257 [00:14<00:02, 202.70it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2848/3257 [00:14<00:01, 209.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2876/3257 [00:14<00:01, 227.76it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2899/3257 [00:14<00:01, 218.33it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2922/3257 [00:14<00:01, 221.04it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2945/3257 [00:14<00:01, 210.24it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2967/3257 [00:14<00:01, 211.42it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2989/3257 [00:14<00:01, 204.34it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3014/3257 [00:14<00:01, 214.76it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3038/3257 [00:15<00:00, 219.46it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:15<00:00, 226.63it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3086/3257 [00:15<00:00, 223.74it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:15<00:00, 228.07it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3133/3257 [00:15<00:00, 225.24it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3156/3257 [00:15<00:00, 215.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3178/3257 [00:15<00:00, 207.12it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:15<00:00, 215.35it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3225/3257 [00:15<00:00, 209.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:16<00:00, 218.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 202.57it/s]
2023-02-07 20:34:33.381 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:34:33,383][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d398,n5,mc2,s0.312305,t4>', 'datetime': '2023-02-07T20:34:33.383672', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:34:33,384][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:34:33,384][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:34:33,739][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 20:34:33,740][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:34:33,771][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 11155 unique words (85.41% of original 13061, drops 1906)', 'datetime': '2023-02-07T20:34:33.771251', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:34:33,771][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 3637464 word corpus (99.95% of original 3639370, drops 1906)', 'datetime': '2023-02-07T20:34:33.771812', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:34:33,809][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 20:34:33,810][gensim.models.word2vec][INFO] - sample=0.312305 downsamples 0 most-common words
[2023-02-07 20:34:33,810][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3637464 word corpus (100.0%% of prior 3637464)', 'datetime': '2023-02-07T20:34:33.810729', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:34:33,878][gensim.models.word2vec][INFO] - estimated required memory for 11155 words and 398 dimensions: 46931564 bytes
[2023-02-07 20:34:33,878][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:34:33,903][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11155 vocabulary and 398 features, using sg=1 hs=0 sample=0.3123045865978263 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T20:34:33.903290', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:34:34,907][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 52.13% examples, 1937555 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:35,646][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3640721 effective words) took 1.7s, 2090825 effective words/s
[2023-02-07 20:34:36,651][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 63.68% examples, 2352701 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:34:37,224][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3640721 effective words) took 1.6s, 2309304 effective words/s
[2023-02-07 20:34:38,231][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 58.21% examples, 2155986 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:38,912][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3640721 effective words) took 1.7s, 2159017 effective words/s
[2023-02-07 20:34:39,920][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 36.44% examples, 1347221 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:40,923][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 71.69% examples, 1324874 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:41,669][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3640721 effective words) took 2.8s, 1322179 effective words/s
[2023-02-07 20:34:42,673][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 53.73% examples, 2004378 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:43,478][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3640721 effective words) took 1.8s, 2013911 effective words/s
[2023-02-07 20:34:44,481][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 54.04% examples, 2016344 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:45,260][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3640721 effective words) took 1.8s, 2045993 effective words/s
[2023-02-07 20:34:46,262][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 55.39% examples, 2065069 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:47,021][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3640721 effective words) took 1.8s, 2070092 effective words/s
[2023-02-07 20:34:48,025][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 55.51% examples, 2069329 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:48,787][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3640721 effective words) took 1.8s, 2063676 effective words/s
[2023-02-07 20:34:49,796][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 55.39% examples, 2052958 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:50,560][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3640721 effective words) took 1.8s, 2056832 effective words/s
[2023-02-07 20:34:51,563][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 56.19% examples, 2098543 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:34:52,290][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3640721 effective words) took 1.7s, 2105842 effective words/s
[2023-02-07 20:34:53,295][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 56.80% examples, 2111652 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:54,021][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3640721 effective words) took 1.7s, 2105974 effective words/s
[2023-02-07 20:34:55,027][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 55.39% examples, 2060063 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:55,768][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3640721 effective words) took 1.7s, 2087548 effective words/s
[2023-02-07 20:34:56,774][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 56.56% examples, 2101574 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:34:57,505][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3640721 effective words) took 1.7s, 2098869 effective words/s
[2023-02-07 20:34:58,510][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 56.19% examples, 2092417 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:59,236][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3640721 effective words) took 1.7s, 2104127 effective words/s
[2023-02-07 20:35:00,241][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 55.88% examples, 2078817 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:35:00,974][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3640721 effective words) took 1.7s, 2097230 effective words/s
[2023-02-07 20:35:00,975][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54610815 effective words) took 27.1s, 2017280 effective words/s', 'datetime': '2023-02-07T20:35:00.975266', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:35:00.975 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:35:03,441][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203408-l05pk34q/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:35:03.441713', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:35:03,442][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:35:03,508][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203408-l05pk34q/files/../tmp/embedding_model.pt
2023-02-07 20:35:03.509 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:35:05.747 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:35:06.562 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:35:09.728 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.908195373223137, 'test_mae': 0.7028011427792303, 'test_r2': -1.8231122111631213}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.85
wandb: percentage 0.14593
wandb:   test_mae 0.7028
wandb:   test_mse 0.9082
wandb:    test_r2 -1.82311
wandb: 
wandb: üöÄ View run apricot-sweep-83 at: https://wandb.ai/xiaoqiz/mof2vec/runs/l05pk34q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_203408-l05pk34q/logs
wandb: Agent Starting Run: y8e8gvtr with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 539
wandb: 	model.gensim.alpha: 0.017954303714641295
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 4
wandb: 	model.gensim.sample: 0.5045207327380832
wandb: 	model.gensim.vector_size: 493
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.022656815027348003
wandb: 	model.sklearn.max_depth: 53
wandb: 	model.sklearn.min_child_weight: 0.058180961472979534
wandb: 	model.sklearn.n_estimators: 2749
wandb: 	model.sklearn.num_leaves: 469
wandb: 	model.sklearn.reg_alpha: 0.00801286929556139
wandb: 	model.sklearn.reg_lambda: 0.18166975813410485
wandb: 	model.sklearn.subsample: 0.6210754655306465
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203522-y8e8gvtr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-84
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/y8e8gvtr
2023-02-07 20:35:34.746 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:35:34.746 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 539 for sweep.
2023-02-07 20:35:34.747 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.017954303714641295 for sweep.
2023-02-07 20:35:34.747 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:35:34.747 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 4 for sweep.
2023-02-07 20:35:34.747 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5045207327380832 for sweep.
2023-02-07 20:35:34.748 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 493 for sweep.
2023-02-07 20:35:34.748 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 20:35:34.748 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.022656815027348003 for sweep.
2023-02-07 20:35:34.748 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 53 for sweep.
2023-02-07 20:35:34.749 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.058180961472979534 for sweep.
2023-02-07 20:35:34.749 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2749 for sweep.
2023-02-07 20:35:34.749 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 469 for sweep.
2023-02-07 20:35:34.749 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.00801286929556139 for sweep.
2023-02-07 20:35:34.749 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.18166975813410485 for sweep.
2023-02-07 20:35:34.750 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6210754655306465 for sweep.
2023-02-07 20:35:34.750 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:35:34.755 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203522-y8e8gvtr/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 539, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 493, 'window': 2, 'min_count': 4, 'dm': 0, 'sample': 0.5045207327380832, 'workers': 4, 'alpha': 0.017954303714641295, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2749, 'max_depth': 53, 'num_leaves': 469, 'reg_alpha': 0.00801286929556139, 'reg_lambda': 0.18166975813410485, 'subsample': 0.6210754655306465, 'min_child_weight': 0.058180961472979534, 'n_jobs': 4, 'learning_rate': 0.022656815027348003}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 178.72it/s]  1%|          | 40/3257 [00:00<00:15, 202.57it/s]  2%|‚ñè         | 61/3257 [00:00<00:16, 194.58it/s]  3%|‚ñé         | 84/3257 [00:00<00:15, 205.16it/s]  3%|‚ñé         | 105/3257 [00:00<00:15, 198.92it/s]  4%|‚ñç         | 125/3257 [00:00<00:17, 181.66it/s]  5%|‚ñç         | 149/3257 [00:00<00:15, 197.11it/s]  5%|‚ñå         | 169/3257 [00:00<00:15, 194.93it/s]  6%|‚ñå         | 190/3257 [00:00<00:15, 198.08it/s]  6%|‚ñã         | 211/3257 [00:01<00:15, 200.45it/s]  7%|‚ñã         | 233/3257 [00:01<00:14, 204.40it/s]  8%|‚ñä         | 254/3257 [00:01<00:14, 203.78it/s]  9%|‚ñä         | 277/3257 [00:01<00:14, 210.40it/s]  9%|‚ñâ         | 299/3257 [00:01<00:19, 152.65it/s] 10%|‚ñâ         | 321/3257 [00:01<00:17, 167.85it/s] 10%|‚ñà         | 340/3257 [00:01<00:16, 172.22it/s] 11%|‚ñà         | 362/3257 [00:01<00:15, 181.95it/s] 12%|‚ñà‚ñè        | 382/3257 [00:02<00:15, 182.22it/s] 12%|‚ñà‚ñè        | 402/3257 [00:02<00:15, 186.96it/s] 13%|‚ñà‚ñé        | 422/3257 [00:02<00:15, 186.85it/s] 14%|‚ñà‚ñé        | 442/3257 [00:02<00:16, 170.16it/s] 14%|‚ñà‚ñç        | 463/3257 [00:02<00:15, 180.35it/s] 15%|‚ñà‚ñç        | 482/3257 [00:02<00:15, 177.81it/s] 16%|‚ñà‚ñå        | 505/3257 [00:02<00:14, 190.19it/s] 16%|‚ñà‚ñå        | 526/3257 [00:02<00:14, 192.71it/s] 17%|‚ñà‚ñã        | 546/3257 [00:02<00:14, 190.55it/s] 17%|‚ñà‚ñã        | 566/3257 [00:03<00:15, 178.73it/s] 18%|‚ñà‚ñä        | 585/3257 [00:03<00:15, 176.37it/s] 19%|‚ñà‚ñä        | 606/3257 [00:03<00:14, 183.91it/s] 19%|‚ñà‚ñâ        | 625/3257 [00:03<00:14, 182.38it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:14, 182.49it/s] 20%|‚ñà‚ñà        | 664/3257 [00:03<00:14, 174.07it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:14, 173.61it/s] 22%|‚ñà‚ñà‚ñè       | 703/3257 [00:03<00:14, 179.57it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:03<00:14, 180.07it/s] 23%|‚ñà‚ñà‚ñé       | 741/3257 [00:04<00:14, 173.10it/s] 23%|‚ñà‚ñà‚ñé       | 763/3257 [00:04<00:13, 183.99it/s] 24%|‚ñà‚ñà‚ñç       | 782/3257 [00:04<00:14, 176.49it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:04<00:13, 182.04it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:04<00:14, 172.62it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:04<00:14, 167.38it/s] 26%|‚ñà‚ñà‚ñã       | 861/3257 [00:04<00:13, 173.44it/s] 27%|‚ñà‚ñà‚ñã       | 879/3257 [00:04<00:13, 171.55it/s] 28%|‚ñà‚ñà‚ñä       | 900/3257 [00:04<00:12, 181.98it/s] 28%|‚ñà‚ñà‚ñä       | 919/3257 [00:05<00:12, 181.11it/s] 29%|‚ñà‚ñà‚ñâ       | 938/3257 [00:05<00:13, 174.56it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:05<00:13, 175.83it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:05<00:13, 166.95it/s] 30%|‚ñà‚ñà‚ñà       | 991/3257 [00:05<00:14, 158.39it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:05<00:14, 153.53it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:05<00:13, 160.42it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1044/3257 [00:05<00:13, 162.10it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1064/3257 [00:05<00:12, 170.88it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1082/3257 [00:06<00:12, 171.81it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1102/3257 [00:06<00:12, 178.83it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1120/3257 [00:06<00:12, 177.47it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:06<00:12, 175.49it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1158/3257 [00:06<00:11, 176.25it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1176/3257 [00:06<00:12, 173.31it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:06<00:12, 158.74it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1211/3257 [00:06<00:12, 157.80it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:06<00:11, 171.29it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1251/3257 [00:07<00:12, 166.95it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:07<00:11, 170.84it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1289/3257 [00:07<00:12, 159.01it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1307/3257 [00:07<00:11, 163.46it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1327/3257 [00:07<00:11, 173.03it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1345/3257 [00:07<00:10, 174.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1363/3257 [00:07<00:11, 166.55it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1380/3257 [00:07<00:11, 157.10it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1396/3257 [00:07<00:11, 156.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1420/3257 [00:08<00:10, 177.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:08<00:10, 179.73it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:08<00:09, 195.32it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1484/3257 [00:08<00:08, 198.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1510/3257 [00:08<00:08, 213.68it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1532/3257 [00:08<00:12, 135.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:08<00:12, 142.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1570/3257 [00:08<00:10, 153.67it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1590/3257 [00:09<00:10, 164.72it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1612/3257 [00:09<00:09, 178.88it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:09<00:09, 178.86it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1653/3257 [00:09<00:08, 181.71it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1672/3257 [00:09<00:08, 179.41it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:09<00:08, 181.43it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1713/3257 [00:09<00:08, 191.18it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1733/3257 [00:09<00:08, 176.01it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1752/3257 [00:09<00:08, 179.17it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1772/3257 [00:10<00:08, 184.61it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1794/3257 [00:10<00:07, 193.24it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:10<00:07, 186.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1834/3257 [00:10<00:07, 189.06it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1856/3257 [00:10<00:07, 196.87it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1878/3257 [00:10<00:06, 202.54it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:10<00:06, 195.47it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1919/3257 [00:10<00:06, 192.48it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1946/3257 [00:10<00:06, 213.70it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1972/3257 [00:10<00:05, 225.07it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1995/3257 [00:11<00:05, 214.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2017/3257 [00:11<00:05, 208.68it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2039/3257 [00:11<00:05, 208.34it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2060/3257 [00:11<00:06, 179.09it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2079/3257 [00:11<00:06, 180.32it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2098/3257 [00:11<00:06, 173.24it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:11<00:06, 175.64it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2135/3257 [00:11<00:07, 156.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2152/3257 [00:12<00:07, 153.59it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:12<00:06, 156.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:12<00:06, 154.57it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:12<00:06, 161.74it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2221/3257 [00:12<00:06, 160.29it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:12<00:06, 154.37it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2254/3257 [00:12<00:06, 155.78it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:12<00:06, 150.33it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2287/3257 [00:12<00:06, 154.95it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2303/3257 [00:13<00:06, 152.80it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2324/3257 [00:13<00:05, 168.82it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2345/3257 [00:13<00:05, 179.45it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2364/3257 [00:13<00:04, 180.50it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2383/3257 [00:13<00:04, 182.54it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2403/3257 [00:13<00:04, 185.32it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:13<00:04, 169.40it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:13<00:05, 161.50it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2457/3257 [00:13<00:05, 159.03it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:14<00:04, 164.06it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2492/3257 [00:14<00:04, 165.15it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2513/3257 [00:14<00:04, 176.60it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2532/3257 [00:14<00:04, 178.94it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2550/3257 [00:14<00:04, 172.78it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2568/3257 [00:14<00:04, 153.76it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2584/3257 [00:14<00:04, 154.24it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2601/3257 [00:14<00:04, 158.13it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2623/3257 [00:14<00:03, 174.78it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2641/3257 [00:15<00:03, 169.54it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2659/3257 [00:15<00:03, 157.52it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2677/3257 [00:15<00:03, 160.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:15<00:03, 158.65it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2711/3257 [00:15<00:03, 143.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2729/3257 [00:15<00:03, 152.35it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2747/3257 [00:15<00:03, 159.61it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2764/3257 [00:15<00:03, 159.83it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2781/3257 [00:15<00:03, 156.95it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2799/3257 [00:16<00:02, 161.60it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2816/3257 [00:16<00:02, 152.00it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2832/3257 [00:16<00:02, 146.34it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2847/3257 [00:16<00:02, 147.14it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2866/3257 [00:16<00:02, 157.75it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2885/3257 [00:16<00:02, 163.92it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2902/3257 [00:17<00:04, 73.73it/s]  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2919/3257 [00:17<00:03, 88.03it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2933/3257 [00:17<00:03, 96.61it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:17<00:03, 102.47it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2961/3257 [00:17<00:02, 110.29it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:17<00:02, 116.48it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2990/3257 [00:17<00:02, 121.05it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3009/3257 [00:17<00:01, 138.38it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3024/3257 [00:17<00:01, 133.33it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3042/3257 [00:18<00:01, 145.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3061/3257 [00:18<00:01, 157.01it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3079/3257 [00:18<00:01, 162.25it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3096/3257 [00:18<00:00, 161.20it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:18<00:00, 172.74it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3136/3257 [00:18<00:00, 167.46it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3153/3257 [00:18<00:00, 161.64it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3171/3257 [00:18<00:00, 166.38it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3188/3257 [00:18<00:00, 160.36it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:19<00:00, 165.20it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3224/3257 [00:19<00:00, 162.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:19<00:00, 170.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 168.29it/s]
2023-02-07 20:35:54.929 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:35:54,930][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d493,n5,mc4,s0.504521,t4>', 'datetime': '2023-02-07T20:35:54.930833', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:35:54,931][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:35:54,931][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:35:55,522][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:35:55,522][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:35:55,606][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 retains 29175 unique words (68.32% of original 42701, drops 13526)', 'datetime': '2023-02-07T20:35:55.606694', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:35:55,607][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 leaves 5800681 word corpus (99.62% of original 5822992, drops 22311)', 'datetime': '2023-02-07T20:35:55.607127', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:35:55,715][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:35:55,716][gensim.models.word2vec][INFO] - sample=0.504521 downsamples 0 most-common words
[2023-02-07 20:35:55,716][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5800681 word corpus (100.0%% of prior 5800681)', 'datetime': '2023-02-07T20:35:55.716906', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:35:55,904][gensim.models.word2vec][INFO] - estimated required memory for 29175 words and 493 dimensions: 136727904 bytes
[2023-02-07 20:35:55,904][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:35:55,972][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 29175 vocabulary and 493 features, using sg=1 hs=0 sample=0.5045207327380832 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T20:35:55.972524', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:35:56,977][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 24.81% examples, 1421131 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:35:57,979][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 49.89% examples, 1464803 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:35:58,987][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 77.68% examples, 1503421 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:35:59,766][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5774537 effective words) took 3.8s, 1523042 effective words/s
[2023-02-07 20:36:00,777][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 29.57% examples, 1692489 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:01,779][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 56.74% examples, 1666586 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:02,780][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 85.11% examples, 1647915 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:03,282][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5774537 effective words) took 3.5s, 1642855 effective words/s
[2023-02-07 20:36:04,289][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 28.58% examples, 1649783 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:05,297][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 56.03% examples, 1645649 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:06,306][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 84.89% examples, 1637287 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:06,809][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5774537 effective words) took 3.5s, 1638682 effective words/s
[2023-02-07 20:36:07,813][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 28.52% examples, 1646735 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:08,815][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 55.82% examples, 1647233 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:09,827][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 85.60% examples, 1652124 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:10,294][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5774537 effective words) took 3.5s, 1657710 effective words/s
[2023-02-07 20:36:11,298][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 29.26% examples, 1688507 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:12,308][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 58.03% examples, 1701924 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:13,313][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 88.12% examples, 1696868 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:13,697][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5774537 effective words) took 3.4s, 1697812 effective words/s
[2023-02-07 20:36:14,701][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 28.89% examples, 1670058 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:15,710][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 57.48% examples, 1686257 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:16,711][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 88.58% examples, 1705641 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:17,082][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5774537 effective words) took 3.4s, 1706786 effective words/s
[2023-02-07 20:36:18,085][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 29.57% examples, 1706308 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:19,094][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 58.03% examples, 1703281 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:20,100][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 88.64% examples, 1706085 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:20,469][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5774537 effective words) took 3.4s, 1705682 effective words/s
[2023-02-07 20:36:21,472][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 28.89% examples, 1672789 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:22,476][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 56.83% examples, 1675650 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:23,480][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 86.83% examples, 1681694 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:23,899][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5774537 effective words) took 3.4s, 1684526 effective words/s
[2023-02-07 20:36:24,902][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 29.26% examples, 1690003 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:25,905][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 58.15% examples, 1713046 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:26,908][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 88.64% examples, 1711625 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:27,272][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5774537 effective words) took 3.4s, 1712564 effective words/s
[2023-02-07 20:36:28,281][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 29.57% examples, 1696709 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:29,285][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 58.58% examples, 1716915 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:30,292][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 88.64% examples, 1705698 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:30,647][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5774537 effective words) took 3.4s, 1712262 effective words/s
[2023-02-07 20:36:31,652][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 29.81% examples, 1720000 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:32,653][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 58.21% examples, 1712380 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:33,656][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 88.33% examples, 1705172 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:34,034][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5774537 effective words) took 3.4s, 1705441 effective words/s
[2023-02-07 20:36:35,039][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 29.57% examples, 1703433 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:36,042][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 58.03% examples, 1707044 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:37,044][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 88.36% examples, 1705120 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:37,418][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5774537 effective words) took 3.4s, 1707409 effective words/s
[2023-02-07 20:36:38,425][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 29.57% examples, 1698589 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:39,426][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 58.34% examples, 1715030 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:40,430][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 88.64% examples, 1709634 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:40,796][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5774537 effective words) took 3.4s, 1709880 effective words/s
[2023-02-07 20:36:41,803][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 29.23% examples, 1682246 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:42,806][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 57.14% examples, 1680165 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:43,812][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 86.58% examples, 1672194 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:44,255][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5774537 effective words) took 3.5s, 1670193 effective words/s
[2023-02-07 20:36:45,268][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 28.89% examples, 1656518 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:46,272][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 56.74% examples, 1664742 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:47,280][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 86.25% examples, 1661028 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:47,730][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5774537 effective words) took 3.5s, 1663036 effective words/s
[2023-02-07 20:36:47,730][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86618055 effective words) took 51.8s, 1673528 effective words/s', 'datetime': '2023-02-07T20:36:47.730754', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:36:47.731 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:36:52,959][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203522-y8e8gvtr/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:36:52.959492', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:36:52,960][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203522-y8e8gvtr/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 20:36:53,022][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203522-y8e8gvtr/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 20:36:53,081][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:36:53,107][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203522-y8e8gvtr/files/../tmp/embedding_model.pt
2023-02-07 20:36:53.107 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:36:55.681 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:36:56.578 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:37:18.137 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9117615413891491, 'test_mae': 0.7352751764508844, 'test_r2': -2.500635248080789}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.88
wandb: percentage 0.31676
wandb:   test_mae 0.73528
wandb:   test_mse 0.91176
wandb:    test_r2 -2.50064
wandb: 
wandb: üöÄ View run robust-sweep-84 at: https://wandb.ai/xiaoqiz/mof2vec/runs/y8e8gvtr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_203522-y8e8gvtr/logs
wandb: Agent Starting Run: g8j1h95r with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 811
wandb: 	model.gensim.alpha: 0.015379769945871272
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.3614134601028616
wandb: 	model.gensim.vector_size: 311
wandb: 	model.gensim.window: 4
wandb: 	model.sklearn.learning_rate: 0.010101026751199204
wandb: 	model.sklearn.max_depth: 49
wandb: 	model.sklearn.min_child_weight: 0.05940650485306533
wandb: 	model.sklearn.n_estimators: 518
wandb: 	model.sklearn.num_leaves: 185
wandb: 	model.sklearn.reg_alpha: 0.007955008409376452
wandb: 	model.sklearn.reg_lambda: 0.00940197376842816
wandb: 	model.sklearn.subsample: 0.2747312045049176
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203736-g8j1h95r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-85
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/g8j1h95r
2023-02-07 20:37:44.441 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 20:37:44.442 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 811 for sweep.
2023-02-07 20:37:44.442 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.015379769945871272 for sweep.
2023-02-07 20:37:44.442 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:37:44.443 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 20:37:44.443 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.3614134601028616 for sweep.
2023-02-07 20:37:44.443 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 311 for sweep.
2023-02-07 20:37:44.443 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 4 for sweep.
2023-02-07 20:37:44.444 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.010101026751199204 for sweep.
2023-02-07 20:37:44.444 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 49 for sweep.
2023-02-07 20:37:44.444 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05940650485306533 for sweep.
2023-02-07 20:37:44.444 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 518 for sweep.
2023-02-07 20:37:44.445 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 185 for sweep.
2023-02-07 20:37:44.445 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.007955008409376452 for sweep.
2023-02-07 20:37:44.445 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.00940197376842816 for sweep.
2023-02-07 20:37:44.446 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2747312045049176 for sweep.
2023-02-07 20:37:44.446 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:37:44.454 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203736-g8j1h95r/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 811, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 311, 'window': 4, 'min_count': 5, 'dm': 0, 'sample': 0.3614134601028616, 'workers': 4, 'alpha': 0.015379769945871272, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 518, 'max_depth': 49, 'num_leaves': 185, 'reg_alpha': 0.007955008409376452, 'reg_lambda': 0.00940197376842816, 'subsample': 0.2747312045049176, 'min_child_weight': 0.05940650485306533, 'n_jobs': 4, 'learning_rate': 0.010101026751199204}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 19/3257 [00:00<00:17, 186.82it/s]  1%|‚ñè         | 41/3257 [00:00<00:15, 202.32it/s]  2%|‚ñè         | 63/3257 [00:00<00:15, 209.24it/s]  3%|‚ñé         | 85/3257 [00:00<00:14, 213.06it/s]  3%|‚ñé         | 107/3257 [00:00<00:15, 200.45it/s]  4%|‚ñç         | 131/3257 [00:00<00:14, 209.44it/s]  5%|‚ñç         | 155/3257 [00:00<00:14, 217.90it/s]  5%|‚ñå         | 177/3257 [00:00<00:14, 209.59it/s]  6%|‚ñå         | 201/3257 [00:00<00:14, 211.09it/s]  7%|‚ñã         | 230/3257 [00:01<00:13, 228.44it/s]  8%|‚ñä         | 253/3257 [00:01<00:13, 225.02it/s]  8%|‚ñä         | 276/3257 [00:01<00:13, 222.41it/s]  9%|‚ñâ         | 300/3257 [00:01<00:13, 224.04it/s] 10%|‚ñâ         | 325/3257 [00:01<00:12, 230.01it/s] 11%|‚ñà         | 349/3257 [00:01<00:13, 215.53it/s] 11%|‚ñà‚ñè        | 373/3257 [00:01<00:13, 221.19it/s] 12%|‚ñà‚ñè        | 396/3257 [00:01<00:13, 210.81it/s] 13%|‚ñà‚ñé        | 419/3257 [00:01<00:13, 216.02it/s] 14%|‚ñà‚ñé        | 441/3257 [00:02<00:14, 192.63it/s] 14%|‚ñà‚ñç        | 464/3257 [00:02<00:13, 201.69it/s] 15%|‚ñà‚ñç        | 485/3257 [00:02<00:13, 200.42it/s] 16%|‚ñà‚ñå        | 510/3257 [00:02<00:12, 211.75it/s] 16%|‚ñà‚ñã        | 532/3257 [00:02<00:13, 209.03it/s] 17%|‚ñà‚ñã        | 556/3257 [00:02<00:12, 215.75it/s] 18%|‚ñà‚ñä        | 578/3257 [00:02<00:13, 192.30it/s] 19%|‚ñà‚ñä        | 603/3257 [00:02<00:12, 206.22it/s] 19%|‚ñà‚ñâ        | 625/3257 [00:02<00:12, 202.72it/s] 20%|‚ñà‚ñâ        | 646/3257 [00:03<00:12, 201.76it/s] 20%|‚ñà‚ñà        | 667/3257 [00:03<00:12, 200.27it/s] 21%|‚ñà‚ñà        | 688/3257 [00:03<00:13, 197.40it/s] 22%|‚ñà‚ñà‚ñè       | 712/3257 [00:03<00:12, 207.84it/s] 23%|‚ñà‚ñà‚ñé       | 733/3257 [00:03<00:12, 202.45it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:03<00:12, 202.08it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:03<00:12, 203.89it/s] 25%|‚ñà‚ñà‚ñç       | 799/3257 [00:03<00:11, 210.45it/s] 25%|‚ñà‚ñà‚ñå       | 821/3257 [00:03<00:11, 208.75it/s] 26%|‚ñà‚ñà‚ñå       | 842/3257 [00:04<00:12, 193.63it/s] 26%|‚ñà‚ñà‚ñã       | 863/3257 [00:04<00:12, 195.40it/s] 27%|‚ñà‚ñà‚ñã       | 883/3257 [00:04<00:12, 192.82it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:04<00:11, 199.03it/s] 28%|‚ñà‚ñà‚ñä       | 927/3257 [00:04<00:11, 203.87it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:04<00:11, 201.43it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:04<00:11, 205.08it/s] 30%|‚ñà‚ñà‚ñà       | 991/3257 [00:04<00:11, 200.71it/s] 31%|‚ñà‚ñà‚ñà       | 1012/3257 [00:04<00:11, 197.97it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1032/3257 [00:05<00:18, 120.96it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1050/3257 [00:05<00:16, 132.39it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1072/3257 [00:05<00:14, 150.57it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:05<00:13, 157.44it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1114/3257 [00:05<00:12, 174.45it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1134/3257 [00:05<00:12, 173.04it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1154/3257 [00:05<00:11, 178.65it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:05<00:11, 184.71it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1195/3257 [00:06<00:11, 178.72it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1214/3257 [00:06<00:11, 178.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1239/3257 [00:06<00:10, 197.50it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1260/3257 [00:06<00:10, 195.37it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1280/3257 [00:06<00:10, 190.76it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1300/3257 [00:06<00:10, 189.38it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:06<00:09, 194.77it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:06<00:09, 203.92it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1365/3257 [00:06<00:09, 193.02it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:07<00:09, 191.89it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1408/3257 [00:07<00:09, 201.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:07<00:08, 205.91it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1455/3257 [00:07<00:08, 211.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:07<00:08, 209.43it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1502/3257 [00:07<00:07, 219.47it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1525/3257 [00:07<00:08, 204.69it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:07<00:08, 197.45it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1568/3257 [00:07<00:08, 202.81it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1589/3257 [00:08<00:08, 202.92it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1613/3257 [00:08<00:07, 211.87it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:08<00:08, 202.46it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1656/3257 [00:08<00:07, 201.51it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:08<00:08, 190.15it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1699/3257 [00:08<00:07, 196.30it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1719/3257 [00:08<00:07, 195.64it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1739/3257 [00:08<00:08, 183.56it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1761/3257 [00:08<00:07, 193.22it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1785/3257 [00:09<00:07, 204.86it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1806/3257 [00:09<00:07, 200.90it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:09<00:07, 199.16it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:09<00:06, 201.90it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1873/3257 [00:09<00:06, 211.91it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:09<00:06, 206.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1917/3257 [00:09<00:06, 207.35it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1943/3257 [00:09<00:05, 222.16it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1968/3257 [00:09<00:05, 228.14it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1991/3257 [00:09<00:05, 220.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2014/3257 [00:10<00:05, 215.85it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2037/3257 [00:10<00:05, 219.78it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2060/3257 [00:10<00:06, 193.30it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:10<00:05, 202.26it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2104/3257 [00:10<00:05, 199.94it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2125/3257 [00:10<00:05, 195.17it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2145/3257 [00:10<00:05, 191.28it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:10<00:05, 201.61it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2189/3257 [00:10<00:05, 201.48it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2210/3257 [00:11<00:05, 195.30it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2233/3257 [00:11<00:05, 203.90it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2254/3257 [00:11<00:07, 125.81it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2271/3257 [00:11<00:07, 134.38it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2295/3257 [00:11<00:06, 156.59it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:11<00:05, 166.35it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2340/3257 [00:11<00:04, 186.95it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2364/3257 [00:12<00:04, 200.83it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2387/3257 [00:12<00:04, 207.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2409/3257 [00:12<00:04, 202.83it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2431/3257 [00:12<00:04, 198.23it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2452/3257 [00:12<00:04, 196.91it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2477/3257 [00:12<00:03, 211.06it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2502/3257 [00:12<00:03, 221.50it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2526/3257 [00:12<00:03, 223.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2550/3257 [00:12<00:03, 225.63it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:13<00:03, 206.82it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2595/3257 [00:13<00:03, 204.12it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2623/3257 [00:13<00:02, 222.89it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2646/3257 [00:13<00:02, 217.91it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2669/3257 [00:13<00:02, 212.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2692/3257 [00:13<00:02, 216.37it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2714/3257 [00:13<00:02, 200.18it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2738/3257 [00:13<00:02, 210.31it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:13<00:02, 212.10it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2783/3257 [00:13<00:02, 212.54it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2806/3257 [00:14<00:02, 216.91it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2828/3257 [00:14<00:02, 206.55it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2850/3257 [00:14<00:01, 208.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2880/3257 [00:14<00:01, 232.90it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2904/3257 [00:14<00:01, 213.76it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:14<00:01, 219.22it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2951/3257 [00:14<00:01, 206.76it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2974/3257 [00:14<00:01, 212.86it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2996/3257 [00:15<00:01, 205.21it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:15<00:01, 207.01it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3042/3257 [00:15<00:01, 214.67it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3067/3257 [00:15<00:00, 223.27it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3090/3257 [00:15<00:00, 219.17it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3116/3257 [00:15<00:00, 229.24it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3140/3257 [00:15<00:00, 217.73it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3162/3257 [00:15<00:00, 213.29it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3184/3257 [00:15<00:00, 205.15it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3208/3257 [00:15<00:00, 211.58it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3230/3257 [00:16<00:00, 210.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:16<00:00, 214.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 201.02it/s]
2023-02-07 20:38:01.193 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:38:01,194][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d311,n5,mc5,s0.361413,t4>', 'datetime': '2023-02-07T20:38:01.194635', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:38:01,195][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:38:01,195][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:38:01,548][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 20:38:01,549][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:38:01,569][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 6948 unique words (53.20% of original 13061, drops 6113)', 'datetime': '2023-02-07T20:38:01.569561', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:38:01,570][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 3624596 word corpus (99.59% of original 3639370, drops 14774)', 'datetime': '2023-02-07T20:38:01.570030', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:38:01,593][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 20:38:01,594][gensim.models.word2vec][INFO] - sample=0.361413 downsamples 0 most-common words
[2023-02-07 20:38:01,594][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3624596 word corpus (100.0%% of prior 3624596)', 'datetime': '2023-02-07T20:38:01.594641', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:38:01,635][gensim.models.word2vec][INFO] - estimated required memory for 6948 words and 311 dimensions: 25463732 bytes
[2023-02-07 20:38:01,636][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:38:01,651][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 6948 vocabulary and 311 features, using sg=1 hs=0 sample=0.3614134601028616 negative=5 window=4 shrink_windows=True', 'datetime': '2023-02-07T20:38:01.651256', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:38:02,654][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 57.35% examples, 2125667 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:38:03,318][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3627853 effective words) took 1.7s, 2178655 effective words/s
[2023-02-07 20:38:04,324][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 65.09% examples, 2399988 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:38:04,863][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3627853 effective words) took 1.5s, 2351068 effective words/s
[2023-02-07 20:38:05,868][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 63.68% examples, 2343199 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:38:06,363][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3627853 effective words) took 1.5s, 2420578 effective words/s
[2023-02-07 20:38:07,366][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 74.18% examples, 2726811 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:38:07,679][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3627853 effective words) took 1.3s, 2760863 effective words/s
[2023-02-07 20:38:08,683][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 69.05% examples, 2551734 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:38:09,115][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3627853 effective words) took 1.4s, 2528010 effective words/s
[2023-02-07 20:38:10,118][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 64.08% examples, 2366496 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:38:10,648][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3627853 effective words) took 1.5s, 2368318 effective words/s
[2023-02-07 20:38:11,651][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 63.92% examples, 2358018 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:38:12,181][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3627853 effective words) took 1.5s, 2368949 effective words/s
[2023-02-07 20:38:13,184][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 64.08% examples, 2367961 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:38:13,707][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3627853 effective words) took 1.5s, 2380122 effective words/s
[2023-02-07 20:38:14,710][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 64.78% examples, 2396832 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:38:15,229][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3627853 effective words) took 1.5s, 2385697 effective words/s
[2023-02-07 20:38:16,232][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 65.06% examples, 2401628 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:38:16,738][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3627853 effective words) took 1.5s, 2406232 effective words/s
[2023-02-07 20:38:17,742][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 64.08% examples, 2366086 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:38:18,276][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3627853 effective words) took 1.5s, 2361465 effective words/s
[2023-02-07 20:38:19,283][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 63.92% examples, 2351992 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:38:19,812][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3627853 effective words) took 1.5s, 2365564 effective words/s
[2023-02-07 20:38:20,816][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 64.75% examples, 2388726 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:38:21,337][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3627853 effective words) took 1.5s, 2381789 effective words/s
[2023-02-07 20:38:22,343][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 63.92% examples, 2350779 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:38:22,882][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3627853 effective words) took 1.5s, 2349752 effective words/s
[2023-02-07 20:38:23,885][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 63.37% examples, 2341008 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:38:24,444][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3627853 effective words) took 1.6s, 2327031 effective words/s
[2023-02-07 20:38:24,444][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54417795 effective words) took 22.8s, 2387501 effective words/s', 'datetime': '2023-02-07T20:38:24.444538', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:38:24.445 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:38:26,590][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203736-g8j1h95r/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:38:26.590115', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:38:26,590][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:38:26,629][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203736-g8j1h95r/files/../tmp/embedding_model.pt
2023-02-07 20:38:26.629 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:38:28.540 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:38:29.255 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:38:33.801 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9639656161462173, 'test_mae': 0.7393180984386637, 'test_r2': -2.0815822637266463}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.89
wandb: percentage 0.46803
wandb:   test_mae 0.73932
wandb:   test_mse 0.96397
wandb:    test_r2 -2.08158
wandb: 
wandb: üöÄ View run avid-sweep-85 at: https://wandb.ai/xiaoqiz/mof2vec/runs/g8j1h95r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_203736-g8j1h95r/logs
wandb: Agent Starting Run: ddif9omh with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 660
wandb: 	model.gensim.alpha: 0.006872301656263293
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.2734265627937742
wandb: 	model.gensim.vector_size: 172
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.0012842742540852244
wandb: 	model.sklearn.max_depth: 20
wandb: 	model.sklearn.min_child_weight: 0.09796875452460715
wandb: 	model.sklearn.n_estimators: 1491
wandb: 	model.sklearn.num_leaves: 339
wandb: 	model.sklearn.reg_alpha: 0.0028590325149287455
wandb: 	model.sklearn.reg_lambda: 0.02838281555427155
wandb: 	model.sklearn.subsample: 0.22594911252007988
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203845-ddif9omh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-86
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/ddif9omh
2023-02-07 20:38:53.614 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:38:53.615 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 660 for sweep.
2023-02-07 20:38:53.615 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.006872301656263293 for sweep.
2023-02-07 20:38:53.616 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:38:53.616 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 20:38:53.616 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2734265627937742 for sweep.
2023-02-07 20:38:53.617 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 172 for sweep.
2023-02-07 20:38:53.617 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 20:38:53.617 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0012842742540852244 for sweep.
2023-02-07 20:38:53.617 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 20 for sweep.
2023-02-07 20:38:53.617 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09796875452460715 for sweep.
2023-02-07 20:38:53.618 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1491 for sweep.
2023-02-07 20:38:53.618 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 339 for sweep.
2023-02-07 20:38:53.618 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0028590325149287455 for sweep.
2023-02-07 20:38:53.618 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.02838281555427155 for sweep.
2023-02-07 20:38:53.619 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.22594911252007988 for sweep.
2023-02-07 20:38:53.619 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:38:53.629 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203845-ddif9omh/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 660, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 172, 'window': 8, 'min_count': 2, 'dm': 0, 'sample': 0.2734265627937742, 'workers': 4, 'alpha': 0.006872301656263293, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1491, 'max_depth': 20, 'num_leaves': 339, 'reg_alpha': 0.0028590325149287455, 'reg_lambda': 0.02838281555427155, 'subsample': 0.22594911252007988, 'min_child_weight': 0.09796875452460715, 'n_jobs': 4, 'learning_rate': 0.0012842742540852244}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:25, 126.33it/s]  1%|          | 33/3257 [00:00<00:19, 161.92it/s]  2%|‚ñè         | 50/3257 [00:00<00:21, 149.16it/s]  2%|‚ñè         | 67/3257 [00:00<00:22, 143.38it/s]  3%|‚ñé         | 85/3257 [00:00<00:20, 154.33it/s]  3%|‚ñé         | 101/3257 [00:00<00:21, 148.19it/s]  4%|‚ñé         | 116/3257 [00:00<00:22, 137.83it/s]  4%|‚ñç         | 132/3257 [00:00<00:21, 143.63it/s]  5%|‚ñç         | 150/3257 [00:01<00:20, 151.70it/s]  5%|‚ñå         | 166/3257 [00:01<00:21, 143.01it/s]  6%|‚ñå         | 181/3257 [00:01<00:21, 141.84it/s]  6%|‚ñå         | 198/3257 [00:01<00:20, 148.84it/s]  7%|‚ñã         | 216/3257 [00:01<00:19, 153.20it/s]  7%|‚ñã         | 236/3257 [00:01<00:18, 161.38it/s]  8%|‚ñä         | 253/3257 [00:01<00:19, 156.70it/s]  8%|‚ñä         | 269/3257 [00:01<00:19, 153.13it/s]  9%|‚ñâ         | 291/3257 [00:01<00:17, 170.27it/s]  9%|‚ñâ         | 309/3257 [00:02<00:17, 164.81it/s] 10%|‚ñà         | 328/3257 [00:02<00:17, 164.97it/s] 11%|‚ñà         | 345/3257 [00:02<00:18, 159.05it/s] 11%|‚ñà         | 362/3257 [00:02<00:18, 159.41it/s] 12%|‚ñà‚ñè        | 378/3257 [00:02<00:19, 148.65it/s] 12%|‚ñà‚ñè        | 393/3257 [00:02<00:19, 147.00it/s] 13%|‚ñà‚ñé        | 411/3257 [00:02<00:18, 152.81it/s] 13%|‚ñà‚ñé        | 427/3257 [00:03<00:32, 88.19it/s]  14%|‚ñà‚ñé        | 440/3257 [00:03<00:29, 95.55it/s] 14%|‚ñà‚ñç        | 456/3257 [00:03<00:25, 108.32it/s] 14%|‚ñà‚ñç        | 471/3257 [00:03<00:23, 117.46it/s] 15%|‚ñà‚ñç        | 485/3257 [00:03<00:23, 118.91it/s] 15%|‚ñà‚ñå        | 501/3257 [00:03<00:21, 129.13it/s] 16%|‚ñà‚ñå        | 517/3257 [00:03<00:20, 134.28it/s] 16%|‚ñà‚ñã        | 532/3257 [00:03<00:20, 132.85it/s] 17%|‚ñà‚ñã        | 547/3257 [00:03<00:20, 135.23it/s] 17%|‚ñà‚ñã        | 561/3257 [00:04<00:20, 129.84it/s] 18%|‚ñà‚ñä        | 575/3257 [00:04<00:21, 123.07it/s] 18%|‚ñà‚ñä        | 590/3257 [00:04<00:20, 130.15it/s] 19%|‚ñà‚ñä        | 605/3257 [00:04<00:19, 135.10it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:04<00:19, 136.39it/s] 20%|‚ñà‚ñâ        | 638/3257 [00:04<00:17, 148.09it/s] 20%|‚ñà‚ñà        | 653/3257 [00:04<00:18, 141.10it/s] 21%|‚ñà‚ñà        | 668/3257 [00:04<00:18, 136.74it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:19, 135.41it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:05<00:18, 138.59it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:05<00:16, 150.68it/s] 23%|‚ñà‚ñà‚ñé       | 733/3257 [00:05<00:18, 140.20it/s] 23%|‚ñà‚ñà‚ñé       | 748/3257 [00:05<00:18, 136.12it/s] 23%|‚ñà‚ñà‚ñé       | 765/3257 [00:05<00:17, 143.28it/s] 24%|‚ñà‚ñà‚ñç       | 780/3257 [00:05<00:18, 135.68it/s] 24%|‚ñà‚ñà‚ñç       | 796/3257 [00:05<00:17, 140.92it/s] 25%|‚ñà‚ñà‚ñç       | 811/3257 [00:05<00:17, 143.31it/s] 25%|‚ñà‚ñà‚ñå       | 826/3257 [00:05<00:18, 134.77it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:06<00:17, 135.61it/s] 26%|‚ñà‚ñà‚ñå       | 854/3257 [00:06<00:18, 131.76it/s] 27%|‚ñà‚ñà‚ñã       | 870/3257 [00:06<00:17, 137.85it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:06<00:17, 133.45it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:06<00:15, 150.41it/s] 28%|‚ñà‚ñà‚ñä       | 921/3257 [00:06<00:15, 149.00it/s] 29%|‚ñà‚ñà‚ñä       | 936/3257 [00:06<00:15, 147.09it/s] 29%|‚ñà‚ñà‚ñâ       | 954/3257 [00:06<00:14, 155.68it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:06<00:15, 152.12it/s] 30%|‚ñà‚ñà‚ñà       | 986/3257 [00:07<00:15, 147.09it/s] 31%|‚ñà‚ñà‚ñà       | 1002/3257 [00:07<00:15, 147.14it/s] 31%|‚ñà‚ñà‚ñà       | 1017/3257 [00:07<00:15, 146.20it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1032/3257 [00:07<00:15, 140.87it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1047/3257 [00:07<00:16, 134.79it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:07<00:15, 138.19it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:15, 138.43it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:07<00:15, 137.67it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:07<00:14, 146.56it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1127/3257 [00:08<00:15, 135.53it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1141/3257 [00:08<00:15, 134.93it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1156/3257 [00:08<00:15, 138.74it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:08<00:15, 139.04it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:08<00:15, 132.28it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1199/3257 [00:08<00:16, 128.45it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1212/3257 [00:08<00:16, 126.37it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1231/3257 [00:08<00:14, 143.66it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1246/3257 [00:08<00:14, 136.66it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:09<00:14, 141.32it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:09<00:14, 133.45it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:09<00:15, 130.87it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1306/3257 [00:09<00:14, 135.59it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:09<00:14, 138.18it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:09<00:13, 146.83it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:09<00:13, 137.97it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:09<00:13, 139.36it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:09<00:13, 136.61it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:10<00:13, 140.94it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:10<00:11, 156.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1438/3257 [00:10<00:12, 149.18it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:10<00:10, 165.84it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1479/3257 [00:10<00:10, 170.71it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1501/3257 [00:10<00:09, 183.08it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1520/3257 [00:10<00:10, 170.64it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1538/3257 [00:10<00:10, 165.99it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:11<00:14, 116.21it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:11<00:12, 129.55it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:11<00:11, 144.91it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:11<00:10, 158.06it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:11<00:10, 158.46it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1652/3257 [00:11<00:09, 160.67it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1669/3257 [00:11<00:09, 161.69it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1686/3257 [00:11<00:09, 163.21it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1706/3257 [00:11<00:08, 172.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1726/3257 [00:12<00:08, 179.82it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:12<00:09, 156.67it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1765/3257 [00:12<00:08, 166.86it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1786/3257 [00:12<00:08, 176.57it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1805/3257 [00:12<00:08, 164.38it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1824/3257 [00:12<00:08, 169.16it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1842/3257 [00:12<00:08, 169.73it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1860/3257 [00:12<00:08, 170.14it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:12<00:08, 170.75it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:13<00:08, 163.35it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:13<00:08, 167.58it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:13<00:07, 176.38it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1962/3257 [00:13<00:06, 196.32it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:13<00:06, 185.55it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2002/3257 [00:13<00:06, 188.48it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:13<00:06, 186.74it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2041/3257 [00:13<00:06, 175.54it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2059/3257 [00:14<00:07, 166.22it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2078/3257 [00:14<00:06, 171.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2096/3257 [00:14<00:06, 166.54it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2116/3257 [00:14<00:06, 175.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:14<00:06, 161.32it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2151/3257 [00:14<00:06, 158.60it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2170/3257 [00:14<00:06, 166.10it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2187/3257 [00:14<00:06, 160.25it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2205/3257 [00:14<00:06, 164.67it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2222/3257 [00:14<00:06, 160.63it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2239/3257 [00:15<00:06, 153.76it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:15<00:06, 163.55it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:15<00:06, 152.50it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2297/3257 [00:15<00:05, 167.41it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:15<00:05, 163.36it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:15<00:05, 175.77it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:15<00:04, 187.58it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2379/3257 [00:15<00:04, 187.23it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:15<00:04, 189.07it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2419/3257 [00:16<00:04, 174.45it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2437/3257 [00:16<00:04, 165.59it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2454/3257 [00:16<00:04, 163.80it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:16<00:04, 175.19it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2495/3257 [00:16<00:04, 179.24it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:16<00:04, 180.17it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2534/3257 [00:16<00:03, 184.36it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2553/3257 [00:16<00:04, 174.41it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2571/3257 [00:17<00:04, 151.48it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2587/3257 [00:17<00:04, 143.76it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2602/3257 [00:17<00:04, 144.79it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2620/3257 [00:17<00:04, 153.55it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2638/3257 [00:17<00:03, 158.58it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2655/3257 [00:17<00:03, 156.76it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:17<00:03, 158.74it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2691/3257 [00:17<00:03, 163.44it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2708/3257 [00:17<00:03, 146.61it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2726/3257 [00:18<00:03, 153.48it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2747/3257 [00:18<00:03, 167.27it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2765/3257 [00:18<00:02, 168.78it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2783/3257 [00:18<00:02, 167.26it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:18<00:02, 174.67it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2821/3257 [00:18<00:02, 165.92it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2838/3257 [00:18<00:02, 156.61it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2859/3257 [00:18<00:02, 170.34it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2882/3257 [00:18<00:02, 185.81it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2901/3257 [00:19<00:02, 164.09it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:19<00:01, 170.48it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2938/3257 [00:19<00:01, 172.25it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2956/3257 [00:19<00:03, 81.79it/s]  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:19<00:02, 98.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2993/3257 [00:20<00:02, 111.08it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3015/3257 [00:20<00:01, 132.80it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3035/3257 [00:20<00:01, 147.56it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3057/3257 [00:20<00:01, 162.61it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3079/3257 [00:20<00:01, 175.30it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3099/3257 [00:20<00:00, 177.84it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3121/3257 [00:20<00:00, 189.17it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3142/3257 [00:20<00:00, 182.78it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3162/3257 [00:20<00:00, 181.34it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3181/3257 [00:20<00:00, 170.45it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:21<00:00, 181.83it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3222/3257 [00:21<00:00, 176.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:21<00:00, 187.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 152.32it/s]
2023-02-07 20:39:15.805 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:39:15,806][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d172,n5,mc2,s0.273427,t4>', 'datetime': '2023-02-07T20:39:15.806523', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:39:15,806][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:39:15,806][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:39:16,366][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:39:16,366][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:39:16,476][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 46469 unique words (85.97% of original 54054, drops 7585)', 'datetime': '2023-02-07T20:39:16.476300', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:39:16,476][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 6543281 word corpus (99.88% of original 6550866, drops 7585)', 'datetime': '2023-02-07T20:39:16.476567', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:39:16,623][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:39:16,623][gensim.models.word2vec][INFO] - sample=0.273427 downsamples 0 most-common words
[2023-02-07 20:39:16,623][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6543281 word corpus (100.0%% of prior 6543281)', 'datetime': '2023-02-07T20:39:16.623894', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:39:16,884][gensim.models.word2vec][INFO] - estimated required memory for 46469 words and 172 dimensions: 90068060 bytes
[2023-02-07 20:39:16,885][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:39:16,953][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 46469 vocabulary and 172 features, using sg=1 hs=0 sample=0.2734265627937742 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T20:39:16.953660', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:39:17,955][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 36.84% examples, 2440873 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:18,956][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 73.50% examples, 2415371 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:19,657][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6488146 effective words) took 2.7s, 2401122 effective words/s
[2023-02-07 20:39:20,661][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 37.55% examples, 2488133 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:21,665][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 76.05% examples, 2492591 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:22,264][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6488146 effective words) took 2.6s, 2489675 effective words/s
[2023-02-07 20:39:23,267][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 37.55% examples, 2491022 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:24,270][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 77.06% examples, 2521804 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:24,818][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6488146 effective words) took 2.6s, 2542158 effective words/s
[2023-02-07 20:39:25,824][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 39.12% examples, 2578250 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:26,825][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 78.81% examples, 2577259 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:27,342][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6488146 effective words) took 2.5s, 2572112 effective words/s
[2023-02-07 20:39:28,344][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 38.62% examples, 2559447 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:29,345][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 77.80% examples, 2545926 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:29,891][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6488146 effective words) took 2.5s, 2547179 effective words/s
[2023-02-07 20:39:30,895][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 38.38% examples, 2538222 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:31,898][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 77.96% examples, 2545319 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:32,434][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6488146 effective words) took 2.5s, 2552991 effective words/s
[2023-02-07 20:39:33,443][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.62% examples, 2541164 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:34,445][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 78.72% examples, 2568814 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:34,955][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6488146 effective words) took 2.5s, 2575822 effective words/s
[2023-02-07 20:39:35,957][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 38.81% examples, 2567123 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:39:36,957][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 78.35% examples, 2563746 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:37,485][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6488146 effective words) took 2.5s, 2565113 effective words/s
[2023-02-07 20:39:38,489][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 39.12% examples, 2584167 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:39,490][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 78.63% examples, 2571335 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:40,012][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6488146 effective words) took 2.5s, 2569587 effective words/s
[2023-02-07 20:39:41,019][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 38.62% examples, 2543971 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:42,022][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 78.23% examples, 2550064 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:42,546][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6488146 effective words) took 2.5s, 2561066 effective words/s
[2023-02-07 20:39:43,548][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 39.05% examples, 2586802 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:44,550][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 78.54% examples, 2571540 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:45,072][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6488146 effective words) took 2.5s, 2570554 effective words/s
[2023-02-07 20:39:46,075][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 39.21% examples, 2600462 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:47,076][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 79.58% examples, 2610818 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:47,554][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6488146 effective words) took 2.5s, 2616440 effective words/s
[2023-02-07 20:39:48,558][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 32.27% examples, 2112739 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:49,560][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 64.05% examples, 2105720 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:50,563][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 97.14% examples, 2099288 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:50,645][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6488146 effective words) took 3.1s, 2100398 effective words/s
[2023-02-07 20:39:51,648][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 38.81% examples, 2565914 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:52,652][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 78.42% examples, 2562997 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:53,161][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6488146 effective words) took 2.5s, 2579915 effective words/s
[2023-02-07 20:39:54,166][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 39.21% examples, 2597449 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:55,166][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 79.77% examples, 2613867 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:55,649][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6488146 effective words) took 2.5s, 2609850 effective words/s
[2023-02-07 20:39:55,650][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (97322190 effective words) took 38.7s, 2515047 effective words/s', 'datetime': '2023-02-07T20:39:55.650094', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:39:55.650 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:40:00,324][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203845-ddif9omh/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:40:00.324019', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:40:00,325][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:40:00,506][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203845-ddif9omh/files/../tmp/embedding_model.pt
2023-02-07 20:40:00.506 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:40:02.125 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:40:02.667 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:41:04.364 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9285482973522544, 'test_mae': 0.7481689058655611, 'test_r2': -1.7064134870976466}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.81
wandb: percentage 0.14032
wandb:   test_mae 0.74817
wandb:   test_mse 0.92855
wandb:    test_r2 -1.70641
wandb: 
wandb: üöÄ View run sleek-sweep-86 at: https://wandb.ai/xiaoqiz/mof2vec/runs/ddif9omh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_203845-ddif9omh/logs
wandb: Agent Starting Run: nohjhr3c with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 934
wandb: 	model.gensim.alpha: 0.003695619137553095
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 4
wandb: 	model.gensim.sample: 0.6619128492955673
wandb: 	model.gensim.vector_size: 314
wandb: 	model.gensim.window: 1
wandb: 	model.sklearn.learning_rate: 0.0009508323108540496
wandb: 	model.sklearn.max_depth: 24
wandb: 	model.sklearn.min_child_weight: 0.062377132081590694
wandb: 	model.sklearn.n_estimators: 2532
wandb: 	model.sklearn.num_leaves: 304
wandb: 	model.sklearn.reg_alpha: 0.008693646301864042
wandb: 	model.sklearn.reg_lambda: 0.007286659877846636
wandb: 	model.sklearn.subsample: 0.30853511380933557
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204117-nohjhr3c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-87
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/nohjhr3c
2023-02-07 20:41:25.582 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:41:25.582 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 934 for sweep.
2023-02-07 20:41:25.583 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.003695619137553095 for sweep.
2023-02-07 20:41:25.583 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:41:25.583 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 4 for sweep.
2023-02-07 20:41:25.583 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6619128492955673 for sweep.
2023-02-07 20:41:25.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 314 for sweep.
2023-02-07 20:41:25.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 1 for sweep.
2023-02-07 20:41:25.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0009508323108540496 for sweep.
2023-02-07 20:41:25.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 24 for sweep.
2023-02-07 20:41:25.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.062377132081590694 for sweep.
2023-02-07 20:41:25.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2532 for sweep.
2023-02-07 20:41:25.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 304 for sweep.
2023-02-07 20:41:25.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.008693646301864042 for sweep.
2023-02-07 20:41:25.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.007286659877846636 for sweep.
2023-02-07 20:41:25.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.30853511380933557 for sweep.
2023-02-07 20:41:25.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:41:25.595 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204117-nohjhr3c/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 934, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 314, 'window': 1, 'min_count': 4, 'dm': 0, 'sample': 0.6619128492955673, 'workers': 4, 'alpha': 0.003695619137553095, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2532, 'max_depth': 24, 'num_leaves': 304, 'reg_alpha': 0.008693646301864042, 'reg_lambda': 0.007286659877846636, 'subsample': 0.30853511380933557, 'min_child_weight': 0.062377132081590694, 'n_jobs': 4, 'learning_rate': 0.0009508323108540496}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 139.18it/s]  1%|          | 31/3257 [00:00<00:20, 154.92it/s]  1%|‚ñè         | 47/3257 [00:00<00:20, 154.15it/s]  2%|‚ñè         | 63/3257 [00:00<00:20, 152.55it/s]  2%|‚ñè         | 80/3257 [00:00<00:20, 156.61it/s]  3%|‚ñé         | 96/3257 [00:00<00:20, 152.46it/s]  3%|‚ñé         | 112/3257 [00:00<00:21, 145.60it/s]  4%|‚ñç         | 128/3257 [00:00<00:20, 149.70it/s]  5%|‚ñç         | 148/3257 [00:00<00:19, 162.46it/s]  5%|‚ñå         | 165/3257 [00:01<00:20, 150.63it/s]  6%|‚ñå         | 181/3257 [00:01<00:20, 152.38it/s]  6%|‚ñå         | 199/3257 [00:01<00:19, 158.45it/s]  7%|‚ñã         | 217/3257 [00:01<00:18, 163.11it/s]  7%|‚ñã         | 237/3257 [00:01<00:18, 166.44it/s]  8%|‚ñä         | 254/3257 [00:01<00:18, 165.64it/s]  8%|‚ñä         | 271/3257 [00:01<00:18, 158.83it/s]  9%|‚ñâ         | 293/3257 [00:01<00:17, 173.83it/s] 10%|‚ñâ         | 311/3257 [00:01<00:17, 165.62it/s] 10%|‚ñà         | 328/3257 [00:02<00:17, 166.42it/s] 11%|‚ñà         | 345/3257 [00:02<00:18, 160.28it/s] 11%|‚ñà         | 363/3257 [00:02<00:17, 163.39it/s] 12%|‚ñà‚ñè        | 380/3257 [00:02<00:18, 154.69it/s] 12%|‚ñà‚ñè        | 396/3257 [00:02<00:18, 153.80it/s] 13%|‚ñà‚ñé        | 414/3257 [00:02<00:17, 160.96it/s] 13%|‚ñà‚ñé        | 431/3257 [00:02<00:20, 139.40it/s] 14%|‚ñà‚ñé        | 447/3257 [00:02<00:19, 140.64it/s] 14%|‚ñà‚ñç        | 466/3257 [00:02<00:18, 152.14it/s] 15%|‚ñà‚ñç        | 482/3257 [00:03<00:18, 150.16it/s] 15%|‚ñà‚ñå        | 501/3257 [00:03<00:17, 160.98it/s] 16%|‚ñà‚ñå        | 520/3257 [00:03<00:16, 167.68it/s] 17%|‚ñà‚ñã        | 538/3257 [00:03<00:16, 162.94it/s] 17%|‚ñà‚ñã        | 555/3257 [00:03<00:16, 163.31it/s] 18%|‚ñà‚ñä        | 572/3257 [00:03<00:19, 138.85it/s] 18%|‚ñà‚ñä        | 591/3257 [00:03<00:17, 151.03it/s] 19%|‚ñà‚ñä        | 610/3257 [00:03<00:16, 158.30it/s] 19%|‚ñà‚ñâ        | 627/3257 [00:04<00:16, 157.26it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:04<00:16, 157.99it/s] 20%|‚ñà‚ñà        | 661/3257 [00:04<00:18, 140.42it/s] 21%|‚ñà‚ñà        | 681/3257 [00:04<00:16, 155.16it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:04<00:17, 146.82it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:04<00:16, 157.83it/s] 23%|‚ñà‚ñà‚ñé       | 734/3257 [00:04<00:16, 149.66it/s] 23%|‚ñà‚ñà‚ñé       | 750/3257 [00:04<00:17, 144.98it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:04<00:15, 155.83it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:05<00:16, 148.30it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:15, 153.51it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:15, 152.48it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:05<00:16, 144.70it/s] 26%|‚ñà‚ñà‚ñå       | 851/3257 [00:05<00:17, 141.26it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:05<00:16, 145.66it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:05<00:16, 142.45it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:14, 158.18it/s] 28%|‚ñà‚ñà‚ñä       | 921/3257 [00:05<00:14, 157.68it/s] 29%|‚ñà‚ñà‚ñâ       | 937/3257 [00:06<00:15, 153.94it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:06<00:14, 160.42it/s] 30%|‚ñà‚ñà‚ñâ       | 973/3257 [00:06<00:14, 157.45it/s] 30%|‚ñà‚ñà‚ñà       | 989/3257 [00:06<00:14, 155.04it/s] 31%|‚ñà‚ñà‚ñà       | 1006/3257 [00:06<00:14, 157.93it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1022/3257 [00:06<00:14, 156.36it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1038/3257 [00:06<00:22, 97.15it/s]  32%|‚ñà‚ñà‚ñà‚ñè      | 1052/3257 [00:07<00:21, 104.85it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1068/3257 [00:07<00:18, 117.04it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1082/3257 [00:07<00:17, 121.20it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:07<00:16, 127.61it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1114/3257 [00:07<00:15, 138.31it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1129/3257 [00:07<00:16, 130.84it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:07<00:15, 133.12it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1157/3257 [00:07<00:15, 134.35it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1172/3257 [00:07<00:15, 137.79it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:08<00:15, 131.73it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1201/3257 [00:08<00:16, 121.21it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1215/3257 [00:08<00:16, 125.24it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:08<00:14, 139.57it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1248/3257 [00:08<00:14, 137.80it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1263/3257 [00:08<00:14, 140.25it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1278/3257 [00:08<00:15, 128.12it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:08<00:15, 127.20it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1307/3257 [00:08<00:14, 132.86it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1322/3257 [00:09<00:14, 135.99it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:09<00:13, 143.17it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:09<00:14, 135.83it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:09<00:13, 137.59it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1384/3257 [00:09<00:13, 134.97it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1401/3257 [00:09<00:12, 143.05it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1421/3257 [00:09<00:11, 157.27it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1437/3257 [00:09<00:11, 154.08it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1455/3257 [00:09<00:11, 160.99it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1472/3257 [00:09<00:11, 160.22it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1489/3257 [00:10<00:11, 158.75it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1507/3257 [00:10<00:10, 164.78it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1524/3257 [00:10<00:11, 150.81it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1540/3257 [00:10<00:11, 145.38it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:10<00:12, 140.79it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1572/3257 [00:10<00:11, 147.38it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1587/3257 [00:10<00:11, 145.36it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1604/3257 [00:10<00:10, 152.20it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:10<00:10, 151.97it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1636/3257 [00:11<00:10, 147.38it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1651/3257 [00:11<00:11, 143.74it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1666/3257 [00:11<00:11, 142.53it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1681/3257 [00:11<00:11, 141.91it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1697/3257 [00:11<00:10, 146.04it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1713/3257 [00:11<00:10, 150.00it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:11<00:11, 138.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:11<00:11, 134.33it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1762/3257 [00:11<00:10, 145.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1777/3257 [00:12<00:10, 143.76it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1794/3257 [00:12<00:09, 149.30it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1810/3257 [00:12<00:10, 141.84it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:12<00:10, 141.13it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1843/3257 [00:12<00:09, 146.30it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1858/3257 [00:12<00:09, 144.41it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1876/3257 [00:12<00:08, 153.83it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1892/3257 [00:12<00:09, 147.55it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1910/3257 [00:12<00:08, 155.42it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1926/3257 [00:13<00:08, 148.68it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1946/3257 [00:13<00:08, 161.91it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:13<00:07, 166.46it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:13<00:07, 161.54it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:13<00:07, 161.10it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2016/3257 [00:13<00:07, 157.95it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:13<00:07, 160.13it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2050/3257 [00:13<00:08, 145.22it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2065/3257 [00:14<00:08, 141.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2082/3257 [00:14<00:07, 147.91it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2097/3257 [00:14<00:08, 141.40it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2115/3257 [00:14<00:07, 151.28it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2131/3257 [00:14<00:08, 137.29it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2146/3257 [00:14<00:08, 133.71it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:14<00:07, 142.10it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2179/3257 [00:14<00:07, 146.00it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2194/3257 [00:14<00:07, 146.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:15<00:07, 138.91it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2225/3257 [00:15<00:07, 141.39it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2240/3257 [00:15<00:07, 137.15it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2256/3257 [00:15<00:07, 142.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2271/3257 [00:15<00:07, 136.10it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2290/3257 [00:15<00:06, 148.02it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2305/3257 [00:15<00:06, 146.42it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2320/3257 [00:16<00:11, 82.41it/s]  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:16<00:09, 98.34it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2359/3257 [00:16<00:07, 122.78it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2375/3257 [00:16<00:07, 125.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2394/3257 [00:16<00:06, 139.24it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2410/3257 [00:16<00:06, 135.90it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2427/3257 [00:16<00:05, 144.25it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:16<00:06, 135.57it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2461/3257 [00:16<00:05, 146.31it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2478/3257 [00:17<00:05, 150.10it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2495/3257 [00:17<00:04, 155.16it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2513/3257 [00:17<00:04, 161.89it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2531/3257 [00:17<00:04, 164.71it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2548/3257 [00:17<00:04, 163.34it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2565/3257 [00:17<00:04, 150.64it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2581/3257 [00:17<00:04, 147.20it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2596/3257 [00:17<00:04, 147.22it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2618/3257 [00:17<00:03, 166.73it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2636/3257 [00:18<00:03, 168.49it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:18<00:03, 156.47it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2670/3257 [00:18<00:03, 156.52it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:18<00:03, 158.60it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:18<00:03, 141.04it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:18<00:03, 138.73it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2740/3257 [00:18<00:03, 157.39it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2758/3257 [00:18<00:03, 162.51it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2775/3257 [00:18<00:03, 158.71it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2798/3257 [00:19<00:02, 178.54it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2817/3257 [00:19<00:02, 171.06it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2835/3257 [00:19<00:02, 164.02it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2855/3257 [00:19<00:02, 173.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2881/3257 [00:19<00:01, 197.23it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2902/3257 [00:19<00:01, 178.98it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2924/3257 [00:19<00:01, 189.69it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2944/3257 [00:19<00:01, 171.85it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2964/3257 [00:19<00:01, 178.71it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2983/3257 [00:20<00:01, 168.53it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:20<00:01, 177.70it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3023/3257 [00:20<00:01, 172.98it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3047/3257 [00:20<00:01, 189.01it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3068/3257 [00:20<00:00, 194.08it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3088/3257 [00:20<00:00, 182.58it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3108/3257 [00:20<00:00, 185.80it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:20<00:00, 186.15it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3146/3257 [00:21<00:00, 169.41it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3164/3257 [00:21<00:00, 167.07it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3181/3257 [00:21<00:00, 157.03it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3199/3257 [00:21<00:00, 162.21it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3216/3257 [00:21<00:00, 151.28it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3235/3257 [00:21<00:00, 160.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:21<00:00, 154.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 149.92it/s]
2023-02-07 20:41:48.434 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:41:48,436][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d314,n5,mc4,s0.661913,t4>', 'datetime': '2023-02-07T20:41:48.436075', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:41:48,436][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:41:48,436][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:41:49,133][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:41:49,134][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:41:49,246][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 retains 36921 unique words (68.30% of original 54054, drops 17133)', 'datetime': '2023-02-07T20:41:49.246381', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:41:49,246][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 leaves 6522479 word corpus (99.57% of original 6550866, drops 28387)', 'datetime': '2023-02-07T20:41:49.246915', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:41:49,381][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:41:49,385][gensim.models.word2vec][INFO] - sample=0.661913 downsamples 0 most-common words
[2023-02-07 20:41:49,386][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6522479 word corpus (100.0%% of prior 6522479)', 'datetime': '2023-02-07T20:41:49.386226', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:41:49,606][gensim.models.word2vec][INFO] - estimated required memory for 36921 words and 314 dimensions: 115948244 bytes
[2023-02-07 20:41:49,606][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:41:49,660][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 36921 vocabulary and 314 features, using sg=1 hs=0 sample=0.6619128492955673 negative=5 window=1 shrink_windows=True', 'datetime': '2023-02-07T20:41:49.660017', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:41:50,664][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 24.44% examples, 1565718 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:51,664][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 47.62% examples, 1569410 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:52,667][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 72.09% examples, 1577632 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:41:53,667][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 97.67% examples, 1581580 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:41:53,745][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6467889 effective words) took 4.1s, 1584561 effective words/s
[2023-02-07 20:41:54,753][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 26.31% examples, 1695681 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:55,756][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 52.23% examples, 1717364 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:56,758][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 79.15% examples, 1719289 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:57,508][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6467889 effective words) took 3.8s, 1719739 effective words/s
[2023-02-07 20:41:58,515][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 26.16% examples, 1686329 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:59,518][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 51.37% examples, 1689006 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:00,522][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 78.42% examples, 1701154 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:01,308][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6467889 effective words) took 3.8s, 1702807 effective words/s
[2023-02-07 20:42:02,316][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 26.34% examples, 1694867 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:03,323][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 52.47% examples, 1721161 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:04,326][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 80.01% examples, 1734172 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:05,040][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6467889 effective words) took 3.7s, 1733876 effective words/s
[2023-02-07 20:42:06,048][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 26.68% examples, 1722756 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:07,055][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 52.47% examples, 1722518 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:08,058][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 79.46% examples, 1726210 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:08,796][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6467889 effective words) took 3.8s, 1723872 effective words/s
[2023-02-07 20:42:09,809][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 26.68% examples, 1712119 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:10,813][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 52.63% examples, 1723929 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:11,826][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 80.66% examples, 1735850 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:42:12,511][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6467889 effective words) took 3.7s, 1741466 effective words/s
[2023-02-07 20:42:13,517][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 26.68% examples, 1724335 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:14,521][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.02% examples, 1742399 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:15,523][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 81.09% examples, 1755997 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:16,195][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6467889 effective words) took 3.7s, 1756465 effective words/s
[2023-02-07 20:42:17,197][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 26.74% examples, 1739009 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:18,201][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 52.69% examples, 1737989 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:19,202][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 79.58% examples, 1734551 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:19,931][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6467889 effective words) took 3.7s, 1731970 effective words/s
[2023-02-07 20:42:20,934][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 26.40% examples, 1711303 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:21,934][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 52.47% examples, 1731568 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:22,936][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 79.58% examples, 1735417 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:23,649][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6467889 effective words) took 3.7s, 1740630 effective words/s
[2023-02-07 20:42:24,655][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 26.74% examples, 1734127 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:25,655][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 53.30% examples, 1763753 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:42:26,657][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 81.55% examples, 1769297 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:27,316][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6467889 effective words) took 3.7s, 1765188 effective words/s
[2023-02-07 20:42:28,319][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 26.74% examples, 1736482 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:29,319][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 53.05% examples, 1753337 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:30,321][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 81.09% examples, 1759774 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:31,001][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6467889 effective words) took 3.7s, 1755812 effective words/s
[2023-02-07 20:42:32,004][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 26.99% examples, 1749285 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:33,008][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 53.30% examples, 1762035 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:34,017][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 81.15% examples, 1756515 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:34,692][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6467889 effective words) took 3.7s, 1753464 effective words/s
[2023-02-07 20:42:35,694][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 26.68% examples, 1730117 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:36,699][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 52.63% examples, 1732433 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:37,700][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 79.37% examples, 1727744 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:38,439][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6467889 effective words) took 3.7s, 1727019 effective words/s
[2023-02-07 20:42:39,447][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 26.68% examples, 1720414 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:40,451][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 52.69% examples, 1733311 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:42:41,451][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 79.77% examples, 1734548 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:42:42,146][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6467889 effective words) took 3.7s, 1745903 effective words/s
[2023-02-07 20:42:43,154][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 26.77% examples, 1724048 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:44,161][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 53.02% examples, 1737856 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:45,165][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 82.71% examples, 1789186 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:45,636][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6467889 effective words) took 3.5s, 1854101 effective words/s
[2023-02-07 20:42:45,636][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (97018335 effective words) took 56.0s, 1733202 effective words/s', 'datetime': '2023-02-07T20:42:45.636861', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:42:45.637 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:42:50,164][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204117-nohjhr3c/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:42:50.163966', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:42:50,164][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204117-nohjhr3c/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 20:42:50,214][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204117-nohjhr3c/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 20:42:50,260][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:42:50,287][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204117-nohjhr3c/files/../tmp/embedding_model.pt
2023-02-07 20:42:50.287 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:42:52.213 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:42:52.853 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:42:55.442 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.989946204648767, 'test_mae': 0.7481077401641688, 'test_r2': -1.8235702367660354}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.72
wandb: percentage 0.31696
wandb:   test_mae 0.74811
wandb:   test_mse 0.98995
wandb:    test_r2 -1.82357
wandb: 
wandb: üöÄ View run dulcet-sweep-87 at: https://wandb.ai/xiaoqiz/mof2vec/runs/nohjhr3c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_204117-nohjhr3c/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: n7hzom1m with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 705
wandb: 	model.gensim.alpha: 0.0008489495286367315
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.4306424496295247
wandb: 	model.gensim.vector_size: 400
wandb: 	model.gensim.window: 7
wandb: 	model.sklearn.learning_rate: 0.023862587855245053
wandb: 	model.sklearn.max_depth: 20
wandb: 	model.sklearn.min_child_weight: 0.0985496919540589
wandb: 	model.sklearn.n_estimators: 3145
wandb: 	model.sklearn.num_leaves: 291
wandb: 	model.sklearn.reg_alpha: 0.027404928763691105
wandb: 	model.sklearn.reg_lambda: 0.002643691772343552
wandb: 	model.sklearn.subsample: 0.3638298382373957
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204312-n7hzom1m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-88
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/n7hzom1m
2023-02-07 20:43:22.310 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:43:22.311 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 705 for sweep.
2023-02-07 20:43:22.311 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0008489495286367315 for sweep.
2023-02-07 20:43:22.312 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:43:22.312 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 20:43:22.312 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4306424496295247 for sweep.
2023-02-07 20:43:22.312 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 400 for sweep.
2023-02-07 20:43:22.313 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 7 for sweep.
2023-02-07 20:43:22.313 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.023862587855245053 for sweep.
2023-02-07 20:43:22.313 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 20 for sweep.
2023-02-07 20:43:22.313 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0985496919540589 for sweep.
2023-02-07 20:43:22.314 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3145 for sweep.
2023-02-07 20:43:22.314 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 291 for sweep.
2023-02-07 20:43:22.314 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.027404928763691105 for sweep.
2023-02-07 20:43:22.315 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.002643691772343552 for sweep.
2023-02-07 20:43:22.315 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3638298382373957 for sweep.
2023-02-07 20:43:22.315 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:43:22.323 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204312-n7hzom1m/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 705, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 400, 'window': 7, 'min_count': 5, 'dm': 0, 'sample': 0.4306424496295247, 'workers': 4, 'alpha': 0.0008489495286367315, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3145, 'max_depth': 20, 'num_leaves': 291, 'reg_alpha': 0.027404928763691105, 'reg_lambda': 0.002643691772343552, 'subsample': 0.3638298382373957, 'min_child_weight': 0.0985496919540589, 'n_jobs': 4, 'learning_rate': 0.023862587855245053}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:25, 125.93it/s]  1%|          | 29/3257 [00:00<00:22, 143.69it/s]  1%|‚ñè         | 44/3257 [00:00<00:22, 143.01it/s]  2%|‚ñè         | 59/3257 [00:00<00:22, 139.65it/s]  2%|‚ñè         | 76/3257 [00:00<00:21, 148.67it/s]  3%|‚ñé         | 91/3257 [00:00<00:21, 148.43it/s]  3%|‚ñé         | 106/3257 [00:00<00:23, 136.89it/s]  4%|‚ñé         | 121/3257 [00:00<00:22, 137.93it/s]  4%|‚ñç         | 136/3257 [00:00<00:22, 140.76it/s]  5%|‚ñç         | 154/3257 [00:01<00:20, 147.91it/s]  5%|‚ñå         | 169/3257 [00:01<00:21, 145.49it/s]  6%|‚ñå         | 184/3257 [00:01<00:21, 144.44it/s]  6%|‚ñå         | 201/3257 [00:01<00:20, 146.16it/s]  7%|‚ñã         | 221/3257 [00:01<00:18, 160.46it/s]  7%|‚ñã         | 238/3257 [00:01<00:18, 162.44it/s]  8%|‚ñä         | 255/3257 [00:01<00:18, 163.54it/s]  8%|‚ñä         | 272/3257 [00:01<00:18, 159.23it/s]  9%|‚ñâ         | 294/3257 [00:01<00:16, 175.32it/s] 10%|‚ñâ         | 312/3257 [00:02<00:17, 164.88it/s] 10%|‚ñà         | 331/3257 [00:02<00:17, 169.75it/s] 11%|‚ñà         | 349/3257 [00:02<00:17, 162.18it/s] 11%|‚ñà‚ñè        | 367/3257 [00:02<00:17, 164.32it/s] 12%|‚ñà‚ñè        | 384/3257 [00:02<00:27, 105.24it/s] 12%|‚ñà‚ñè        | 398/3257 [00:02<00:25, 111.77it/s] 13%|‚ñà‚ñé        | 416/3257 [00:02<00:22, 126.87it/s] 13%|‚ñà‚ñé        | 431/3257 [00:03<00:23, 118.15it/s] 14%|‚ñà‚ñé        | 447/3257 [00:03<00:22, 126.40it/s] 14%|‚ñà‚ñç        | 465/3257 [00:03<00:19, 139.69it/s] 15%|‚ñà‚ñç        | 481/3257 [00:03<00:20, 138.65it/s] 15%|‚ñà‚ñå        | 501/3257 [00:03<00:18, 152.83it/s] 16%|‚ñà‚ñå        | 518/3257 [00:03<00:17, 157.36it/s] 16%|‚ñà‚ñã        | 535/3257 [00:03<00:17, 156.16it/s] 17%|‚ñà‚ñã        | 551/3257 [00:03<00:17, 156.33it/s] 17%|‚ñà‚ñã        | 567/3257 [00:03<00:18, 145.51it/s] 18%|‚ñà‚ñä        | 582/3257 [00:04<00:19, 140.55it/s] 18%|‚ñà‚ñä        | 600/3257 [00:04<00:17, 149.84it/s] 19%|‚ñà‚ñâ        | 619/3257 [00:04<00:16, 160.18it/s] 20%|‚ñà‚ñâ        | 636/3257 [00:04<00:16, 156.76it/s] 20%|‚ñà‚ñà        | 652/3257 [00:04<00:17, 147.38it/s] 20%|‚ñà‚ñà        | 667/3257 [00:04<00:18, 142.66it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:18, 142.28it/s] 21%|‚ñà‚ñà‚ñè       | 699/3257 [00:04<00:17, 145.69it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:16, 156.57it/s] 23%|‚ñà‚ñà‚ñé       | 734/3257 [00:05<00:16, 149.29it/s] 23%|‚ñà‚ñà‚ñé       | 750/3257 [00:05<00:17, 141.57it/s] 24%|‚ñà‚ñà‚ñé       | 769/3257 [00:05<00:16, 153.94it/s] 24%|‚ñà‚ñà‚ñç       | 785/3257 [00:05<00:17, 141.77it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:16, 149.07it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:16, 147.45it/s] 26%|‚ñà‚ñà‚ñå       | 835/3257 [00:05<00:16, 143.56it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:05<00:17, 135.24it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:05<00:17, 140.27it/s] 27%|‚ñà‚ñà‚ñã       | 881/3257 [00:06<00:17, 138.05it/s] 28%|‚ñà‚ñà‚ñä       | 897/3257 [00:06<00:16, 142.71it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:06<00:16, 145.25it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:06<00:15, 151.54it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:06<00:14, 155.33it/s] 30%|‚ñà‚ñà‚ñâ       | 965/3257 [00:06<00:14, 159.09it/s] 30%|‚ñà‚ñà‚ñà       | 981/3257 [00:06<00:15, 151.16it/s] 31%|‚ñà‚ñà‚ñà       | 997/3257 [00:06<00:15, 148.62it/s] 31%|‚ñà‚ñà‚ñà       | 1012/3257 [00:06<00:15, 145.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:07<00:15, 143.18it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1042/3257 [00:07<00:15, 141.04it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1058/3257 [00:07<00:15, 145.41it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1078/3257 [00:07<00:13, 159.16it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:07<00:14, 146.32it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:07<00:13, 154.98it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1128/3257 [00:07<00:14, 142.72it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:07<00:14, 144.66it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1160/3257 [00:07<00:14, 149.55it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1176/3257 [00:08<00:14, 148.12it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:08<00:15, 134.88it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:08<00:15, 131.36it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:08<00:15, 132.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1240/3257 [00:08<00:13, 152.22it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1256/3257 [00:08<00:13, 144.84it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1273/3257 [00:08<00:13, 149.74it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1289/3257 [00:08<00:14, 139.29it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1305/3257 [00:08<00:13, 143.75it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1322/3257 [00:09<00:12, 148.88it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1340/3257 [00:09<00:12, 156.57it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1356/3257 [00:09<00:12, 149.06it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1372/3257 [00:09<00:12, 147.04it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1387/3257 [00:09<00:12, 146.79it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1404/3257 [00:09<00:12, 151.85it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:09<00:11, 160.63it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1440/3257 [00:09<00:11, 157.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1461/3257 [00:09<00:10, 171.27it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1479/3257 [00:10<00:10, 168.53it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1497/3257 [00:10<00:10, 170.96it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1515/3257 [00:10<00:10, 170.35it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1533/3257 [00:10<00:16, 101.55it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1547/3257 [00:10<00:15, 107.04it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1564/3257 [00:10<00:14, 120.27it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1579/3257 [00:10<00:13, 124.25it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:11<00:12, 135.30it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:11<00:11, 146.93it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1631/3257 [00:11<00:10, 150.16it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1647/3257 [00:11<00:11, 139.74it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:11<00:11, 135.28it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:11<00:11, 136.05it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:11<00:11, 138.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1709/3257 [00:11<00:10, 145.82it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1727/3257 [00:11<00:09, 153.31it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1743/3257 [00:12<00:11, 135.26it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1762/3257 [00:12<00:10, 149.38it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1778/3257 [00:12<00:09, 151.03it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1795/3257 [00:12<00:09, 154.24it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1811/3257 [00:12<00:09, 145.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:12<00:09, 146.67it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1844/3257 [00:12<00:09, 151.45it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1860/3257 [00:12<00:09, 150.27it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:12<00:08, 157.72it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:13<00:08, 152.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1915/3257 [00:13<00:08, 163.75it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1932/3257 [00:13<00:08, 156.86it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:13<00:07, 173.39it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:13<00:07, 174.07it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1992/3257 [00:13<00:07, 168.18it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2009/3257 [00:13<00:07, 164.18it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2028/3257 [00:13<00:07, 170.74it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2046/3257 [00:13<00:07, 159.57it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2063/3257 [00:14<00:08, 144.70it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2081/3257 [00:14<00:07, 152.10it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2097/3257 [00:14<00:08, 144.56it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2116/3257 [00:14<00:07, 155.56it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:14<00:07, 142.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2147/3257 [00:14<00:08, 138.60it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:14<00:07, 150.44it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2182/3257 [00:14<00:07, 147.97it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2201/3257 [00:14<00:06, 158.85it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2218/3257 [00:15<00:06, 149.84it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2235/3257 [00:15<00:06, 154.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2251/3257 [00:15<00:06, 148.77it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2267/3257 [00:15<00:06, 148.47it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2282/3257 [00:15<00:06, 147.55it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:15<00:06, 151.55it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2317/3257 [00:15<00:05, 157.89it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:15<00:05, 168.47it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:15<00:05, 176.76it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2378/3257 [00:16<00:04, 176.21it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2398/3257 [00:16<00:04, 180.42it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2417/3257 [00:16<00:05, 165.93it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2434/3257 [00:16<00:05, 156.95it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2450/3257 [00:16<00:05, 152.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2473/3257 [00:16<00:04, 169.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2491/3257 [00:16<00:04, 166.93it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2512/3257 [00:16<00:04, 176.26it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2531/3257 [00:16<00:04, 178.12it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2549/3257 [00:17<00:04, 173.12it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2567/3257 [00:17<00:04, 159.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2584/3257 [00:17<00:04, 152.86it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2601/3257 [00:17<00:04, 156.41it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2622/3257 [00:17<00:03, 170.96it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2640/3257 [00:17<00:03, 171.76it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2658/3257 [00:17<00:03, 158.72it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2676/3257 [00:17<00:03, 163.73it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2693/3257 [00:17<00:03, 165.34it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2710/3257 [00:18<00:03, 143.49it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2729/3257 [00:18<00:03, 155.23it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2748/3257 [00:18<00:03, 162.40it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2765/3257 [00:18<00:03, 160.85it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2782/3257 [00:18<00:03, 154.71it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2800/3257 [00:18<00:02, 160.11it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2817/3257 [00:18<00:02, 148.26it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:18<00:02, 144.82it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2848/3257 [00:19<00:05, 77.47it/s]  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2867/3257 [00:19<00:04, 95.95it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:19<00:03, 110.20it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2901/3257 [00:19<00:03, 113.06it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2919/3257 [00:19<00:02, 127.54it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2934/3257 [00:19<00:02, 128.16it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2949/3257 [00:20<00:02, 124.88it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:20<00:02, 134.21it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2981/3257 [00:20<00:02, 129.50it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2998/3257 [00:20<00:01, 139.04it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3014/3257 [00:20<00:01, 143.84it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3029/3257 [00:20<00:01, 144.05it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:20<00:01, 153.53it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3066/3257 [00:20<00:01, 158.38it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3083/3257 [00:20<00:01, 157.91it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3100/3257 [00:21<00:00, 161.09it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3121/3257 [00:21<00:00, 172.20it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3139/3257 [00:21<00:00, 166.13it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3156/3257 [00:21<00:00, 159.49it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3173/3257 [00:21<00:00, 160.70it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3190/3257 [00:21<00:00, 158.30it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:21<00:00, 159.65it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3224/3257 [00:21<00:00, 157.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:21<00:00, 167.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 148.29it/s]
2023-02-07 20:43:45.112 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:43:45,113][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d400,n5,mc5,s0.430642,t4>', 'datetime': '2023-02-07T20:43:45.113475', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:43:45,113][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:43:45,114][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:43:45,714][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:43:45,714][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:43:45,779][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 21312 unique words (49.91% of original 42701, drops 21389)', 'datetime': '2023-02-07T20:43:45.779029', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:43:45,781][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5769229 word corpus (99.08% of original 5822992, drops 53763)', 'datetime': '2023-02-07T20:43:45.781224', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:43:45,858][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:43:45,860][gensim.models.word2vec][INFO] - sample=0.430642 downsamples 0 most-common words
[2023-02-07 20:43:45,860][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5769229 word corpus (100.0%% of prior 5769229)', 'datetime': '2023-02-07T20:43:45.860389', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:43:45,992][gensim.models.word2vec][INFO] - estimated required memory for 21312 words and 400 dimensions: 84717000 bytes
[2023-02-07 20:43:45,992][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:43:46,035][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 21312 vocabulary and 400 features, using sg=1 hs=0 sample=0.4306424496295247 negative=5 window=7 shrink_windows=True', 'datetime': '2023-02-07T20:43:46.035136', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:43:47,037][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 25.85% examples, 1490559 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:43:48,042][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 51.49% examples, 1507760 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:43:49,045][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 78.05% examples, 1504532 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:49,854][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5743174 effective words) took 3.8s, 1504667 effective words/s
[2023-02-07 20:43:50,866][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 25.85% examples, 1478511 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:51,867][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 51.06% examples, 1490078 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:52,868][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 78.05% examples, 1503318 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:43:53,674][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5743174 effective words) took 3.8s, 1504674 effective words/s
[2023-02-07 20:43:54,680][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 25.85% examples, 1485707 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:55,689][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 51.06% examples, 1487502 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:43:56,692][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 77.10% examples, 1484532 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:43:57,553][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5743174 effective words) took 3.9s, 1481454 effective words/s
[2023-02-07 20:43:58,561][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 25.42% examples, 1449919 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:59,561][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 49.77% examples, 1450884 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:00,565][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 75.13% examples, 1455739 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:01,478][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5743174 effective words) took 3.9s, 1464076 effective words/s
[2023-02-07 20:44:02,485][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 25.58% examples, 1459589 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:03,487][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 50.38% examples, 1468599 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:04,490][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 76.14% examples, 1472691 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:05,368][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5743174 effective words) took 3.9s, 1476947 effective words/s
[2023-02-07 20:44:06,381][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 25.85% examples, 1475659 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:07,385][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 50.97% examples, 1481584 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:08,387][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 77.46% examples, 1490227 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:09,215][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5743174 effective words) took 3.8s, 1493490 effective words/s
[2023-02-07 20:44:10,220][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 25.70% examples, 1473181 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:11,224][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 50.84% examples, 1482989 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:12,227][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 77.31% examples, 1490601 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:13,063][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5743174 effective words) took 3.8s, 1493304 effective words/s
[2023-02-07 20:44:14,065][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 25.79% examples, 1481973 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:15,071][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 50.97% examples, 1488241 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:16,073][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 77.10% examples, 1488068 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:16,917][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5743174 effective words) took 3.9s, 1490869 effective words/s
[2023-02-07 20:44:17,926][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 25.85% examples, 1481337 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:18,930][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 51.06% examples, 1489209 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:19,933][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 77.31% examples, 1488722 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:20,771][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5743174 effective words) took 3.9s, 1491077 effective words/s
[2023-02-07 20:44:21,775][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 25.85% examples, 1487892 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:22,780][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 51.06% examples, 1491718 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:23,781][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 77.77% examples, 1498581 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:24,607][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5743174 effective words) took 3.8s, 1497854 effective words/s
[2023-02-07 20:44:25,613][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 25.58% examples, 1459745 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:26,622][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 50.38% examples, 1464049 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:27,630][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 76.14% examples, 1466888 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:28,507][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5743174 effective words) took 3.9s, 1473196 effective words/s
[2023-02-07 20:44:29,520][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 25.85% examples, 1473903 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:30,531][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 51.06% examples, 1480314 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:31,546][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 78.05% examples, 1490271 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:32,349][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5743174 effective words) took 3.8s, 1495259 effective words/s
[2023-02-07 20:44:33,358][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 25.85% examples, 1482822 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:34,369][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 51.06% examples, 1485093 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:35,370][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 77.46% examples, 1489825 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:36,214][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5743174 effective words) took 3.9s, 1487291 effective words/s
[2023-02-07 20:44:37,223][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 25.85% examples, 1480894 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:38,225][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 51.06% examples, 1490069 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:39,229][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 77.77% examples, 1496039 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:40,049][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5743174 effective words) took 3.8s, 1498229 effective words/s
[2023-02-07 20:44:41,057][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 25.85% examples, 1481068 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:42,062][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 50.97% examples, 1483449 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:43,066][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 77.68% examples, 1493584 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:43,882][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5743174 effective words) took 3.8s, 1498963 effective words/s
[2023-02-07 20:44:43,882][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86147610 effective words) took 57.8s, 1489232 effective words/s', 'datetime': '2023-02-07T20:44:43.882602', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:44:43.882 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:44:49,495][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204312-n7hzom1m/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:44:49.495363', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:44:49,496][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:44:49,613][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204312-n7hzom1m/files/../tmp/embedding_model.pt
2023-02-07 20:44:49.614 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:44:51.651 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:44:52.450 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:45:20.600 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1063313696039985, 'test_mae': 0.791786382214789, 'test_r2': -3.0316773545520332}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.032 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.032 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.37
wandb: percentage 0.5009
wandb:   test_mae 0.79179
wandb:   test_mse 1.10633
wandb:    test_r2 -3.03168
wandb: 
wandb: üöÄ View run comfy-sweep-88 at: https://wandb.ai/xiaoqiz/mof2vec/runs/n7hzom1m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_204312-n7hzom1m/logs
wandb: Agent Starting Run: zpfqta2v with config:
wandb: 	data.data.wl_step: 3
wandb: 	data.nn.batch_size: 961
wandb: 	model.gensim.alpha: 0.01151003487806808
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.5141780775550231
wandb: 	model.gensim.vector_size: 267
wandb: 	model.gensim.window: 4
wandb: 	model.sklearn.learning_rate: 0.04860969913500942
wandb: 	model.sklearn.max_depth: 45
wandb: 	model.sklearn.min_child_weight: 0.05610820516768707
wandb: 	model.sklearn.n_estimators: 1858
wandb: 	model.sklearn.num_leaves: 411
wandb: 	model.sklearn.reg_alpha: 0.004095806804404662
wandb: 	model.sklearn.reg_lambda: 0.026944477172722005
wandb: 	model.sklearn.subsample: 0.2777356187802775
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204532-zpfqta2v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-89
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/zpfqta2v
2023-02-07 20:45:40.495 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 3 for sweep.
2023-02-07 20:45:40.496 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 961 for sweep.
2023-02-07 20:45:40.496 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.01151003487806808 for sweep.
2023-02-07 20:45:40.497 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:45:40.497 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 20:45:40.497 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5141780775550231 for sweep.
2023-02-07 20:45:40.497 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 267 for sweep.
2023-02-07 20:45:40.498 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 4 for sweep.
2023-02-07 20:45:40.498 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.04860969913500942 for sweep.
2023-02-07 20:45:40.498 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 45 for sweep.
2023-02-07 20:45:40.498 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05610820516768707 for sweep.
2023-02-07 20:45:40.499 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1858 for sweep.
2023-02-07 20:45:40.499 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 411 for sweep.
2023-02-07 20:45:40.499 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004095806804404662 for sweep.
2023-02-07 20:45:40.500 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.026944477172722005 for sweep.
2023-02-07 20:45:40.500 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2777356187802775 for sweep.
2023-02-07 20:45:40.500 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:45:40.505 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 3}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204532-zpfqta2v/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 961, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 267, 'window': 4, 'min_count': 6, 'dm': 0, 'sample': 0.5141780775550231, 'workers': 4, 'alpha': 0.01151003487806808, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1858, 'max_depth': 45, 'num_leaves': 411, 'reg_alpha': 0.004095806804404662, 'reg_lambda': 0.026944477172722005, 'subsample': 0.2777356187802775, 'min_child_weight': 0.05610820516768707, 'n_jobs': 4, 'learning_rate': 0.04860969913500942}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 23/3257 [00:00<00:14, 227.95it/s]  1%|‚ñè         | 46/3257 [00:00<00:14, 223.90it/s]  2%|‚ñè         | 69/3257 [00:00<00:14, 216.24it/s]  3%|‚ñé         | 95/3257 [00:00<00:13, 231.70it/s]  4%|‚ñé         | 119/3257 [00:00<00:14, 223.51it/s]  4%|‚ñç         | 145/3257 [00:00<00:13, 233.10it/s]  5%|‚ñå         | 169/3257 [00:00<00:13, 226.05it/s]  6%|‚ñå         | 193/3257 [00:00<00:13, 227.01it/s]  7%|‚ñã         | 217/3257 [00:00<00:13, 229.75it/s]  8%|‚ñä         | 245/3257 [00:01<00:12, 241.17it/s]  8%|‚ñä         | 270/3257 [00:01<00:12, 237.36it/s]  9%|‚ñâ         | 304/3257 [00:01<00:11, 264.51it/s] 10%|‚ñà         | 336/3257 [00:01<00:10, 278.40it/s] 11%|‚ñà‚ñè        | 367/3257 [00:01<00:10, 284.25it/s] 12%|‚ñà‚ñè        | 396/3257 [00:01<00:10, 274.94it/s] 13%|‚ñà‚ñé        | 425/3257 [00:01<00:10, 268.95it/s] 14%|‚ñà‚ñç        | 452/3257 [00:01<00:10, 264.88it/s] 15%|‚ñà‚ñç        | 481/3257 [00:01<00:10, 270.95it/s] 16%|‚ñà‚ñå        | 513/3257 [00:02<00:09, 284.60it/s] 17%|‚ñà‚ñã        | 544/3257 [00:02<00:09, 290.38it/s] 18%|‚ñà‚ñä        | 574/3257 [00:02<00:09, 268.86it/s] 19%|‚ñà‚ñä        | 606/3257 [00:02<00:09, 282.76it/s] 20%|‚ñà‚ñâ        | 637/3257 [00:02<00:09, 289.20it/s] 20%|‚ñà‚ñà        | 667/3257 [00:02<00:09, 274.77it/s] 21%|‚ñà‚ñà‚ñè       | 695/3257 [00:02<00:09, 273.37it/s] 22%|‚ñà‚ñà‚ñè       | 723/3257 [00:02<00:09, 274.34it/s] 23%|‚ñà‚ñà‚ñé       | 751/3257 [00:02<00:09, 275.31it/s] 24%|‚ñà‚ñà‚ñç       | 780/3257 [00:02<00:08, 278.51it/s] 25%|‚ñà‚ñà‚ñç       | 810/3257 [00:03<00:08, 284.74it/s] 26%|‚ñà‚ñà‚ñå       | 839/3257 [00:03<00:08, 275.97it/s] 27%|‚ñà‚ñà‚ñã       | 867/3257 [00:03<00:08, 276.46it/s] 27%|‚ñà‚ñà‚ñã       | 895/3257 [00:03<00:11, 197.69it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:03<00:10, 226.64it/s] 29%|‚ñà‚ñà‚ñâ       | 957/3257 [00:03<00:09, 240.44it/s] 30%|‚ñà‚ñà‚ñà       | 984/3257 [00:03<00:09, 246.57it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:03<00:09, 248.57it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1038/3257 [00:04<00:08, 252.53it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:04<00:08, 258.95it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:04<00:08, 258.83it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:04<00:07, 266.78it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1152/3257 [00:04<00:07, 266.84it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1179/3257 [00:04<00:07, 266.71it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1206/3257 [00:04<00:07, 259.74it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1239/3257 [00:04<00:07, 277.93it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1268/3257 [00:04<00:07, 280.88it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1297/3257 [00:05<00:07, 259.71it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:05<00:07, 269.54it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1357/3257 [00:05<00:06, 273.68it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:05<00:06, 273.55it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1420/3257 [00:05<00:06, 292.60it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1451/3257 [00:05<00:06, 297.55it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1483/3257 [00:05<00:05, 303.74it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1514/3257 [00:05<00:05, 304.16it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1545/3257 [00:05<00:06, 281.58it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:05<00:05, 282.10it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1605/3257 [00:06<00:05, 286.42it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:06<00:05, 285.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1663/3257 [00:06<00:05, 280.74it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:06<00:05, 279.32it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:06<00:05, 286.41it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1752/3257 [00:06<00:05, 271.97it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1785/3257 [00:06<00:05, 286.01it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:06<00:05, 281.96it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:06<00:04, 288.40it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:07<00:04, 299.00it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1911/3257 [00:07<00:04, 301.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1945/3257 [00:07<00:04, 311.25it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1978/3257 [00:07<00:04, 316.54it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2010/3257 [00:07<00:03, 315.65it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2042/3257 [00:07<00:03, 310.29it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2074/3257 [00:07<00:03, 301.03it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2105/3257 [00:07<00:03, 296.14it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2135/3257 [00:07<00:03, 289.03it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2164/3257 [00:08<00:05, 201.09it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2196/3257 [00:08<00:04, 225.76it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2225/3257 [00:08<00:04, 238.69it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2256/3257 [00:08<00:03, 254.93it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2287/3257 [00:08<00:03, 269.10it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2319/3257 [00:08<00:03, 282.43it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2357/3257 [00:08<00:02, 309.56it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2390/3257 [00:08<00:02, 313.98it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2423/3257 [00:08<00:02, 309.82it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2455/3257 [00:09<00:02, 297.53it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2491/3257 [00:09<00:02, 314.07it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2527/3257 [00:09<00:02, 326.46it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2561/3257 [00:09<00:02, 321.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2594/3257 [00:09<00:02, 311.26it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:09<00:01, 333.52it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2668/3257 [00:09<00:01, 324.01it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2701/3257 [00:09<00:01, 307.87it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2736/3257 [00:09<00:01, 318.98it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2769/3257 [00:10<00:01, 313.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2805/3257 [00:10<00:01, 323.85it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2838/3257 [00:10<00:01, 305.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2873/3257 [00:10<00:01, 316.31it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2905/3257 [00:10<00:01, 296.01it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2935/3257 [00:10<00:01, 294.21it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2965/3257 [00:10<00:01, 289.04it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2995/3257 [00:10<00:00, 284.69it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3027/3257 [00:10<00:00, 292.80it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3064/3257 [00:11<00:00, 313.61it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3096/3257 [00:11<00:00, 304.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3130/3257 [00:11<00:00, 313.61it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3162/3257 [00:11<00:00, 300.43it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3193/3257 [00:11<00:00, 299.29it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3224/3257 [00:11<00:00, 293.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:11<00:00, 303.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:11<00:00, 279.41it/s]
2023-02-07 20:45:52.512 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:45:52,513][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d267,n5,mc6,s0.514178,t4>', 'datetime': '2023-02-07T20:45:52.513199', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:45:52,513][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:45:52,513][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:45:52,767][gensim.models.doc2vec][INFO] - collected 6662 word types and 3257 unique tags from a corpus of 3257 examples and 2911496 words
[2023-02-07 20:45:52,767][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:45:52,777][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 3569 unique words (53.57% of original 6662, drops 3093)', 'datetime': '2023-02-07T20:45:52.777145', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:45:52,777][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 2903654 word corpus (99.73% of original 2911496, drops 7842)', 'datetime': '2023-02-07T20:45:52.777483', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:45:52,789][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 6662 items
[2023-02-07 20:45:52,789][gensim.models.word2vec][INFO] - sample=0.514178 downsamples 0 most-common words
[2023-02-07 20:45:52,790][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2903654 word corpus (100.0%% of prior 2903654)', 'datetime': '2023-02-07T20:45:52.790913', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:45:52,811][gensim.models.word2vec][INFO] - estimated required memory for 3569 words and 267 dimensions: 13537760 bytes
[2023-02-07 20:45:52,812][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:45:52,818][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 3569 vocabulary and 267 features, using sg=1 hs=0 sample=0.5141780775550231 negative=5 window=4 shrink_windows=True', 'datetime': '2023-02-07T20:45:52.818726', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:45:53,820][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 89.01% examples, 2603489 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:45:53,927][gensim.models.word2vec][INFO] - EPOCH 0: training on 2911496 raw words (2906911 effective words) took 1.1s, 2626628 effective words/s
[2023-02-07 20:45:54,870][gensim.models.word2vec][INFO] - EPOCH 1: training on 2911496 raw words (2906911 effective words) took 0.9s, 3086601 effective words/s
[2023-02-07 20:45:55,872][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 96.16% examples, 2797656 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:45:55,913][gensim.models.word2vec][INFO] - EPOCH 2: training on 2911496 raw words (2906911 effective words) took 1.0s, 2790924 effective words/s
[2023-02-07 20:45:56,918][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 97.61% examples, 2833238 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:45:56,934][gensim.models.word2vec][INFO] - EPOCH 3: training on 2911496 raw words (2906911 effective words) took 1.0s, 2851261 effective words/s
[2023-02-07 20:45:57,941][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 96.16% examples, 2781395 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:57,974][gensim.models.word2vec][INFO] - EPOCH 4: training on 2911496 raw words (2906911 effective words) took 1.0s, 2797738 effective words/s
[2023-02-07 20:45:58,980][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 62.08% examples, 1828885 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:45:59,495][gensim.models.word2vec][INFO] - EPOCH 5: training on 2911496 raw words (2906911 effective words) took 1.5s, 1914619 effective words/s
[2023-02-07 20:46:00,497][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 96.47% examples, 2804784 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:00,527][gensim.models.word2vec][INFO] - EPOCH 6: training on 2911496 raw words (2906911 effective words) took 1.0s, 2820942 effective words/s
[2023-02-07 20:46:01,529][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 97.61% examples, 2840880 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:46:01,545][gensim.models.word2vec][INFO] - EPOCH 7: training on 2911496 raw words (2906911 effective words) took 1.0s, 2857573 effective words/s
[2023-02-07 20:46:02,536][gensim.models.word2vec][INFO] - EPOCH 8: training on 2911496 raw words (2906911 effective words) took 1.0s, 2936583 effective words/s
[2023-02-07 20:46:03,539][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 99.11% examples, 2883852 words/s, in_qsize 2, out_qsize 1
[2023-02-07 20:46:03,541][gensim.models.word2vec][INFO] - EPOCH 9: training on 2911496 raw words (2906911 effective words) took 1.0s, 2896183 effective words/s
[2023-02-07 20:46:04,545][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 96.47% examples, 2798670 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:46:04,585][gensim.models.word2vec][INFO] - EPOCH 10: training on 2911496 raw words (2906911 effective words) took 1.0s, 2786479 effective words/s
[2023-02-07 20:46:05,589][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 97.61% examples, 2840617 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:46:05,604][gensim.models.word2vec][INFO] - EPOCH 11: training on 2911496 raw words (2906911 effective words) took 1.0s, 2860553 effective words/s
[2023-02-07 20:46:06,608][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 59.20% examples, 1759754 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:07,026][gensim.models.word2vec][INFO] - EPOCH 12: training on 2911496 raw words (2906911 effective words) took 1.4s, 2047841 effective words/s
[2023-02-07 20:46:08,029][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 97.39% examples, 2831693 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:08,050][gensim.models.word2vec][INFO] - EPOCH 13: training on 2911496 raw words (2906911 effective words) took 1.0s, 2843284 effective words/s
[2023-02-07 20:46:09,053][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 97.61% examples, 2838925 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:46:09,070][gensim.models.word2vec][INFO] - EPOCH 14: training on 2911496 raw words (2906911 effective words) took 1.0s, 2853582 effective words/s
[2023-02-07 20:46:09,070][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 43672440 raw words (43603665 effective words) took 16.3s, 2683032 effective words/s', 'datetime': '2023-02-07T20:46:09.070733', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:46:09.070 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:46:10,464][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204532-zpfqta2v/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:46:10.464872', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:46:10,466][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:46:10,499][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204532-zpfqta2v/files/../tmp/embedding_model.pt
2023-02-07 20:46:10.500 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:46:12.178 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:46:12.822 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:46:14.641 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9930519530731402, 'test_mae': 0.7636833886153127, 'test_r2': -2.100913460773278}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.7
wandb: percentage 0.46427
wandb:   test_mae 0.76368
wandb:   test_mse 0.99305
wandb:    test_r2 -2.10091
wandb: 
wandb: üöÄ View run lively-sweep-89 at: https://wandb.ai/xiaoqiz/mof2vec/runs/zpfqta2v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_204532-zpfqta2v/logs
wandb: Agent Starting Run: i16l7x59 with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 631
wandb: 	model.gensim.alpha: 0.010643177548394202
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.488198354818006
wandb: 	model.gensim.vector_size: 324
wandb: 	model.gensim.window: 5
wandb: 	model.sklearn.learning_rate: 0.1901483230175405
wandb: 	model.sklearn.max_depth: 27
wandb: 	model.sklearn.min_child_weight: 0.05597664457251158
wandb: 	model.sklearn.n_estimators: 2463
wandb: 	model.sklearn.num_leaves: 340
wandb: 	model.sklearn.reg_alpha: 0.026387007590092923
wandb: 	model.sklearn.reg_lambda: 0.9690503367788912
wandb: 	model.sklearn.subsample: 0.7861522722286807
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204624-i16l7x59
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-90
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/i16l7x59
2023-02-07 20:46:32.632 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 20:46:32.632 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 631 for sweep.
2023-02-07 20:46:32.632 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.010643177548394202 for sweep.
2023-02-07 20:46:32.633 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:46:32.633 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 20:46:32.633 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.488198354818006 for sweep.
2023-02-07 20:46:32.633 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 324 for sweep.
2023-02-07 20:46:32.633 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 5 for sweep.
2023-02-07 20:46:32.634 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.1901483230175405 for sweep.
2023-02-07 20:46:32.634 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 27 for sweep.
2023-02-07 20:46:32.634 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05597664457251158 for sweep.
2023-02-07 20:46:32.634 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2463 for sweep.
2023-02-07 20:46:32.635 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 340 for sweep.
2023-02-07 20:46:32.635 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.026387007590092923 for sweep.
2023-02-07 20:46:32.635 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.9690503367788912 for sweep.
2023-02-07 20:46:32.635 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7861522722286807 for sweep.
2023-02-07 20:46:32.635 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:46:32.639 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204624-i16l7x59/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 631, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 324, 'window': 5, 'min_count': 5, 'dm': 0, 'sample': 0.488198354818006, 'workers': 4, 'alpha': 0.010643177548394202, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2463, 'max_depth': 27, 'num_leaves': 340, 'reg_alpha': 0.026387007590092923, 'reg_lambda': 0.9690503367788912, 'subsample': 0.7861522722286807, 'min_child_weight': 0.05597664457251158, 'n_jobs': 4, 'learning_rate': 0.1901483230175405}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 22/3257 [00:00<00:14, 218.20it/s]  1%|‚ñè         | 44/3257 [00:00<00:14, 214.67it/s]  2%|‚ñè         | 66/3257 [00:00<00:15, 211.40it/s]  3%|‚ñé         | 88/3257 [00:00<00:14, 211.89it/s]  3%|‚ñé         | 110/3257 [00:00<00:15, 201.02it/s]  4%|‚ñç         | 134/3257 [00:00<00:14, 210.98it/s]  5%|‚ñç         | 158/3257 [00:00<00:14, 219.90it/s]  6%|‚ñå         | 181/3257 [00:00<00:14, 212.21it/s]  6%|‚ñã         | 204/3257 [00:00<00:14, 216.07it/s]  7%|‚ñã         | 234/3257 [00:01<00:12, 238.77it/s]  8%|‚ñä         | 259/3257 [00:01<00:13, 228.45it/s]  9%|‚ñâ         | 286/3257 [00:01<00:12, 239.28it/s] 10%|‚ñâ         | 311/3257 [00:01<00:12, 234.37it/s] 10%|‚ñà         | 335/3257 [00:01<00:18, 158.32it/s] 11%|‚ñà         | 355/3257 [00:01<00:17, 166.52it/s] 12%|‚ñà‚ñè        | 375/3257 [00:01<00:16, 172.99it/s] 12%|‚ñà‚ñè        | 395/3257 [00:01<00:16, 176.88it/s] 13%|‚ñà‚ñé        | 417/3257 [00:02<00:15, 188.04it/s] 13%|‚ñà‚ñé        | 437/3257 [00:02<00:16, 169.92it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:15, 181.72it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:15, 180.04it/s] 15%|‚ñà‚ñå        | 501/3257 [00:02<00:14, 190.35it/s] 16%|‚ñà‚ñå        | 522/3257 [00:02<00:14, 190.96it/s] 17%|‚ñà‚ñã        | 542/3257 [00:02<00:14, 191.37it/s] 17%|‚ñà‚ñã        | 562/3257 [00:02<00:14, 182.85it/s] 18%|‚ñà‚ñä        | 581/3257 [00:02<00:14, 183.74it/s] 19%|‚ñà‚ñä        | 607/3257 [00:03<00:12, 204.12it/s] 19%|‚ñà‚ñâ        | 630/3257 [00:03<00:12, 210.91it/s] 20%|‚ñà‚ñà        | 652/3257 [00:03<00:12, 207.99it/s] 21%|‚ñà‚ñà        | 674/3257 [00:03<00:12, 210.31it/s] 21%|‚ñà‚ñà‚ñè       | 696/3257 [00:03<00:12, 203.01it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:03<00:12, 206.77it/s] 23%|‚ñà‚ñà‚ñé       | 741/3257 [00:03<00:12, 194.21it/s] 24%|‚ñà‚ñà‚ñé       | 766/3257 [00:03<00:12, 207.55it/s] 24%|‚ñà‚ñà‚ñç       | 787/3257 [00:03<00:12, 195.42it/s] 25%|‚ñà‚ñà‚ñç       | 807/3257 [00:04<00:12, 193.55it/s] 25%|‚ñà‚ñà‚ñå       | 827/3257 [00:04<00:12, 188.54it/s] 26%|‚ñà‚ñà‚ñå       | 846/3257 [00:04<00:13, 182.72it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:04<00:12, 185.30it/s] 27%|‚ñà‚ñà‚ñã       | 885/3257 [00:04<00:12, 185.50it/s] 28%|‚ñà‚ñà‚ñä       | 908/3257 [00:04<00:11, 197.02it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:04<00:11, 204.65it/s] 29%|‚ñà‚ñà‚ñâ       | 952/3257 [00:04<00:11, 201.61it/s] 30%|‚ñà‚ñà‚ñâ       | 973/3257 [00:04<00:11, 193.57it/s] 30%|‚ñà‚ñà‚ñà       | 993/3257 [00:05<00:12, 185.82it/s] 31%|‚ñà‚ñà‚ñà       | 1012/3257 [00:05<00:12, 185.79it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1033/3257 [00:05<00:11, 191.38it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1055/3257 [00:05<00:11, 196.95it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:05<00:10, 201.90it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1104/3257 [00:05<00:10, 210.70it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1126/3257 [00:05<00:10, 205.03it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1147/3257 [00:05<00:10, 202.48it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:05<00:09, 211.62it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1193/3257 [00:06<00:10, 199.30it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1214/3257 [00:06<00:10, 197.20it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:06<00:09, 214.61it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1263/3257 [00:06<00:09, 213.42it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1285/3257 [00:06<00:09, 201.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:06<00:09, 206.82it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1332/3257 [00:06<00:08, 215.47it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:06<00:08, 214.67it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1376/3257 [00:06<00:08, 214.89it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1398/3257 [00:06<00:08, 212.39it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:07<00:08, 217.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1448/3257 [00:07<00:08, 224.56it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:07<00:07, 233.78it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1502/3257 [00:07<00:07, 245.14it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1527/3257 [00:07<00:07, 228.75it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1551/3257 [00:07<00:07, 222.38it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:07<00:11, 151.55it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1598/3257 [00:08<00:09, 168.63it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1622/3257 [00:08<00:08, 183.81it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1644/3257 [00:08<00:08, 190.88it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1665/3257 [00:08<00:08, 193.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1687/3257 [00:08<00:07, 200.41it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1711/3257 [00:08<00:07, 210.76it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1733/3257 [00:08<00:08, 189.36it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1756/3257 [00:08<00:07, 199.47it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:08<00:07, 205.73it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1801/3257 [00:09<00:07, 206.70it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1823/3257 [00:09<00:07, 202.43it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1844/3257 [00:09<00:07, 197.60it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1866/3257 [00:09<00:06, 203.38it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1887/3257 [00:09<00:06, 197.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1907/3257 [00:09<00:07, 190.45it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1927/3257 [00:09<00:07, 186.43it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1952/3257 [00:09<00:06, 203.54it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1973/3257 [00:09<00:06, 204.68it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1994/3257 [00:09<00:06, 198.88it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2015/3257 [00:10<00:06, 195.24it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2036/3257 [00:10<00:06, 198.60it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2056/3257 [00:10<00:06, 180.60it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2075/3257 [00:10<00:06, 181.87it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2094/3257 [00:10<00:06, 182.84it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2113/3257 [00:10<00:06, 180.56it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:10<00:06, 173.09it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2150/3257 [00:10<00:06, 172.80it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2170/3257 [00:10<00:06, 179.19it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2189/3257 [00:11<00:05, 179.20it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2208/3257 [00:11<00:05, 180.36it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2227/3257 [00:11<00:05, 178.29it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2245/3257 [00:11<00:05, 174.78it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2265/3257 [00:11<00:05, 179.05it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2283/3257 [00:11<00:05, 178.13it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2303/3257 [00:11<00:05, 182.30it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2327/3257 [00:11<00:04, 196.87it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2352/3257 [00:11<00:04, 211.04it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2374/3257 [00:12<00:04, 202.84it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:12<00:04, 208.73it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2418/3257 [00:12<00:04, 193.28it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2438/3257 [00:12<00:04, 186.34it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2457/3257 [00:12<00:04, 186.67it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2479/3257 [00:12<00:04, 194.08it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2502/3257 [00:12<00:03, 202.60it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:12<00:03, 205.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2545/3257 [00:12<00:03, 202.47it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2566/3257 [00:13<00:03, 184.15it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2585/3257 [00:13<00:03, 173.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2605/3257 [00:13<00:03, 179.53it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2628/3257 [00:13<00:03, 192.55it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2648/3257 [00:13<00:03, 184.25it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2667/3257 [00:13<00:03, 181.33it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:13<00:03, 186.08it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2706/3257 [00:13<00:03, 171.65it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2724/3257 [00:13<00:03, 166.91it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2742/3257 [00:14<00:03, 168.84it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:14<00:02, 168.45it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:14<00:02, 171.33it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2801/3257 [00:14<00:02, 184.21it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2820/3257 [00:14<00:02, 176.05it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2838/3257 [00:14<00:02, 171.50it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2862/3257 [00:14<00:02, 187.14it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:14<00:01, 194.52it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:14<00:01, 186.28it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:15<00:01, 191.64it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2948/3257 [00:15<00:01, 183.92it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2968/3257 [00:15<00:01, 187.66it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2987/3257 [00:15<00:01, 175.61it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:15<00:01, 192.80it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3031/3257 [00:15<00:02, 112.46it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3053/3257 [00:15<00:01, 132.48it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:16<00:01, 150.43it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3095/3257 [00:16<00:01, 160.22it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:16<00:00, 176.27it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3138/3257 [00:16<00:00, 179.98it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3158/3257 [00:16<00:00, 176.17it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3177/3257 [00:16<00:00, 174.33it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3197/3257 [00:16<00:00, 180.56it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3216/3257 [00:16<00:00, 176.73it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3238/3257 [00:16<00:00, 187.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 191.35it/s]
2023-02-07 20:46:50.311 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:46:50,313][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d324,n5,mc5,s0.488198,t4>', 'datetime': '2023-02-07T20:46:50.313104', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:46:50,313][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:46:50,314][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:46:50,738][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 20:46:50,738][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:46:50,771][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11219 unique words (51.70% of original 21699, drops 10480)', 'datetime': '2023-02-07T20:46:50.771594', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:46:50,772][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 4341582 word corpus (99.41% of original 4367244, drops 25662)', 'datetime': '2023-02-07T20:46:50.772053', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:46:50,811][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 20:46:50,812][gensim.models.word2vec][INFO] - sample=0.488198 downsamples 0 most-common words
[2023-02-07 20:46:50,812][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4341582 word corpus (100.0%% of prior 4341582)', 'datetime': '2023-02-07T20:46:50.812904', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:46:50,882][gensim.models.word2vec][INFO] - estimated required memory for 11219 words and 324 dimensions: 39561620 bytes
[2023-02-07 20:46:50,882][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:46:50,903][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11219 vocabulary and 324 features, using sg=1 hs=0 sample=0.488198354818006 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-07T20:46:50.903645', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:46:51,912][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 44.83% examples, 1975694 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:52,916][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 94.20% examples, 2041420 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:53,023][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4343128 effective words) took 2.1s, 2051293 effective words/s
[2023-02-07 20:46:54,027][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 52.32% examples, 2319029 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:54,904][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4343128 effective words) took 1.9s, 2310150 effective words/s
[2023-02-07 20:46:55,910][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 50.88% examples, 2247218 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:56,827][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4343128 effective words) took 1.9s, 2259634 effective words/s
[2023-02-07 20:46:57,830][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 51.27% examples, 2275039 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:58,729][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4343128 effective words) took 1.9s, 2285872 effective words/s
[2023-02-07 20:46:59,735][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 51.64% examples, 2284523 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:47:00,617][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4343128 effective words) took 1.9s, 2301898 effective words/s
[2023-02-07 20:47:01,624][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 52.44% examples, 2325809 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:02,483][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4343128 effective words) took 1.9s, 2331036 effective words/s
[2023-02-07 20:47:03,486][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 52.44% examples, 2330293 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:04,336][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4343128 effective words) took 1.9s, 2345465 effective words/s
[2023-02-07 20:47:05,338][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 53.24% examples, 2371227 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:06,177][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4343128 effective words) took 1.8s, 2360643 effective words/s
[2023-02-07 20:47:07,180][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 52.04% examples, 2311863 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:08,048][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4343128 effective words) took 1.9s, 2323385 effective words/s
[2023-02-07 20:47:09,050][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 53.05% examples, 2361236 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:09,895][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4343128 effective words) took 1.8s, 2352570 effective words/s
[2023-02-07 20:47:10,901][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 51.64% examples, 2287081 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:11,787][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4343128 effective words) took 1.9s, 2298324 effective words/s
[2023-02-07 20:47:12,791][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 52.04% examples, 2308422 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:13,677][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4343128 effective words) took 1.9s, 2299741 effective words/s
[2023-02-07 20:47:14,681][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 52.29% examples, 2318231 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:15,541][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4343128 effective words) took 1.9s, 2331662 effective words/s
[2023-02-07 20:47:16,545][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 53.67% examples, 2388390 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:47:17,371][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4343128 effective words) took 1.8s, 2376248 effective words/s
[2023-02-07 20:47:18,375][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 53.05% examples, 2358321 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:19,236][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4343128 effective words) took 1.9s, 2330375 effective words/s
[2023-02-07 20:47:19,237][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65146920 effective words) took 28.3s, 2299325 effective words/s', 'datetime': '2023-02-07T20:47:19.237173', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:47:19.237 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:47:21,971][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204624-i16l7x59/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:47:21.971487', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:47:21,972][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:47:22,024][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204624-i16l7x59/files/../tmp/embedding_model.pt
2023-02-07 20:47:22.025 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:47:24.043 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:47:24.765 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:47:29.428 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0007257084316472, 'test_mae': 0.7429606838186095, 'test_r2': -1.7024613126892003}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.79
wandb: percentage 0.48297
wandb:   test_mae 0.74296
wandb:   test_mse 1.00073
wandb:    test_r2 -1.70246
wandb: 
wandb: üöÄ View run celestial-sweep-90 at: https://wandb.ai/xiaoqiz/mof2vec/runs/i16l7x59
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_204624-i16l7x59/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: l0e45x9f with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 663
wandb: 	model.gensim.alpha: 0.008454014618717687
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.2078758109556809
wandb: 	model.gensim.vector_size: 258
wandb: 	model.gensim.window: 4
wandb: 	model.sklearn.learning_rate: 0.0016890301728720255
wandb: 	model.sklearn.max_depth: 35
wandb: 	model.sklearn.min_child_weight: 0.09635200151810586
wandb: 	model.sklearn.n_estimators: 917
wandb: 	model.sklearn.num_leaves: 372
wandb: 	model.sklearn.reg_alpha: 0.00782864742527444
wandb: 	model.sklearn.reg_lambda: 0.043090222080889744
wandb: 	model.sklearn.subsample: 0.9692589043917136
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204748-l0e45x9f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-91
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/l0e45x9f
2023-02-07 20:47:57.074 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:47:57.075 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 663 for sweep.
2023-02-07 20:47:57.075 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.008454014618717687 for sweep.
2023-02-07 20:47:57.076 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:47:57.076 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 20:47:57.076 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2078758109556809 for sweep.
2023-02-07 20:47:57.076 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 258 for sweep.
2023-02-07 20:47:57.077 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 4 for sweep.
2023-02-07 20:47:57.077 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0016890301728720255 for sweep.
2023-02-07 20:47:57.077 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 35 for sweep.
2023-02-07 20:47:57.078 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09635200151810586 for sweep.
2023-02-07 20:47:57.078 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 917 for sweep.
2023-02-07 20:47:57.078 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 372 for sweep.
2023-02-07 20:47:57.079 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.00782864742527444 for sweep.
2023-02-07 20:47:57.079 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.043090222080889744 for sweep.
2023-02-07 20:47:57.079 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9692589043917136 for sweep.
2023-02-07 20:47:57.079 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:47:57.085 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204748-l0e45x9f/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 663, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 258, 'window': 4, 'min_count': 2, 'dm': 0, 'sample': 0.2078758109556809, 'workers': 4, 'alpha': 0.008454014618717687, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 917, 'max_depth': 35, 'num_leaves': 372, 'reg_alpha': 0.00782864742527444, 'reg_lambda': 0.043090222080889744, 'subsample': 0.9692589043917136, 'min_child_weight': 0.09635200151810586, 'n_jobs': 4, 'learning_rate': 0.0016890301728720255}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:25, 126.12it/s]  1%|          | 29/3257 [00:00<00:22, 143.97it/s]  1%|‚ñè         | 44/3257 [00:00<00:22, 140.78it/s]  2%|‚ñè         | 59/3257 [00:00<00:23, 136.63it/s]  2%|‚ñè         | 76/3257 [00:00<00:21, 147.22it/s]  3%|‚ñé         | 91/3257 [00:00<00:21, 147.88it/s]  3%|‚ñé         | 106/3257 [00:00<00:22, 140.33it/s]  4%|‚ñé         | 121/3257 [00:00<00:21, 143.15it/s]  4%|‚ñç         | 140/3257 [00:00<00:20, 155.62it/s]  5%|‚ñç         | 157/3257 [00:01<00:19, 157.63it/s]  5%|‚ñå         | 173/3257 [00:01<00:21, 146.29it/s]  6%|‚ñå         | 192/3257 [00:01<00:19, 156.22it/s]  6%|‚ñã         | 209/3257 [00:01<00:19, 159.43it/s]  7%|‚ñã         | 230/3257 [00:01<00:17, 170.83it/s]  8%|‚ñä         | 248/3257 [00:01<00:17, 170.79it/s]  8%|‚ñä         | 266/3257 [00:01<00:18, 161.36it/s]  9%|‚ñâ         | 287/3257 [00:01<00:17, 173.84it/s]  9%|‚ñâ         | 305/3257 [00:01<00:17, 166.96it/s] 10%|‚ñâ         | 324/3257 [00:02<00:17, 172.21it/s] 11%|‚ñà         | 342/3257 [00:02<00:17, 162.06it/s] 11%|‚ñà         | 360/3257 [00:02<00:17, 165.00it/s] 12%|‚ñà‚ñè        | 377/3257 [00:02<00:19, 151.28it/s] 12%|‚ñà‚ñè        | 393/3257 [00:02<00:18, 152.79it/s] 13%|‚ñà‚ñé        | 411/3257 [00:02<00:17, 158.28it/s] 13%|‚ñà‚ñé        | 428/3257 [00:02<00:20, 137.82it/s] 14%|‚ñà‚ñé        | 443/3257 [00:02<00:20, 139.98it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:19, 144.14it/s] 15%|‚ñà‚ñç        | 476/3257 [00:03<00:18, 150.75it/s] 15%|‚ñà‚ñå        | 493/3257 [00:03<00:17, 153.57it/s] 16%|‚ñà‚ñå        | 512/3257 [00:03<00:16, 163.03it/s] 16%|‚ñà‚ñå        | 529/3257 [00:03<00:17, 159.45it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:17, 158.09it/s] 17%|‚ñà‚ñã        | 562/3257 [00:03<00:18, 149.45it/s] 18%|‚ñà‚ñä        | 578/3257 [00:03<00:18, 141.84it/s] 18%|‚ñà‚ñä        | 597/3257 [00:03<00:17, 153.76it/s] 19%|‚ñà‚ñâ        | 615/3257 [00:03<00:16, 159.41it/s] 19%|‚ñà‚ñâ        | 632/3257 [00:04<00:16, 159.24it/s] 20%|‚ñà‚ñâ        | 649/3257 [00:04<00:17, 149.95it/s] 20%|‚ñà‚ñà        | 665/3257 [00:04<00:18, 142.18it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:17, 144.11it/s] 21%|‚ñà‚ñà‚ñè       | 699/3257 [00:04<00:17, 147.73it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:16, 157.20it/s] 23%|‚ñà‚ñà‚ñé       | 734/3257 [00:04<00:16, 150.82it/s] 23%|‚ñà‚ñà‚ñé       | 750/3257 [00:04<00:17, 144.24it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:05<00:16, 153.40it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:05<00:16, 149.19it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:15, 154.03it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:15, 153.17it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:05<00:16, 143.78it/s] 26%|‚ñà‚ñà‚ñå       | 851/3257 [00:05<00:17, 137.83it/s] 27%|‚ñà‚ñà‚ñã       | 867/3257 [00:05<00:16, 142.99it/s] 27%|‚ñà‚ñà‚ñã       | 882/3257 [00:05<00:16, 141.81it/s] 28%|‚ñà‚ñà‚ñä       | 898/3257 [00:05<00:16, 145.51it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:06<00:16, 144.45it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:06<00:15, 150.64it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:06<00:15, 153.28it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:06<00:14, 159.84it/s] 30%|‚ñà‚ñà‚ñà       | 983/3257 [00:06<00:14, 152.84it/s] 31%|‚ñà‚ñà‚ñà       | 999/3257 [00:06<00:15, 148.34it/s] 31%|‚ñà‚ñà‚ñà       | 1014/3257 [00:06<00:15, 146.20it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1029/3257 [00:06<00:15, 143.88it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1044/3257 [00:06<00:15, 140.93it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1059/3257 [00:07<00:15, 142.51it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1078/3257 [00:07<00:14, 155.63it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:07<00:15, 140.50it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1113/3257 [00:07<00:14, 152.36it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1129/3257 [00:07<00:24, 88.15it/s]  35%|‚ñà‚ñà‚ñà‚ñå      | 1145/3257 [00:07<00:21, 98.85it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1163/3257 [00:07<00:18, 114.20it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1178/3257 [00:08<00:18, 115.34it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1192/3257 [00:08<00:17, 118.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1206/3257 [00:08<00:17, 120.19it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1220/3257 [00:08<00:16, 124.65it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:08<00:14, 143.68it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:08<00:14, 140.39it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1273/3257 [00:08<00:13, 145.25it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:08<00:14, 134.00it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1304/3257 [00:08<00:14, 138.36it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:09<00:13, 146.13it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:09<00:12, 151.35it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1355/3257 [00:09<00:13, 143.87it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:09<00:13, 144.91it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:09<00:13, 142.83it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:09<00:12, 146.27it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:09<00:11, 160.71it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:09<00:11, 155.02it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:09<00:10, 165.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:10<00:10, 161.82it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1495/3257 [00:10<00:10, 166.81it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:10<00:10, 166.92it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:10<00:11, 152.17it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:10<00:11, 144.01it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1562/3257 [00:10<00:11, 147.71it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1577/3257 [00:10<00:11, 146.09it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:10<00:10, 152.61it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1612/3257 [00:10<00:10, 159.43it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1629/3257 [00:11<00:10, 159.72it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1646/3257 [00:11<00:10, 149.20it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:11<00:11, 141.89it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:11<00:11, 141.35it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:11<00:11, 141.45it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:11<00:10, 146.18it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1726/3257 [00:11<00:09, 155.10it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1742/3257 [00:11<00:11, 130.96it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1761/3257 [00:11<00:10, 144.91it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1777/3257 [00:12<00:10, 145.74it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1795/3257 [00:12<00:09, 153.06it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1811/3257 [00:12<00:10, 144.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:12<00:09, 145.62it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1843/3257 [00:12<00:09, 150.66it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1859/3257 [00:12<00:09, 148.14it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1878/3257 [00:12<00:08, 158.06it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1894/3257 [00:12<00:09, 149.59it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1913/3257 [00:12<00:08, 159.05it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1930/3257 [00:13<00:08, 150.75it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:13<00:07, 172.96it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1973/3257 [00:13<00:07, 176.19it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1991/3257 [00:13<00:07, 166.25it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:13<00:07, 162.81it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2027/3257 [00:13<00:07, 169.49it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2045/3257 [00:13<00:07, 159.83it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2062/3257 [00:13<00:08, 143.40it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2080/3257 [00:14<00:07, 151.89it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2096/3257 [00:14<00:07, 146.80it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2113/3257 [00:14<00:07, 152.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2129/3257 [00:14<00:08, 140.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2144/3257 [00:14<00:08, 137.31it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2161/3257 [00:14<00:07, 144.85it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:14<00:07, 149.30it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2194/3257 [00:14<00:07, 151.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2210/3257 [00:14<00:07, 144.21it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2227/3257 [00:15<00:06, 150.24it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2243/3257 [00:15<00:07, 144.18it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:15<00:06, 147.97it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:15<00:06, 140.58it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2295/3257 [00:15<00:06, 156.17it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2311/3257 [00:15<00:06, 151.65it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2332/3257 [00:15<00:05, 166.78it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2353/3257 [00:15<00:05, 177.35it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2371/3257 [00:15<00:05, 170.04it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2390/3257 [00:16<00:04, 174.44it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2408/3257 [00:16<00:05, 162.55it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2425/3257 [00:16<00:05, 163.64it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2442/3257 [00:16<00:08, 91.52it/s]  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2458/3257 [00:16<00:07, 103.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:16<00:06, 116.16it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2490/3257 [00:16<00:06, 123.32it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2508/3257 [00:17<00:05, 136.82it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:17<00:05, 141.74it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:17<00:04, 144.91it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2556/3257 [00:17<00:04, 143.36it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:17<00:04, 137.95it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2587/3257 [00:17<00:04, 138.26it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2604/3257 [00:17<00:04, 145.72it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2624/3257 [00:17<00:03, 159.06it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2641/3257 [00:17<00:03, 155.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2657/3257 [00:18<00:04, 146.99it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:18<00:03, 148.54it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:18<00:03, 152.30it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2706/3257 [00:18<00:04, 135.84it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2720/3257 [00:18<00:04, 133.30it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2740/3257 [00:18<00:03, 150.37it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:18<00:03, 154.30it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2773/3257 [00:18<00:03, 148.93it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:18<00:02, 159.27it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2809/3257 [00:19<00:02, 157.55it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2825/3257 [00:19<00:02, 148.14it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2841/3257 [00:19<00:02, 147.42it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2862/3257 [00:19<00:02, 164.08it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2883/3257 [00:19<00:02, 176.79it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2901/3257 [00:19<00:02, 155.68it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:19<00:02, 163.81it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2937/3257 [00:19<00:01, 161.60it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2954/3257 [00:19<00:02, 149.49it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2970/3257 [00:20<00:01, 151.96it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2986/3257 [00:20<00:01, 143.52it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3007/3257 [00:20<00:01, 159.56it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3024/3257 [00:20<00:01, 152.52it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3044/3257 [00:20<00:01, 164.25it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3064/3257 [00:20<00:01, 172.59it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:20<00:01, 167.34it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3099/3257 [00:20<00:00, 167.11it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:20<00:00, 172.24it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3136/3257 [00:21<00:00, 162.79it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3153/3257 [00:21<00:00, 154.18it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3169/3257 [00:21<00:00, 155.37it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:21<00:00, 149.50it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:21<00:00, 156.26it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3219/3257 [00:21<00:00, 148.19it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:21<00:00, 159.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3256/3257 [00:21<00:00, 161.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 148.82it/s]
2023-02-07 20:48:20.095 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:48:20,097][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d258,n5,mc2,s0.207876,t4>', 'datetime': '2023-02-07T20:48:20.097731', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:48:20,099][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:48:20,099][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:48:20,799][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:48:20,800][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:48:20,936][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 46469 unique words (85.97% of original 54054, drops 7585)', 'datetime': '2023-02-07T20:48:20.936551', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:48:20,937][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 6543281 word corpus (99.88% of original 6550866, drops 7585)', 'datetime': '2023-02-07T20:48:20.937044', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:48:21,105][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:48:21,107][gensim.models.word2vec][INFO] - sample=0.207876 downsamples 0 most-common words
[2023-02-07 20:48:21,108][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6543281 word corpus (100.0%% of prior 6543281)', 'datetime': '2023-02-07T20:48:21.108011', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:48:21,401][gensim.models.word2vec][INFO] - estimated required memory for 46469 words and 258 dimensions: 123159140 bytes
[2023-02-07 20:48:21,401][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:48:21,460][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 46469 vocabulary and 258 features, using sg=1 hs=0 sample=0.2078758109556809 negative=5 window=4 shrink_windows=True', 'datetime': '2023-02-07T20:48:21.460300', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:48:22,464][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 29.38% examples, 1907369 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:23,464][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 58.92% examples, 1953095 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:24,468][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 90.45% examples, 1963749 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:24,748][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6488146 effective words) took 3.3s, 1975526 effective words/s
[2023-02-07 20:48:25,755][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 33.87% examples, 2205295 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:26,756][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 66.38% examples, 2190751 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:48:27,713][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6488146 effective words) took 3.0s, 2189627 effective words/s
[2023-02-07 20:48:28,722][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 34.33% examples, 2232502 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:29,722][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 67.61% examples, 2229759 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:30,631][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6488146 effective words) took 2.9s, 2224737 effective words/s
[2023-02-07 20:48:31,634][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 33.74% examples, 2210394 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:32,635][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 67.45% examples, 2228160 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:33,557][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6488146 effective words) took 2.9s, 2219066 effective words/s
[2023-02-07 20:48:34,562][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 34.57% examples, 2263193 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:48:35,564][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 68.62% examples, 2264927 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:36,435][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6488146 effective words) took 2.9s, 2256413 effective words/s
[2023-02-07 20:48:37,442][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 34.82% examples, 2277065 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:38,443][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 68.99% examples, 2280727 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:39,279][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6488146 effective words) took 2.8s, 2283753 effective words/s
[2023-02-07 20:48:40,285][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 34.82% examples, 2276053 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:41,286][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 69.42% examples, 2293108 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:42,088][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6488146 effective words) took 2.8s, 2310984 effective words/s
[2023-02-07 20:48:43,091][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 35.92% examples, 2357585 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:44,097][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 71.05% examples, 2345257 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:44,861][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6488146 effective words) took 2.8s, 2340694 effective words/s
[2023-02-07 20:48:45,863][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 36.08% examples, 2370332 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:46,863][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 72.06% examples, 2376739 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:47,584][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6488146 effective words) took 2.7s, 2383864 effective words/s
[2023-02-07 20:48:48,587][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.94% examples, 2446434 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:49,588][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 77.06% examples, 2525242 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:50,063][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6488146 effective words) took 2.5s, 2618833 effective words/s
[2023-02-07 20:48:51,065][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 40.84% examples, 2714949 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:48:52,069][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 80.01% examples, 2617490 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:52,599][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6488146 effective words) took 2.5s, 2560172 effective words/s
[2023-02-07 20:48:53,604][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 35.12% examples, 2300284 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:48:54,609][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 69.85% examples, 2310795 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:55,400][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6488146 effective words) took 2.8s, 2317172 effective words/s
[2023-02-07 20:48:56,404][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 35.34% examples, 2320569 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:48:57,408][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 69.45% examples, 2295391 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:48:58,242][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6488146 effective words) took 2.8s, 2284097 effective words/s
[2023-02-07 20:48:59,246][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 35.00% examples, 2296027 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:49:00,246][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 69.97% examples, 2322564 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:49:01,031][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6488146 effective words) took 2.8s, 2327347 effective words/s
[2023-02-07 20:49:02,036][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 35.00% examples, 2292504 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:49:03,037][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 69.42% examples, 2294269 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:49:03,878][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6488146 effective words) took 2.8s, 2280133 effective words/s
[2023-02-07 20:49:03,879][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (97322190 effective words) took 42.4s, 2294345 effective words/s', 'datetime': '2023-02-07T20:49:03.879084', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:49:03.879 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:49:08,469][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204748-l0e45x9f/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:49:08.469211', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:49:08,470][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204748-l0e45x9f/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 20:49:08,521][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204748-l0e45x9f/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 20:49:08,573][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:49:08,624][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204748-l0e45x9f/files/../tmp/embedding_model.pt
2023-02-07 20:49:08.624 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:49:10.482 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:49:11.119 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:49:36.096 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9731495452846216, 'test_mae': 0.7709581113757531, 'test_r2': -2.2177738341648863}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.84
wandb: percentage 0.14032
wandb:   test_mae 0.77096
wandb:   test_mse 0.97315
wandb:    test_r2 -2.21777
wandb: 
wandb: üöÄ View run polished-sweep-91 at: https://wandb.ai/xiaoqiz/mof2vec/runs/l0e45x9f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_204748-l0e45x9f/logs
wandb: Agent Starting Run: lm66gyu3 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 390
wandb: 	model.gensim.alpha: 0.15701177271447217
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.726830818435162
wandb: 	model.gensim.vector_size: 357
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.04989743060054568
wandb: 	model.sklearn.max_depth: 49
wandb: 	model.sklearn.min_child_weight: 0.08436855986050071
wandb: 	model.sklearn.n_estimators: 1374
wandb: 	model.sklearn.num_leaves: 403
wandb: 	model.sklearn.reg_alpha: 0.005454810616820878
wandb: 	model.sklearn.reg_lambda: 0.6570295344875279
wandb: 	model.sklearn.subsample: 0.7034971487137878
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204947-lm66gyu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-92
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/lm66gyu3
2023-02-07 20:49:55.634 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 20:49:55.634 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 390 for sweep.
2023-02-07 20:49:55.635 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.15701177271447217 for sweep.
2023-02-07 20:49:55.635 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:49:55.635 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 20:49:55.635 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.726830818435162 for sweep.
2023-02-07 20:49:55.636 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 357 for sweep.
2023-02-07 20:49:55.636 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 20:49:55.636 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.04989743060054568 for sweep.
2023-02-07 20:49:55.636 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 49 for sweep.
2023-02-07 20:49:55.636 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08436855986050071 for sweep.
2023-02-07 20:49:55.637 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1374 for sweep.
2023-02-07 20:49:55.637 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 403 for sweep.
2023-02-07 20:49:55.637 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.005454810616820878 for sweep.
2023-02-07 20:49:55.637 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.6570295344875279 for sweep.
2023-02-07 20:49:55.637 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7034971487137878 for sweep.
2023-02-07 20:49:55.638 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:49:55.644 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204947-lm66gyu3/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 390, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 357, 'window': 2, 'min_count': 3, 'dm': 0, 'sample': 0.726830818435162, 'workers': 4, 'alpha': 0.15701177271447217, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1374, 'max_depth': 49, 'num_leaves': 403, 'reg_alpha': 0.005454810616820878, 'reg_lambda': 0.6570295344875279, 'subsample': 0.7034971487137878, 'min_child_weight': 0.08436855986050071, 'n_jobs': 4, 'learning_rate': 0.04989743060054568}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:19, 168.49it/s]  1%|‚ñè         | 41/3257 [00:00<00:16, 191.70it/s]  2%|‚ñè         | 62/3257 [00:00<00:16, 199.05it/s]  3%|‚ñé         | 85/3257 [00:00<00:15, 209.49it/s]  3%|‚ñé         | 106/3257 [00:00<00:15, 199.02it/s]  4%|‚ñç         | 128/3257 [00:00<00:15, 203.89it/s]  5%|‚ñç         | 152/3257 [00:00<00:14, 213.15it/s]  5%|‚ñå         | 174/3257 [00:00<00:14, 207.91it/s]  6%|‚ñå         | 197/3257 [00:00<00:14, 213.86it/s]  7%|‚ñã         | 222/3257 [00:01<00:13, 223.47it/s]  8%|‚ñä         | 247/3257 [00:01<00:13, 230.19it/s]  8%|‚ñä         | 271/3257 [00:01<00:13, 219.06it/s]  9%|‚ñâ         | 298/3257 [00:01<00:12, 230.79it/s] 10%|‚ñâ         | 322/3257 [00:01<00:12, 231.06it/s] 11%|‚ñà         | 346/3257 [00:01<00:13, 218.08it/s] 11%|‚ñà‚ñè        | 369/3257 [00:01<00:13, 216.76it/s] 12%|‚ñà‚ñè        | 391/3257 [00:01<00:13, 207.56it/s] 13%|‚ñà‚ñé        | 415/3257 [00:01<00:13, 215.33it/s] 13%|‚ñà‚ñé        | 437/3257 [00:02<00:14, 190.73it/s] 14%|‚ñà‚ñç        | 461/3257 [00:02<00:13, 201.90it/s] 15%|‚ñà‚ñç        | 482/3257 [00:02<00:13, 203.44it/s] 16%|‚ñà‚ñå        | 509/3257 [00:02<00:12, 220.71it/s] 16%|‚ñà‚ñã        | 532/3257 [00:02<00:12, 213.56it/s] 17%|‚ñà‚ñã        | 556/3257 [00:02<00:12, 218.83it/s] 18%|‚ñà‚ñä        | 579/3257 [00:02<00:13, 196.50it/s] 19%|‚ñà‚ñä        | 603/3257 [00:02<00:12, 207.74it/s] 19%|‚ñà‚ñâ        | 625/3257 [00:03<00:19, 137.79it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:03<00:17, 147.32it/s] 20%|‚ñà‚ñà        | 662/3257 [00:03<00:17, 149.85it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:16, 160.42it/s] 22%|‚ñà‚ñà‚ñè       | 703/3257 [00:03<00:15, 168.60it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:03<00:14, 169.27it/s] 23%|‚ñà‚ñà‚ñé       | 740/3257 [00:03<00:15, 165.70it/s] 23%|‚ñà‚ñà‚ñé       | 761/3257 [00:03<00:14, 176.89it/s] 24%|‚ñà‚ñà‚ñç       | 780/3257 [00:04<00:14, 172.45it/s] 25%|‚ñà‚ñà‚ñç       | 799/3257 [00:04<00:13, 176.77it/s] 25%|‚ñà‚ñà‚ñå       | 818/3257 [00:04<00:13, 177.42it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:04<00:14, 166.73it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:04<00:14, 160.39it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:04<00:14, 163.83it/s] 27%|‚ñà‚ñà‚ñã       | 889/3257 [00:04<00:14, 166.06it/s] 28%|‚ñà‚ñà‚ñä       | 910/3257 [00:04<00:13, 178.25it/s] 29%|‚ñà‚ñà‚ñä       | 930/3257 [00:04<00:12, 181.71it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:05<00:12, 178.56it/s] 30%|‚ñà‚ñà‚ñâ       | 967/3257 [00:05<00:13, 174.97it/s] 30%|‚ñà‚ñà‚ñà       | 985/3257 [00:05<00:13, 172.55it/s] 31%|‚ñà‚ñà‚ñà       | 1003/3257 [00:05<00:13, 165.88it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1020/3257 [00:05<00:13, 165.52it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1037/3257 [00:05<00:13, 159.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1054/3257 [00:05<00:14, 156.12it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1074/3257 [00:05<00:13, 167.42it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:05<00:13, 159.12it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:05<00:12, 170.85it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1130/3257 [00:06<00:12, 164.74it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1147/3257 [00:06<00:13, 159.84it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1168/3257 [00:06<00:12, 173.04it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1186/3257 [00:06<00:13, 159.29it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1203/3257 [00:06<00:13, 149.85it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:06<00:13, 152.09it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:06<00:11, 168.80it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1259/3257 [00:06<00:11, 167.77it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1276/3257 [00:07<00:12, 164.56it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1293/3257 [00:07<00:12, 158.36it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:07<00:12, 158.59it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:07<00:11, 164.33it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:07<00:11, 168.57it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1363/3257 [00:07<00:11, 165.41it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1380/3257 [00:07<00:11, 161.55it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1397/3257 [00:07<00:11, 159.88it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1420/3257 [00:07<00:10, 176.92it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1438/3257 [00:07<00:10, 170.40it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:08<00:09, 183.07it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1479/3257 [00:08<00:09, 182.96it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1500/3257 [00:08<00:09, 189.03it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1519/3257 [00:08<00:09, 179.10it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1538/3257 [00:08<00:10, 168.99it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1556/3257 [00:08<00:10, 164.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:08<00:10, 167.95it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:08<00:09, 166.70it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1611/3257 [00:08<00:09, 174.70it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1630/3257 [00:09<00:09, 178.86it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1648/3257 [00:09<00:09, 163.15it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1665/3257 [00:09<00:09, 162.72it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1682/3257 [00:09<00:09, 164.28it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:09<00:09, 167.36it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1717/3257 [00:09<00:09, 165.89it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1734/3257 [00:09<00:10, 152.07it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1753/3257 [00:09<00:09, 161.66it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1773/3257 [00:09<00:08, 172.03it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:10<00:08, 176.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1810/3257 [00:10<00:14, 103.31it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:10<00:12, 115.71it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1848/3257 [00:10<00:10, 133.23it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:10<00:09, 146.35it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1886/3257 [00:10<00:09, 151.96it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1905/3257 [00:10<00:08, 161.20it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1923/3257 [00:11<00:08, 161.12it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1947/3257 [00:11<00:07, 181.52it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1969/3257 [00:11<00:06, 191.52it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1989/3257 [00:11<00:07, 180.52it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:11<00:06, 180.54it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2030/3257 [00:11<00:06, 189.29it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2050/3257 [00:11<00:07, 169.56it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2068/3257 [00:11<00:07, 165.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2086/3257 [00:11<00:07, 167.02it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2103/3257 [00:12<00:06, 165.66it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:12<00:06, 164.08it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2138/3257 [00:12<00:06, 165.37it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2155/3257 [00:12<00:06, 163.86it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2177/3257 [00:12<00:06, 176.06it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2195/3257 [00:12<00:06, 172.74it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2213/3257 [00:12<00:06, 163.32it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2233/3257 [00:12<00:05, 171.61it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2251/3257 [00:12<00:06, 165.26it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2268/3257 [00:13<00:06, 164.59it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2286/3257 [00:13<00:05, 166.87it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2303/3257 [00:13<00:05, 167.59it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2326/3257 [00:13<00:05, 184.96it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2348/3257 [00:13<00:04, 193.30it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2368/3257 [00:13<00:04, 192.36it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2389/3257 [00:13<00:04, 196.18it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2409/3257 [00:13<00:04, 181.84it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2428/3257 [00:13<00:04, 181.12it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2447/3257 [00:14<00:04, 173.15it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2466/3257 [00:14<00:04, 176.46it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2484/3257 [00:14<00:04, 177.22it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:14<00:03, 190.87it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2527/3257 [00:14<00:03, 189.77it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2547/3257 [00:14<00:03, 190.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2567/3257 [00:14<00:03, 179.37it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:14<00:03, 172.00it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2606/3257 [00:14<00:03, 179.34it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2630/3257 [00:14<00:03, 195.62it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2650/3257 [00:15<00:03, 183.70it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2669/3257 [00:15<00:03, 182.99it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:15<00:03, 188.39it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:15<00:03, 165.81it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2730/3257 [00:15<00:03, 175.42it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2751/3257 [00:15<00:02, 181.35it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2770/3257 [00:15<00:02, 175.26it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:15<00:02, 184.82it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2811/3257 [00:16<00:02, 182.66it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2830/3257 [00:16<00:02, 169.77it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2850/3257 [00:16<00:02, 177.34it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2873/3257 [00:16<00:02, 191.61it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2893/3257 [00:16<00:01, 183.82it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2912/3257 [00:16<00:01, 184.93it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2931/3257 [00:16<00:01, 180.37it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:16<00:01, 171.87it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:16<00:01, 174.46it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2987/3257 [00:17<00:01, 166.10it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:17<00:01, 182.88it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3030/3257 [00:17<00:01, 179.79it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3052/3257 [00:17<00:01, 189.15it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3074/3257 [00:17<00:00, 197.66it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3094/3257 [00:17<00:00, 189.46it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3117/3257 [00:17<00:00, 200.84it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3138/3257 [00:17<00:00, 191.34it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3158/3257 [00:17<00:00, 183.14it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3177/3257 [00:18<00:00, 93.89it/s]  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3197/3257 [00:18<00:00, 110.07it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:18<00:00, 117.30it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3234/3257 [00:18<00:00, 134.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:18<00:00, 143.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 173.04it/s]
2023-02-07 20:50:15.245 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:50:15,246][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d357,n5,mc3,s0.726831,t4>', 'datetime': '2023-02-07T20:50:15.246568', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:50:15,246][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:50:15,247][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:50:15,763][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 20:50:15,764][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:50:15,830][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 22723 unique words (71.45% of original 31803, drops 9080)', 'datetime': '2023-02-07T20:50:15.830073', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:50:15,830][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 5081575 word corpus (99.73% of original 5095118, drops 13543)', 'datetime': '2023-02-07T20:50:15.830536', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:50:15,914][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 20:50:15,915][gensim.models.word2vec][INFO] - sample=0.726831 downsamples 0 most-common words
[2023-02-07 20:50:15,915][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5081575 word corpus (100.0%% of prior 5081575)', 'datetime': '2023-02-07T20:50:15.915486', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:50:16,059][gensim.models.word2vec][INFO] - estimated required memory for 22723 words and 357 dimensions: 81560784 bytes
[2023-02-07 20:50:16,059][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:50:16,111][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 22723 vocabulary and 357 features, using sg=1 hs=0 sample=0.726830818435162 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T20:50:16.111149', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:50:17,115][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 43.66% examples, 2268442 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:18,117][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 90.85% examples, 2317958 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:18,296][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5073452 effective words) took 2.2s, 2325716 effective words/s
[2023-02-07 20:50:19,304][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 49.25% examples, 2533373 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:20,282][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5073452 effective words) took 2.0s, 2556385 effective words/s
[2023-02-07 20:50:21,285][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 49.49% examples, 2555517 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:22,284][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5073452 effective words) took 2.0s, 2535872 effective words/s
[2023-02-07 20:50:23,293][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 48.36% examples, 2492265 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:24,296][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 98.65% examples, 2494954 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:50:24,315][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5073452 effective words) took 2.0s, 2499612 effective words/s
[2023-02-07 20:50:25,319][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 49.25% examples, 2542687 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:26,324][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 99.57% examples, 2516600 words/s, in_qsize 3, out_qsize 1
[2023-02-07 20:50:26,329][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5073452 effective words) took 2.0s, 2521626 effective words/s
[2023-02-07 20:50:27,334][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 47.71% examples, 2464997 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:28,339][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 96.47% examples, 2438120 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:28,409][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5073452 effective words) took 2.1s, 2440414 effective words/s
[2023-02-07 20:50:29,411][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 47.37% examples, 2452006 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:30,413][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 96.59% examples, 2450842 words/s, in_qsize 6, out_qsize 1
[2023-02-07 20:50:30,473][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5073452 effective words) took 2.1s, 2460181 effective words/s
[2023-02-07 20:50:31,475][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 47.56% examples, 2457535 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:32,478][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 96.96% examples, 2458664 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:32,534][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5073452 effective words) took 2.1s, 2463649 effective words/s
[2023-02-07 20:50:33,536][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 47.22% examples, 2440440 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:34,537][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 96.47% examples, 2446901 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:34,607][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5073452 effective words) took 2.1s, 2448484 effective words/s
[2023-02-07 20:50:35,609][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 48.11% examples, 2490165 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:36,609][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 98.43% examples, 2497278 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:36,637][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5073452 effective words) took 2.0s, 2500392 effective words/s
[2023-02-07 20:50:37,643][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 48.57% examples, 2510847 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:38,648][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 98.13% examples, 2479431 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:38,681][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5073452 effective words) took 2.0s, 2484276 effective words/s
[2023-02-07 20:50:39,684][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 47.56% examples, 2455147 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:40,690][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 97.36% examples, 2463036 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:40,734][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5073452 effective words) took 2.1s, 2472510 effective words/s
[2023-02-07 20:50:41,741][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 35.06% examples, 1799492 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:50:42,749][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 70.86% examples, 1827904 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:50:43,478][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5073452 effective words) took 2.7s, 1850817 effective words/s
[2023-02-07 20:50:44,485][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 46.79% examples, 2407849 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:45,493][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 91.65% examples, 2327720 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:45,685][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5073452 effective words) took 2.2s, 2300133 effective words/s
[2023-02-07 20:50:46,688][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 46.39% examples, 2388336 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:47,688][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 93.28% examples, 2377083 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:50:47,818][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5073452 effective words) took 2.1s, 2380654 effective words/s
[2023-02-07 20:50:47,818][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76101780 effective words) took 31.7s, 2400140 effective words/s', 'datetime': '2023-02-07T20:50:47.818900', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:50:47.819 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:50:51,242][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204947-lm66gyu3/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:50:51.241927', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:50:51,243][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:50:51,351][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204947-lm66gyu3/files/../tmp/embedding_model.pt
2023-02-07 20:50:51.352 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:50:53.593 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:50:54.388 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:51:03.502 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0767947517226417, 'test_mae': 0.7678324065051196, 'test_r2': -2.7035112928049982}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: | 0.014 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: / 0.014 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: - 0.014 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: \ 0.014 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: | 0.014 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: / 0.014 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: - 0.014 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: \ 0.014 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: | 0.014 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: / 0.014 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: - 0.014 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: \ 0.014 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.94
wandb: percentage 0.28551
wandb:   test_mae 0.76783
wandb:   test_mse 1.07679
wandb:    test_r2 -2.70351
wandb: 
wandb: üöÄ View run rose-sweep-92 at: https://wandb.ai/xiaoqiz/mof2vec/runs/lm66gyu3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_204947-lm66gyu3/logs
wandb: Agent Starting Run: hapyov2z with config:
wandb: 	data.data.wl_step: 2
wandb: 	data.nn.batch_size: 809
wandb: 	model.gensim.alpha: 0.0013690680661736531
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.32256215731073623
wandb: 	model.gensim.vector_size: 139
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.0009100252189429748
wandb: 	model.sklearn.max_depth: 40
wandb: 	model.sklearn.min_child_weight: 0.03476448040679982
wandb: 	model.sklearn.n_estimators: 357
wandb: 	model.sklearn.num_leaves: 248
wandb: 	model.sklearn.reg_alpha: 0.009558728508503386
wandb: 	model.sklearn.reg_lambda: 0.011192307308568737
wandb: 	model.sklearn.subsample: 0.26589161865750477
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205123-hapyov2z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-93
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/hapyov2z
2023-02-07 20:51:34.993 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 2 for sweep.
2023-02-07 20:51:34.994 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 809 for sweep.
2023-02-07 20:51:34.994 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0013690680661736531 for sweep.
2023-02-07 20:51:34.995 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:51:34.995 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 20:51:34.995 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.32256215731073623 for sweep.
2023-02-07 20:51:34.995 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 139 for sweep.
2023-02-07 20:51:34.996 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 20:51:34.996 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0009100252189429748 for sweep.
2023-02-07 20:51:34.996 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 40 for sweep.
2023-02-07 20:51:34.996 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03476448040679982 for sweep.
2023-02-07 20:51:34.997 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 357 for sweep.
2023-02-07 20:51:34.998 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 248 for sweep.
2023-02-07 20:51:34.998 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.009558728508503386 for sweep.
2023-02-07 20:51:34.998 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.011192307308568737 for sweep.
2023-02-07 20:51:34.999 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.26589161865750477 for sweep.
2023-02-07 20:51:34.999 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:51:35.005 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 2}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205123-hapyov2z/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 809, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 139, 'window': 8, 'min_count': 5, 'dm': 0, 'sample': 0.32256215731073623, 'workers': 4, 'alpha': 0.0013690680661736531, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 357, 'max_depth': 40, 'num_leaves': 248, 'reg_alpha': 0.009558728508503386, 'reg_lambda': 0.011192307308568737, 'subsample': 0.26589161865750477, 'min_child_weight': 0.03476448040679982, 'n_jobs': 4, 'learning_rate': 0.0009100252189429748}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 25/3257 [00:00<00:13, 241.45it/s]  2%|‚ñè         | 51/3257 [00:00<00:12, 249.37it/s]  2%|‚ñè         | 78/3257 [00:00<00:12, 257.58it/s]  3%|‚ñé         | 105/3257 [00:00<00:12, 255.18it/s]  4%|‚ñç         | 132/3257 [00:00<00:12, 257.36it/s]  5%|‚ñç         | 160/3257 [00:00<00:11, 262.76it/s]  6%|‚ñå         | 187/3257 [00:00<00:11, 262.64it/s]  7%|‚ñã         | 216/3257 [00:00<00:11, 271.06it/s]  8%|‚ñä         | 245/3257 [00:00<00:10, 274.52it/s]  8%|‚ñä         | 274/3257 [00:01<00:10, 278.11it/s]  9%|‚ñâ         | 304/3257 [00:01<00:10, 281.18it/s] 10%|‚ñà         | 334/3257 [00:01<00:10, 284.53it/s] 11%|‚ñà         | 363/3257 [00:01<00:10, 278.42it/s] 12%|‚ñà‚ñè        | 391/3257 [00:01<00:10, 269.56it/s] 13%|‚ñà‚ñé        | 420/3257 [00:01<00:10, 273.39it/s] 14%|‚ñà‚ñç        | 448/3257 [00:01<00:11, 250.56it/s] 15%|‚ñà‚ñç        | 476/3257 [00:01<00:10, 258.26it/s] 16%|‚ñà‚ñå        | 506/3257 [00:01<00:10, 269.13it/s] 16%|‚ñà‚ñã        | 534/3257 [00:02<00:10, 263.51it/s] 17%|‚ñà‚ñã        | 561/3257 [00:02<00:10, 256.80it/s] 18%|‚ñà‚ñä        | 587/3257 [00:02<00:10, 254.94it/s] 19%|‚ñà‚ñâ        | 617/3257 [00:02<00:09, 267.12it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:02<00:10, 259.56it/s] 21%|‚ñà‚ñà        | 671/3257 [00:02<00:09, 259.87it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:02<00:09, 258.95it/s] 22%|‚ñà‚ñà‚ñè       | 725/3257 [00:02<00:09, 260.84it/s] 23%|‚ñà‚ñà‚ñé       | 752/3257 [00:02<00:09, 262.87it/s] 24%|‚ñà‚ñà‚ñç       | 780/3257 [00:02<00:09, 264.46it/s] 25%|‚ñà‚ñà‚ñç       | 809/3257 [00:03<00:09, 270.85it/s] 26%|‚ñà‚ñà‚ñå       | 837/3257 [00:03<00:09, 265.00it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:03<00:09, 262.96it/s] 27%|‚ñà‚ñà‚ñã       | 891/3257 [00:03<00:08, 263.04it/s] 28%|‚ñà‚ñà‚ñä       | 921/3257 [00:03<00:08, 272.95it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:03<00:08, 272.23it/s] 30%|‚ñà‚ñà‚ñà       | 979/3257 [00:03<00:08, 273.71it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:03<00:08, 269.08it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1034/3257 [00:03<00:08, 266.05it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1061/3257 [00:04<00:08, 261.80it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1089/3257 [00:04<00:08, 265.67it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:04<00:08, 267.41it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:04<00:07, 266.28it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:04<00:07, 271.31it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1201/3257 [00:04<00:12, 163.63it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1231/3257 [00:04<00:10, 190.89it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:04<00:09, 204.66it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1282/3257 [00:05<00:09, 213.32it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:05<00:08, 224.75it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1338/3257 [00:05<00:07, 243.39it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1365/3257 [00:05<00:07, 242.12it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1391/3257 [00:05<00:07, 243.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:05<00:06, 263.75it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1454/3257 [00:05<00:06, 275.96it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1483/3257 [00:05<00:06, 277.84it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:05<00:06, 282.43it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1542/3257 [00:06<00:06, 264.89it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1569/3257 [00:06<00:06, 259.53it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:06<00:06, 261.64it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1623/3257 [00:06<00:06, 263.26it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:06<00:06, 258.77it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:06<00:06, 250.93it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1702/3257 [00:06<00:06, 250.70it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:06<00:06, 240.51it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1753/3257 [00:06<00:06, 236.93it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1781/3257 [00:06<00:05, 248.24it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1806/3257 [00:07<00:05, 247.83it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1831/3257 [00:07<00:05, 247.61it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1858/3257 [00:07<00:05, 250.50it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1886/3257 [00:07<00:05, 258.43it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1915/3257 [00:07<00:05, 267.09it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1944/3257 [00:07<00:04, 273.45it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:07<00:04, 279.71it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2003/3257 [00:07<00:04, 270.85it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:07<00:04, 273.59it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2061/3257 [00:08<00:04, 254.97it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2088/3257 [00:08<00:04, 258.48it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2116/3257 [00:08<00:04, 263.80it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:08<00:04, 240.29it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2172/3257 [00:08<00:04, 252.75it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2198/3257 [00:08<00:04, 251.47it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2224/3257 [00:08<00:04, 248.61it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2250/3257 [00:08<00:04, 249.35it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:08<00:04, 244.17it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2306/3257 [00:08<00:03, 257.58it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:09<00:03, 270.75it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2368/3257 [00:09<00:03, 280.14it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:09<00:02, 288.09it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2428/3257 [00:09<00:02, 280.47it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2457/3257 [00:09<00:02, 268.90it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2485/3257 [00:09<00:02, 267.16it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2516/3257 [00:09<00:02, 277.85it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2544/3257 [00:10<00:03, 187.97it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2568/3257 [00:10<00:03, 196.74it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2595/3257 [00:10<00:03, 212.84it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2627/3257 [00:10<00:02, 239.15it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:10<00:02, 244.01it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2682/3257 [00:10<00:02, 253.57it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:10<00:02, 244.52it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2738/3257 [00:10<00:02, 256.70it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2768/3257 [00:10<00:01, 264.02it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2797/3257 [00:10<00:01, 271.23it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2825/3257 [00:11<00:01, 264.12it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:11<00:01, 266.01it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:11<00:01, 282.43it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2915/3257 [00:11<00:01, 276.30it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2943/3257 [00:11<00:01, 268.87it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2971/3257 [00:11<00:01, 270.95it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2999/3257 [00:11<00:00, 268.71it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:11<00:00, 268.42it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3057/3257 [00:11<00:00, 279.38it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3085/3257 [00:11<00:00, 279.48it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3115/3257 [00:12<00:00, 285.03it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3144/3257 [00:12<00:00, 273.66it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3172/3257 [00:12<00:00, 267.84it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3199/3257 [00:12<00:00, 267.70it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3226/3257 [00:12<00:00, 268.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:12<00:00, 277.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:12<00:00, 257.86it/s]
2023-02-07 20:51:47.917 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:51:47,919][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d139,n5,mc5,s0.322562,t4>', 'datetime': '2023-02-07T20:51:47.919134', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:51:47,919][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:51:47,919][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:51:48,124][gensim.models.doc2vec][INFO] - collected 2819 word types and 3257 unique tags from a corpus of 3257 examples and 2183622 words
[2023-02-07 20:51:48,125][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:51:48,130][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1660 unique words (58.89% of original 2819, drops 1159)', 'datetime': '2023-02-07T20:51:48.130196', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:51:48,131][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2180669 word corpus (99.86% of original 2183622, drops 2953)', 'datetime': '2023-02-07T20:51:48.131498', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:51:48,137][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 2819 items
[2023-02-07 20:51:48,138][gensim.models.word2vec][INFO] - sample=0.322562 downsamples 0 most-common words
[2023-02-07 20:51:48,138][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2180669 word corpus (100.0%% of prior 2180669)', 'datetime': '2023-02-07T20:51:48.138246', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:51:48,148][gensim.models.word2vec][INFO] - estimated required memory for 1660 words and 139 dimensions: 5138212 bytes
[2023-02-07 20:51:48,148][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:51:48,152][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 1660 vocabulary and 139 features, using sg=1 hs=0 sample=0.32256215731073623 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T20:51:48.151982', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:51:48,994][gensim.models.word2vec][INFO] - EPOCH 0: training on 2183622 raw words (2183926 effective words) took 0.8s, 2600494 effective words/s
[2023-02-07 20:51:49,786][gensim.models.word2vec][INFO] - EPOCH 1: training on 2183622 raw words (2183926 effective words) took 0.8s, 2760929 effective words/s
[2023-02-07 20:51:50,589][gensim.models.word2vec][INFO] - EPOCH 2: training on 2183622 raw words (2183926 effective words) took 0.8s, 2722865 effective words/s
[2023-02-07 20:51:51,433][gensim.models.word2vec][INFO] - EPOCH 3: training on 2183622 raw words (2183926 effective words) took 0.8s, 2594120 effective words/s
[2023-02-07 20:51:52,295][gensim.models.word2vec][INFO] - EPOCH 4: training on 2183622 raw words (2183926 effective words) took 0.9s, 2537335 effective words/s
[2023-02-07 20:51:53,298][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 66.93% examples, 1492166 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:51:53,748][gensim.models.word2vec][INFO] - EPOCH 5: training on 2183622 raw words (2183926 effective words) took 1.5s, 1505719 effective words/s
[2023-02-07 20:51:54,629][gensim.models.word2vec][INFO] - EPOCH 6: training on 2183622 raw words (2183926 effective words) took 0.9s, 2481113 effective words/s
[2023-02-07 20:51:55,486][gensim.models.word2vec][INFO] - EPOCH 7: training on 2183622 raw words (2183926 effective words) took 0.9s, 2554754 effective words/s
[2023-02-07 20:51:56,274][gensim.models.word2vec][INFO] - EPOCH 8: training on 2183622 raw words (2183926 effective words) took 0.8s, 2772538 effective words/s
[2023-02-07 20:51:57,077][gensim.models.word2vec][INFO] - EPOCH 9: training on 2183622 raw words (2183926 effective words) took 0.8s, 2725465 effective words/s
[2023-02-07 20:51:58,087][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 54.93% examples, 1217859 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:51:58,858][gensim.models.word2vec][INFO] - EPOCH 10: training on 2183622 raw words (2183926 effective words) took 1.8s, 1227856 effective words/s
[2023-02-07 20:51:59,735][gensim.models.word2vec][INFO] - EPOCH 11: training on 2183622 raw words (2183926 effective words) took 0.9s, 2496762 effective words/s
[2023-02-07 20:52:00,617][gensim.models.word2vec][INFO] - EPOCH 12: training on 2183622 raw words (2183926 effective words) took 0.9s, 2480101 effective words/s
[2023-02-07 20:52:01,496][gensim.models.word2vec][INFO] - EPOCH 13: training on 2183622 raw words (2183926 effective words) took 0.9s, 2488275 effective words/s
[2023-02-07 20:52:02,383][gensim.models.word2vec][INFO] - EPOCH 14: training on 2183622 raw words (2183926 effective words) took 0.9s, 2468287 effective words/s
[2023-02-07 20:52:02,383][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 32754330 raw words (32758890 effective words) took 14.2s, 2301938 effective words/s', 'datetime': '2023-02-07T20:52:02.383537', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:52:02.383 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:52:03,805][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205123-hapyov2z/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:52:03.805124', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:52:03,805][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:52:03,814][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205123-hapyov2z/files/../tmp/embedding_model.pt
2023-02-07 20:52:03.814 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:52:05.169 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:52:05.694 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:52:06.745 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0492068553648164, 'test_mae': 0.7652816184185034, 'test_r2': -2.5327330611217973}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.29
wandb: percentage 0.41114
wandb:   test_mae 0.76528
wandb:   test_mse 1.04921
wandb:    test_r2 -2.53273
wandb: 
wandb: üöÄ View run soft-sweep-93 at: https://wandb.ai/xiaoqiz/mof2vec/runs/hapyov2z
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_205123-hapyov2z/logs
wandb: Agent Starting Run: 2tupv19m with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 572
wandb: 	model.gensim.alpha: 0.0175069344084211
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.2002955565797315
wandb: 	model.gensim.vector_size: 248
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.008648858645826856
wandb: 	model.sklearn.max_depth: 7
wandb: 	model.sklearn.min_child_weight: 0.04464185743324087
wandb: 	model.sklearn.n_estimators: 3207
wandb: 	model.sklearn.num_leaves: 443
wandb: 	model.sklearn.reg_alpha: 0.0025515236276169103
wandb: 	model.sklearn.reg_lambda: 0.017630277280775212
wandb: 	model.sklearn.subsample: 0.813270021035944
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205217-2tupv19m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-94
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/2tupv19m
2023-02-07 20:52:25.288 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 20:52:25.289 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 572 for sweep.
2023-02-07 20:52:25.289 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0175069344084211 for sweep.
2023-02-07 20:52:25.290 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:52:25.290 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 20:52:25.290 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2002955565797315 for sweep.
2023-02-07 20:52:25.291 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 248 for sweep.
2023-02-07 20:52:25.291 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 20:52:25.291 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.008648858645826856 for sweep.
2023-02-07 20:52:25.291 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 7 for sweep.
2023-02-07 20:52:25.292 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.04464185743324087 for sweep.
2023-02-07 20:52:25.292 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3207 for sweep.
2023-02-07 20:52:25.292 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 443 for sweep.
2023-02-07 20:52:25.292 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0025515236276169103 for sweep.
2023-02-07 20:52:25.292 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.017630277280775212 for sweep.
2023-02-07 20:52:25.293 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.813270021035944 for sweep.
2023-02-07 20:52:25.293 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:52:25.300 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205217-2tupv19m/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 572, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 248, 'window': 8, 'min_count': 5, 'dm': 0, 'sample': 0.2002955565797315, 'workers': 4, 'alpha': 0.0175069344084211, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3207, 'max_depth': 7, 'num_leaves': 443, 'reg_alpha': 0.0025515236276169103, 'reg_lambda': 0.017630277280775212, 'subsample': 0.813270021035944, 'min_child_weight': 0.04464185743324087, 'n_jobs': 4, 'learning_rate': 0.008648858645826856}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:20, 159.68it/s]  1%|          | 34/3257 [00:00<00:19, 166.53it/s]  2%|‚ñè         | 53/3257 [00:00<00:19, 167.90it/s]  2%|‚ñè         | 73/3257 [00:00<00:17, 178.80it/s]  3%|‚ñé         | 92/3257 [00:00<00:17, 180.05it/s]  3%|‚ñé         | 111/3257 [00:00<00:18, 169.61it/s]  4%|‚ñç         | 131/3257 [00:00<00:17, 176.26it/s]  5%|‚ñç         | 152/3257 [00:00<00:16, 185.48it/s]  5%|‚ñå         | 171/3257 [00:00<00:17, 178.72it/s]  6%|‚ñå         | 190/3257 [00:01<00:17, 179.85it/s]  6%|‚ñã         | 209/3257 [00:01<00:16, 181.77it/s]  7%|‚ñã         | 231/3257 [00:01<00:15, 190.90it/s]  8%|‚ñä         | 251/3257 [00:01<00:15, 191.99it/s]  8%|‚ñä         | 271/3257 [00:01<00:16, 184.67it/s]  9%|‚ñâ         | 295/3257 [00:01<00:14, 198.72it/s] 10%|‚ñâ         | 315/3257 [00:01<00:15, 184.92it/s] 10%|‚ñà         | 336/3257 [00:01<00:15, 187.82it/s] 11%|‚ñà         | 357/3257 [00:01<00:15, 193.06it/s] 12%|‚ñà‚ñè        | 377/3257 [00:02<00:16, 175.81it/s] 12%|‚ñà‚ñè        | 395/3257 [00:02<00:16, 173.53it/s] 13%|‚ñà‚ñé        | 414/3257 [00:02<00:16, 176.76it/s] 13%|‚ñà‚ñé        | 432/3257 [00:02<00:18, 156.12it/s] 14%|‚ñà‚ñç        | 449/3257 [00:02<00:18, 155.37it/s] 14%|‚ñà‚ñç        | 468/3257 [00:02<00:16, 164.22it/s] 15%|‚ñà‚ñç        | 485/3257 [00:02<00:16, 163.51it/s] 16%|‚ñà‚ñå        | 505/3257 [00:02<00:15, 173.18it/s] 16%|‚ñà‚ñå        | 523/3257 [00:02<00:15, 173.72it/s] 17%|‚ñà‚ñã        | 542/3257 [00:03<00:15, 176.14it/s] 17%|‚ñà‚ñã        | 560/3257 [00:03<00:25, 104.88it/s] 18%|‚ñà‚ñä        | 575/3257 [00:03<00:24, 110.43it/s] 18%|‚ñà‚ñä        | 596/3257 [00:03<00:20, 130.94it/s] 19%|‚ñà‚ñâ        | 615/3257 [00:03<00:18, 144.00it/s] 19%|‚ñà‚ñâ        | 634/3257 [00:03<00:16, 154.33it/s] 20%|‚ñà‚ñà        | 652/3257 [00:03<00:17, 150.65it/s] 21%|‚ñà‚ñà        | 669/3257 [00:04<00:16, 152.65it/s] 21%|‚ñà‚ñà        | 686/3257 [00:04<00:16, 152.64it/s] 22%|‚ñà‚ñà‚ñè       | 705/3257 [00:04<00:15, 161.22it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:04<00:15, 161.49it/s] 23%|‚ñà‚ñà‚ñé       | 739/3257 [00:04<00:16, 157.00it/s] 23%|‚ñà‚ñà‚ñé       | 759/3257 [00:04<00:14, 168.60it/s] 24%|‚ñà‚ñà‚ñç       | 777/3257 [00:04<00:14, 167.44it/s] 24%|‚ñà‚ñà‚ñç       | 797/3257 [00:04<00:14, 174.87it/s] 25%|‚ñà‚ñà‚ñå       | 815/3257 [00:04<00:14, 173.95it/s] 26%|‚ñà‚ñà‚ñå       | 833/3257 [00:05<00:14, 168.19it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:05<00:15, 160.04it/s] 27%|‚ñà‚ñà‚ñã       | 869/3257 [00:05<00:14, 166.79it/s] 27%|‚ñà‚ñà‚ñã       | 886/3257 [00:05<00:14, 163.58it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:05<00:13, 173.68it/s] 28%|‚ñà‚ñà‚ñä       | 927/3257 [00:05<00:13, 179.16it/s] 29%|‚ñà‚ñà‚ñâ       | 945/3257 [00:05<00:13, 175.70it/s] 30%|‚ñà‚ñà‚ñâ       | 965/3257 [00:05<00:12, 180.98it/s] 30%|‚ñà‚ñà‚ñà       | 984/3257 [00:05<00:13, 173.94it/s] 31%|‚ñà‚ñà‚ñà       | 1002/3257 [00:06<00:13, 170.62it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1020/3257 [00:06<00:13, 171.82it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1038/3257 [00:06<00:13, 160.95it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1055/3257 [00:06<00:13, 161.39it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1074/3257 [00:06<00:12, 168.23it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:06<00:13, 158.38it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1111/3257 [00:06<00:12, 168.97it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1129/3257 [00:06<00:13, 161.32it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1146/3257 [00:06<00:13, 158.59it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1167/3257 [00:07<00:12, 171.03it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:07<00:13, 157.41it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1202/3257 [00:07<00:13, 148.22it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:07<00:13, 151.14it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1240/3257 [00:07<00:11, 169.56it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:07<00:12, 164.07it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:07<00:12, 162.95it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:07<00:12, 155.39it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:07<00:12, 158.07it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:08<00:11, 166.33it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:08<00:11, 169.45it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:08<00:11, 164.45it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1381/3257 [00:08<00:11, 159.04it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1400/3257 [00:08<00:11, 167.35it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:08<00:10, 180.44it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1441/3257 [00:08<00:10, 174.05it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:08<00:09, 184.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1482/3257 [00:08<00:09, 186.23it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1503/3257 [00:08<00:09, 190.72it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1523/3257 [00:09<00:09, 175.35it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1541/3257 [00:09<00:10, 169.30it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1559/3257 [00:09<00:10, 165.58it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1576/3257 [00:09<00:10, 162.95it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:09<00:09, 169.38it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1616/3257 [00:09<00:09, 177.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:09<00:09, 166.47it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1651/3257 [00:09<00:09, 165.01it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:10<00:09, 159.25it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1685/3257 [00:10<00:10, 156.64it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1704/3257 [00:10<00:09, 163.96it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1721/3257 [00:10<00:09, 165.45it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1738/3257 [00:10<00:10, 151.13it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1758/3257 [00:10<00:09, 163.81it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1776/3257 [00:10<00:08, 165.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:10<00:08, 172.10it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:10<00:08, 165.44it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1831/3257 [00:11<00:13, 102.63it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1850/3257 [00:11<00:11, 119.45it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:11<00:10, 134.34it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1887/3257 [00:11<00:09, 144.48it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1906/3257 [00:11<00:08, 154.26it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1924/3257 [00:11<00:08, 154.69it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1948/3257 [00:11<00:07, 175.38it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1970/3257 [00:11<00:06, 186.47it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1990/3257 [00:12<00:07, 176.31it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2009/3257 [00:12<00:07, 175.06it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2031/3257 [00:12<00:06, 186.16it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2051/3257 [00:12<00:07, 168.32it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2069/3257 [00:12<00:07, 163.60it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2086/3257 [00:12<00:07, 164.45it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2103/3257 [00:12<00:07, 164.24it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:12<00:07, 160.91it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:12<00:06, 160.63it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:13<00:06, 158.11it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2174/3257 [00:13<00:06, 168.66it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2191/3257 [00:13<00:06, 166.10it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2208/3257 [00:13<00:06, 167.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2225/3257 [00:13<00:06, 164.42it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2242/3257 [00:13<00:06, 161.43it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:13<00:06, 162.29it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2277/3257 [00:13<00:06, 156.19it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:13<00:05, 167.21it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2321/3257 [00:14<00:05, 179.31it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2342/3257 [00:14<00:04, 187.10it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2363/3257 [00:14<00:04, 193.44it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2383/3257 [00:14<00:04, 190.60it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:14<00:04, 194.45it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2424/3257 [00:14<00:04, 183.16it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:14<00:04, 168.13it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2463/3257 [00:14<00:04, 176.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2482/3257 [00:14<00:04, 179.76it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2504/3257 [00:15<00:03, 189.87it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:15<00:03, 190.03it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2544/3257 [00:15<00:03, 187.58it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2563/3257 [00:15<00:03, 178.29it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2581/3257 [00:15<00:03, 170.24it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2599/3257 [00:15<00:03, 172.51it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2625/3257 [00:15<00:03, 195.83it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2645/3257 [00:15<00:03, 187.31it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2664/3257 [00:15<00:03, 179.36it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2684/3257 [00:16<00:03, 183.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2703/3257 [00:16<00:03, 162.71it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2720/3257 [00:16<00:03, 160.35it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2743/3257 [00:16<00:02, 177.71it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2762/3257 [00:16<00:02, 174.31it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2780/3257 [00:16<00:02, 174.15it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2802/3257 [00:16<00:02, 186.24it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2821/3257 [00:16<00:02, 178.47it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2840/3257 [00:16<00:02, 167.81it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2863/3257 [00:17<00:02, 183.70it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:17<00:01, 190.28it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:17<00:01, 179.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:17<00:01, 183.31it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:17<00:01, 174.30it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:17<00:01, 177.24it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:17<00:01, 165.47it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3005/3257 [00:17<00:01, 176.74it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3023/3257 [00:18<00:01, 170.36it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3046/3257 [00:18<00:01, 184.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3067/3257 [00:18<00:00, 190.72it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3087/3257 [00:18<00:00, 185.20it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3109/3257 [00:18<00:00, 192.74it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3129/3257 [00:18<00:00, 190.86it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3149/3257 [00:18<00:00, 176.80it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3167/3257 [00:18<00:00, 174.85it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:18<00:00, 167.37it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3204/3257 [00:19<00:00, 173.27it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3222/3257 [00:19<00:00, 163.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3242/3257 [00:19<00:00, 172.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 168.54it/s]
2023-02-07 20:52:45.419 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:52:45,421][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d248,n5,mc5,s0.200296,t4>', 'datetime': '2023-02-07T20:52:45.421053', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:52:45,421][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:52:45,421][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:52:46,204][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 20:52:46,204][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:52:46,252][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 16108 unique words (50.65% of original 31803, drops 15695)', 'datetime': '2023-02-07T20:52:46.252111', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:52:46,252][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5056108 word corpus (99.23% of original 5095118, drops 39010)', 'datetime': '2023-02-07T20:52:46.252573', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:52:46,308][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 20:52:46,309][gensim.models.word2vec][INFO] - sample=0.200296 downsamples 0 most-common words
[2023-02-07 20:52:46,309][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5056108 word corpus (100.0%% of prior 5056108)', 'datetime': '2023-02-07T20:52:46.309945', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:52:46,408][gensim.models.word2vec][INFO] - estimated required memory for 16108 words and 248 dimensions: 43894616 bytes
[2023-02-07 20:52:46,408][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:52:46,436][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 16108 vocabulary and 248 features, using sg=1 hs=0 sample=0.2002955565797315 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T20:52:46.436925', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:52:47,446][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 39.70% examples, 2051772 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:52:48,448][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 82.90% examples, 2107771 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:52:48,820][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5048130 effective words) took 2.4s, 2120749 effective words/s
[2023-02-07 20:52:49,827][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 48.36% examples, 2486094 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:52:50,747][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5048130 effective words) took 1.9s, 2622724 effective words/s
[2023-02-07 20:52:51,749][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 54.28% examples, 2800600 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:52:52,515][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5048130 effective words) took 1.8s, 2857571 effective words/s
[2023-02-07 20:52:53,523][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 57.29% examples, 2939087 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:52:54,333][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5048130 effective words) took 1.8s, 2779522 effective words/s
[2023-02-07 20:52:55,341][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 47.71% examples, 2446163 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:52:56,344][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 98.65% examples, 2482614 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:52:56,361][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5048130 effective words) took 2.0s, 2491034 effective words/s
[2023-02-07 20:52:57,363][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 51.70% examples, 2667746 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:52:58,273][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5048130 effective words) took 1.9s, 2640958 effective words/s
[2023-02-07 20:52:59,276][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 56.09% examples, 2901691 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:52:59,994][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5048130 effective words) took 1.7s, 2937450 effective words/s
[2023-02-07 20:53:00,997][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 58.80% examples, 3020525 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:53:01,652][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5048130 effective words) took 1.7s, 3045898 effective words/s
[2023-02-07 20:53:02,654][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 51.37% examples, 2650413 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:53:03,599][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5048130 effective words) took 1.9s, 2594639 effective words/s
[2023-02-07 20:53:04,605][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 47.71% examples, 2451410 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:53:05,607][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 97.36% examples, 2452718 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:53:05,651][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5048130 effective words) took 2.1s, 2462408 effective words/s
[2023-02-07 20:53:06,652][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 47.37% examples, 2439771 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:53:07,653][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 96.75% examples, 2445347 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:53:07,711][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5048130 effective words) took 2.1s, 2452220 effective words/s
[2023-02-07 20:53:08,721][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 49.25% examples, 2513890 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:53:09,713][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5048130 effective words) took 2.0s, 2522518 effective words/s
[2023-02-07 20:53:10,717][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 48.08% examples, 2479635 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:53:11,722][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 97.36% examples, 2452629 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:53:11,768][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5048130 effective words) took 2.1s, 2460041 effective words/s
[2023-02-07 20:53:12,772][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 45.29% examples, 2328315 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:53:13,775][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 84.03% examples, 2136044 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:53:14,164][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5048130 effective words) took 2.4s, 2108114 effective words/s
[2023-02-07 20:53:15,173][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 47.22% examples, 2413438 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:53:16,176][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 85.82% examples, 2171703 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:53:16,524][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5048130 effective words) took 2.4s, 2140478 effective words/s
[2023-02-07 20:53:16,525][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75721950 effective words) took 30.1s, 2516715 effective words/s', 'datetime': '2023-02-07T20:53:16.525037', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:53:16.525 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:53:19,710][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205217-2tupv19m/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:53:19.710485', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:53:19,711][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:53:19,776][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205217-2tupv19m/files/../tmp/embedding_model.pt
2023-02-07 20:53:19.776 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:53:21.580 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:53:22.273 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:53:26.671 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.8885019607231742, 'test_mae': 0.7140653382506839, 'test_r2': -1.7708624187175377}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.9
wandb: percentage 0.49351
wandb:   test_mae 0.71407
wandb:   test_mse 0.8885
wandb:    test_r2 -1.77086
wandb: 
wandb: üöÄ View run earnest-sweep-94 at: https://wandb.ai/xiaoqiz/mof2vec/runs/2tupv19m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_205217-2tupv19m/logs
wandb: Agent Starting Run: p46s27j4 with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 647
wandb: 	model.gensim.alpha: 0.001973596452909219
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.26556393801295464
wandb: 	model.gensim.vector_size: 446
wandb: 	model.gensim.window: 9
wandb: 	model.sklearn.learning_rate: 0.010429957676488442
wandb: 	model.sklearn.max_depth: 9
wandb: 	model.sklearn.min_child_weight: 0.05761847629444189
wandb: 	model.sklearn.n_estimators: 3466
wandb: 	model.sklearn.num_leaves: 498
wandb: 	model.sklearn.reg_alpha: 0.002518285958692901
wandb: 	model.sklearn.reg_lambda: 0.0974238439900504
wandb: 	model.sklearn.subsample: 0.6799843642602512
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205336-p46s27j4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-95
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/p46s27j4
2023-02-07 20:53:44.799 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 20:53:44.800 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 647 for sweep.
2023-02-07 20:53:44.800 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.001973596452909219 for sweep.
2023-02-07 20:53:44.801 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:53:44.801 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 20:53:44.801 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.26556393801295464 for sweep.
2023-02-07 20:53:44.801 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 446 for sweep.
2023-02-07 20:53:44.802 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 9 for sweep.
2023-02-07 20:53:44.802 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.010429957676488442 for sweep.
2023-02-07 20:53:44.802 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 9 for sweep.
2023-02-07 20:53:44.803 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05761847629444189 for sweep.
2023-02-07 20:53:44.803 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3466 for sweep.
2023-02-07 20:53:44.803 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 498 for sweep.
2023-02-07 20:53:44.803 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.002518285958692901 for sweep.
2023-02-07 20:53:44.804 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0974238439900504 for sweep.
2023-02-07 20:53:44.804 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6799843642602512 for sweep.
2023-02-07 20:53:44.804 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:53:44.810 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205336-p46s27j4/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 647, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 446, 'window': 9, 'min_count': 8, 'dm': 0, 'sample': 0.26556393801295464, 'workers': 4, 'alpha': 0.001973596452909219, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3466, 'max_depth': 9, 'num_leaves': 498, 'reg_alpha': 0.002518285958692901, 'reg_lambda': 0.0974238439900504, 'subsample': 0.6799843642602512, 'min_child_weight': 0.05761847629444189, 'n_jobs': 4, 'learning_rate': 0.010429957676488442}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:20, 157.79it/s]  1%|          | 35/3257 [00:00<00:19, 167.35it/s]  2%|‚ñè         | 53/3257 [00:00<00:19, 165.45it/s]  2%|‚ñè         | 71/3257 [00:00<00:18, 169.34it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 172.74it/s]  3%|‚ñé         | 108/3257 [00:00<00:18, 167.21it/s]  4%|‚ñç         | 126/3257 [00:00<00:18, 169.25it/s]  5%|‚ñç         | 147/3257 [00:00<00:17, 180.98it/s]  5%|‚ñå         | 166/3257 [00:00<00:17, 174.12it/s]  6%|‚ñå         | 184/3257 [00:01<00:17, 174.12it/s]  6%|‚ñå         | 202/3257 [00:01<00:17, 175.60it/s]  7%|‚ñã         | 224/3257 [00:01<00:16, 186.29it/s]  7%|‚ñã         | 244/3257 [00:01<00:15, 188.59it/s]  8%|‚ñä         | 263/3257 [00:01<00:16, 183.76it/s]  9%|‚ñâ         | 285/3257 [00:01<00:15, 192.60it/s]  9%|‚ñâ         | 305/3257 [00:01<00:15, 185.39it/s] 10%|‚ñà         | 327/3257 [00:01<00:15, 193.34it/s] 11%|‚ñà         | 347/3257 [00:01<00:15, 183.51it/s] 11%|‚ñà‚ñè        | 367/3257 [00:02<00:15, 184.55it/s] 12%|‚ñà‚ñè        | 386/3257 [00:02<00:16, 177.70it/s] 12%|‚ñà‚ñè        | 407/3257 [00:02<00:15, 183.98it/s] 13%|‚ñà‚ñé        | 426/3257 [00:02<00:17, 164.90it/s] 14%|‚ñà‚ñé        | 445/3257 [00:02<00:16, 170.84it/s] 14%|‚ñà‚ñç        | 466/3257 [00:02<00:15, 181.11it/s] 15%|‚ñà‚ñç        | 485/3257 [00:02<00:15, 182.98it/s] 16%|‚ñà‚ñå        | 509/3257 [00:02<00:13, 198.55it/s] 16%|‚ñà‚ñã        | 530/3257 [00:02<00:14, 193.04it/s] 17%|‚ñà‚ñã        | 550/3257 [00:03<00:14, 193.24it/s] 18%|‚ñà‚ñä        | 570/3257 [00:03<00:14, 185.84it/s] 18%|‚ñà‚ñä        | 589/3257 [00:03<00:14, 178.66it/s] 19%|‚ñà‚ñâ        | 611/3257 [00:03<00:13, 189.23it/s] 19%|‚ñà‚ñâ        | 632/3257 [00:03<00:13, 194.14it/s] 20%|‚ñà‚ñà        | 652/3257 [00:03<00:14, 184.06it/s] 21%|‚ñà‚ñà        | 671/3257 [00:03<00:14, 184.04it/s] 21%|‚ñà‚ñà        | 690/3257 [00:03<00:14, 181.30it/s] 22%|‚ñà‚ñà‚ñè       | 711/3257 [00:03<00:13, 188.25it/s] 22%|‚ñà‚ñà‚ñè       | 730/3257 [00:04<00:14, 177.68it/s] 23%|‚ñà‚ñà‚ñé       | 749/3257 [00:04<00:14, 176.63it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:04<00:13, 184.50it/s] 24%|‚ñà‚ñà‚ñç       | 789/3257 [00:04<00:13, 181.03it/s] 25%|‚ñà‚ñà‚ñç       | 809/3257 [00:04<00:13, 184.69it/s] 25%|‚ñà‚ñà‚ñå       | 828/3257 [00:04<00:13, 178.84it/s] 26%|‚ñà‚ñà‚ñå       | 846/3257 [00:04<00:14, 172.03it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:04<00:13, 178.92it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:04<00:13, 175.11it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:04<00:12, 188.75it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:05<00:12, 192.06it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:05<00:12, 187.61it/s] 30%|‚ñà‚ñà‚ñâ       | 969/3257 [00:05<00:11, 192.12it/s] 30%|‚ñà‚ñà‚ñà       | 989/3257 [00:05<00:12, 187.26it/s] 31%|‚ñà‚ñà‚ñà       | 1008/3257 [00:05<00:12, 183.42it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:05<00:12, 183.41it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:05<00:12, 181.18it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1066/3257 [00:05<00:11, 186.14it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1085/3257 [00:05<00:11, 182.30it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:06<00:11, 184.74it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:06<00:11, 184.52it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:06<00:11, 183.01it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1164/3257 [00:06<00:11, 189.16it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1183/3257 [00:06<00:11, 179.04it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1202/3257 [00:06<00:12, 166.34it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1221/3257 [00:06<00:11, 171.76it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:06<00:10, 183.64it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:06<00:10, 185.09it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1281/3257 [00:07<00:11, 173.80it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1299/3257 [00:07<00:18, 108.01it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1320/3257 [00:07<00:15, 127.69it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1340/3257 [00:07<00:13, 142.76it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1358/3257 [00:07<00:12, 148.80it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1376/3257 [00:07<00:12, 155.71it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1394/3257 [00:07<00:11, 161.26it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1419/3257 [00:08<00:10, 183.49it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:08<00:09, 183.19it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:08<00:09, 195.97it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1484/3257 [00:08<00:09, 196.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1509/3257 [00:08<00:08, 208.43it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1531/3257 [00:08<00:09, 189.50it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1551/3257 [00:08<00:09, 185.92it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1570/3257 [00:08<00:09, 182.90it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1589/3257 [00:08<00:09, 183.19it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1610/3257 [00:09<00:08, 188.52it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1630/3257 [00:09<00:08, 190.43it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:09<00:09, 175.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:09<00:09, 175.83it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1686/3257 [00:09<00:09, 171.68it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1706/3257 [00:09<00:08, 179.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1726/3257 [00:09<00:08, 184.85it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:09<00:09, 166.19it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1765/3257 [00:09<00:08, 174.51it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1786/3257 [00:10<00:08, 183.51it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1805/3257 [00:10<00:08, 176.93it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1824/3257 [00:10<00:08, 179.01it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1843/3257 [00:10<00:07, 177.09it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1861/3257 [00:10<00:07, 175.26it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1880/3257 [00:10<00:07, 177.16it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1898/3257 [00:10<00:07, 175.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:10<00:07, 175.35it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1935/3257 [00:10<00:07, 179.26it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1959/3257 [00:10<00:06, 195.49it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1979/3257 [00:11<00:06, 188.31it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:11<00:06, 190.15it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2020/3257 [00:11<00:06, 194.92it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2040/3257 [00:11<00:06, 187.11it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2059/3257 [00:11<00:06, 178.45it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2080/3257 [00:11<00:06, 186.64it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2099/3257 [00:11<00:06, 179.47it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:11<00:06, 179.37it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2139/3257 [00:11<00:06, 178.84it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2158/3257 [00:12<00:06, 181.02it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:12<00:05, 184.09it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2199/3257 [00:12<00:05, 189.60it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:12<00:05, 183.93it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:12<00:05, 182.73it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:12<00:05, 187.48it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2278/3257 [00:12<00:05, 180.22it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2300/3257 [00:12<00:05, 189.83it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2326/3257 [00:12<00:04, 207.29it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2352/3257 [00:13<00:04, 220.85it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2375/3257 [00:13<00:04, 215.29it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:13<00:03, 220.52it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:13<00:03, 209.91it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2444/3257 [00:13<00:04, 197.26it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2467/3257 [00:13<00:03, 205.04it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2488/3257 [00:13<00:03, 206.18it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2511/3257 [00:13<00:03, 211.71it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2535/3257 [00:13<00:03, 216.64it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2557/3257 [00:14<00:03, 203.04it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2578/3257 [00:14<00:03, 196.65it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2598/3257 [00:14<00:03, 192.62it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2626/3257 [00:14<00:02, 215.53it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2648/3257 [00:14<00:02, 204.78it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2669/3257 [00:14<00:02, 200.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:14<00:02, 202.53it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2711/3257 [00:14<00:03, 176.58it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:14<00:02, 184.45it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2752/3257 [00:15<00:04, 111.18it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2770/3257 [00:15<00:03, 122.87it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2793/3257 [00:15<00:03, 144.96it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:15<00:02, 156.47it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2832/3257 [00:15<00:02, 160.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:15<00:02, 172.41it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2881/3257 [00:15<00:01, 197.75it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:16<00:01, 186.96it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2927/3257 [00:16<00:01, 199.84it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2948/3257 [00:16<00:01, 185.97it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:16<00:01, 190.33it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2989/3257 [00:16<00:01, 184.12it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:16<00:01, 194.41it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3034/3257 [00:16<00:01, 200.99it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3058/3257 [00:16<00:00, 210.57it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3081/3257 [00:16<00:00, 211.98it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3104/3257 [00:17<00:00, 214.61it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:17<00:00, 214.81it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3149/3257 [00:17<00:00, 201.20it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3170/3257 [00:17<00:00, 201.53it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3191/3257 [00:17<00:00, 197.58it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3211/3257 [00:17<00:00, 195.09it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3232/3257 [00:17<00:00, 198.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:17<00:00, 198.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 182.96it/s]
2023-02-07 20:54:03.295 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:54:03,296][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d446,n5,mc8,s0.265564,t4>', 'datetime': '2023-02-07T20:54:03.296698', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:54:03,297][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:54:03,297][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:54:03,749][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 20:54:03,749][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:54:03,780][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 9584 unique words (44.17% of original 21699, drops 12115)', 'datetime': '2023-02-07T20:54:03.780534', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:54:03,781][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 4331919 word corpus (99.19% of original 4367244, drops 35325)', 'datetime': '2023-02-07T20:54:03.781058', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:54:03,815][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 20:54:03,816][gensim.models.word2vec][INFO] - sample=0.265564 downsamples 0 most-common words
[2023-02-07 20:54:03,816][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4331919 word corpus (100.0%% of prior 4331919)', 'datetime': '2023-02-07T20:54:03.816780', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:54:03,873][gensim.models.word2vec][INFO] - estimated required memory for 9584 words and 446 dimensions: 45449600 bytes
[2023-02-07 20:54:03,874][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:54:03,900][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 9584 vocabulary and 446 features, using sg=1 hs=0 sample=0.26556393801295464 negative=5 window=9 shrink_windows=True', 'datetime': '2023-02-07T20:54:03.900437', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:54:04,904][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 33.13% examples, 1446037 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:05,905][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 65.77% examples, 1453598 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:06,888][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4333519 effective words) took 3.0s, 1451290 effective words/s
[2023-02-07 20:54:07,895][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 34.08% examples, 1487565 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:08,899][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 67.79% examples, 1493824 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:09,767][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4333519 effective words) took 2.9s, 1506495 effective words/s
[2023-02-07 20:54:10,769][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 34.69% examples, 1525884 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:11,777][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 69.36% examples, 1530496 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:12,583][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4333519 effective words) took 2.8s, 1539772 effective words/s
[2023-02-07 20:54:13,585][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 34.26% examples, 1503191 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:14,590][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 68.07% examples, 1505061 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:15,455][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4333519 effective words) took 2.9s, 1509852 effective words/s
[2023-02-07 20:54:16,460][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 34.57% examples, 1515397 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:17,462][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 68.71% examples, 1518584 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:18,300][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4333519 effective words) took 2.8s, 1523650 effective words/s
[2023-02-07 20:54:19,304][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 34.08% examples, 1492970 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:20,305][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 68.62% examples, 1516090 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:21,155][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4333519 effective words) took 2.9s, 1519507 effective words/s
[2023-02-07 20:54:22,162][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 34.69% examples, 1518425 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:23,167][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 68.90% examples, 1519435 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:23,987][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4333519 effective words) took 2.8s, 1530986 effective words/s
[2023-02-07 20:54:24,998][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 34.91% examples, 1521251 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:26,003][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 69.36% examples, 1525945 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:54:26,816][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4333519 effective words) took 2.8s, 1532507 effective words/s
[2023-02-07 20:54:27,820][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 34.69% examples, 1523315 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:54:28,822][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 69.54% examples, 1538229 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:29,617][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4333519 effective words) took 2.8s, 1547902 effective words/s
[2023-02-07 20:54:30,622][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 35.06% examples, 1540310 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:31,631][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 70.22% examples, 1546754 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:32,420][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4333519 effective words) took 2.8s, 1547314 effective words/s
[2023-02-07 20:54:33,427][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 34.91% examples, 1527725 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:34,430][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 69.36% examples, 1529969 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:54:35,244][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4333519 effective words) took 2.8s, 1535331 effective words/s
[2023-02-07 20:54:36,247][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 34.69% examples, 1525249 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:54:37,255][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 69.36% examples, 1529516 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:38,065][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4333519 effective words) took 2.8s, 1537236 effective words/s
[2023-02-07 20:54:39,071][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 35.22% examples, 1546923 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:54:40,073][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 70.43% examples, 1555516 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:40,835][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4333519 effective words) took 2.8s, 1565396 effective words/s
[2023-02-07 20:54:41,843][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 35.77% examples, 1562903 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:42,845][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 70.22% examples, 1549287 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:43,621][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4333519 effective words) took 2.8s, 1556257 effective words/s
[2023-02-07 20:54:44,625][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 35.06% examples, 1542530 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:45,626][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 69.54% examples, 1539168 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:54:46,427][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4333519 effective words) took 2.8s, 1545683 effective words/s
[2023-02-07 20:54:46,428][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65002785 effective words) took 42.5s, 1528497 effective words/s', 'datetime': '2023-02-07T20:54:46.428195', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:54:46.428 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:54:49,971][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205336-p46s27j4/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:54:49.971103', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:54:49,972][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:54:50,043][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205336-p46s27j4/files/../tmp/embedding_model.pt
2023-02-07 20:54:50.044 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:54:52.572 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:54:53.453 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:54:58.384 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0790513842737555, 'test_mae': 0.7802954985777293, 'test_r2': -2.3285293438265504}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.43
wandb: percentage 0.55832
wandb:   test_mae 0.7803
wandb:   test_mse 1.07905
wandb:    test_r2 -2.32853
wandb: 
wandb: üöÄ View run fragrant-sweep-95 at: https://wandb.ai/xiaoqiz/mof2vec/runs/p46s27j4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_205336-p46s27j4/logs
wandb: Agent Starting Run: u68jo4dh with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 718
wandb: 	model.gensim.alpha: 0.004339777939337287
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.29225703942770864
wandb: 	model.gensim.vector_size: 188
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.1438699968408393
wandb: 	model.sklearn.max_depth: 40
wandb: 	model.sklearn.min_child_weight: 0.05059986407709801
wandb: 	model.sklearn.n_estimators: 3273
wandb: 	model.sklearn.num_leaves: 140
wandb: 	model.sklearn.reg_alpha: 0.003549239278288542
wandb: 	model.sklearn.reg_lambda: 0.01345625729665931
wandb: 	model.sklearn.subsample: 0.37458124032390006
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205507-u68jo4dh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-96
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/u68jo4dh
2023-02-07 20:55:15.264 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 20:55:15.265 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 718 for sweep.
2023-02-07 20:55:15.265 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.004339777939337287 for sweep.
2023-02-07 20:55:15.266 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:55:15.266 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 20:55:15.266 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.29225703942770864 for sweep.
2023-02-07 20:55:15.266 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 188 for sweep.
2023-02-07 20:55:15.266 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 20:55:15.267 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.1438699968408393 for sweep.
2023-02-07 20:55:15.267 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 40 for sweep.
2023-02-07 20:55:15.267 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05059986407709801 for sweep.
2023-02-07 20:55:15.267 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3273 for sweep.
2023-02-07 20:55:15.267 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 140 for sweep.
2023-02-07 20:55:15.268 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.003549239278288542 for sweep.
2023-02-07 20:55:15.268 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.01345625729665931 for sweep.
2023-02-07 20:55:15.268 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.37458124032390006 for sweep.
2023-02-07 20:55:15.268 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:55:15.277 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205507-u68jo4dh/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 718, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 188, 'window': 2, 'min_count': 1, 'dm': 0, 'sample': 0.29225703942770864, 'workers': 4, 'alpha': 0.004339777939337287, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3273, 'max_depth': 40, 'num_leaves': 140, 'reg_alpha': 0.003549239278288542, 'reg_lambda': 0.01345625729665931, 'subsample': 0.37458124032390006, 'min_child_weight': 0.05059986407709801, 'n_jobs': 4, 'learning_rate': 0.1438699968408393}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 20/3257 [00:00<00:16, 199.11it/s]  1%|‚ñè         | 42/3257 [00:00<00:15, 208.36it/s]  2%|‚ñè         | 66/3257 [00:00<00:14, 218.46it/s]  3%|‚ñé         | 88/3257 [00:00<00:14, 213.67it/s]  3%|‚ñé         | 110/3257 [00:00<00:16, 187.70it/s]  4%|‚ñç         | 132/3257 [00:00<00:15, 195.46it/s]  5%|‚ñç         | 154/3257 [00:00<00:15, 199.64it/s]  5%|‚ñå         | 175/3257 [00:00<00:16, 189.06it/s]  6%|‚ñå         | 197/3257 [00:00<00:15, 195.52it/s]  7%|‚ñã         | 220/3257 [00:01<00:14, 204.71it/s]  7%|‚ñã         | 244/3257 [00:01<00:14, 212.71it/s]  8%|‚ñä         | 266/3257 [00:01<00:14, 203.85it/s]  9%|‚ñâ         | 291/3257 [00:01<00:13, 216.32it/s] 10%|‚ñâ         | 313/3257 [00:01<00:14, 204.99it/s] 10%|‚ñà         | 336/3257 [00:01<00:14, 208.34it/s] 11%|‚ñà         | 358/3257 [00:01<00:13, 208.87it/s] 12%|‚ñà‚ñè        | 380/3257 [00:01<00:14, 193.66it/s] 12%|‚ñà‚ñè        | 400/3257 [00:01<00:14, 192.79it/s] 13%|‚ñà‚ñé        | 421/3257 [00:02<00:14, 193.45it/s] 14%|‚ñà‚ñé        | 441/3257 [00:02<00:16, 173.78it/s] 14%|‚ñà‚ñç        | 461/3257 [00:02<00:15, 180.39it/s] 15%|‚ñà‚ñç        | 480/3257 [00:02<00:15, 181.77it/s] 15%|‚ñà‚ñå        | 504/3257 [00:02<00:14, 195.91it/s] 16%|‚ñà‚ñå        | 525/3257 [00:02<00:13, 199.07it/s] 17%|‚ñà‚ñã        | 546/3257 [00:02<00:13, 195.68it/s] 17%|‚ñà‚ñã        | 566/3257 [00:02<00:14, 186.31it/s] 18%|‚ñà‚ñä        | 585/3257 [00:02<00:14, 182.39it/s] 19%|‚ñà‚ñä        | 606/3257 [00:03<00:14, 187.97it/s] 19%|‚ñà‚ñâ        | 626/3257 [00:03<00:13, 191.12it/s] 20%|‚ñà‚ñâ        | 646/3257 [00:03<00:13, 190.01it/s] 20%|‚ñà‚ñà        | 666/3257 [00:03<00:13, 186.86it/s] 21%|‚ñà‚ñà        | 685/3257 [00:03<00:13, 185.90it/s] 22%|‚ñà‚ñà‚ñè       | 707/3257 [00:03<00:13, 194.89it/s] 22%|‚ñà‚ñà‚ñè       | 727/3257 [00:03<00:13, 191.22it/s] 23%|‚ñà‚ñà‚ñé       | 747/3257 [00:04<00:21, 116.30it/s] 24%|‚ñà‚ñà‚ñé       | 769/3257 [00:04<00:18, 136.56it/s] 24%|‚ñà‚ñà‚ñç       | 787/3257 [00:04<00:17, 143.59it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:15, 153.43it/s] 25%|‚ñà‚ñà‚ñå       | 824/3257 [00:04<00:15, 159.77it/s] 26%|‚ñà‚ñà‚ñå       | 842/3257 [00:04<00:14, 161.14it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:04<00:13, 171.60it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:04<00:13, 171.64it/s] 28%|‚ñà‚ñà‚ñä       | 908/3257 [00:04<00:12, 186.88it/s] 29%|‚ñà‚ñà‚ñä       | 930/3257 [00:05<00:11, 194.43it/s] 29%|‚ñà‚ñà‚ñâ       | 950/3257 [00:05<00:11, 193.10it/s] 30%|‚ñà‚ñà‚ñâ       | 971/3257 [00:05<00:11, 196.86it/s] 30%|‚ñà‚ñà‚ñà       | 991/3257 [00:05<00:11, 191.24it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:05<00:11, 188.03it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1030/3257 [00:05<00:11, 186.45it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1049/3257 [00:05<00:12, 181.86it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1069/3257 [00:05<00:11, 185.89it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:05<00:11, 183.58it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1107/3257 [00:05<00:11, 185.04it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1126/3257 [00:06<00:11, 183.74it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1145/3257 [00:06<00:11, 179.01it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1167/3257 [00:06<00:11, 188.81it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1186/3257 [00:06<00:11, 173.20it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:06<00:12, 162.33it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1224/3257 [00:06<00:11, 171.25it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:06<00:11, 181.38it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1267/3257 [00:06<00:10, 190.47it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1287/3257 [00:07<00:11, 173.19it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1307/3257 [00:07<00:10, 179.93it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:07<00:10, 185.14it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1349/3257 [00:07<00:09, 191.46it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1369/3257 [00:07<00:10, 187.33it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:07<00:10, 180.11it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:07<00:09, 194.92it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1434/3257 [00:07<00:09, 199.98it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1458/3257 [00:07<00:08, 209.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1480/3257 [00:07<00:08, 207.30it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1504/3257 [00:08<00:08, 213.63it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1526/3257 [00:08<00:08, 197.64it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1547/3257 [00:08<00:09, 186.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1567/3257 [00:08<00:08, 188.75it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1587/3257 [00:08<00:09, 185.55it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1609/3257 [00:08<00:08, 193.59it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1630/3257 [00:08<00:08, 196.93it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:08<00:08, 184.26it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1669/3257 [00:08<00:08, 182.47it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1688/3257 [00:09<00:08, 183.66it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:09<00:08, 184.64it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:09<00:08, 179.87it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1747/3257 [00:09<00:08, 177.79it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1766/3257 [00:09<00:08, 180.56it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1788/3257 [00:09<00:07, 189.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1808/3257 [00:09<00:07, 181.99it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:09<00:07, 182.27it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:09<00:07, 189.13it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1870/3257 [00:10<00:07, 194.46it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1890/3257 [00:10<00:06, 195.73it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1911/3257 [00:10<00:06, 199.34it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:10<00:06, 194.39it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:10<00:10, 129.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:10<00:08, 144.07it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1993/3257 [00:10<00:08, 154.26it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2012/3257 [00:10<00:07, 161.76it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2034/3257 [00:11<00:07, 174.38it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2053/3257 [00:11<00:07, 168.83it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2071/3257 [00:11<00:06, 171.36it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2092/3257 [00:11<00:06, 181.35it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2111/3257 [00:11<00:06, 182.10it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2130/3257 [00:11<00:06, 171.06it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2148/3257 [00:11<00:06, 170.65it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2170/3257 [00:11<00:05, 184.04it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2189/3257 [00:11<00:05, 184.22it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:12<00:05, 182.34it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2229/3257 [00:12<00:05, 185.87it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2248/3257 [00:12<00:05, 178.88it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2267/3257 [00:12<00:05, 181.99it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2286/3257 [00:12<00:05, 183.47it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2305/3257 [00:12<00:05, 184.94it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2330/3257 [00:12<00:04, 201.58it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2354/3257 [00:12<00:04, 212.43it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2376/3257 [00:12<00:04, 202.52it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:12<00:04, 207.96it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2420/3257 [00:13<00:04, 197.42it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:13<00:04, 192.42it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2460/3257 [00:13<00:04, 190.26it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:13<00:03, 195.68it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2504/3257 [00:13<00:03, 203.05it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2525/3257 [00:13<00:03, 203.57it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2546/3257 [00:13<00:03, 201.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2567/3257 [00:13<00:03, 191.77it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2587/3257 [00:13<00:03, 179.95it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2609/3257 [00:14<00:03, 188.77it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2633/3257 [00:14<00:03, 201.18it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:14<00:03, 192.31it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2674/3257 [00:14<00:03, 188.86it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:14<00:02, 189.71it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2714/3257 [00:14<00:03, 174.24it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2735/3257 [00:14<00:02, 183.18it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:14<00:02, 190.37it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2776/3257 [00:14<00:02, 184.94it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2800/3257 [00:15<00:02, 199.96it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2821/3257 [00:15<00:02, 193.93it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2841/3257 [00:15<00:02, 184.20it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2866/3257 [00:15<00:01, 202.12it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2888/3257 [00:15<00:01, 206.56it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2909/3257 [00:15<00:01, 197.02it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2929/3257 [00:15<00:01, 195.90it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2949/3257 [00:15<00:01, 181.76it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2970/3257 [00:15<00:01, 188.61it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2990/3257 [00:16<00:01, 179.30it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3013/3257 [00:16<00:01, 190.43it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3034/3257 [00:16<00:01, 194.64it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3057/3257 [00:16<00:00, 204.30it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3079/3257 [00:16<00:00, 208.28it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3100/3257 [00:16<00:00, 204.39it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3122/3257 [00:16<00:00, 208.55it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3143/3257 [00:16<00:00, 195.67it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3163/3257 [00:16<00:00, 193.05it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:17<00:00, 186.17it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3206/3257 [00:17<00:00, 197.34it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3226/3257 [00:17<00:00, 188.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3251/3257 [00:17<00:00, 204.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 186.72it/s]
2023-02-07 20:55:33.449 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:55:33,451][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d188,n5,s0.292257,t4>', 'datetime': '2023-02-07T20:55:33.450879', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:55:33,451][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:55:33,451][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:55:33,872][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 20:55:33,874][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:55:33,931][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 21699 unique words (100.00% of original 21699, drops 0)', 'datetime': '2023-02-07T20:55:33.931730', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:55:33,932][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 4367244 word corpus (100.00% of original 4367244, drops 0)', 'datetime': '2023-02-07T20:55:33.932242', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:55:34,006][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 20:55:34,007][gensim.models.word2vec][INFO] - sample=0.292257 downsamples 0 most-common words
[2023-02-07 20:55:34,007][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4367244 word corpus (100.0%% of prior 4367244)', 'datetime': '2023-02-07T20:55:34.007746', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:55:34,138][gensim.models.word2vec][INFO] - estimated required memory for 21699 words and 188 dimensions: 46585460 bytes
[2023-02-07 20:55:34,139][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:55:34,161][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 21699 vocabulary and 188 features, using sg=1 hs=0 sample=0.29225703942770864 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T20:55:34.161450', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:55:35,168][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 46.70% examples, 2065283 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:55:36,168][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 97.48% examples, 2126350 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:55:36,220][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4368669 effective words) took 2.1s, 2124773 effective words/s
[2023-02-07 20:55:37,222][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 51.43% examples, 2296774 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:55:38,112][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4368669 effective words) took 1.9s, 2310178 effective words/s
[2023-02-07 20:55:39,115][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 51.27% examples, 2287080 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:55:40,027][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4368669 effective words) took 1.9s, 2283335 effective words/s
[2023-02-07 20:55:41,032][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 37.95% examples, 1692292 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:55:42,040][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 78.35% examples, 1718152 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:55:42,550][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4368669 effective words) took 2.5s, 1733043 effective words/s
[2023-02-07 20:55:43,562][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 50.88% examples, 2251133 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:55:44,475][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4368669 effective words) took 1.9s, 2272678 effective words/s
[2023-02-07 20:55:45,477][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 51.64% examples, 2307576 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:55:46,359][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4368669 effective words) took 1.9s, 2319790 effective words/s
[2023-02-07 20:55:47,367][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 51.43% examples, 2287308 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:55:48,260][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4368669 effective words) took 1.9s, 2301805 effective words/s
[2023-02-07 20:55:49,262][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 52.04% examples, 2325315 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:55:50,134][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4368669 effective words) took 1.9s, 2332436 effective words/s
[2023-02-07 20:55:51,146][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 51.64% examples, 2286635 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:55:52,022][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4368669 effective words) took 1.9s, 2316637 effective words/s
[2023-02-07 20:55:53,026][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 53.24% examples, 2382408 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:55:53,708][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4368669 effective words) took 1.7s, 2594153 effective words/s
[2023-02-07 20:55:54,710][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 65.77% examples, 2932076 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:55:55,222][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4368669 effective words) took 1.5s, 2887873 effective words/s
[2023-02-07 20:55:56,225][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 64.32% examples, 2856046 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:55:56,726][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4368669 effective words) took 1.5s, 2906778 effective words/s
[2023-02-07 20:55:57,728][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 59.69% examples, 2657532 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:55:58,524][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4368669 effective words) took 1.8s, 2432107 effective words/s
[2023-02-07 20:55:59,528][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 53.21% examples, 2379567 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:56:00,353][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4368669 effective words) took 1.8s, 2389917 effective words/s
[2023-02-07 20:56:01,360][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 54.10% examples, 2409773 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:56:02,202][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4368669 effective words) took 1.8s, 2363955 effective words/s
[2023-02-07 20:56:02,203][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65530035 effective words) took 28.0s, 2336910 effective words/s', 'datetime': '2023-02-07T20:56:02.203304', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:56:02.203 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:56:04,541][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205507-u68jo4dh/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:56:04.540900', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:56:04,541][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:56:04,599][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205507-u68jo4dh/files/../tmp/embedding_model.pt
2023-02-07 20:56:04.600 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:56:05.910 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:56:06.471 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:56:08.755 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9570662348709965, 'test_mae': 0.7376628789159417, 'test_r2': -2.2257252860019774}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.67
wandb: percentage 0.0
wandb:   test_mae 0.73766
wandb:   test_mse 0.95707
wandb:    test_r2 -2.22573
wandb: 
wandb: üöÄ View run glad-sweep-96 at: https://wandb.ai/xiaoqiz/mof2vec/runs/u68jo4dh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_205507-u68jo4dh/logs
wandb: Agent Starting Run: wzmxby63 with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 234
wandb: 	model.gensim.alpha: 0.0021318552325161355
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.5533722264329091
wandb: 	model.gensim.vector_size: 259
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.007935131097813556
wandb: 	model.sklearn.max_depth: 59
wandb: 	model.sklearn.min_child_weight: 0.07236548316918646
wandb: 	model.sklearn.n_estimators: 965
wandb: 	model.sklearn.num_leaves: 226
wandb: 	model.sklearn.reg_alpha: 0.01112718955267107
wandb: 	model.sklearn.reg_lambda: 0.016613570426268546
wandb: 	model.sklearn.subsample: 0.3597879752127563
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205620-wzmxby63
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-97
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/wzmxby63
2023-02-07 20:56:29.236 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:56:29.237 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 234 for sweep.
2023-02-07 20:56:29.237 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0021318552325161355 for sweep.
2023-02-07 20:56:29.237 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:56:29.238 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 20:56:29.238 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5533722264329091 for sweep.
2023-02-07 20:56:29.238 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 259 for sweep.
2023-02-07 20:56:29.238 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 20:56:29.239 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.007935131097813556 for sweep.
2023-02-07 20:56:29.239 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 59 for sweep.
2023-02-07 20:56:29.239 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.07236548316918646 for sweep.
2023-02-07 20:56:29.240 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 965 for sweep.
2023-02-07 20:56:29.240 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 226 for sweep.
2023-02-07 20:56:29.241 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.01112718955267107 for sweep.
2023-02-07 20:56:29.241 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.016613570426268546 for sweep.
2023-02-07 20:56:29.241 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3597879752127563 for sweep.
2023-02-07 20:56:29.242 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:56:29.248 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205620-wzmxby63/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 234, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 259, 'window': 8, 'min_count': 1, 'dm': 0, 'sample': 0.5533722264329091, 'workers': 4, 'alpha': 0.0021318552325161355, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 965, 'max_depth': 59, 'num_leaves': 226, 'reg_alpha': 0.01112718955267107, 'reg_lambda': 0.016613570426268546, 'subsample': 0.3597879752127563, 'min_child_weight': 0.07236548316918646, 'n_jobs': 4, 'learning_rate': 0.007935131097813556}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:24, 129.77it/s]  1%|          | 26/3257 [00:00<00:43, 73.58it/s]   1%|‚ñè         | 41/3257 [00:00<00:33, 95.56it/s]  2%|‚ñè         | 56/3257 [00:00<00:29, 109.82it/s]  2%|‚ñè         | 75/3257 [00:00<00:23, 133.13it/s]  3%|‚ñé         | 91/3257 [00:00<00:22, 140.87it/s]  3%|‚ñé         | 106/3257 [00:00<00:22, 137.05it/s]  4%|‚ñé         | 122/3257 [00:00<00:22, 142.24it/s]  4%|‚ñç         | 141/3257 [00:01<00:20, 153.52it/s]  5%|‚ñç         | 158/3257 [00:01<00:20, 152.93it/s]  5%|‚ñå         | 174/3257 [00:01<00:20, 150.14it/s]  6%|‚ñå         | 192/3257 [00:01<00:19, 157.37it/s]  6%|‚ñã         | 209/3257 [00:01<00:19, 160.07it/s]  7%|‚ñã         | 230/3257 [00:01<00:17, 169.61it/s]  8%|‚ñä         | 248/3257 [00:01<00:17, 168.45it/s]  8%|‚ñä         | 265/3257 [00:01<00:18, 158.14it/s]  9%|‚ñâ         | 287/3257 [00:01<00:17, 172.37it/s]  9%|‚ñâ         | 305/3257 [00:02<00:17, 165.55it/s] 10%|‚ñâ         | 323/3257 [00:02<00:17, 169.43it/s] 10%|‚ñà         | 341/3257 [00:02<00:18, 158.93it/s] 11%|‚ñà         | 359/3257 [00:02<00:17, 163.02it/s] 12%|‚ñà‚ñè        | 376/3257 [00:02<00:18, 154.72it/s] 12%|‚ñà‚ñè        | 392/3257 [00:02<00:19, 148.06it/s] 13%|‚ñà‚ñé        | 410/3257 [00:02<00:18, 156.04it/s] 13%|‚ñà‚ñé        | 426/3257 [00:02<00:21, 133.67it/s] 14%|‚ñà‚ñé        | 440/3257 [00:03<00:20, 135.14it/s] 14%|‚ñà‚ñç        | 457/3257 [00:03<00:19, 143.47it/s] 15%|‚ñà‚ñç        | 474/3257 [00:03<00:18, 148.57it/s] 15%|‚ñà‚ñå        | 490/3257 [00:03<00:18, 149.24it/s] 16%|‚ñà‚ñå        | 509/3257 [00:03<00:17, 160.22it/s] 16%|‚ñà‚ñå        | 526/3257 [00:03<00:18, 150.63it/s] 17%|‚ñà‚ñã        | 543/3257 [00:03<00:17, 155.53it/s] 17%|‚ñà‚ñã        | 559/3257 [00:03<00:19, 139.76it/s] 18%|‚ñà‚ñä        | 574/3257 [00:03<00:20, 132.56it/s] 18%|‚ñà‚ñä        | 592/3257 [00:04<00:18, 143.09it/s] 19%|‚ñà‚ñä        | 610/3257 [00:04<00:17, 150.27it/s] 19%|‚ñà‚ñâ        | 626/3257 [00:04<00:17, 147.76it/s] 20%|‚ñà‚ñâ        | 643/3257 [00:04<00:17, 152.94it/s] 20%|‚ñà‚ñà        | 659/3257 [00:04<00:18, 137.92it/s] 21%|‚ñà‚ñà        | 677/3257 [00:04<00:17, 147.09it/s] 21%|‚ñà‚ñà‚ñè       | 693/3257 [00:04<00:17, 144.73it/s] 22%|‚ñà‚ñà‚ñè       | 709/3257 [00:04<00:17, 147.66it/s] 22%|‚ñà‚ñà‚ñè       | 724/3257 [00:04<00:18, 138.89it/s] 23%|‚ñà‚ñà‚ñé       | 739/3257 [00:05<00:18, 134.68it/s] 23%|‚ñà‚ñà‚ñé       | 757/3257 [00:05<00:17, 146.54it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:05<00:16, 147.18it/s] 24%|‚ñà‚ñà‚ñç       | 788/3257 [00:05<00:17, 143.97it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:05<00:16, 144.98it/s] 25%|‚ñà‚ñà‚ñå       | 822/3257 [00:05<00:16, 148.37it/s] 26%|‚ñà‚ñà‚ñå       | 837/3257 [00:05<00:17, 141.49it/s] 26%|‚ñà‚ñà‚ñå       | 852/3257 [00:05<00:17, 137.32it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:05<00:16, 141.63it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:06<00:17, 137.60it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:06<00:15, 152.66it/s] 28%|‚ñà‚ñà‚ñä       | 921/3257 [00:06<00:15, 151.23it/s] 29%|‚ñà‚ñà‚ñâ       | 937/3257 [00:06<00:15, 148.77it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:06<00:14, 156.89it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:06<00:14, 153.45it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:06<00:15, 148.85it/s] 31%|‚ñà‚ñà‚ñà       | 1005/3257 [00:06<00:14, 152.67it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1021/3257 [00:06<00:14, 152.51it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1037/3257 [00:07<00:15, 142.72it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1052/3257 [00:07<00:16, 137.57it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1070/3257 [00:07<00:14, 147.60it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1085/3257 [00:07<00:15, 144.64it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1100/3257 [00:07<00:14, 144.34it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:07<00:14, 146.55it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1132/3257 [00:07<00:14, 142.59it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1147/3257 [00:07<00:14, 141.67it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1165/3257 [00:07<00:13, 151.72it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1181/3257 [00:08<00:14, 139.04it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1196/3257 [00:08<00:15, 132.54it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:08<00:15, 129.99it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1229/3257 [00:08<00:13, 144.93it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1244/3257 [00:08<00:13, 145.34it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1259/3257 [00:08<00:13, 145.09it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:08<00:13, 141.71it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:08<00:14, 135.86it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1304/3257 [00:08<00:14, 136.16it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:09<00:13, 142.49it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:09<00:12, 147.58it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:09<00:21, 87.55it/s]  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:09<00:19, 99.26it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1383/3257 [00:09<00:17, 105.23it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1401/3257 [00:09<00:15, 120.56it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1421/3257 [00:09<00:13, 139.55it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1437/3257 [00:10<00:12, 140.28it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1455/3257 [00:10<00:12, 150.07it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1472/3257 [00:10<00:11, 154.15it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1489/3257 [00:10<00:11, 155.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1509/3257 [00:10<00:10, 165.93it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1526/3257 [00:10<00:11, 147.51it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1542/3257 [00:10<00:11, 144.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1557/3257 [00:10<00:12, 140.45it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:10<00:11, 146.92it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1589/3257 [00:11<00:11, 147.57it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1606/3257 [00:11<00:10, 151.50it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1622/3257 [00:11<00:10, 153.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1638/3257 [00:11<00:10, 150.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:11<00:10, 148.77it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1669/3257 [00:11<00:11, 144.18it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1684/3257 [00:11<00:11, 141.38it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:11<00:10, 146.33it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:11<00:10, 145.82it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1730/3257 [00:12<00:11, 137.00it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:12<00:11, 134.83it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:12<00:10, 145.43it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1780/3257 [00:12<00:09, 150.61it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1797/3257 [00:12<00:09, 151.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1813/3257 [00:12<00:09, 145.29it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:12<00:10, 142.25it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:12<00:09, 148.53it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1863/3257 [00:12<00:09, 154.32it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:13<00:08, 155.01it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:13<00:09, 150.06it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1913/3257 [00:13<00:08, 157.23it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1929/3257 [00:13<00:09, 145.82it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1952/3257 [00:13<00:07, 167.58it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1971/3257 [00:13<00:07, 171.66it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1989/3257 [00:13<00:08, 158.31it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2006/3257 [00:13<00:07, 157.70it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2024/3257 [00:13<00:07, 161.00it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2041/3257 [00:14<00:07, 152.28it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2057/3257 [00:14<00:08, 144.57it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2072/3257 [00:14<00:08, 142.31it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2087/3257 [00:14<00:08, 143.25it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2102/3257 [00:14<00:08, 140.05it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2119/3257 [00:14<00:07, 148.18it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:14<00:08, 135.03it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2148/3257 [00:14<00:08, 131.40it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:14<00:07, 143.20it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:15<00:07, 140.38it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2198/3257 [00:15<00:07, 146.33it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2213/3257 [00:15<00:07, 136.01it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2228/3257 [00:15<00:07, 139.56it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2243/3257 [00:15<00:07, 133.55it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:15<00:07, 138.67it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2274/3257 [00:15<00:07, 127.48it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2292/3257 [00:15<00:06, 140.05it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2307/3257 [00:16<00:06, 138.81it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2326/3257 [00:16<00:06, 151.33it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2343/3257 [00:16<00:05, 154.37it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:16<00:05, 156.98it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2376/3257 [00:16<00:05, 154.68it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2394/3257 [00:16<00:05, 161.48it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2411/3257 [00:16<00:05, 147.82it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2427/3257 [00:16<00:05, 149.99it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:16<00:05, 136.57it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2460/3257 [00:17<00:05, 143.20it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:17<00:05, 145.48it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2492/3257 [00:17<00:05, 149.27it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2509/3257 [00:17<00:04, 152.90it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2525/3257 [00:17<00:04, 152.70it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2541/3257 [00:17<00:04, 150.31it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2557/3257 [00:17<00:04, 145.25it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:17<00:05, 136.46it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:17<00:04, 135.81it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2601/3257 [00:17<00:04, 139.07it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2620/3257 [00:18<00:04, 151.97it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2636/3257 [00:18<00:04, 153.90it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2652/3257 [00:18<00:04, 142.06it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2667/3257 [00:18<00:04, 142.08it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2684/3257 [00:18<00:03, 147.07it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2699/3257 [00:18<00:04, 130.75it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2713/3257 [00:18<00:04, 133.03it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2730/3257 [00:18<00:03, 142.86it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2747/3257 [00:18<00:03, 149.53it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2763/3257 [00:19<00:03, 148.91it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:19<00:03, 147.11it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2799/3257 [00:19<00:02, 160.34it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2816/3257 [00:19<00:05, 77.62it/s]  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2829/3257 [00:19<00:05, 84.91it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2844/3257 [00:20<00:04, 96.97it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2866/3257 [00:20<00:03, 121.67it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:20<00:02, 133.68it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2902/3257 [00:20<00:02, 130.32it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:20<00:02, 140.71it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2936/3257 [00:20<00:02, 142.61it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2952/3257 [00:20<00:02, 134.79it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:20<00:02, 143.34it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:20<00:01, 138.95it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3003/3257 [00:21<00:01, 149.03it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3019/3257 [00:21<00:01, 145.16it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3038/3257 [00:21<00:01, 155.55it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3055/3257 [00:21<00:01, 158.42it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:21<00:01, 166.24it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3092/3257 [00:21<00:01, 157.91it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3111/3257 [00:21<00:00, 165.91it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3128/3257 [00:21<00:00, 165.68it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3145/3257 [00:21<00:00, 153.17it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3161/3257 [00:22<00:00, 154.47it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3177/3257 [00:22<00:00, 146.15it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3196/3257 [00:22<00:00, 157.60it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:22<00:00, 144.44it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3231/3257 [00:22<00:00, 152.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3250/3257 [00:22<00:00, 161.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 143.65it/s]
2023-02-07 20:56:52.891 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:56:52,892][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d259,n5,s0.553372,t4>', 'datetime': '2023-02-07T20:56:52.892822', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:56:52,893][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:56:52,893][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:56:53,571][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:56:53,572][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:56:53,725][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 54054 unique words (100.00% of original 54054, drops 0)', 'datetime': '2023-02-07T20:56:53.725823', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:56:53,726][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 6550866 word corpus (100.00% of original 6550866, drops 0)', 'datetime': '2023-02-07T20:56:53.726283', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:56:53,927][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:56:53,928][gensim.models.word2vec][INFO] - sample=0.553372 downsamples 0 most-common words
[2023-02-07 20:56:53,928][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6550866 word corpus (100.0%% of prior 6550866)', 'datetime': '2023-02-07T20:56:53.928918', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:56:54,273][gensim.models.word2vec][INFO] - estimated required memory for 54054 words and 259 dimensions: 143052540 bytes
[2023-02-07 20:56:54,273][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:56:54,341][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 54054 vocabulary and 259 features, using sg=1 hs=0 sample=0.5533722264329091 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T20:56:54.341487', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:56:55,352][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 27.85% examples, 1797388 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:56:56,352][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 55.88% examples, 1845273 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:56:57,362][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 85.78% examples, 1860375 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:56:57,817][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6494971 effective words) took 3.5s, 1869670 effective words/s
[2023-02-07 20:56:58,820][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 29.75% examples, 1929804 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:56:59,820][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 58.80% examples, 1943825 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:00,823][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 88.82% examples, 1933067 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:01,178][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6494971 effective words) took 3.4s, 1933015 effective words/s
[2023-02-07 20:57:02,182][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 29.54% examples, 1915937 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:03,187][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 58.06% examples, 1920165 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:04,188][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 88.61% examples, 1922214 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:04,554][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6494971 effective words) took 3.4s, 1925296 effective words/s
[2023-02-07 20:57:05,558][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 29.08% examples, 1885224 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:06,560][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 57.60% examples, 1906068 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:07,562][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 87.35% examples, 1905002 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:07,961][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6494971 effective words) took 3.4s, 1907001 effective words/s
[2023-02-07 20:57:08,982][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 28.46% examples, 1851266 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:57:09,984][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 56.74% examples, 1881150 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:10,985][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 86.80% examples, 1890376 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:11,412][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6494971 effective words) took 3.4s, 1892668 effective words/s
[2023-02-07 20:57:12,421][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 29.66% examples, 1909944 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:13,424][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 58.61% examples, 1930483 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:14,432][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 89.25% examples, 1933957 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:14,758][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6494971 effective words) took 3.3s, 1942112 effective words/s
[2023-02-07 20:57:15,764][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 29.66% examples, 1918224 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:16,764][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 58.43% examples, 1933211 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:17,770][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 89.25% examples, 1939826 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:18,097][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6494971 effective words) took 3.3s, 1946906 effective words/s
[2023-02-07 20:57:19,099][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 30.06% examples, 1955520 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:20,099][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 58.92% examples, 1953938 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:21,101][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 89.50% examples, 1947186 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:21,424][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6494971 effective words) took 3.3s, 1952773 effective words/s
[2023-02-07 20:57:22,435][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 28.46% examples, 1839652 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:57:23,436][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 57.35% examples, 1892218 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:24,438][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 87.57% examples, 1905593 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:24,826][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6494971 effective words) took 3.4s, 1910962 effective words/s
[2023-02-07 20:57:25,838][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 24.35% examples, 1554442 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:26,839][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 45.59% examples, 1501231 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:27,840][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 67.39% examples, 1482281 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:28,847][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 90.48% examples, 1470297 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:29,245][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6494971 effective words) took 4.4s, 1470634 effective words/s
[2023-02-07 20:57:30,248][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 29.90% examples, 1936550 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:31,253][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 58.80% examples, 1939390 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:32,258][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 89.25% examples, 1938386 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:32,588][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6494971 effective words) took 3.3s, 1943740 effective words/s
[2023-02-07 20:57:33,592][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 30.06% examples, 1951321 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:34,594][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 59.10% examples, 1955309 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:35,596][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 89.62% examples, 1947599 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:35,921][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6494971 effective words) took 3.3s, 1949322 effective words/s
[2023-02-07 20:57:36,929][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 29.66% examples, 1913018 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:37,935][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 57.97% examples, 1911244 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:38,938][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 88.61% examples, 1917354 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:39,299][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6494971 effective words) took 3.4s, 1923777 effective words/s
[2023-02-07 20:57:40,308][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 28.55% examples, 1841734 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:41,314][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 57.60% examples, 1897151 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:42,314][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 88.61% examples, 1918419 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:42,673][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6494971 effective words) took 3.4s, 1925964 effective words/s
[2023-02-07 20:57:43,677][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 30.06% examples, 1952196 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:44,684][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 58.89% examples, 1940974 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:45,685][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 90.18% examples, 1956572 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:57:45,988][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6494971 effective words) took 3.3s, 1959962 effective words/s
[2023-02-07 20:57:45,989][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (97424565 effective words) took 51.6s, 1886356 effective words/s', 'datetime': '2023-02-07T20:57:45.988970', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:57:45.989 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:57:50,703][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205620-wzmxby63/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:57:50.703336', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:57:50,704][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205620-wzmxby63/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 20:57:50,759][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205620-wzmxby63/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 20:57:50,814][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:57:50,867][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205620-wzmxby63/files/../tmp/embedding_model.pt
2023-02-07 20:57:50.867 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:57:52.803 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:57:53.435 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:57:57.917 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1086121290119952, 'test_mae': 0.8122592126390685, 'test_r2': -2.410697623718715}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.54
wandb: percentage 0.0
wandb:   test_mae 0.81226
wandb:   test_mse 1.10861
wandb:    test_r2 -2.4107
wandb: 
wandb: üöÄ View run playful-sweep-97 at: https://wandb.ai/xiaoqiz/mof2vec/runs/wzmxby63
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_205620-wzmxby63/logs
wandb: Agent Starting Run: bi7ba585 with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 591
wandb: 	model.gensim.alpha: 0.005575420724153396
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.21708561251928168
wandb: 	model.gensim.vector_size: 421
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.024165370028618263
wandb: 	model.sklearn.max_depth: 14
wandb: 	model.sklearn.min_child_weight: 0.08285308312775198
wandb: 	model.sklearn.n_estimators: 436
wandb: 	model.sklearn.num_leaves: 275
wandb: 	model.sklearn.reg_alpha: 0.00992790137806117
wandb: 	model.sklearn.reg_lambda: 0.042572221443708
wandb: 	model.sklearn.subsample: 0.5192908927001626
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205811-bi7ba585
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-98
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/bi7ba585
2023-02-07 20:58:19.450 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 20:58:19.450 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 591 for sweep.
2023-02-07 20:58:19.451 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.005575420724153396 for sweep.
2023-02-07 20:58:19.451 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:58:19.452 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 20:58:19.452 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.21708561251928168 for sweep.
2023-02-07 20:58:19.452 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 421 for sweep.
2023-02-07 20:58:19.453 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 20:58:19.453 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.024165370028618263 for sweep.
2023-02-07 20:58:19.453 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 14 for sweep.
2023-02-07 20:58:19.453 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08285308312775198 for sweep.
2023-02-07 20:58:19.454 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 436 for sweep.
2023-02-07 20:58:19.454 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 275 for sweep.
2023-02-07 20:58:19.454 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.00992790137806117 for sweep.
2023-02-07 20:58:19.454 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.042572221443708 for sweep.
2023-02-07 20:58:19.455 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5192908927001626 for sweep.
2023-02-07 20:58:19.455 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:58:19.461 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205811-bi7ba585/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 591, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 421, 'window': 2, 'min_count': 3, 'dm': 0, 'sample': 0.21708561251928168, 'workers': 4, 'alpha': 0.005575420724153396, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 436, 'max_depth': 14, 'num_leaves': 275, 'reg_alpha': 0.00992790137806117, 'reg_lambda': 0.042572221443708, 'subsample': 0.5192908927001626, 'min_child_weight': 0.08285308312775198, 'n_jobs': 4, 'learning_rate': 0.024165370028618263}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:19, 169.19it/s]  1%|          | 38/3257 [00:00<00:17, 185.34it/s]  2%|‚ñè         | 57/3257 [00:00<00:17, 180.05it/s]  2%|‚ñè         | 79/3257 [00:00<00:16, 194.32it/s]  3%|‚ñé         | 99/3257 [00:00<00:16, 189.39it/s]  4%|‚ñé         | 118/3257 [00:00<00:16, 187.06it/s]  4%|‚ñç         | 140/3257 [00:00<00:15, 195.42it/s]  5%|‚ñç         | 160/3257 [00:00<00:15, 196.16it/s]  6%|‚ñå         | 180/3257 [00:00<00:16, 189.12it/s]  6%|‚ñå         | 201/3257 [00:01<00:15, 194.15it/s]  7%|‚ñã         | 226/3257 [00:01<00:14, 209.68it/s]  8%|‚ñä         | 248/3257 [00:01<00:14, 206.65it/s]  8%|‚ñä         | 269/3257 [00:01<00:15, 196.36it/s]  9%|‚ñâ         | 295/3257 [00:01<00:13, 213.66it/s] 10%|‚ñâ         | 317/3257 [00:01<00:14, 205.79it/s] 10%|‚ñà         | 339/3257 [00:01<00:14, 207.20it/s] 11%|‚ñà         | 361/3257 [00:01<00:13, 210.36it/s] 12%|‚ñà‚ñè        | 383/3257 [00:01<00:14, 198.40it/s] 12%|‚ñà‚ñè        | 404/3257 [00:02<00:14, 197.26it/s] 13%|‚ñà‚ñé        | 424/3257 [00:02<00:14, 196.36it/s] 14%|‚ñà‚ñé        | 444/3257 [00:02<00:15, 178.79it/s] 14%|‚ñà‚ñç        | 465/3257 [00:02<00:14, 186.72it/s] 15%|‚ñà‚ñç        | 484/3257 [00:02<00:14, 187.07it/s] 16%|‚ñà‚ñå        | 507/3257 [00:02<00:13, 198.57it/s] 16%|‚ñà‚ñå        | 528/3257 [00:02<00:14, 194.34it/s] 17%|‚ñà‚ñã        | 549/3257 [00:02<00:13, 197.51it/s] 17%|‚ñà‚ñã        | 569/3257 [00:02<00:14, 189.48it/s] 18%|‚ñà‚ñä        | 589/3257 [00:03<00:14, 183.09it/s] 19%|‚ñà‚ñâ        | 611/3257 [00:03<00:13, 192.08it/s] 19%|‚ñà‚ñâ        | 633/3257 [00:03<00:13, 198.86it/s] 20%|‚ñà‚ñà        | 654/3257 [00:03<00:13, 189.19it/s] 21%|‚ñà‚ñà        | 674/3257 [00:03<00:13, 188.38it/s] 21%|‚ñà‚ñà‚ñè       | 693/3257 [00:03<00:13, 185.54it/s] 22%|‚ñà‚ñà‚ñè       | 716/3257 [00:03<00:12, 196.68it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:03<00:13, 180.72it/s] 23%|‚ñà‚ñà‚ñé       | 757/3257 [00:03<00:13, 186.35it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:04<00:13, 185.52it/s] 24%|‚ñà‚ñà‚ñç       | 796/3257 [00:04<00:20, 117.95it/s] 25%|‚ñà‚ñà‚ñç       | 814/3257 [00:04<00:18, 129.72it/s] 26%|‚ñà‚ñà‚ñå       | 831/3257 [00:04<00:17, 138.13it/s] 26%|‚ñà‚ñà‚ñå       | 848/3257 [00:04<00:16, 144.77it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:04<00:15, 156.95it/s] 27%|‚ñà‚ñà‚ñã       | 887/3257 [00:04<00:14, 165.53it/s] 28%|‚ñà‚ñà‚ñä       | 909/3257 [00:04<00:13, 179.83it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:05<00:12, 185.71it/s] 29%|‚ñà‚ñà‚ñâ       | 952/3257 [00:05<00:12, 191.18it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:05<00:11, 193.20it/s] 30%|‚ñà‚ñà‚ñà       | 992/3257 [00:05<00:11, 191.62it/s] 31%|‚ñà‚ñà‚ñà       | 1012/3257 [00:05<00:11, 188.79it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1032/3257 [00:05<00:11, 187.23it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:05<00:12, 181.43it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1073/3257 [00:05<00:11, 191.17it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1093/3257 [00:05<00:11, 182.05it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1116/3257 [00:06<00:11, 193.47it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1136/3257 [00:06<00:11, 184.84it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1155/3257 [00:06<00:11, 183.45it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:06<00:11, 186.23it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:06<00:11, 172.08it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1212/3257 [00:06<00:12, 170.18it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1235/3257 [00:06<00:10, 185.52it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1254/3257 [00:06<00:10, 183.47it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1273/3257 [00:06<00:10, 182.85it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:07<00:11, 168.48it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1311/3257 [00:07<00:11, 172.97it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1330/3257 [00:07<00:10, 177.61it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:07<00:10, 177.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1368/3257 [00:07<00:10, 176.56it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:07<00:10, 170.36it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1408/3257 [00:07<00:10, 183.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1431/3257 [00:07<00:09, 194.30it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:07<00:09, 196.08it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:07<00:08, 202.70it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1495/3257 [00:08<00:08, 203.67it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1516/3257 [00:08<00:08, 205.42it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1537/3257 [00:08<00:09, 184.81it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1556/3257 [00:08<00:09, 182.47it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:08<00:09, 180.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:08<00:08, 186.16it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:08<00:08, 192.42it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1637/3257 [00:08<00:08, 183.40it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:08<00:08, 181.68it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:09<00:08, 178.45it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1696/3257 [00:09<00:08, 183.04it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1716/3257 [00:09<00:08, 185.10it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1735/3257 [00:09<00:08, 172.44it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1756/3257 [00:09<00:08, 181.76it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1776/3257 [00:09<00:08, 183.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:09<00:07, 186.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1815/3257 [00:09<00:08, 174.03it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1833/3257 [00:09<00:08, 172.07it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1853/3257 [00:10<00:07, 178.34it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1875/3257 [00:10<00:07, 189.49it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:10<00:07, 184.30it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:10<00:07, 187.55it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1938/3257 [00:10<00:06, 196.57it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1964/3257 [00:10<00:06, 213.53it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1986/3257 [00:10<00:06, 201.27it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2007/3257 [00:10<00:06, 201.42it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2031/3257 [00:10<00:05, 210.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2053/3257 [00:11<00:06, 191.16it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2073/3257 [00:11<00:06, 188.94it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2093/3257 [00:11<00:06, 191.77it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2113/3257 [00:11<00:06, 189.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2133/3257 [00:11<00:06, 177.40it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2151/3257 [00:11<00:10, 109.55it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2172/3257 [00:11<00:08, 128.74it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2189/3257 [00:12<00:07, 137.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:12<00:07, 147.90it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2229/3257 [00:12<00:06, 160.11it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2247/3257 [00:12<00:06, 162.41it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2266/3257 [00:12<00:05, 167.41it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2284/3257 [00:12<00:05, 170.56it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2302/3257 [00:12<00:05, 173.20it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2326/3257 [00:12<00:04, 191.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2351/3257 [00:12<00:04, 207.93it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2373/3257 [00:13<00:04, 200.04it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:13<00:04, 207.33it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2418/3257 [00:13<00:04, 196.35it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2438/3257 [00:13<00:04, 190.22it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2458/3257 [00:13<00:04, 190.40it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:13<00:03, 197.77it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2505/3257 [00:13<00:03, 208.47it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2526/3257 [00:13<00:03, 204.90it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2547/3257 [00:13<00:03, 206.34it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2568/3257 [00:14<00:03, 190.85it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2588/3257 [00:14<00:03, 186.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2612/3257 [00:14<00:03, 201.34it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2635/3257 [00:14<00:02, 208.60it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2657/3257 [00:14<00:03, 193.98it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2677/3257 [00:14<00:03, 189.50it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2697/3257 [00:14<00:02, 187.24it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2716/3257 [00:14<00:03, 168.48it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:14<00:02, 187.33it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:15<00:02, 186.30it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2780/3257 [00:15<00:02, 186.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:15<00:02, 198.70it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2824/3257 [00:15<00:02, 185.27it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2843/3257 [00:15<00:02, 183.32it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2867/3257 [00:15<00:01, 198.81it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2888/3257 [00:15<00:01, 199.95it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2909/3257 [00:15<00:01, 191.35it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2929/3257 [00:15<00:01, 192.92it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2949/3257 [00:16<00:01, 184.55it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2970/3257 [00:16<00:01, 190.47it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2990/3257 [00:16<00:01, 181.10it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:16<00:01, 189.78it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3034/3257 [00:16<00:01, 196.48it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3057/3257 [00:16<00:00, 203.71it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3079/3257 [00:16<00:00, 207.88it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3100/3257 [00:16<00:00, 202.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3124/3257 [00:16<00:00, 209.40it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3146/3257 [00:16<00:00, 195.58it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:17<00:00, 191.33it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3186/3257 [00:17<00:00, 185.17it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:17<00:00, 189.22it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3227/3257 [00:17<00:00, 189.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3250/3257 [00:17<00:00, 199.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 185.19it/s]
2023-02-07 20:58:37.711 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:58:37,712][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d421,n5,mc3,s0.217086,t4>', 'datetime': '2023-02-07T20:58:37.712733', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:58:37,713][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:58:37,713][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:58:38,157][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 20:58:38,158][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:58:38,201][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 15507 unique words (71.46% of original 21699, drops 6192)', 'datetime': '2023-02-07T20:58:38.201869', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:58:38,202][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 4358064 word corpus (99.79% of original 4367244, drops 9180)', 'datetime': '2023-02-07T20:58:38.202297', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:58:38,256][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 20:58:38,257][gensim.models.word2vec][INFO] - sample=0.217086 downsamples 0 most-common words
[2023-02-07 20:58:38,257][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4358064 word corpus (100.0%% of prior 4358064)', 'datetime': '2023-02-07T20:58:38.257874', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:58:38,349][gensim.models.word2vec][INFO] - estimated required memory for 15507 words and 421 dimensions: 66117264 bytes
[2023-02-07 20:58:38,350][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:58:38,389][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 15507 vocabulary and 421 features, using sg=1 hs=0 sample=0.21708561251928168 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T20:58:38.389109', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:58:39,391][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 35.98% examples, 1592265 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:40,399][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 73.81% examples, 1623569 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:58:41,052][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4359560 effective words) took 2.7s, 1638108 effective words/s
[2023-02-07 20:58:42,055][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 41.73% examples, 1869736 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:43,060][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 85.63% examples, 1875411 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:43,374][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4359560 effective words) took 2.3s, 1878761 effective words/s
[2023-02-07 20:58:44,382][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 42.19% examples, 1883866 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:45,384][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 86.43% examples, 1891658 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:45,682][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4359560 effective words) took 2.3s, 1890778 effective words/s
[2023-02-07 20:58:46,689][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 41.63% examples, 1858863 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:47,692][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 85.23% examples, 1867598 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:48,007][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4359560 effective words) took 2.3s, 1875939 effective words/s
[2023-02-07 20:58:49,013][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 42.49% examples, 1898921 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:50,018][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 87.14% examples, 1907765 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:50,296][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4359560 effective words) took 2.3s, 1905731 effective words/s
[2023-02-07 20:58:51,300][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 42.19% examples, 1891152 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:52,301][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 90.57% examples, 1985544 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:52,457][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4359560 effective words) took 2.2s, 2018716 effective words/s
[2023-02-07 20:58:53,464][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.21% examples, 2368233 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:54,316][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4359560 effective words) took 1.9s, 2346303 effective words/s
[2023-02-07 20:58:55,321][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 54.77% examples, 2435997 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:56,174][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4359560 effective words) took 1.9s, 2348184 effective words/s
[2023-02-07 20:58:57,176][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 43.87% examples, 1959561 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:58,182][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 89.87% examples, 1961604 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:58:58,474][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4359560 effective words) took 2.3s, 1896510 effective words/s
[2023-02-07 20:58:59,477][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 41.73% examples, 1869086 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:59:00,479][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 90.33% examples, 1976001 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:59:00,656][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4359560 effective words) took 2.2s, 1999411 effective words/s
[2023-02-07 20:59:01,661][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 46.79% examples, 2070957 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:59:02,627][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4359560 effective words) took 2.0s, 2212876 effective words/s
[2023-02-07 20:59:03,630][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 53.24% examples, 2379200 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:59:04,418][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4359560 effective words) took 1.8s, 2436462 effective words/s
[2023-02-07 20:59:05,420][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 44.83% examples, 1994736 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:59:06,422][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 91.40% examples, 2004118 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:59:06,594][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4359560 effective words) took 2.2s, 2004251 effective words/s
[2023-02-07 20:59:07,596][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 43.87% examples, 1958590 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:59:08,601][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 90.57% examples, 1983159 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:59:08,791][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4359560 effective words) took 2.2s, 1985465 effective words/s
[2023-02-07 20:59:09,794][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 43.87% examples, 1960106 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:59:10,799][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 91.25% examples, 1997476 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:59:10,970][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4359560 effective words) took 2.2s, 2002489 effective words/s
[2023-02-07 20:59:10,971][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65393400 effective words) took 32.6s, 2007049 effective words/s', 'datetime': '2023-02-07T20:59:10.971441', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:59:10.971 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:59:13,993][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205811-bi7ba585/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:59:13.993711', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:59:13,994][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:59:14,083][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205811-bi7ba585/files/../tmp/embedding_model.pt
2023-02-07 20:59:14.083 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:59:16.460 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:59:17.295 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:59:20.727 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9406469615896655, 'test_mae': 0.7387705621269584, 'test_r2': -1.9013690106959604}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.75
wandb: percentage 0.28536
wandb:   test_mae 0.73877
wandb:   test_mse 0.94065
wandb:    test_r2 -1.90137
wandb: 
wandb: üöÄ View run gentle-sweep-98 at: https://wandb.ai/xiaoqiz/mof2vec/runs/bi7ba585
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_205811-bi7ba585/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: k5ct8zj7 with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 406
wandb: 	model.gensim.alpha: 0.002650038158412835
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 4
wandb: 	model.gensim.sample: 0.2160137444537071
wandb: 	model.gensim.vector_size: 115
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.001494281780630243
wandb: 	model.sklearn.max_depth: 36
wandb: 	model.sklearn.min_child_weight: 0.09500374601327025
wandb: 	model.sklearn.n_estimators: 347
wandb: 	model.sklearn.num_leaves: 83
wandb: 	model.sklearn.reg_alpha: 0.015610063986579666
wandb: 	model.sklearn.reg_lambda: 0.04677315633678241
wandb: 	model.sklearn.subsample: 0.4012863554868919
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205940-k5ct8zj7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-99
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/k5ct8zj7
2023-02-07 20:59:49.013 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 20:59:49.014 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 406 for sweep.
2023-02-07 20:59:49.014 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.002650038158412835 for sweep.
2023-02-07 20:59:49.015 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:59:49.015 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 4 for sweep.
2023-02-07 20:59:49.015 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2160137444537071 for sweep.
2023-02-07 20:59:49.016 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 115 for sweep.
2023-02-07 20:59:49.017 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 20:59:49.017 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.001494281780630243 for sweep.
2023-02-07 20:59:49.017 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 36 for sweep.
2023-02-07 20:59:49.017 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09500374601327025 for sweep.
2023-02-07 20:59:49.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 347 for sweep.
2023-02-07 20:59:49.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 83 for sweep.
2023-02-07 20:59:49.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.015610063986579666 for sweep.
2023-02-07 20:59:49.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.04677315633678241 for sweep.
2023-02-07 20:59:49.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.4012863554868919 for sweep.
2023-02-07 20:59:49.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:59:49.023 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205940-k5ct8zj7/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 406, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 115, 'window': 8, 'min_count': 4, 'dm': 0, 'sample': 0.2160137444537071, 'workers': 4, 'alpha': 0.002650038158412835, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 347, 'max_depth': 36, 'num_leaves': 83, 'reg_alpha': 0.015610063986579666, 'reg_lambda': 0.04677315633678241, 'subsample': 0.4012863554868919, 'min_child_weight': 0.09500374601327025, 'n_jobs': 4, 'learning_rate': 0.001494281780630243}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 174.67it/s]  1%|          | 39/3257 [00:00<00:16, 194.24it/s]  2%|‚ñè         | 59/3257 [00:00<00:17, 187.15it/s]  3%|‚ñé         | 82/3257 [00:00<00:15, 200.47it/s]  3%|‚ñé         | 103/3257 [00:00<00:15, 200.45it/s]  4%|‚ñç         | 124/3257 [00:00<00:16, 189.73it/s]  5%|‚ñç         | 148/3257 [00:00<00:15, 204.35it/s]  5%|‚ñå         | 169/3257 [00:00<00:15, 197.40it/s]  6%|‚ñå         | 190/3257 [00:00<00:15, 200.01it/s]  7%|‚ñã         | 212/3257 [00:01<00:14, 203.54it/s]  7%|‚ñã         | 236/3257 [00:01<00:14, 213.31it/s]  8%|‚ñä         | 258/3257 [00:01<00:21, 138.83it/s]  9%|‚ñä         | 281/3257 [00:01<00:18, 158.18it/s]  9%|‚ñâ         | 300/3257 [00:01<00:17, 164.54it/s] 10%|‚ñâ         | 323/3257 [00:01<00:16, 180.46it/s] 11%|‚ñà         | 344/3257 [00:01<00:16, 179.03it/s] 11%|‚ñà         | 366/3257 [00:01<00:15, 186.94it/s] 12%|‚ñà‚ñè        | 386/3257 [00:02<00:16, 178.91it/s] 13%|‚ñà‚ñé        | 408/3257 [00:02<00:15, 188.24it/s] 13%|‚ñà‚ñé        | 428/3257 [00:02<00:16, 171.50it/s] 14%|‚ñà‚ñé        | 447/3257 [00:02<00:16, 172.51it/s] 14%|‚ñà‚ñç        | 469/3257 [00:02<00:15, 184.13it/s] 15%|‚ñà‚ñç        | 488/3257 [00:02<00:15, 184.11it/s] 16%|‚ñà‚ñå        | 512/3257 [00:02<00:13, 196.33it/s] 16%|‚ñà‚ñã        | 532/3257 [00:02<00:14, 190.58it/s] 17%|‚ñà‚ñã        | 554/3257 [00:02<00:13, 196.83it/s] 18%|‚ñà‚ñä        | 574/3257 [00:03<00:15, 175.57it/s] 18%|‚ñà‚ñä        | 596/3257 [00:03<00:14, 187.11it/s] 19%|‚ñà‚ñâ        | 618/3257 [00:03<00:13, 195.28it/s] 20%|‚ñà‚ñâ        | 638/3257 [00:03<00:13, 192.42it/s] 20%|‚ñà‚ñà        | 658/3257 [00:03<00:14, 176.97it/s] 21%|‚ñà‚ñà        | 679/3257 [00:03<00:13, 185.56it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:03<00:14, 179.13it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:03<00:13, 187.73it/s] 23%|‚ñà‚ñà‚ñé       | 740/3257 [00:04<00:14, 176.53it/s] 23%|‚ñà‚ñà‚ñé       | 763/3257 [00:04<00:13, 189.46it/s] 24%|‚ñà‚ñà‚ñç       | 783/3257 [00:04<00:13, 184.07it/s] 25%|‚ñà‚ñà‚ñç       | 805/3257 [00:04<00:12, 193.21it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:04<00:13, 179.37it/s] 26%|‚ñà‚ñà‚ñå       | 844/3257 [00:04<00:13, 175.54it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:04<00:13, 179.10it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:04<00:13, 176.69it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:04<00:12, 190.03it/s] 29%|‚ñà‚ñà‚ñä       | 929/3257 [00:05<00:11, 195.83it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:05<00:11, 192.64it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:05<00:11, 196.46it/s] 30%|‚ñà‚ñà‚ñà       | 990/3257 [00:05<00:11, 191.84it/s] 31%|‚ñà‚ñà‚ñà       | 1010/3257 [00:05<00:11, 187.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1029/3257 [00:05<00:11, 188.29it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1048/3257 [00:05<00:11, 184.44it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1068/3257 [00:05<00:11, 188.69it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:05<00:11, 188.48it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1108/3257 [00:05<00:11, 191.43it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1128/3257 [00:06<00:11, 186.95it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1147/3257 [00:06<00:11, 184.60it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:06<00:10, 192.84it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1190/3257 [00:06<00:11, 175.29it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1208/3257 [00:06<00:11, 174.11it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:06<00:10, 190.03it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1252/3257 [00:06<00:10, 187.81it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:06<00:10, 190.15it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:06<00:10, 178.68it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:07<00:10, 184.45it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1334/3257 [00:07<00:10, 191.10it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:07<00:10, 185.05it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1373/3257 [00:07<00:10, 184.15it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1392/3257 [00:07<00:10, 183.43it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1418/3257 [00:07<00:08, 205.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:07<00:09, 199.68it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:07<00:08, 209.95it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1485/3257 [00:07<00:08, 208.42it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:08<00:07, 219.07it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1533/3257 [00:08<00:13, 124.27it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1552/3257 [00:08<00:12, 134.60it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1572/3257 [00:08<00:11, 148.31it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1592/3257 [00:08<00:10, 158.99it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:08<00:09, 174.53it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:08<00:09, 172.41it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:09<00:09, 176.81it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1673/3257 [00:09<00:08, 176.63it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:09<00:08, 178.24it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1713/3257 [00:09<00:08, 186.62it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1733/3257 [00:09<00:08, 171.71it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1753/3257 [00:09<00:08, 176.98it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1772/3257 [00:09<00:08, 179.86it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1793/3257 [00:09<00:07, 185.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1812/3257 [00:09<00:08, 178.47it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1831/3257 [00:10<00:07, 178.58it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1852/3257 [00:10<00:07, 186.23it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1875/3257 [00:10<00:07, 196.98it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:10<00:07, 192.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:10<00:06, 192.84it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1938/3257 [00:10<00:06, 199.83it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1964/3257 [00:10<00:05, 216.94it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1986/3257 [00:10<00:06, 201.31it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2007/3257 [00:10<00:06, 202.89it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2031/3257 [00:10<00:05, 210.67it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2053/3257 [00:11<00:06, 189.27it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2073/3257 [00:11<00:06, 188.33it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2094/3257 [00:11<00:06, 191.76it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2114/3257 [00:11<00:05, 191.99it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:11<00:06, 179.47it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2153/3257 [00:11<00:06, 177.15it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2176/3257 [00:11<00:05, 190.61it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2196/3257 [00:11<00:05, 186.30it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2215/3257 [00:12<00:05, 181.69it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:12<00:05, 186.78it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2255/3257 [00:12<00:05, 182.20it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2274/3257 [00:12<00:05, 173.35it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2298/3257 [00:12<00:05, 190.48it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2319/3257 [00:12<00:04, 195.10it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2343/3257 [00:12<00:04, 205.19it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2367/3257 [00:12<00:04, 210.28it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2390/3257 [00:12<00:04, 214.31it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2412/3257 [00:13<00:04, 204.53it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2433/3257 [00:13<00:04, 194.56it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2453/3257 [00:13<00:04, 191.81it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:13<00:03, 202.05it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2499/3257 [00:13<00:03, 209.49it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2522/3257 [00:13<00:03, 215.27it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2544/3257 [00:13<00:03, 212.01it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2566/3257 [00:13<00:03, 195.80it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:13<00:03, 190.35it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2610/3257 [00:13<00:03, 202.00it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:14<00:02, 211.98it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:14<00:02, 204.76it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2677/3257 [00:14<00:02, 197.65it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2697/3257 [00:14<00:02, 193.52it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2717/3257 [00:14<00:03, 175.63it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:14<00:02, 191.99it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:14<00:02, 190.39it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2781/3257 [00:14<00:02, 190.58it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:14<00:02, 197.63it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:15<00:02, 192.49it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2843/3257 [00:15<00:02, 181.19it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2870/3257 [00:15<00:01, 203.96it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2891/3257 [00:15<00:03, 120.86it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2908/3257 [00:15<00:02, 128.45it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2929/3257 [00:15<00:02, 143.44it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:16<00:02, 148.78it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2967/3257 [00:16<00:01, 158.88it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:16<00:01, 157.59it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3007/3257 [00:16<00:01, 172.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:16<00:01, 172.53it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:16<00:01, 183.52it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3071/3257 [00:16<00:00, 194.31it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3091/3257 [00:16<00:00, 190.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3115/3257 [00:16<00:00, 204.71it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3136/3257 [00:16<00:00, 197.64it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3157/3257 [00:17<00:00, 189.39it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3177/3257 [00:17<00:00, 180.75it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3197/3257 [00:17<00:00, 183.68it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3216/3257 [00:17<00:00, 176.33it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3238/3257 [00:17<00:00, 185.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 186.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 184.60it/s]
2023-02-07 21:00:07.325 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 21:00:07,327][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d115,n5,mc4,s0.216014,t4>', 'datetime': '2023-02-07T21:00:07.326953', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 21:00:07,327][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 21:00:07,327][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 21:00:07,777][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 21:00:07,777][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 21:00:07,818][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 retains 14837 unique words (68.38% of original 21699, drops 6862)', 'datetime': '2023-02-07T21:00:07.818204', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 21:00:07,818][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 leaves 4356054 word corpus (99.74% of original 4367244, drops 11190)', 'datetime': '2023-02-07T21:00:07.818640', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 21:00:07,869][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 21:00:07,870][gensim.models.word2vec][INFO] - sample=0.216014 downsamples 0 most-common words
[2023-02-07 21:00:07,870][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4356054 word corpus (100.0%% of prior 4356054)', 'datetime': '2023-02-07T21:00:07.870802', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 21:00:07,965][gensim.models.word2vec][INFO] - estimated required memory for 14837 words and 115 dimensions: 23218160 bytes
[2023-02-07 21:00:07,965][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 21:00:07,975][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14837 vocabulary and 115 features, using sg=1 hs=0 sample=0.2160137444537071 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T21:00:07.975729', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 21:00:08,978][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 56.34% examples, 2519592 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:00:09,693][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4357583 effective words) took 1.7s, 2540812 effective words/s
[2023-02-07 21:00:10,696][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 61.96% examples, 2739699 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:00:11,280][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4357583 effective words) took 1.6s, 2748667 effective words/s
[2023-02-07 21:00:12,284][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 61.68% examples, 2727284 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:00:12,867][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4357583 effective words) took 1.6s, 2749157 effective words/s
[2023-02-07 21:00:13,873][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 61.68% examples, 2719000 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:00:14,455][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4357583 effective words) took 1.6s, 2746539 effective words/s
[2023-02-07 21:00:15,459][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 61.68% examples, 2724725 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:00:16,042][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4357583 effective words) took 1.6s, 2748174 effective words/s
[2023-02-07 21:00:17,043][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 62.85% examples, 2785470 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:00:17,597][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4357583 effective words) took 1.6s, 2803997 effective words/s
[2023-02-07 21:00:18,604][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 62.57% examples, 2754724 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:00:19,164][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4357583 effective words) took 1.6s, 2784301 effective words/s
[2023-02-07 21:00:20,168][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 49.22% examples, 2183444 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:00:21,168][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4357583 effective words) took 2.0s, 2176341 effective words/s
[2023-02-07 21:00:22,179][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 62.57% examples, 2742021 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:00:22,752][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4357583 effective words) took 1.6s, 2753762 effective words/s
[2023-02-07 21:00:23,760][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 62.57% examples, 2747959 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:00:24,333][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4357583 effective words) took 1.6s, 2758419 effective words/s
[2023-02-07 21:00:25,336][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 62.60% examples, 2766250 words/s, in_qsize 7, out_qsize 2
[2023-02-07 21:00:25,892][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4357583 effective words) took 1.6s, 2797063 effective words/s
[2023-02-07 21:00:26,897][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 63.31% examples, 2805559 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:00:27,437][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4357583 effective words) took 1.5s, 2825356 effective words/s
[2023-02-07 21:00:28,439][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 63.80% examples, 2830518 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:00:28,985][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4357583 effective words) took 1.5s, 2818630 effective words/s
[2023-02-07 21:00:29,987][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 63.19% examples, 2800866 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:00:30,544][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4357583 effective words) took 1.6s, 2796716 effective words/s
[2023-02-07 21:00:31,546][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 62.60% examples, 2768952 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:00:32,103][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4357583 effective words) took 1.6s, 2798452 effective words/s
[2023-02-07 21:00:32,104][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65363745 effective words) took 24.1s, 2709072 effective words/s', 'datetime': '2023-02-07T21:00:32.103959', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 21:00:32.104 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 21:00:34,468][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205940-k5ct8zj7/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T21:00:34.468280', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 21:00:34,469][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 21:00:34,504][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_205940-k5ct8zj7/files/../tmp/embedding_model.pt
2023-02-07 21:00:34.505 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 21:00:35.762 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 21:00:36.269 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 21:00:43.910 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9525231061352902, 'test_mae': 0.7494085314540775, 'test_r2': -1.9510844152090296}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.58
wandb: percentage 0.31624
wandb:   test_mae 0.74941
wandb:   test_mse 0.95252
wandb:    test_r2 -1.95108
wandb: 
wandb: üöÄ View run helpful-sweep-99 at: https://wandb.ai/xiaoqiz/mof2vec/runs/k5ct8zj7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_205940-k5ct8zj7/logs
wandb: Agent Starting Run: 2quqj4xy with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 864
wandb: 	model.gensim.alpha: 0.0017106732432739633
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.48847178946019354
wandb: 	model.gensim.vector_size: 425
wandb: 	model.gensim.window: 5
wandb: 	model.sklearn.learning_rate: 0.07840875865687051
wandb: 	model.sklearn.max_depth: 33
wandb: 	model.sklearn.min_child_weight: 0.09062530130465855
wandb: 	model.sklearn.n_estimators: 2684
wandb: 	model.sklearn.num_leaves: 203
wandb: 	model.sklearn.reg_alpha: 0.0067148859777268225
wandb: 	model.sklearn.reg_lambda: 0.050022306619493466
wandb: 	model.sklearn.subsample: 0.26279211105878214
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_210055-2quqj4xy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-100
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/xx96mndu
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/2quqj4xy
2023-02-07 21:01:03.134 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 21:01:03.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 864 for sweep.
2023-02-07 21:01:03.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0017106732432739633 for sweep.
2023-02-07 21:01:03.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 21:01:03.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 21:01:03.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.48847178946019354 for sweep.
2023-02-07 21:01:03.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 425 for sweep.
2023-02-07 21:01:03.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 5 for sweep.
2023-02-07 21:01:03.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.07840875865687051 for sweep.
2023-02-07 21:01:03.137 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 33 for sweep.
2023-02-07 21:01:03.137 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09062530130465855 for sweep.
2023-02-07 21:01:03.137 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2684 for sweep.
2023-02-07 21:01:03.137 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 203 for sweep.
2023-02-07 21:01:03.138 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0067148859777268225 for sweep.
2023-02-07 21:01:03.138 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.050022306619493466 for sweep.
2023-02-07 21:01:03.138 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.26279211105878214 for sweep.
2023-02-07 21:01:03.138 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 21:01:03.144 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'qmof, bandgap, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_210055-2quqj4xy/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 864, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 425, 'window': 5, 'min_count': 2, 'dm': 0, 'sample': 0.48847178946019354, 'workers': 4, 'alpha': 0.0017106732432739633, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2684, 'max_depth': 33, 'num_leaves': 203, 'reg_alpha': 0.0067148859777268225, 'reg_lambda': 0.050022306619493466, 'subsample': 0.26279211105878214, 'min_child_weight': 0.09062530130465855, 'n_jobs': 4, 'learning_rate': 0.07840875865687051}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 20/3257 [00:00<00:16, 197.86it/s]  1%|‚ñè         | 41/3257 [00:00<00:15, 201.85it/s]  2%|‚ñè         | 64/3257 [00:00<00:14, 213.83it/s]  3%|‚ñé         | 87/3257 [00:00<00:14, 219.29it/s]  3%|‚ñé         | 109/3257 [00:00<00:15, 200.26it/s]  4%|‚ñç         | 133/3257 [00:00<00:14, 211.54it/s]  5%|‚ñç         | 158/3257 [00:00<00:14, 216.77it/s]  6%|‚ñå         | 180/3257 [00:00<00:14, 208.97it/s]  6%|‚ñå         | 203/3257 [00:00<00:14, 213.24it/s]  7%|‚ñã         | 230/3257 [00:01<00:13, 229.58it/s]  8%|‚ñä         | 254/3257 [00:01<00:13, 223.38it/s]  9%|‚ñä         | 277/3257 [00:01<00:13, 224.46it/s]  9%|‚ñâ         | 300/3257 [00:01<00:13, 221.25it/s] 10%|‚ñâ         | 325/3257 [00:01<00:12, 227.95it/s] 11%|‚ñà         | 348/3257 [00:01<00:13, 213.30it/s] 11%|‚ñà‚ñè        | 373/3257 [00:01<00:13, 219.70it/s] 12%|‚ñà‚ñè        | 396/3257 [00:01<00:13, 207.62it/s] 13%|‚ñà‚ñé        | 420/3257 [00:01<00:13, 211.74it/s] 14%|‚ñà‚ñé        | 442/3257 [00:02<00:14, 192.08it/s] 14%|‚ñà‚ñç        | 465/3257 [00:02<00:13, 201.29it/s] 15%|‚ñà‚ñç        | 486/3257 [00:02<00:13, 203.02it/s] 16%|‚ñà‚ñå        | 510/3257 [00:02<00:12, 211.84it/s] 16%|‚ñà‚ñã        | 532/3257 [00:02<00:13, 207.64it/s] 17%|‚ñà‚ñã        | 555/3257 [00:02<00:12, 212.81it/s] 18%|‚ñà‚ñä        | 577/3257 [00:02<00:13, 192.16it/s] 18%|‚ñà‚ñä        | 602/3257 [00:02<00:12, 206.37it/s] 19%|‚ñà‚ñâ        | 624/3257 [00:02<00:12, 204.99it/s] 20%|‚ñà‚ñâ        | 646/3257 [00:03<00:12, 207.94it/s] 21%|‚ñà‚ñà        | 668/3257 [00:03<00:12, 204.05it/s] 21%|‚ñà‚ñà        | 689/3257 [00:03<00:12, 204.73it/s] 22%|‚ñà‚ñà‚ñè       | 713/3257 [00:03<00:11, 213.94it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:03<00:12, 210.09it/s] 23%|‚ñà‚ñà‚ñé       | 757/3257 [00:03<00:12, 206.89it/s] 24%|‚ñà‚ñà‚ñç       | 779/3257 [00:03<00:11, 208.94it/s] 25%|‚ñà‚ñà‚ñç       | 803/3257 [00:03<00:11, 216.28it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:04<00:18, 129.10it/s] 26%|‚ñà‚ñà‚ñå       | 843/3257 [00:04<00:17, 138.37it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:04<00:15, 153.84it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:04<00:14, 159.09it/s] 28%|‚ñà‚ñà‚ñä       | 908/3257 [00:04<00:13, 177.90it/s] 29%|‚ñà‚ñà‚ñä       | 930/3257 [00:04<00:12, 186.28it/s] 29%|‚ñà‚ñà‚ñâ       | 951/3257 [00:04<00:12, 189.48it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:04<00:11, 193.05it/s] 30%|‚ñà‚ñà‚ñà       | 993/3257 [00:04<00:11, 195.61it/s] 31%|‚ñà‚ñà‚ñà       | 1014/3257 [00:05<00:11, 197.09it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1035/3257 [00:05<00:11, 195.94it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1055/3257 [00:05<00:11, 193.72it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:05<00:11, 196.65it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1102/3257 [00:05<00:10, 201.43it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:05<00:10, 199.88it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:05<00:10, 200.14it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1167/3257 [00:05<00:10, 207.06it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:05<00:11, 184.71it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:06<00:11, 184.06it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:06<00:10, 198.67it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1253/3257 [00:06<00:10, 198.38it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1274/3257 [00:06<00:09, 201.40it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1295/3257 [00:06<00:10, 190.83it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1319/3257 [00:06<00:09, 202.63it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1342/3257 [00:06<00:09, 210.27it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:06<00:09, 205.70it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:06<00:09, 197.55it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1409/3257 [00:07<00:08, 209.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:07<00:08, 214.67it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1457/3257 [00:07<00:08, 224.81it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1480/3257 [00:07<00:08, 220.56it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1505/3257 [00:07<00:07, 228.13it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1528/3257 [00:07<00:08, 211.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:07<00:08, 204.69it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1572/3257 [00:07<00:08, 207.62it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1593/3257 [00:07<00:08, 207.34it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:08<00:07, 212.13it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:08<00:07, 208.01it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1660/3257 [00:08<00:07, 206.97it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1681/3257 [00:08<00:07, 198.90it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1702/3257 [00:08<00:07, 200.46it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:08<00:07, 201.32it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:08<00:08, 186.40it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1766/3257 [00:08<00:07, 195.32it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1788/3257 [00:08<00:07, 200.20it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1809/3257 [00:09<00:07, 194.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1829/3257 [00:09<00:07, 194.04it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1851/3257 [00:09<00:07, 200.38it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1874/3257 [00:09<00:06, 208.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:09<00:06, 203.84it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:09<00:06, 204.44it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1940/3257 [00:09<00:06, 212.17it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:09<00:05, 221.83it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1988/3257 [00:09<00:06, 209.13it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2011/3257 [00:09<00:05, 213.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:10<00:05, 218.85it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2058/3257 [00:10<00:08, 133.86it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2078/3257 [00:10<00:08, 146.00it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2098/3257 [00:10<00:07, 156.67it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:10<00:06, 166.56it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2139/3257 [00:10<00:06, 170.73it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2158/3257 [00:10<00:06, 175.68it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2179/3257 [00:11<00:05, 184.71it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2201/3257 [00:11<00:05, 193.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2221/3257 [00:11<00:05, 193.59it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2241/3257 [00:11<00:05, 190.92it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2262/3257 [00:11<00:05, 194.51it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2282/3257 [00:11<00:05, 194.34it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2304/3257 [00:11<00:04, 201.04it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2332/3257 [00:11<00:04, 222.27it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:11<00:03, 231.49it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2384/3257 [00:11<00:03, 231.48it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2408/3257 [00:12<00:03, 222.78it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2431/3257 [00:12<00:03, 215.56it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2453/3257 [00:12<00:03, 211.47it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2479/3257 [00:12<00:03, 223.51it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2505/3257 [00:12<00:03, 232.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2529/3257 [00:12<00:03, 230.82it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2553/3257 [00:12<00:03, 221.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2576/3257 [00:12<00:03, 209.45it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2598/3257 [00:12<00:03, 209.29it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2627/3257 [00:13<00:02, 229.58it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2651/3257 [00:13<00:02, 219.60it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2674/3257 [00:13<00:02, 216.97it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2696/3257 [00:13<00:02, 212.54it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2718/3257 [00:13<00:02, 196.86it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2744/3257 [00:13<00:02, 213.35it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2766/3257 [00:13<00:02, 214.12it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2789/3257 [00:13<00:02, 217.46it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2811/3257 [00:13<00:02, 215.35it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:14<00:02, 205.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2857/3257 [00:14<00:01, 214.81it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:14<00:01, 231.03it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2910/3257 [00:14<00:01, 219.61it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2933/3257 [00:14<00:01, 220.17it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2956/3257 [00:14<00:01, 207.94it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2978/3257 [00:14<00:01, 208.72it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3002/3257 [00:14<00:01, 216.36it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3024/3257 [00:14<00:01, 208.99it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:15<00:00, 218.85it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:15<00:00, 230.31it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3099/3257 [00:15<00:00, 225.52it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3124/3257 [00:15<00:00, 229.95it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3148/3257 [00:15<00:00, 215.30it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3170/3257 [00:15<00:00, 212.62it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3192/3257 [00:15<00:00, 209.39it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3214/3257 [00:15<00:00, 200.06it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:15<00:00, 212.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 203.38it/s]
2023-02-07 21:01:19.665 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 21:01:19,666][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d425,n5,mc2,s0.488472,t4>', 'datetime': '2023-02-07T21:01:19.666664', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 21:01:19,667][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 21:01:19,667][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 21:01:20,007][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 21:01:20,008][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 21:01:20,038][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 11155 unique words (85.41% of original 13061, drops 1906)', 'datetime': '2023-02-07T21:01:20.038672', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 21:01:20,040][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 3637464 word corpus (99.95% of original 3639370, drops 1906)', 'datetime': '2023-02-07T21:01:20.040557', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 21:01:20,078][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 21:01:20,079][gensim.models.word2vec][INFO] - sample=0.488472 downsamples 0 most-common words
[2023-02-07 21:01:20,079][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3637464 word corpus (100.0%% of prior 3637464)', 'datetime': '2023-02-07T21:01:20.079262', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 21:01:20,148][gensim.models.word2vec][INFO] - estimated required memory for 11155 words and 425 dimensions: 49692800 bytes
[2023-02-07 21:01:20,149][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 21:01:20,179][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11155 vocabulary and 425 features, using sg=1 hs=0 sample=0.48847178946019354 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-07T21:01:20.179924', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 21:01:21,186][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 40.41% examples, 1508160 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:22,189][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 83.33% examples, 1529183 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:22,559][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3640721 effective words) took 2.4s, 1532199 effective words/s
[2023-02-07 21:01:23,561][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 43.66% examples, 1629058 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:24,563][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 89.19% examples, 1633698 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:24,792][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3640721 effective words) took 2.2s, 1631841 effective words/s
[2023-02-07 21:01:25,799][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 43.84% examples, 1630318 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:26,804][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 89.50% examples, 1630863 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:27,026][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3640721 effective words) took 2.2s, 1631535 effective words/s
[2023-02-07 21:01:28,035][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 42.65% examples, 1591647 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:29,036][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 87.23% examples, 1596207 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:01:29,299][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3640721 effective words) took 2.3s, 1602523 effective words/s
[2023-02-07 21:01:30,306][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 42.65% examples, 1597353 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:31,316][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 88.61% examples, 1609472 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:01:31,560][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3640721 effective words) took 2.3s, 1612776 effective words/s
[2023-02-07 21:01:32,563][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 42.65% examples, 1601906 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:01:33,569][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 88.61% examples, 1614715 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:33,812][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3640721 effective words) took 2.2s, 1618592 effective words/s
[2023-02-07 21:01:34,814][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 43.66% examples, 1628226 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:35,821][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 88.92% examples, 1623865 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:36,053][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3640721 effective words) took 2.2s, 1625282 effective words/s
[2023-02-07 21:01:37,056][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 42.65% examples, 1602463 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:38,061][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 88.61% examples, 1615711 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:01:38,300][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3640721 effective words) took 2.2s, 1621639 effective words/s
[2023-02-07 21:01:39,312][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 43.94% examples, 1622210 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:01:40,315][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 89.87% examples, 1632690 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:40,526][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3640721 effective words) took 2.2s, 1636534 effective words/s
[2023-02-07 21:01:41,531][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 43.02% examples, 1607817 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:01:42,538][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 88.61% examples, 1613002 words/s, in_qsize 6, out_qsize 1
[2023-02-07 21:01:42,774][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3640721 effective words) took 2.2s, 1621302 effective words/s
[2023-02-07 21:01:43,778][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 43.02% examples, 1608099 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:01:44,791][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 88.61% examples, 1607799 words/s, in_qsize 7, out_qsize 0
[2023-02-07 21:01:45,028][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3640721 effective words) took 2.3s, 1616486 effective words/s
[2023-02-07 21:01:46,032][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 48.02% examples, 1780492 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:46,976][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3640721 effective words) took 1.9s, 1869917 effective words/s
[2023-02-07 21:01:47,979][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 50.45% examples, 1871388 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:48,861][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3640721 effective words) took 1.9s, 1932708 effective words/s
[2023-02-07 21:01:49,867][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 45.56% examples, 1684227 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:50,868][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 90.02% examples, 1643407 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:51,069][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3640721 effective words) took 2.2s, 1650018 effective words/s
[2023-02-07 21:01:52,070][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 37.18% examples, 1389659 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:53,072][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 79.95% examples, 1470289 words/s, in_qsize 8, out_qsize 0
[2023-02-07 21:01:53,559][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3640721 effective words) took 2.5s, 1463016 effective words/s
[2023-02-07 21:01:53,560][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54610815 effective words) took 33.4s, 1636041 effective words/s', 'datetime': '2023-02-07T21:01:53.560317', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 21:01:53.560 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 21:01:56,059][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_210055-2quqj4xy/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T21:01:56.059733', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 21:01:56,060][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 21:01:56,132][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_210055-2quqj4xy/files/../tmp/embedding_model.pt
2023-02-07 21:01:56.132 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 21:01:58.544 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 21:01:59.394 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 21:02:14.838 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.068684271814375, 'test_mae': 0.7842167492018887, 'test_r2': -2.7923360024703583}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.39
wandb: percentage 0.14593
wandb:   test_mae 0.78422
wandb:   test_mse 1.06868
wandb:    test_r2 -2.79234
wandb: 
wandb: üöÄ View run comfy-sweep-100 at: https://wandb.ai/xiaoqiz/mof2vec/runs/2quqj4xy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_210055-2quqj4xy/logs
