2023-02-07 18:18:06.098 | DEBUG    | mofgraph2vec.trainer.sweep:sweep:19 - No sweep id provided, creating new sweep
wandb: WARNING Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.
wandb: WARNING To avoid this, please fix the sweep config schema violations below:
wandb: WARNING   Violation 1. model.sklearn.learning_rate uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.
wandb: WARNING   Violation 2. model.sklearn.reg_alpha uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.
wandb: WARNING   Violation 3. model.gensim.alpha uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.
wandb: WARNING   Violation 4. model.sklearn.reg_lambda uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.
Create sweep with ID: 5qa4vj5i
Sweep URL: https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
[2023-02-07 18:18:08,075][wandb.agents.pyagent][INFO] - Starting sweep agent: entity=None, project=None, count=100
wandb: Agent Starting Run: 7u5yghd4 with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 654
wandb: 	model.gensim.alpha: 0.0011061025527559314
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.5859646366263492
wandb: 	model.gensim.vector_size: 250
wandb: 	model.gensim.window: 7
wandb: 	model.sklearn.learning_rate: 0.09288440488943692
wandb: 	model.sklearn.max_depth: 77
wandb: 	model.sklearn.min_child_weight: 0.005151720889012623
wandb: 	model.sklearn.n_estimators: 1156
wandb: 	model.sklearn.num_leaves: 203
wandb: 	model.sklearn.reg_alpha: 0.22138791913939457
wandb: 	model.sklearn.reg_lambda: 0.04586594604597424
wandb: 	model.sklearn.subsample: 0.636216662922162
wandb: Currently logged in as: xiaoqiz. Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181810-7u5yghd4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/7u5yghd4
2023-02-07 18:18:18.467 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 18:18:18.468 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 654 for sweep.
2023-02-07 18:18:18.468 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0011061025527559314 for sweep.
2023-02-07 18:18:18.468 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:18:18.469 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 18:18:18.469 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5859646366263492 for sweep.
2023-02-07 18:18:18.469 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 250 for sweep.
2023-02-07 18:18:18.469 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 7 for sweep.
2023-02-07 18:18:18.470 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.09288440488943692 for sweep.
2023-02-07 18:18:18.470 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 77 for sweep.
2023-02-07 18:18:18.471 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.005151720889012623 for sweep.
2023-02-07 18:18:18.471 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1156 for sweep.
2023-02-07 18:18:18.471 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 203 for sweep.
2023-02-07 18:18:18.472 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.22138791913939457 for sweep.
2023-02-07 18:18:18.472 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.04586594604597424 for sweep.
2023-02-07 18:18:18.472 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.636216662922162 for sweep.
2023-02-07 18:18:18.472 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:18:18.483 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181810-7u5yghd4/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 654, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 250, 'window': 7, 'min_count': 8, 'dm': 1, 'sample': 0.5859646366263492, 'workers': 4, 'alpha': 0.0011061025527559314, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1156, 'max_depth': 77, 'num_leaves': 203, 'reg_alpha': 0.22138791913939457, 'reg_lambda': 0.04586594604597424, 'subsample': 0.636216662922162, 'min_child_weight': 0.005151720889012623, 'n_jobs': 4, 'learning_rate': 0.09288440488943692}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:20, 160.39it/s]  1%|          | 39/3257 [00:00<00:16, 191.74it/s]  2%|‚ñè         | 59/3257 [00:00<00:16, 191.04it/s]  3%|‚ñé         | 83/3257 [00:00<00:15, 207.96it/s]  3%|‚ñé         | 104/3257 [00:00<00:15, 205.65it/s]  4%|‚ñç         | 125/3257 [00:00<00:24, 127.36it/s]  5%|‚ñç         | 152/3257 [00:00<00:19, 159.33it/s]  5%|‚ñå         | 177/3257 [00:01<00:17, 180.82it/s]  6%|‚ñã         | 205/3257 [00:01<00:14, 205.42it/s]  7%|‚ñã         | 237/3257 [00:01<00:12, 233.24it/s]  8%|‚ñä         | 266/3257 [00:01<00:12, 247.30it/s]  9%|‚ñâ         | 298/3257 [00:01<00:11, 265.46it/s] 10%|‚ñà         | 328/3257 [00:01<00:10, 271.23it/s] 11%|‚ñà         | 358/3257 [00:01<00:10, 277.94it/s] 12%|‚ñà‚ñè        | 387/3257 [00:01<00:10, 262.51it/s] 13%|‚ñà‚ñé        | 417/3257 [00:01<00:10, 271.07it/s] 14%|‚ñà‚ñé        | 445/3257 [00:02<00:11, 240.06it/s] 15%|‚ñà‚ñç        | 473/3257 [00:02<00:11, 248.89it/s] 15%|‚ñà‚ñå        | 499/3257 [00:02<00:11, 250.45it/s] 16%|‚ñà‚ñå        | 526/3257 [00:02<00:10, 250.57it/s] 17%|‚ñà‚ñã        | 553/3257 [00:02<00:10, 254.21it/s] 18%|‚ñà‚ñä        | 579/3257 [00:02<00:11, 231.89it/s] 19%|‚ñà‚ñä        | 604/3257 [00:02<00:11, 236.65it/s] 19%|‚ñà‚ñâ        | 630/3257 [00:02<00:10, 242.12it/s] 20%|‚ñà‚ñà        | 655/3257 [00:02<00:11, 231.96it/s] 21%|‚ñà‚ñà        | 680/3257 [00:02<00:10, 235.61it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:03<00:10, 232.17it/s] 22%|‚ñà‚ñà‚ñè       | 728/3257 [00:03<00:10, 230.37it/s] 23%|‚ñà‚ñà‚ñé       | 752/3257 [00:03<00:11, 227.52it/s] 24%|‚ñà‚ñà‚ñç       | 777/3257 [00:03<00:10, 232.57it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:03<00:10, 241.10it/s] 25%|‚ñà‚ñà‚ñå       | 829/3257 [00:03<00:10, 235.41it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:03<00:10, 229.69it/s] 27%|‚ñà‚ñà‚ñã       | 877/3257 [00:03<00:10, 232.54it/s] 28%|‚ñà‚ñà‚ñä       | 903/3257 [00:03<00:09, 240.04it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:04<00:10, 229.96it/s] 29%|‚ñà‚ñà‚ñâ       | 952/3257 [00:04<00:10, 222.20it/s] 30%|‚ñà‚ñà‚ñâ       | 975/3257 [00:04<00:10, 220.64it/s] 31%|‚ñà‚ñà‚ñà       | 998/3257 [00:04<00:10, 206.38it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1019/3257 [00:04<00:10, 204.55it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1040/3257 [00:04<00:11, 193.66it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1060/3257 [00:04<00:11, 194.72it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:04<00:11, 194.07it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1102/3257 [00:04<00:10, 199.83it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:05<00:10, 196.76it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:05<00:10, 194.93it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1166/3257 [00:05<00:10, 202.97it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:05<00:10, 190.38it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:05<00:11, 181.64it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:05<00:10, 195.66it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1252/3257 [00:05<00:10, 191.59it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:05<00:10, 193.50it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:05<00:10, 183.04it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1311/3257 [00:06<00:16, 118.37it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1332/3257 [00:06<00:14, 136.27it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1353/3257 [00:06<00:12, 151.86it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1372/3257 [00:06<00:11, 160.04it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1392/3257 [00:06<00:11, 169.26it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1419/3257 [00:06<00:09, 195.55it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1440/3257 [00:06<00:09, 195.73it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1466/3257 [00:06<00:08, 212.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1489/3257 [00:07<00:08, 215.49it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1514/3257 [00:07<00:07, 224.43it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1537/3257 [00:07<00:07, 221.72it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1564/3257 [00:07<00:07, 235.45it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:07<00:06, 244.68it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1621/3257 [00:07<00:06, 259.23it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1648/3257 [00:07<00:06, 255.55it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:07<00:06, 253.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1702/3257 [00:07<00:05, 259.34it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:08<00:06, 252.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1755/3257 [00:08<00:05, 251.18it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1784/3257 [00:08<00:05, 262.00it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1811/3257 [00:08<00:05, 250.20it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1838/3257 [00:08<00:05, 253.75it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1867/3257 [00:08<00:05, 263.25it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1894/3257 [00:08<00:05, 255.25it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1920/3257 [00:08<00:05, 251.71it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:08<00:04, 275.17it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:08<00:04, 269.07it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2010/3257 [00:09<00:04, 264.66it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2038/3257 [00:09<00:04, 264.57it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2065/3257 [00:09<00:04, 240.97it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2093/3257 [00:09<00:04, 249.98it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2119/3257 [00:09<00:04, 248.10it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2145/3257 [00:09<00:04, 226.64it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2175/3257 [00:09<00:04, 244.72it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2201/3257 [00:09<00:04, 244.23it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2226/3257 [00:09<00:04, 241.29it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2252/3257 [00:10<00:04, 244.25it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2277/3257 [00:10<00:04, 224.00it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:10<00:04, 224.86it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2327/3257 [00:10<00:03, 233.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2355/3257 [00:10<00:03, 245.95it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2380/3257 [00:10<00:03, 238.10it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2405/3257 [00:10<00:03, 233.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2429/3257 [00:10<00:03, 228.54it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2452/3257 [00:11<00:03, 215.22it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2479/3257 [00:11<00:03, 228.33it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:11<00:03, 238.68it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2533/3257 [00:11<00:02, 244.21it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2558/3257 [00:11<00:03, 230.59it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2582/3257 [00:11<00:03, 218.29it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2605/3257 [00:11<00:02, 218.10it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:11<00:02, 235.20it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2658/3257 [00:11<00:02, 222.94it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2682/3257 [00:11<00:02, 227.17it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2705/3257 [00:12<00:04, 120.27it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2726/3257 [00:12<00:03, 135.92it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2752/3257 [00:12<00:03, 159.70it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2773/3257 [00:12<00:02, 168.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2800/3257 [00:12<00:02, 191.38it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:12<00:02, 195.57it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2845/3257 [00:13<00:02, 194.35it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2874/3257 [00:13<00:01, 219.06it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2898/3257 [00:13<00:01, 215.34it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2923/3257 [00:13<00:01, 224.55it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:13<00:01, 221.71it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:13<00:01, 236.00it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3008/3257 [00:13<00:00, 257.46it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3038/3257 [00:13<00:00, 268.83it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3072/3257 [00:13<00:00, 288.52it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3104/3257 [00:13<00:00, 296.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3135/3257 [00:14<00:00, 296.95it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:14<00:00, 290.28it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3197/3257 [00:14<00:00, 292.23it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3227/3257 [00:14<00:00, 292.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:14<00:00, 224.47it/s]
2023-02-07 18:18:34.611 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:18:34,636][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d250,n5,w7,mc8,s0.585965,t4>', 'datetime': '2023-02-07T18:18:34.612426', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:18:34,637][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:18:34,637][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:18:34,955][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 18:18:34,955][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:18:34,971][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 5936 unique words (45.45% of original 13061, drops 7125)', 'datetime': '2023-02-07T18:18:34.971585', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:18:34,971][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 3618620 word corpus (99.43% of original 3639370, drops 20750)', 'datetime': '2023-02-07T18:18:34.971928', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:18:34,991][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 18:18:34,992][gensim.models.word2vec][INFO] - sample=0.585965 downsamples 0 most-common words
[2023-02-07 18:18:34,992][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3618620 word corpus (100.0%% of prior 3618620)', 'datetime': '2023-02-07T18:18:34.992533', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:18:35,028][gensim.models.word2vec][INFO] - estimated required memory for 5936 words and 250 dimensions: 18748400 bytes
[2023-02-07 18:18:35,028][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:18:35,037][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 5936 vocabulary and 250 features, using sg=0 hs=0 sample=0.5859646366263492 negative=5 window=7 shrink_windows=True', 'datetime': '2023-02-07T18:18:35.037912', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:18:36,040][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 38.72% examples, 1433817 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:37,045][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 81.98% examples, 1493026 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:37,447][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3621877 effective words) took 2.4s, 1504412 effective words/s
[2023-02-07 18:18:38,456][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 42.65% examples, 1584467 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:39,458][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 87.23% examples, 1587909 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:39,721][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3621877 effective words) took 2.3s, 1594103 effective words/s
[2023-02-07 18:18:40,727][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 42.22% examples, 1569722 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:41,736][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 88.61% examples, 1601409 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:41,974][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3621877 effective words) took 2.3s, 1609081 effective words/s
[2023-02-07 18:18:42,978][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 43.84% examples, 1624570 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:18:43,981][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 90.42% examples, 1644052 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:44,182][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3621877 effective words) took 2.2s, 1640883 effective words/s
[2023-02-07 18:18:45,187][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 44.43% examples, 1643572 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:18:46,202][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 91.65% examples, 1658413 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:18:46,354][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3621877 effective words) took 2.2s, 1669061 effective words/s
[2023-02-07 18:18:47,359][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 46.18% examples, 1697183 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:48,361][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 94.69% examples, 1714851 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:48,467][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3621877 effective words) took 2.1s, 1715258 effective words/s
[2023-02-07 18:18:49,475][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 46.64% examples, 1709802 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:50,477][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 90.42% examples, 1642801 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:50,687][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3621877 effective words) took 2.2s, 1632927 effective words/s
[2023-02-07 18:18:51,701][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 42.65% examples, 1576836 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:18:52,710][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 87.23% examples, 1578035 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:18:52,979][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3621877 effective words) took 2.3s, 1581172 effective words/s
[2023-02-07 18:18:53,986][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 40.96% examples, 1519491 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:54,987][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 85.20% examples, 1555323 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:18:55,302][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3621877 effective words) took 2.3s, 1561067 effective words/s
[2023-02-07 18:18:56,305][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 42.03% examples, 1565362 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:18:57,308][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 86.52% examples, 1578065 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:57,598][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3621877 effective words) took 2.3s, 1579348 effective words/s
[2023-02-07 18:18:58,600][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 43.84% examples, 1628807 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:18:59,607][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 98.62% examples, 1781499 words/s, in_qsize 5, out_qsize 0
[2023-02-07 18:18:59,633][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3621877 effective words) took 2.0s, 1781168 effective words/s
[2023-02-07 18:19:00,637][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 46.55% examples, 1708820 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:01,637][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 93.09% examples, 1693455 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:01,772][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3621877 effective words) took 2.1s, 1694511 effective words/s
[2023-02-07 18:19:02,780][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 45.07% examples, 1655103 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:03,783][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 93.74% examples, 1697146 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:03,915][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3621877 effective words) took 2.1s, 1691194 effective words/s
[2023-02-07 18:19:04,918][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 46.55% examples, 1709960 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:05,918][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 94.11% examples, 1708184 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:06,040][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3621877 effective words) took 2.1s, 1705867 effective words/s
[2023-02-07 18:19:07,045][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 45.56% examples, 1678627 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:08,056][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 94.11% examples, 1697432 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:19:08,168][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3621877 effective words) took 2.1s, 1702998 effective words/s
[2023-02-07 18:19:08,168][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54328155 effective words) took 33.1s, 1639825 effective words/s', 'datetime': '2023-02-07T18:19:08.168759', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:19:08.169 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:19:10,585][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181810-7u5yghd4/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:19:10.585655', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:19:10,586][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:19:10,619][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181810-7u5yghd4/files/../tmp/embedding_model.pt
2023-02-07 18:19:10.619 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:19:12.328 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:19:12.917 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:19:14.777 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1018516740407425, 'test_mae': 0.8015688124335617, 'test_r2': -2.652963619513823}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.23
wandb: percentage 0.54552
wandb:   test_mae 0.80157
wandb:   test_mse 1.10185
wandb:    test_r2 -2.65296
wandb: 
wandb: üöÄ View run jolly-sweep-1 at: https://wandb.ai/xiaoqiz/mof2vec/runs/7u5yghd4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_181810-7u5yghd4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xsrnfmwf with config:
wandb: 	data.data.wl_step: 3
wandb: 	data.nn.batch_size: 609
wandb: 	model.gensim.alpha: 0.0008093771177201213
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.6319003777579448
wandb: 	model.gensim.vector_size: 341
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.0252726968427855
wandb: 	model.sklearn.max_depth: 50
wandb: 	model.sklearn.min_child_weight: 0.03811214182683246
wandb: 	model.sklearn.n_estimators: 4839
wandb: 	model.sklearn.num_leaves: 328
wandb: 	model.sklearn.reg_alpha: 0.0931553924834789
wandb: 	model.sklearn.reg_lambda: 0.007329787469816276
wandb: 	model.sklearn.subsample: 0.8775987428611798
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181935-xsrnfmwf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/xsrnfmwf
2023-02-07 18:19:43.403 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 3 for sweep.
2023-02-07 18:19:43.403 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 609 for sweep.
2023-02-07 18:19:43.403 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0008093771177201213 for sweep.
2023-02-07 18:19:43.404 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:19:43.404 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 18:19:43.404 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6319003777579448 for sweep.
2023-02-07 18:19:43.404 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 341 for sweep.
2023-02-07 18:19:43.405 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 18:19:43.405 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0252726968427855 for sweep.
2023-02-07 18:19:43.405 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 50 for sweep.
2023-02-07 18:19:43.405 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03811214182683246 for sweep.
2023-02-07 18:19:43.405 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4839 for sweep.
2023-02-07 18:19:43.406 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 328 for sweep.
2023-02-07 18:19:43.406 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0931553924834789 for sweep.
2023-02-07 18:19:43.406 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.007329787469816276 for sweep.
2023-02-07 18:19:43.406 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8775987428611798 for sweep.
2023-02-07 18:19:43.406 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:19:43.411 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 3}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181935-xsrnfmwf/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 609, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 341, 'window': 11, 'min_count': 3, 'dm': 0, 'sample': 0.6319003777579448, 'workers': 4, 'alpha': 0.0008093771177201213, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4839, 'max_depth': 50, 'num_leaves': 328, 'reg_alpha': 0.0931553924834789, 'reg_lambda': 0.007329787469816276, 'subsample': 0.8775987428611798, 'min_child_weight': 0.03811214182683246, 'n_jobs': 4, 'learning_rate': 0.0252726968427855}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 32/3257 [00:00<00:10, 317.94it/s]  2%|‚ñè         | 66/3257 [00:00<00:09, 329.39it/s]  3%|‚ñé         | 100/3257 [00:00<00:09, 333.02it/s]  4%|‚ñç         | 134/3257 [00:00<00:09, 332.56it/s]  5%|‚ñå         | 170/3257 [00:00<00:09, 339.80it/s]  6%|‚ñã         | 205/3257 [00:00<00:08, 342.65it/s]  7%|‚ñã         | 244/3257 [00:00<00:08, 355.09it/s]  9%|‚ñä         | 280/3257 [00:00<00:08, 356.07it/s] 10%|‚ñâ         | 316/3257 [00:00<00:08, 340.76it/s] 11%|‚ñà         | 351/3257 [00:01<00:08, 339.38it/s] 12%|‚ñà‚ñè        | 386/3257 [00:01<00:08, 321.86it/s] 13%|‚ñà‚ñé        | 420/3257 [00:01<00:08, 326.43it/s] 14%|‚ñà‚ñç        | 453/3257 [00:01<00:09, 300.80it/s] 15%|‚ñà‚ñç        | 485/3257 [00:01<00:09, 306.05it/s] 16%|‚ñà‚ñå        | 520/3257 [00:01<00:08, 317.34it/s] 17%|‚ñà‚ñã        | 553/3257 [00:01<00:08, 309.94it/s] 18%|‚ñà‚ñä        | 585/3257 [00:01<00:09, 288.68it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:01<00:08, 295.72it/s] 20%|‚ñà‚ñâ        | 651/3257 [00:02<00:08, 297.90it/s] 21%|‚ñà‚ñà        | 682/3257 [00:02<00:12, 205.56it/s] 22%|‚ñà‚ñà‚ñè       | 711/3257 [00:02<00:11, 222.04it/s] 23%|‚ñà‚ñà‚ñé       | 737/3257 [00:02<00:10, 230.01it/s] 24%|‚ñà‚ñà‚ñé       | 769/3257 [00:02<00:09, 251.68it/s] 24%|‚ñà‚ñà‚ñç       | 797/3257 [00:02<00:09, 256.31it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:02<00:09, 256.68it/s] 26%|‚ñà‚ñà‚ñå       | 852/3257 [00:02<00:09, 257.68it/s] 27%|‚ñà‚ñà‚ñã       | 880/3257 [00:03<00:09, 263.64it/s] 28%|‚ñà‚ñà‚ñä       | 912/3257 [00:03<00:08, 278.99it/s] 29%|‚ñà‚ñà‚ñâ       | 941/3257 [00:03<00:08, 274.98it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:03<00:08, 283.88it/s] 31%|‚ñà‚ñà‚ñà       | 1001/3257 [00:03<00:07, 284.24it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1030/3257 [00:03<00:08, 276.73it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1058/3257 [00:03<00:08, 274.70it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:03<00:07, 281.44it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:03<00:07, 282.77it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1146/3257 [00:03<00:07, 271.60it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1176/3257 [00:04<00:07, 278.46it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:04<00:07, 258.28it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1237/3257 [00:04<00:07, 276.95it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1266/3257 [00:04<00:07, 278.84it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1295/3257 [00:04<00:07, 262.62it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:04<00:06, 275.74it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1358/3257 [00:04<00:06, 280.29it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1387/3257 [00:04<00:06, 270.44it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:04<00:06, 291.40it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:05<00:06, 290.94it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1485/3257 [00:05<00:05, 299.59it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1519/3257 [00:05<00:05, 303.24it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:05<00:05, 289.18it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1580/3257 [00:05<00:05, 283.59it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1612/3257 [00:05<00:05, 293.45it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1642/3257 [00:05<00:05, 282.63it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1671/3257 [00:05<00:05, 276.99it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1702/3257 [00:05<00:05, 285.09it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:06<00:05, 274.69it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1762/3257 [00:06<00:05, 282.58it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1793/3257 [00:06<00:05, 289.79it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1823/3257 [00:06<00:05, 286.20it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1852/3257 [00:06<00:04, 282.32it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1883/3257 [00:06<00:04, 288.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1912/3257 [00:06<00:07, 186.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1945/3257 [00:06<00:06, 214.86it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1978/3257 [00:07<00:05, 240.15it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2010/3257 [00:07<00:04, 258.48it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2040/3257 [00:07<00:04, 266.58it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2069/3257 [00:07<00:04, 263.51it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2097/3257 [00:07<00:04, 267.42it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2125/3257 [00:07<00:04, 267.01it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2153/3257 [00:07<00:04, 268.93it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2182/3257 [00:07<00:03, 273.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2212/3257 [00:07<00:03, 279.09it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2241/3257 [00:08<00:03, 280.23it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:08<00:03, 279.66it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2300/3257 [00:08<00:03, 284.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2335/3257 [00:08<00:03, 302.57it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2369/3257 [00:08<00:02, 311.72it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2403/3257 [00:08<00:02, 319.57it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2436/3257 [00:08<00:02, 295.09it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2469/3257 [00:08<00:02, 304.08it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2504/3257 [00:08<00:02, 314.09it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2539/3257 [00:08<00:02, 322.40it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:09<00:02, 300.39it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2604/3257 [00:09<00:02, 305.65it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2641/3257 [00:09<00:01, 321.17it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2674/3257 [00:09<00:01, 309.45it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2706/3257 [00:09<00:01, 293.41it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2737/3257 [00:09<00:01, 296.22it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2768/3257 [00:09<00:01, 296.95it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:09<00:01, 310.46it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2835/3257 [00:09<00:01, 291.77it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2873/3257 [00:10<00:01, 312.06it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2905/3257 [00:10<00:01, 298.21it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2937/3257 [00:10<00:01, 302.48it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2968/3257 [00:10<00:00, 296.30it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2998/3257 [00:10<00:00, 291.66it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3029/3257 [00:10<00:00, 296.79it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3065/3257 [00:10<00:00, 314.58it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3097/3257 [00:10<00:00, 313.41it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3133/3257 [00:10<00:00, 324.61it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:11<00:00, 317.20it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3198/3257 [00:11<00:00, 317.04it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3230/3257 [00:11<00:00, 195.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:11<00:00, 209.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:11<00:00, 282.47it/s]
2023-02-07 18:19:55.357 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:19:55,358][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d341,n5,mc3,s0.6319,t4>', 'datetime': '2023-02-07T18:19:55.358799', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:19:55,359][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:19:55,359][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:19:55,631][gensim.models.doc2vec][INFO] - collected 6662 word types and 3257 unique tags from a corpus of 3257 examples and 2911496 words
[2023-02-07 18:19:55,631][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:19:55,645][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 4875 unique words (73.18% of original 6662, drops 1787)', 'datetime': '2023-02-07T18:19:55.645499', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:19:55,645][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 2908813 word corpus (99.91% of original 2911496, drops 2683)', 'datetime': '2023-02-07T18:19:55.645933', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:19:55,663][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 6662 items
[2023-02-07 18:19:55,664][gensim.models.word2vec][INFO] - sample=0.6319 downsamples 0 most-common words
[2023-02-07 18:19:55,664][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2908813 word corpus (100.0%% of prior 2908813)', 'datetime': '2023-02-07T18:19:55.664460', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:19:55,693][gensim.models.word2vec][INFO] - estimated required memory for 4875 words and 341 dimensions: 20830448 bytes
[2023-02-07 18:19:55,694][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:19:55,706][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 4875 vocabulary and 341 features, using sg=1 hs=0 sample=0.6319003777579448 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T18:19:55.706286', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:19:56,721][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 55.97% examples, 1651090 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:19:57,456][gensim.models.word2vec][INFO] - EPOCH 0: training on 2911496 raw words (2912070 effective words) took 1.7s, 1667203 effective words/s
[2023-02-07 18:19:58,468][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 55.97% examples, 1654130 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:19:59,209][gensim.models.word2vec][INFO] - EPOCH 1: training on 2911496 raw words (2912070 effective words) took 1.8s, 1663143 effective words/s
[2023-02-07 18:20:00,212][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 54.44% examples, 1623594 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:00,991][gensim.models.word2vec][INFO] - EPOCH 2: training on 2911496 raw words (2912070 effective words) took 1.8s, 1636205 effective words/s
[2023-02-07 18:20:01,996][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 55.57% examples, 1657436 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:02,759][gensim.models.word2vec][INFO] - EPOCH 3: training on 2911496 raw words (2912070 effective words) took 1.8s, 1649701 effective words/s
[2023-02-07 18:20:03,768][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 54.81% examples, 1624045 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:04,428][gensim.models.word2vec][INFO] - EPOCH 4: training on 2911496 raw words (2912070 effective words) took 1.7s, 1746912 effective words/s
[2023-02-07 18:20:05,431][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 61.50% examples, 1818849 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:06,054][gensim.models.word2vec][INFO] - EPOCH 5: training on 2911496 raw words (2912070 effective words) took 1.6s, 1792833 effective words/s
[2023-02-07 18:20:07,060][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 58.46% examples, 1738506 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:20:07,714][gensim.models.word2vec][INFO] - EPOCH 6: training on 2911496 raw words (2912070 effective words) took 1.7s, 1756800 effective words/s
[2023-02-07 18:20:08,720][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 58.46% examples, 1737572 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:09,380][gensim.models.word2vec][INFO] - EPOCH 7: training on 2911496 raw words (2912070 effective words) took 1.7s, 1749494 effective words/s
[2023-02-07 18:20:10,384][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 57.66% examples, 1714425 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:11,053][gensim.models.word2vec][INFO] - EPOCH 8: training on 2911496 raw words (2912070 effective words) took 1.7s, 1742766 effective words/s
[2023-02-07 18:20:12,055][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 59.20% examples, 1763566 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:12,696][gensim.models.word2vec][INFO] - EPOCH 9: training on 2911496 raw words (2912070 effective words) took 1.6s, 1773996 effective words/s
[2023-02-07 18:20:13,698][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 60.06% examples, 1782535 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:14,312][gensim.models.word2vec][INFO] - EPOCH 10: training on 2911496 raw words (2912070 effective words) took 1.6s, 1803387 effective words/s
[2023-02-07 18:20:15,318][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 59.72% examples, 1766352 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:16,009][gensim.models.word2vec][INFO] - EPOCH 11: training on 2911496 raw words (2912070 effective words) took 1.7s, 1717935 effective words/s
[2023-02-07 18:20:17,012][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 55.39% examples, 1650887 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:20:17,778][gensim.models.word2vec][INFO] - EPOCH 12: training on 2911496 raw words (2912070 effective words) took 1.8s, 1648223 effective words/s
[2023-02-07 18:20:18,782][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 54.71% examples, 1630530 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:20:19,544][gensim.models.word2vec][INFO] - EPOCH 13: training on 2911496 raw words (2912070 effective words) took 1.8s, 1651368 effective words/s
[2023-02-07 18:20:20,564][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 54.81% examples, 1607385 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:20:21,322][gensim.models.word2vec][INFO] - EPOCH 14: training on 2911496 raw words (2912070 effective words) took 1.8s, 1640121 effective words/s
[2023-02-07 18:20:21,323][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 43672440 raw words (43681050 effective words) took 25.6s, 1705176 effective words/s', 'datetime': '2023-02-07T18:20:21.323562', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:20:21.323 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:20:23,234][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181935-xsrnfmwf/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:20:23.234857', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:20:23,235][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:20:23,274][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_181935-xsrnfmwf/files/../tmp/embedding_model.pt
2023-02-07 18:20:23.274 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:20:25.195 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:20:25.866 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:20:28.110 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1023866712924244, 'test_mae': 0.8044884954950561, 'test_r2': -3.015081973698253}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.33
wandb: percentage 0.26824
wandb:   test_mae 0.80449
wandb:   test_mse 1.10239
wandb:    test_r2 -3.01508
wandb: 
wandb: üöÄ View run misunderstood-sweep-2 at: https://wandb.ai/xiaoqiz/mof2vec/runs/xsrnfmwf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_181935-xsrnfmwf/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: womyimtc with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 701
wandb: 	model.gensim.alpha: 0.3088355722514177
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.8163586999124266
wandb: 	model.gensim.vector_size: 444
wandb: 	model.gensim.window: 9
wandb: 	model.sklearn.learning_rate: 0.04875698134938921
wandb: 	model.sklearn.max_depth: 84
wandb: 	model.sklearn.min_child_weight: 0.08543435557634271
wandb: 	model.sklearn.n_estimators: 4240
wandb: 	model.sklearn.num_leaves: 124
wandb: 	model.sklearn.reg_alpha: 0.00971965014516567
wandb: 	model.sklearn.reg_lambda: 0.10015497549750572
wandb: 	model.sklearn.subsample: 0.2228274487351481
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182057-womyimtc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/womyimtc
2023-02-07 18:21:05.777 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 18:21:05.778 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 701 for sweep.
2023-02-07 18:21:05.778 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.3088355722514177 for sweep.
2023-02-07 18:21:05.778 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:21:05.779 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 18:21:05.779 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8163586999124266 for sweep.
2023-02-07 18:21:05.779 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 444 for sweep.
2023-02-07 18:21:05.779 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 9 for sweep.
2023-02-07 18:21:05.780 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.04875698134938921 for sweep.
2023-02-07 18:21:05.780 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 84 for sweep.
2023-02-07 18:21:05.780 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08543435557634271 for sweep.
2023-02-07 18:21:05.780 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4240 for sweep.
2023-02-07 18:21:05.781 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 124 for sweep.
2023-02-07 18:21:05.781 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.00971965014516567 for sweep.
2023-02-07 18:21:05.781 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.10015497549750572 for sweep.
2023-02-07 18:21:05.781 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2228274487351481 for sweep.
2023-02-07 18:21:05.782 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:21:05.789 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182057-womyimtc/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 701, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 444, 'window': 9, 'min_count': 2, 'dm': 0, 'sample': 0.8163586999124266, 'workers': 4, 'alpha': 0.3088355722514177, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4240, 'max_depth': 84, 'num_leaves': 124, 'reg_alpha': 0.00971965014516567, 'reg_lambda': 0.10015497549750572, 'subsample': 0.2228274487351481, 'min_child_weight': 0.08543435557634271, 'n_jobs': 4, 'learning_rate': 0.04875698134938921}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 20/3257 [00:00<00:16, 197.34it/s]  1%|‚ñè         | 43/3257 [00:00<00:15, 213.89it/s]  2%|‚ñè         | 67/3257 [00:00<00:14, 213.75it/s]  3%|‚ñé         | 93/3257 [00:00<00:13, 229.85it/s]  4%|‚ñé         | 117/3257 [00:00<00:14, 221.85it/s]  4%|‚ñç         | 144/3257 [00:00<00:13, 236.52it/s]  5%|‚ñå         | 168/3257 [00:00<00:13, 229.10it/s]  6%|‚ñå         | 192/3257 [00:00<00:13, 228.41it/s]  7%|‚ñã         | 217/3257 [00:00<00:13, 232.60it/s]  7%|‚ñã         | 244/3257 [00:01<00:12, 242.45it/s]  8%|‚ñä         | 269/3257 [00:01<00:12, 234.29it/s]  9%|‚ñâ         | 298/3257 [00:01<00:11, 248.55it/s] 10%|‚ñâ         | 324/3257 [00:01<00:11, 250.09it/s] 11%|‚ñà         | 350/3257 [00:01<00:12, 239.00it/s] 12%|‚ñà‚ñè        | 375/3257 [00:01<00:12, 236.86it/s] 12%|‚ñà‚ñè        | 399/3257 [00:01<00:12, 226.78it/s] 13%|‚ñà‚ñé        | 423/3257 [00:01<00:12, 230.38it/s] 14%|‚ñà‚ñé        | 447/3257 [00:01<00:13, 205.37it/s] 15%|‚ñà‚ñç        | 473/3257 [00:02<00:12, 219.62it/s] 15%|‚ñà‚ñå        | 496/3257 [00:02<00:12, 221.61it/s] 16%|‚ñà‚ñå        | 521/3257 [00:02<00:11, 229.25it/s] 17%|‚ñà‚ñã        | 545/3257 [00:02<00:11, 229.39it/s] 17%|‚ñà‚ñã        | 569/3257 [00:02<00:12, 215.62it/s] 18%|‚ñà‚ñä        | 591/3257 [00:02<00:12, 205.97it/s] 19%|‚ñà‚ñâ        | 617/3257 [00:02<00:11, 220.47it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:02<00:12, 213.31it/s] 20%|‚ñà‚ñà        | 662/3257 [00:02<00:13, 196.42it/s] 21%|‚ñà‚ñà        | 685/3257 [00:03<00:12, 203.39it/s] 22%|‚ñà‚ñà‚ñè       | 711/3257 [00:03<00:11, 216.88it/s] 23%|‚ñà‚ñà‚ñé       | 734/3257 [00:03<00:11, 212.84it/s] 23%|‚ñà‚ñà‚ñé       | 756/3257 [00:03<00:11, 209.89it/s] 24%|‚ñà‚ñà‚ñç       | 778/3257 [00:03<00:11, 211.39it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:03<00:11, 219.97it/s] 25%|‚ñà‚ñà‚ñå       | 827/3257 [00:03<00:11, 211.56it/s] 26%|‚ñà‚ñà‚ñå       | 849/3257 [00:03<00:11, 204.83it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:03<00:11, 207.54it/s] 27%|‚ñà‚ñà‚ñã       | 892/3257 [00:04<00:11, 206.03it/s] 28%|‚ñà‚ñà‚ñä       | 915/3257 [00:04<00:11, 209.21it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:04<00:10, 217.79it/s] 30%|‚ñà‚ñà‚ñâ       | 964/3257 [00:04<00:10, 223.84it/s] 30%|‚ñà‚ñà‚ñà       | 987/3257 [00:04<00:10, 218.49it/s] 31%|‚ñà‚ñà‚ñà       | 1009/3257 [00:04<00:10, 213.22it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1031/3257 [00:04<00:10, 214.58it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1053/3257 [00:04<00:10, 209.08it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:05<00:15, 138.39it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1103/3257 [00:05<00:13, 156.41it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:05<00:12, 166.24it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1145/3257 [00:05<00:12, 174.26it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:05<00:11, 188.95it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:05<00:11, 180.87it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1212/3257 [00:05<00:11, 185.47it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1240/3257 [00:05<00:09, 209.40it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:05<00:09, 209.43it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1284/3257 [00:06<00:09, 199.12it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:06<00:09, 206.17it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1332/3257 [00:06<00:08, 214.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:06<00:08, 212.46it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1377/3257 [00:06<00:08, 217.17it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1401/3257 [00:06<00:08, 221.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1429/3257 [00:06<00:07, 237.10it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1456/3257 [00:06<00:07, 244.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1481/3257 [00:06<00:07, 231.60it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1505/3257 [00:07<00:07, 229.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1529/3257 [00:07<00:08, 204.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1551/3257 [00:07<00:08, 194.23it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1571/3257 [00:07<00:08, 191.56it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:07<00:08, 188.45it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1612/3257 [00:07<00:08, 193.80it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1632/3257 [00:07<00:08, 194.19it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1652/3257 [00:07<00:09, 175.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1670/3257 [00:08<00:09, 174.37it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1688/3257 [00:08<00:09, 173.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:08<00:08, 175.44it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:08<00:08, 171.49it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1746/3257 [00:08<00:08, 170.16it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1766/3257 [00:08<00:08, 176.39it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1788/3257 [00:08<00:07, 187.03it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1807/3257 [00:08<00:08, 177.31it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:08<00:07, 181.70it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:08<00:07, 183.94it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:09<00:07, 190.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1889/3257 [00:09<00:07, 191.40it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1910/3257 [00:09<00:06, 196.57it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1930/3257 [00:09<00:06, 190.27it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1959/3257 [00:09<00:05, 217.86it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1981/3257 [00:09<00:06, 206.55it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2002/3257 [00:09<00:06, 205.26it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2023/3257 [00:09<00:06, 204.97it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2044/3257 [00:09<00:06, 198.05it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2064/3257 [00:10<00:06, 183.94it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2084/3257 [00:10<00:06, 188.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2104/3257 [00:10<00:06, 186.93it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2123/3257 [00:10<00:06, 178.26it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:10<00:06, 176.39it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:10<00:05, 187.86it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:10<00:05, 185.65it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2206/3257 [00:10<00:05, 191.79it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2226/3257 [00:10<00:05, 189.26it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2245/3257 [00:11<00:05, 183.65it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2265/3257 [00:11<00:05, 187.51it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2284/3257 [00:11<00:05, 185.84it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2303/3257 [00:11<00:05, 186.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2329/3257 [00:11<00:04, 205.00it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2354/3257 [00:11<00:04, 217.61it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2376/3257 [00:11<00:04, 208.68it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2400/3257 [00:11<00:03, 217.54it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:11<00:04, 203.66it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:12<00:07, 106.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2466/3257 [00:12<00:06, 127.28it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2486/3257 [00:12<00:05, 141.29it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2511/3257 [00:12<00:04, 164.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2535/3257 [00:12<00:04, 180.43it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2557/3257 [00:12<00:03, 179.57it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2578/3257 [00:13<00:03, 177.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2598/3257 [00:13<00:03, 177.76it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2625/3257 [00:13<00:03, 200.68it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2647/3257 [00:13<00:03, 194.88it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2668/3257 [00:13<00:03, 195.11it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2689/3257 [00:13<00:02, 198.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2710/3257 [00:13<00:03, 177.17it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:13<00:02, 185.05it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:13<00:02, 195.80it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2777/3257 [00:14<00:02, 190.61it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2801/3257 [00:14<00:02, 202.89it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2822/3257 [00:14<00:02, 194.30it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:14<00:02, 184.12it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2868/3257 [00:14<00:01, 203.26it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2889/3257 [00:14<00:01, 202.57it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2910/3257 [00:14<00:01, 194.77it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2930/3257 [00:14<00:01, 195.12it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:14<00:01, 187.33it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2972/3257 [00:15<00:01, 192.85it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2992/3257 [00:15<00:01, 183.52it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3015/3257 [00:15<00:01, 195.03it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3037/3257 [00:15<00:01, 200.57it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3061/3257 [00:15<00:00, 210.42it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3083/3257 [00:15<00:00, 209.95it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3107/3257 [00:15<00:00, 216.61it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3134/3257 [00:15<00:00, 229.44it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3159/3257 [00:15<00:00, 234.00it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:15<00:00, 232.37it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3209/3257 [00:16<00:00, 240.30it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3236/3257 [00:16<00:00, 248.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 200.41it/s]
2023-02-07 18:21:22.567 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:21:22,568][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d444,n5,mc2,s0.816359,t4>', 'datetime': '2023-02-07T18:21:22.568758', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:21:22,569][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:21:22,569][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:21:22,940][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 18:21:22,940][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:21:22,985][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 18495 unique words (85.23% of original 21699, drops 3204)', 'datetime': '2023-02-07T18:21:22.985510', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:21:22,985][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 4364040 word corpus (99.93% of original 4367244, drops 3204)', 'datetime': '2023-02-07T18:21:22.985869', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:21:23,047][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 18:21:23,047][gensim.models.word2vec][INFO] - sample=0.816359 downsamples 0 most-common words
[2023-02-07 18:21:23,048][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4364040 word corpus (100.0%% of prior 4364040)', 'datetime': '2023-02-07T18:21:23.048149', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:21:23,153][gensim.models.word2vec][INFO] - estimated required memory for 18495 words and 444 dimensions: 81377572 bytes
[2023-02-07 18:21:23,153][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:21:23,190][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18495 vocabulary and 444 features, using sg=1 hs=0 sample=0.8163586999124266 negative=5 window=9 shrink_windows=True', 'datetime': '2023-02-07T18:21:23.190105', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:21:24,192][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 61.19% examples, 2717395 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:24,742][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4365521 effective words) took 1.5s, 2816641 effective words/s
[2023-02-07 18:21:25,750][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 70.03% examples, 3114111 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:26,155][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4365521 effective words) took 1.4s, 3091863 effective words/s
[2023-02-07 18:21:27,159][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 69.54% examples, 3098601 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:27,560][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4365521 effective words) took 1.4s, 3112093 effective words/s
[2023-02-07 18:21:28,569][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 71.66% examples, 3165724 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:28,930][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4365521 effective words) took 1.4s, 3191136 effective words/s
[2023-02-07 18:21:29,934][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 71.66% examples, 3181752 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:30,302][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4365521 effective words) took 1.4s, 3184821 effective words/s
[2023-02-07 18:21:31,311][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 76.51% examples, 3358536 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:21:31,666][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4365521 effective words) took 1.4s, 3203119 effective words/s
[2023-02-07 18:21:32,673][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 60.82% examples, 2689532 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:33,277][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4365521 effective words) took 1.6s, 2713302 effective words/s
[2023-02-07 18:21:34,290][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 61.68% examples, 2710219 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:34,891][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4365521 effective words) took 1.6s, 2709348 effective words/s
[2023-02-07 18:21:35,899][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 61.68% examples, 2724407 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:36,495][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4365521 effective words) took 1.6s, 2725791 effective words/s
[2023-02-07 18:21:37,503][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 59.81% examples, 2648955 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:38,125][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4365521 effective words) took 1.6s, 2682817 effective words/s
[2023-02-07 18:21:39,134][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 60.82% examples, 2684263 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:21:39,753][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4365521 effective words) took 1.6s, 2684925 effective words/s
[2023-02-07 18:21:40,756][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 69.36% examples, 3093637 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:41,097][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4365521 effective words) took 1.3s, 3253015 effective words/s
[2023-02-07 18:21:42,100][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 83.08% examples, 3655544 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:42,281][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4365521 effective words) took 1.2s, 3690521 effective words/s
[2023-02-07 18:21:43,285][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 83.51% examples, 3678138 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:21:43,477][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4365521 effective words) took 1.2s, 3653514 effective words/s
[2023-02-07 18:21:44,480][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 76.24% examples, 3371193 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:21:44,791][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4365521 effective words) took 1.3s, 3325994 effective words/s
[2023-02-07 18:21:44,792][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65482815 effective words) took 21.6s, 3031400 effective words/s', 'datetime': '2023-02-07T18:21:44.792049', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:21:44.792 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:21:47,375][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182057-womyimtc/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:21:47.375265', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:21:47,376][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:21:47,469][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182057-womyimtc/files/../tmp/embedding_model.pt
2023-02-07 18:21:47.470 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:21:49.701 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:21:50.492 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:21:53.673 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.3114342447313874, 'test_mae': 0.8850802275026503, 'test_r2': -3.9336435500610225}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.025 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: | 0.025 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.02
wandb: percentage 0.14766
wandb:   test_mae 0.88508
wandb:   test_mse 1.31143
wandb:    test_r2 -3.93364
wandb: 
wandb: üöÄ View run fiery-sweep-3 at: https://wandb.ai/xiaoqiz/mof2vec/runs/womyimtc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_182057-womyimtc/logs
wandb: Agent Starting Run: fojz7ttk with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 440
wandb: 	model.gensim.alpha: 0.0017479464628873643
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 4
wandb: 	model.gensim.sample: 0.3859020902737722
wandb: 	model.gensim.vector_size: 445
wandb: 	model.gensim.window: 12
wandb: 	model.sklearn.learning_rate: 0.007911861994020783
wandb: 	model.sklearn.max_depth: 92
wandb: 	model.sklearn.min_child_weight: 0.046592534448687106
wandb: 	model.sklearn.n_estimators: 2766
wandb: 	model.sklearn.num_leaves: 373
wandb: 	model.sklearn.reg_alpha: 0.1612254640294983
wandb: 	model.sklearn.reg_lambda: 0.005242896927528261
wandb: 	model.sklearn.subsample: 0.9310747707246588
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182203-fojz7ttk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/fojz7ttk
2023-02-07 18:22:11.268 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 18:22:11.268 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 440 for sweep.
2023-02-07 18:22:11.268 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0017479464628873643 for sweep.
2023-02-07 18:22:11.269 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:22:11.269 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 4 for sweep.
2023-02-07 18:22:11.269 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.3859020902737722 for sweep.
2023-02-07 18:22:11.269 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 445 for sweep.
2023-02-07 18:22:11.270 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 12 for sweep.
2023-02-07 18:22:11.270 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.007911861994020783 for sweep.
2023-02-07 18:22:11.270 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 92 for sweep.
2023-02-07 18:22:11.270 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.046592534448687106 for sweep.
2023-02-07 18:22:11.270 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2766 for sweep.
2023-02-07 18:22:11.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 373 for sweep.
2023-02-07 18:22:11.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.1612254640294983 for sweep.
2023-02-07 18:22:11.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.005242896927528261 for sweep.
2023-02-07 18:22:11.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9310747707246588 for sweep.
2023-02-07 18:22:11.272 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:22:11.276 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182203-fojz7ttk/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 440, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 445, 'window': 12, 'min_count': 4, 'dm': 1, 'sample': 0.3859020902737722, 'workers': 4, 'alpha': 0.0017479464628873643, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2766, 'max_depth': 92, 'num_leaves': 373, 'reg_alpha': 0.1612254640294983, 'reg_lambda': 0.005242896927528261, 'subsample': 0.9310747707246588, 'min_child_weight': 0.046592534448687106, 'n_jobs': 4, 'learning_rate': 0.007911861994020783}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 26/3257 [00:00<00:12, 253.92it/s]  2%|‚ñè         | 53/3257 [00:00<00:12, 250.14it/s]  3%|‚ñé         | 83/3257 [00:00<00:11, 271.91it/s]  3%|‚ñé         | 111/3257 [00:00<00:12, 255.76it/s]  4%|‚ñç         | 140/3257 [00:00<00:11, 266.52it/s]  5%|‚ñå         | 167/3257 [00:00<00:11, 263.06it/s]  6%|‚ñå         | 195/3257 [00:00<00:11, 268.21it/s]  7%|‚ñã         | 228/3257 [00:00<00:10, 286.27it/s]  8%|‚ñä         | 257/3257 [00:00<00:10, 280.04it/s]  9%|‚ñâ         | 288/3257 [00:01<00:10, 288.16it/s] 10%|‚ñâ         | 317/3257 [00:01<00:10, 280.80it/s] 11%|‚ñà         | 346/3257 [00:01<00:10, 273.79it/s] 12%|‚ñà‚ñè        | 375/3257 [00:01<00:10, 275.26it/s] 12%|‚ñà‚ñè        | 403/3257 [00:01<00:10, 270.16it/s] 13%|‚ñà‚ñé        | 431/3257 [00:01<00:11, 249.05it/s] 14%|‚ñà‚ñç        | 459/3257 [00:01<00:11, 253.71it/s] 15%|‚ñà‚ñç        | 485/3257 [00:01<00:15, 182.91it/s] 16%|‚ñà‚ñå        | 514/3257 [00:02<00:13, 205.75it/s] 17%|‚ñà‚ñã        | 538/3257 [00:02<00:12, 209.94it/s] 17%|‚ñà‚ñã        | 562/3257 [00:02<00:13, 205.48it/s] 18%|‚ñà‚ñä        | 584/3257 [00:02<00:13, 201.76it/s] 19%|‚ñà‚ñä        | 609/3257 [00:02<00:12, 212.83it/s] 19%|‚ñà‚ñâ        | 633/3257 [00:02<00:11, 219.75it/s] 20%|‚ñà‚ñà        | 656/3257 [00:02<00:12, 204.57it/s] 21%|‚ñà‚ñà        | 679/3257 [00:02<00:12, 210.22it/s] 22%|‚ñà‚ñà‚ñè       | 701/3257 [00:02<00:12, 205.62it/s] 22%|‚ñà‚ñà‚ñè       | 723/3257 [00:03<00:12, 207.81it/s] 23%|‚ñà‚ñà‚ñé       | 745/3257 [00:03<00:12, 204.34it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:03<00:11, 212.23it/s] 24%|‚ñà‚ñà‚ñç       | 792/3257 [00:03<00:11, 209.21it/s] 25%|‚ñà‚ñà‚ñå       | 815/3257 [00:03<00:11, 212.27it/s] 26%|‚ñà‚ñà‚ñå       | 837/3257 [00:03<00:11, 203.35it/s] 26%|‚ñà‚ñà‚ñã       | 858/3257 [00:03<00:11, 203.46it/s] 27%|‚ñà‚ñà‚ñã       | 879/3257 [00:03<00:11, 199.87it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:03<00:11, 213.76it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:04<00:10, 216.46it/s] 29%|‚ñà‚ñà‚ñâ       | 950/3257 [00:04<00:10, 212.95it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:04<00:10, 213.99it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:04<00:10, 206.94it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:04<00:10, 207.54it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1036/3257 [00:04<00:10, 203.41it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1057/3257 [00:04<00:10, 200.54it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:04<00:10, 204.41it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1102/3257 [00:04<00:10, 208.78it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:04<00:10, 207.81it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:05<00:10, 205.57it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1167/3257 [00:05<00:09, 211.74it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1189/3257 [00:05<00:10, 191.03it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1209/3257 [00:05<00:10, 190.34it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1235/3257 [00:05<00:09, 207.64it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:05<00:09, 205.67it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1278/3257 [00:05<00:09, 198.94it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1299/3257 [00:05<00:09, 198.15it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:05<00:09, 203.98it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:06<00:09, 211.00it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1366/3257 [00:06<00:09, 202.50it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1387/3257 [00:06<00:09, 202.04it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:06<00:08, 214.45it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1436/3257 [00:06<00:08, 219.35it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1462/3257 [00:06<00:07, 228.75it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1485/3257 [00:06<00:07, 228.26it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1512/3257 [00:06<00:07, 238.24it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1536/3257 [00:06<00:07, 217.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1559/3257 [00:07<00:07, 215.97it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1581/3257 [00:07<00:07, 213.69it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1606/3257 [00:07<00:07, 222.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1632/3257 [00:07<00:06, 232.16it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1656/3257 [00:07<00:07, 217.10it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1678/3257 [00:07<00:07, 206.45it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1701/3257 [00:07<00:07, 212.27it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:07<00:07, 214.22it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:07<00:07, 200.20it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1770/3257 [00:08<00:06, 212.86it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1793/3257 [00:08<00:06, 217.60it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1815/3257 [00:08<00:06, 209.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1838/3257 [00:08<00:06, 212.35it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1860/3257 [00:08<00:11, 123.18it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1883/3257 [00:08<00:09, 143.08it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1908/3257 [00:08<00:08, 164.56it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1929/3257 [00:09<00:07, 174.22it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:09<00:06, 209.11it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1985/3257 [00:09<00:06, 209.16it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2009/3257 [00:09<00:05, 215.64it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2034/3257 [00:09<00:05, 224.68it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2058/3257 [00:09<00:05, 211.52it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2081/3257 [00:09<00:05, 214.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2104/3257 [00:09<00:05, 210.07it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2126/3257 [00:09<00:05, 207.38it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2148/3257 [00:10<00:05, 202.99it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2174/3257 [00:10<00:04, 217.95it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2197/3257 [00:10<00:04, 216.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:10<00:04, 212.03it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2241/3257 [00:10<00:04, 209.22it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2265/3257 [00:10<00:04, 215.44it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2288/3257 [00:10<00:04, 216.18it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:10<00:04, 229.40it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2356/3257 [00:10<00:03, 281.16it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2388/3257 [00:10<00:02, 290.88it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2418/3257 [00:11<00:02, 285.96it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2447/3257 [00:11<00:02, 282.25it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2479/3257 [00:11<00:02, 291.33it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:11<00:02, 305.93it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2546/3257 [00:11<00:02, 309.11it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2577/3257 [00:11<00:02, 286.78it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2608/3257 [00:11<00:02, 292.48it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2642/3257 [00:11<00:02, 305.89it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:11<00:01, 301.65it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:12<00:01, 288.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2736/3257 [00:12<00:01, 296.37it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2768/3257 [00:12<00:01, 295.41it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2801/3257 [00:12<00:01, 304.11it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2832/3257 [00:12<00:01, 286.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2867/3257 [00:12<00:01, 303.19it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2898/3257 [00:12<00:01, 294.78it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:12<00:01, 293.38it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2958/3257 [00:12<00:01, 276.12it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2986/3257 [00:13<00:00, 276.07it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:13<00:00, 286.29it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:13<00:00, 292.68it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:13<00:00, 302.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3116/3257 [00:13<00:00, 311.08it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3148/3257 [00:13<00:00, 293.62it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3178/3257 [00:13<00:00, 288.64it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3211/3257 [00:13<00:00, 297.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3245/3257 [00:13<00:00, 308.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:13<00:00, 234.27it/s]
2023-02-07 18:22:25.599 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:22:25,600][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d445,n5,w12,mc4,s0.385902,t4>', 'datetime': '2023-02-07T18:22:25.600410', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:22:25,600][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:22:25,600][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:22:25,905][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 18:22:25,905][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:22:25,926][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 retains 8978 unique words (68.74% of original 13061, drops 4083)', 'datetime': '2023-02-07T18:22:25.926653', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:22:25,926][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 leaves 3632716 word corpus (99.82% of original 3639370, drops 6654)', 'datetime': '2023-02-07T18:22:25.926836', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:22:25,954][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 18:22:25,955][gensim.models.word2vec][INFO] - sample=0.385902 downsamples 0 most-common words
[2023-02-07 18:22:25,955][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3632716 word corpus (100.0%% of prior 3632716)', 'datetime': '2023-02-07T18:22:25.955181', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:22:26,003][gensim.models.word2vec][INFO] - estimated required memory for 8978 words and 445 dimensions: 42899540 bytes
[2023-02-07 18:22:26,003][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:22:26,023][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 8978 vocabulary and 445 features, using sg=0 hs=0 sample=0.3859020902737722 negative=5 window=12 shrink_windows=True', 'datetime': '2023-02-07T18:22:26.023108', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:22:27,030][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 21.89% examples, 779814 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:22:28,032][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 43.32% examples, 805903 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:22:29,044][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 67.27% examples, 826167 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:22:30,046][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 94.69% examples, 858471 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:30,233][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3635973 effective words) took 4.2s, 864121 effective words/s
[2023-02-07 18:22:31,245][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 25.18% examples, 901764 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:32,256][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 49.95% examples, 912533 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:22:33,275][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 75.10% examples, 912026 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:34,244][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3635973 effective words) took 4.0s, 906832 effective words/s
[2023-02-07 18:22:35,265][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 23.21% examples, 823426 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:22:36,284][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 46.18% examples, 839075 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:37,286][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 69.85% examples, 856667 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:38,287][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 97.14% examples, 875331 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:38,404][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3635973 effective words) took 4.2s, 874634 effective words/s
[2023-02-07 18:22:39,406][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 25.33% examples, 920259 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:40,407][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 49.80% examples, 922823 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:22:41,419][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 73.93% examples, 905252 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:42,422][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 98.62% examples, 893741 words/s, in_qsize 5, out_qsize 0
[2023-02-07 18:22:42,483][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3635973 effective words) took 4.1s, 891603 effective words/s
[2023-02-07 18:22:43,497][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 23.37% examples, 837423 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:22:44,504][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 48.30% examples, 887844 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:45,514][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 74.79% examples, 912539 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:46,460][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3635973 effective words) took 4.0s, 914709 effective words/s
[2023-02-07 18:22:47,463][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 25.33% examples, 919980 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:48,467][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 49.31% examples, 913012 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:49,469][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 72.64% examples, 892470 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:22:50,479][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 97.85% examples, 887302 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:50,559][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3635973 effective words) took 4.1s, 887455 effective words/s
[2023-02-07 18:22:51,568][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 24.16% examples, 870009 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:52,573][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 50.20% examples, 927118 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:53,594][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 75.93% examples, 924195 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:22:54,464][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3635973 effective words) took 3.9s, 931850 effective words/s
[2023-02-07 18:22:55,478][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 24.47% examples, 874349 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:22:56,482][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 47.07% examples, 866037 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:57,493][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 70.77% examples, 869449 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:22:58,502][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 97.85% examples, 883140 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:22:58,578][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3635973 effective words) took 4.1s, 884343 effective words/s
[2023-02-07 18:22:59,589][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 25.94% examples, 938353 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:23:00,604][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 50.66% examples, 929518 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:23:01,609][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 76.33% examples, 927977 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:23:02,572][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3635973 effective words) took 4.0s, 910657 effective words/s
[2023-02-07 18:23:03,583][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 22.90% examples, 821593 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:23:04,592][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 45.56% examples, 838010 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:23:05,603][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 71.72% examples, 877877 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:23:06,614][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 98.80% examples, 891138 words/s, in_qsize 4, out_qsize 0
[2023-02-07 18:23:06,648][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3635973 effective words) took 4.1s, 892538 effective words/s
[2023-02-07 18:23:07,660][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 25.33% examples, 911148 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:23:08,684][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 48.76% examples, 890151 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:23:09,695][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 72.64% examples, 881234 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:23:10,695][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 97.14% examples, 874333 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:23:10,809][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3635973 effective words) took 4.2s, 874075 effective words/s
[2023-02-07 18:23:11,814][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 25.94% examples, 946044 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:23:12,823][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 51.12% examples, 945661 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:23:13,828][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 77.22% examples, 941313 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:23:14,737][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3635973 effective words) took 3.9s, 926241 effective words/s
[2023-02-07 18:23:15,752][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 22.90% examples, 819986 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:23:16,753][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 45.96% examples, 845200 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:23:17,757][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 70.77% examples, 872774 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:23:18,773][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 100.00% examples, 901838 words/s, in_qsize 0, out_qsize 1
[2023-02-07 18:23:18,773][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3635973 effective words) took 4.0s, 901737 effective words/s
[2023-02-07 18:23:19,779][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 25.18% examples, 907516 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:23:20,796][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 49.80% examples, 914011 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:23:21,796][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 75.10% examples, 918055 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:23:22,726][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3635973 effective words) took 4.0s, 920249 effective words/s
[2023-02-07 18:23:23,740][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 24.72% examples, 881497 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:23:24,741][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 48.17% examples, 889969 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:23:25,746][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 74.24% examples, 907027 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:23:26,745][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3635973 effective words) took 4.0s, 905080 effective words/s
[2023-02-07 18:23:26,745][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54539595 effective words) took 60.7s, 898179 effective words/s', 'datetime': '2023-02-07T18:23:26.745784', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:23:26.746 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:23:30,548][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182203-fojz7ttk/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:23:30.548086', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:23:30,548][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:23:30,607][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182203-fojz7ttk/files/../tmp/embedding_model.pt
2023-02-07 18:23:30.608 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:23:32.968 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:23:33.870 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:23:36.984 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9863973596467248, 'test_mae': 0.7765097936695339, 'test_r2': -2.3618353311671387}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.16
wandb: percentage 0.31261
wandb:   test_mae 0.77651
wandb:   test_mse 0.9864
wandb:    test_r2 -2.36184
wandb: 
wandb: üöÄ View run helpful-sweep-4 at: https://wandb.ai/xiaoqiz/mof2vec/runs/fojz7ttk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_182203-fojz7ttk/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: e9tghoi5 with config:
wandb: 	data.data.wl_step: 2
wandb: 	data.nn.batch_size: 409
wandb: 	model.gensim.alpha: 0.004595340299551265
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.20001671148603847
wandb: 	model.gensim.vector_size: 352
wandb: 	model.gensim.window: 15
wandb: 	model.sklearn.learning_rate: 0.004167546925119993
wandb: 	model.sklearn.max_depth: 87
wandb: 	model.sklearn.min_child_weight: 0.007185980885730933
wandb: 	model.sklearn.n_estimators: 3391
wandb: 	model.sklearn.num_leaves: 196
wandb: 	model.sklearn.reg_alpha: 0.7831373459470194
wandb: 	model.sklearn.reg_lambda: 0.006362147224830572
wandb: 	model.sklearn.subsample: 0.5783412011022293
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182353-e9tghoi5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/e9tghoi5
2023-02-07 18:24:02.204 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 2 for sweep.
2023-02-07 18:24:02.204 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 409 for sweep.
2023-02-07 18:24:02.205 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.004595340299551265 for sweep.
2023-02-07 18:24:02.205 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:24:02.205 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 18:24:02.205 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.20001671148603847 for sweep.
2023-02-07 18:24:02.206 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 352 for sweep.
2023-02-07 18:24:02.206 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 15 for sweep.
2023-02-07 18:24:02.206 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.004167546925119993 for sweep.
2023-02-07 18:24:02.206 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 87 for sweep.
2023-02-07 18:24:02.206 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.007185980885730933 for sweep.
2023-02-07 18:24:02.207 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3391 for sweep.
2023-02-07 18:24:02.207 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 196 for sweep.
2023-02-07 18:24:02.207 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.7831373459470194 for sweep.
2023-02-07 18:24:02.207 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.006362147224830572 for sweep.
2023-02-07 18:24:02.208 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5783412011022293 for sweep.
2023-02-07 18:24:02.208 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:24:02.213 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 2}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182353-e9tghoi5/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 409, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 352, 'window': 15, 'min_count': 8, 'dm': 1, 'sample': 0.20001671148603847, 'workers': 4, 'alpha': 0.004595340299551265, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3391, 'max_depth': 87, 'num_leaves': 196, 'reg_alpha': 0.7831373459470194, 'reg_lambda': 0.006362147224830572, 'subsample': 0.5783412011022293, 'min_child_weight': 0.007185980885730933, 'n_jobs': 4, 'learning_rate': 0.004167546925119993}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 34/3257 [00:00<00:09, 335.93it/s]  2%|‚ñè         | 71/3257 [00:00<00:08, 355.54it/s]  3%|‚ñé         | 107/3257 [00:00<00:13, 225.27it/s]  5%|‚ñç         | 149/3257 [00:00<00:11, 280.00it/s]  6%|‚ñå         | 185/3257 [00:00<00:10, 303.33it/s]  7%|‚ñã         | 230/3257 [00:00<00:08, 342.13it/s]  8%|‚ñä         | 267/3257 [00:00<00:08, 345.35it/s]  9%|‚ñâ         | 308/3257 [00:00<00:08, 361.54it/s] 11%|‚ñà         | 346/3257 [00:01<00:08, 361.79it/s] 12%|‚ñà‚ñè        | 384/3257 [00:01<00:08, 357.69it/s] 13%|‚ñà‚ñé        | 421/3257 [00:01<00:08, 349.36it/s] 14%|‚ñà‚ñç        | 457/3257 [00:01<00:08, 329.77it/s] 15%|‚ñà‚ñå        | 493/3257 [00:01<00:08, 336.40it/s] 16%|‚ñà‚ñã        | 531/3257 [00:01<00:07, 347.84it/s] 17%|‚ñà‚ñã        | 567/3257 [00:01<00:07, 336.35it/s] 18%|‚ñà‚ñä        | 601/3257 [00:01<00:07, 332.68it/s] 20%|‚ñà‚ñâ        | 637/3257 [00:01<00:07, 337.92it/s] 21%|‚ñà‚ñà        | 671/3257 [00:02<00:07, 330.98it/s] 22%|‚ñà‚ñà‚ñè       | 705/3257 [00:02<00:07, 323.35it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:02<00:08, 311.71it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:02<00:07, 321.86it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:02<00:07, 320.38it/s] 26%|‚ñà‚ñà‚ñå       | 839/3257 [00:02<00:07, 315.66it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:02<00:07, 310.95it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:02<00:07, 317.89it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:02<00:07, 322.42it/s] 30%|‚ñà‚ñà‚ñâ       | 977/3257 [00:02<00:06, 337.47it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:03<00:06, 321.04it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1044/3257 [00:03<00:07, 312.13it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:03<00:06, 315.96it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:03<00:06, 316.98it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:03<00:06, 312.94it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1177/3257 [00:03<00:06, 316.95it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1209/3257 [00:03<00:06, 300.27it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:03<00:06, 314.63it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:03<00:06, 311.71it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:04<00:09, 215.39it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:04<00:07, 244.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1374/3257 [00:04<00:07, 255.90it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1408/3257 [00:04<00:06, 276.64it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1441/3257 [00:04<00:06, 290.70it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:04<00:05, 308.73it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:04<00:05, 322.40it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1547/3257 [00:04<00:05, 298.24it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1579/3257 [00:05<00:05, 300.57it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1614/3257 [00:05<00:05, 313.44it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1647/3257 [00:05<00:05, 298.38it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1678/3257 [00:05<00:05, 291.63it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1709/3257 [00:05<00:05, 296.39it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1739/3257 [00:05<00:05, 283.82it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1774/3257 [00:05<00:04, 300.27it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1806/3257 [00:05<00:04, 304.90it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1837/3257 [00:05<00:04, 299.20it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:06<00:04, 298.21it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1901/3257 [00:06<00:04, 303.55it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1933/3257 [00:06<00:04, 306.73it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1973/3257 [00:06<00:03, 331.13it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2007/3257 [00:06<00:03, 317.85it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2040/3257 [00:06<00:03, 313.81it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2072/3257 [00:06<00:03, 305.39it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2103/3257 [00:06<00:03, 300.84it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:06<00:03, 297.88it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2167/3257 [00:06<00:03, 305.84it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2199/3257 [00:07<00:03, 308.44it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2231/3257 [00:07<00:03, 311.77it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2263/3257 [00:07<00:03, 309.43it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2296/3257 [00:07<00:03, 312.41it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2333/3257 [00:07<00:02, 327.31it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2371/3257 [00:07<00:02, 339.82it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2406/3257 [00:07<00:02, 338.98it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:07<00:02, 331.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:07<00:02, 334.81it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:08<00:02, 346.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2550/3257 [00:08<00:02, 348.96it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2585/3257 [00:08<00:02, 329.79it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2625/3257 [00:08<00:01, 346.33it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2660/3257 [00:08<00:02, 219.83it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:08<00:02, 243.90it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2724/3257 [00:08<00:02, 255.17it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2760/3257 [00:08<00:01, 279.86it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:09<00:01, 282.90it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:09<00:01, 286.97it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2855/3257 [00:09<00:01, 294.65it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2893/3257 [00:09<00:01, 316.96it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2930/3257 [00:09<00:00, 328.55it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2964/3257 [00:09<00:00, 326.94it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2998/3257 [00:09<00:00, 328.35it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3036/3257 [00:09<00:00, 341.83it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3077/3257 [00:09<00:00, 360.02it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3116/3257 [00:09<00:00, 368.79it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3154/3257 [00:10<00:00, 356.37it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3190/3257 [00:10<00:00, 356.10it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3226/3257 [00:10<00:00, 351.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:10<00:00, 313.27it/s]
2023-02-07 18:24:12.885 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:24:12,886][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d352,n5,w15,mc8,s0.200017,t4>', 'datetime': '2023-02-07T18:24:12.885966', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:24:12,886][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:24:12,886][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:24:13,070][gensim.models.doc2vec][INFO] - collected 2819 word types and 3257 unique tags from a corpus of 3257 examples and 2183622 words
[2023-02-07 18:24:13,071][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:24:13,075][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 1410 unique words (50.02% of original 2819, drops 1409)', 'datetime': '2023-02-07T18:24:13.074983', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:24:13,075][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 2179184 word corpus (99.80% of original 2183622, drops 4438)', 'datetime': '2023-02-07T18:24:13.075203', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:24:13,079][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 2819 items
[2023-02-07 18:24:13,080][gensim.models.word2vec][INFO] - sample=0.200017 downsamples 0 most-common words
[2023-02-07 18:24:13,080][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2179184 word corpus (100.0%% of prior 2179184)', 'datetime': '2023-02-07T18:24:13.080157', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:24:13,088][gensim.models.word2vec][INFO] - estimated required memory for 1410 words and 352 dimensions: 9912816 bytes
[2023-02-07 18:24:13,088][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:24:13,094][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 1410 vocabulary and 352 features, using sg=0 hs=0 sample=0.20001671148603847 negative=5 window=15 shrink_windows=True', 'datetime': '2023-02-07T18:24:13.094257', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:24:14,102][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 33.83% examples, 742845 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:15,117][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 66.17% examples, 728829 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:16,064][gensim.models.word2vec][INFO] - EPOCH 0: training on 2183622 raw words (2182441 effective words) took 3.0s, 735115 effective words/s
[2023-02-07 18:24:17,075][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 33.13% examples, 722258 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:18,078][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 65.70% examples, 727910 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:19,063][gensim.models.word2vec][INFO] - EPOCH 1: training on 2183622 raw words (2182441 effective words) took 3.0s, 728368 effective words/s
[2023-02-07 18:24:20,066][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 31.81% examples, 700584 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:21,083][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 64.72% examples, 711404 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:22,052][gensim.models.word2vec][INFO] - EPOCH 2: training on 2183622 raw words (2182441 effective words) took 3.0s, 730643 effective words/s
[2023-02-07 18:24:23,060][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 36.41% examples, 806010 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:24,068][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 70.31% examples, 778941 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:24,844][gensim.models.word2vec][INFO] - EPOCH 3: training on 2183622 raw words (2182441 effective words) took 2.8s, 782160 effective words/s
[2023-02-07 18:24:25,850][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 33.83% examples, 744844 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:26,872][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 68.65% examples, 755321 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:24:27,723][gensim.models.word2vec][INFO] - EPOCH 4: training on 2183622 raw words (2182441 effective words) took 2.9s, 758451 effective words/s
[2023-02-07 18:24:28,729][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 33.56% examples, 734648 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:29,743][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 67.39% examples, 744416 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:30,597][gensim.models.word2vec][INFO] - EPOCH 5: training on 2183622 raw words (2182441 effective words) took 2.9s, 760003 effective words/s
[2023-02-07 18:24:31,605][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 33.44% examples, 734062 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:32,609][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 67.79% examples, 751788 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:33,490][gensim.models.word2vec][INFO] - EPOCH 6: training on 2183622 raw words (2182441 effective words) took 2.9s, 754988 effective words/s
[2023-02-07 18:24:34,495][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 32.64% examples, 719425 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:35,496][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 65.70% examples, 730829 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:36,447][gensim.models.word2vec][INFO] - EPOCH 7: training on 2183622 raw words (2182441 effective words) took 3.0s, 738808 effective words/s
[2023-02-07 18:24:37,462][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 32.18% examples, 701775 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:38,467][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 65.27% examples, 720811 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:39,448][gensim.models.word2vec][INFO] - EPOCH 8: training on 2183622 raw words (2182441 effective words) took 3.0s, 727784 effective words/s
[2023-02-07 18:24:40,474][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 33.44% examples, 721398 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:41,480][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 66.07% examples, 726049 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:42,292][gensim.models.word2vec][INFO] - EPOCH 9: training on 2183622 raw words (2182441 effective words) took 2.8s, 767774 effective words/s
[2023-02-07 18:24:43,294][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 33.56% examples, 736941 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:44,300][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 68.25% examples, 758046 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:45,175][gensim.models.word2vec][INFO] - EPOCH 10: training on 2183622 raw words (2182441 effective words) took 2.9s, 757474 effective words/s
[2023-02-07 18:24:46,195][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 33.44% examples, 725737 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:47,214][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 70.31% examples, 770474 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:47,981][gensim.models.word2vec][INFO] - EPOCH 11: training on 2183622 raw words (2182441 effective words) took 2.8s, 778144 effective words/s
[2023-02-07 18:24:48,990][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 33.44% examples, 733842 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:50,004][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 68.65% examples, 757565 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:50,867][gensim.models.word2vec][INFO] - EPOCH 12: training on 2183622 raw words (2182441 effective words) took 2.9s, 756857 effective words/s
[2023-02-07 18:24:51,874][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 34.26% examples, 752729 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:52,877][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 66.93% examples, 742801 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:53,783][gensim.models.word2vec][INFO] - EPOCH 13: training on 2183622 raw words (2182441 effective words) took 2.9s, 748683 effective words/s
[2023-02-07 18:24:54,807][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 32.18% examples, 696059 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:24:55,810][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 66.07% examples, 728112 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:24:56,738][gensim.models.word2vec][INFO] - EPOCH 14: training on 2183622 raw words (2182441 effective words) took 3.0s, 739269 effective words/s
[2023-02-07 18:24:56,739][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 32754330 raw words (32736615 effective words) took 43.6s, 750073 effective words/s', 'datetime': '2023-02-07T18:24:56.739108', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:24:56.739 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:24:58,604][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182353-e9tghoi5/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:24:58.604425', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:24:58,605][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:24:58,626][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182353-e9tghoi5/files/../tmp/embedding_model.pt
2023-02-07 18:24:58.627 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:25:00.772 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:25:01.401 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:25:03.768 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0601579605072238, 'test_mae': 0.799781273159147, 'test_r2': -2.2046464661825356}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.027 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: | 0.027 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: / 0.027 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: - 0.027 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: \ 0.027 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.16
wandb: percentage 0.49982
wandb:   test_mae 0.79978
wandb:   test_mse 1.06016
wandb:    test_r2 -2.20465
wandb: 
wandb: üöÄ View run copper-sweep-5 at: https://wandb.ai/xiaoqiz/mof2vec/runs/e9tghoi5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_182353-e9tghoi5/logs
wandb: Agent Starting Run: k3is6zwp with config:
wandb: 	data.data.wl_step: 2
wandb: 	data.nn.batch_size: 304
wandb: 	model.gensim.alpha: 0.0032561618975409296
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.25568906432331656
wandb: 	model.gensim.vector_size: 173
wandb: 	model.gensim.window: 19
wandb: 	model.sklearn.learning_rate: 0.009616362126414474
wandb: 	model.sklearn.max_depth: 74
wandb: 	model.sklearn.min_child_weight: 0.05860393707962259
wandb: 	model.sklearn.n_estimators: 2361
wandb: 	model.sklearn.num_leaves: 391
wandb: 	model.sklearn.reg_alpha: 0.01872281222648713
wandb: 	model.sklearn.reg_lambda: 0.009810733093531816
wandb: 	model.sklearn.subsample: 0.9899371173171888
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182519-k3is6zwp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/k3is6zwp
2023-02-07 18:25:28.359 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 2 for sweep.
2023-02-07 18:25:28.360 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 304 for sweep.
2023-02-07 18:25:28.360 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0032561618975409296 for sweep.
2023-02-07 18:25:28.360 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:25:28.360 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 18:25:28.361 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.25568906432331656 for sweep.
2023-02-07 18:25:28.361 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 173 for sweep.
2023-02-07 18:25:28.361 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 19 for sweep.
2023-02-07 18:25:28.361 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.009616362126414474 for sweep.
2023-02-07 18:25:28.362 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 74 for sweep.
2023-02-07 18:25:28.362 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05860393707962259 for sweep.
2023-02-07 18:25:28.362 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2361 for sweep.
2023-02-07 18:25:28.362 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 391 for sweep.
2023-02-07 18:25:28.362 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.01872281222648713 for sweep.
2023-02-07 18:25:28.363 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.009810733093531816 for sweep.
2023-02-07 18:25:28.363 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9899371173171888 for sweep.
2023-02-07 18:25:28.363 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:25:28.372 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 2}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182519-k3is6zwp/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 304, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 173, 'window': 19, 'min_count': 3, 'dm': 1, 'sample': 0.25568906432331656, 'workers': 4, 'alpha': 0.0032561618975409296, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2361, 'max_depth': 74, 'num_leaves': 391, 'reg_alpha': 0.01872281222648713, 'reg_lambda': 0.009810733093531816, 'subsample': 0.9899371173171888, 'min_child_weight': 0.05860393707962259, 'n_jobs': 4, 'learning_rate': 0.009616362126414474}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 25/3257 [00:00<00:13, 244.93it/s]  2%|‚ñè         | 50/3257 [00:00<00:12, 247.23it/s]  2%|‚ñè         | 76/3257 [00:00<00:12, 248.60it/s]  3%|‚ñé         | 101/3257 [00:00<00:12, 247.92it/s]  4%|‚ñç         | 126/3257 [00:00<00:12, 243.49it/s]  5%|‚ñç         | 154/3257 [00:00<00:12, 254.45it/s]  6%|‚ñå         | 180/3257 [00:00<00:12, 249.26it/s]  6%|‚ñã         | 210/3257 [00:00<00:11, 263.02it/s]  7%|‚ñã         | 242/3257 [00:00<00:10, 279.41it/s]  8%|‚ñä         | 271/3257 [00:01<00:10, 277.55it/s]  9%|‚ñâ         | 303/3257 [00:01<00:10, 287.27it/s] 10%|‚ñà         | 332/3257 [00:01<00:10, 284.18it/s] 11%|‚ñà         | 361/3257 [00:01<00:10, 283.04it/s] 12%|‚ñà‚ñè        | 390/3257 [00:01<00:10, 269.78it/s] 13%|‚ñà‚ñé        | 419/3257 [00:01<00:10, 275.38it/s] 14%|‚ñà‚ñé        | 447/3257 [00:01<00:10, 255.54it/s] 15%|‚ñà‚ñç        | 476/3257 [00:01<00:10, 262.75it/s] 16%|‚ñà‚ñå        | 506/3257 [00:01<00:10, 272.73it/s] 16%|‚ñà‚ñã        | 534/3257 [00:01<00:09, 272.87it/s] 17%|‚ñà‚ñã        | 562/3257 [00:02<00:10, 266.32it/s] 18%|‚ñà‚ñä        | 589/3257 [00:02<00:10, 258.84it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:02<00:09, 267.20it/s] 20%|‚ñà‚ñâ        | 648/3257 [00:02<00:09, 270.79it/s] 21%|‚ñà‚ñà        | 676/3257 [00:02<00:14, 172.56it/s] 21%|‚ñà‚ñà‚ñè       | 700/3257 [00:02<00:13, 185.79it/s] 22%|‚ñà‚ñà‚ñè       | 728/3257 [00:02<00:12, 206.95it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:03<00:11, 219.61it/s] 24%|‚ñà‚ñà‚ñç       | 781/3257 [00:03<00:10, 230.47it/s] 25%|‚ñà‚ñà‚ñç       | 807/3257 [00:03<00:10, 236.85it/s] 26%|‚ñà‚ñà‚ñå       | 834/3257 [00:03<00:09, 244.55it/s] 26%|‚ñà‚ñà‚ñã       | 860/3257 [00:03<00:09, 240.76it/s] 27%|‚ñà‚ñà‚ñã       | 885/3257 [00:03<00:09, 241.76it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:03<00:09, 254.33it/s] 29%|‚ñà‚ñà‚ñâ       | 944/3257 [00:03<00:08, 266.59it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:03<00:08, 267.00it/s] 31%|‚ñà‚ñà‚ñà       | 999/3257 [00:03<00:08, 259.11it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1026/3257 [00:04<00:08, 260.39it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1053/3257 [00:04<00:08, 249.31it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:04<00:08, 253.31it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1107/3257 [00:04<00:08, 257.91it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1133/3257 [00:04<00:08, 251.47it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1160/3257 [00:04<00:08, 255.14it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1186/3257 [00:04<00:08, 250.90it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1212/3257 [00:04<00:08, 245.32it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:04<00:07, 255.78it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1269/3257 [00:05<00:07, 262.30it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1296/3257 [00:05<00:08, 244.33it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1324/3257 [00:05<00:07, 253.87it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:05<00:07, 252.65it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1376/3257 [00:05<00:07, 249.46it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1404/3257 [00:05<00:07, 256.42it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1434/3257 [00:05<00:06, 267.35it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1465/3257 [00:05<00:06, 278.05it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1494/3257 [00:05<00:06, 277.77it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1522/3257 [00:06<00:06, 267.91it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1549/3257 [00:06<00:06, 261.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1576/3257 [00:06<00:06, 260.96it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1606/3257 [00:06<00:06, 270.20it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:06<00:05, 272.32it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:06<00:06, 263.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:06<00:05, 264.93it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1718/3257 [00:06<00:05, 269.09it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:06<00:05, 257.50it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:07<00:09, 164.06it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1800/3257 [00:07<00:07, 188.52it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:07<00:06, 205.51it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1856/3257 [00:07<00:06, 225.65it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1885/3257 [00:07<00:05, 241.30it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:07<00:05, 255.37it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1948/3257 [00:07<00:04, 271.74it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1979/3257 [00:07<00:04, 281.64it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2009/3257 [00:07<00:04, 285.29it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2039/3257 [00:08<00:04, 285.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2069/3257 [00:08<00:04, 269.65it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2097/3257 [00:08<00:04, 272.42it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2131/3257 [00:08<00:03, 290.43it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:08<00:03, 313.53it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2206/3257 [00:08<00:03, 329.37it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2242/3257 [00:08<00:03, 336.26it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:08<00:02, 337.04it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2317/3257 [00:08<00:02, 357.45it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2361/3257 [00:09<00:02, 381.48it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2403/3257 [00:09<00:02, 390.34it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:09<00:02, 360.70it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2483/3257 [00:09<00:02, 370.95it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:09<00:01, 380.76it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2563/3257 [00:09<00:01, 366.57it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:09<00:01, 356.60it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2642/3257 [00:09<00:01, 372.61it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2680/3257 [00:09<00:01, 361.48it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2717/3257 [00:10<00:01, 336.44it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2758/3257 [00:10<00:01, 354.97it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2794/3257 [00:10<00:01, 355.80it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2830/3257 [00:10<00:01, 342.14it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2869/3257 [00:10<00:01, 353.88it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2905/3257 [00:10<00:01, 343.44it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2943/3257 [00:10<00:00, 342.19it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2978/3257 [00:10<00:00, 335.04it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3015/3257 [00:10<00:00, 343.79it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3054/3257 [00:10<00:00, 356.16it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3092/3257 [00:11<00:00, 361.84it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3132/3257 [00:11<00:00, 371.45it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3170/3257 [00:11<00:00, 359.29it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:11<00:00, 354.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:11<00:00, 358.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:11<00:00, 282.37it/s]
2023-02-07 18:25:40.193 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:25:40,194][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d173,n5,w19,mc3,s0.255689,t4>', 'datetime': '2023-02-07T18:25:40.194758', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:25:40,195][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:25:40,195][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:25:40,397][gensim.models.doc2vec][INFO] - collected 2819 word types and 3257 unique tags from a corpus of 3257 examples and 2183622 words
[2023-02-07 18:25:40,398][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:25:40,403][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 2159 unique words (76.59% of original 2819, drops 660)', 'datetime': '2023-02-07T18:25:40.403815', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:25:40,404][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 2182579 word corpus (99.95% of original 2183622, drops 1043)', 'datetime': '2023-02-07T18:25:40.404065', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:25:40,411][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 2819 items
[2023-02-07 18:25:40,411][gensim.models.word2vec][INFO] - sample=0.255689 downsamples 0 most-common words
[2023-02-07 18:25:40,412][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2182579 word corpus (100.0%% of prior 2182579)', 'datetime': '2023-02-07T18:25:40.412005', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:25:40,425][gensim.models.word2vec][INFO] - estimated required memory for 2159 words and 173 dimensions: 6972800 bytes
[2023-02-07 18:25:40,425][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:25:40,429][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 2159 vocabulary and 173 features, using sg=0 hs=0 sample=0.25568906432331656 negative=5 window=19 shrink_windows=True', 'datetime': '2023-02-07T18:25:40.429276', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:25:41,432][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 42.03% examples, 944159 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:42,452][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 86.46% examples, 942885 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:42,741][gensim.models.word2vec][INFO] - EPOCH 0: training on 2183622 raw words (2185836 effective words) took 2.3s, 946224 effective words/s
[2023-02-07 18:25:43,750][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 41.66% examples, 930073 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:44,751][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 86.83% examples, 953413 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:45,027][gensim.models.word2vec][INFO] - EPOCH 1: training on 2183622 raw words (2185836 effective words) took 2.3s, 956687 effective words/s
[2023-02-07 18:25:46,037][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 42.68% examples, 955081 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:47,039][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 85.08% examples, 934528 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:47,372][gensim.models.word2vec][INFO] - EPOCH 2: training on 2183622 raw words (2185836 effective words) took 2.3s, 932623 effective words/s
[2023-02-07 18:25:48,402][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 40.37% examples, 883681 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:49,406][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 83.27% examples, 905732 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:49,772][gensim.models.word2vec][INFO] - EPOCH 3: training on 2183622 raw words (2185836 effective words) took 2.4s, 911514 effective words/s
[2023-02-07 18:25:50,786][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 39.91% examples, 888840 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:51,809][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 83.27% examples, 905058 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:52,168][gensim.models.word2vec][INFO] - EPOCH 4: training on 2183622 raw words (2185836 effective words) took 2.4s, 913604 effective words/s
[2023-02-07 18:25:53,171][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 40.84% examples, 916644 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:54,179][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 82.68% examples, 906080 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:54,562][gensim.models.word2vec][INFO] - EPOCH 5: training on 2183622 raw words (2185836 effective words) took 2.4s, 913718 effective words/s
[2023-02-07 18:25:55,573][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 45.38% examples, 1001219 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:56,578][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 90.82% examples, 992507 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:56,762][gensim.models.word2vec][INFO] - EPOCH 6: training on 2183622 raw words (2185836 effective words) took 2.2s, 994304 effective words/s
[2023-02-07 18:25:57,767][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 39.91% examples, 894852 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:25:58,772][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 84.31% examples, 925775 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:25:59,112][gensim.models.word2vec][INFO] - EPOCH 7: training on 2183622 raw words (2185836 effective words) took 2.3s, 930614 effective words/s
[2023-02-07 18:26:00,128][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 41.66% examples, 922913 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:01,128][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 85.66% examples, 936899 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:01,423][gensim.models.word2vec][INFO] - EPOCH 8: training on 2183622 raw words (2185836 effective words) took 2.3s, 946709 effective words/s
[2023-02-07 18:26:02,427][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 42.68% examples, 960962 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:03,439][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 89.25% examples, 975329 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:26:03,661][gensim.models.word2vec][INFO] - EPOCH 9: training on 2183622 raw words (2185836 effective words) took 2.2s, 977884 effective words/s
[2023-02-07 18:26:04,694][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 39.48% examples, 863039 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:05,695][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 82.68% examples, 896197 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:26:06,091][gensim.models.word2vec][INFO] - EPOCH 10: training on 2183622 raw words (2185836 effective words) took 2.4s, 900482 effective words/s
[2023-02-07 18:26:07,120][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 40.37% examples, 883999 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:08,135][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 83.79% examples, 906359 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:26:08,485][gensim.models.word2vec][INFO] - EPOCH 11: training on 2183622 raw words (2185836 effective words) took 2.4s, 914103 effective words/s
[2023-02-07 18:26:09,490][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 39.48% examples, 886283 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:10,496][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 82.68% examples, 906385 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:10,870][gensim.models.word2vec][INFO] - EPOCH 12: training on 2183622 raw words (2185836 effective words) took 2.4s, 917397 effective words/s
[2023-02-07 18:26:11,883][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 39.91% examples, 888705 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:26:12,897][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 88.58% examples, 960562 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:13,102][gensim.models.word2vec][INFO] - EPOCH 13: training on 2183622 raw words (2185836 effective words) took 2.2s, 980381 effective words/s
[2023-02-07 18:26:14,109][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 47.71% examples, 1060104 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:15,110][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 96.28% examples, 1049312 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:26:15,177][gensim.models.word2vec][INFO] - EPOCH 14: training on 2183622 raw words (2185836 effective words) took 2.1s, 1053622 effective words/s
[2023-02-07 18:26:15,178][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 32754330 raw words (32787540 effective words) took 34.7s, 943558 effective words/s', 'datetime': '2023-02-07T18:26:15.178417', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:26:15.178 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:26:16,533][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182519-k3is6zwp/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:26:16.533523', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:26:16,534][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:26:16,550][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182519-k3is6zwp/files/../tmp/embedding_model.pt
2023-02-07 18:26:16.551 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:26:17.916 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:26:18.460 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:26:19.692 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0859550527149993, 'test_mae': 0.8111747514707911, 'test_r2': -2.662740412766797}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.03
wandb: percentage 0.23413
wandb:   test_mae 0.81117
wandb:   test_mse 1.08596
wandb:    test_r2 -2.66274
wandb: 
wandb: üöÄ View run misty-sweep-6 at: https://wandb.ai/xiaoqiz/mof2vec/runs/k3is6zwp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_182519-k3is6zwp/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: f5u0w0tp with config:
wandb: 	data.data.wl_step: 2
wandb: 	data.nn.batch_size: 78
wandb: 	model.gensim.alpha: 0.002280950281563492
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.6170051155376873
wandb: 	model.gensim.vector_size: 395
wandb: 	model.gensim.window: 13
wandb: 	model.sklearn.learning_rate: 0.0004132541050723349
wandb: 	model.sklearn.max_depth: 58
wandb: 	model.sklearn.min_child_weight: 0.06737186971346763
wandb: 	model.sklearn.n_estimators: 2769
wandb: 	model.sklearn.num_leaves: 389
wandb: 	model.sklearn.reg_alpha: 0.8295134714927005
wandb: 	model.sklearn.reg_lambda: 0.02308193954136924
wandb: 	model.sklearn.subsample: 0.9841799820171864
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182638-f5u0w0tp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/f5u0w0tp
2023-02-07 18:26:47.104 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 2 for sweep.
2023-02-07 18:26:47.104 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 78 for sweep.
2023-02-07 18:26:47.105 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.002280950281563492 for sweep.
2023-02-07 18:26:47.105 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:26:47.105 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 18:26:47.105 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6170051155376873 for sweep.
2023-02-07 18:26:47.106 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 395 for sweep.
2023-02-07 18:26:47.106 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 13 for sweep.
2023-02-07 18:26:47.106 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0004132541050723349 for sweep.
2023-02-07 18:26:47.106 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 58 for sweep.
2023-02-07 18:26:47.106 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.06737186971346763 for sweep.
2023-02-07 18:26:47.107 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2769 for sweep.
2023-02-07 18:26:47.107 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 389 for sweep.
2023-02-07 18:26:47.107 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.8295134714927005 for sweep.
2023-02-07 18:26:47.107 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.02308193954136924 for sweep.
2023-02-07 18:26:47.108 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9841799820171864 for sweep.
2023-02-07 18:26:47.108 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:26:47.116 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 2}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182638-f5u0w0tp/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 78, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 395, 'window': 13, 'min_count': 6, 'dm': 1, 'sample': 0.6170051155376873, 'workers': 4, 'alpha': 0.002280950281563492, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2769, 'max_depth': 58, 'num_leaves': 389, 'reg_alpha': 0.8295134714927005, 'reg_lambda': 0.02308193954136924, 'subsample': 0.9841799820171864, 'min_child_weight': 0.06737186971346763, 'n_jobs': 4, 'learning_rate': 0.0004132541050723349}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 3/3257 [00:00<03:21, 16.16it/s]  1%|          | 30/3257 [00:00<00:25, 124.74it/s]  2%|‚ñè         | 56/3257 [00:00<00:18, 175.09it/s]  3%|‚ñé         | 85/3257 [00:00<00:14, 214.64it/s]  3%|‚ñé         | 110/3257 [00:00<00:13, 226.11it/s]  4%|‚ñç         | 139/3257 [00:00<00:12, 246.33it/s]  5%|‚ñå         | 165/3257 [00:00<00:12, 249.52it/s]  6%|‚ñå         | 196/3257 [00:00<00:11, 265.36it/s]  7%|‚ñã         | 229/3257 [00:00<00:10, 284.70it/s]  8%|‚ñä         | 258/3257 [00:01<00:10, 284.08it/s]  9%|‚ñâ         | 288/3257 [00:01<00:10, 287.96it/s] 10%|‚ñâ         | 317/3257 [00:01<00:10, 283.09it/s] 11%|‚ñà         | 346/3257 [00:01<00:10, 284.89it/s] 12%|‚ñà‚ñè        | 376/3257 [00:01<00:10, 284.87it/s] 12%|‚ñà‚ñè        | 405/3257 [00:01<00:10, 280.16it/s] 13%|‚ñà‚ñé        | 434/3257 [00:01<00:10, 260.22it/s] 14%|‚ñà‚ñç        | 466/3257 [00:01<00:10, 275.71it/s] 15%|‚ñà‚ñå        | 496/3257 [00:01<00:09, 282.06it/s] 16%|‚ñà‚ñå        | 526/3257 [00:02<00:09, 284.56it/s] 17%|‚ñà‚ñã        | 558/3257 [00:02<00:09, 286.37it/s] 18%|‚ñà‚ñä        | 587/3257 [00:02<00:09, 271.49it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:02<00:09, 282.20it/s] 20%|‚ñà‚ñà        | 655/3257 [00:02<00:08, 300.80it/s] 21%|‚ñà‚ñà        | 690/3257 [00:02<00:08, 314.83it/s] 22%|‚ñà‚ñà‚ñè       | 726/3257 [00:02<00:07, 327.67it/s] 23%|‚ñà‚ñà‚ñé       | 765/3257 [00:02<00:07, 345.39it/s] 25%|‚ñà‚ñà‚ñç       | 801/3257 [00:02<00:07, 349.10it/s] 26%|‚ñà‚ñà‚ñå       | 837/3257 [00:03<00:07, 336.66it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:03<00:07, 332.03it/s] 28%|‚ñà‚ñà‚ñä       | 906/3257 [00:03<00:06, 337.15it/s] 29%|‚ñà‚ñà‚ñâ       | 945/3257 [00:03<00:06, 351.87it/s] 30%|‚ñà‚ñà‚ñà       | 982/3257 [00:03<00:06, 357.16it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1018/3257 [00:03<00:06, 351.84it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1054/3257 [00:03<00:06, 345.07it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1089/3257 [00:03<00:06, 342.21it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:03<00:06, 334.10it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1160/3257 [00:03<00:06, 340.41it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1195/3257 [00:04<00:06, 327.86it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:04<00:05, 337.85it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1270/3257 [00:04<00:05, 349.24it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1306/3257 [00:04<00:08, 236.03it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:04<00:07, 265.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1376/3257 [00:04<00:06, 276.15it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:04<00:06, 296.57it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1451/3257 [00:04<00:05, 319.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1490/3257 [00:05<00:05, 337.13it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1526/3257 [00:05<00:05, 343.15it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1562/3257 [00:05<00:04, 345.65it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1602/3257 [00:05<00:04, 358.40it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:05<00:04, 360.01it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:05<00:04, 350.80it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1714/3257 [00:05<00:04, 358.20it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1751/3257 [00:05<00:04, 339.12it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:05<00:04, 354.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:06<00:04, 348.76it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:06<00:03, 363.08it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1906/3257 [00:06<00:03, 362.54it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1943/3257 [00:06<00:03, 358.59it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1979/3257 [00:06<00:03, 336.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2013/3257 [00:06<00:03, 316.85it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2046/3257 [00:06<00:03, 307.96it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2078/3257 [00:06<00:04, 286.89it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2108/3257 [00:06<00:04, 279.41it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:07<00:04, 274.73it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:07<00:03, 275.72it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2197/3257 [00:07<00:03, 284.41it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2226/3257 [00:07<00:03, 280.72it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2255/3257 [00:07<00:03, 281.10it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2284/3257 [00:07<00:03, 283.25it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:07<00:03, 286.38it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2355/3257 [00:07<00:02, 318.82it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2388/3257 [00:07<00:02, 319.30it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2421/3257 [00:07<00:02, 308.22it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2452/3257 [00:08<00:02, 291.57it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2487/3257 [00:08<00:02, 306.74it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2523/3257 [00:08<00:02, 318.56it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2556/3257 [00:08<00:02, 311.74it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2588/3257 [00:08<00:02, 297.09it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2626/3257 [00:08<00:01, 317.80it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2659/3257 [00:08<00:02, 207.60it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2695/3257 [00:09<00:02, 237.95it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2730/3257 [00:09<00:02, 262.75it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2769/3257 [00:09<00:01, 291.39it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2809/3257 [00:09<00:01, 319.07it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2844/3257 [00:09<00:01, 323.78it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2889/3257 [00:09<00:01, 357.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:09<00:00, 361.06it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:09<00:00, 359.12it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:09<00:00, 361.96it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3045/3257 [00:09<00:00, 374.44it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3087/3257 [00:10<00:00, 384.75it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3129/3257 [00:10<00:00, 394.05it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3169/3257 [00:10<00:00, 384.13it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3208/3257 [00:10<00:00, 379.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3247/3257 [00:10<00:00, 377.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:10<00:00, 309.90it/s]
2023-02-07 18:26:57.890 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:26:57,892][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d395,n5,w13,mc6,s0.617005,t4>', 'datetime': '2023-02-07T18:26:57.892285', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:26:57,892][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:26:57,892][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:26:58,078][gensim.models.doc2vec][INFO] - collected 2819 word types and 3257 unique tags from a corpus of 3257 examples and 2183622 words
[2023-02-07 18:26:58,078][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:26:58,083][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 1604 unique words (56.90% of original 2819, drops 1215)', 'datetime': '2023-02-07T18:26:58.083045', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:26:58,083][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 2180389 word corpus (99.85% of original 2183622, drops 3233)', 'datetime': '2023-02-07T18:26:58.083275', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:26:58,088][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 2819 items
[2023-02-07 18:26:58,088][gensim.models.word2vec][INFO] - sample=0.617005 downsamples 0 most-common words
[2023-02-07 18:26:58,088][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2180389 word corpus (100.0%% of prior 2180389)', 'datetime': '2023-02-07T18:26:58.088873', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:26:58,098][gensim.models.word2vec][INFO] - estimated required memory for 1604 words and 395 dimensions: 11668100 bytes
[2023-02-07 18:26:58,098][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:26:58,105][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 1604 vocabulary and 395 features, using sg=0 hs=0 sample=0.6170051155376873 negative=5 window=13 shrink_windows=True', 'datetime': '2023-02-07T18:26:58.105363', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:26:59,115][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 33.87% examples, 741987 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:00,126][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 68.65% examples, 758521 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:00,982][gensim.models.word2vec][INFO] - EPOCH 0: training on 2183622 raw words (2183646 effective words) took 2.9s, 759595 effective words/s
[2023-02-07 18:27:02,000][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 33.44% examples, 727372 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:27:03,001][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 66.93% examples, 740131 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:03,941][gensim.models.word2vec][INFO] - EPOCH 1: training on 2183622 raw words (2183646 effective words) took 3.0s, 738614 effective words/s
[2023-02-07 18:27:04,951][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 35.55% examples, 786298 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:05,957][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 70.71% examples, 784426 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:06,723][gensim.models.word2vec][INFO] - EPOCH 2: training on 2183622 raw words (2183646 effective words) took 2.8s, 785484 effective words/s
[2023-02-07 18:27:07,729][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 34.26% examples, 753977 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:08,746][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 66.53% examples, 733837 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:09,662][gensim.models.word2vec][INFO] - EPOCH 3: training on 2183622 raw words (2183646 effective words) took 2.9s, 743499 effective words/s
[2023-02-07 18:27:10,693][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 33.44% examples, 718542 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:11,695][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 68.59% examples, 754080 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:12,514][gensim.models.word2vec][INFO] - EPOCH 4: training on 2183622 raw words (2183646 effective words) took 2.8s, 766241 effective words/s
[2023-02-07 18:27:13,524][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 33.83% examples, 742245 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:14,544][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 68.25% examples, 750568 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:27:15,415][gensim.models.word2vec][INFO] - EPOCH 5: training on 2183622 raw words (2183646 effective words) took 2.9s, 753380 effective words/s
[2023-02-07 18:27:16,417][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 33.44% examples, 738423 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:27:17,429][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 66.53% examples, 737359 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:18,264][gensim.models.word2vec][INFO] - EPOCH 6: training on 2183622 raw words (2183646 effective words) took 2.8s, 766948 effective words/s
[2023-02-07 18:27:19,269][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 34.57% examples, 763426 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:27:20,283][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 68.99% examples, 763656 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:21,154][gensim.models.word2vec][INFO] - EPOCH 7: training on 2183622 raw words (2183646 effective words) took 2.9s, 756107 effective words/s
[2023-02-07 18:27:22,160][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 33.13% examples, 725620 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:23,179][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 65.74% examples, 723747 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:27:24,074][gensim.models.word2vec][INFO] - EPOCH 8: training on 2183622 raw words (2183646 effective words) took 2.9s, 748144 effective words/s
[2023-02-07 18:27:25,082][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 35.22% examples, 777901 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:26,097][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 70.13% examples, 776785 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:27:26,877][gensim.models.word2vec][INFO] - EPOCH 9: training on 2183622 raw words (2183646 effective words) took 2.8s, 779385 effective words/s
[2023-02-07 18:27:27,896][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 31.50% examples, 681027 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:27:28,904][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 64.17% examples, 704571 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:29,872][gensim.models.word2vec][INFO] - EPOCH 10: training on 2183622 raw words (2183646 effective words) took 3.0s, 729714 effective words/s
[2023-02-07 18:27:30,881][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 36.11% examples, 796264 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:31,884][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 71.32% examples, 790964 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:27:32,644][gensim.models.word2vec][INFO] - EPOCH 11: training on 2183622 raw words (2183646 effective words) took 2.8s, 788222 effective words/s
[2023-02-07 18:27:33,658][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 33.56% examples, 728561 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:34,676][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 67.79% examples, 744875 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:35,542][gensim.models.word2vec][INFO] - EPOCH 12: training on 2183622 raw words (2183646 effective words) took 2.9s, 753952 effective words/s
[2023-02-07 18:27:36,546][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 33.44% examples, 737720 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:27:37,548][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 67.79% examples, 754435 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:38,390][gensim.models.word2vec][INFO] - EPOCH 13: training on 2183622 raw words (2183646 effective words) took 2.8s, 767303 effective words/s
[2023-02-07 18:27:39,400][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 34.57% examples, 760296 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:40,415][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 67.79% examples, 747681 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:27:41,268][gensim.models.word2vec][INFO] - EPOCH 14: training on 2183622 raw words (2183646 effective words) took 2.9s, 759537 effective words/s
[2023-02-07 18:27:41,268][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 32754330 raw words (32754690 effective words) took 43.2s, 758862 effective words/s', 'datetime': '2023-02-07T18:27:41.268610', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:27:41.268 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:27:43,019][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182638-f5u0w0tp/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:27:43.019663', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:27:43,020][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:27:43,039][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182638-f5u0w0tp/files/../tmp/embedding_model.pt
2023-02-07 18:27:43.039 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:27:45.221 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:27:46.084 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:27:48.878 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0935776379909656, 'test_mae': 0.7934733651624135, 'test_r2': -2.6005952020435856}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.11
wandb: percentage 0.431
wandb:   test_mae 0.79347
wandb:   test_mse 1.09358
wandb:    test_r2 -2.6006
wandb: 
wandb: üöÄ View run visionary-sweep-7 at: https://wandb.ai/xiaoqiz/mof2vec/runs/f5u0w0tp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_182638-f5u0w0tp/logs
wandb: Agent Starting Run: kkd37g67 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 809
wandb: 	model.gensim.alpha: 0.0004134889326862686
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.27375435763681594
wandb: 	model.gensim.vector_size: 442
wandb: 	model.gensim.window: 1
wandb: 	model.sklearn.learning_rate: 0.002190951006607668
wandb: 	model.sklearn.max_depth: 63
wandb: 	model.sklearn.min_child_weight: 0.0810071400578935
wandb: 	model.sklearn.n_estimators: 2273
wandb: 	model.sklearn.num_leaves: 220
wandb: 	model.sklearn.reg_alpha: 0.9474737762030596
wandb: 	model.sklearn.reg_lambda: 0.007466343363795238
wandb: 	model.sklearn.subsample: 0.9956217497232625
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182759-kkd37g67
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/kkd37g67
2023-02-07 18:28:07.204 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 18:28:07.205 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 809 for sweep.
2023-02-07 18:28:07.205 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0004134889326862686 for sweep.
2023-02-07 18:28:07.205 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:28:07.206 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 18:28:07.206 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.27375435763681594 for sweep.
2023-02-07 18:28:07.206 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 442 for sweep.
2023-02-07 18:28:07.206 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 1 for sweep.
2023-02-07 18:28:07.207 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.002190951006607668 for sweep.
2023-02-07 18:28:07.207 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 63 for sweep.
2023-02-07 18:28:07.208 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0810071400578935 for sweep.
2023-02-07 18:28:07.208 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2273 for sweep.
2023-02-07 18:28:07.208 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 220 for sweep.
2023-02-07 18:28:07.208 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.9474737762030596 for sweep.
2023-02-07 18:28:07.209 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.007466343363795238 for sweep.
2023-02-07 18:28:07.209 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9956217497232625 for sweep.
2023-02-07 18:28:07.209 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:28:07.215 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182759-kkd37g67/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 809, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 442, 'window': 1, 'min_count': 5, 'dm': 1, 'sample': 0.27375435763681594, 'workers': 4, 'alpha': 0.0004134889326862686, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2273, 'max_depth': 63, 'num_leaves': 220, 'reg_alpha': 0.9474737762030596, 'reg_lambda': 0.007466343363795238, 'subsample': 0.9956217497232625, 'min_child_weight': 0.0810071400578935, 'n_jobs': 4, 'learning_rate': 0.002190951006607668}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:22, 145.87it/s]  1%|          | 34/3257 [00:00<00:20, 159.56it/s]  2%|‚ñè         | 52/3257 [00:00<00:19, 166.43it/s]  2%|‚ñè         | 69/3257 [00:00<00:19, 166.10it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 175.20it/s]  3%|‚ñé         | 108/3257 [00:00<00:18, 169.23it/s]  4%|‚ñç         | 126/3257 [00:00<00:18, 171.55it/s]  5%|‚ñç         | 148/3257 [00:00<00:16, 184.59it/s]  5%|‚ñå         | 167/3257 [00:00<00:17, 175.50it/s]  6%|‚ñå         | 185/3257 [00:01<00:17, 174.82it/s]  6%|‚ñå         | 203/3257 [00:01<00:17, 173.34it/s]  7%|‚ñã         | 228/3257 [00:01<00:15, 194.27it/s]  8%|‚ñä         | 248/3257 [00:01<00:15, 192.05it/s]  8%|‚ñä         | 268/3257 [00:01<00:16, 181.50it/s]  9%|‚ñâ         | 294/3257 [00:01<00:14, 201.28it/s] 10%|‚ñâ         | 315/3257 [00:01<00:15, 190.77it/s] 10%|‚ñà         | 336/3257 [00:01<00:15, 192.92it/s] 11%|‚ñà         | 357/3257 [00:01<00:14, 197.22it/s] 12%|‚ñà‚ñè        | 377/3257 [00:02<00:15, 181.27it/s] 12%|‚ñà‚ñè        | 396/3257 [00:02<00:15, 179.90it/s] 13%|‚ñà‚ñé        | 416/3257 [00:02<00:15, 184.65it/s] 13%|‚ñà‚ñé        | 435/3257 [00:02<00:18, 155.83it/s] 14%|‚ñà‚ñç        | 456/3257 [00:02<00:16, 168.01it/s] 15%|‚ñà‚ñç        | 475/3257 [00:02<00:16, 170.83it/s] 15%|‚ñà‚ñå        | 495/3257 [00:02<00:15, 176.50it/s] 16%|‚ñà‚ñå        | 516/3257 [00:02<00:14, 185.05it/s] 16%|‚ñà‚ñã        | 535/3257 [00:02<00:15, 178.99it/s] 17%|‚ñà‚ñã        | 554/3257 [00:03<00:14, 181.72it/s] 18%|‚ñà‚ñä        | 573/3257 [00:03<00:17, 157.26it/s] 18%|‚ñà‚ñä        | 593/3257 [00:03<00:15, 168.25it/s] 19%|‚ñà‚ñâ        | 611/3257 [00:03<00:23, 110.97it/s] 19%|‚ñà‚ñâ        | 628/3257 [00:03<00:21, 122.49it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:19, 132.07it/s] 20%|‚ñà‚ñà        | 661/3257 [00:03<00:19, 133.32it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:17, 146.13it/s] 22%|‚ñà‚ñà‚ñè       | 702/3257 [00:04<00:16, 155.81it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:04<00:15, 162.84it/s] 23%|‚ñà‚ñà‚ñé       | 739/3257 [00:04<00:16, 155.12it/s] 23%|‚ñà‚ñà‚ñé       | 760/3257 [00:04<00:14, 169.08it/s] 24%|‚ñà‚ñà‚ñç       | 778/3257 [00:04<00:14, 166.32it/s] 24%|‚ñà‚ñà‚ñç       | 797/3257 [00:04<00:14, 170.86it/s] 25%|‚ñà‚ñà‚ñå       | 815/3257 [00:04<00:14, 169.79it/s] 26%|‚ñà‚ñà‚ñå       | 833/3257 [00:04<00:14, 165.16it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:05<00:15, 157.16it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:05<00:14, 162.70it/s] 27%|‚ñà‚ñà‚ñã       | 885/3257 [00:05<00:14, 160.02it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:05<00:13, 173.67it/s] 28%|‚ñà‚ñà‚ñä       | 925/3257 [00:05<00:13, 175.33it/s] 29%|‚ñà‚ñà‚ñâ       | 943/3257 [00:05<00:13, 171.15it/s] 30%|‚ñà‚ñà‚ñâ       | 963/3257 [00:05<00:12, 178.80it/s] 30%|‚ñà‚ñà‚ñà       | 981/3257 [00:05<00:13, 172.81it/s] 31%|‚ñà‚ñà‚ñà       | 999/3257 [00:05<00:13, 170.68it/s] 31%|‚ñà‚ñà‚ñà       | 1017/3257 [00:06<00:13, 171.63it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1035/3257 [00:06<00:13, 163.85it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1052/3257 [00:06<00:13, 159.16it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1071/3257 [00:06<00:13, 167.60it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:06<00:13, 163.84it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:06<00:13, 163.93it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1122/3257 [00:06<00:13, 164.16it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:06<00:13, 161.11it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1156/3257 [00:06<00:12, 163.47it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1174/3257 [00:07<00:12, 166.90it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:07<00:13, 149.23it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:07<00:13, 149.31it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1226/3257 [00:07<00:12, 160.01it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:07<00:12, 164.57it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1269/3257 [00:07<00:10, 184.96it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:07<00:11, 170.57it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:07<00:10, 181.04it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1333/3257 [00:07<00:09, 196.74it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:08<00:09, 198.79it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1376/3257 [00:08<00:09, 203.68it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1398/3257 [00:08<00:08, 207.16it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1424/3257 [00:08<00:08, 219.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1449/3257 [00:08<00:07, 226.17it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:08<00:07, 231.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1498/3257 [00:08<00:07, 226.91it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1521/3257 [00:08<00:08, 213.08it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1543/3257 [00:08<00:08, 206.13it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1564/3257 [00:08<00:08, 201.97it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1585/3257 [00:09<00:08, 199.53it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1608/3257 [00:09<00:07, 206.93it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1632/3257 [00:09<00:07, 215.21it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:09<00:08, 197.77it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1675/3257 [00:09<00:08, 189.68it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1695/3257 [00:09<00:08, 188.71it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1716/3257 [00:09<00:08, 191.88it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1736/3257 [00:09<00:08, 176.38it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1758/3257 [00:10<00:08, 187.00it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:10<00:07, 191.75it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1800/3257 [00:10<00:07, 194.88it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1820/3257 [00:10<00:07, 195.07it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1840/3257 [00:10<00:07, 190.10it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1860/3257 [00:10<00:07, 187.16it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:10<00:11, 116.40it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:10<00:10, 128.71it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1917/3257 [00:11<00:09, 143.83it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1941/3257 [00:11<00:07, 166.53it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1968/3257 [00:11<00:06, 192.74it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1990/3257 [00:11<00:06, 192.54it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2012/3257 [00:11<00:06, 197.03it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2034/3257 [00:11<00:06, 202.26it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2056/3257 [00:11<00:06, 186.42it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2076/3257 [00:11<00:06, 187.40it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2096/3257 [00:11<00:06, 182.72it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:12<00:06, 189.73it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:12<00:06, 182.08it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2156/3257 [00:12<00:06, 180.74it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:12<00:05, 186.96it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2199/3257 [00:12<00:05, 193.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:12<00:05, 188.60it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:12<00:05, 183.45it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2257/3257 [00:12<00:05, 183.39it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:12<00:05, 170.60it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:13<00:05, 184.35it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2324/3257 [00:13<00:04, 201.50it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2350/3257 [00:13<00:04, 216.45it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2372/3257 [00:13<00:04, 205.26it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:13<00:04, 214.29it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2419/3257 [00:13<00:04, 200.51it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:13<00:04, 198.18it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2461/3257 [00:13<00:04, 197.82it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2483/3257 [00:13<00:03, 203.11it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:14<00:03, 213.53it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2530/3257 [00:14<00:03, 217.27it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2552/3257 [00:14<00:03, 207.68it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:14<00:03, 192.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2593/3257 [00:14<00:03, 190.58it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2621/3257 [00:14<00:02, 214.49it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2643/3257 [00:14<00:02, 209.09it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2665/3257 [00:14<00:03, 197.29it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:14<00:02, 201.66it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2708/3257 [00:15<00:02, 183.17it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2727/3257 [00:15<00:02, 184.21it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2750/3257 [00:15<00:02, 196.44it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2770/3257 [00:15<00:02, 185.37it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:15<00:02, 200.74it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2816/3257 [00:15<00:02, 195.34it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2836/3257 [00:15<00:02, 188.34it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2861/3257 [00:15<00:01, 203.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:15<00:01, 209.63it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2908/3257 [00:16<00:01, 196.33it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2930/3257 [00:16<00:01, 198.18it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:16<00:01, 192.31it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2972/3257 [00:16<00:01, 196.28it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2992/3257 [00:16<00:01, 188.18it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:16<00:01, 198.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3039/3257 [00:16<00:01, 206.43it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3065/3257 [00:16<00:00, 219.27it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3088/3257 [00:16<00:00, 213.08it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3114/3257 [00:17<00:00, 224.97it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3137/3257 [00:17<00:00, 215.87it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3159/3257 [00:17<00:00, 208.57it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3180/3257 [00:17<00:00, 196.96it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3204/3257 [00:17<00:00, 208.21it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3226/3257 [00:17<00:00, 203.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:17<00:00, 209.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 183.50it/s]
2023-02-07 18:28:25.630 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:28:25,631][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d442,n5,w1,mc5,s0.273754,t4>', 'datetime': '2023-02-07T18:28:25.631209', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:28:25,631][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:28:25,631][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:28:26,078][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 18:28:26,079][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:28:26,130][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 16108 unique words (50.65% of original 31803, drops 15695)', 'datetime': '2023-02-07T18:28:26.130619', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:28:26,131][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5056108 word corpus (99.23% of original 5095118, drops 39010)', 'datetime': '2023-02-07T18:28:26.131137', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:28:26,188][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 18:28:26,190][gensim.models.word2vec][INFO] - sample=0.273754 downsamples 0 most-common words
[2023-02-07 18:28:26,190][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5056108 word corpus (100.0%% of prior 5056108)', 'datetime': '2023-02-07T18:28:26.190328', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:28:26,290][gensim.models.word2vec][INFO] - estimated required memory for 16108 words and 442 dimensions: 71421664 bytes
[2023-02-07 18:28:26,290][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:28:26,332][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 16108 vocabulary and 442 features, using sg=0 hs=0 sample=0.27375435763681594 negative=5 window=1 shrink_windows=True', 'datetime': '2023-02-07T18:28:26.332568', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:28:27,343][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 22.78% examples, 1138534 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:28:28,345][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 44.89% examples, 1152336 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:29,358][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 67.85% examples, 1158756 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:30,360][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 92.35% examples, 1165690 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:30,647][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5048130 effective words) took 4.3s, 1170803 effective words/s
[2023-02-07 18:28:31,664][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 24.07% examples, 1195903 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:28:32,670][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 48.08% examples, 1228215 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:33,674][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 72.92% examples, 1236519 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:28:34,675][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 99.69% examples, 1249645 words/s, in_qsize 2, out_qsize 1
[2023-02-07 18:28:34,682][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5048130 effective words) took 4.0s, 1251947 effective words/s
[2023-02-07 18:28:35,685][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 31.72% examples, 1618462 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:36,686][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 61.28% examples, 1568586 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:37,686][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 90.85% examples, 1538889 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:37,963][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5048130 effective words) took 3.3s, 1539384 effective words/s
[2023-02-07 18:28:38,966][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 29.32% examples, 1480770 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:39,969][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 58.06% examples, 1496904 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:40,971][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 88.70% examples, 1496120 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:28:41,336][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5048130 effective words) took 3.4s, 1497542 effective words/s
[2023-02-07 18:28:42,341][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 30.00% examples, 1511790 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:43,344][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 59.47% examples, 1527385 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:44,348][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 91.37% examples, 1543928 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:44,591][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5048130 effective words) took 3.3s, 1551825 effective words/s
[2023-02-07 18:28:45,595][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 30.95% examples, 1572380 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:28:46,598][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 58.80% examples, 1509920 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:28:47,599][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 86.40% examples, 1461188 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:48,059][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5048130 effective words) took 3.5s, 1456180 effective words/s
[2023-02-07 18:28:49,067][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 26.87% examples, 1357839 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:28:50,080][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.30% examples, 1368441 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:28:51,086][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 81.39% examples, 1370256 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:28:51,737][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5048130 effective words) took 3.7s, 1373532 effective words/s
[2023-02-07 18:28:52,740][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 26.71% examples, 1355523 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:53,754][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 53.30% examples, 1371522 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:54,761][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 83.30% examples, 1407168 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:28:55,208][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5048130 effective words) took 3.5s, 1455417 effective words/s
[2023-02-07 18:28:56,212][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 33.83% examples, 1724527 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:28:57,221][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 65.09% examples, 1665864 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:28:58,223][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 98.13% examples, 1644556 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:28:58,275][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5048130 effective words) took 3.1s, 1646729 effective words/s
[2023-02-07 18:28:59,285][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 30.95% examples, 1562201 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:29:00,294][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 61.84% examples, 1569499 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:29:01,296][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 94.20% examples, 1579657 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:29:01,467][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5048130 effective words) took 3.2s, 1581956 effective words/s
[2023-02-07 18:29:02,471][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 31.26% examples, 1590674 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:03,476][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 62.60% examples, 1598182 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:04,480][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 95.89% examples, 1608108 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:29:04,598][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5048130 effective words) took 3.1s, 1613411 effective words/s
[2023-02-07 18:29:05,603][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 28.65% examples, 1450939 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:06,611][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 55.76% examples, 1434059 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:07,618][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 84.03% examples, 1419538 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:08,156][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5048130 effective words) took 3.6s, 1419486 effective words/s
[2023-02-07 18:29:09,163][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 27.14% examples, 1378238 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:10,164][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 54.28% examples, 1397786 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:11,164][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 82.71% examples, 1401209 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:29:11,755][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5048130 effective words) took 3.6s, 1403592 effective words/s
[2023-02-07 18:29:12,766][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 28.03% examples, 1408003 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:29:13,774][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 56.25% examples, 1443987 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:14,777][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 92.51% examples, 1555939 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:29:14,984][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5048130 effective words) took 3.2s, 1564158 effective words/s
[2023-02-07 18:29:15,987][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 31.72% examples, 1618455 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:16,990][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 63.37% examples, 1624571 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:29:17,991][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 96.28% examples, 1619089 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:29:18,105][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5048130 effective words) took 3.1s, 1618513 effective words/s
[2023-02-07 18:29:18,106][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75721950 effective words) took 51.8s, 1462577 effective words/s', 'datetime': '2023-02-07T18:29:18.106070', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:29:18.106 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:29:22,292][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182759-kkd37g67/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:29:22.292619', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:29:22,293][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:29:22,368][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182759-kkd37g67/files/../tmp/embedding_model.pt
2023-02-07 18:29:22.368 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:29:24.818 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:29:25.715 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:29:28.731 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0973690199237933, 'test_mae': 0.8221396347222153, 'test_r2': -3.5037296414758297}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.032 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.032 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.15
wandb: percentage 0.49351
wandb:   test_mae 0.82214
wandb:   test_mse 1.09737
wandb:    test_r2 -3.50373
wandb: 
wandb: üöÄ View run desert-sweep-8 at: https://wandb.ai/xiaoqiz/mof2vec/runs/kkd37g67
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_182759-kkd37g67/logs
wandb: Agent Starting Run: afpg2aza with config:
wandb: 	data.data.wl_step: 2
wandb: 	data.nn.batch_size: 147
wandb: 	model.gensim.alpha: 0.001004354398023403
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.3679030417579083
wandb: 	model.gensim.vector_size: 338
wandb: 	model.gensim.window: 12
wandb: 	model.sklearn.learning_rate: 0.02107379459560509
wandb: 	model.sklearn.max_depth: 68
wandb: 	model.sklearn.min_child_weight: 0.030181733474183528
wandb: 	model.sklearn.n_estimators: 2460
wandb: 	model.sklearn.num_leaves: 383
wandb: 	model.sklearn.reg_alpha: 0.07951156976685243
wandb: 	model.sklearn.reg_lambda: 0.011196648672216907
wandb: 	model.sklearn.subsample: 0.7396135449692098
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182940-afpg2aza
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/afpg2aza
2023-02-07 18:29:48.742 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 2 for sweep.
2023-02-07 18:29:48.743 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 147 for sweep.
2023-02-07 18:29:48.743 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.001004354398023403 for sweep.
2023-02-07 18:29:48.744 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:29:48.744 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 18:29:48.744 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.3679030417579083 for sweep.
2023-02-07 18:29:48.745 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 338 for sweep.
2023-02-07 18:29:48.745 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 12 for sweep.
2023-02-07 18:29:48.745 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.02107379459560509 for sweep.
2023-02-07 18:29:48.745 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 68 for sweep.
2023-02-07 18:29:48.746 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.030181733474183528 for sweep.
2023-02-07 18:29:48.746 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2460 for sweep.
2023-02-07 18:29:48.746 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 383 for sweep.
2023-02-07 18:29:48.746 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.07951156976685243 for sweep.
2023-02-07 18:29:48.747 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.011196648672216907 for sweep.
2023-02-07 18:29:48.747 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7396135449692098 for sweep.
2023-02-07 18:29:48.747 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:29:48.754 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 2}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182940-afpg2aza/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 147, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 338, 'window': 12, 'min_count': 8, 'dm': 1, 'sample': 0.3679030417579083, 'workers': 4, 'alpha': 0.001004354398023403, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2460, 'max_depth': 68, 'num_leaves': 383, 'reg_alpha': 0.07951156976685243, 'reg_lambda': 0.011196648672216907, 'subsample': 0.7396135449692098, 'min_child_weight': 0.030181733474183528, 'n_jobs': 4, 'learning_rate': 0.02107379459560509}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 28/3257 [00:00<00:11, 275.50it/s]  2%|‚ñè         | 56/3257 [00:00<00:12, 261.98it/s]  3%|‚ñé         | 89/3257 [00:00<00:10, 290.62it/s]  4%|‚ñé         | 119/3257 [00:00<00:18, 167.45it/s]  5%|‚ñç         | 151/3257 [00:00<00:15, 201.91it/s]  5%|‚ñå         | 179/3257 [00:00<00:13, 219.90it/s]  6%|‚ñã         | 211/3257 [00:00<00:12, 244.55it/s]  7%|‚ñã         | 243/3257 [00:01<00:11, 263.39it/s]  9%|‚ñä         | 282/3257 [00:01<00:09, 298.19it/s] 10%|‚ñâ         | 324/3257 [00:01<00:08, 332.37it/s] 11%|‚ñà         | 362/3257 [00:01<00:08, 344.42it/s] 12%|‚ñà‚ñè        | 399/3257 [00:01<00:08, 350.09it/s] 13%|‚ñà‚ñé        | 435/3257 [00:01<00:08, 334.22it/s] 15%|‚ñà‚ñç        | 477/3257 [00:01<00:07, 356.39it/s] 16%|‚ñà‚ñå        | 519/3257 [00:01<00:07, 372.46it/s] 17%|‚ñà‚ñã        | 558/3257 [00:01<00:07, 370.79it/s] 18%|‚ñà‚ñä        | 596/3257 [00:01<00:07, 363.53it/s] 20%|‚ñà‚ñâ        | 637/3257 [00:02<00:06, 375.72it/s] 21%|‚ñà‚ñà        | 675/3257 [00:02<00:07, 360.19it/s] 22%|‚ñà‚ñà‚ñè       | 712/3257 [00:02<00:07, 357.42it/s] 23%|‚ñà‚ñà‚ñé       | 748/3257 [00:02<00:07, 339.71it/s] 24%|‚ñà‚ñà‚ñç       | 783/3257 [00:02<00:07, 338.73it/s] 25%|‚ñà‚ñà‚ñå       | 819/3257 [00:02<00:07, 344.00it/s] 26%|‚ñà‚ñà‚ñå       | 854/3257 [00:02<00:07, 329.72it/s] 27%|‚ñà‚ñà‚ñã       | 888/3257 [00:02<00:07, 329.27it/s] 28%|‚ñà‚ñà‚ñä       | 924/3257 [00:02<00:06, 336.44it/s] 29%|‚ñà‚ñà‚ñâ       | 958/3257 [00:03<00:06, 335.86it/s] 30%|‚ñà‚ñà‚ñà       | 992/3257 [00:03<00:06, 329.07it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:03<00:06, 328.03it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1058/3257 [00:03<00:06, 316.25it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:03<00:06, 315.33it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:03<00:06, 318.35it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1156/3257 [00:03<00:06, 314.99it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:03<00:06, 300.38it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:03<00:06, 298.51it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1255/3257 [00:03<00:06, 313.09it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1287/3257 [00:04<00:09, 207.78it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1322/3257 [00:04<00:08, 237.58it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:04<00:07, 256.65it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:04<00:06, 268.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1424/3257 [00:04<00:06, 298.60it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:04<00:05, 322.57it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1504/3257 [00:04<00:05, 344.36it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1540/3257 [00:05<00:05, 330.46it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:05<00:05, 327.36it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1609/3257 [00:05<00:04, 330.76it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1643/3257 [00:05<00:05, 318.91it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:05<00:05, 310.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1710/3257 [00:05<00:04, 316.53it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1742/3257 [00:05<00:05, 295.61it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1778/3257 [00:05<00:04, 312.30it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1810/3257 [00:05<00:04, 313.75it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:05<00:04, 322.86it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1881/3257 [00:06<00:04, 329.16it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:06<00:04, 329.82it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1957/3257 [00:06<00:03, 351.02it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1993/3257 [00:06<00:03, 343.08it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2028/3257 [00:06<00:03, 335.77it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2062/3257 [00:06<00:03, 309.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2096/3257 [00:06<00:03, 310.74it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2128/3257 [00:06<00:03, 309.45it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2160/3257 [00:06<00:03, 310.03it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2192/3257 [00:07<00:03, 311.58it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2224/3257 [00:07<00:03, 312.17it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2256/3257 [00:07<00:03, 311.78it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2289/3257 [00:07<00:03, 315.95it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2328/3257 [00:07<00:02, 335.80it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2364/3257 [00:07<00:02, 340.37it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2403/3257 [00:07<00:02, 353.45it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2439/3257 [00:07<00:02, 331.09it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2473/3257 [00:07<00:02, 332.78it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:07<00:02, 334.08it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2541/3257 [00:08<00:02, 334.23it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2575/3257 [00:08<00:02, 326.26it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:08<00:01, 341.26it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2651/3257 [00:08<00:01, 347.40it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2688/3257 [00:08<00:01, 353.41it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2724/3257 [00:08<00:02, 211.35it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2764/3257 [00:08<00:01, 247.84it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2800/3257 [00:09<00:01, 271.54it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:09<00:01, 278.54it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2879/3257 [00:09<00:01, 322.06it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2915/3257 [00:09<00:01, 324.92it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:09<00:00, 322.68it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:09<00:00, 323.30it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3022/3257 [00:09<00:00, 337.55it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3066/3257 [00:09<00:00, 364.11it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3107/3257 [00:09<00:00, 375.03it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3146/3257 [00:09<00:00, 372.32it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3184/3257 [00:10<00:00, 345.69it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3220/3257 [00:10<00:00, 322.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:10<00:00, 320.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:10<00:00, 313.91it/s]
2023-02-07 18:29:59.448 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:29:59,450][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d338,n5,w12,mc8,s0.367903,t4>', 'datetime': '2023-02-07T18:29:59.450880', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:29:59,451][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:29:59,451][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:29:59,676][gensim.models.doc2vec][INFO] - collected 2819 word types and 3257 unique tags from a corpus of 3257 examples and 2183622 words
[2023-02-07 18:29:59,677][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:29:59,681][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 1410 unique words (50.02% of original 2819, drops 1409)', 'datetime': '2023-02-07T18:29:59.681673', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:29:59,682][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 2179184 word corpus (99.80% of original 2183622, drops 4438)', 'datetime': '2023-02-07T18:29:59.682127', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:29:59,687][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 2819 items
[2023-02-07 18:29:59,687][gensim.models.word2vec][INFO] - sample=0.367903 downsamples 0 most-common words
[2023-02-07 18:29:59,688][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2179184 word corpus (100.0%% of prior 2179184)', 'datetime': '2023-02-07T18:29:59.688031', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:29:59,696][gensim.models.word2vec][INFO] - estimated required memory for 1410 words and 338 dimensions: 9572504 bytes
[2023-02-07 18:29:59,697][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:29:59,705][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 1410 vocabulary and 338 features, using sg=0 hs=0 sample=0.3679030417579083 negative=5 window=12 shrink_windows=True', 'datetime': '2023-02-07T18:29:59.705776', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:30:00,718][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 38.38% examples, 850939 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:30:01,723][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 80.07% examples, 878894 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:30:02,170][gensim.models.word2vec][INFO] - EPOCH 0: training on 2183622 raw words (2182441 effective words) took 2.5s, 886570 effective words/s
[2023-02-07 18:30:03,183][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 39.48% examples, 878128 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:30:04,190][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 81.73% examples, 892286 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:30:04,595][gensim.models.word2vec][INFO] - EPOCH 1: training on 2183622 raw words (2182441 effective words) took 2.4s, 901060 effective words/s
[2023-02-07 18:30:05,600][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 39.91% examples, 894309 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:30:06,618][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 82.87% examples, 904653 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:07,008][gensim.models.word2vec][INFO] - EPOCH 2: training on 2183622 raw words (2182441 effective words) took 2.4s, 905311 effective words/s
[2023-02-07 18:30:08,014][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 44.24% examples, 986643 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:09,021][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 90.82% examples, 993365 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:09,209][gensim.models.word2vec][INFO] - EPOCH 3: training on 2183622 raw words (2182441 effective words) took 2.2s, 992517 effective words/s
[2023-02-07 18:30:10,228][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 42.00% examples, 927176 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:30:11,232][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 86.83% examples, 946039 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:30:11,497][gensim.models.word2vec][INFO] - EPOCH 4: training on 2183622 raw words (2182441 effective words) took 2.3s, 954668 effective words/s
[2023-02-07 18:30:12,526][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 40.84% examples, 891788 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:30:13,533][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 85.66% examples, 925956 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:13,845][gensim.models.word2vec][INFO] - EPOCH 5: training on 2183622 raw words (2182441 effective words) took 2.3s, 929909 effective words/s
[2023-02-07 18:30:14,856][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 41.66% examples, 927164 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:15,864][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 85.66% examples, 934502 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:16,154][gensim.models.word2vec][INFO] - EPOCH 6: training on 2183622 raw words (2182441 effective words) took 2.3s, 945900 effective words/s
[2023-02-07 18:30:17,165][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 40.84% examples, 907280 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:30:18,179][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 83.27% examples, 908441 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:30:18,540][gensim.models.word2vec][INFO] - EPOCH 7: training on 2183622 raw words (2182441 effective words) took 2.4s, 915508 effective words/s
[2023-02-07 18:30:19,549][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 39.48% examples, 881827 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:30:20,554][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 82.25% examples, 899928 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:20,951][gensim.models.word2vec][INFO] - EPOCH 8: training on 2183622 raw words (2182441 effective words) took 2.4s, 906129 effective words/s
[2023-02-07 18:30:21,959][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 39.91% examples, 891646 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:22,966][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 81.73% examples, 894538 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:30:23,376][gensim.models.word2vec][INFO] - EPOCH 9: training on 2183622 raw words (2182441 effective words) took 2.4s, 900966 effective words/s
[2023-02-07 18:30:24,380][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 39.48% examples, 886629 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:25,381][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 85.66% examples, 941062 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:25,651][gensim.models.word2vec][INFO] - EPOCH 10: training on 2183622 raw words (2182441 effective words) took 2.3s, 960527 effective words/s
[2023-02-07 18:30:26,656][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 48.60% examples, 1080256 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:30:27,662][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 97.91% examples, 1064443 words/s, in_qsize 5, out_qsize 0
[2023-02-07 18:30:27,688][gensim.models.word2vec][INFO] - EPOCH 11: training on 2183622 raw words (2182441 effective words) took 2.0s, 1071861 effective words/s
[2023-02-07 18:30:28,702][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 44.24% examples, 978228 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:30:29,708][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 87.87% examples, 956886 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:29,968][gensim.models.word2vec][INFO] - EPOCH 12: training on 2183622 raw words (2182441 effective words) took 2.3s, 957783 effective words/s
[2023-02-07 18:30:30,970][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 40.84% examples, 916242 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:31,974][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 82.87% examples, 911704 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:32,344][gensim.models.word2vec][INFO] - EPOCH 13: training on 2183622 raw words (2182441 effective words) took 2.4s, 919305 effective words/s
[2023-02-07 18:30:33,351][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 41.66% examples, 930012 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:30:34,353][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 84.22% examples, 924612 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:30:34,696][gensim.models.word2vec][INFO] - EPOCH 14: training on 2183622 raw words (2182441 effective words) took 2.4s, 928608 effective words/s
[2023-02-07 18:30:34,696][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 32754330 raw words (32736615 effective words) took 35.0s, 935587 effective words/s', 'datetime': '2023-02-07T18:30:34.696700', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:30:34.696 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:30:36,356][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182940-afpg2aza/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:30:36.355987', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:30:36,356][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:30:36,373][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_182940-afpg2aza/files/../tmp/embedding_model.pt
2023-02-07 18:30:36.373 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:30:38.304 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:30:38.986 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:30:41.320 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1137079440536992, 'test_mae': 0.8122033009225605, 'test_r2': -2.589493751278106}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.14
wandb: percentage 0.49982
wandb:   test_mae 0.8122
wandb:   test_mse 1.11371
wandb:    test_r2 -2.58949
wandb: 
wandb: üöÄ View run sleek-sweep-9 at: https://wandb.ai/xiaoqiz/mof2vec/runs/afpg2aza
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_182940-afpg2aza/logs
wandb: Agent Starting Run: 3ykc2ro4 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 305
wandb: 	model.gensim.alpha: 0.004824090696294149
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.3404889687474886
wandb: 	model.gensim.vector_size: 499
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.45534859681107825
wandb: 	model.sklearn.max_depth: 45
wandb: 	model.sklearn.min_child_weight: 0.047138916736223065
wandb: 	model.sklearn.n_estimators: 1670
wandb: 	model.sklearn.num_leaves: 350
wandb: 	model.sklearn.reg_alpha: 0.03403629497913053
wandb: 	model.sklearn.reg_lambda: 0.0025426345650089647
wandb: 	model.sklearn.subsample: 0.961877094589414
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183053-3ykc2ro4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/3ykc2ro4
2023-02-07 18:31:01.819 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 18:31:01.819 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 305 for sweep.
2023-02-07 18:31:01.820 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.004824090696294149 for sweep.
2023-02-07 18:31:01.820 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:31:01.820 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 18:31:01.820 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.3404889687474886 for sweep.
2023-02-07 18:31:01.821 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 499 for sweep.
2023-02-07 18:31:01.821 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 18:31:01.821 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.45534859681107825 for sweep.
2023-02-07 18:31:01.821 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 45 for sweep.
2023-02-07 18:31:01.822 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.047138916736223065 for sweep.
2023-02-07 18:31:01.822 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1670 for sweep.
2023-02-07 18:31:01.822 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 350 for sweep.
2023-02-07 18:31:01.822 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.03403629497913053 for sweep.
2023-02-07 18:31:01.822 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0025426345650089647 for sweep.
2023-02-07 18:31:01.823 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.961877094589414 for sweep.
2023-02-07 18:31:01.823 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:31:01.831 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183053-3ykc2ro4/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 305, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 499, 'window': 11, 'min_count': 2, 'dm': 1, 'sample': 0.3404889687474886, 'workers': 4, 'alpha': 0.004824090696294149, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1670, 'max_depth': 45, 'num_leaves': 350, 'reg_alpha': 0.03403629497913053, 'reg_lambda': 0.0025426345650089647, 'subsample': 0.961877094589414, 'min_child_weight': 0.047138916736223065, 'n_jobs': 4, 'learning_rate': 0.45534859681107825}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 163.63it/s]  1%|          | 36/3257 [00:00<00:18, 177.42it/s]  2%|‚ñè         | 54/3257 [00:00<00:18, 175.05it/s]  2%|‚ñè         | 74/3257 [00:00<00:17, 183.70it/s]  3%|‚ñé         | 94/3257 [00:00<00:16, 188.65it/s]  3%|‚ñé         | 113/3257 [00:00<00:17, 181.40it/s]  4%|‚ñç         | 133/3257 [00:00<00:16, 185.35it/s]  5%|‚ñç         | 154/3257 [00:00<00:16, 191.10it/s]  5%|‚ñå         | 174/3257 [00:00<00:16, 182.70it/s]  6%|‚ñå         | 196/3257 [00:01<00:15, 192.46it/s]  7%|‚ñã         | 218/3257 [00:01<00:15, 199.57it/s]  7%|‚ñã         | 242/3257 [00:01<00:14, 209.22it/s]  8%|‚ñä         | 264/3257 [00:01<00:15, 199.07it/s]  9%|‚ñâ         | 291/3257 [00:01<00:13, 217.58it/s] 10%|‚ñâ         | 313/3257 [00:01<00:13, 216.94it/s] 10%|‚ñà         | 340/3257 [00:01<00:12, 231.17it/s] 11%|‚ñà‚ñè        | 367/3257 [00:01<00:12, 238.67it/s] 12%|‚ñà‚ñè        | 391/3257 [00:01<00:12, 229.96it/s] 13%|‚ñà‚ñé        | 417/3257 [00:02<00:12, 236.40it/s] 14%|‚ñà‚ñé        | 441/3257 [00:02<00:13, 211.65it/s] 14%|‚ñà‚ñç        | 466/3257 [00:02<00:12, 221.52it/s] 15%|‚ñà‚ñå        | 489/3257 [00:02<00:12, 223.85it/s] 16%|‚ñà‚ñå        | 517/3257 [00:02<00:11, 238.10it/s] 17%|‚ñà‚ñã        | 543/3257 [00:02<00:11, 240.79it/s] 17%|‚ñà‚ñã        | 568/3257 [00:02<00:11, 227.86it/s] 18%|‚ñà‚ñä        | 592/3257 [00:02<00:11, 223.14it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:02<00:11, 230.27it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:11, 229.78it/s] 21%|‚ñà‚ñà        | 669/3257 [00:03<00:11, 226.28it/s] 21%|‚ñà‚ñà        | 692/3257 [00:03<00:16, 159.99it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:03<00:14, 179.91it/s] 23%|‚ñà‚ñà‚ñé       | 739/3257 [00:03<00:14, 177.57it/s] 24%|‚ñà‚ñà‚ñé       | 766/3257 [00:03<00:12, 199.42it/s] 24%|‚ñà‚ñà‚ñç       | 788/3257 [00:03<00:12, 196.32it/s] 25%|‚ñà‚ñà‚ñç       | 812/3257 [00:03<00:11, 205.62it/s] 26%|‚ñà‚ñà‚ñå       | 834/3257 [00:04<00:12, 201.59it/s] 26%|‚ñà‚ñà‚ñã       | 855/3257 [00:04<00:12, 194.20it/s] 27%|‚ñà‚ñà‚ñã       | 876/3257 [00:04<00:12, 197.17it/s] 28%|‚ñà‚ñà‚ñä       | 902/3257 [00:04<00:10, 214.39it/s] 28%|‚ñà‚ñà‚ñä       | 926/3257 [00:04<00:10, 221.42it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:04<00:10, 221.80it/s] 30%|‚ñà‚ñà‚ñâ       | 973/3257 [00:04<00:10, 225.93it/s] 31%|‚ñà‚ñà‚ñà       | 996/3257 [00:04<00:10, 220.55it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1021/3257 [00:04<00:09, 227.32it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1044/3257 [00:05<00:10, 210.62it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:05<00:10, 213.86it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1090/3257 [00:05<00:10, 215.70it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1113/3257 [00:05<00:09, 217.85it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1135/3257 [00:05<00:10, 210.11it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1157/3257 [00:05<00:10, 204.03it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1178/3257 [00:05<00:11, 187.25it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1198/3257 [00:05<00:11, 176.97it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1216/3257 [00:05<00:12, 168.91it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1239/3257 [00:06<00:10, 183.95it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:06<00:11, 176.79it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1276/3257 [00:06<00:11, 172.01it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1294/3257 [00:06<00:11, 167.34it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:06<00:11, 173.37it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1332/3257 [00:06<00:10, 177.15it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:06<00:10, 176.21it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1369/3257 [00:06<00:10, 179.14it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1387/3257 [00:06<00:10, 170.61it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1409/3257 [00:07<00:10, 183.04it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:07<00:09, 188.48it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1453/3257 [00:07<00:09, 194.17it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1475/3257 [00:07<00:08, 198.79it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:07<00:08, 201.08it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1517/3257 [00:07<00:08, 202.20it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1538/3257 [00:07<00:09, 180.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1557/3257 [00:07<00:09, 176.76it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:07<00:09, 177.55it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:07<00:08, 185.52it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:08<00:08, 197.38it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1641/3257 [00:08<00:08, 201.72it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:08<00:08, 196.33it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1683/3257 [00:08<00:08, 196.50it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:08<00:07, 205.95it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:08<00:07, 198.72it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1749/3257 [00:08<00:07, 200.26it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1773/3257 [00:08<00:07, 210.44it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:08<00:06, 214.45it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1818/3257 [00:09<00:10, 138.85it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1841/3257 [00:09<00:09, 157.20it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1865/3257 [00:09<00:07, 175.04it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1887/3257 [00:09<00:07, 184.92it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1910/3257 [00:09<00:06, 195.88it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1932/3257 [00:09<00:06, 197.22it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:09<00:05, 219.16it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1984/3257 [00:09<00:06, 207.97it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2006/3257 [00:10<00:05, 210.11it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2029/3257 [00:10<00:05, 213.52it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2051/3257 [00:10<00:06, 193.79it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2071/3257 [00:10<00:06, 190.58it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2092/3257 [00:10<00:05, 195.31it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2112/3257 [00:10<00:05, 191.99it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:10<00:06, 183.41it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2151/3257 [00:10<00:06, 184.25it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2173/3257 [00:10<00:05, 193.35it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2193/3257 [00:11<00:05, 192.42it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2213/3257 [00:11<00:05, 187.34it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2235/3257 [00:11<00:05, 196.05it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2255/3257 [00:11<00:05, 189.21it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:11<00:05, 176.71it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:11<00:05, 189.00it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2323/3257 [00:11<00:04, 202.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2348/3257 [00:11<00:04, 214.64it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2370/3257 [00:11<00:04, 215.20it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2393/3257 [00:12<00:03, 219.23it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2416/3257 [00:12<00:04, 205.09it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2437/3257 [00:12<00:04, 194.32it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2459/3257 [00:12<00:03, 200.51it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:12<00:03, 205.24it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2506/3257 [00:12<00:03, 217.42it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2528/3257 [00:12<00:03, 217.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2550/3257 [00:12<00:03, 217.67it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:12<00:03, 190.88it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2592/3257 [00:13<00:03, 178.31it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2615/3257 [00:13<00:03, 190.80it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2636/3257 [00:13<00:03, 193.94it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:13<00:03, 182.99it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2675/3257 [00:13<00:03, 176.20it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:13<00:03, 173.10it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2712/3257 [00:13<00:03, 159.16it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2731/3257 [00:13<00:03, 166.84it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2751/3257 [00:14<00:02, 172.77it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2769/3257 [00:14<00:02, 167.03it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2791/3257 [00:14<00:02, 177.23it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2809/3257 [00:14<00:02, 175.72it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2827/3257 [00:14<00:02, 165.54it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2844/3257 [00:14<00:02, 164.45it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2869/3257 [00:14<00:02, 186.94it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2888/3257 [00:14<00:02, 184.04it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:14<00:02, 172.66it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:15<00:01, 177.10it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2946/3257 [00:15<00:01, 170.84it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2964/3257 [00:15<00:01, 172.65it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2982/3257 [00:15<00:01, 161.95it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3003/3257 [00:15<00:01, 172.20it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3021/3257 [00:15<00:01, 167.40it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3041/3257 [00:15<00:01, 173.40it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:15<00:01, 184.85it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:15<00:00, 184.05it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3102/3257 [00:15<00:00, 187.46it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3125/3257 [00:16<00:00, 199.50it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3146/3257 [00:16<00:00, 195.65it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3168/3257 [00:16<00:00, 202.02it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3189/3257 [00:16<00:00, 202.16it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3211/3257 [00:16<00:00, 203.71it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3234/3257 [00:16<00:00, 210.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 215.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 194.76it/s]
2023-02-07 18:31:19.217 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:31:19,218][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d499,n5,w11,mc2,s0.340489,t4>', 'datetime': '2023-02-07T18:31:19.218493', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:31:19,218][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:31:19,218][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:31:19,682][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 18:31:19,682][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:31:19,757][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 27186 unique words (85.48% of original 31803, drops 4617)', 'datetime': '2023-02-07T18:31:19.757426', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:31:19,757][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5090501 word corpus (99.91% of original 5095118, drops 4617)', 'datetime': '2023-02-07T18:31:19.757862', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:31:19,852][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 18:31:19,853][gensim.models.word2vec][INFO] - sample=0.340489 downsamples 0 most-common words
[2023-02-07 18:31:19,853][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5090501 word corpus (100.0%% of prior 5090501)', 'datetime': '2023-02-07T18:31:19.853460', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:31:20,016][gensim.models.word2vec][INFO] - estimated required memory for 27186 words and 499 dimensions: 129271884 bytes
[2023-02-07 18:31:20,017][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:31:20,081][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 27186 vocabulary and 499 features, using sg=0 hs=0 sample=0.3404889687474886 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T18:31:20.080976', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:31:21,090][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 16.70% examples, 813815 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:22,096][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 32.36% examples, 827935 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:23,115][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 48.36% examples, 829511 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:24,125][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 64.51% examples, 826855 words/s, in_qsize 7, out_qsize 2
[2023-02-07 18:31:25,128][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 82.07% examples, 833641 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:26,017][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5082292 effective words) took 5.9s, 856490 effective words/s
[2023-02-07 18:31:27,024][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 18.36% examples, 907057 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:28,026][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 35.65% examples, 916147 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:29,030][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 52.04% examples, 899427 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:30,034][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 68.71% examples, 888863 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:31,040][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 86.21% examples, 879116 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:31,776][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5082292 effective words) took 5.8s, 882714 effective words/s
[2023-02-07 18:31:32,788][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 19.65% examples, 965474 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:33,793][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 36.57% examples, 941247 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:34,812][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 54.59% examples, 936360 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:35,817][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 71.66% examples, 918696 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:36,818][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 88.85% examples, 902343 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:37,428][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5082292 effective words) took 5.6s, 899527 effective words/s
[2023-02-07 18:31:38,440][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 18.36% examples, 903761 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:39,449][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 36.91% examples, 953391 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:40,450][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 55.45% examples, 956036 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:41,454][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 73.63% examples, 942473 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:42,463][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 90.67% examples, 922404 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:42,958][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5082292 effective words) took 5.5s, 919427 effective words/s
[2023-02-07 18:31:43,969][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 17.50% examples, 861072 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:44,994][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 35.89% examples, 908484 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:46,001][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 54.77% examples, 936452 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:47,006][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 73.63% examples, 937107 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:48,013][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 92.78% examples, 939748 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:48,359][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5082292 effective words) took 5.4s, 941222 effective words/s
[2023-02-07 18:31:49,362][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 18.54% examples, 920542 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:50,365][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 35.89% examples, 921786 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:51,376][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 53.85% examples, 931219 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:52,379][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 72.21% examples, 928106 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:53,382][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 90.85% examples, 926409 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:53,822][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5082292 effective words) took 5.5s, 930608 effective words/s
[2023-02-07 18:31:54,825][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 18.73% examples, 928795 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:55,830][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 36.32% examples, 937698 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:56,831][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 54.44% examples, 941699 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:57,844][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 73.63% examples, 943149 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:31:58,848][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 93.00% examples, 946720 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:31:59,170][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5082292 effective words) took 5.3s, 950623 effective words/s
[2023-02-07 18:32:00,178][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 19.01% examples, 933744 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:01,205][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 35.06% examples, 890624 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:02,222][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 51.89% examples, 884948 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:03,246][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 69.02% examples, 880400 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:32:04,250][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 86.77% examples, 876490 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:04,988][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5082292 effective words) took 5.8s, 873898 effective words/s
[2023-02-07 18:32:05,990][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 17.32% examples, 860142 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:07,010][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 33.59% examples, 856882 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:08,018][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 50.14% examples, 856186 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:32:09,026][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 67.79% examples, 871224 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:10,037][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 89.22% examples, 904638 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:10,567][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5082292 effective words) took 5.6s, 911281 effective words/s
[2023-02-07 18:32:11,570][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 19.01% examples, 937606 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:12,571][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.32% examples, 939010 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:13,579][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 54.44% examples, 940590 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:14,579][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 73.44% examples, 942980 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:15,582][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 91.80% examples, 937997 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:15,980][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5082292 effective words) took 5.4s, 939093 effective words/s
[2023-02-07 18:32:16,987][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 19.01% examples, 933974 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:17,992][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 36.44% examples, 939856 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:32:18,997][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 54.77% examples, 944580 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:32:19,998][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 73.81% examples, 946299 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:21,001][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 93.28% examples, 949581 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:21,322][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5082292 effective words) took 5.3s, 951735 effective words/s
[2023-02-07 18:32:22,329][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 19.22% examples, 941214 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:32:23,342][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 36.32% examples, 931784 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:24,353][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 52.78% examples, 905482 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:25,366][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 69.67% examples, 895358 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:26,368][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 86.95% examples, 884163 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:27,075][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5082292 effective words) took 5.8s, 883615 effective words/s
[2023-02-07 18:32:28,078][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 17.22% examples, 847142 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:32:29,093][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 33.34% examples, 846505 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:32:30,100][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 49.46% examples, 848246 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:31,106][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 65.86% examples, 849517 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:32,112][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 84.99% examples, 866405 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:32,802][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5082292 effective words) took 5.7s, 887921 effective words/s
[2023-02-07 18:32:33,817][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 19.22% examples, 934138 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:34,822][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 36.81% examples, 948804 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:35,826][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 54.77% examples, 942515 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:36,827][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 73.20% examples, 937746 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:37,832][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 92.14% examples, 937253 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:38,221][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5082292 effective words) took 5.4s, 938218 effective words/s
[2023-02-07 18:32:39,227][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 18.73% examples, 925353 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:40,233][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 35.89% examples, 919157 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:32:41,238][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 53.85% examples, 931080 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:42,240][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 72.52% examples, 932414 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:32:43,250][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 92.14% examples, 937326 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:32:43,612][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5082292 effective words) took 5.4s, 942959 effective words/s
[2023-02-07 18:32:43,613][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76234380 effective words) took 83.5s, 912640 effective words/s', 'datetime': '2023-02-07T18:32:43.613132', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:32:43.613 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:32:50,595][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183053-3ykc2ro4/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:32:50.595193', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:32:50,596][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183053-3ykc2ro4/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 18:32:50,633][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183053-3ykc2ro4/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 18:32:50,673][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:32:50,714][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183053-3ykc2ro4/files/../tmp/embedding_model.pt
2023-02-07 18:32:50.714 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:32:53.309 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:32:54.169 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:32:57.572 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.077148952374611, 'test_mae': 0.8043158815408046, 'test_r2': -2.502167305087363}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.41
wandb: percentage 0.14517
wandb:   test_mae 0.80432
wandb:   test_mse 1.07715
wandb:    test_r2 -2.50217
wandb: 
wandb: üöÄ View run fresh-sweep-10 at: https://wandb.ai/xiaoqiz/mof2vec/runs/3ykc2ro4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_183053-3ykc2ro4/logs
wandb: Agent Starting Run: uj21zop8 with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 284
wandb: 	model.gensim.alpha: 0.006322705670030783
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.2812181095737556
wandb: 	model.gensim.vector_size: 203
wandb: 	model.gensim.window: 19
wandb: 	model.sklearn.learning_rate: 0.14243689572700002
wandb: 	model.sklearn.max_depth: 90
wandb: 	model.sklearn.min_child_weight: 0.006719487578462821
wandb: 	model.sklearn.n_estimators: 3647
wandb: 	model.sklearn.num_leaves: 327
wandb: 	model.sklearn.reg_alpha: 0.622108422791865
wandb: 	model.sklearn.reg_lambda: 0.010843668710707188
wandb: 	model.sklearn.subsample: 0.9977771228896988
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183307-uj21zop8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/uj21zop8
2023-02-07 18:33:15.387 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 18:33:15.388 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 284 for sweep.
2023-02-07 18:33:15.388 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.006322705670030783 for sweep.
2023-02-07 18:33:15.389 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:33:15.389 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 18:33:15.389 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2812181095737556 for sweep.
2023-02-07 18:33:15.389 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 203 for sweep.
2023-02-07 18:33:15.390 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 19 for sweep.
2023-02-07 18:33:15.390 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.14243689572700002 for sweep.
2023-02-07 18:33:15.390 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 90 for sweep.
2023-02-07 18:33:15.391 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.006719487578462821 for sweep.
2023-02-07 18:33:15.391 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3647 for sweep.
2023-02-07 18:33:15.391 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 327 for sweep.
2023-02-07 18:33:15.391 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.622108422791865 for sweep.
2023-02-07 18:33:15.392 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.010843668710707188 for sweep.
2023-02-07 18:33:15.392 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9977771228896988 for sweep.
2023-02-07 18:33:15.392 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:33:15.397 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183307-uj21zop8/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 284, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 203, 'window': 19, 'min_count': 8, 'dm': 1, 'sample': 0.2812181095737556, 'workers': 4, 'alpha': 0.006322705670030783, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3647, 'max_depth': 90, 'num_leaves': 327, 'reg_alpha': 0.622108422791865, 'reg_lambda': 0.010843668710707188, 'subsample': 0.9977771228896988, 'min_child_weight': 0.006719487578462821, 'n_jobs': 4, 'learning_rate': 0.14243689572700002}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 24/3257 [00:00<00:13, 237.21it/s]  2%|‚ñè         | 49/3257 [00:00<00:13, 244.31it/s]  2%|‚ñè         | 74/3257 [00:00<00:13, 238.65it/s]  3%|‚ñé         | 98/3257 [00:00<00:13, 238.39it/s]  4%|‚ñé         | 122/3257 [00:00<00:13, 236.94it/s]  5%|‚ñç         | 151/3257 [00:00<00:12, 249.15it/s]  5%|‚ñå         | 176/3257 [00:00<00:12, 239.10it/s]  6%|‚ñå         | 202/3257 [00:00<00:12, 244.24it/s]  7%|‚ñã         | 232/3257 [00:00<00:11, 260.89it/s]  8%|‚ñä         | 259/3257 [00:01<00:11, 255.55it/s]  9%|‚ñâ         | 290/3257 [00:01<00:11, 266.75it/s] 10%|‚ñâ         | 317/3257 [00:01<00:11, 259.66it/s] 11%|‚ñà         | 344/3257 [00:01<00:11, 260.98it/s] 11%|‚ñà‚ñè        | 373/3257 [00:01<00:10, 267.31it/s] 12%|‚ñà‚ñè        | 400/3257 [00:01<00:11, 247.78it/s] 13%|‚ñà‚ñé        | 426/3257 [00:01<00:12, 233.83it/s] 14%|‚ñà‚ñç        | 450/3257 [00:01<00:12, 233.22it/s] 15%|‚ñà‚ñç        | 477/3257 [00:01<00:11, 243.16it/s] 15%|‚ñà‚ñå        | 504/3257 [00:02<00:11, 247.81it/s] 16%|‚ñà‚ñå        | 529/3257 [00:02<00:11, 246.21it/s] 17%|‚ñà‚ñã        | 557/3257 [00:02<00:10, 252.99it/s] 18%|‚ñà‚ñä        | 583/3257 [00:02<00:11, 232.69it/s] 19%|‚ñà‚ñâ        | 614/3257 [00:02<00:10, 251.75it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:02<00:10, 249.01it/s] 20%|‚ñà‚ñà        | 666/3257 [00:02<00:11, 234.46it/s] 21%|‚ñà‚ñà        | 691/3257 [00:02<00:10, 238.03it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:02<00:10, 243.18it/s] 23%|‚ñà‚ñà‚ñé       | 742/3257 [00:03<00:10, 229.96it/s] 24%|‚ñà‚ñà‚ñé       | 771/3257 [00:03<00:10, 245.07it/s] 24%|‚ñà‚ñà‚ñç       | 796/3257 [00:03<00:10, 242.22it/s] 25%|‚ñà‚ñà‚ñå       | 821/3257 [00:03<00:10, 237.84it/s] 26%|‚ñà‚ñà‚ñå       | 845/3257 [00:03<00:11, 219.13it/s] 27%|‚ñà‚ñà‚ñã       | 869/3257 [00:03<00:10, 224.22it/s] 27%|‚ñà‚ñà‚ñã       | 893/3257 [00:03<00:10, 227.08it/s] 28%|‚ñà‚ñà‚ñä       | 917/3257 [00:03<00:10, 229.96it/s] 29%|‚ñà‚ñà‚ñâ       | 943/3257 [00:03<00:09, 237.75it/s] 30%|‚ñà‚ñà‚ñâ       | 969/3257 [00:03<00:09, 243.16it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:04<00:09, 234.47it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1018/3257 [00:04<00:09, 231.75it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1042/3257 [00:04<00:10, 217.33it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:04<00:09, 224.83it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:04<00:09, 227.41it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:04<00:09, 228.60it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1140/3257 [00:04<00:09, 225.43it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1167/3257 [00:04<00:08, 236.67it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:04<00:09, 217.46it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1214/3257 [00:05<00:09, 218.51it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:05<00:08, 237.71it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1268/3257 [00:05<00:12, 158.51it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:05<00:12, 161.50it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1314/3257 [00:05<00:10, 182.75it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1341/3257 [00:05<00:09, 202.67it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:05<00:09, 208.52it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1387/3257 [00:06<00:09, 207.15it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1417/3257 [00:06<00:07, 231.35it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1442/3257 [00:06<00:07, 231.72it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1472/3257 [00:06<00:07, 249.35it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1501/3257 [00:06<00:06, 260.04it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1528/3257 [00:06<00:06, 247.17it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1554/3257 [00:06<00:07, 237.72it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1580/3257 [00:06<00:06, 243.28it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1606/3257 [00:06<00:06, 247.91it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:06<00:06, 251.90it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1660/3257 [00:07<00:06, 246.71it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1685/3257 [00:07<00:07, 220.21it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:07<00:07, 218.65it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:07<00:07, 205.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1752/3257 [00:07<00:07, 202.94it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1775/3257 [00:07<00:07, 208.85it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1797/3257 [00:07<00:06, 209.78it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1819/3257 [00:07<00:06, 212.06it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1841/3257 [00:07<00:06, 211.67it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1863/3257 [00:08<00:06, 211.49it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1885/3257 [00:08<00:06, 209.30it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1909/3257 [00:08<00:06, 216.46it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:08<00:06, 213.25it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:08<00:05, 235.58it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1985/3257 [00:08<00:05, 221.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:08<00:05, 221.28it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2032/3257 [00:08<00:05, 224.31it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:08<00:05, 201.32it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2076/3257 [00:09<00:05, 202.80it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2097/3257 [00:09<00:05, 197.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2119/3257 [00:09<00:05, 201.20it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2140/3257 [00:09<00:05, 188.69it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2160/3257 [00:09<00:05, 189.41it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:09<00:05, 194.05it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:09<00:05, 204.03it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2225/3257 [00:09<00:05, 197.88it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2245/3257 [00:09<00:05, 197.06it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2267/3257 [00:10<00:04, 201.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2289/3257 [00:10<00:04, 206.83it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2310/3257 [00:10<00:04, 205.84it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:10<00:04, 220.09it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2364/3257 [00:10<00:03, 232.51it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2388/3257 [00:10<00:03, 232.17it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2412/3257 [00:10<00:03, 220.74it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2435/3257 [00:10<00:03, 211.21it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2458/3257 [00:10<00:03, 215.54it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2482/3257 [00:11<00:03, 221.05it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2508/3257 [00:11<00:03, 230.00it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2532/3257 [00:11<00:03, 232.66it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2556/3257 [00:11<00:03, 220.00it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2579/3257 [00:11<00:03, 208.61it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2602/3257 [00:11<00:03, 213.05it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2630/3257 [00:11<00:02, 231.54it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:12<00:04, 126.40it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2676/3257 [00:12<00:04, 143.18it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2696/3257 [00:12<00:03, 153.58it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2716/3257 [00:12<00:03, 157.79it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2744/3257 [00:12<00:02, 185.77it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2767/3257 [00:12<00:02, 195.92it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2789/3257 [00:12<00:02, 199.32it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2811/3257 [00:12<00:02, 203.87it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:12<00:02, 196.36it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2858/3257 [00:13<00:01, 210.47it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:13<00:01, 223.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2909/3257 [00:13<00:01, 214.47it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2931/3257 [00:13<00:01, 213.50it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2953/3257 [00:13<00:01, 206.77it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:13<00:01, 209.59it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3000/3257 [00:13<00:01, 216.87it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3022/3257 [00:13<00:01, 212.86it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:13<00:00, 224.53it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3076/3257 [00:14<00:00, 237.32it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3100/3257 [00:14<00:00, 233.66it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:14<00:00, 239.70it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3152/3257 [00:14<00:00, 225.51it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3175/3257 [00:14<00:00, 223.53it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3198/3257 [00:14<00:00, 220.85it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3221/3257 [00:14<00:00, 214.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3249/3257 [00:14<00:00, 231.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:14<00:00, 219.74it/s]
2023-02-07 18:33:30.745 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:33:30,746][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d203,n5,w19,mc8,s0.281218,t4>', 'datetime': '2023-02-07T18:33:30.746448', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:33:30,747][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:33:30,747][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:33:31,112][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 18:33:31,113][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:33:31,130][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 5936 unique words (45.45% of original 13061, drops 7125)', 'datetime': '2023-02-07T18:33:31.130720', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:33:31,130][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 3618620 word corpus (99.43% of original 3639370, drops 20750)', 'datetime': '2023-02-07T18:33:31.130903', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:33:31,150][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 18:33:31,150][gensim.models.word2vec][INFO] - sample=0.281218 downsamples 0 most-common words
[2023-02-07 18:33:31,150][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3618620 word corpus (100.0%% of prior 3618620)', 'datetime': '2023-02-07T18:33:31.150653', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:33:31,182][gensim.models.word2vec][INFO] - estimated required memory for 5936 words and 203 dimensions: 15904148 bytes
[2023-02-07 18:33:31,183][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:33:31,191][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 5936 vocabulary and 203 features, using sg=0 hs=0 sample=0.2812181095737556 negative=5 window=19 shrink_windows=True', 'datetime': '2023-02-07T18:33:31.191528', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:33:32,193][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 34.45% examples, 1264673 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:33:33,196][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 66.29% examples, 1224230 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:34,191][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3621877 effective words) took 3.0s, 1207914 effective words/s
[2023-02-07 18:33:35,199][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 32.33% examples, 1179536 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:36,204][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 64.45% examples, 1183990 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:33:37,205][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 97.85% examples, 1178743 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:37,258][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3621877 effective words) took 3.1s, 1181833 effective words/s
[2023-02-07 18:33:38,265][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 32.48% examples, 1182637 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:39,267][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 65.34% examples, 1203012 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:40,265][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3621877 effective words) took 3.0s, 1205087 effective words/s
[2023-02-07 18:33:41,267][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 32.76% examples, 1199531 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:42,286][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 63.68% examples, 1162924 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:33:43,289][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 94.69% examples, 1137534 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:43,459][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3621877 effective words) took 3.2s, 1134368 effective words/s
[2023-02-07 18:33:44,473][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 30.43% examples, 1092120 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:33:45,478][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 60.73% examples, 1110917 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:46,479][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 92.54% examples, 1118310 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:46,698][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3621877 effective words) took 3.2s, 1119221 effective words/s
[2023-02-07 18:33:47,713][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 31.01% examples, 1118638 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:33:48,714][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 61.34% examples, 1121357 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:49,718][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 92.54% examples, 1118124 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:49,944][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3621877 effective words) took 3.2s, 1116659 effective words/s
[2023-02-07 18:33:50,953][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 33.68% examples, 1229306 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:51,955][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 68.04% examples, 1254888 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:52,854][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3621877 effective words) took 2.9s, 1245700 effective words/s
[2023-02-07 18:33:53,861][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 32.33% examples, 1179390 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:54,865][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 65.09% examples, 1197715 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:55,875][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 99.17% examples, 1190843 words/s, in_qsize 3, out_qsize 1
[2023-02-07 18:33:55,889][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3621877 effective words) took 3.0s, 1193738 effective words/s
[2023-02-07 18:33:56,893][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 33.47% examples, 1225929 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:57,904][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 66.93% examples, 1230297 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:33:58,820][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3621877 effective words) took 2.9s, 1236636 effective words/s
[2023-02-07 18:33:59,822][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 33.47% examples, 1228063 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:00,829][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 66.17% examples, 1221755 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:01,838][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 98.80% examples, 1188934 words/s, in_qsize 4, out_qsize 0
[2023-02-07 18:34:01,864][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3621877 effective words) took 3.0s, 1190677 effective words/s
[2023-02-07 18:34:02,874][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 30.61% examples, 1104848 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:03,882][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 61.59% examples, 1125032 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:04,887][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 93.74% examples, 1128767 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:05,065][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3621877 effective words) took 3.2s, 1132143 effective words/s
[2023-02-07 18:34:06,074][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 30.89% examples, 1116138 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:07,077][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 61.01% examples, 1118919 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:08,092][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 92.75% examples, 1118030 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:08,298][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3621877 effective words) took 3.2s, 1120803 effective words/s
[2023-02-07 18:34:09,304][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 31.65% examples, 1153474 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:34:10,311][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 69.05% examples, 1271686 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:34:11,180][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3621877 effective words) took 2.9s, 1257825 effective words/s
[2023-02-07 18:34:12,185][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 33.13% examples, 1204948 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:13,189][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 66.17% examples, 1221613 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:14,163][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3621877 effective words) took 3.0s, 1214531 effective words/s
[2023-02-07 18:34:15,169][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 32.82% examples, 1204658 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:16,171][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 65.92% examples, 1218464 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:34:17,111][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3621877 effective words) took 2.9s, 1229433 effective words/s
[2023-02-07 18:34:17,112][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54328155 effective words) took 45.9s, 1183087 effective words/s', 'datetime': '2023-02-07T18:34:17.112446', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:34:17.112 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:34:19,710][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183307-uj21zop8/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:34:19.710339', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:34:19,711][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:34:19,744][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183307-uj21zop8/files/../tmp/embedding_model.pt
2023-02-07 18:34:19.744 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:34:21.460 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:34:22.104 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:34:23.608 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0946370076025054, 'test_mae': 0.7997133454387905, 'test_r2': -2.682051174916161}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.33
wandb: percentage 0.54552
wandb:   test_mae 0.79971
wandb:   test_mse 1.09464
wandb:    test_r2 -2.68205
wandb: 
wandb: üöÄ View run eager-sweep-11 at: https://wandb.ai/xiaoqiz/mof2vec/runs/uj21zop8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_183307-uj21zop8/logs
wandb: Agent Starting Run: 2wm3cnmh with config:
wandb: 	data.data.wl_step: 2
wandb: 	data.nn.batch_size: 650
wandb: 	model.gensim.alpha: 0.0012565160332501028
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.42398745660123094
wandb: 	model.gensim.vector_size: 494
wandb: 	model.gensim.window: 15
wandb: 	model.sklearn.learning_rate: 0.9780872924096008
wandb: 	model.sklearn.max_depth: 93
wandb: 	model.sklearn.min_child_weight: 0.05184965202462539
wandb: 	model.sklearn.n_estimators: 1948
wandb: 	model.sklearn.num_leaves: 349
wandb: 	model.sklearn.reg_alpha: 0.01753373762267019
wandb: 	model.sklearn.reg_lambda: 0.017735844963781913
wandb: 	model.sklearn.subsample: 0.9531327521769536
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183437-2wm3cnmh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/2wm3cnmh
2023-02-07 18:34:45.845 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 2 for sweep.
2023-02-07 18:34:45.846 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 650 for sweep.
2023-02-07 18:34:45.846 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0012565160332501028 for sweep.
2023-02-07 18:34:45.846 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:34:45.846 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 18:34:45.847 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.42398745660123094 for sweep.
2023-02-07 18:34:45.847 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 494 for sweep.
2023-02-07 18:34:45.847 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 15 for sweep.
2023-02-07 18:34:45.847 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.9780872924096008 for sweep.
2023-02-07 18:34:45.847 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 93 for sweep.
2023-02-07 18:34:45.848 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05184965202462539 for sweep.
2023-02-07 18:34:45.848 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1948 for sweep.
2023-02-07 18:34:45.848 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 349 for sweep.
2023-02-07 18:34:45.848 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.01753373762267019 for sweep.
2023-02-07 18:34:45.849 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.017735844963781913 for sweep.
2023-02-07 18:34:45.849 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9531327521769536 for sweep.
2023-02-07 18:34:45.849 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:34:45.854 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 2}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183437-2wm3cnmh/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 650, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 494, 'window': 15, 'min_count': 2, 'dm': 1, 'sample': 0.42398745660123094, 'workers': 4, 'alpha': 0.0012565160332501028, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1948, 'max_depth': 93, 'num_leaves': 349, 'reg_alpha': 0.01753373762267019, 'reg_lambda': 0.017735844963781913, 'subsample': 0.9531327521769536, 'min_child_weight': 0.05184965202462539, 'n_jobs': 4, 'learning_rate': 0.9780872924096008}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 36/3257 [00:00<00:08, 357.98it/s]  2%|‚ñè         | 77/3257 [00:00<00:08, 386.57it/s]  4%|‚ñé         | 116/3257 [00:00<00:08, 376.44it/s]  5%|‚ñç         | 155/3257 [00:00<00:08, 380.39it/s]  6%|‚ñå         | 194/3257 [00:00<00:08, 374.48it/s]  7%|‚ñã         | 237/3257 [00:00<00:07, 390.05it/s]  9%|‚ñä         | 282/3257 [00:00<00:07, 407.91it/s] 10%|‚ñâ         | 325/3257 [00:00<00:07, 414.75it/s] 11%|‚ñà‚ñè        | 367/3257 [00:00<00:07, 408.51it/s] 13%|‚ñà‚ñé        | 408/3257 [00:01<00:07, 399.67it/s] 14%|‚ñà‚ñç        | 449/3257 [00:01<00:07, 379.02it/s] 15%|‚ñà‚ñå        | 490/3257 [00:01<00:07, 386.41it/s] 16%|‚ñà‚ñã        | 531/3257 [00:01<00:06, 390.69it/s] 18%|‚ñà‚ñä        | 571/3257 [00:01<00:07, 372.08it/s] 19%|‚ñà‚ñâ        | 614/3257 [00:01<00:09, 285.42it/s] 20%|‚ñà‚ñâ        | 649/3257 [00:01<00:08, 298.16it/s] 21%|‚ñà‚ñà        | 685/3257 [00:01<00:08, 311.65it/s] 22%|‚ñà‚ñà‚ñè       | 724/3257 [00:02<00:07, 331.32it/s] 23%|‚ñà‚ñà‚ñé       | 763/3257 [00:02<00:07, 345.15it/s] 25%|‚ñà‚ñà‚ñç       | 799/3257 [00:02<00:07, 349.02it/s] 26%|‚ñà‚ñà‚ñå       | 835/3257 [00:02<00:07, 330.44it/s] 27%|‚ñà‚ñà‚ñã       | 869/3257 [00:02<00:07, 300.29it/s] 28%|‚ñà‚ñà‚ñä       | 903/3257 [00:02<00:07, 310.34it/s] 29%|‚ñà‚ñà‚ñâ       | 938/3257 [00:02<00:07, 319.33it/s] 30%|‚ñà‚ñà‚ñâ       | 977/3257 [00:02<00:06, 336.87it/s] 31%|‚ñà‚ñà‚ñà       | 1012/3257 [00:02<00:06, 329.80it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:03<00:06, 324.99it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1081/3257 [00:03<00:06, 330.76it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1116/3257 [00:03<00:06, 334.65it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1150/3257 [00:03<00:06, 324.30it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1184/3257 [00:03<00:06, 327.97it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1217/3257 [00:03<00:06, 322.04it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1255/3257 [00:03<00:05, 336.85it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1289/3257 [00:03<00:05, 330.20it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1324/3257 [00:03<00:05, 335.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1359/3257 [00:03<00:05, 337.10it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1393/3257 [00:04<00:05, 333.37it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1434/3257 [00:04<00:05, 352.43it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:04<00:04, 365.81it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1512/3257 [00:04<00:04, 369.47it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1549/3257 [00:04<00:05, 340.80it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1584/3257 [00:04<00:04, 336.51it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:04<00:04, 342.07it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1655/3257 [00:04<00:04, 321.72it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1688/3257 [00:04<00:05, 293.57it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1720/3257 [00:05<00:05, 298.90it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1751/3257 [00:05<00:07, 209.49it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:05<00:05, 246.80it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1824/3257 [00:05<00:05, 267.78it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1858/3257 [00:05<00:04, 282.59it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1893/3257 [00:05<00:04, 297.26it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1929/3257 [00:05<00:04, 311.69it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:05<00:03, 344.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2010/3257 [00:06<00:03, 343.98it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2046/3257 [00:06<00:03, 346.92it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2082/3257 [00:06<00:03, 333.60it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:06<00:03, 334.47it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2151/3257 [00:06<00:03, 322.16it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2187/3257 [00:06<00:03, 329.37it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2222/3257 [00:06<00:03, 334.92it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2256/3257 [00:06<00:03, 333.24it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2290/3257 [00:06<00:02, 335.16it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2329/3257 [00:06<00:02, 348.64it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2369/3257 [00:07<00:02, 362.13it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2406/3257 [00:07<00:02, 356.09it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2442/3257 [00:07<00:02, 346.92it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2478/3257 [00:07<00:02, 350.26it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2518/3257 [00:07<00:02, 363.21it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2555/3257 [00:07<00:01, 356.10it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2591/3257 [00:07<00:01, 336.80it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2632/3257 [00:07<00:01, 355.33it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2668/3257 [00:07<00:01, 345.67it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2703/3257 [00:08<00:01, 333.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2740/3257 [00:08<00:01, 343.09it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2775/3257 [00:08<00:01, 338.91it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2814/3257 [00:08<00:01, 351.30it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2850/3257 [00:08<00:01, 345.95it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2892/3257 [00:08<00:00, 365.87it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2929/3257 [00:08<00:00, 360.97it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:08<00:00, 354.30it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3002/3257 [00:08<00:00, 353.91it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3039/3257 [00:08<00:00, 357.34it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3079/3257 [00:09<00:00, 368.61it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3119/3257 [00:09<00:00, 376.19it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3157/3257 [00:09<00:00, 360.28it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3194/3257 [00:09<00:00, 356.70it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3230/3257 [00:09<00:00, 221.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:09<00:00, 331.95it/s]
2023-02-07 18:34:55.937 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:34:55,938][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d494,n5,w15,mc2,s0.423987,t4>', 'datetime': '2023-02-07T18:34:55.938324', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:34:55,938][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:34:55,938][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:34:56,130][gensim.models.doc2vec][INFO] - collected 2819 word types and 3257 unique tags from a corpus of 3257 examples and 2183622 words
[2023-02-07 18:34:56,130][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:34:56,136][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 2542 unique words (90.17% of original 2819, drops 277)', 'datetime': '2023-02-07T18:34:56.136653', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:34:56,137][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 2183345 word corpus (99.99% of original 2183622, drops 277)', 'datetime': '2023-02-07T18:34:56.137610', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:34:56,146][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 2819 items
[2023-02-07 18:34:56,146][gensim.models.word2vec][INFO] - sample=0.423987 downsamples 0 most-common words
[2023-02-07 18:34:56,146][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2183345 word corpus (100.0%% of prior 2183345)', 'datetime': '2023-02-07T18:34:56.146693', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:34:56,161][gensim.models.word2vec][INFO] - estimated required memory for 2542 words and 494 dimensions: 18404216 bytes
[2023-02-07 18:34:56,161][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:34:56,172][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 2542 vocabulary and 494 features, using sg=0 hs=0 sample=0.42398745660123094 negative=5 window=15 shrink_windows=True', 'datetime': '2023-02-07T18:34:56.172230', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:34:57,204][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 26.56% examples, 566097 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:58,216][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 53.42% examples, 587924 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:59,231][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 82.87% examples, 599029 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:34:59,818][gensim.models.word2vec][INFO] - EPOCH 0: training on 2183622 raw words (2186602 effective words) took 3.6s, 599989 effective words/s
[2023-02-07 18:35:00,831][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 26.13% examples, 567977 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:01,858][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 53.18% examples, 584583 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:02,873][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 82.87% examples, 599845 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:03,489][gensim.models.word2vec][INFO] - EPOCH 1: training on 2183622 raw words (2186602 effective words) took 3.7s, 596034 effective words/s
[2023-02-07 18:35:04,496][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 26.56% examples, 579877 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:05,514][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 53.12% examples, 588791 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:06,545][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 81.73% examples, 590453 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:07,160][gensim.models.word2vec][INFO] - EPOCH 2: training on 2183622 raw words (2186602 effective words) took 3.7s, 595863 effective words/s
[2023-02-07 18:35:08,185][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 26.13% examples, 561296 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:09,208][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 52.41% examples, 573083 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:10,231][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 80.47% examples, 578296 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:10,901][gensim.models.word2vec][INFO] - EPOCH 3: training on 2183622 raw words (2186602 effective words) took 3.7s, 584736 effective words/s
[2023-02-07 18:35:11,907][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 26.56% examples, 580623 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:12,925][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 52.87% examples, 584458 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:13,958][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 80.47% examples, 580972 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:14,612][gensim.models.word2vec][INFO] - EPOCH 4: training on 2183622 raw words (2186602 effective words) took 3.7s, 589490 effective words/s
[2023-02-07 18:35:15,639][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 27.39% examples, 586458 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:16,655][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 54.93% examples, 602445 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:17,677][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 83.27% examples, 601049 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:18,218][gensim.models.word2vec][INFO] - EPOCH 5: training on 2183622 raw words (2186602 effective words) took 3.6s, 606827 effective words/s
[2023-02-07 18:35:19,220][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 26.22% examples, 573287 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:20,225][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 52.87% examples, 589468 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:21,246][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 81.33% examples, 592737 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:21,880][gensim.models.word2vec][INFO] - EPOCH 6: training on 2183622 raw words (2186602 effective words) took 3.7s, 597344 effective words/s
[2023-02-07 18:35:22,891][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 27.33% examples, 595792 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:23,903][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 53.42% examples, 594245 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:24,920][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 82.87% examples, 602865 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:25,410][gensim.models.word2vec][INFO] - EPOCH 7: training on 2183622 raw words (2186602 effective words) took 3.5s, 619846 effective words/s
[2023-02-07 18:35:26,414][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 29.20% examples, 638612 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:27,431][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 57.54% examples, 637495 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:28,446][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 89.25% examples, 647499 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:28,823][gensim.models.word2vec][INFO] - EPOCH 8: training on 2183622 raw words (2186602 effective words) took 3.4s, 640909 effective words/s
[2023-02-07 18:35:29,836][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 26.56% examples, 577261 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:30,851][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 52.66% examples, 583850 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:31,858][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 81.73% examples, 594951 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:32,444][gensim.models.word2vec][INFO] - EPOCH 9: training on 2183622 raw words (2186602 effective words) took 3.6s, 604411 effective words/s
[2023-02-07 18:35:33,475][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 27.82% examples, 593024 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:34,497][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 54.93% examples, 599261 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:35,503][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 85.66% examples, 617373 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:35,966][gensim.models.word2vec][INFO] - EPOCH 10: training on 2183622 raw words (2186602 effective words) took 3.5s, 621084 effective words/s
[2023-02-07 18:35:36,979][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 26.47% examples, 576360 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:37,984][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 52.87% examples, 586176 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:39,022][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 80.47% examples, 581231 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:39,688][gensim.models.word2vec][INFO] - EPOCH 11: training on 2183622 raw words (2186602 effective words) took 3.7s, 587797 effective words/s
[2023-02-07 18:35:40,693][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 27.82% examples, 608785 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:41,711][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 55.63% examples, 617581 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:42,722][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 84.74% examples, 616431 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:43,248][gensim.models.word2vec][INFO] - EPOCH 12: training on 2183622 raw words (2186602 effective words) took 3.6s, 614494 effective words/s
[2023-02-07 18:35:44,266][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 25.12% examples, 538599 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:45,268][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 50.75% examples, 562114 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:46,293][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 78.23% examples, 567674 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:46,996][gensim.models.word2vec][INFO] - EPOCH 13: training on 2183622 raw words (2186602 effective words) took 3.7s, 583944 effective words/s
[2023-02-07 18:35:48,030][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 27.82% examples, 591509 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:49,049][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 54.93% examples, 599393 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:35:50,049][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 84.22% examples, 609259 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:35:50,587][gensim.models.word2vec][INFO] - EPOCH 14: training on 2183622 raw words (2186602 effective words) took 3.6s, 609150 effective words/s
[2023-02-07 18:35:50,588][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 32754330 raw words (32799030 effective words) took 54.4s, 602750 effective words/s', 'datetime': '2023-02-07T18:35:50.588190', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:35:50.588 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:35:53,088][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183437-2wm3cnmh/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:35:53.088794', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:35:53,089][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:35:53,116][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183437-2wm3cnmh/files/../tmp/embedding_model.pt
2023-02-07 18:35:53.116 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:35:55.623 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:35:56.596 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:35:59.943 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.098762605436839, 'test_mae': 0.8095855610959369, 'test_r2': -3.2686466417733024}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.03
wandb: percentage 0.09826
wandb:   test_mae 0.80959
wandb:   test_mse 1.09876
wandb:    test_r2 -3.26865
wandb: 
wandb: üöÄ View run spring-sweep-12 at: https://wandb.ai/xiaoqiz/mof2vec/runs/2wm3cnmh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_183437-2wm3cnmh/logs
wandb: Agent Starting Run: 2wg1y7r9 with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 462
wandb: 	model.gensim.alpha: 0.00047504055856710666
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.5290498111672246
wandb: 	model.gensim.vector_size: 505
wandb: 	model.gensim.window: 16
wandb: 	model.sklearn.learning_rate: 0.0006569581699855443
wandb: 	model.sklearn.max_depth: 79
wandb: 	model.sklearn.min_child_weight: 0.008845664006423115
wandb: 	model.sklearn.n_estimators: 1814
wandb: 	model.sklearn.num_leaves: 209
wandb: 	model.sklearn.reg_alpha: 0.27248595387212776
wandb: 	model.sklearn.reg_lambda: 0.013904895505591153
wandb: 	model.sklearn.subsample: 0.5775476798582142
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183611-2wg1y7r9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/2wg1y7r9
2023-02-07 18:36:19.582 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 18:36:19.583 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 462 for sweep.
2023-02-07 18:36:19.583 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.00047504055856710666 for sweep.
2023-02-07 18:36:19.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:36:19.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 18:36:19.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5290498111672246 for sweep.
2023-02-07 18:36:19.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 505 for sweep.
2023-02-07 18:36:19.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 16 for sweep.
2023-02-07 18:36:19.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0006569581699855443 for sweep.
2023-02-07 18:36:19.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 79 for sweep.
2023-02-07 18:36:19.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.008845664006423115 for sweep.
2023-02-07 18:36:19.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1814 for sweep.
2023-02-07 18:36:19.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 209 for sweep.
2023-02-07 18:36:19.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.27248595387212776 for sweep.
2023-02-07 18:36:19.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.013904895505591153 for sweep.
2023-02-07 18:36:19.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5775476798582142 for sweep.
2023-02-07 18:36:19.587 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:36:19.593 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183611-2wg1y7r9/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 462, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 505, 'window': 16, 'min_count': 5, 'dm': 1, 'sample': 0.5290498111672246, 'workers': 4, 'alpha': 0.00047504055856710666, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1814, 'max_depth': 79, 'num_leaves': 209, 'reg_alpha': 0.27248595387212776, 'reg_lambda': 0.013904895505591153, 'subsample': 0.5775476798582142, 'min_child_weight': 0.008845664006423115, 'n_jobs': 4, 'learning_rate': 0.0006569581699855443}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 22/3257 [00:00<00:14, 219.19it/s]  1%|‚ñè         | 44/3257 [00:00<00:14, 217.94it/s]  2%|‚ñè         | 67/3257 [00:00<00:14, 218.94it/s]  3%|‚ñé         | 94/3257 [00:00<00:13, 235.00it/s]  4%|‚ñé         | 118/3257 [00:00<00:14, 222.81it/s]  4%|‚ñç         | 141/3257 [00:00<00:14, 216.57it/s]  5%|‚ñå         | 163/3257 [00:00<00:15, 202.68it/s]  6%|‚ñå         | 184/3257 [00:00<00:15, 202.49it/s]  6%|‚ñã         | 205/3257 [00:00<00:15, 201.94it/s]  7%|‚ñã         | 231/3257 [00:01<00:14, 215.85it/s]  8%|‚ñä         | 253/3257 [00:01<00:14, 208.09it/s]  8%|‚ñä         | 275/3257 [00:01<00:14, 209.38it/s]  9%|‚ñâ         | 299/3257 [00:01<00:13, 215.51it/s] 10%|‚ñâ         | 321/3257 [00:01<00:13, 213.38it/s] 11%|‚ñà         | 343/3257 [00:01<00:14, 207.21it/s] 11%|‚ñà         | 364/3257 [00:01<00:13, 206.86it/s] 12%|‚ñà‚ñè        | 385/3257 [00:01<00:14, 199.60it/s] 12%|‚ñà‚ñè        | 406/3257 [00:01<00:14, 197.32it/s] 13%|‚ñà‚ñé        | 426/3257 [00:02<00:15, 178.49it/s] 14%|‚ñà‚ñé        | 445/3257 [00:02<00:15, 181.05it/s] 14%|‚ñà‚ñç        | 467/3257 [00:02<00:14, 189.83it/s] 15%|‚ñà‚ñç        | 487/3257 [00:02<00:14, 186.01it/s] 16%|‚ñà‚ñå        | 510/3257 [00:02<00:13, 196.96it/s] 16%|‚ñà‚ñã        | 530/3257 [00:02<00:13, 195.48it/s] 17%|‚ñà‚ñã        | 550/3257 [00:02<00:13, 194.19it/s] 18%|‚ñà‚ñä        | 570/3257 [00:02<00:14, 188.69it/s] 18%|‚ñà‚ñä        | 589/3257 [00:02<00:14, 178.33it/s] 19%|‚ñà‚ñâ        | 614/3257 [00:03<00:13, 196.38it/s] 19%|‚ñà‚ñâ        | 635/3257 [00:03<00:13, 198.62it/s] 20%|‚ñà‚ñà        | 656/3257 [00:03<00:14, 178.80it/s] 21%|‚ñà‚ñà        | 677/3257 [00:03<00:13, 184.69it/s] 21%|‚ñà‚ñà‚ñè       | 696/3257 [00:03<00:14, 179.67it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:03<00:13, 189.83it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:03<00:14, 173.45it/s] 23%|‚ñà‚ñà‚ñé       | 758/3257 [00:03<00:13, 179.90it/s] 24%|‚ñà‚ñà‚ñç       | 777/3257 [00:03<00:14, 176.33it/s] 24%|‚ñà‚ñà‚ñç       | 797/3257 [00:04<00:13, 181.59it/s] 25%|‚ñà‚ñà‚ñå       | 816/3257 [00:04<00:13, 177.57it/s] 26%|‚ñà‚ñà‚ñå       | 834/3257 [00:04<00:14, 172.01it/s] 26%|‚ñà‚ñà‚ñå       | 852/3257 [00:04<00:14, 166.15it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:04<00:13, 171.47it/s] 27%|‚ñà‚ñà‚ñã       | 890/3257 [00:04<00:13, 175.35it/s] 28%|‚ñà‚ñà‚ñä       | 911/3257 [00:04<00:12, 181.84it/s] 29%|‚ñà‚ñà‚ñä       | 930/3257 [00:04<00:12, 181.65it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:04<00:13, 177.27it/s] 30%|‚ñà‚ñà‚ñâ       | 969/3257 [00:05<00:12, 182.12it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:05<00:13, 174.25it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:05<00:13, 169.45it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1026/3257 [00:05<00:12, 173.89it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1044/3257 [00:05<00:13, 162.33it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1061/3257 [00:05<00:13, 164.32it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:05<00:13, 162.41it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1099/3257 [00:05<00:12, 167.46it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:05<00:12, 169.78it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1135/3257 [00:06<00:12, 164.49it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1152/3257 [00:06<00:13, 161.08it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:06<00:12, 164.85it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:06<00:22, 92.20it/s]  37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:06<00:19, 103.22it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1223/3257 [00:06<00:16, 119.89it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:06<00:14, 137.39it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1261/3257 [00:07<00:13, 146.82it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1278/3257 [00:07<00:13, 147.94it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1295/3257 [00:07<00:13, 149.43it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1314/3257 [00:07<00:12, 159.40it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1334/3257 [00:07<00:11, 169.41it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1352/3257 [00:07<00:11, 169.45it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:07<00:11, 168.88it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:07<00:11, 166.26it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1409/3257 [00:07<00:10, 178.32it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1430/3257 [00:08<00:09, 185.87it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1449/3257 [00:08<00:09, 181.26it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1471/3257 [00:08<00:09, 189.08it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1491/3257 [00:08<00:09, 189.37it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1512/3257 [00:08<00:09, 193.00it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1532/3257 [00:08<00:09, 181.22it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1551/3257 [00:08<00:09, 176.51it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1569/3257 [00:08<00:09, 176.09it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1587/3257 [00:08<00:09, 171.67it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1611/3257 [00:09<00:08, 190.24it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:09<00:08, 197.59it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:09<00:07, 202.57it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1678/3257 [00:09<00:07, 204.17it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1703/3257 [00:09<00:07, 215.40it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:09<00:07, 212.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1750/3257 [00:09<00:07, 214.63it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1775/3257 [00:09<00:06, 224.28it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1798/3257 [00:09<00:06, 223.74it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:09<00:06, 221.23it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1844/3257 [00:10<00:06, 221.27it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:10<00:06, 226.31it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1892/3257 [00:10<00:06, 224.17it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:10<00:05, 228.70it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1944/3257 [00:10<00:05, 242.32it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1972/3257 [00:10<00:05, 252.20it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1998/3257 [00:10<00:05, 242.26it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2023/3257 [00:10<00:05, 237.35it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2047/3257 [00:10<00:05, 221.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2070/3257 [00:11<00:05, 212.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2094/3257 [00:11<00:05, 218.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:11<00:05, 215.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2139/3257 [00:11<00:05, 204.79it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2160/3257 [00:11<00:05, 203.75it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2182/3257 [00:11<00:05, 206.09it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2206/3257 [00:11<00:04, 213.29it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2228/3257 [00:11<00:04, 209.21it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2250/3257 [00:11<00:04, 210.56it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2272/3257 [00:12<00:04, 201.41it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2297/3257 [00:12<00:04, 212.95it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2322/3257 [00:12<00:04, 221.97it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2352/3257 [00:12<00:03, 241.76it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2377/3257 [00:12<00:03, 238.44it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2405/3257 [00:12<00:03, 240.67it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2430/3257 [00:12<00:03, 236.13it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2454/3257 [00:12<00:03, 224.42it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:12<00:03, 236.18it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:13<00:03, 242.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2535/3257 [00:13<00:02, 252.11it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2561/3257 [00:13<00:02, 233.23it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2585/3257 [00:13<00:02, 224.58it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:13<00:02, 240.85it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2639/3257 [00:13<00:04, 148.37it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2659/3257 [00:13<00:03, 155.63it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2685/3257 [00:14<00:03, 177.45it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2706/3257 [00:14<00:03, 175.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2726/3257 [00:14<00:02, 179.83it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2753/3257 [00:14<00:02, 201.53it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2775/3257 [00:14<00:02, 199.65it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:14<00:02, 220.76it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2827/3257 [00:14<00:02, 209.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2850/3257 [00:14<00:01, 212.73it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2876/3257 [00:14<00:01, 225.42it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2900/3257 [00:15<00:01, 215.93it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2926/3257 [00:15<00:01, 227.33it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:15<00:01, 211.10it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2975/3257 [00:15<00:01, 219.43it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2998/3257 [00:15<00:01, 219.12it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3021/3257 [00:15<00:01, 220.86it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:15<00:00, 233.10it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3077/3257 [00:15<00:00, 247.90it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3102/3257 [00:15<00:00, 234.86it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3128/3257 [00:15<00:00, 240.61it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3153/3257 [00:16<00:00, 229.21it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3177/3257 [00:16<00:00, 226.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:16<00:00, 233.62it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3227/3257 [00:16<00:00, 227.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:16<00:00, 233.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 196.83it/s]
2023-02-07 18:36:36.688 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:36:36,689][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d505,n5,w16,mc5,s0.52905,t4>', 'datetime': '2023-02-07T18:36:36.689823', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:36:36,690][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:36:36,690][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:36:37,074][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 18:36:37,075][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:36:37,107][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11219 unique words (51.70% of original 21699, drops 10480)', 'datetime': '2023-02-07T18:36:37.107265', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:36:37,107][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 4341582 word corpus (99.41% of original 4367244, drops 25662)', 'datetime': '2023-02-07T18:36:37.107684', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:36:37,146][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 18:36:37,147][gensim.models.word2vec][INFO] - sample=0.52905 downsamples 0 most-common words
[2023-02-07 18:36:37,147][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4341582 word corpus (100.0%% of prior 4341582)', 'datetime': '2023-02-07T18:36:37.147899', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:36:37,213][gensim.models.word2vec][INFO] - estimated required memory for 11219 words and 505 dimensions: 58164800 bytes
[2023-02-07 18:36:37,213][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:36:37,245][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11219 vocabulary and 505 features, using sg=0 hs=0 sample=0.5290498111672246 negative=5 window=16 shrink_windows=True', 'datetime': '2023-02-07T18:36:37.245591', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:36:38,269][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 15.14% examples, 625310 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:39,300][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 30.30% examples, 644639 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:40,319][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 45.81% examples, 659762 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:41,320][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 61.68% examples, 668752 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:42,325][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 78.60% examples, 679629 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:36:43,327][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 94.38% examples, 676670 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:43,662][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4343128 effective words) took 6.4s, 677079 effective words/s
[2023-02-07 18:36:44,681][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 15.90% examples, 655792 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:36:45,686][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 30.49% examples, 658714 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:46,697][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 45.32% examples, 662341 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:36:47,701][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 60.67% examples, 663590 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:36:48,703][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 75.87% examples, 662811 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:49,705][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 91.40% examples, 662103 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:36:50,197][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4343128 effective words) took 6.5s, 664747 effective words/s
[2023-02-07 18:36:51,206][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 16.73% examples, 695771 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:52,210][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 33.16% examples, 726592 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:53,216][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 50.14% examples, 734588 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:54,216][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 66.38% examples, 733490 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:55,217][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 83.08% examples, 726322 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:56,206][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4343128 effective words) took 6.0s, 723117 effective words/s
[2023-02-07 18:36:57,223][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 16.86% examples, 697965 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:36:58,233][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 32.39% examples, 703218 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:36:59,235][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 48.33% examples, 708506 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:00,242][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 64.57% examples, 707176 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:01,242][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 81.85% examples, 712293 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:02,244][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 99.23% examples, 714642 words/s, in_qsize 4, out_qsize 0
[2023-02-07 18:37:02,273][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4343128 effective words) took 6.1s, 716109 effective words/s
[2023-02-07 18:37:03,277][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 17.13% examples, 723356 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:04,301][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 31.78% examples, 688175 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:05,321][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 47.37% examples, 689131 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:06,323][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 63.19% examples, 689996 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:07,333][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 78.94% examples, 685872 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:08,334][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 95.67% examples, 686372 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:08,600][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4343128 effective words) took 6.3s, 686600 effective words/s
[2023-02-07 18:37:09,603][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 15.90% examples, 666164 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:10,632][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 30.98% examples, 668650 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:11,668][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 46.70% examples, 672409 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:12,670][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 65.06% examples, 707373 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:13,676][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 82.74% examples, 714739 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:14,649][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4343128 effective words) took 6.0s, 718286 effective words/s
[2023-02-07 18:37:15,670][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 16.89% examples, 702897 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:16,678][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 32.61% examples, 705708 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:17,690][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 49.22% examples, 717561 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:18,708][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 65.46% examples, 715429 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:19,716][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 82.74% examples, 715927 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:20,709][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4343128 effective words) took 6.1s, 716856 effective words/s
[2023-02-07 18:37:21,719][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 16.86% examples, 703037 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:22,723][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 32.85% examples, 716219 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:23,740][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 49.22% examples, 720331 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:24,752][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 65.06% examples, 712090 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:25,759][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 81.24% examples, 704990 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:26,763][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 97.48% examples, 700430 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:26,913][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4343128 effective words) took 6.2s, 700291 effective words/s
[2023-02-07 18:37:27,917][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 16.30% examples, 684280 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:28,933][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 31.29% examples, 677468 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:37:29,944][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 46.98% examples, 686919 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:30,951][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 62.60% examples, 684040 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:31,976][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 78.94% examples, 685551 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:33,003][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 97.76% examples, 698990 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:33,099][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4343128 effective words) took 6.2s, 702398 effective words/s
[2023-02-07 18:37:34,109][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 17.53% examples, 744187 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:35,111][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 33.80% examples, 740117 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:36,142][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 50.35% examples, 730733 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:37,148][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 66.84% examples, 731920 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:38,151][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 84.59% examples, 733679 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:39,011][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4343128 effective words) took 5.9s, 734769 effective words/s
[2023-02-07 18:37:40,015][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 16.86% examples, 706680 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:41,017][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 33.25% examples, 732712 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:42,048][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 50.35% examples, 732143 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:43,059][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 67.64% examples, 740774 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:44,085][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 84.74% examples, 731887 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:44,995][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4343128 effective words) took 6.0s, 725995 effective words/s
[2023-02-07 18:37:46,004][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 15.69% examples, 653151 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:47,029][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 30.98% examples, 668029 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:37:48,032][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 46.55% examples, 676975 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:49,074][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 62.57% examples, 676646 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:50,090][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 78.94% examples, 681232 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:37:51,123][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 96.10% examples, 681742 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:51,352][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4343128 effective words) took 6.4s, 683479 effective words/s
[2023-02-07 18:37:52,364][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 17.50% examples, 734647 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:53,373][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 34.57% examples, 755035 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:54,376][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 51.27% examples, 753469 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:55,377][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 68.22% examples, 752320 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:56,388][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 85.91% examples, 746494 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:37:57,182][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4343128 effective words) took 5.8s, 745290 effective words/s
[2023-02-07 18:37:58,184][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 17.50% examples, 741658 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:37:59,199][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 33.99% examples, 742644 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:38:00,216][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 50.88% examples, 744733 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:38:01,227][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 68.07% examples, 748051 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:38:02,240][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 86.52% examples, 750119 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:38:02,977][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4343128 effective words) took 5.8s, 749617 effective words/s
[2023-02-07 18:38:03,981][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 15.90% examples, 665748 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:38:04,995][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 30.98% examples, 673435 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:38:06,006][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 46.79% examples, 684518 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:38:07,010][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 62.57% examples, 684503 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:38:08,019][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 79.03% examples, 688167 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:38:09,039][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 96.10% examples, 689258 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:38:09,261][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4343128 effective words) took 6.3s, 691421 effective words/s
[2023-02-07 18:38:09,262][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65146920 effective words) took 92.0s, 707994 effective words/s', 'datetime': '2023-02-07T18:38:09.262297', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:38:09.262 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:38:14,731][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183611-2wg1y7r9/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:38:14.731714', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:38:14,732][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:38:14,805][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183611-2wg1y7r9/files/../tmp/embedding_model.pt
2023-02-07 18:38:14.805 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:38:17.412 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:38:18.318 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:38:21.581 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0364141647356206, 'test_mae': 0.7600118097809195, 'test_r2': -2.7006744510558316}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.037 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.037 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.17
wandb: percentage 0.48297
wandb:   test_mae 0.76001
wandb:   test_mse 1.03641
wandb:    test_r2 -2.70067
wandb: 
wandb: üöÄ View run comic-sweep-13 at: https://wandb.ai/xiaoqiz/mof2vec/runs/2wg1y7r9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_183611-2wg1y7r9/logs
wandb: Agent Starting Run: rmqrj2sq with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 685
wandb: 	model.gensim.alpha: 0.0009475411193089714
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.31279053905733645
wandb: 	model.gensim.vector_size: 477
wandb: 	model.gensim.window: 17
wandb: 	model.sklearn.learning_rate: 0.006967380832475843
wandb: 	model.sklearn.max_depth: 95
wandb: 	model.sklearn.min_child_weight: 0.08345694839244852
wandb: 	model.sklearn.n_estimators: 618
wandb: 	model.sklearn.num_leaves: 135
wandb: 	model.sklearn.reg_alpha: 0.24657514722902757
wandb: 	model.sklearn.reg_lambda: 0.006873812415196631
wandb: 	model.sklearn.subsample: 0.9374482027645954
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183833-rmqrj2sq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-14
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/rmqrj2sq
2023-02-07 18:38:41.388 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 18:38:41.389 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 685 for sweep.
2023-02-07 18:38:41.389 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0009475411193089714 for sweep.
2023-02-07 18:38:41.390 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:38:41.390 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 18:38:41.390 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.31279053905733645 for sweep.
2023-02-07 18:38:41.390 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 477 for sweep.
2023-02-07 18:38:41.391 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 17 for sweep.
2023-02-07 18:38:41.391 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.006967380832475843 for sweep.
2023-02-07 18:38:41.391 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 95 for sweep.
2023-02-07 18:38:41.391 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08345694839244852 for sweep.
2023-02-07 18:38:41.392 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 618 for sweep.
2023-02-07 18:38:41.392 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 135 for sweep.
2023-02-07 18:38:41.392 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.24657514722902757 for sweep.
2023-02-07 18:38:41.393 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.006873812415196631 for sweep.
2023-02-07 18:38:41.393 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9374482027645954 for sweep.
2023-02-07 18:38:41.393 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:38:41.400 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183833-rmqrj2sq/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 685, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 477, 'window': 17, 'min_count': 6, 'dm': 1, 'sample': 0.31279053905733645, 'workers': 4, 'alpha': 0.0009475411193089714, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 618, 'max_depth': 95, 'num_leaves': 135, 'reg_alpha': 0.24657514722902757, 'reg_lambda': 0.006873812415196631, 'subsample': 0.9374482027645954, 'min_child_weight': 0.08345694839244852, 'n_jobs': 4, 'learning_rate': 0.006967380832475843}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 135.90it/s]  1%|          | 31/3257 [00:00<00:21, 153.28it/s]  1%|‚ñè         | 47/3257 [00:00<00:20, 154.86it/s]  2%|‚ñè         | 63/3257 [00:00<00:20, 152.81it/s]  2%|‚ñè         | 81/3257 [00:00<00:19, 160.70it/s]  3%|‚ñé         | 98/3257 [00:00<00:20, 155.39it/s]  4%|‚ñé         | 114/3257 [00:00<00:20, 150.69it/s]  4%|‚ñç         | 131/3257 [00:00<00:20, 154.20it/s]  5%|‚ñç         | 149/3257 [00:00<00:19, 161.24it/s]  5%|‚ñå         | 166/3257 [00:01<00:20, 150.27it/s]  6%|‚ñå         | 182/3257 [00:01<00:20, 149.23it/s]  6%|‚ñå         | 199/3257 [00:01<00:19, 153.34it/s]  7%|‚ñã         | 217/3257 [00:01<00:19, 159.84it/s]  7%|‚ñã         | 237/3257 [00:01<00:18, 163.77it/s]  8%|‚ñä         | 255/3257 [00:01<00:17, 167.24it/s]  8%|‚ñä         | 272/3257 [00:01<00:18, 162.13it/s]  9%|‚ñâ         | 293/3257 [00:01<00:17, 174.20it/s] 10%|‚ñâ         | 311/3257 [00:01<00:17, 168.21it/s] 10%|‚ñà         | 328/3257 [00:02<00:17, 167.21it/s] 11%|‚ñà         | 345/3257 [00:02<00:18, 161.44it/s] 11%|‚ñà         | 362/3257 [00:02<00:17, 163.53it/s] 12%|‚ñà‚ñè        | 379/3257 [00:02<00:18, 151.55it/s] 12%|‚ñà‚ñè        | 395/3257 [00:02<00:18, 152.10it/s] 13%|‚ñà‚ñé        | 412/3257 [00:02<00:18, 156.92it/s] 13%|‚ñà‚ñé        | 428/3257 [00:02<00:20, 136.79it/s] 14%|‚ñà‚ñé        | 443/3257 [00:02<00:20, 139.78it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:19, 145.11it/s] 15%|‚ñà‚ñç        | 476/3257 [00:03<00:18, 150.88it/s] 15%|‚ñà‚ñå        | 493/3257 [00:03<00:17, 155.36it/s] 16%|‚ñà‚ñå        | 512/3257 [00:03<00:16, 163.88it/s] 16%|‚ñà‚ñå        | 529/3257 [00:03<00:17, 158.78it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:17, 158.43it/s] 17%|‚ñà‚ñã        | 562/3257 [00:03<00:17, 150.05it/s] 18%|‚ñà‚ñä        | 578/3257 [00:03<00:18, 142.63it/s] 18%|‚ñà‚ñä        | 593/3257 [00:04<00:29, 91.20it/s]  19%|‚ñà‚ñâ        | 611/3257 [00:04<00:24, 107.96it/s] 19%|‚ñà‚ñâ        | 625/3257 [00:04<00:23, 112.34it/s] 20%|‚ñà‚ñâ        | 642/3257 [00:04<00:20, 124.98it/s] 20%|‚ñà‚ñà        | 657/3257 [00:04<00:21, 121.80it/s] 21%|‚ñà‚ñà        | 675/3257 [00:04<00:19, 133.67it/s] 21%|‚ñà‚ñà        | 690/3257 [00:04<00:19, 132.51it/s] 22%|‚ñà‚ñà‚ñè       | 706/3257 [00:04<00:18, 138.73it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:04<00:18, 140.04it/s] 23%|‚ñà‚ñà‚ñé       | 737/3257 [00:05<00:18, 138.14it/s] 23%|‚ñà‚ñà‚ñé       | 753/3257 [00:05<00:17, 142.24it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:05<00:16, 148.18it/s] 24%|‚ñà‚ñà‚ñç       | 785/3257 [00:05<00:17, 143.94it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:16, 150.44it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:16, 145.93it/s] 26%|‚ñà‚ñà‚ñå       | 835/3257 [00:05<00:16, 143.77it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:05<00:17, 136.15it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:05<00:17, 140.45it/s] 27%|‚ñà‚ñà‚ñã       | 881/3257 [00:06<00:16, 140.55it/s] 28%|‚ñà‚ñà‚ñä       | 897/3257 [00:06<00:16, 145.96it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:06<00:15, 146.86it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:06<00:15, 152.60it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:06<00:14, 154.31it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:06<00:14, 160.60it/s] 30%|‚ñà‚ñà‚ñà       | 983/3257 [00:06<00:14, 153.31it/s] 31%|‚ñà‚ñà‚ñà       | 999/3257 [00:06<00:15, 146.45it/s] 31%|‚ñà‚ñà‚ñà       | 1014/3257 [00:06<00:15, 144.33it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1029/3257 [00:07<00:15, 143.09it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1044/3257 [00:07<00:15, 140.70it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1059/3257 [00:07<00:15, 143.07it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1078/3257 [00:07<00:14, 154.61it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:07<00:15, 144.00it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1116/3257 [00:07<00:13, 163.92it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1133/3257 [00:07<00:13, 162.90it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1151/3257 [00:07<00:12, 166.62it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:07<00:11, 181.43it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1192/3257 [00:08<00:12, 167.67it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:08<00:12, 167.36it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:08<00:11, 180.05it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1251/3257 [00:08<00:11, 174.15it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:08<00:10, 181.60it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:08<00:11, 167.72it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:08<00:11, 167.22it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1330/3257 [00:08<00:10, 178.39it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:08<00:10, 179.08it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1369/3257 [00:09<00:10, 179.73it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:09<00:10, 173.28it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1410/3257 [00:09<00:09, 185.44it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1431/3257 [00:09<00:09, 192.08it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1451/3257 [00:09<00:09, 190.41it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1472/3257 [00:09<00:09, 194.98it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1492/3257 [00:09<00:09, 195.65it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:09<00:08, 197.12it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1533/3257 [00:09<00:09, 177.62it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1552/3257 [00:10<00:10, 169.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1571/3257 [00:10<00:09, 173.68it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1589/3257 [00:10<00:09, 172.71it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1609/3257 [00:10<00:09, 179.80it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1630/3257 [00:10<00:08, 188.22it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1649/3257 [00:10<00:09, 170.56it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1667/3257 [00:10<00:09, 169.91it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1685/3257 [00:10<00:09, 167.32it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1705/3257 [00:10<00:08, 174.20it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:10<00:08, 175.62it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1741/3257 [00:11<00:09, 157.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:11<00:08, 172.20it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1784/3257 [00:11<00:08, 180.60it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:11<00:08, 180.78it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1822/3257 [00:11<00:07, 180.27it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1841/3257 [00:11<00:08, 175.30it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1859/3257 [00:11<00:08, 174.13it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1880/3257 [00:11<00:07, 181.88it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:11<00:07, 177.77it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1918/3257 [00:12<00:07, 175.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1942/3257 [00:12<00:06, 192.98it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1963/3257 [00:12<00:11, 114.58it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1979/3257 [00:12<00:10, 123.02it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:12<00:09, 137.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2018/3257 [00:12<00:08, 149.44it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2038/3257 [00:12<00:07, 159.30it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2056/3257 [00:13<00:07, 152.85it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2074/3257 [00:13<00:07, 159.57it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:13<00:07, 161.60it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2108/3257 [00:13<00:07, 162.17it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2125/3257 [00:13<00:07, 154.93it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2142/3257 [00:13<00:07, 157.30it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2160/3257 [00:13<00:06, 159.08it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2179/3257 [00:13<00:06, 166.36it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2198/3257 [00:13<00:06, 171.75it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2216/3257 [00:14<00:06, 165.51it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2235/3257 [00:14<00:05, 170.98it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2253/3257 [00:14<00:06, 162.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:14<00:06, 158.15it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2290/3257 [00:14<00:05, 167.60it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2307/3257 [00:14<00:05, 167.01it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2330/3257 [00:14<00:05, 184.27it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2355/3257 [00:14<00:04, 202.97it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2376/3257 [00:14<00:04, 190.09it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:15<00:04, 199.31it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2420/3257 [00:15<00:04, 188.14it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:15<00:04, 178.84it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2459/3257 [00:15<00:04, 177.11it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2479/3257 [00:15<00:04, 182.20it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2503/3257 [00:15<00:03, 196.92it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2523/3257 [00:15<00:03, 197.00it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2543/3257 [00:15<00:03, 191.95it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2563/3257 [00:15<00:03, 181.16it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2582/3257 [00:16<00:03, 175.99it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2602/3257 [00:16<00:03, 182.31it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2628/3257 [00:16<00:03, 203.28it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2649/3257 [00:16<00:03, 181.07it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2668/3257 [00:16<00:03, 175.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2686/3257 [00:16<00:03, 172.97it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:16<00:03, 148.56it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2720/3257 [00:16<00:03, 144.08it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2739/3257 [00:17<00:03, 155.38it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:17<00:03, 158.14it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2773/3257 [00:17<00:03, 149.63it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2791/3257 [00:17<00:02, 155.98it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:17<00:03, 148.78it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:17<00:03, 144.32it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2838/3257 [00:17<00:03, 137.86it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2855/3257 [00:17<00:02, 145.31it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2876/3257 [00:17<00:02, 162.28it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2893/3257 [00:18<00:02, 149.49it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2909/3257 [00:18<00:02, 147.61it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2926/3257 [00:18<00:02, 153.62it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2942/3257 [00:18<00:02, 147.98it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2957/3257 [00:18<00:02, 132.97it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2975/3257 [00:18<00:01, 143.66it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2990/3257 [00:18<00:01, 136.15it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3010/3257 [00:18<00:01, 152.13it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:18<00:01, 144.05it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3045/3257 [00:19<00:01, 154.85it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3064/3257 [00:19<00:01, 163.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3081/3257 [00:19<00:01, 164.15it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3098/3257 [00:19<00:00, 161.40it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:19<00:00, 169.68it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3136/3257 [00:19<00:00, 162.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3153/3257 [00:19<00:00, 156.65it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3170/3257 [00:19<00:00, 160.18it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3187/3257 [00:19<00:00, 154.01it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3205/3257 [00:20<00:00, 160.92it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3222/3257 [00:20<00:00, 147.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3242/3257 [00:20<00:00, 160.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 159.55it/s]
2023-02-07 18:39:02.731 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:39:02,733][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d477,n5,w17,mc6,s0.312791,t4>', 'datetime': '2023-02-07T18:39:02.733569', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:39:02,734][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:39:02,734][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:39:03,332][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 18:39:03,333][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:39:03,396][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 20659 unique words (48.38% of original 42701, drops 22042)', 'datetime': '2023-02-07T18:39:03.396531', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:39:03,398][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 5765964 word corpus (99.02% of original 5822992, drops 57028)', 'datetime': '2023-02-07T18:39:03.398720', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:39:03,475][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 18:39:03,476][gensim.models.word2vec][INFO] - sample=0.312791 downsamples 0 most-common words
[2023-02-07 18:39:03,476][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5765964 word corpus (100.0%% of prior 5765964)', 'datetime': '2023-02-07T18:39:03.476643', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:39:03,605][gensim.models.word2vec][INFO] - estimated required memory for 20659 words and 477 dimensions: 96030000 bytes
[2023-02-07 18:39:03,606][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:39:03,657][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 20659 vocabulary and 477 features, using sg=0 hs=0 sample=0.31279053905733645 negative=5 window=17 shrink_windows=True', 'datetime': '2023-02-07T18:39:03.657280', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:39:04,696][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 11.64% examples, 604325 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:05,709][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 22.60% examples, 629808 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:06,724][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 34.45% examples, 653378 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:07,725][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 48.05% examples, 693450 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:08,732][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 62.45% examples, 715510 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:09,744][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 75.99% examples, 726899 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:10,754][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 89.65% examples, 729928 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:11,506][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5739976 effective words) took 7.8s, 731628 effective words/s
[2023-02-07 18:39:12,516][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 13.05% examples, 719590 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:13,516][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 25.67% examples, 732880 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:14,518][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 37.58% examples, 734485 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:15,522][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 50.45% examples, 736178 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:16,533][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 63.99% examples, 743663 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:17,534][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 77.31% examples, 744036 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:18,542][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 90.85% examples, 747196 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:19,188][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5739976 effective words) took 7.7s, 747395 effective words/s
[2023-02-07 18:39:20,190][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 13.54% examples, 761161 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:21,207][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 26.50% examples, 755592 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:22,222][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 38.99% examples, 753369 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:23,231][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 52.16% examples, 756823 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:24,236][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 65.24% examples, 755732 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:25,245][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 79.06% examples, 756972 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:26,252][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 92.57% examples, 756626 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:26,761][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5739976 effective words) took 7.6s, 758079 effective words/s
[2023-02-07 18:39:27,769][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 13.20% examples, 727994 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:28,781][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 25.85% examples, 738610 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:29,800][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 38.29% examples, 740257 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:30,803][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 51.34% examples, 745589 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:31,809][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 64.75% examples, 749516 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:32,821][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 78.54% examples, 751559 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:33,827][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 91.77% examples, 751606 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:34,397][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5739976 effective words) took 7.6s, 751866 effective words/s
[2023-02-07 18:39:35,403][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 13.33% examples, 748961 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:36,406][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 25.85% examples, 742787 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:37,414][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 38.44% examples, 748756 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:38,424][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 51.06% examples, 743541 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:39,433][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 63.99% examples, 742414 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:40,439][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 76.51% examples, 736663 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:41,443][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 89.50% examples, 733836 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:42,248][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5739976 effective words) took 7.8s, 731340 effective words/s
[2023-02-07 18:39:43,267][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 12.68% examples, 685475 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:44,270][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 24.87% examples, 700139 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:45,297][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 36.57% examples, 702574 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:39:46,308][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 48.97% examples, 706926 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:47,312][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 63.37% examples, 731398 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:48,320][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 78.81% examples, 753330 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:49,333][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 93.12% examples, 759041 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:49,739][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5739976 effective words) took 7.5s, 766480 effective words/s
[2023-02-07 18:39:50,745][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 14.00% examples, 781804 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:51,750][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 26.34% examples, 754599 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:52,766][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.29% examples, 743138 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:53,775][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 51.64% examples, 751067 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:54,776][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 65.83% examples, 766789 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:55,784][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 80.17% examples, 769074 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:56,790][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 93.74% examples, 766647 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:39:57,213][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5739976 effective words) took 7.5s, 768147 effective words/s
[2023-02-07 18:39:58,215][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 13.33% examples, 751643 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:39:59,239][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 25.58% examples, 724310 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:00,247][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 36.97% examples, 717143 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:01,251][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 49.55% examples, 717594 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:02,263][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 63.37% examples, 733348 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:03,266][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 77.46% examples, 742477 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:04,284][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 91.34% examples, 746510 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:04,879][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5739976 effective words) took 7.7s, 748891 effective words/s
[2023-02-07 18:40:05,891][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 13.05% examples, 718374 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:06,918][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 25.30% examples, 711773 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:07,918][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 36.72% examples, 709945 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:08,918][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 49.28% examples, 714897 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:09,926][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 63.52% examples, 735854 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:10,947][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 77.31% examples, 739198 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:11,967][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 91.28% examples, 744184 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:12,623][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5739976 effective words) took 7.7s, 741455 effective words/s
[2023-02-07 18:40:13,643][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 12.68% examples, 684323 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:14,643][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 24.44% examples, 690392 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:15,645][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.48% examples, 707428 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:16,656][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 50.45% examples, 733072 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:17,665][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 63.89% examples, 739766 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:18,692][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 77.10% examples, 737374 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:19,699][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 89.87% examples, 732818 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:20,492][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5739976 effective words) took 7.9s, 729625 effective words/s
[2023-02-07 18:40:21,497][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 12.68% examples, 695074 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:22,512][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 26.50% examples, 755619 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:23,516][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 39.09% examples, 759584 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:24,518][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 52.29% examples, 762492 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:25,522][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 64.63% examples, 751916 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:26,525][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 77.46% examples, 745034 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:27,538][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 89.96% examples, 736561 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:28,218][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5739976 effective words) took 7.7s, 743210 effective words/s
[2023-02-07 18:40:29,222][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 14.15% examples, 790736 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:30,229][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 27.23% examples, 783390 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:31,264][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 39.94% examples, 774544 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:32,279][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 53.05% examples, 767810 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:33,280][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 66.26% examples, 766775 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:34,306][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 79.95% examples, 762149 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:35,336][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 93.74% examples, 759498 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:35,758][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5739976 effective words) took 7.5s, 761390 effective words/s
[2023-02-07 18:40:36,761][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 13.26% examples, 741411 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:37,764][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 26.01% examples, 748401 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:38,797][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 38.99% examples, 752425 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:39,809][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 52.16% examples, 755490 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:40,816][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 65.77% examples, 761800 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:41,821][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 79.40% examples, 760951 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:42,838][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 93.74% examples, 763578 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:43,266][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5739976 effective words) took 7.5s, 764690 effective words/s
[2023-02-07 18:40:44,290][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 12.68% examples, 683358 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:45,304][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 24.72% examples, 691915 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:46,306][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 36.23% examples, 696083 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:47,307][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 48.08% examples, 699218 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:48,313][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 60.58% examples, 699576 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:49,324][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 72.77% examples, 700480 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:50,324][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 84.99% examples, 698242 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:51,327][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 97.67% examples, 697455 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:51,483][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5739976 effective words) took 8.2s, 698839 effective words/s
[2023-02-07 18:40:52,495][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 14.00% examples, 777814 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:53,496][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 27.82% examples, 797155 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:54,496][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 40.13% examples, 786244 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:55,521][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 53.45% examples, 780210 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:56,534][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 66.99% examples, 778137 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:40:57,552][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 80.81% examples, 770487 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:58,561][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 94.53% examples, 768938 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:40:58,932][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5739976 effective words) took 7.4s, 770767 effective words/s
[2023-02-07 18:40:58,933][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86099640 effective words) took 115.3s, 746900 effective words/s', 'datetime': '2023-02-07T18:40:58.933707', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:40:58.933 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:41:06,666][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183833-rmqrj2sq/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:41:06.666408', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:41:06,667][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:41:06,778][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_183833-rmqrj2sq/files/../tmp/embedding_model.pt
2023-02-07 18:41:06.779 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:41:09.579 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:41:10.532 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:41:13.778 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.15202213062584, 'test_mae': 0.831030893956591, 'test_r2': -2.5743496688664576}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.14
wandb: percentage 0.51619
wandb:   test_mae 0.83103
wandb:   test_mse 1.15202
wandb:    test_r2 -2.57435
wandb: 
wandb: üöÄ View run misty-sweep-14 at: https://wandb.ai/xiaoqiz/mof2vec/runs/rmqrj2sq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_183833-rmqrj2sq/logs
wandb: Agent Starting Run: 52ngu38i with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 460
wandb: 	model.gensim.alpha: 0.0041277978930275155
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.4698417046741944
wandb: 	model.gensim.vector_size: 496
wandb: 	model.gensim.window: 7
wandb: 	model.sklearn.learning_rate: 0.008551578787820901
wandb: 	model.sklearn.max_depth: 70
wandb: 	model.sklearn.min_child_weight: 0.03128035664827293
wandb: 	model.sklearn.n_estimators: 1746
wandb: 	model.sklearn.num_leaves: 213
wandb: 	model.sklearn.reg_alpha: 0.36557294488882475
wandb: 	model.sklearn.reg_lambda: 0.012434752683606037
wandb: 	model.sklearn.subsample: 0.928189749820704
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184124-52ngu38i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-15
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/52ngu38i
2023-02-07 18:41:34.607 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 18:41:34.607 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 460 for sweep.
2023-02-07 18:41:34.608 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0041277978930275155 for sweep.
2023-02-07 18:41:34.608 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:41:34.608 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 18:41:34.608 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4698417046741944 for sweep.
2023-02-07 18:41:34.608 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 496 for sweep.
2023-02-07 18:41:34.609 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 7 for sweep.
2023-02-07 18:41:34.609 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.008551578787820901 for sweep.
2023-02-07 18:41:34.609 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 70 for sweep.
2023-02-07 18:41:34.609 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03128035664827293 for sweep.
2023-02-07 18:41:34.610 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1746 for sweep.
2023-02-07 18:41:34.610 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 213 for sweep.
2023-02-07 18:41:34.610 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.36557294488882475 for sweep.
2023-02-07 18:41:34.611 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.012434752683606037 for sweep.
2023-02-07 18:41:34.611 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.928189749820704 for sweep.
2023-02-07 18:41:34.611 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:41:34.618 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184124-52ngu38i/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 460, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 496, 'window': 7, 'min_count': 9, 'dm': 1, 'sample': 0.4698417046741944, 'workers': 4, 'alpha': 0.0041277978930275155, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1746, 'max_depth': 70, 'num_leaves': 213, 'reg_alpha': 0.36557294488882475, 'reg_lambda': 0.012434752683606037, 'subsample': 0.928189749820704, 'min_child_weight': 0.03128035664827293, 'n_jobs': 4, 'learning_rate': 0.008551578787820901}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 21/3257 [00:00<00:15, 204.75it/s]  1%|‚ñè         | 43/3257 [00:00<00:15, 208.33it/s]  2%|‚ñè         | 67/3257 [00:00<00:23, 137.43it/s]  3%|‚ñé         | 91/3257 [00:00<00:19, 166.09it/s]  3%|‚ñé         | 112/3257 [00:00<00:17, 177.06it/s]  4%|‚ñç         | 135/3257 [00:00<00:16, 190.45it/s]  5%|‚ñç         | 160/3257 [00:00<00:15, 205.66it/s]  6%|‚ñå         | 182/3257 [00:00<00:15, 202.23it/s]  6%|‚ñã         | 204/3257 [00:01<00:14, 203.77it/s]  7%|‚ñã         | 231/3257 [00:01<00:13, 221.86it/s]  8%|‚ñä         | 254/3257 [00:01<00:13, 216.91it/s]  9%|‚ñä         | 277/3257 [00:01<00:13, 217.67it/s]  9%|‚ñâ         | 300/3257 [00:01<00:13, 216.27it/s] 10%|‚ñâ         | 325/3257 [00:01<00:13, 224.36it/s] 11%|‚ñà         | 348/3257 [00:01<00:13, 209.60it/s] 11%|‚ñà‚ñè        | 372/3257 [00:01<00:13, 217.03it/s] 12%|‚ñà‚ñè        | 394/3257 [00:01<00:14, 198.15it/s] 13%|‚ñà‚ñé        | 417/3257 [00:02<00:13, 205.93it/s] 13%|‚ñà‚ñé        | 438/3257 [00:02<00:16, 175.89it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:15, 180.92it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:15, 182.96it/s] 15%|‚ñà‚ñå        | 501/3257 [00:02<00:14, 192.59it/s] 16%|‚ñà‚ñå        | 522/3257 [00:02<00:13, 196.61it/s] 17%|‚ñà‚ñã        | 543/3257 [00:02<00:13, 197.77it/s] 17%|‚ñà‚ñã        | 564/3257 [00:02<00:14, 182.94it/s] 18%|‚ñà‚ñä        | 583/3257 [00:02<00:14, 182.73it/s] 19%|‚ñà‚ñä        | 605/3257 [00:03<00:13, 191.99it/s] 19%|‚ñà‚ñâ        | 625/3257 [00:03<00:13, 191.22it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:13, 192.62it/s] 20%|‚ñà‚ñà        | 665/3257 [00:03<00:13, 186.64it/s] 21%|‚ñà‚ñà        | 685/3257 [00:03<00:13, 187.26it/s] 22%|‚ñà‚ñà‚ñè       | 707/3257 [00:03<00:13, 195.59it/s] 22%|‚ñà‚ñà‚ñè       | 727/3257 [00:03<00:13, 189.61it/s] 23%|‚ñà‚ñà‚ñé       | 747/3257 [00:03<00:13, 189.14it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:03<00:12, 197.52it/s] 24%|‚ñà‚ñà‚ñç       | 790/3257 [00:04<00:12, 191.17it/s] 25%|‚ñà‚ñà‚ñç       | 810/3257 [00:04<00:12, 191.60it/s] 25%|‚ñà‚ñà‚ñå       | 830/3257 [00:04<00:13, 186.27it/s] 26%|‚ñà‚ñà‚ñå       | 849/3257 [00:04<00:13, 179.99it/s] 27%|‚ñà‚ñà‚ñã       | 869/3257 [00:04<00:12, 184.09it/s] 27%|‚ñà‚ñà‚ñã       | 888/3257 [00:04<00:12, 182.68it/s] 28%|‚ñà‚ñà‚ñä       | 909/3257 [00:04<00:12, 188.36it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:04<00:12, 192.53it/s] 29%|‚ñà‚ñà‚ñâ       | 953/3257 [00:04<00:11, 199.78it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:05<00:11, 199.33it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:05<00:12, 187.32it/s] 31%|‚ñà‚ñà‚ñà       | 1013/3257 [00:05<00:12, 185.70it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1032/3257 [00:05<00:12, 182.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:05<00:12, 179.58it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1074/3257 [00:05<00:11, 192.98it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:05<00:11, 182.14it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:05<00:11, 188.17it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1134/3257 [00:05<00:11, 182.40it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1153/3257 [00:06<00:11, 182.81it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1174/3257 [00:06<00:10, 189.98it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:06<00:12, 171.85it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1212/3257 [00:06<00:11, 170.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1236/3257 [00:06<00:10, 188.46it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1256/3257 [00:06<00:10, 187.70it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:06<00:10, 183.71it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1294/3257 [00:07<00:17, 113.28it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1315/3257 [00:07<00:14, 132.23it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1336/3257 [00:07<00:12, 148.26it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:07<00:12, 154.12it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1373/3257 [00:07<00:11, 162.43it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1392/3257 [00:07<00:11, 168.64it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1417/3257 [00:07<00:09, 190.68it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1438/3257 [00:07<00:09, 190.34it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:07<00:08, 206.70it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1485/3257 [00:07<00:08, 207.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:08<00:07, 219.96it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1534/3257 [00:08<00:08, 196.24it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:08<00:08, 190.43it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:08<00:08, 188.55it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1598/3257 [00:08<00:08, 199.22it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:08<00:08, 200.27it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1640/3257 [00:08<00:08, 198.36it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:08<00:08, 186.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1681/3257 [00:08<00:08, 188.32it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1702/3257 [00:09<00:08, 192.96it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:09<00:07, 194.37it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1743/3257 [00:09<00:08, 177.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1766/3257 [00:09<00:07, 191.09it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:09<00:07, 203.64it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1811/3257 [00:09<00:07, 194.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1832/3257 [00:09<00:07, 196.51it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1855/3257 [00:09<00:06, 204.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:09<00:06, 210.49it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1901/3257 [00:10<00:06, 209.09it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1923/3257 [00:10<00:06, 207.09it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1949/3257 [00:10<00:05, 221.77it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:10<00:05, 225.68it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1997/3257 [00:10<00:05, 220.41it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2021/3257 [00:10<00:05, 224.02it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2044/3257 [00:10<00:05, 216.32it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2066/3257 [00:10<00:05, 202.19it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2087/3257 [00:10<00:06, 194.01it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2107/3257 [00:11<00:06, 187.52it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2126/3257 [00:11<00:06, 172.40it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2144/3257 [00:11<00:06, 162.90it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:11<00:06, 168.25it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:11<00:06, 169.96it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2200/3257 [00:11<00:06, 175.34it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2218/3257 [00:11<00:06, 167.99it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:11<00:06, 169.72it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2254/3257 [00:11<00:05, 167.21it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2271/3257 [00:12<00:06, 156.89it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2291/3257 [00:12<00:05, 166.80it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2308/3257 [00:12<00:05, 164.91it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2332/3257 [00:12<00:04, 185.38it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2357/3257 [00:12<00:04, 201.11it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2378/3257 [00:12<00:04, 189.46it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:12<00:04, 194.64it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2419/3257 [00:12<00:04, 180.39it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2438/3257 [00:12<00:04, 173.17it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2456/3257 [00:13<00:04, 171.41it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2477/3257 [00:13<00:04, 180.60it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2496/3257 [00:13<00:04, 182.09it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2516/3257 [00:13<00:04, 184.90it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2536/3257 [00:13<00:03, 189.03it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2555/3257 [00:13<00:04, 174.68it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:13<00:04, 167.38it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2590/3257 [00:13<00:04, 163.43it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2615/3257 [00:13<00:03, 185.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2637/3257 [00:14<00:03, 192.41it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2657/3257 [00:14<00:03, 178.91it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2676/3257 [00:14<00:06, 94.30it/s]  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:14<00:05, 106.62it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:14<00:04, 110.93it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2728/3257 [00:14<00:04, 126.91it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2749/3257 [00:15<00:03, 144.99it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2767/3257 [00:15<00:03, 152.71it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2785/3257 [00:15<00:02, 158.06it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2805/3257 [00:15<00:02, 167.55it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:15<00:02, 163.02it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2841/3257 [00:15<00:02, 157.39it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2865/3257 [00:15<00:02, 179.00it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:15<00:02, 184.17it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2905/3257 [00:15<00:02, 172.31it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2926/3257 [00:16<00:01, 180.84it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2945/3257 [00:16<00:01, 164.67it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2963/3257 [00:16<00:01, 168.40it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2981/3257 [00:16<00:01, 161.74it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3002/3257 [00:16<00:01, 174.25it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3020/3257 [00:16<00:01, 170.37it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3041/3257 [00:16<00:01, 181.10it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:16<00:01, 189.84it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3083/3257 [00:16<00:00, 190.96it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3104/3257 [00:17<00:00, 194.43it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3126/3257 [00:17<00:00, 200.80it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3147/3257 [00:17<00:00, 178.92it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:17<00:00, 179.10it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:17<00:00, 173.48it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3205/3257 [00:17<00:00, 179.03it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3224/3257 [00:17<00:00, 166.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:17<00:00, 173.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 181.49it/s]
2023-02-07 18:41:53.354 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:41:53,355][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d496,n5,w7,mc9,s0.469842,t4>', 'datetime': '2023-02-07T18:41:53.355898', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:41:53,356][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:41:53,356][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:41:53,868][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 18:41:53,869][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:41:53,907][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 11387 unique words (35.80% of original 31803, drops 20416)', 'datetime': '2023-02-07T18:41:53.907002', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:41:53,907][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 5023141 word corpus (98.59% of original 5095118, drops 71977)', 'datetime': '2023-02-07T18:41:53.907433', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:41:53,947][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 18:41:53,948][gensim.models.word2vec][INFO] - sample=0.469842 downsamples 0 most-common words
[2023-02-07 18:41:53,948][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5023141 word corpus (100.0%% of prior 5023141)', 'datetime': '2023-02-07T18:41:53.948446', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:41:54,013][gensim.models.word2vec][INFO] - estimated required memory for 11387 words and 496 dimensions: 57990404 bytes
[2023-02-07 18:41:54,013][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:41:54,040][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11387 vocabulary and 496 features, using sg=0 hs=0 sample=0.4698417046741944 negative=5 window=7 shrink_windows=True', 'datetime': '2023-02-07T18:41:54.040682', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:41:55,046][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 24.72% examples, 1229108 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:41:56,046][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 48.11% examples, 1230256 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:41:57,060][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 73.63% examples, 1240309 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:41:58,062][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 100.00% examples, 1247793 words/s, in_qsize 0, out_qsize 1
[2023-02-07 18:41:58,063][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5015324 effective words) took 4.0s, 1247644 effective words/s
[2023-02-07 18:41:59,068][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 24.84% examples, 1234105 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:00,085][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 49.25% examples, 1247363 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:01,091][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 74.58% examples, 1253761 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:02,037][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5015324 effective words) took 4.0s, 1262548 effective words/s
[2023-02-07 18:42:03,040][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 25.45% examples, 1274259 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:04,053][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 50.63% examples, 1287887 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:42:05,062][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 75.22% examples, 1268988 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:06,063][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 99.48% examples, 1239417 words/s, in_qsize 3, out_qsize 1
[2023-02-07 18:42:06,072][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5015324 effective words) took 4.0s, 1243327 effective words/s
[2023-02-07 18:42:07,084][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 22.97% examples, 1136562 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:08,086][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 45.13% examples, 1148759 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:09,086][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 67.79% examples, 1152730 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:10,087][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 91.80% examples, 1157000 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:10,407][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5015324 effective words) took 4.3s, 1157484 effective words/s
[2023-02-07 18:42:11,417][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 23.61% examples, 1164860 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:12,419][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 45.47% examples, 1158663 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:13,420][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 69.51% examples, 1183952 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:14,428][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 98.65% examples, 1233899 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:14,462][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5015324 effective words) took 4.1s, 1237730 effective words/s
[2023-02-07 18:42:15,469][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 25.82% examples, 1295998 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:16,488][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 51.21% examples, 1296922 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:17,491][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 77.80% examples, 1300158 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:18,329][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5015324 effective words) took 3.9s, 1297328 effective words/s
[2023-02-07 18:42:19,337][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 25.64% examples, 1277755 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:20,355][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 50.75% examples, 1280879 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:21,358][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 76.85% examples, 1288220 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:22,222][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5015324 effective words) took 3.9s, 1289264 effective words/s
[2023-02-07 18:42:23,227][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 25.82% examples, 1298699 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:24,228][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 49.68% examples, 1267102 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:42:25,232][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 72.92% examples, 1234451 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:26,236][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 97.36% examples, 1217939 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:26,329][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5015324 effective words) took 4.1s, 1221519 effective words/s
[2023-02-07 18:42:27,341][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 23.61% examples, 1162183 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:28,346][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 45.96% examples, 1164749 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:42:29,356][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 69.02% examples, 1169017 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:30,357][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 93.28% examples, 1168213 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:30,617][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5015324 effective words) took 4.3s, 1170167 effective words/s
[2023-02-07 18:42:31,632][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 23.49% examples, 1155796 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:32,642][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 47.71% examples, 1209206 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:33,643][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 75.96% examples, 1276876 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:34,510][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5015324 effective words) took 3.9s, 1288933 effective words/s
[2023-02-07 18:42:35,521][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 25.82% examples, 1290794 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:36,529][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 51.21% examples, 1301888 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:37,530][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 77.80% examples, 1304132 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:38,348][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5015324 effective words) took 3.8s, 1307184 effective words/s
[2023-02-07 18:42:39,351][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 25.45% examples, 1273527 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:40,365][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 50.63% examples, 1287405 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:41,371][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 77.06% examples, 1293831 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:42,189][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5015324 effective words) took 3.8s, 1306327 effective words/s
[2023-02-07 18:42:43,198][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 23.61% examples, 1165628 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:44,198][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 46.39% examples, 1178085 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:45,204][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 69.02% examples, 1173875 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:46,207][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 93.80% examples, 1175299 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:46,446][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5015324 effective words) took 4.3s, 1178664 effective words/s
[2023-02-07 18:42:47,449][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 23.61% examples, 1172331 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:48,463][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 46.27% examples, 1170919 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:42:49,465][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 69.36% examples, 1178149 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:42:50,466][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 93.80% examples, 1174711 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:50,702][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5015324 effective words) took 4.3s, 1179026 effective words/s
[2023-02-07 18:42:51,704][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 26.71% examples, 1347915 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:52,706][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 52.78% examples, 1352537 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:42:53,711][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 79.24% examples, 1337455 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:42:54,468][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5015324 effective words) took 3.8s, 1332387 effective words/s
[2023-02-07 18:42:54,468][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75229860 effective words) took 60.4s, 1244981 effective words/s', 'datetime': '2023-02-07T18:42:54.468819', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:42:54.469 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:42:59,127][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184124-52ngu38i/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:42:59.127917', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:42:59,128][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:42:59,203][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184124-52ngu38i/files/../tmp/embedding_model.pt
2023-02-07 18:42:59.204 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:43:01.904 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:43:02.889 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:43:06.409 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0406017038838207, 'test_mae': 0.7840195689921731, 'test_r2': -3.0048621766228116}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.54
wandb: percentage 0.64195
wandb:   test_mae 0.78402
wandb:   test_mse 1.0406
wandb:    test_r2 -3.00486
wandb: 
wandb: üöÄ View run breezy-sweep-15 at: https://wandb.ai/xiaoqiz/mof2vec/runs/52ngu38i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_184124-52ngu38i/logs
wandb: Agent Starting Run: 42uet8jk with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 728
wandb: 	model.gensim.alpha: 0.11989870694789524
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.4106875344771654
wandb: 	model.gensim.vector_size: 402
wandb: 	model.gensim.window: 6
wandb: 	model.sklearn.learning_rate: 0.0023276335452198055
wandb: 	model.sklearn.max_depth: 71
wandb: 	model.sklearn.min_child_weight: 0.002866541662147798
wandb: 	model.sklearn.n_estimators: 789
wandb: 	model.sklearn.num_leaves: 445
wandb: 	model.sklearn.reg_alpha: 0.15074835876456216
wandb: 	model.sklearn.reg_lambda: 0.007645466666054384
wandb: 	model.sklearn.subsample: 0.7982000247577112
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184316-42uet8jk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/42uet8jk
2023-02-07 18:43:25.067 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 18:43:25.068 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 728 for sweep.
2023-02-07 18:43:25.068 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.11989870694789524 for sweep.
2023-02-07 18:43:25.069 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:43:25.069 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 18:43:25.069 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4106875344771654 for sweep.
2023-02-07 18:43:25.069 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 402 for sweep.
2023-02-07 18:43:25.070 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 6 for sweep.
2023-02-07 18:43:25.070 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0023276335452198055 for sweep.
2023-02-07 18:43:25.070 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 71 for sweep.
2023-02-07 18:43:25.070 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.002866541662147798 for sweep.
2023-02-07 18:43:25.071 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 789 for sweep.
2023-02-07 18:43:25.071 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 445 for sweep.
2023-02-07 18:43:25.071 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.15074835876456216 for sweep.
2023-02-07 18:43:25.071 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.007645466666054384 for sweep.
2023-02-07 18:43:25.072 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7982000247577112 for sweep.
2023-02-07 18:43:25.072 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:43:25.079 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184316-42uet8jk/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 728, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 402, 'window': 6, 'min_count': 3, 'dm': 1, 'sample': 0.4106875344771654, 'workers': 4, 'alpha': 0.11989870694789524, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 789, 'max_depth': 71, 'num_leaves': 445, 'reg_alpha': 0.15074835876456216, 'reg_lambda': 0.007645466666054384, 'subsample': 0.7982000247577112, 'min_child_weight': 0.002866541662147798, 'n_jobs': 4, 'learning_rate': 0.0023276335452198055}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:21, 149.60it/s]  1%|          | 34/3257 [00:00<00:20, 160.49it/s]  2%|‚ñè         | 53/3257 [00:00<00:19, 166.25it/s]  2%|‚ñè         | 72/3257 [00:00<00:18, 173.48it/s]  3%|‚ñé         | 91/3257 [00:00<00:17, 175.93it/s]  3%|‚ñé         | 109/3257 [00:00<00:18, 166.19it/s]  4%|‚ñç         | 129/3257 [00:00<00:17, 175.82it/s]  5%|‚ñç         | 150/3257 [00:00<00:16, 184.34it/s]  5%|‚ñå         | 169/3257 [00:00<00:17, 177.48it/s]  6%|‚ñå         | 187/3257 [00:01<00:17, 175.63it/s]  6%|‚ñã         | 210/3257 [00:01<00:16, 189.86it/s]  7%|‚ñã         | 237/3257 [00:01<00:14, 210.02it/s]  8%|‚ñä         | 260/3257 [00:01<00:13, 214.27it/s]  9%|‚ñâ         | 288/3257 [00:01<00:12, 232.38it/s] 10%|‚ñâ         | 312/3257 [00:01<00:12, 227.17it/s] 10%|‚ñà         | 337/3257 [00:01<00:12, 233.24it/s] 11%|‚ñà         | 362/3257 [00:01<00:12, 236.37it/s] 12%|‚ñà‚ñè        | 386/3257 [00:01<00:12, 222.30it/s] 13%|‚ñà‚ñé        | 412/3257 [00:02<00:12, 232.10it/s] 13%|‚ñà‚ñé        | 436/3257 [00:02<00:13, 206.18it/s] 14%|‚ñà‚ñç        | 462/3257 [00:02<00:12, 218.99it/s] 15%|‚ñà‚ñç        | 485/3257 [00:02<00:12, 221.03it/s] 16%|‚ñà‚ñå        | 511/3257 [00:02<00:11, 231.74it/s] 16%|‚ñà‚ñã        | 535/3257 [00:02<00:12, 226.55it/s] 17%|‚ñà‚ñã        | 558/3257 [00:02<00:12, 219.22it/s] 18%|‚ñà‚ñä        | 581/3257 [00:02<00:17, 152.56it/s] 19%|‚ñà‚ñä        | 607/3257 [00:03<00:15, 175.30it/s] 19%|‚ñà‚ñâ        | 631/3257 [00:03<00:13, 190.15it/s] 20%|‚ñà‚ñà        | 653/3257 [00:03<00:13, 193.11it/s] 21%|‚ñà‚ñà        | 675/3257 [00:03<00:13, 197.73it/s] 21%|‚ñà‚ñà‚ñè       | 697/3257 [00:03<00:13, 195.14it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:03<00:12, 204.10it/s] 23%|‚ñà‚ñà‚ñé       | 743/3257 [00:03<00:12, 199.10it/s] 24%|‚ñà‚ñà‚ñé       | 769/3257 [00:03<00:11, 215.08it/s] 24%|‚ñà‚ñà‚ñç       | 791/3257 [00:03<00:11, 206.74it/s] 25%|‚ñà‚ñà‚ñç       | 814/3257 [00:04<00:11, 210.06it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:04<00:11, 206.17it/s] 26%|‚ñà‚ñà‚ñã       | 857/3257 [00:04<00:11, 204.33it/s] 27%|‚ñà‚ñà‚ñã       | 879/3257 [00:04<00:11, 207.77it/s] 28%|‚ñà‚ñà‚ñä       | 902/3257 [00:04<00:11, 213.57it/s] 28%|‚ñà‚ñà‚ñä       | 924/3257 [00:04<00:11, 210.95it/s] 29%|‚ñà‚ñà‚ñâ       | 946/3257 [00:04<00:11, 204.75it/s] 30%|‚ñà‚ñà‚ñâ       | 969/3257 [00:04<00:10, 209.89it/s] 30%|‚ñà‚ñà‚ñà       | 991/3257 [00:04<00:11, 202.20it/s] 31%|‚ñà‚ñà‚ñà       | 1012/3257 [00:05<00:11, 199.90it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1033/3257 [00:05<00:11, 197.48it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1053/3257 [00:05<00:11, 195.18it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1078/3257 [00:05<00:10, 209.05it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1099/3257 [00:05<00:10, 197.28it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1119/3257 [00:05<00:10, 197.14it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1140/3257 [00:05<00:10, 198.34it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1163/3257 [00:05<00:10, 205.75it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1184/3257 [00:05<00:10, 192.89it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:06<00:11, 185.15it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1227/3257 [00:06<00:10, 197.04it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1248/3257 [00:06<00:10, 198.91it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:06<00:09, 204.44it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:06<00:10, 191.40it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1314/3257 [00:06<00:09, 197.88it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1337/3257 [00:06<00:09, 205.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1358/3257 [00:06<00:09, 197.80it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1378/3257 [00:06<00:09, 194.89it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1398/3257 [00:06<00:10, 184.57it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1421/3257 [00:07<00:09, 196.29it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1441/3257 [00:07<00:09, 193.02it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1467/3257 [00:07<00:08, 210.23it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1489/3257 [00:07<00:08, 211.88it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:07<00:07, 218.13it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1535/3257 [00:07<00:08, 198.77it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1556/3257 [00:07<00:08, 192.10it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1576/3257 [00:07<00:08, 191.27it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1599/3257 [00:07<00:08, 200.65it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:08<00:08, 202.88it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1641/3257 [00:08<00:08, 197.73it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:08<00:08, 189.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1681/3257 [00:08<00:08, 188.91it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1702/3257 [00:08<00:07, 194.78it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1722/3257 [00:08<00:07, 192.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1742/3257 [00:08<00:08, 173.12it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1766/3257 [00:08<00:07, 188.92it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:08<00:07, 201.48it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1811/3257 [00:09<00:07, 190.46it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1831/3257 [00:09<00:07, 190.44it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1853/3257 [00:09<00:07, 198.51it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1875/3257 [00:09<00:06, 204.18it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1896/3257 [00:09<00:06, 198.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1917/3257 [00:09<00:11, 121.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1941/3257 [00:09<00:09, 143.99it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1967/3257 [00:10<00:07, 168.54it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1988/3257 [00:10<00:07, 171.41it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:10<00:07, 177.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2031/3257 [00:10<00:06, 191.10it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:10<00:06, 180.32it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2072/3257 [00:10<00:06, 182.81it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2094/3257 [00:10<00:06, 191.12it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2115/3257 [00:10<00:05, 194.04it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2135/3257 [00:10<00:06, 181.37it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:11<00:06, 181.15it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2177/3257 [00:11<00:05, 192.80it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2197/3257 [00:11<00:05, 192.77it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2217/3257 [00:11<00:05, 188.61it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:11<00:05, 188.74it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:11<00:05, 192.81it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2279/3257 [00:11<00:05, 186.20it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:11<00:04, 193.33it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2327/3257 [00:11<00:04, 212.10it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2354/3257 [00:12<00:03, 226.53it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2377/3257 [00:12<00:04, 218.30it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2402/3257 [00:12<00:03, 226.60it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2425/3257 [00:12<00:03, 215.46it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2447/3257 [00:12<00:03, 203.35it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2469/3257 [00:12<00:03, 206.40it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2490/3257 [00:12<00:03, 204.94it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2515/3257 [00:12<00:03, 217.28it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:12<00:03, 218.12it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2562/3257 [00:13<00:03, 208.53it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2583/3257 [00:13<00:03, 197.96it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2605/3257 [00:13<00:03, 203.48it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2631/3257 [00:13<00:02, 218.92it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:13<00:02, 208.57it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2676/3257 [00:13<00:02, 200.45it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2697/3257 [00:13<00:02, 192.35it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2717/3257 [00:13<00:03, 176.13it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2742/3257 [00:13<00:02, 194.99it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2763/3257 [00:14<00:02, 195.19it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2785/3257 [00:14<00:02, 200.35it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:14<00:02, 199.99it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2828/3257 [00:14<00:02, 191.18it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2848/3257 [00:14<00:02, 190.82it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2874/3257 [00:14<00:01, 207.73it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2895/3257 [00:14<00:01, 194.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:14<00:01, 197.51it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2936/3257 [00:14<00:01, 196.97it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2956/3257 [00:15<00:01, 183.02it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:15<00:01, 185.40it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2995/3257 [00:15<00:01, 184.36it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:15<00:01, 191.43it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3039/3257 [00:15<00:01, 200.08it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3064/3257 [00:15<00:00, 213.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3086/3257 [00:15<00:00, 210.38it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:15<00:00, 216.29it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3132/3257 [00:15<00:00, 216.30it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3154/3257 [00:15<00:00, 203.54it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3175/3257 [00:16<00:00, 203.09it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3196/3257 [00:16<00:00, 201.08it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3217/3257 [00:16<00:00, 185.27it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3240/3257 [00:16<00:00, 196.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 197.06it/s]
2023-02-07 18:43:42.317 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:43:42,319][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d402,n5,w6,mc3,s0.410688,t4>', 'datetime': '2023-02-07T18:43:42.319116', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:43:42,320][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:43:42,320][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:43:42,786][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 18:43:42,786][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:43:42,847][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 22723 unique words (71.45% of original 31803, drops 9080)', 'datetime': '2023-02-07T18:43:42.847262', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:43:42,848][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 5081575 word corpus (99.73% of original 5095118, drops 13543)', 'datetime': '2023-02-07T18:43:42.848438', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:43:42,928][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 18:43:42,929][gensim.models.word2vec][INFO] - sample=0.410688 downsamples 0 most-common words
[2023-02-07 18:43:42,929][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5081575 word corpus (100.0%% of prior 5081575)', 'datetime': '2023-02-07T18:43:42.929370', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:43:43,067][gensim.models.word2vec][INFO] - estimated required memory for 22723 words and 402 dimensions: 90327324 bytes
[2023-02-07 18:43:43,068][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:43:43,109][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 22723 vocabulary and 402 features, using sg=0 hs=0 sample=0.4106875344771654 negative=5 window=6 shrink_windows=True', 'datetime': '2023-02-07T18:43:43.109802', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:43:44,121][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 28.40% examples, 1430646 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:43:45,128][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 58.80% examples, 1509161 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:46,131][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 91.00% examples, 1540582 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:46,384][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5073452 effective words) took 3.3s, 1550208 effective words/s
[2023-02-07 18:43:47,392][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 31.84% examples, 1627565 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:48,392][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 64.05% examples, 1649426 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:49,393][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 97.36% examples, 1644370 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:43:49,457][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5073452 effective words) took 3.1s, 1652260 effective words/s
[2023-02-07 18:43:50,461][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 31.72% examples, 1623462 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:51,464][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 63.22% examples, 1628416 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:52,477][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 96.62% examples, 1625687 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:52,566][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5073452 effective words) took 3.1s, 1632679 effective words/s
[2023-02-07 18:43:53,571][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 32.21% examples, 1649126 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:54,584][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 64.54% examples, 1653051 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:43:55,590][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 98.56% examples, 1656264 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:55,620][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5073452 effective words) took 3.1s, 1661978 effective words/s
[2023-02-07 18:43:56,621][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 32.36% examples, 1662392 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:57,633][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 61.84% examples, 1581985 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:58,640][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 91.65% examples, 1552050 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:43:58,889][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5073452 effective words) took 3.3s, 1552210 effective words/s
[2023-02-07 18:43:59,895][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 29.87% examples, 1509978 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:44:00,902][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 58.80% examples, 1514379 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:01,904][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 88.85% examples, 1507013 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:02,250][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5073452 effective words) took 3.4s, 1510926 effective words/s
[2023-02-07 18:44:03,256][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 29.32% examples, 1485108 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:04,256][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 57.78% examples, 1495883 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:05,261][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 87.53% examples, 1489162 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:05,628][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5073452 effective words) took 3.4s, 1503260 effective words/s
[2023-02-07 18:44:06,631][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 36.20% examples, 1867947 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:07,639][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 71.20% examples, 1833794 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:08,405][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5073452 effective words) took 2.8s, 1827936 effective words/s
[2023-02-07 18:44:09,415][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 35.06% examples, 1790907 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:10,419][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 64.45% examples, 1655218 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:11,421][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 96.04% examples, 1616754 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:11,544][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5073452 effective words) took 3.1s, 1616863 effective words/s
[2023-02-07 18:44:12,551][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 32.36% examples, 1653276 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:13,558][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 67.30% examples, 1731550 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:14,478][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5073452 effective words) took 2.9s, 1730370 effective words/s
[2023-02-07 18:44:15,480][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 32.36% examples, 1661306 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:16,485][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 64.60% examples, 1666275 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:17,491][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 97.36% examples, 1641617 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:44:17,574][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5073452 effective words) took 3.1s, 1639227 effective words/s
[2023-02-07 18:44:18,584][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 27.88% examples, 1413859 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:19,586][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 55.45% examples, 1433359 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:20,596][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 85.66% examples, 1450158 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:20,972][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5073452 effective words) took 3.4s, 1493548 effective words/s
[2023-02-07 18:44:21,979][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 33.59% examples, 1720794 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:22,979][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 65.61% examples, 1694172 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:23,979][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 99.11% examples, 1675528 words/s, in_qsize 5, out_qsize 0
[2023-02-07 18:44:24,000][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5073452 effective words) took 3.0s, 1677023 effective words/s
[2023-02-07 18:44:25,006][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 28.55% examples, 1444885 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:44:26,018][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 55.82% examples, 1437826 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:27,026][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 84.99% examples, 1438811 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:44:27,502][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5073452 effective words) took 3.5s, 1449082 effective words/s
[2023-02-07 18:44:28,505][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 35.40% examples, 1824198 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:29,505][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 67.06% examples, 1736663 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:44:30,455][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5073452 effective words) took 3.0s, 1718876 effective words/s
[2023-02-07 18:44:30,455][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76101780 effective words) took 47.3s, 1607370 effective words/s', 'datetime': '2023-02-07T18:44:30.455744', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:44:30.455 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:44:34,986][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184316-42uet8jk/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:44:34.986532', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:44:34,987][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:44:35,096][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184316-42uet8jk/files/../tmp/embedding_model.pt
2023-02-07 18:44:35.097 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:44:37.306 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:44:38.188 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:44:41.012 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.130745799111805, 'test_mae': 0.8234786340521157, 'test_r2': -3.298207378066686}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.032 MB uploaded (0.000 MB deduped)wandb: | 0.032 MB of 0.032 MB uploaded (0.000 MB deduped)wandb: / 0.032 MB of 0.032 MB uploaded (0.000 MB deduped)wandb: - 0.032 MB of 0.032 MB uploaded (0.000 MB deduped)wandb: \ 0.032 MB of 0.032 MB uploaded (0.000 MB deduped)wandb: | 0.032 MB of 0.032 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.06
wandb: percentage 0.28551
wandb:   test_mae 0.82348
wandb:   test_mse 1.13075
wandb:    test_r2 -3.29821
wandb: 
wandb: üöÄ View run zany-sweep-16 at: https://wandb.ai/xiaoqiz/mof2vec/runs/42uet8jk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_184316-42uet8jk/logs
wandb: Agent Starting Run: 97k50v1a with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 775
wandb: 	model.gensim.alpha: 0.0005891787430839583
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.5000313025127233
wandb: 	model.gensim.vector_size: 485
wandb: 	model.gensim.window: 13
wandb: 	model.sklearn.learning_rate: 0.008440447278927884
wandb: 	model.sklearn.max_depth: 72
wandb: 	model.sklearn.min_child_weight: 0.014986533709572567
wandb: 	model.sklearn.n_estimators: 2541
wandb: 	model.sklearn.num_leaves: 149
wandb: 	model.sklearn.reg_alpha: 0.3040498537810616
wandb: 	model.sklearn.reg_lambda: 0.09677093008424936
wandb: 	model.sklearn.subsample: 0.9175702491897282
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184456-97k50v1a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-17
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/97k50v1a
2023-02-07 18:45:04.354 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 18:45:04.355 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 775 for sweep.
2023-02-07 18:45:04.355 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0005891787430839583 for sweep.
2023-02-07 18:45:04.355 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:45:04.355 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 18:45:04.356 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5000313025127233 for sweep.
2023-02-07 18:45:04.356 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 485 for sweep.
2023-02-07 18:45:04.356 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 13 for sweep.
2023-02-07 18:45:04.356 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.008440447278927884 for sweep.
2023-02-07 18:45:04.356 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 72 for sweep.
2023-02-07 18:45:04.357 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.014986533709572567 for sweep.
2023-02-07 18:45:04.357 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2541 for sweep.
2023-02-07 18:45:04.357 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 149 for sweep.
2023-02-07 18:45:04.357 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.3040498537810616 for sweep.
2023-02-07 18:45:04.357 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.09677093008424936 for sweep.
2023-02-07 18:45:04.358 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9175702491897282 for sweep.
2023-02-07 18:45:04.358 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:45:04.363 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184456-97k50v1a/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 775, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 485, 'window': 13, 'min_count': 5, 'dm': 1, 'sample': 0.5000313025127233, 'workers': 4, 'alpha': 0.0005891787430839583, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2541, 'max_depth': 72, 'num_leaves': 149, 'reg_alpha': 0.3040498537810616, 'reg_lambda': 0.09677093008424936, 'subsample': 0.9175702491897282, 'min_child_weight': 0.014986533709572567, 'n_jobs': 4, 'learning_rate': 0.008440447278927884}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 4/3257 [00:00<02:20, 23.17it/s]  1%|          | 27/3257 [00:00<00:27, 115.99it/s]  1%|‚ñè         | 46/3257 [00:00<00:22, 144.28it/s]  2%|‚ñè         | 67/3257 [00:00<00:19, 161.81it/s]  3%|‚ñé         | 90/3257 [00:00<00:17, 181.94it/s]  3%|‚ñé         | 110/3257 [00:00<00:17, 180.47it/s]  4%|‚ñç         | 131/3257 [00:00<00:16, 188.73it/s]  5%|‚ñç         | 152/3257 [00:00<00:15, 194.71it/s]  5%|‚ñå         | 172/3257 [00:01<00:16, 190.69it/s]  6%|‚ñå         | 193/3257 [00:01<00:15, 192.49it/s]  7%|‚ñã         | 215/3257 [00:01<00:15, 200.19it/s]  7%|‚ñã         | 237/3257 [00:01<00:14, 201.55it/s]  8%|‚ñä         | 259/3257 [00:01<00:14, 201.09it/s]  9%|‚ñâ         | 285/3257 [00:01<00:13, 216.06it/s]  9%|‚ñâ         | 307/3257 [00:01<00:14, 210.06it/s] 10%|‚ñà         | 329/3257 [00:01<00:13, 212.20it/s] 11%|‚ñà         | 351/3257 [00:01<00:13, 210.06it/s] 11%|‚ñà‚ñè        | 374/3257 [00:01<00:13, 214.71it/s] 12%|‚ñà‚ñè        | 396/3257 [00:02<00:14, 196.93it/s] 13%|‚ñà‚ñé        | 418/3257 [00:02<00:14, 201.20it/s] 13%|‚ñà‚ñé        | 439/3257 [00:02<00:16, 171.97it/s] 14%|‚ñà‚ñç        | 460/3257 [00:02<00:15, 181.48it/s] 15%|‚ñà‚ñç        | 480/3257 [00:02<00:15, 182.70it/s] 15%|‚ñà‚ñå        | 504/3257 [00:02<00:14, 195.55it/s] 16%|‚ñà‚ñå        | 525/3257 [00:02<00:13, 198.05it/s] 17%|‚ñà‚ñã        | 546/3257 [00:02<00:14, 193.36it/s] 17%|‚ñà‚ñã        | 566/3257 [00:03<00:14, 183.77it/s] 18%|‚ñà‚ñä        | 585/3257 [00:03<00:14, 182.16it/s] 19%|‚ñà‚ñä        | 605/3257 [00:03<00:14, 186.17it/s] 19%|‚ñà‚ñâ        | 625/3257 [00:03<00:13, 189.87it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:13, 192.04it/s] 20%|‚ñà‚ñà        | 665/3257 [00:03<00:14, 184.55it/s] 21%|‚ñà‚ñà        | 684/3257 [00:03<00:13, 186.06it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:03<00:13, 189.19it/s] 22%|‚ñà‚ñà‚ñè       | 723/3257 [00:03<00:13, 186.79it/s] 23%|‚ñà‚ñà‚ñé       | 742/3257 [00:03<00:14, 178.50it/s] 23%|‚ñà‚ñà‚ñé       | 765/3257 [00:04<00:12, 192.35it/s] 24%|‚ñà‚ñà‚ñç       | 785/3257 [00:04<00:13, 183.90it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:13, 186.13it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:04<00:13, 183.23it/s] 26%|‚ñà‚ñà‚ñå       | 844/3257 [00:04<00:13, 178.37it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:04<00:13, 182.18it/s] 27%|‚ñà‚ñà‚ñã       | 883/3257 [00:04<00:13, 182.37it/s] 28%|‚ñà‚ñà‚ñä       | 904/3257 [00:04<00:12, 189.75it/s] 28%|‚ñà‚ñà‚ñä       | 924/3257 [00:04<00:12, 190.44it/s] 29%|‚ñà‚ñà‚ñâ       | 944/3257 [00:05<00:12, 187.07it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:05<00:11, 195.56it/s] 30%|‚ñà‚ñà‚ñà       | 986/3257 [00:05<00:12, 185.76it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:05<00:12, 181.40it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:05<00:12, 180.18it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:05<00:12, 178.44it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1066/3257 [00:05<00:11, 184.00it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1085/3257 [00:05<00:11, 183.69it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:05<00:11, 184.73it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:06<00:11, 180.74it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:06<00:11, 179.58it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1164/3257 [00:06<00:11, 186.90it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1183/3257 [00:06<00:11, 177.14it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1201/3257 [00:06<00:12, 162.68it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:06<00:12, 166.52it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:06<00:17, 117.73it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1259/3257 [00:07<00:15, 130.20it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:07<00:14, 139.83it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1294/3257 [00:07<00:13, 146.14it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1314/3257 [00:07<00:12, 159.19it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1336/3257 [00:07<00:11, 174.00it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1355/3257 [00:07<00:10, 173.20it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1374/3257 [00:07<00:10, 174.27it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1392/3257 [00:07<00:10, 175.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1419/3257 [00:07<00:09, 201.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1440/3257 [00:07<00:09, 195.06it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1465/3257 [00:08<00:08, 210.00it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1487/3257 [00:08<00:08, 206.46it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:08<00:08, 215.56it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1533/3257 [00:08<00:08, 193.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1553/3257 [00:08<00:09, 186.19it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:08<00:08, 190.92it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:08<00:08, 192.11it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:08<00:08, 198.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1638/3257 [00:08<00:08, 191.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1658/3257 [00:09<00:08, 186.82it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:09<00:08, 182.63it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1698/3257 [00:09<00:08, 189.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1718/3257 [00:09<00:08, 190.14it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1738/3257 [00:09<00:08, 175.76it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1760/3257 [00:09<00:07, 187.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1783/3257 [00:09<00:07, 197.19it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:09<00:07, 193.78it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1823/3257 [00:09<00:07, 193.26it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1843/3257 [00:10<00:07, 193.70it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1865/3257 [00:10<00:06, 199.25it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1885/3257 [00:10<00:07, 193.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1908/3257 [00:10<00:06, 200.95it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1929/3257 [00:10<00:06, 193.37it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1959/3257 [00:10<00:05, 223.03it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:10<00:06, 212.46it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:10<00:05, 212.24it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2028/3257 [00:10<00:05, 218.82it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2051/3257 [00:11<00:06, 196.87it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2072/3257 [00:11<00:06, 194.06it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2093/3257 [00:11<00:05, 197.44it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2114/3257 [00:11<00:05, 197.54it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:11<00:06, 183.11it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2153/3257 [00:11<00:05, 184.59it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2176/3257 [00:11<00:05, 196.79it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2196/3257 [00:11<00:05, 193.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2216/3257 [00:11<00:05, 189.27it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:12<00:05, 193.19it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2257/3257 [00:12<00:05, 194.04it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2277/3257 [00:12<00:05, 184.18it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:12<00:04, 196.38it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2324/3257 [00:12<00:04, 203.82it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2345/3257 [00:12<00:04, 203.90it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2366/3257 [00:12<00:04, 204.27it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2387/3257 [00:12<00:04, 196.79it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2407/3257 [00:12<00:04, 184.51it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2426/3257 [00:13<00:04, 183.64it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2445/3257 [00:13<00:04, 168.93it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2465/3257 [00:13<00:04, 175.46it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2484/3257 [00:13<00:04, 175.68it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:13<00:04, 187.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2526/3257 [00:13<00:03, 185.14it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2545/3257 [00:13<00:03, 186.45it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2564/3257 [00:13<00:03, 175.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2582/3257 [00:13<00:04, 168.37it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2599/3257 [00:14<00:03, 166.76it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2623/3257 [00:14<00:03, 186.15it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2642/3257 [00:14<00:03, 182.44it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2661/3257 [00:14<00:03, 170.94it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2681/3257 [00:14<00:03, 178.26it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2700/3257 [00:14<00:06, 85.57it/s]  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2715/3257 [00:15<00:05, 94.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2736/3257 [00:15<00:04, 115.63it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:15<00:03, 130.64it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2773/3257 [00:15<00:03, 136.10it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2794/3257 [00:15<00:03, 153.14it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:15<00:02, 158.60it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2831/3257 [00:15<00:02, 152.54it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2851/3257 [00:15<00:02, 161.91it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2875/3257 [00:15<00:02, 182.31it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2895/3257 [00:16<00:02, 170.61it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2915/3257 [00:16<00:01, 176.30it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2934/3257 [00:16<00:01, 174.59it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2952/3257 [00:16<00:01, 166.15it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2971/3257 [00:16<00:01, 171.84it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2989/3257 [00:16<00:01, 159.96it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:16<00:01, 175.20it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3029/3257 [00:16<00:01, 169.87it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:16<00:01, 177.52it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3072/3257 [00:17<00:00, 192.06it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3092/3257 [00:17<00:00, 186.32it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3116/3257 [00:17<00:00, 198.95it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3137/3257 [00:17<00:00, 189.25it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3157/3257 [00:17<00:00, 181.52it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3176/3257 [00:17<00:00, 178.71it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3196/3257 [00:17<00:00, 182.43it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3215/3257 [00:17<00:00, 163.84it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3234/3257 [00:17<00:00, 170.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:18<00:00, 168.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 179.78it/s]
2023-02-07 18:45:23.232 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:45:23,234][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d485,n5,w13,mc5,s0.500031,t4>', 'datetime': '2023-02-07T18:45:23.234107', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:45:23,234][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:45:23,234][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:45:23,783][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 18:45:23,784][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:45:23,836][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 16108 unique words (50.65% of original 31803, drops 15695)', 'datetime': '2023-02-07T18:45:23.836802', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:45:23,837][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5056108 word corpus (99.23% of original 5095118, drops 39010)', 'datetime': '2023-02-07T18:45:23.837914', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:45:23,896][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 18:45:23,897][gensim.models.word2vec][INFO] - sample=0.500031 downsamples 0 most-common words
[2023-02-07 18:45:23,897][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5056108 word corpus (100.0%% of prior 5056108)', 'datetime': '2023-02-07T18:45:23.897637', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:45:24,001][gensim.models.word2vec][INFO] - estimated required memory for 16108 words and 485 dimensions: 77523020 bytes
[2023-02-07 18:45:24,001][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:45:24,048][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 16108 vocabulary and 485 features, using sg=0 hs=0 sample=0.5000313025127233 negative=5 window=13 shrink_windows=True', 'datetime': '2023-02-07T18:45:24.048395', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:45:25,059][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 14.98% examples, 732676 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:26,085][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 31.56% examples, 791930 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:45:27,110][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 49.25% examples, 829243 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:28,133][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 66.47% examples, 839072 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:45:29,145][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 84.83% examples, 848473 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:45:29,971][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5048130 effective words) took 5.9s, 852670 effective words/s
[2023-02-07 18:45:30,995][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 17.53% examples, 855257 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:45:32,010][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 34.48% examples, 864824 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:45:33,031][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 51.95% examples, 876831 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:34,032][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 69.36% examples, 881390 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:35,032][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 88.42% examples, 886474 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:35,657][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5048130 effective words) took 5.7s, 888260 effective words/s
[2023-02-07 18:45:36,660][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 17.72% examples, 870320 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:37,685][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 35.06% examples, 887397 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:45:38,693][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 51.55% examples, 877127 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:45:39,693][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 68.28% examples, 872571 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:40,693][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 86.15% examples, 870239 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:41,492][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5048130 effective words) took 5.8s, 865274 effective words/s
[2023-02-07 18:45:42,496][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 16.86% examples, 825336 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:43,507][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 32.91% examples, 833714 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:44,518][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 49.46% examples, 842043 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:45,525][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 65.77% examples, 841260 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:45:46,529][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 84.46% examples, 854602 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:47,272][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5048130 effective words) took 5.8s, 873834 effective words/s
[2023-02-07 18:45:48,296][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 19.01% examples, 914080 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:45:49,299][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 36.11% examples, 915633 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:50,304][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 53.45% examples, 914908 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:45:51,308][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 71.66% examples, 913648 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:45:52,312][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 90.51% examples, 913331 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:52,803][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5048130 effective words) took 5.5s, 913108 effective words/s
[2023-02-07 18:45:53,807][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 17.96% examples, 889135 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:54,811][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 35.06% examples, 896686 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:55,814][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 53.02% examples, 908617 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:56,819][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 71.11% examples, 913842 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:45:57,823][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 90.33% examples, 913530 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:45:58,342][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5048130 effective words) took 5.5s, 911584 effective words/s
[2023-02-07 18:45:59,352][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 17.22% examples, 836433 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:00,364][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 33.59% examples, 852388 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:01,365][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 50.32% examples, 858738 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:46:02,373][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 67.06% examples, 858735 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:03,373][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 84.99% examples, 861484 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:04,187][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5048130 effective words) took 5.8s, 864062 effective words/s
[2023-02-07 18:46:05,193][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 17.16% examples, 835691 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:06,199][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 33.59% examples, 856272 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:07,200][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 52.13% examples, 893646 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:08,207][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 70.65% examples, 908348 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:09,209][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 89.93% examples, 910013 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:09,714][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5048130 effective words) took 5.5s, 913685 effective words/s
[2023-02-07 18:46:10,722][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 18.73% examples, 918731 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:11,728][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 36.01% examples, 916311 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:12,730][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 53.85% examples, 925507 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:13,737][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 72.43% examples, 922923 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:14,748][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 91.50% examples, 924778 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:15,158][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5048130 effective words) took 5.4s, 927575 effective words/s
[2023-02-07 18:46:16,173][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 19.01% examples, 921874 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:17,175][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.20% examples, 925055 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:18,176][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 53.02% examples, 906636 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:19,194][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 70.37% examples, 900332 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:20,194][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 88.79% examples, 895266 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:20,803][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5048130 effective words) took 5.6s, 894698 effective words/s
[2023-02-07 18:46:21,818][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 17.72% examples, 860533 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:22,821][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 34.33% examples, 870980 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:23,828][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 51.06% examples, 871452 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:24,844][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 67.85% examples, 867155 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:25,856][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 86.21% examples, 868179 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:26,501][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5048130 effective words) took 5.7s, 886253 effective words/s
[2023-02-07 18:46:27,511][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 19.65% examples, 961735 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:28,523][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 36.91% examples, 946321 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:29,525][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 55.11% examples, 941746 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:30,540][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 74.06% examples, 939610 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:31,558][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 93.52% examples, 938268 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:31,876][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5048130 effective words) took 5.4s, 939476 effective words/s
[2023-02-07 18:46:32,884][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 18.73% examples, 919383 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:33,887][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 36.32% examples, 930315 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:34,897][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 54.44% examples, 931890 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:35,907][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 73.47% examples, 934558 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:36,908][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 91.50% examples, 925253 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:37,343][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5048130 effective words) took 5.5s, 923722 effective words/s
[2023-02-07 18:46:38,370][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 17.72% examples, 850700 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:39,376][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 34.33% examples, 864322 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:40,383][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 50.97% examples, 864333 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:41,410][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 68.07% examples, 861887 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:42,410][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 86.21% examples, 865756 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:43,156][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5048130 effective words) took 5.8s, 868807 effective words/s
[2023-02-07 18:46:44,163][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 17.50% examples, 859601 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:45,188][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 35.06% examples, 886305 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:46,191][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 54.44% examples, 927602 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:46:47,200][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 73.44% examples, 929549 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:48,206][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 92.14% examples, 927317 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:46:48,592][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5048130 effective words) took 5.4s, 929063 effective words/s
[2023-02-07 18:46:48,592][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75721950 effective words) took 84.5s, 895651 effective words/s', 'datetime': '2023-02-07T18:46:48.592937', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:46:48.593 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:46:53,913][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184456-97k50v1a/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:46:53.912923', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:46:53,913][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:46:54,005][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184456-97k50v1a/files/../tmp/embedding_model.pt
2023-02-07 18:46:54.005 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:46:56.776 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:46:57.761 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:47:01.070 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1120779059330441, 'test_mae': 0.8141759404101254, 'test_r2': -3.8794923573995437}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.16
wandb: percentage 0.49351
wandb:   test_mae 0.81418
wandb:   test_mse 1.11208
wandb:    test_r2 -3.87949
wandb: 
wandb: üöÄ View run kind-sweep-17 at: https://wandb.ai/xiaoqiz/mof2vec/runs/97k50v1a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_184456-97k50v1a/logs
wandb: Agent Starting Run: n54p95eq with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 509
wandb: 	model.gensim.alpha: 0.0019619929023239942
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.5702703865823607
wandb: 	model.gensim.vector_size: 443
wandb: 	model.gensim.window: 20
wandb: 	model.sklearn.learning_rate: 0.0015791131289663149
wandb: 	model.sklearn.max_depth: 60
wandb: 	model.sklearn.min_child_weight: 0.032361107021452694
wandb: 	model.sklearn.n_estimators: 2433
wandb: 	model.sklearn.num_leaves: 346
wandb: 	model.sklearn.reg_alpha: 0.2115031479862376
wandb: 	model.sklearn.reg_lambda: 0.005131722312443118
wandb: 	model.sklearn.subsample: 0.3146562138388694
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184713-n54p95eq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-18
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/n54p95eq
2023-02-07 18:47:21.994 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 18:47:21.995 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 509 for sweep.
2023-02-07 18:47:21.995 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0019619929023239942 for sweep.
2023-02-07 18:47:21.995 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:47:21.995 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 18:47:21.996 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5702703865823607 for sweep.
2023-02-07 18:47:21.996 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 443 for sweep.
2023-02-07 18:47:21.996 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 20 for sweep.
2023-02-07 18:47:21.996 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0015791131289663149 for sweep.
2023-02-07 18:47:21.997 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 60 for sweep.
2023-02-07 18:47:21.997 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.032361107021452694 for sweep.
2023-02-07 18:47:21.997 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2433 for sweep.
2023-02-07 18:47:21.997 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 346 for sweep.
2023-02-07 18:47:21.997 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.2115031479862376 for sweep.
2023-02-07 18:47:21.998 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.005131722312443118 for sweep.
2023-02-07 18:47:21.998 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3146562138388694 for sweep.
2023-02-07 18:47:21.998 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:47:22.004 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184713-n54p95eq/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 509, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 443, 'window': 20, 'min_count': 3, 'dm': 1, 'sample': 0.5702703865823607, 'workers': 4, 'alpha': 0.0019619929023239942, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2433, 'max_depth': 60, 'num_leaves': 346, 'reg_alpha': 0.2115031479862376, 'reg_lambda': 0.005131722312443118, 'subsample': 0.3146562138388694, 'min_child_weight': 0.032361107021452694, 'n_jobs': 4, 'learning_rate': 0.0015791131289663149}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:19, 168.77it/s]  1%|          | 38/3257 [00:00<00:17, 185.24it/s]  2%|‚ñè         | 57/3257 [00:00<00:17, 180.36it/s]  2%|‚ñè         | 80/3257 [00:00<00:16, 198.24it/s]  3%|‚ñé         | 100/3257 [00:00<00:16, 192.10it/s]  4%|‚ñé         | 120/3257 [00:00<00:17, 182.89it/s]  4%|‚ñç         | 139/3257 [00:00<00:16, 184.69it/s]  5%|‚ñç         | 158/3257 [00:00<00:16, 183.80it/s]  5%|‚ñå         | 177/3257 [00:00<00:17, 178.49it/s]  6%|‚ñå         | 197/3257 [00:01<00:16, 183.69it/s]  7%|‚ñã         | 219/3257 [00:01<00:15, 191.18it/s]  7%|‚ñã         | 242/3257 [00:01<00:15, 200.73it/s]  8%|‚ñä         | 263/3257 [00:01<00:16, 186.91it/s]  9%|‚ñâ         | 287/3257 [00:01<00:15, 197.39it/s]  9%|‚ñâ         | 307/3257 [00:01<00:15, 195.46it/s] 10%|‚ñà         | 328/3257 [00:01<00:14, 196.44it/s] 11%|‚ñà         | 348/3257 [00:01<00:15, 185.18it/s] 11%|‚ñà‚ñè        | 369/3257 [00:01<00:15, 191.57it/s] 12%|‚ñà‚ñè        | 389/3257 [00:02<00:16, 178.51it/s] 13%|‚ñà‚ñé        | 410/3257 [00:02<00:15, 186.75it/s] 13%|‚ñà‚ñé        | 429/3257 [00:02<00:17, 163.25it/s] 14%|‚ñà‚ñé        | 447/3257 [00:02<00:17, 164.74it/s] 14%|‚ñà‚ñç        | 468/3257 [00:02<00:15, 175.87it/s] 15%|‚ñà‚ñç        | 487/3257 [00:02<00:16, 172.49it/s] 16%|‚ñà‚ñå        | 510/3257 [00:02<00:14, 184.46it/s] 16%|‚ñà‚ñå        | 529/3257 [00:02<00:15, 181.37it/s] 17%|‚ñà‚ñã        | 548/3257 [00:02<00:15, 180.12it/s] 17%|‚ñà‚ñã        | 567/3257 [00:03<00:15, 170.53it/s] 18%|‚ñà‚ñä        | 585/3257 [00:03<00:15, 167.13it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:15, 173.00it/s] 19%|‚ñà‚ñâ        | 622/3257 [00:03<00:15, 172.02it/s] 20%|‚ñà‚ñâ        | 643/3257 [00:03<00:14, 182.56it/s] 20%|‚ñà‚ñà        | 662/3257 [00:03<00:15, 167.20it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:14, 173.08it/s] 22%|‚ñà‚ñà‚ñè       | 702/3257 [00:03<00:14, 177.64it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:03<00:14, 179.20it/s] 23%|‚ñà‚ñà‚ñé       | 740/3257 [00:04<00:14, 168.19it/s] 23%|‚ñà‚ñà‚ñé       | 762/3257 [00:04<00:13, 181.97it/s] 24%|‚ñà‚ñà‚ñç       | 781/3257 [00:04<00:21, 114.43it/s] 25%|‚ñà‚ñà‚ñç       | 801/3257 [00:04<00:18, 131.03it/s] 25%|‚ñà‚ñà‚ñå       | 819/3257 [00:04<00:17, 141.13it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:04<00:16, 143.90it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:04<00:16, 144.26it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:05<00:15, 152.55it/s] 27%|‚ñà‚ñà‚ñã       | 888/3257 [00:05<00:15, 156.58it/s] 28%|‚ñà‚ñà‚ñä       | 908/3257 [00:05<00:13, 167.79it/s] 29%|‚ñà‚ñà‚ñä       | 929/3257 [00:05<00:13, 177.86it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:05<00:13, 174.82it/s] 30%|‚ñà‚ñà‚ñâ       | 969/3257 [00:05<00:12, 183.11it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:05<00:12, 177.17it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:05<00:12, 173.93it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:05<00:12, 173.67it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1045/3257 [00:06<00:12, 172.32it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1065/3257 [00:06<00:12, 177.92it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1083/3257 [00:06<00:12, 173.99it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1103/3257 [00:06<00:12, 178.95it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1121/3257 [00:06<00:12, 174.57it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:06<00:12, 174.84it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1158/3257 [00:06<00:11, 177.84it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1176/3257 [00:06<00:11, 177.78it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:06<00:12, 163.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1211/3257 [00:07<00:12, 162.32it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:07<00:11, 177.24it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1251/3257 [00:07<00:11, 175.94it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:07<00:10, 182.27it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:07<00:11, 171.23it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:07<00:11, 174.73it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1331/3257 [00:07<00:10, 185.49it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:07<00:10, 178.50it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1368/3257 [00:07<00:10, 174.36it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:08<00:11, 162.72it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1405/3257 [00:08<00:10, 169.15it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1424/3257 [00:08<00:10, 174.23it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1442/3257 [00:08<00:10, 173.01it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:08<00:09, 182.98it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1482/3257 [00:08<00:09, 182.74it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1503/3257 [00:08<00:09, 187.93it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1522/3257 [00:08<00:10, 170.10it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1540/3257 [00:08<00:10, 163.85it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1557/3257 [00:09<00:10, 156.37it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:09<00:10, 159.19it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:09<00:10, 157.87it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1609/3257 [00:09<00:10, 163.78it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1627/3257 [00:09<00:09, 167.87it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1644/3257 [00:09<00:10, 153.47it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:09<00:10, 150.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:09<00:10, 149.53it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1693/3257 [00:09<00:10, 149.86it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1711/3257 [00:09<00:09, 157.95it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:10<00:10, 148.72it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:10<00:10, 143.92it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:10<00:09, 154.84it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1780/3257 [00:10<00:09, 158.81it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1797/3257 [00:10<00:09, 161.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:10<00:09, 157.93it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1830/3257 [00:10<00:09, 155.24it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:10<00:08, 162.05it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:10<00:08, 166.13it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1886/3257 [00:11<00:08, 164.50it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1904/3257 [00:11<00:08, 166.96it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1921/3257 [00:11<00:08, 161.53it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1944/3257 [00:11<00:07, 179.22it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:11<00:06, 184.70it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1984/3257 [00:11<00:07, 171.10it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:11<00:07, 174.39it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2023/3257 [00:11<00:06, 176.56it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2041/3257 [00:12<00:13, 90.41it/s]  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2056/3257 [00:12<00:12, 99.64it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2073/3257 [00:12<00:10, 112.55it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2089/3257 [00:12<00:09, 122.49it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2105/3257 [00:12<00:08, 131.22it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:12<00:08, 130.28it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2138/3257 [00:12<00:08, 139.83it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:13<00:07, 142.75it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2173/3257 [00:13<00:07, 154.32it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2190/3257 [00:13<00:06, 153.97it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2207/3257 [00:13<00:06, 157.44it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2224/3257 [00:13<00:06, 157.15it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2240/3257 [00:13<00:06, 152.36it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:13<00:06, 160.27it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:13<00:06, 148.19it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2297/3257 [00:13<00:05, 164.72it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:14<00:05, 164.49it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:14<00:05, 179.12it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:14<00:04, 188.27it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2380/3257 [00:14<00:04, 189.26it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2400/3257 [00:14<00:04, 189.56it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2420/3257 [00:14<00:04, 178.01it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2439/3257 [00:14<00:04, 168.92it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2457/3257 [00:14<00:04, 167.23it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:14<00:04, 171.23it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2496/3257 [00:15<00:04, 176.96it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2517/3257 [00:15<00:04, 183.75it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2537/3257 [00:15<00:03, 186.53it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2556/3257 [00:15<00:04, 172.93it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2574/3257 [00:15<00:04, 161.14it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2591/3257 [00:15<00:04, 157.74it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:15<00:03, 176.14it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:15<00:03, 180.98it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2653/3257 [00:15<00:03, 171.23it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2671/3257 [00:16<00:03, 171.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2689/3257 [00:16<00:03, 172.91it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2707/3257 [00:16<00:03, 154.01it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2727/3257 [00:16<00:03, 165.43it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2751/3257 [00:16<00:02, 183.63it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2770/3257 [00:16<00:02, 181.32it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:16<00:02, 199.80it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2816/3257 [00:16<00:02, 194.11it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2836/3257 [00:16<00:02, 187.72it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2861/3257 [00:17<00:01, 203.85it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:17<00:01, 214.27it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2908/3257 [00:17<00:01, 204.12it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2930/3257 [00:17<00:01, 204.40it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2951/3257 [00:17<00:01, 194.83it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2974/3257 [00:17<00:01, 201.81it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2995/3257 [00:17<00:01, 193.20it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:17<00:01, 198.71it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3042/3257 [00:17<00:01, 209.53it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3068/3257 [00:18<00:00, 222.06it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3091/3257 [00:18<00:00, 223.44it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:18<00:00, 236.34it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3142/3257 [00:18<00:00, 228.68it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:18<00:00, 218.04it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3188/3257 [00:18<00:00, 211.29it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3210/3257 [00:18<00:00, 211.58it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3232/3257 [00:18<00:00, 212.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3254/3257 [00:18<00:00, 211.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 172.23it/s]
2023-02-07 18:47:41.644 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:47:41,646][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d443,n5,w20,mc3,s0.57027,t4>', 'datetime': '2023-02-07T18:47:41.646300', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:47:41,646][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:47:41,646][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:47:42,168][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 18:47:42,169][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:47:42,245][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 30516 unique words (71.46% of original 42701, drops 12185)', 'datetime': '2023-02-07T18:47:42.245656', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:47:42,245][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 5804704 word corpus (99.69% of original 5822992, drops 18288)', 'datetime': '2023-02-07T18:47:42.245972', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:47:42,347][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 18:47:42,348][gensim.models.word2vec][INFO] - sample=0.57027 downsamples 0 most-common words
[2023-02-07 18:47:42,348][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5804704 word corpus (100.0%% of prior 5804704)', 'datetime': '2023-02-07T18:47:42.348354', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:47:42,522][gensim.models.word2vec][INFO] - estimated required memory for 30516 words and 443 dimensions: 129829508 bytes
[2023-02-07 18:47:42,522][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:47:42,579][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 30516 vocabulary and 443 features, using sg=0 hs=0 sample=0.5702703865823607 negative=5 window=20 shrink_windows=True', 'datetime': '2023-02-07T18:47:42.579623', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:47:43,588][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 11.82% examples, 642430 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:44,595][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 23.03% examples, 657190 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:45,604][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 34.45% examples, 666523 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:46,607][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 46.15% examples, 673011 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:47,610][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 57.78% examples, 678199 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:48,611][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 69.70% examples, 683295 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:49,626][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 82.71% examples, 684471 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:47:50,633][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 95.64% examples, 686813 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:50,978][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5778362 effective words) took 8.4s, 688165 effective words/s
[2023-02-07 18:47:51,987][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 12.90% examples, 706163 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:47:52,992][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 25.15% examples, 717336 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:54,009][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 36.48% examples, 709810 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:47:55,050][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 49.09% examples, 711617 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:56,066][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 61.71% examples, 711929 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:57,076][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 74.36% examples, 714795 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:58,086][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 87.07% examples, 715125 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:47:59,092][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 100.00% examples, 712391 words/s, in_qsize 0, out_qsize 1
[2023-02-07 18:47:59,092][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5778362 effective words) took 8.1s, 712346 effective words/s
[2023-02-07 18:48:00,101][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 12.90% examples, 705409 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:01,102][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 24.81% examples, 709654 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:02,127][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 36.48% examples, 708797 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:03,143][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 49.09% examples, 715194 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:04,166][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 61.71% examples, 713738 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:05,178][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 74.52% examples, 717278 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:06,180][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 87.26% examples, 718389 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:07,129][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5778362 effective words) took 8.0s, 719114 effective words/s
[2023-02-07 18:48:08,138][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 13.05% examples, 724175 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:09,142][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 25.15% examples, 717263 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:10,146][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 36.44% examples, 711500 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:11,147][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 47.90% examples, 703911 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:12,156][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 59.69% examples, 698745 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:13,169][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 71.51% examples, 697355 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:14,196][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 84.22% examples, 695166 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:15,203][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 96.56% examples, 692254 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:15,468][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5778362 effective words) took 8.3s, 693023 effective words/s
[2023-02-07 18:48:16,476][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 12.04% examples, 661626 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:17,477][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 23.37% examples, 667555 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:18,484][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 35.22% examples, 686509 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:19,515][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 49.09% examples, 716163 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:20,534][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 62.85% examples, 729012 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:21,547][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 76.94% examples, 739807 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:22,548][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 90.76% examples, 746776 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:23,281][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5778362 effective words) took 7.8s, 739878 effective words/s
[2023-02-07 18:48:24,296][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 12.62% examples, 685141 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:25,310][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 24.50% examples, 694966 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:26,312][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 37.12% examples, 725911 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:27,322][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 50.38% examples, 734425 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:28,326][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 63.00% examples, 733915 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:29,326][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 75.90% examples, 735328 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:30,329][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 88.67% examples, 732271 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:31,257][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5778362 effective words) took 8.0s, 724692 effective words/s
[2023-02-07 18:48:32,296][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 12.04% examples, 642073 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:33,308][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 23.61% examples, 658418 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:34,309][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 36.26% examples, 697770 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:35,311][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 48.97% examples, 712904 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:36,334][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 61.74% examples, 713653 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:37,341][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 74.64% examples, 720471 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:38,357][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 86.92% examples, 713283 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:39,360][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 98.89% examples, 706846 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:39,419][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5778362 effective words) took 8.2s, 708272 effective words/s
[2023-02-07 18:48:40,440][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 12.07% examples, 653660 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:48:41,442][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 25.18% examples, 715302 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:42,469][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 36.97% examples, 717964 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:43,483][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 50.17% examples, 727735 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:44,489][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 62.70% examples, 724535 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:45,493][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 73.99% examples, 714390 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:46,495][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 86.00% examples, 707695 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:47,495][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 98.62% examples, 706763 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:47,579][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5778362 effective words) took 8.2s, 708320 effective words/s
[2023-02-07 18:48:48,581][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 13.63% examples, 772048 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:49,584][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 25.85% examples, 748043 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:50,598][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 37.58% examples, 737165 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:51,601][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 49.09% examples, 720339 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:52,624][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 61.01% examples, 710429 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:48:53,633][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 72.77% examples, 705319 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:54,640][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 86.95% examples, 718392 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:55,577][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5778362 effective words) took 8.0s, 722609 effective words/s
[2023-02-07 18:48:56,591][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 13.11% examples, 730054 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:57,602][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 25.58% examples, 728737 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:58,638][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 37.58% examples, 727241 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:48:59,651][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 50.38% examples, 728268 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:00,651][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 63.00% examples, 729463 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:01,655][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 75.47% examples, 728516 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:02,663][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 89.01% examples, 730779 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:03,497][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5778362 effective words) took 7.9s, 729787 effective words/s
[2023-02-07 18:49:04,507][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 13.02% examples, 713401 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:05,520][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 25.30% examples, 721330 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:06,522][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 37.09% examples, 726930 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:07,528][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 50.02% examples, 728892 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:49:08,537][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 62.94% examples, 734226 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:09,543][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 75.99% examples, 736477 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:10,554][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 88.00% examples, 725676 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:11,527][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5778362 effective words) took 8.0s, 719705 effective words/s
[2023-02-07 18:49:12,555][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 12.07% examples, 650516 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:13,567][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 23.70% examples, 666665 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:14,583][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 34.85% examples, 668662 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:15,597][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 46.45% examples, 670421 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:16,611][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 57.48% examples, 667879 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:17,624][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 69.17% examples, 669908 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:18,626][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 82.81% examples, 680450 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:19,629][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 97.08% examples, 693430 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:19,856][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5778362 effective words) took 8.3s, 694089 effective words/s
[2023-02-07 18:49:20,862][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 13.02% examples, 716580 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:21,869][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 25.15% examples, 717595 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:22,876][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 36.72% examples, 718959 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:23,882][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 49.09% examples, 719700 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:24,884][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 61.93% examples, 722196 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:25,886][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 74.58% examples, 725193 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:26,894][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 87.50% examples, 724901 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:27,824][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5778362 effective words) took 8.0s, 725337 effective words/s
[2023-02-07 18:49:28,833][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 13.11% examples, 733790 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:29,843][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 25.30% examples, 723090 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:30,843][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 36.97% examples, 725397 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:31,844][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 50.17% examples, 735903 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:32,844][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 62.54% examples, 729866 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:33,846][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 74.03% examples, 720804 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:34,866][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 86.25% examples, 713545 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:35,875][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 98.34% examples, 706749 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:35,990][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5778362 effective words) took 8.2s, 707813 effective words/s
[2023-02-07 18:49:37,033][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 12.07% examples, 640549 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:38,043][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 23.61% examples, 657690 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:39,054][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 34.57% examples, 660911 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:40,055][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 46.12% examples, 666372 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:49:41,055][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 57.35% examples, 668347 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:42,066][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 70.62% examples, 686984 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:43,070][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 84.59% examples, 696604 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:44,075][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 97.67% examples, 699900 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:49:44,232][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5778362 effective words) took 8.2s, 701277 effective words/s
[2023-02-07 18:49:44,233][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86675430 effective words) took 121.7s, 712480 effective words/s', 'datetime': '2023-02-07T18:49:44.233178', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:49:44.233 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:49:52,134][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184713-n54p95eq/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:49:52.134442', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:49:52,135][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184713-n54p95eq/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 18:49:52,186][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184713-n54p95eq/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 18:49:52,231][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:49:52,266][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_184713-n54p95eq/files/../tmp/embedding_model.pt
2023-02-07 18:49:52.267 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:49:54.796 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:49:55.696 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:49:58.807 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1581924611352794, 'test_mae': 0.8218800992779205, 'test_r2': -3.399449406403158}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.23
wandb: percentage 0.28536
wandb:   test_mae 0.82188
wandb:   test_mse 1.15819
wandb:    test_r2 -3.39945
wandb: 
wandb: üöÄ View run devoted-sweep-18 at: https://wandb.ai/xiaoqiz/mof2vec/runs/n54p95eq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_184713-n54p95eq/logs
wandb: Agent Starting Run: 3k6zpk9b with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 246
wandb: 	model.gensim.alpha: 0.0004652554685540976
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.25303980251680347
wandb: 	model.gensim.vector_size: 466
wandb: 	model.gensim.window: 15
wandb: 	model.sklearn.learning_rate: 0.0006745063378684561
wandb: 	model.sklearn.max_depth: 89
wandb: 	model.sklearn.min_child_weight: 0.002197368989492309
wandb: 	model.sklearn.n_estimators: 4219
wandb: 	model.sklearn.num_leaves: 385
wandb: 	model.sklearn.reg_alpha: 0.07290870342885343
wandb: 	model.sklearn.reg_lambda: 0.003857559333956664
wandb: 	model.sklearn.subsample: 0.8712600666373278
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185012-3k6zpk9b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/3k6zpk9b
2023-02-07 18:50:20.471 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 18:50:20.472 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 246 for sweep.
2023-02-07 18:50:20.472 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0004652554685540976 for sweep.
2023-02-07 18:50:20.473 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:50:20.473 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 18:50:20.473 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.25303980251680347 for sweep.
2023-02-07 18:50:20.473 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 466 for sweep.
2023-02-07 18:50:20.474 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 15 for sweep.
2023-02-07 18:50:20.474 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0006745063378684561 for sweep.
2023-02-07 18:50:20.474 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 89 for sweep.
2023-02-07 18:50:20.474 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.002197368989492309 for sweep.
2023-02-07 18:50:20.475 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4219 for sweep.
2023-02-07 18:50:20.475 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 385 for sweep.
2023-02-07 18:50:20.475 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.07290870342885343 for sweep.
2023-02-07 18:50:20.475 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.003857559333956664 for sweep.
2023-02-07 18:50:20.476 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8712600666373278 for sweep.
2023-02-07 18:50:20.476 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:50:20.482 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185012-3k6zpk9b/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 246, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 466, 'window': 15, 'min_count': 8, 'dm': 1, 'sample': 0.25303980251680347, 'workers': 4, 'alpha': 0.0004652554685540976, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4219, 'max_depth': 89, 'num_leaves': 385, 'reg_alpha': 0.07290870342885343, 'reg_lambda': 0.003857559333956664, 'subsample': 0.8712600666373278, 'min_child_weight': 0.002197368989492309, 'n_jobs': 4, 'learning_rate': 0.0006745063378684561}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 4/3257 [00:00<02:57, 18.31it/s]  1%|          | 25/3257 [00:00<00:34, 93.23it/s]  1%|‚ñè         | 42/3257 [00:00<00:27, 118.62it/s]  2%|‚ñè         | 61/3257 [00:00<00:22, 141.10it/s]  3%|‚ñé         | 82/3257 [00:00<00:19, 161.71it/s]  3%|‚ñé         | 100/3257 [00:00<00:18, 166.66it/s]  4%|‚ñé         | 118/3257 [00:00<00:18, 167.91it/s]  4%|‚ñç         | 138/3257 [00:00<00:17, 176.91it/s]  5%|‚ñç         | 158/3257 [00:01<00:17, 179.70it/s]  5%|‚ñå         | 177/3257 [00:01<00:17, 176.93it/s]  6%|‚ñå         | 197/3257 [00:01<00:16, 181.82it/s]  7%|‚ñã         | 218/3257 [00:01<00:16, 189.52it/s]  7%|‚ñã         | 243/3257 [00:01<00:14, 207.19it/s]  8%|‚ñä         | 270/3257 [00:01<00:13, 225.29it/s]  9%|‚ñâ         | 303/3257 [00:01<00:11, 256.01it/s] 10%|‚ñà         | 333/3257 [00:01<00:10, 268.01it/s] 11%|‚ñà         | 361/3257 [00:01<00:10, 270.47it/s] 12%|‚ñà‚ñè        | 389/3257 [00:01<00:11, 256.73it/s] 13%|‚ñà‚ñé        | 419/3257 [00:02<00:10, 268.99it/s] 14%|‚ñà‚ñé        | 447/3257 [00:02<00:11, 243.77it/s] 15%|‚ñà‚ñç        | 476/3257 [00:02<00:10, 253.60it/s] 16%|‚ñà‚ñå        | 505/3257 [00:02<00:10, 263.31it/s] 16%|‚ñà‚ñã        | 532/3257 [00:02<00:10, 258.48it/s] 17%|‚ñà‚ñã        | 559/3257 [00:02<00:10, 252.34it/s] 18%|‚ñà‚ñä        | 585/3257 [00:02<00:10, 248.73it/s] 19%|‚ñà‚ñâ        | 614/3257 [00:02<00:10, 259.01it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:02<00:10, 250.98it/s] 20%|‚ñà‚ñà        | 667/3257 [00:03<00:10, 241.06it/s] 21%|‚ñà‚ñà        | 692/3257 [00:03<00:10, 238.87it/s] 22%|‚ñà‚ñà‚ñè       | 719/3257 [00:03<00:10, 245.92it/s] 23%|‚ñà‚ñà‚ñé       | 744/3257 [00:03<00:11, 227.06it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:03<00:10, 235.72it/s] 24%|‚ñà‚ñà‚ñç       | 794/3257 [00:03<00:10, 234.13it/s] 25%|‚ñà‚ñà‚ñå       | 818/3257 [00:03<00:10, 234.39it/s] 26%|‚ñà‚ñà‚ñå       | 842/3257 [00:03<00:11, 218.78it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:03<00:10, 223.02it/s] 27%|‚ñà‚ñà‚ñã       | 889/3257 [00:04<00:10, 219.84it/s] 28%|‚ñà‚ñà‚ñä       | 913/3257 [00:04<00:10, 224.86it/s] 29%|‚ñà‚ñà‚ñä       | 936/3257 [00:04<00:10, 223.09it/s] 30%|‚ñà‚ñà‚ñâ       | 965/3257 [00:04<00:09, 240.84it/s] 30%|‚ñà‚ñà‚ñà       | 990/3257 [00:04<00:09, 233.44it/s] 31%|‚ñà‚ñà‚ñà       | 1014/3257 [00:04<00:09, 227.37it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1037/3257 [00:04<00:09, 223.62it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1060/3257 [00:04<00:09, 222.93it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1084/3257 [00:04<00:09, 226.71it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1110/3257 [00:05<00:09, 236.02it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1134/3257 [00:05<00:09, 229.61it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1158/3257 [00:05<00:09, 232.14it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1182/3257 [00:05<00:09, 225.75it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:05<00:14, 145.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:05<00:11, 170.10it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1255/3257 [00:05<00:10, 183.54it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1278/3257 [00:05<00:10, 192.30it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1301/3257 [00:06<00:09, 200.76it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1327/3257 [00:06<00:08, 216.36it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:06<00:08, 215.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1373/3257 [00:06<00:08, 217.38it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1397/3257 [00:06<00:08, 223.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1425/3257 [00:06<00:07, 237.50it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:06<00:07, 245.10it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1480/3257 [00:06<00:06, 254.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1509/3257 [00:06<00:06, 262.99it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1536/3257 [00:07<00:07, 238.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1561/3257 [00:07<00:07, 234.08it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1585/3257 [00:07<00:07, 231.02it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1612/3257 [00:07<00:06, 239.81it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1637/3257 [00:07<00:07, 229.97it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:07<00:07, 217.72it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1684/3257 [00:07<00:07, 218.05it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:07<00:06, 223.83it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:07<00:06, 219.04it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1755/3257 [00:08<00:06, 223.77it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1783/3257 [00:08<00:06, 239.34it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1808/3257 [00:08<00:06, 230.17it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1833/3257 [00:08<00:06, 235.06it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1860/3257 [00:08<00:05, 244.62it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1886/3257 [00:08<00:05, 247.97it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1914/3257 [00:08<00:05, 256.26it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1940/3257 [00:08<00:05, 254.17it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1969/3257 [00:08<00:04, 263.95it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1996/3257 [00:08<00:04, 254.34it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:09<00:04, 248.10it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2047/3257 [00:09<00:05, 234.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2071/3257 [00:09<00:05, 224.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2096/3257 [00:09<00:05, 225.76it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:09<00:05, 224.16it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:09<00:05, 217.25it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:09<00:04, 227.06it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2193/3257 [00:09<00:04, 228.24it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2216/3257 [00:09<00:04, 227.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2239/3257 [00:10<00:04, 222.86it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2266/3257 [00:10<00:04, 233.41it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2291/3257 [00:10<00:04, 234.03it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2317/3257 [00:10<00:03, 240.75it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2348/3257 [00:10<00:03, 259.38it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2375/3257 [00:10<00:03, 258.21it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2405/3257 [00:10<00:03, 259.27it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2431/3257 [00:10<00:03, 249.28it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2456/3257 [00:11<00:05, 156.28it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2485/3257 [00:11<00:04, 182.15it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2517/3257 [00:11<00:03, 211.37it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2544/3257 [00:11<00:03, 225.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2570/3257 [00:11<00:03, 225.02it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2595/3257 [00:11<00:02, 228.57it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2630/3257 [00:11<00:02, 260.10it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2658/3257 [00:11<00:02, 247.69it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2684/3257 [00:11<00:02, 246.38it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2710/3257 [00:12<00:02, 214.35it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2733/3257 [00:12<00:02, 214.02it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:12<00:02, 213.77it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2778/3257 [00:12<00:02, 206.43it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:12<00:02, 217.67it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2826/3257 [00:12<00:02, 206.69it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2848/3257 [00:12<00:01, 207.89it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2874/3257 [00:12<00:01, 221.63it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2897/3257 [00:13<00:01, 206.92it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:13<00:01, 212.94it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2942/3257 [00:13<00:01, 214.76it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2964/3257 [00:13<00:01, 204.78it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:13<00:01, 199.23it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:13<00:01, 214.13it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3033/3257 [00:13<00:01, 212.46it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3058/3257 [00:13<00:00, 222.47it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:13<00:00, 226.99it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3106/3257 [00:13<00:00, 229.71it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3130/3257 [00:14<00:00, 230.00it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3154/3257 [00:14<00:00, 217.29it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3176/3257 [00:14<00:00, 215.94it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3198/3257 [00:14<00:00, 214.08it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3220/3257 [00:14<00:00, 207.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3246/3257 [00:14<00:00, 220.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:14<00:00, 221.80it/s]
2023-02-07 18:50:35.714 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:50:35,716][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d466,n5,w15,mc8,s0.25304,t4>', 'datetime': '2023-02-07T18:50:35.716115', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:50:35,716][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:50:35,716][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:50:36,080][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 18:50:36,081][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:50:36,101][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 5936 unique words (45.45% of original 13061, drops 7125)', 'datetime': '2023-02-07T18:50:36.101002', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:50:36,101][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 3618620 word corpus (99.43% of original 3639370, drops 20750)', 'datetime': '2023-02-07T18:50:36.101437', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:50:36,122][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 18:50:36,124][gensim.models.word2vec][INFO] - sample=0.25304 downsamples 0 most-common words
[2023-02-07 18:50:36,125][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3618620 word corpus (100.0%% of prior 3618620)', 'datetime': '2023-02-07T18:50:36.125310', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:50:36,161][gensim.models.word2vec][INFO] - estimated required memory for 5936 words and 466 dimensions: 31819856 bytes
[2023-02-07 18:50:36,162][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:50:36,182][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 5936 vocabulary and 466 features, using sg=0 hs=0 sample=0.25303980251680347 negative=5 window=15 shrink_windows=True', 'datetime': '2023-02-07T18:50:36.182384', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:50:37,188][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 19.01% examples, 667666 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:50:38,198][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 36.97% examples, 683457 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:39,213][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 56.43% examples, 693182 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:50:40,215][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 77.22% examples, 702001 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:41,220][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 99.17% examples, 714123 words/s, in_qsize 3, out_qsize 1
[2023-02-07 18:50:41,249][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3621877 effective words) took 5.1s, 715399 effective words/s
[2023-02-07 18:50:42,264][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 22.90% examples, 814412 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:43,297][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 43.94% examples, 796751 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:50:44,308][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 65.92% examples, 798987 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:50:45,315][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 88.61% examples, 793133 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:45,817][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3621877 effective words) took 4.6s, 793039 effective words/s
[2023-02-07 18:50:46,820][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 21.52% examples, 770744 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:50:47,824][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 41.73% examples, 776674 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:48,835][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 63.83% examples, 781607 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:50:49,836][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 86.52% examples, 787084 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:50,395][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3621877 effective words) took 4.6s, 791444 effective words/s
[2023-02-07 18:50:51,407][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 22.20% examples, 789885 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:50:52,412][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 42.03% examples, 777423 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:53,426][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 63.00% examples, 765862 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:54,429][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 84.28% examples, 764005 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:50:55,136][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3621877 effective words) took 4.7s, 764274 effective words/s
[2023-02-07 18:50:56,140][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 20.20% examples, 723070 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:50:57,155][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 40.13% examples, 742180 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:50:58,176][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 61.59% examples, 747094 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:50:59,193][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 83.11% examples, 750494 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:50:59,949][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3621877 effective words) took 4.8s, 753009 effective words/s
[2023-02-07 18:51:00,979][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 22.90% examples, 803565 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:01,982][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 45.32% examples, 825277 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:03,005][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 66.93% examples, 810893 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:04,016][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 90.02% examples, 807030 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:04,431][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3621877 effective words) took 4.5s, 808500 effective words/s
[2023-02-07 18:51:05,446][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 22.20% examples, 787467 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:06,455][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 43.66% examples, 801775 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:07,456][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 65.34% examples, 798967 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:08,459][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 88.79% examples, 803072 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:08,942][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3621877 effective words) took 4.5s, 803147 effective words/s
[2023-02-07 18:51:09,945][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 21.71% examples, 778247 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:10,949][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 42.22% examples, 785730 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:11,954][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 63.68% examples, 780202 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:12,970][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 85.20% examples, 774272 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:13,627][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3621877 effective words) took 4.7s, 773417 effective words/s
[2023-02-07 18:51:14,631][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 21.31% examples, 761361 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:15,640][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 40.96% examples, 758541 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:16,654][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 62.82% examples, 764047 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:17,676][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 84.07% examples, 761322 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:18,387][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3621877 effective words) took 4.8s, 761328 effective words/s
[2023-02-07 18:51:19,391][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 21.52% examples, 770464 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:20,396][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 44.80% examples, 825907 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:21,398][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 66.93% examples, 823047 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:22,404][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 89.65% examples, 814598 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:22,840][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3621877 effective words) took 4.5s, 813686 effective words/s
[2023-02-07 18:51:23,861][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 22.35% examples, 791115 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:24,871][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 43.32% examples, 794156 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:25,872][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 65.77% examples, 803127 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:26,883][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 88.79% examples, 800152 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:27,352][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3621877 effective words) took 4.5s, 803109 effective words/s
[2023-02-07 18:51:28,361][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 22.20% examples, 791863 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:29,380][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 42.65% examples, 787363 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:30,388][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 63.92% examples, 776846 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:31,391][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 86.15% examples, 778627 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:32,021][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3621877 effective words) took 4.7s, 775959 effective words/s
[2023-02-07 18:51:33,025][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 20.97% examples, 751956 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:34,041][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 41.08% examples, 759329 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:51:35,046][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 62.82% examples, 764592 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:36,061][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 83.88% examples, 760513 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:36,781][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3621877 effective words) took 4.8s, 761276 effective words/s
[2023-02-07 18:51:37,783][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 20.97% examples, 752929 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:38,784][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 43.66% examples, 810092 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:39,786][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 65.55% examples, 807417 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:51:40,791][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 88.92% examples, 809038 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:41,253][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3621877 effective words) took 4.5s, 810243 effective words/s
[2023-02-07 18:51:42,261][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 22.08% examples, 783763 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:43,268][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 43.02% examples, 796662 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:44,287][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 65.70% examples, 802761 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:45,305][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 89.87% examples, 807543 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:51:45,749][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3621877 effective words) took 4.5s, 805906 effective words/s
[2023-02-07 18:51:45,749][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54328155 effective words) took 69.6s, 780966 effective words/s', 'datetime': '2023-02-07T18:51:45.749469', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:51:45.750 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:51:49,932][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185012-3k6zpk9b/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:51:49.932643', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:51:49,933][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:51:49,980][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185012-3k6zpk9b/files/../tmp/embedding_model.pt
2023-02-07 18:51:49.980 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:51:52.679 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:51:53.629 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:51:56.626 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1489767768116563, 'test_mae': 0.808810607101654, 'test_r2': -2.9859324174639865}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.034 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.16
wandb: percentage 0.54552
wandb:   test_mae 0.80881
wandb:   test_mse 1.14898
wandb:    test_r2 -2.98593
wandb: 
wandb: üöÄ View run comfy-sweep-19 at: https://wandb.ai/xiaoqiz/mof2vec/runs/3k6zpk9b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_185012-3k6zpk9b/logs
wandb: Agent Starting Run: tnll22z5 with config:
wandb: 	data.data.wl_step: 3
wandb: 	data.nn.batch_size: 587
wandb: 	model.gensim.alpha: 0.054677632596810896
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.5279538559942952
wandb: 	model.gensim.vector_size: 501
wandb: 	model.gensim.window: 16
wandb: 	model.sklearn.learning_rate: 0.002086279994642842
wandb: 	model.sklearn.max_depth: 75
wandb: 	model.sklearn.min_child_weight: 0.04601410549461697
wandb: 	model.sklearn.n_estimators: 1300
wandb: 	model.sklearn.num_leaves: 378
wandb: 	model.sklearn.reg_alpha: 0.07928426391692926
wandb: 	model.sklearn.reg_lambda: 0.0029606338978586185
wandb: 	model.sklearn.subsample: 0.6739642180729001
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185207-tnll22z5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/tnll22z5
2023-02-07 18:52:15.500 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 3 for sweep.
2023-02-07 18:52:15.500 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 587 for sweep.
2023-02-07 18:52:15.501 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.054677632596810896 for sweep.
2023-02-07 18:52:15.501 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:52:15.502 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 18:52:15.502 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5279538559942952 for sweep.
2023-02-07 18:52:15.502 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 501 for sweep.
2023-02-07 18:52:15.503 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 16 for sweep.
2023-02-07 18:52:15.503 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.002086279994642842 for sweep.
2023-02-07 18:52:15.503 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 75 for sweep.
2023-02-07 18:52:15.503 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.04601410549461697 for sweep.
2023-02-07 18:52:15.504 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1300 for sweep.
2023-02-07 18:52:15.504 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 378 for sweep.
2023-02-07 18:52:15.504 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.07928426391692926 for sweep.
2023-02-07 18:52:15.504 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0029606338978586185 for sweep.
2023-02-07 18:52:15.504 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6739642180729001 for sweep.
2023-02-07 18:52:15.505 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:52:15.510 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 3}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185207-tnll22z5/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 587, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 501, 'window': 16, 'min_count': 3, 'dm': 1, 'sample': 0.5279538559942952, 'workers': 4, 'alpha': 0.054677632596810896, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1300, 'max_depth': 75, 'num_leaves': 378, 'reg_alpha': 0.07928426391692926, 'reg_lambda': 0.0029606338978586185, 'subsample': 0.6739642180729001, 'min_child_weight': 0.04601410549461697, 'n_jobs': 4, 'learning_rate': 0.002086279994642842}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 21/3257 [00:00<00:15, 208.93it/s]  1%|‚ñè         | 42/3257 [00:00<00:15, 202.95it/s]  2%|‚ñè         | 68/3257 [00:00<00:14, 227.24it/s]  3%|‚ñé         | 97/3257 [00:00<00:12, 249.77it/s]  4%|‚ñç         | 123/3257 [00:00<00:12, 250.95it/s]  5%|‚ñç         | 153/3257 [00:00<00:11, 266.13it/s]  6%|‚ñå         | 180/3257 [00:00<00:11, 262.41it/s]  6%|‚ñã         | 211/3257 [00:00<00:11, 276.91it/s]  7%|‚ñã         | 244/3257 [00:00<00:10, 292.64it/s]  8%|‚ñä         | 274/3257 [00:01<00:10, 293.39it/s]  9%|‚ñâ         | 305/3257 [00:01<00:09, 297.70it/s] 10%|‚ñà         | 335/3257 [00:01<00:09, 296.66it/s] 11%|‚ñà         | 365/3257 [00:01<00:09, 296.97it/s] 12%|‚ñà‚ñè        | 395/3257 [00:01<00:10, 281.91it/s] 13%|‚ñà‚ñé        | 424/3257 [00:01<00:10, 281.45it/s] 14%|‚ñà‚ñç        | 453/3257 [00:01<00:10, 264.05it/s] 15%|‚ñà‚ñç        | 480/3257 [00:01<00:14, 192.25it/s] 16%|‚ñà‚ñå        | 512/3257 [00:02<00:12, 219.28it/s] 17%|‚ñà‚ñã        | 539/3257 [00:02<00:11, 230.98it/s] 17%|‚ñà‚ñã        | 565/3257 [00:02<00:11, 232.84it/s] 18%|‚ñà‚ñä        | 590/3257 [00:02<00:11, 237.18it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:02<00:10, 244.89it/s] 20%|‚ñà‚ñâ        | 646/3257 [00:02<00:10, 246.36it/s] 21%|‚ñà‚ñà        | 673/3257 [00:02<00:10, 251.85it/s] 21%|‚ñà‚ñà‚ñè       | 699/3257 [00:02<00:10, 248.08it/s] 22%|‚ñà‚ñà‚ñè       | 726/3257 [00:02<00:10, 251.47it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:02<00:09, 257.43it/s] 24%|‚ñà‚ñà‚ñç       | 780/3257 [00:03<00:09, 258.15it/s] 25%|‚ñà‚ñà‚ñç       | 809/3257 [00:03<00:09, 265.05it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:03<00:09, 255.55it/s] 26%|‚ñà‚ñà‚ñã       | 862/3257 [00:03<00:09, 256.75it/s] 27%|‚ñà‚ñà‚ñã       | 889/3257 [00:03<00:09, 259.23it/s] 28%|‚ñà‚ñà‚ñä       | 919/3257 [00:03<00:08, 270.55it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:03<00:08, 276.25it/s] 30%|‚ñà‚ñà‚ñà       | 979/3257 [00:03<00:08, 278.75it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:03<00:08, 268.92it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1034/3257 [00:04<00:08, 257.84it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1060/3257 [00:04<00:08, 256.22it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:04<00:08, 259.15it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:04<00:08, 262.42it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:04<00:08, 258.10it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:04<00:07, 265.31it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1200/3257 [00:04<00:08, 249.33it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1229/3257 [00:04<00:07, 260.33it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1256/3257 [00:04<00:07, 259.31it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1283/3257 [00:04<00:07, 252.53it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:05<00:07, 251.29it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:05<00:07, 264.96it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1366/3257 [00:05<00:07, 261.00it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1393/3257 [00:05<00:07, 259.40it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1425/3257 [00:05<00:06, 275.56it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1455/3257 [00:05<00:06, 282.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1484/3257 [00:05<00:06, 283.78it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1516/3257 [00:05<00:05, 292.08it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:05<00:06, 270.31it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:06<00:06, 271.47it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1606/3257 [00:06<00:05, 279.17it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:06<00:05, 276.47it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1663/3257 [00:06<00:05, 269.84it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:06<00:05, 263.14it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1720/3257 [00:06<00:05, 270.00it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1748/3257 [00:06<00:05, 260.44it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1775/3257 [00:06<00:08, 178.74it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1805/3257 [00:07<00:07, 202.64it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1832/3257 [00:07<00:06, 217.44it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1864/3257 [00:07<00:05, 242.57it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1891/3257 [00:07<00:05, 248.11it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1919/3257 [00:07<00:05, 256.45it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1955/3257 [00:07<00:04, 284.42it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1985/3257 [00:07<00:04, 282.25it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2017/3257 [00:07<00:04, 292.00it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2047/3257 [00:07<00:04, 284.41it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2076/3257 [00:08<00:04, 279.89it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2105/3257 [00:08<00:04, 275.78it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2133/3257 [00:08<00:04, 268.29it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2160/3257 [00:08<00:04, 267.88it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2188/3257 [00:08<00:03, 270.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2218/3257 [00:08<00:03, 276.88it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2246/3257 [00:08<00:03, 274.43it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2274/3257 [00:08<00:03, 265.85it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2302/3257 [00:08<00:03, 268.89it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2331/3257 [00:08<00:03, 274.51it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:09<00:03, 278.87it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2389/3257 [00:09<00:03, 279.57it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2417/3257 [00:09<00:03, 272.59it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2445/3257 [00:09<00:03, 268.78it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2477/3257 [00:09<00:02, 283.05it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2511/3257 [00:09<00:02, 297.85it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2541/3257 [00:09<00:02, 298.12it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2571/3257 [00:09<00:02, 288.34it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:09<00:02, 286.02it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2638/3257 [00:09<00:01, 310.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2670/3257 [00:10<00:01, 300.77it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2701/3257 [00:10<00:01, 284.28it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:10<00:01, 286.70it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:10<00:01, 283.17it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2790/3257 [00:10<00:01, 275.48it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2818/3257 [00:10<00:01, 260.93it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2845/3257 [00:10<00:01, 249.57it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2879/3257 [00:10<00:01, 272.89it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:11<00:01, 247.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2933/3257 [00:11<00:01, 248.78it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2959/3257 [00:11<00:01, 236.41it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:11<00:01, 235.60it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:11<00:01, 243.36it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3039/3257 [00:11<00:00, 249.60it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3069/3257 [00:11<00:00, 263.40it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3096/3257 [00:11<00:00, 265.05it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:11<00:00, 276.01it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3155/3257 [00:12<00:00, 259.80it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3182/3257 [00:12<00:00, 250.67it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3210/3257 [00:12<00:00, 257.53it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3237/3257 [00:12<00:00, 258.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:12<00:00, 262.62it/s]
2023-02-07 18:52:28.387 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:52:28,388][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d501,n5,w16,mc3,s0.527954,t4>', 'datetime': '2023-02-07T18:52:28.388679', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:52:28,390][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:52:28,391][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:52:28,666][gensim.models.doc2vec][INFO] - collected 6662 word types and 3257 unique tags from a corpus of 3257 examples and 2911496 words
[2023-02-07 18:52:28,666][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:52:28,680][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 4875 unique words (73.18% of original 6662, drops 1787)', 'datetime': '2023-02-07T18:52:28.680612', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:52:28,681][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 2908813 word corpus (99.91% of original 2911496, drops 2683)', 'datetime': '2023-02-07T18:52:28.681104', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:52:28,698][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 6662 items
[2023-02-07 18:52:28,698][gensim.models.word2vec][INFO] - sample=0.527954 downsamples 0 most-common words
[2023-02-07 18:52:28,698][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2908813 word corpus (100.0%% of prior 2908813)', 'datetime': '2023-02-07T18:52:28.698862', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:52:28,727][gensim.models.word2vec][INFO] - estimated required memory for 4875 words and 501 dimensions: 29154928 bytes
[2023-02-07 18:52:28,727][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:52:28,746][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 4875 vocabulary and 501 features, using sg=0 hs=0 sample=0.5279538559942952 negative=5 window=16 shrink_windows=True', 'datetime': '2023-02-07T18:52:28.746773', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:52:29,751][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 22.14% examples, 637032 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:52:30,769][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 42.89% examples, 637345 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:52:31,780][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 65.77% examples, 645816 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:52:32,780][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 89.32% examples, 649600 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:52:33,214][gensim.models.word2vec][INFO] - EPOCH 0: training on 2911496 raw words (2912070 effective words) took 4.5s, 652332 effective words/s
[2023-02-07 18:52:34,230][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 22.14% examples, 629102 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:52:35,242][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 46.30% examples, 676390 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:52:36,242][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 71.66% examples, 703135 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:52:37,244][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 97.39% examples, 705077 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:52:37,330][gensim.models.word2vec][INFO] - EPOCH 1: training on 2911496 raw words (2912070 effective words) took 4.1s, 708009 effective words/s
[2023-02-07 18:52:38,350][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 26.22% examples, 754089 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:52:39,355][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 48.23% examples, 708878 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:52:40,370][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 70.00% examples, 687195 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:52:41,382][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 94.69% examples, 682573 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:52:41,577][gensim.models.word2vec][INFO] - EPOCH 2: training on 2911496 raw words (2912070 effective words) took 4.2s, 685933 effective words/s
[2023-02-07 18:52:42,587][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 24.26% examples, 697147 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:52:43,606][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 47.31% examples, 693197 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:52:44,609][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 70.46% examples, 692369 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:52:45,614][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 94.38% examples, 682812 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:52:45,841][gensim.models.word2vec][INFO] - EPOCH 3: training on 2911496 raw words (2912070 effective words) took 4.3s, 683318 effective words/s
[2023-02-07 18:52:46,845][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 22.97% examples, 663560 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:52:47,866][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 44.18% examples, 652343 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:52:48,890][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 66.20% examples, 647974 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:52:49,894][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 90.48% examples, 654735 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:52:50,240][gensim.models.word2vec][INFO] - EPOCH 4: training on 2911496 raw words (2912070 effective words) took 4.4s, 662134 effective words/s
[2023-02-07 18:52:51,251][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 23.92% examples, 687087 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:52:52,277][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 47.04% examples, 686094 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:52:53,294][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 70.00% examples, 684191 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:52:54,298][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 93.00% examples, 672106 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:52:54,577][gensim.models.word2vec][INFO] - EPOCH 5: training on 2911496 raw words (2912070 effective words) took 4.3s, 671721 effective words/s
[2023-02-07 18:52:55,614][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 22.38% examples, 625303 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:52:56,628][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 44.18% examples, 644538 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:52:57,640][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 67.88% examples, 660820 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:52:58,650][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 93.49% examples, 672207 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:52:58,876][gensim.models.word2vec][INFO] - EPOCH 6: training on 2911496 raw words (2912070 effective words) took 4.3s, 677928 effective words/s
[2023-02-07 18:52:59,893][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 22.63% examples, 645673 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:00,926][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 44.67% examples, 649288 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:01,935][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 66.47% examples, 646100 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:02,938][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 90.33% examples, 651318 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:03,327][gensim.models.word2vec][INFO] - EPOCH 7: training on 2911496 raw words (2912070 effective words) took 4.4s, 654485 effective words/s
[2023-02-07 18:53:04,346][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 24.90% examples, 709097 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:05,354][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 47.31% examples, 693995 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:06,363][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 70.46% examples, 691458 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:07,382][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 93.92% examples, 677473 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:07,614][gensim.models.word2vec][INFO] - EPOCH 8: training on 2911496 raw words (2912070 effective words) took 4.3s, 679660 effective words/s
[2023-02-07 18:53:08,631][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 22.38% examples, 637101 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:09,664][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 42.86% examples, 627206 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:10,679][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 67.88% examples, 660282 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:11,680][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 93.00% examples, 670814 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:11,938][gensim.models.word2vec][INFO] - EPOCH 9: training on 2911496 raw words (2912070 effective words) took 4.3s, 673716 effective words/s
[2023-02-07 18:53:12,970][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 23.37% examples, 655303 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:13,989][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 44.18% examples, 644347 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:15,009][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 66.81% examples, 646677 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:16,023][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 90.05% examples, 645308 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:16,387][gensim.models.word2vec][INFO] - EPOCH 10: training on 2911496 raw words (2912070 effective words) took 4.4s, 654888 effective words/s
[2023-02-07 18:53:17,394][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 24.90% examples, 716472 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:18,418][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 47.28% examples, 692252 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:19,455][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 70.00% examples, 680692 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:20,465][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 95.46% examples, 682670 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:20,632][gensim.models.word2vec][INFO] - EPOCH 11: training on 2911496 raw words (2912070 effective words) took 4.2s, 686092 effective words/s
[2023-02-07 18:53:21,650][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 23.67% examples, 673419 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:22,677][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 45.59% examples, 665240 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:23,679][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 68.28% examples, 667197 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:53:24,682][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 92.63% examples, 670905 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:24,944][gensim.models.word2vec][INFO] - EPOCH 12: training on 2911496 raw words (2912070 effective words) took 4.3s, 675594 effective words/s
[2023-02-07 18:53:25,946][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 22.63% examples, 655157 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:26,948][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 45.84% examples, 678919 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:27,957][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 68.22% examples, 674277 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:28,964][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 92.63% examples, 675856 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:29,250][gensim.models.word2vec][INFO] - EPOCH 13: training on 2911496 raw words (2912070 effective words) took 4.3s, 676542 effective words/s
[2023-02-07 18:53:30,265][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 22.63% examples, 647034 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:31,295][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 45.84% examples, 665279 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:32,298][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 68.28% examples, 666955 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:53:33,319][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 91.86% examples, 663008 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:53:33,622][gensim.models.word2vec][INFO] - EPOCH 14: training on 2911496 raw words (2912070 effective words) took 4.4s, 666389 effective words/s
[2023-02-07 18:53:33,622][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 43672440 raw words (43681050 effective words) took 64.9s, 673306 effective words/s', 'datetime': '2023-02-07T18:53:33.622691', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:53:33.623 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:53:37,070][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185207-tnll22z5/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:53:37.070479', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:53:37,071][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:53:37,120][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185207-tnll22z5/files/../tmp/embedding_model.pt
2023-02-07 18:53:37.121 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:53:39.795 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:53:40.660 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:53:44.073 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1706609825007175, 'test_mae': 0.8244347748306632, 'test_r2': -3.212214290575929}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.76
wandb: percentage 0.26824
wandb:   test_mae 0.82443
wandb:   test_mse 1.17066
wandb:    test_r2 -3.21221
wandb: 
wandb: üöÄ View run misty-sweep-20 at: https://wandb.ai/xiaoqiz/mof2vec/runs/tnll22z5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_185207-tnll22z5/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ujsxd46e with config:
wandb: 	data.data.wl_step: 3
wandb: 	data.nn.batch_size: 695
wandb: 	model.gensim.alpha: 0.0003775804666610816
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.8229126988278983
wandb: 	model.gensim.vector_size: 155
wandb: 	model.gensim.window: 9
wandb: 	model.sklearn.learning_rate: 0.0038311756466386303
wandb: 	model.sklearn.max_depth: 75
wandb: 	model.sklearn.min_child_weight: 0.09011690970957505
wandb: 	model.sklearn.n_estimators: 3290
wandb: 	model.sklearn.num_leaves: 158
wandb: 	model.sklearn.reg_alpha: 0.04980433582521802
wandb: 	model.sklearn.reg_lambda: 0.052672349547022414
wandb: 	model.sklearn.subsample: 0.7022958765375154
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185403-ujsxd46e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-21
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/ujsxd46e
2023-02-07 18:54:16.016 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 3 for sweep.
2023-02-07 18:54:16.017 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 695 for sweep.
2023-02-07 18:54:16.017 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0003775804666610816 for sweep.
2023-02-07 18:54:16.017 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 18:54:16.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 18:54:16.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8229126988278983 for sweep.
2023-02-07 18:54:16.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 155 for sweep.
2023-02-07 18:54:16.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 9 for sweep.
2023-02-07 18:54:16.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0038311756466386303 for sweep.
2023-02-07 18:54:16.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 75 for sweep.
2023-02-07 18:54:16.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09011690970957505 for sweep.
2023-02-07 18:54:16.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3290 for sweep.
2023-02-07 18:54:16.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 158 for sweep.
2023-02-07 18:54:16.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.04980433582521802 for sweep.
2023-02-07 18:54:16.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.052672349547022414 for sweep.
2023-02-07 18:54:16.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7022958765375154 for sweep.
2023-02-07 18:54:16.021 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:54:16.028 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 3}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185403-ujsxd46e/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 695, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 155, 'window': 9, 'min_count': 1, 'dm': 0, 'sample': 0.8229126988278983, 'workers': 4, 'alpha': 0.0003775804666610816, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3290, 'max_depth': 75, 'num_leaves': 158, 'reg_alpha': 0.04980433582521802, 'reg_lambda': 0.052672349547022414, 'subsample': 0.7022958765375154, 'min_child_weight': 0.09011690970957505, 'n_jobs': 4, 'learning_rate': 0.0038311756466386303}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 23/3257 [00:00<00:14, 225.28it/s]  1%|‚ñè         | 47/3257 [00:00<00:13, 233.26it/s]  2%|‚ñè         | 71/3257 [00:00<00:13, 231.60it/s]  3%|‚ñé         | 97/3257 [00:00<00:13, 240.29it/s]  4%|‚ñé         | 122/3257 [00:00<00:13, 235.38it/s]  5%|‚ñç         | 149/3257 [00:00<00:12, 246.27it/s]  5%|‚ñå         | 174/3257 [00:00<00:13, 233.03it/s]  6%|‚ñå         | 201/3257 [00:00<00:12, 238.15it/s]  7%|‚ñã         | 233/3257 [00:00<00:11, 261.41it/s]  8%|‚ñä         | 260/3257 [00:01<00:11, 251.22it/s]  9%|‚ñâ         | 291/3257 [00:01<00:11, 265.70it/s] 10%|‚ñâ         | 318/3257 [00:01<00:11, 259.02it/s] 11%|‚ñà         | 345/3257 [00:01<00:11, 258.78it/s] 11%|‚ñà‚ñè        | 373/3257 [00:01<00:10, 263.99it/s] 12%|‚ñà‚ñè        | 400/3257 [00:01<00:11, 245.18it/s] 13%|‚ñà‚ñé        | 425/3257 [00:01<00:11, 237.69it/s] 14%|‚ñà‚ñç        | 449/3257 [00:01<00:12, 229.32it/s] 15%|‚ñà‚ñç        | 475/3257 [00:01<00:11, 237.07it/s] 15%|‚ñà‚ñå        | 502/3257 [00:02<00:11, 245.36it/s] 16%|‚ñà‚ñå        | 527/3257 [00:02<00:11, 241.95it/s] 17%|‚ñà‚ñã        | 552/3257 [00:02<00:11, 242.40it/s] 18%|‚ñà‚ñä        | 577/3257 [00:02<00:12, 221.59it/s] 19%|‚ñà‚ñä        | 604/3257 [00:02<00:11, 234.11it/s] 19%|‚ñà‚ñâ        | 631/3257 [00:02<00:10, 243.08it/s] 20%|‚ñà‚ñà        | 656/3257 [00:02<00:11, 226.89it/s] 21%|‚ñà‚ñà        | 683/3257 [00:02<00:11, 228.43it/s] 22%|‚ñà‚ñà‚ñè       | 709/3257 [00:02<00:10, 235.75it/s] 23%|‚ñà‚ñà‚ñé       | 733/3257 [00:03<00:10, 232.40it/s] 23%|‚ñà‚ñà‚ñé       | 758/3257 [00:03<00:10, 235.92it/s] 24%|‚ñà‚ñà‚ñç       | 782/3257 [00:03<00:10, 232.67it/s] 25%|‚ñà‚ñà‚ñç       | 807/3257 [00:03<00:10, 236.19it/s] 26%|‚ñà‚ñà‚ñå       | 831/3257 [00:03<00:10, 232.63it/s] 26%|‚ñà‚ñà‚ñã       | 855/3257 [00:03<00:10, 225.03it/s] 27%|‚ñà‚ñà‚ñã       | 879/3257 [00:03<00:10, 228.63it/s] 28%|‚ñà‚ñà‚ñä       | 906/3257 [00:03<00:09, 238.82it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:03<00:09, 239.73it/s] 29%|‚ñà‚ñà‚ñâ       | 957/3257 [00:03<00:09, 242.93it/s] 30%|‚ñà‚ñà‚ñà       | 982/3257 [00:04<00:09, 239.92it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:04<00:09, 231.29it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1031/3257 [00:04<00:09, 229.30it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1054/3257 [00:04<00:09, 224.77it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:04<00:09, 226.04it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:04<00:09, 230.90it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1129/3257 [00:04<00:09, 226.29it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1152/3257 [00:04<00:09, 223.55it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1177/3257 [00:04<00:09, 228.17it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1200/3257 [00:05<00:09, 213.28it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1222/3257 [00:05<00:15, 134.75it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:05<00:12, 155.72it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:05<00:11, 171.65it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:05<00:11, 174.72it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1314/3257 [00:05<00:10, 185.19it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1341/3257 [00:05<00:09, 205.05it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1363/3257 [00:06<00:09, 207.52it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:06<00:09, 202.84it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1411/3257 [00:06<00:08, 218.43it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1437/3257 [00:06<00:07, 229.84it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1466/3257 [00:06<00:07, 243.70it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1493/3257 [00:06<00:07, 250.78it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1519/3257 [00:06<00:07, 246.86it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1544/3257 [00:06<00:07, 233.90it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:06<00:06, 250.54it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1606/3257 [00:06<00:06, 269.53it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1637/3257 [00:07<00:05, 278.94it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1666/3257 [00:07<00:05, 278.10it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1694/3257 [00:07<00:05, 278.26it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:07<00:05, 282.63it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1758/3257 [00:07<00:05, 286.07it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:07<00:04, 301.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1823/3257 [00:07<00:04, 294.88it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1855/3257 [00:07<00:04, 299.75it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1887/3257 [00:07<00:04, 304.92it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1918/3257 [00:08<00:04, 291.71it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1957/3257 [00:08<00:04, 315.58it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1989/3257 [00:08<00:04, 309.47it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:08<00:03, 313.80it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2054/3257 [00:08<00:04, 295.85it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2084/3257 [00:08<00:04, 288.17it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2113/3257 [00:08<00:04, 283.24it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2142/3257 [00:08<00:04, 268.23it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2170/3257 [00:08<00:04, 269.16it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2199/3257 [00:09<00:03, 273.60it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2227/3257 [00:09<00:03, 271.30it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2255/3257 [00:09<00:03, 268.47it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2282/3257 [00:09<00:03, 261.24it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2312/3257 [00:09<00:03, 270.71it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2348/3257 [00:09<00:03, 295.70it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2378/3257 [00:09<00:02, 295.82it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2408/3257 [00:09<00:02, 290.49it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2438/3257 [00:09<00:02, 280.49it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2467/3257 [00:10<00:04, 180.40it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2498/3257 [00:10<00:03, 205.81it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2530/3257 [00:10<00:03, 231.53it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2558/3257 [00:10<00:02, 242.95it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:10<00:02, 241.66it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2620/3257 [00:10<00:02, 266.19it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2649/3257 [00:10<00:02, 268.59it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2679/3257 [00:10<00:02, 276.83it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2708/3257 [00:11<00:02, 263.51it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2737/3257 [00:11<00:01, 269.68it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2768/3257 [00:11<00:01, 272.58it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2800/3257 [00:11<00:01, 284.49it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2829/3257 [00:11<00:01, 271.31it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2862/3257 [00:11<00:01, 287.00it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2893/3257 [00:11<00:01, 289.66it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2925/3257 [00:11<00:01, 297.78it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2955/3257 [00:11<00:01, 276.89it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:12<00:01, 270.80it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:12<00:00, 279.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:12<00:00, 287.43it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:12<00:00, 300.94it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3115/3257 [00:12<00:00, 309.08it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3147/3257 [00:12<00:00, 293.37it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3177/3257 [00:12<00:00, 284.45it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3208/3257 [00:12<00:00, 289.55it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:12<00:00, 293.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:12<00:00, 251.81it/s]
2023-02-07 18:54:29.343 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:54:29,344][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d155,n5,s0.822913,t4>', 'datetime': '2023-02-07T18:54:29.344084', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:54:29,344][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:54:29,344][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:54:29,600][gensim.models.doc2vec][INFO] - collected 6662 word types and 3257 unique tags from a corpus of 3257 examples and 2911496 words
[2023-02-07 18:54:29,600][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:54:29,617][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 6662 unique words (100.00% of original 6662, drops 0)', 'datetime': '2023-02-07T18:54:29.616982', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:54:29,617][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 2911496 word corpus (100.00% of original 2911496, drops 0)', 'datetime': '2023-02-07T18:54:29.617366', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:54:29,639][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 6662 items
[2023-02-07 18:54:29,639][gensim.models.word2vec][INFO] - sample=0.822913 downsamples 0 most-common words
[2023-02-07 18:54:29,640][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2911496 word corpus (100.0%% of prior 2911496)', 'datetime': '2023-02-07T18:54:29.640123', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:54:29,678][gensim.models.word2vec][INFO] - estimated required memory for 6662 words and 155 dimensions: 14262620 bytes
[2023-02-07 18:54:29,679][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:54:29,686][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 6662 vocabulary and 155 features, using sg=1 hs=0 sample=0.8229126988278983 negative=5 window=9 shrink_windows=True', 'datetime': '2023-02-07T18:54:29.686510', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:54:30,692][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 81.55% examples, 2388388 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:30,903][gensim.models.word2vec][INFO] - EPOCH 0: training on 2911496 raw words (2914753 effective words) took 1.2s, 2400887 effective words/s
[2023-02-07 18:54:31,906][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 82.16% examples, 2411672 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:32,105][gensim.models.word2vec][INFO] - EPOCH 1: training on 2911496 raw words (2914753 effective words) took 1.2s, 2426904 effective words/s
[2023-02-07 18:54:33,109][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 82.56% examples, 2419632 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:33,308][gensim.models.word2vec][INFO] - EPOCH 2: training on 2911496 raw words (2914753 effective words) took 1.2s, 2426262 effective words/s
[2023-02-07 18:54:34,309][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 83.51% examples, 2462305 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:34,509][gensim.models.word2vec][INFO] - EPOCH 3: training on 2911496 raw words (2914753 effective words) took 1.2s, 2429279 effective words/s
[2023-02-07 18:54:35,515][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 73.72% examples, 2169453 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:35,841][gensim.models.word2vec][INFO] - EPOCH 4: training on 2911496 raw words (2914753 effective words) took 1.3s, 2191915 effective words/s
[2023-02-07 18:54:36,847][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 74.46% examples, 2197154 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:37,158][gensim.models.word2vec][INFO] - EPOCH 5: training on 2911496 raw words (2914753 effective words) took 1.3s, 2217017 effective words/s
[2023-02-07 18:54:38,166][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 74.55% examples, 2191741 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:38,485][gensim.models.word2vec][INFO] - EPOCH 6: training on 2911496 raw words (2914753 effective words) took 1.3s, 2199310 effective words/s
[2023-02-07 18:54:39,488][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 74.76% examples, 2209876 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:39,795][gensim.models.word2vec][INFO] - EPOCH 7: training on 2911496 raw words (2914753 effective words) took 1.3s, 2227497 effective words/s
[2023-02-07 18:54:40,801][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 74.46% examples, 2195743 words/s, in_qsize 7, out_qsize 1
[2023-02-07 18:54:41,113][gensim.models.word2vec][INFO] - EPOCH 8: training on 2911496 raw words (2914753 effective words) took 1.3s, 2215169 effective words/s
[2023-02-07 18:54:42,119][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 74.76% examples, 2206265 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:42,426][gensim.models.word2vec][INFO] - EPOCH 9: training on 2911496 raw words (2914753 effective words) took 1.3s, 2223280 effective words/s
[2023-02-07 18:54:43,431][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 78.72% examples, 2314675 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:43,648][gensim.models.word2vec][INFO] - EPOCH 10: training on 2911496 raw words (2914753 effective words) took 1.2s, 2390917 effective words/s
[2023-02-07 18:54:44,651][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 87.10% examples, 2560213 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:44,793][gensim.models.word2vec][INFO] - EPOCH 11: training on 2911496 raw words (2914753 effective words) took 1.1s, 2549789 effective words/s
[2023-02-07 18:54:45,805][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 80.53% examples, 2343346 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:46,033][gensim.models.word2vec][INFO] - EPOCH 12: training on 2911496 raw words (2914753 effective words) took 1.2s, 2352674 effective words/s
[2023-02-07 18:54:47,036][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 79.52% examples, 2347006 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:47,274][gensim.models.word2vec][INFO] - EPOCH 13: training on 2911496 raw words (2914753 effective words) took 1.2s, 2354811 effective words/s
[2023-02-07 18:54:48,277][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 80.01% examples, 2353063 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:54:48,512][gensim.models.word2vec][INFO] - EPOCH 14: training on 2911496 raw words (2914753 effective words) took 1.2s, 2356231 effective words/s
[2023-02-07 18:54:48,512][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 43672440 raw words (43721295 effective words) took 18.8s, 2322487 effective words/s', 'datetime': '2023-02-07T18:54:48.512906', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:54:48.513 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:54:49,949][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185403-ujsxd46e/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:54:49.949517', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:54:49,950][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:54:49,975][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185403-ujsxd46e/files/../tmp/embedding_model.pt
2023-02-07 18:54:49.975 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:54:51.289 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:54:51.785 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:54:52.841 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0731237188150644, 'test_mae': 0.8049201782952788, 'test_r2': -2.4999966126635944}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.06
wandb: percentage 0.0
wandb:   test_mae 0.80492
wandb:   test_mse 1.07312
wandb:    test_r2 -2.5
wandb: 
wandb: üöÄ View run dark-sweep-21 at: https://wandb.ai/xiaoqiz/mof2vec/runs/ujsxd46e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_185403-ujsxd46e/logs
wandb: Agent Starting Run: p00mp4kl with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 115
wandb: 	model.gensim.alpha: 0.029382588966991384
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.4024597165658714
wandb: 	model.gensim.vector_size: 479
wandb: 	model.gensim.window: 19
wandb: 	model.sklearn.learning_rate: 0.0007975608944207486
wandb: 	model.sklearn.max_depth: 47
wandb: 	model.sklearn.min_child_weight: 0.05227302049806596
wandb: 	model.sklearn.n_estimators: 3076
wandb: 	model.sklearn.num_leaves: 247
wandb: 	model.sklearn.reg_alpha: 0.0500006903569337
wandb: 	model.sklearn.reg_lambda: 0.0531968456066088
wandb: 	model.sklearn.subsample: 0.6184113665043625
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185502-p00mp4kl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-22
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/p00mp4kl
2023-02-07 18:55:11.282 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 18:55:11.283 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 115 for sweep.
2023-02-07 18:55:11.283 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.029382588966991384 for sweep.
2023-02-07 18:55:11.283 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:55:11.283 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 18:55:11.284 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4024597165658714 for sweep.
2023-02-07 18:55:11.284 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 479 for sweep.
2023-02-07 18:55:11.284 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 19 for sweep.
2023-02-07 18:55:11.284 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0007975608944207486 for sweep.
2023-02-07 18:55:11.285 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 47 for sweep.
2023-02-07 18:55:11.285 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05227302049806596 for sweep.
2023-02-07 18:55:11.285 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3076 for sweep.
2023-02-07 18:55:11.285 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 247 for sweep.
2023-02-07 18:55:11.285 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0500006903569337 for sweep.
2023-02-07 18:55:11.286 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0531968456066088 for sweep.
2023-02-07 18:55:11.286 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6184113665043625 for sweep.
2023-02-07 18:55:11.286 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:55:11.291 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185502-p00mp4kl/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 115, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 479, 'window': 19, 'min_count': 9, 'dm': 1, 'sample': 0.4024597165658714, 'workers': 4, 'alpha': 0.029382588966991384, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3076, 'max_depth': 47, 'num_leaves': 247, 'reg_alpha': 0.0500006903569337, 'reg_lambda': 0.0531968456066088, 'subsample': 0.6184113665043625, 'min_child_weight': 0.05227302049806596, 'n_jobs': 4, 'learning_rate': 0.0007975608944207486}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 24/3257 [00:00<00:13, 236.70it/s]  2%|‚ñè         | 50/3257 [00:00<00:13, 241.08it/s]  2%|‚ñè         | 75/3257 [00:00<00:13, 236.28it/s]  3%|‚ñé         | 102/3257 [00:00<00:12, 248.70it/s]  4%|‚ñç         | 127/3257 [00:00<00:12, 241.59it/s]  5%|‚ñç         | 158/3257 [00:00<00:12, 255.54it/s]  6%|‚ñå         | 184/3257 [00:00<00:12, 253.80it/s]  7%|‚ñã         | 214/3257 [00:00<00:11, 267.35it/s]  8%|‚ñä         | 245/3257 [00:00<00:10, 278.77it/s]  8%|‚ñä         | 274/3257 [00:01<00:10, 281.83it/s]  9%|‚ñâ         | 305/3257 [00:01<00:10, 289.97it/s] 10%|‚ñà         | 335/3257 [00:01<00:10, 288.21it/s] 11%|‚ñà         | 364/3257 [00:01<00:10, 268.67it/s] 12%|‚ñà‚ñè        | 392/3257 [00:01<00:12, 237.33it/s] 13%|‚ñà‚ñé        | 417/3257 [00:01<00:12, 235.95it/s] 14%|‚ñà‚ñé        | 442/3257 [00:01<00:13, 208.06it/s] 14%|‚ñà‚ñç        | 467/3257 [00:02<00:18, 150.82it/s] 15%|‚ñà‚ñç        | 487/3257 [00:02<00:17, 160.46it/s] 16%|‚ñà‚ñå        | 511/3257 [00:02<00:15, 177.20it/s] 16%|‚ñà‚ñã        | 531/3257 [00:02<00:14, 182.08it/s] 17%|‚ñà‚ñã        | 554/3257 [00:02<00:14, 192.97it/s] 18%|‚ñà‚ñä        | 575/3257 [00:02<00:14, 182.46it/s] 18%|‚ñà‚ñä        | 600/3257 [00:02<00:13, 198.21it/s] 19%|‚ñà‚ñâ        | 621/3257 [00:02<00:13, 200.46it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:02<00:12, 208.26it/s] 20%|‚ñà‚ñà        | 666/3257 [00:03<00:13, 196.76it/s] 21%|‚ñà‚ñà        | 687/3257 [00:03<00:12, 198.07it/s] 22%|‚ñà‚ñà‚ñè       | 710/3257 [00:03<00:12, 206.90it/s] 22%|‚ñà‚ñà‚ñè       | 732/3257 [00:03<00:12, 200.28it/s] 23%|‚ñà‚ñà‚ñé       | 753/3257 [00:03<00:12, 200.59it/s] 24%|‚ñà‚ñà‚ñç       | 775/3257 [00:03<00:12, 204.77it/s] 24%|‚ñà‚ñà‚ñç       | 796/3257 [00:03<00:11, 205.69it/s] 25%|‚ñà‚ñà‚ñå       | 818/3257 [00:03<00:11, 206.54it/s] 26%|‚ñà‚ñà‚ñå       | 839/3257 [00:03<00:12, 198.85it/s] 26%|‚ñà‚ñà‚ñã       | 859/3257 [00:03<00:12, 195.73it/s] 27%|‚ñà‚ñà‚ñã       | 879/3257 [00:04<00:12, 195.03it/s] 28%|‚ñà‚ñà‚ñä       | 904/3257 [00:04<00:11, 209.51it/s] 28%|‚ñà‚ñà‚ñä       | 927/3257 [00:04<00:10, 213.63it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:04<00:10, 209.85it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:04<00:10, 213.52it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:04<00:10, 211.14it/s] 31%|‚ñà‚ñà‚ñà       | 1016/3257 [00:04<00:10, 212.17it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1038/3257 [00:04<00:10, 204.23it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1059/3257 [00:04<00:10, 202.83it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1081/3257 [00:05<00:10, 205.34it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1103/3257 [00:05<00:10, 208.52it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:05<00:10, 206.12it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1145/3257 [00:05<00:10, 199.54it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1169/3257 [00:05<00:09, 209.67it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:05<00:10, 189.72it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1211/3257 [00:05<00:10, 187.91it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:05<00:10, 195.79it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1254/3257 [00:05<00:10, 199.24it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:06<00:10, 194.60it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1295/3257 [00:06<00:10, 187.69it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1318/3257 [00:06<00:09, 197.99it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1341/3257 [00:06<00:09, 205.06it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1362/3257 [00:06<00:09, 201.15it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1383/3257 [00:06<00:09, 190.06it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1406/3257 [00:06<00:09, 199.88it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1431/3257 [00:06<00:08, 213.49it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1453/3257 [00:06<00:08, 213.43it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1476/3257 [00:07<00:08, 216.42it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1501/3257 [00:07<00:07, 223.61it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1524/3257 [00:07<00:08, 213.22it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:07<00:08, 203.95it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1568/3257 [00:07<00:13, 127.40it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1589/3257 [00:07<00:11, 143.36it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1613/3257 [00:07<00:10, 163.42it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:07<00:09, 170.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:08<00:09, 177.82it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1675/3257 [00:08<00:08, 183.02it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1698/3257 [00:08<00:08, 193.56it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1720/3257 [00:08<00:07, 198.90it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1741/3257 [00:08<00:08, 188.95it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1764/3257 [00:08<00:07, 199.29it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1788/3257 [00:08<00:07, 208.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1810/3257 [00:08<00:07, 200.97it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1831/3257 [00:08<00:07, 198.02it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1855/3257 [00:09<00:06, 207.43it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:09<00:06, 215.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1901/3257 [00:09<00:06, 215.23it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1923/3257 [00:09<00:06, 214.68it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1952/3257 [00:09<00:05, 235.53it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1977/3257 [00:09<00:05, 234.44it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2001/3257 [00:09<00:05, 233.04it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2025/3257 [00:09<00:05, 231.27it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2049/3257 [00:09<00:05, 219.30it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2075/3257 [00:10<00:05, 229.94it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2101/3257 [00:10<00:04, 237.71it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2129/3257 [00:10<00:04, 243.97it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2157/3257 [00:10<00:04, 253.16it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:10<00:04, 260.69it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2213/3257 [00:10<00:03, 263.61it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2241/3257 [00:10<00:03, 267.24it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:10<00:03, 271.03it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:10<00:03, 274.29it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2335/3257 [00:10<00:03, 296.85it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2367/3257 [00:11<00:02, 299.35it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:11<00:02, 303.70it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2430/3257 [00:11<00:02, 283.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2459/3257 [00:11<00:02, 276.45it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2489/3257 [00:11<00:02, 282.54it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2523/3257 [00:11<00:02, 295.86it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2553/3257 [00:11<00:02, 290.26it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2583/3257 [00:11<00:02, 266.23it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2615/3257 [00:11<00:02, 278.03it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2644/3257 [00:12<00:02, 277.99it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:12<00:02, 270.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2701/3257 [00:12<00:02, 253.32it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2730/3257 [00:12<00:02, 260.75it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2758/3257 [00:12<00:01, 265.53it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2785/3257 [00:12<00:01, 266.07it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:12<00:01, 266.59it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2840/3257 [00:12<00:01, 253.13it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2875/3257 [00:12<00:01, 279.73it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2904/3257 [00:13<00:01, 262.06it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2933/3257 [00:13<00:01, 269.59it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2961/3257 [00:13<00:01, 159.71it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:13<00:01, 174.73it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3014/3257 [00:13<00:01, 198.75it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3043/3257 [00:13<00:00, 219.67it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3073/3257 [00:13<00:00, 238.92it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3103/3257 [00:14<00:00, 253.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3131/3257 [00:14<00:00, 260.61it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3159/3257 [00:14<00:00, 260.50it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3187/3257 [00:14<00:00, 256.55it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3214/3257 [00:14<00:00, 250.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3245/3257 [00:14<00:00, 266.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:14<00:00, 223.24it/s]
2023-02-07 18:55:26.328 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:55:26,329][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d479,n5,w19,mc9,s0.40246,t4>', 'datetime': '2023-02-07T18:55:26.329789', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:55:26,330][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:55:26,330][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:55:26,649][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 18:55:26,650][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:55:26,666][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 5109 unique words (39.12% of original 13061, drops 7952)', 'datetime': '2023-02-07T18:55:26.666087', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:55:26,666][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 3612004 word corpus (99.25% of original 3639370, drops 27366)', 'datetime': '2023-02-07T18:55:26.666440', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:55:26,684][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 18:55:26,685][gensim.models.word2vec][INFO] - sample=0.40246 downsamples 0 most-common words
[2023-02-07 18:55:26,685][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3612004 word corpus (100.0%% of prior 3612004)', 'datetime': '2023-02-07T18:55:26.685877', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:55:26,715][gensim.models.word2vec][INFO] - estimated required memory for 5109 words and 479 dimensions: 29024000 bytes
[2023-02-07 18:55:26,716][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:55:26,732][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 5109 vocabulary and 479 features, using sg=0 hs=0 sample=0.4024597165658714 negative=5 window=19 shrink_windows=True', 'datetime': '2023-02-07T18:55:26.732138', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:55:27,746][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 17.53% examples, 617391 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:55:28,762][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 34.45% examples, 622767 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:55:29,770][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 51.61% examples, 628967 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:30,778][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 69.51% examples, 635643 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:31,782][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 87.23% examples, 630782 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:32,503][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3615261 effective words) took 5.8s, 626663 effective words/s
[2023-02-07 18:55:33,523][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 17.16% examples, 596231 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:34,539][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 33.68% examples, 607566 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:35,546][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 49.80% examples, 604041 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:36,563][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 66.93% examples, 609202 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:37,576][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 84.28% examples, 606442 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:55:38,462][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3615261 effective words) took 6.0s, 606945 effective words/s
[2023-02-07 18:55:39,493][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 17.16% examples, 589437 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:40,497][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 34.94% examples, 630896 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:41,501][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 53.02% examples, 645346 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:42,518][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 71.05% examples, 647858 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:55:43,534][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 89.87% examples, 644044 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:55:44,041][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3615261 effective words) took 5.6s, 648391 effective words/s
[2023-02-07 18:55:45,055][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 17.81% examples, 624962 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:46,071][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 35.31% examples, 641156 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:55:47,085][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 53.21% examples, 649826 words/s, in_qsize 8, out_qsize 1
[2023-02-07 18:55:48,091][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 72.43% examples, 656789 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:49,093][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 91.40% examples, 659467 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:49,523][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3615261 effective words) took 5.5s, 659639 effective words/s
[2023-02-07 18:55:50,528][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 17.16% examples, 605011 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:55:51,531][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 33.13% examples, 602432 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:52,559][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 49.95% examples, 605008 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:53,596][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 67.12% examples, 609510 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:54,604][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 84.99% examples, 610946 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:55,442][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3615261 effective words) took 5.9s, 611120 effective words/s
[2023-02-07 18:55:56,457][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 17.16% examples, 598983 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:57,478][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 33.68% examples, 607625 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:55:58,494][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 50.66% examples, 613929 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:55:59,503][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 70.56% examples, 642725 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:00,529][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 91.65% examples, 656964 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:00,914][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3615261 effective words) took 5.5s, 660983 effective words/s
[2023-02-07 18:56:01,923][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 19.01% examples, 662436 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:02,928][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 35.31% examples, 646443 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:03,933][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 52.38% examples, 642234 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:56:04,937][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 70.28% examples, 646290 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:05,957][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 89.22% examples, 643842 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:56:06,538][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3615261 effective words) took 5.6s, 642978 effective words/s
[2023-02-07 18:56:07,549][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 18.58% examples, 652157 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:08,555][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 35.52% examples, 648270 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:09,560][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 53.02% examples, 648820 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:10,574][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 70.56% examples, 646633 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:11,579][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 89.07% examples, 642479 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:12,143][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3615261 effective words) took 5.6s, 645253 effective words/s
[2023-02-07 18:56:13,154][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 18.05% examples, 634993 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:14,172][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 35.34% examples, 639269 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:56:15,173][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 53.02% examples, 647059 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:56:16,173][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 70.28% examples, 645003 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:17,185][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 89.22% examples, 643921 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:17,752][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3615261 effective words) took 5.6s, 644671 effective words/s
[2023-02-07 18:56:18,759][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 18.05% examples, 637614 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:19,760][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 35.12% examples, 643526 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:20,763][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 52.78% examples, 648086 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:21,782][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 70.49% examples, 647306 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:56:22,801][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 90.02% examples, 648737 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:23,302][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3615261 effective words) took 5.5s, 651637 effective words/s
[2023-02-07 18:56:24,305][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 18.36% examples, 647305 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:25,319][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 35.68% examples, 651976 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:56:26,326][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 53.21% examples, 653879 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:27,326][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 71.72% examples, 657102 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:28,341][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 90.42% examples, 653629 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:28,835][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3615261 effective words) took 5.5s, 653534 effective words/s
[2023-02-07 18:56:29,864][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 19.07% examples, 658131 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:30,866][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 36.44% examples, 662655 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:31,881][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 53.05% examples, 646586 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:32,899][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 71.05% examples, 646437 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:56:33,913][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 89.87% examples, 643181 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:56:34,441][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3615261 effective words) took 5.6s, 645135 effective words/s
[2023-02-07 18:56:35,444][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 17.81% examples, 632024 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:36,450][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 34.45% examples, 629195 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:37,456][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 51.37% examples, 630677 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:38,474][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 68.53% examples, 628999 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:56:39,480][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 88.92% examples, 642665 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:39,986][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3615261 effective words) took 5.5s, 652139 effective words/s
[2023-02-07 18:56:41,000][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 19.80% examples, 694995 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:56:42,004][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 38.50% examples, 707268 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:43,007][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 57.57% examples, 705525 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:56:44,011][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 75.68% examples, 690277 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:45,011][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 94.11% examples, 679549 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:56:45,331][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3615261 effective words) took 5.3s, 676686 effective words/s
[2023-02-07 18:56:46,340][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 19.01% examples, 662821 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:47,342][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 36.60% examples, 674188 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:48,347][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 54.81% examples, 674617 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:56:49,355][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 73.81% examples, 672294 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:56:50,384][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 93.09% examples, 670459 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:56:50,715][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3615261 effective words) took 5.4s, 671776 effective words/s
[2023-02-07 18:56:50,715][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54228915 effective words) took 84.0s, 645719 effective words/s', 'datetime': '2023-02-07T18:56:50.715550', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:56:50.715 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:56:55,346][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185502-p00mp4kl/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:56:55.346336', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:56:55,347][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:56:55,405][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185502-p00mp4kl/files/../tmp/embedding_model.pt
2023-02-07 18:56:55.406 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:56:57.832 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:56:58.745 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:57:02.102 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.145314204313139, 'test_mae': 0.8253490749769415, 'test_r2': -3.0223357197287184}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.68
wandb: percentage 0.60884
wandb:   test_mae 0.82535
wandb:   test_mse 1.14531
wandb:    test_r2 -3.02234
wandb: 
wandb: üöÄ View run colorful-sweep-22 at: https://wandb.ai/xiaoqiz/mof2vec/runs/p00mp4kl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_185502-p00mp4kl/logs
wandb: Agent Starting Run: imosvvvc with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 486
wandb: 	model.gensim.alpha: 0.017160530386663746
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.407066895385145
wandb: 	model.gensim.vector_size: 222
wandb: 	model.gensim.window: 19
wandb: 	model.sklearn.learning_rate: 0.022991750163276425
wandb: 	model.sklearn.max_depth: 79
wandb: 	model.sklearn.min_child_weight: 0.027715994522291423
wandb: 	model.sklearn.n_estimators: 567
wandb: 	model.sklearn.num_leaves: 298
wandb: 	model.sklearn.reg_alpha: 0.6521778726087923
wandb: 	model.sklearn.reg_lambda: 0.004242225032813856
wandb: 	model.sklearn.subsample: 0.27815473336550894
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185713-imosvvvc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/imosvvvc
2023-02-07 18:57:21.294 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 18:57:21.295 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 486 for sweep.
2023-02-07 18:57:21.295 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.017160530386663746 for sweep.
2023-02-07 18:57:21.295 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:57:21.296 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 18:57:21.296 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.407066895385145 for sweep.
2023-02-07 18:57:21.296 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 222 for sweep.
2023-02-07 18:57:21.296 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 19 for sweep.
2023-02-07 18:57:21.296 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.022991750163276425 for sweep.
2023-02-07 18:57:21.297 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 79 for sweep.
2023-02-07 18:57:21.297 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.027715994522291423 for sweep.
2023-02-07 18:57:21.297 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 567 for sweep.
2023-02-07 18:57:21.297 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 298 for sweep.
2023-02-07 18:57:21.298 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.6521778726087923 for sweep.
2023-02-07 18:57:21.298 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.004242225032813856 for sweep.
2023-02-07 18:57:21.298 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.27815473336550894 for sweep.
2023-02-07 18:57:21.298 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:57:21.301 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185713-imosvvvc/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 486, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 222, 'window': 19, 'min_count': 5, 'dm': 1, 'sample': 0.407066895385145, 'workers': 4, 'alpha': 0.017160530386663746, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 567, 'max_depth': 79, 'num_leaves': 298, 'reg_alpha': 0.6521778726087923, 'reg_lambda': 0.004242225032813856, 'subsample': 0.27815473336550894, 'min_child_weight': 0.027715994522291423, 'n_jobs': 4, 'learning_rate': 0.022991750163276425}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 175.69it/s]  1%|‚ñè         | 41/3257 [00:00<00:16, 194.05it/s]  2%|‚ñè         | 61/3257 [00:00<00:16, 195.71it/s]  3%|‚ñé         | 85/3257 [00:00<00:15, 210.96it/s]  3%|‚ñé         | 107/3257 [00:00<00:16, 192.76it/s]  4%|‚ñç         | 128/3257 [00:00<00:15, 195.98it/s]  5%|‚ñç         | 151/3257 [00:00<00:15, 203.54it/s]  5%|‚ñå         | 172/3257 [00:00<00:15, 195.51it/s]  6%|‚ñå         | 193/3257 [00:00<00:15, 197.30it/s]  7%|‚ñã         | 215/3257 [00:01<00:14, 203.64it/s]  7%|‚ñã         | 237/3257 [00:01<00:14, 206.48it/s]  8%|‚ñä         | 259/3257 [00:01<00:14, 207.15it/s]  9%|‚ñâ         | 285/3257 [00:01<00:13, 218.39it/s]  9%|‚ñâ         | 307/3257 [00:01<00:14, 210.62it/s] 10%|‚ñà         | 329/3257 [00:01<00:13, 212.86it/s] 11%|‚ñà         | 351/3257 [00:01<00:14, 203.07it/s] 11%|‚ñà‚ñè        | 373/3257 [00:01<00:14, 203.80it/s] 12%|‚ñà‚ñè        | 394/3257 [00:01<00:15, 185.45it/s] 13%|‚ñà‚ñé        | 416/3257 [00:02<00:14, 193.30it/s] 13%|‚ñà‚ñé        | 436/3257 [00:02<00:17, 163.62it/s] 14%|‚ñà‚ñç        | 457/3257 [00:02<00:16, 173.08it/s] 15%|‚ñà‚ñç        | 476/3257 [00:02<00:15, 174.49it/s] 15%|‚ñà‚ñå        | 497/3257 [00:02<00:15, 183.42it/s] 16%|‚ñà‚ñå        | 518/3257 [00:02<00:14, 188.86it/s] 17%|‚ñà‚ñã        | 538/3257 [00:02<00:14, 185.86it/s] 17%|‚ñà‚ñã        | 557/3257 [00:02<00:14, 186.01it/s] 18%|‚ñà‚ñä        | 576/3257 [00:03<00:16, 162.58it/s] 18%|‚ñà‚ñä        | 598/3257 [00:03<00:15, 177.12it/s] 19%|‚ñà‚ñâ        | 618/3257 [00:03<00:14, 182.97it/s] 20%|‚ñà‚ñâ        | 637/3257 [00:03<00:14, 178.38it/s] 20%|‚ñà‚ñà        | 656/3257 [00:03<00:15, 165.33it/s] 21%|‚ñà‚ñà        | 676/3257 [00:03<00:14, 172.24it/s] 21%|‚ñà‚ñà‚ñè       | 694/3257 [00:03<00:14, 171.45it/s] 22%|‚ñà‚ñà‚ñè       | 715/3257 [00:03<00:14, 180.45it/s] 23%|‚ñà‚ñà‚ñé       | 734/3257 [00:03<00:14, 170.52it/s] 23%|‚ñà‚ñà‚ñé       | 752/3257 [00:04<00:14, 170.66it/s] 24%|‚ñà‚ñà‚ñé       | 772/3257 [00:04<00:13, 178.09it/s] 24%|‚ñà‚ñà‚ñç       | 790/3257 [00:04<00:13, 178.18it/s] 25%|‚ñà‚ñà‚ñç       | 809/3257 [00:04<00:13, 180.02it/s] 25%|‚ñà‚ñà‚ñå       | 828/3257 [00:04<00:13, 176.11it/s] 26%|‚ñà‚ñà‚ñå       | 846/3257 [00:04<00:14, 167.33it/s] 27%|‚ñà‚ñà‚ñã       | 865/3257 [00:04<00:13, 172.97it/s] 27%|‚ñà‚ñà‚ñã       | 883/3257 [00:04<00:13, 170.02it/s] 28%|‚ñà‚ñà‚ñä       | 904/3257 [00:04<00:13, 179.87it/s] 28%|‚ñà‚ñà‚ñä       | 923/3257 [00:04<00:12, 179.97it/s] 29%|‚ñà‚ñà‚ñâ       | 942/3257 [00:05<00:13, 176.77it/s] 30%|‚ñà‚ñà‚ñâ       | 963/3257 [00:05<00:12, 184.61it/s] 30%|‚ñà‚ñà‚ñà       | 982/3257 [00:05<00:12, 177.87it/s] 31%|‚ñà‚ñà‚ñà       | 1000/3257 [00:05<00:20, 111.87it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1019/3257 [00:05<00:17, 126.46it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1035/3257 [00:05<00:16, 131.58it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:05<00:16, 136.27it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1071/3257 [00:06<00:14, 152.06it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:06<00:14, 154.38it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:06<00:13, 156.60it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1122/3257 [00:06<00:13, 159.21it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:06<00:13, 157.50it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1157/3257 [00:06<00:12, 163.11it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:06<00:12, 164.50it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1192/3257 [00:06<00:13, 153.78it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1208/3257 [00:06<00:13, 148.61it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1230/3257 [00:07<00:12, 166.94it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:07<00:12, 163.47it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1267/3257 [00:07<00:11, 172.36it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1285/3257 [00:07<00:12, 156.56it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1303/3257 [00:07<00:12, 161.31it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1322/3257 [00:07<00:11, 168.70it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1343/3257 [00:07<00:10, 178.03it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1362/3257 [00:07<00:10, 173.84it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1380/3257 [00:07<00:10, 170.68it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1398/3257 [00:08<00:10, 169.08it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1421/3257 [00:08<00:09, 185.55it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1440/3257 [00:08<00:10, 176.46it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:08<00:09, 190.52it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1483/3257 [00:08<00:09, 192.09it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1506/3257 [00:08<00:08, 200.96it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1527/3257 [00:08<00:09, 183.41it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:08<00:09, 172.76it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1565/3257 [00:08<00:09, 176.86it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1583/3257 [00:09<00:09, 177.12it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1604/3257 [00:09<00:09, 183.60it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1623/3257 [00:09<00:08, 182.80it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1642/3257 [00:09<00:09, 178.60it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1660/3257 [00:09<00:09, 175.67it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1678/3257 [00:09<00:09, 160.67it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1695/3257 [00:09<00:09, 160.62it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:09<00:09, 168.30it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1732/3257 [00:09<00:09, 158.31it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1750/3257 [00:10<00:09, 162.90it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1769/3257 [00:10<00:08, 169.22it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1789/3257 [00:10<00:08, 177.59it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1807/3257 [00:10<00:08, 163.53it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:10<00:08, 170.15it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1845/3257 [00:10<00:08, 175.63it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1865/3257 [00:10<00:07, 181.26it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1884/3257 [00:10<00:07, 182.71it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1903/3257 [00:10<00:07, 183.54it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1922/3257 [00:10<00:07, 179.83it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1946/3257 [00:11<00:06, 197.01it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1968/3257 [00:11<00:06, 203.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1989/3257 [00:11<00:06, 189.49it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2009/3257 [00:11<00:06, 191.00it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2032/3257 [00:11<00:06, 198.74it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2053/3257 [00:11<00:06, 179.76it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2072/3257 [00:11<00:06, 176.65it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:11<00:06, 179.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2110/3257 [00:11<00:06, 177.83it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2128/3257 [00:12<00:06, 168.87it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2146/3257 [00:12<00:06, 163.21it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:12<00:10, 102.71it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:12<00:09, 117.22it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2202/3257 [00:12<00:07, 135.13it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2218/3257 [00:12<00:07, 140.63it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:12<00:06, 147.77it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2253/3257 [00:13<00:06, 151.37it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:13<00:06, 151.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2291/3257 [00:13<00:05, 164.93it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2310/3257 [00:13<00:05, 170.90it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2336/3257 [00:13<00:04, 194.72it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:13<00:04, 206.35it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2381/3257 [00:13<00:04, 207.14it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:13<00:04, 210.72it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2426/3257 [00:13<00:04, 196.83it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2446/3257 [00:14<00:04, 188.25it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2469/3257 [00:14<00:03, 197.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2490/3257 [00:14<00:03, 200.84it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2515/3257 [00:14<00:03, 213.07it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2537/3257 [00:14<00:03, 214.12it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2559/3257 [00:14<00:03, 200.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2580/3257 [00:14<00:03, 187.02it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:14<00:03, 179.55it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2623/3257 [00:14<00:03, 191.65it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2643/3257 [00:15<00:03, 180.08it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2662/3257 [00:15<00:03, 164.61it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2681/3257 [00:15<00:03, 169.33it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2699/3257 [00:15<00:03, 152.21it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2715/3257 [00:15<00:03, 145.94it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2737/3257 [00:15<00:03, 162.95it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:15<00:02, 167.84it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:15<00:03, 154.77it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2793/3257 [00:16<00:02, 163.80it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2810/3257 [00:16<00:02, 160.31it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2827/3257 [00:16<00:02, 149.66it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2843/3257 [00:16<00:02, 148.19it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2862/3257 [00:16<00:02, 159.08it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2881/3257 [00:16<00:02, 166.50it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2898/3257 [00:16<00:02, 150.54it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2914/3257 [00:16<00:02, 152.39it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2930/3257 [00:16<00:02, 148.02it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2946/3257 [00:17<00:02, 144.71it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2961/3257 [00:17<00:02, 144.89it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:17<00:01, 141.71it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2991/3257 [00:17<00:01, 140.51it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:17<00:01, 155.75it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3027/3257 [00:17<00:01, 148.81it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3044/3257 [00:17<00:01, 154.39it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:17<00:01, 163.97it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3081/3257 [00:17<00:01, 167.28it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3099/3257 [00:18<00:00, 169.12it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3120/3257 [00:18<00:00, 180.01it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3139/3257 [00:18<00:00, 171.82it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3157/3257 [00:18<00:00, 164.78it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3174/3257 [00:18<00:00, 166.02it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3191/3257 [00:18<00:00, 163.27it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3208/3257 [00:18<00:00, 161.16it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3225/3257 [00:18<00:00, 160.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3245/3257 [00:18<00:00, 170.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 171.76it/s]
2023-02-07 18:57:41.181 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:57:41,183][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d222,n5,w19,mc5,s0.407067,t4>', 'datetime': '2023-02-07T18:57:41.183247', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:57:41,183][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:57:41,183][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:57:41,776][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 18:57:41,777][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:57:41,846][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 21312 unique words (49.91% of original 42701, drops 21389)', 'datetime': '2023-02-07T18:57:41.846207', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:57:41,848][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5769229 word corpus (99.08% of original 5822992, drops 53763)', 'datetime': '2023-02-07T18:57:41.848033', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:57:41,927][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 18:57:41,928][gensim.models.word2vec][INFO] - sample=0.407067 downsamples 0 most-common words
[2023-02-07 18:57:41,928][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5769229 word corpus (100.0%% of prior 5769229)', 'datetime': '2023-02-07T18:57:41.928765', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:57:42,066][gensim.models.word2vec][INFO] - estimated required memory for 21312 words and 222 dimensions: 52049728 bytes
[2023-02-07 18:57:42,067][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 18:57:42,092][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 21312 vocabulary and 222 features, using sg=0 hs=0 sample=0.407066895385145 negative=5 window=19 shrink_windows=True', 'datetime': '2023-02-07T18:57:42.092462', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 18:57:43,096][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 17.68% examples, 998623 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:44,099][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 34.85% examples, 1012329 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:45,099][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 53.33% examples, 1045233 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:46,101][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 75.90% examples, 1102228 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:47,122][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 96.56% examples, 1104668 words/s, in_qsize 6, out_qsize 1
[2023-02-07 18:57:47,281][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5743174 effective words) took 5.2s, 1107329 effective words/s
[2023-02-07 18:57:48,285][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 20.08% examples, 1127018 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:57:49,296][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 38.29% examples, 1116913 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:50,301][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 57.66% examples, 1120119 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:51,304][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 77.96% examples, 1123122 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:52,306][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 97.88% examples, 1120718 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:52,397][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5743174 effective words) took 5.1s, 1122881 effective words/s
[2023-02-07 18:57:53,407][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 20.08% examples, 1121306 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:54,424][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 38.99% examples, 1128495 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:57:55,426][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 58.80% examples, 1137457 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:56,433][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 79.06% examples, 1136829 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:57,424][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5743174 effective words) took 5.0s, 1142604 effective words/s
[2023-02-07 18:57:58,427][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 20.66% examples, 1166635 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:57:59,434][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 39.36% examples, 1157067 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:00,438][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 57.02% examples, 1112136 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:01,445][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 74.95% examples, 1087827 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:02,447][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 93.28% examples, 1073234 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:02,786][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5743174 effective words) took 5.4s, 1071594 effective words/s
[2023-02-07 18:58:03,790][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 18.05% examples, 1016735 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:04,791][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 34.97% examples, 1017751 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:05,811][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 52.29% examples, 1014887 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:58:06,818][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 69.88% examples, 1020097 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:07,822][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 89.01% examples, 1022002 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:58:08,349][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5743174 effective words) took 5.6s, 1032829 effective words/s
[2023-02-07 18:58:09,354][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 22.57% examples, 1275491 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:10,358][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 41.26% examples, 1210333 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:11,367][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 61.01% examples, 1180328 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:58:12,375][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 81.55% examples, 1172821 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:13,279][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5743174 effective words) took 4.9s, 1165150 effective words/s
[2023-02-07 18:58:14,294][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 20.08% examples, 1116463 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:15,295][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.81% examples, 1130534 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:16,309][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 58.21% examples, 1127645 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:17,321][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 78.78% examples, 1130984 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:18,326][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 99.36% examples, 1131541 words/s, in_qsize 5, out_qsize 0
[2023-02-07 18:58:18,354][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5743174 effective words) took 5.1s, 1131997 effective words/s
[2023-02-07 18:58:19,357][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 20.42% examples, 1156822 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:58:20,364][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 39.36% examples, 1156791 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:21,365][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 57.88% examples, 1129744 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:22,370][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 76.14% examples, 1104242 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:23,375][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 95.00% examples, 1089673 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:23,638][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5743174 effective words) took 5.3s, 1087192 effective words/s
[2023-02-07 18:58:24,664][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 18.24% examples, 1004295 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:58:25,672][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 35.49% examples, 1018939 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:26,674][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 52.59% examples, 1017351 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:27,674][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 70.34% examples, 1024076 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:28,678][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 89.13% examples, 1023435 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:29,243][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5743174 effective words) took 5.6s, 1025221 effective words/s
[2023-02-07 18:58:30,247][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 21.40% examples, 1211767 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:31,270][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 41.42% examples, 1204926 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:32,287][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 61.71% examples, 1182859 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:58:33,288][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 81.82% examples, 1171939 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:34,176][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5743174 effective words) took 4.9s, 1164743 effective words/s
[2023-02-07 18:58:35,182][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 19.83% examples, 1107217 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:36,187][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 38.29% examples, 1118941 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:37,198][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 58.03% examples, 1127391 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:38,199][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 78.69% examples, 1135401 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:39,201][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 98.89% examples, 1132673 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:39,238][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5743174 effective words) took 5.1s, 1134796 effective words/s
[2023-02-07 18:58:40,251][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 20.42% examples, 1145622 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:41,274][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 39.94% examples, 1159424 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:42,279][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 58.15% examples, 1123606 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:58:43,286][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 76.76% examples, 1102472 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:44,290][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 95.64% examples, 1088273 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:44,524][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5743174 effective words) took 5.3s, 1086784 effective words/s
[2023-02-07 18:58:45,527][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 18.05% examples, 1018788 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:46,527][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 35.09% examples, 1023015 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:58:47,531][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 52.04% examples, 1018225 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:48,541][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 69.88% examples, 1024108 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:49,558][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 89.71% examples, 1029277 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:50,080][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5743174 effective words) took 5.6s, 1034139 effective words/s
[2023-02-07 18:58:51,084][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 22.11% examples, 1250345 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:52,089][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 41.42% examples, 1216040 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:53,108][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 61.71% examples, 1189504 words/s, in_qsize 8, out_qsize 0
[2023-02-07 18:58:54,109][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 82.16% examples, 1181179 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:54,992][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5743174 effective words) took 4.9s, 1169753 effective words/s
[2023-02-07 18:58:55,994][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 20.08% examples, 1130264 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:56,995][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 38.81% examples, 1137739 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:58,001][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 58.21% examples, 1135467 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:58:59,003][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 78.54% examples, 1136095 words/s, in_qsize 7, out_qsize 0
[2023-02-07 18:59:00,010][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 99.72% examples, 1140983 words/s, in_qsize 2, out_qsize 1
[2023-02-07 18:59:00,020][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5743174 effective words) took 5.0s, 1142513 effective words/s
[2023-02-07 18:59:00,021][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86147610 effective words) took 77.9s, 1105473 effective words/s', 'datetime': '2023-02-07T18:59:00.021179', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 18:59:00.021 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 18:59:06,049][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185713-imosvvvc/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T18:59:06.049292', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 18:59:06,051][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 18:59:06,121][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185713-imosvvvc/files/../tmp/embedding_model.pt
2023-02-07 18:59:06.121 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 18:59:07.953 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 18:59:08.628 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 18:59:10.271 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.086156762989105, 'test_mae': 0.8082283604090199, 'test_r2': -2.8307410837029803}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.59
wandb: percentage 0.5009
wandb:   test_mae 0.80823
wandb:   test_mse 1.08616
wandb:    test_r2 -2.83074
wandb: 
wandb: üöÄ View run vibrant-sweep-23 at: https://wandb.ai/xiaoqiz/mof2vec/runs/imosvvvc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_185713-imosvvvc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: olhhpwuf with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 692
wandb: 	model.gensim.alpha: 0.057156342705702926
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.6100145243217152
wandb: 	model.gensim.vector_size: 327
wandb: 	model.gensim.window: 7
wandb: 	model.sklearn.learning_rate: 0.0029376101649155532
wandb: 	model.sklearn.max_depth: 58
wandb: 	model.sklearn.min_child_weight: 0.03866962922644528
wandb: 	model.sklearn.n_estimators: 2717
wandb: 	model.sklearn.num_leaves: 187
wandb: 	model.sklearn.reg_alpha: 0.18833468062309988
wandb: 	model.sklearn.reg_lambda: 0.012048815735123944
wandb: 	model.sklearn.subsample: 0.7011762993189283
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185930-olhhpwuf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/olhhpwuf
2023-02-07 18:59:38.147 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 18:59:38.147 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 692 for sweep.
2023-02-07 18:59:38.148 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.057156342705702926 for sweep.
2023-02-07 18:59:38.148 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 18:59:38.148 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 18:59:38.148 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6100145243217152 for sweep.
2023-02-07 18:59:38.148 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 327 for sweep.
2023-02-07 18:59:38.149 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 7 for sweep.
2023-02-07 18:59:38.149 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0029376101649155532 for sweep.
2023-02-07 18:59:38.149 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 58 for sweep.
2023-02-07 18:59:38.150 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03866962922644528 for sweep.
2023-02-07 18:59:38.150 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2717 for sweep.
2023-02-07 18:59:38.150 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 187 for sweep.
2023-02-07 18:59:38.150 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.18833468062309988 for sweep.
2023-02-07 18:59:38.151 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.012048815735123944 for sweep.
2023-02-07 18:59:38.151 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7011762993189283 for sweep.
2023-02-07 18:59:38.151 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 18:59:38.156 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185930-olhhpwuf/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 692, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 327, 'window': 7, 'min_count': 1, 'dm': 1, 'sample': 0.6100145243217152, 'workers': 4, 'alpha': 0.057156342705702926, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2717, 'max_depth': 58, 'num_leaves': 187, 'reg_alpha': 0.18833468062309988, 'reg_lambda': 0.012048815735123944, 'subsample': 0.7011762993189283, 'min_child_weight': 0.03866962922644528, 'n_jobs': 4, 'learning_rate': 0.0029376101649155532}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 167.93it/s]  1%|          | 37/3257 [00:00<00:17, 183.15it/s]  2%|‚ñè         | 56/3257 [00:00<00:17, 178.11it/s]  2%|‚ñè         | 79/3257 [00:00<00:16, 194.99it/s]  3%|‚ñé         | 99/3257 [00:00<00:16, 191.24it/s]  4%|‚ñé         | 119/3257 [00:00<00:16, 186.94it/s]  4%|‚ñç         | 141/3257 [00:00<00:16, 194.33it/s]  5%|‚ñç         | 162/3257 [00:00<00:15, 193.47it/s]  6%|‚ñå         | 182/3257 [00:00<00:15, 195.02it/s]  6%|‚ñå         | 202/3257 [00:01<00:15, 192.55it/s]  7%|‚ñã         | 223/3257 [00:01<00:15, 197.12it/s]  7%|‚ñã         | 243/3257 [00:01<00:15, 193.37it/s]  8%|‚ñä         | 263/3257 [00:01<00:16, 180.57it/s]  9%|‚ñâ         | 285/3257 [00:01<00:15, 189.64it/s]  9%|‚ñâ         | 305/3257 [00:01<00:24, 119.90it/s] 10%|‚ñâ         | 325/3257 [00:01<00:21, 135.66it/s] 11%|‚ñà         | 342/3257 [00:02<00:21, 136.95it/s] 11%|‚ñà         | 361/3257 [00:02<00:19, 148.82it/s] 12%|‚ñà‚ñè        | 378/3257 [00:02<00:20, 143.31it/s] 12%|‚ñà‚ñè        | 394/3257 [00:02<00:19, 145.82it/s] 13%|‚ñà‚ñé        | 413/3257 [00:02<00:18, 157.02it/s] 13%|‚ñà‚ñé        | 430/3257 [00:02<00:20, 138.53it/s] 14%|‚ñà‚ñé        | 447/3257 [00:02<00:19, 141.90it/s] 14%|‚ñà‚ñç        | 467/3257 [00:02<00:18, 153.79it/s] 15%|‚ñà‚ñç        | 483/3257 [00:02<00:18, 151.03it/s] 15%|‚ñà‚ñå        | 503/3257 [00:03<00:16, 163.67it/s] 16%|‚ñà‚ñå        | 522/3257 [00:03<00:16, 164.82it/s] 17%|‚ñà‚ñã        | 539/3257 [00:03<00:16, 164.20it/s] 17%|‚ñà‚ñã        | 556/3257 [00:03<00:16, 165.79it/s] 18%|‚ñà‚ñä        | 573/3257 [00:03<00:18, 142.24it/s] 18%|‚ñà‚ñä        | 593/3257 [00:03<00:17, 155.85it/s] 19%|‚ñà‚ñâ        | 612/3257 [00:03<00:16, 164.52it/s] 19%|‚ñà‚ñâ        | 630/3257 [00:03<00:16, 162.01it/s] 20%|‚ñà‚ñâ        | 647/3257 [00:03<00:16, 156.17it/s] 20%|‚ñà‚ñà        | 663/3257 [00:04<00:17, 149.01it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:17, 151.36it/s] 21%|‚ñà‚ñà‚ñè       | 699/3257 [00:04<00:16, 153.38it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:15, 163.08it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:04<00:16, 153.50it/s] 23%|‚ñà‚ñà‚ñé       | 751/3257 [00:04<00:17, 146.68it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:04<00:15, 156.64it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:04<00:16, 151.51it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:15, 157.31it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:15, 155.21it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:05<00:16, 147.01it/s] 26%|‚ñà‚ñà‚ñå       | 851/3257 [00:05<00:17, 141.16it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:05<00:16, 145.34it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:05<00:16, 141.78it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:15, 156.14it/s] 28%|‚ñà‚ñà‚ñä       | 923/3257 [00:05<00:14, 161.02it/s] 29%|‚ñà‚ñà‚ñâ       | 940/3257 [00:05<00:14, 156.98it/s] 29%|‚ñà‚ñà‚ñâ       | 958/3257 [00:06<00:14, 161.82it/s] 30%|‚ñà‚ñà‚ñâ       | 975/3257 [00:06<00:14, 160.78it/s] 30%|‚ñà‚ñà‚ñà       | 992/3257 [00:06<00:14, 153.92it/s] 31%|‚ñà‚ñà‚ñà       | 1008/3257 [00:06<00:15, 147.65it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1026/3257 [00:06<00:14, 154.03it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1042/3257 [00:06<00:15, 140.64it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1057/3257 [00:06<00:15, 142.13it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1076/3257 [00:06<00:14, 154.94it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1092/3257 [00:06<00:15, 143.03it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1110/3257 [00:07<00:14, 152.84it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1126/3257 [00:07<00:14, 146.94it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1141/3257 [00:07<00:14, 143.88it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1158/3257 [00:07<00:14, 149.82it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:07<00:13, 150.21it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:07<00:15, 136.55it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:07<00:15, 134.96it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1220/3257 [00:07<00:14, 138.70it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:07<00:12, 155.23it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:08<00:13, 148.72it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1273/3257 [00:08<00:13, 151.65it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1289/3257 [00:08<00:14, 138.45it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1304/3257 [00:08<00:13, 140.85it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:08<00:13, 148.74it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:08<00:12, 155.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1355/3257 [00:08<00:12, 148.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:08<00:12, 147.34it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:08<00:13, 143.33it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:09<00:12, 149.05it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:09<00:11, 160.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1440/3257 [00:09<00:11, 158.70it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1462/3257 [00:09<00:10, 173.78it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1480/3257 [00:09<00:10, 170.75it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1500/3257 [00:09<00:09, 176.66it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1518/3257 [00:09<00:10, 173.50it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1536/3257 [00:09<00:10, 162.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1554/3257 [00:09<00:10, 165.26it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:10<00:09, 171.22it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1597/3257 [00:10<00:09, 184.32it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:10<00:08, 191.64it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:10<00:13, 124.45it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:10<00:11, 134.23it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:10<00:10, 145.13it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1694/3257 [00:10<00:10, 153.37it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:10<00:09, 165.42it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1733/3257 [00:11<00:09, 158.89it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1752/3257 [00:11<00:09, 166.85it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1774/3257 [00:11<00:08, 177.55it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1795/3257 [00:11<00:07, 185.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1815/3257 [00:11<00:08, 178.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1834/3257 [00:11<00:07, 178.22it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1855/3257 [00:11<00:07, 184.03it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1877/3257 [00:11<00:07, 193.92it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:11<00:07, 184.68it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:12<00:07, 185.30it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:12<00:07, 188.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:12<00:06, 202.46it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:12<00:06, 191.74it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2002/3257 [00:12<00:06, 192.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:12<00:06, 190.32it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2042/3257 [00:12<00:06, 181.22it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2061/3257 [00:12<00:07, 165.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2082/3257 [00:12<00:06, 175.84it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:13<00:06, 166.29it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:13<00:06, 168.25it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2138/3257 [00:13<00:06, 168.26it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2155/3257 [00:13<00:06, 165.16it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2176/3257 [00:13<00:06, 176.18it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2194/3257 [00:13<00:06, 170.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2212/3257 [00:13<00:06, 163.16it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2233/3257 [00:13<00:05, 174.49it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2251/3257 [00:13<00:05, 170.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2269/3257 [00:14<00:05, 170.15it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2288/3257 [00:14<00:05, 172.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2306/3257 [00:14<00:05, 169.72it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2330/3257 [00:14<00:04, 187.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2354/3257 [00:14<00:04, 201.83it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2375/3257 [00:14<00:04, 195.59it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2398/3257 [00:14<00:04, 202.85it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2419/3257 [00:14<00:04, 189.29it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2439/3257 [00:14<00:04, 182.52it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2458/3257 [00:15<00:04, 182.43it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2479/3257 [00:15<00:04, 188.51it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2501/3257 [00:15<00:03, 197.06it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2521/3257 [00:15<00:03, 195.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2541/3257 [00:15<00:03, 188.12it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2560/3257 [00:15<00:03, 183.31it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2579/3257 [00:15<00:03, 169.69it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2597/3257 [00:15<00:03, 171.91it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2622/3257 [00:15<00:03, 192.62it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2642/3257 [00:16<00:03, 188.22it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2662/3257 [00:16<00:03, 175.43it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2683/3257 [00:16<00:03, 184.68it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2702/3257 [00:16<00:03, 163.13it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:16<00:03, 163.02it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:16<00:02, 177.33it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2760/3257 [00:16<00:02, 180.09it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:16<00:02, 172.05it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2802/3257 [00:16<00:02, 186.06it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2821/3257 [00:17<00:02, 177.28it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2839/3257 [00:17<00:02, 166.87it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2863/3257 [00:17<00:02, 186.13it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:17<00:01, 192.15it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:17<00:01, 179.12it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:17<00:01, 181.81it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:17<00:01, 175.07it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2965/3257 [00:17<00:01, 175.56it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2983/3257 [00:18<00:01, 163.60it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:18<00:01, 175.42it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3022/3257 [00:18<00:01, 172.52it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3044/3257 [00:18<00:01, 185.01it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3067/3257 [00:18<00:00, 195.20it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3087/3257 [00:18<00:00, 191.73it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:18<00:00, 202.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3131/3257 [00:18<00:00, 197.98it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3151/3257 [00:18<00:00, 186.88it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3170/3257 [00:19<00:00, 107.60it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:19<00:00, 113.70it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:19<00:00, 126.37it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3219/3257 [00:19<00:00, 126.31it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3238/3257 [00:19<00:00, 141.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3254/3257 [00:19<00:00, 142.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 164.32it/s]
2023-02-07 18:59:58.831 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 18:59:58,833][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d327,n5,w7,s0.610015,t4>', 'datetime': '2023-02-07T18:59:58.833032', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 18:59:58,833][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 18:59:58,833][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 18:59:59,429][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 18:59:59,429][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 18:59:59,551][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 42701 unique words (100.00% of original 42701, drops 0)', 'datetime': '2023-02-07T18:59:59.551012', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:59:59,551][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 5822992 word corpus (100.00% of original 5822992, drops 0)', 'datetime': '2023-02-07T18:59:59.551573', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:59:59,712][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 18:59:59,714][gensim.models.word2vec][INFO] - sample=0.610015 downsamples 0 most-common words
[2023-02-07 18:59:59,714][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5822992 word corpus (100.0%% of prior 5822992)', 'datetime': '2023-02-07T18:59:59.714761', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 18:59:59,991][gensim.models.word2vec][INFO] - estimated required memory for 42701 words and 327 dimensions: 137967872 bytes
[2023-02-07 18:59:59,991][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:00:00,060][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 42701 vocabulary and 327 features, using sg=0 hs=0 sample=0.6100145243217152 negative=5 window=7 shrink_windows=True', 'datetime': '2023-02-07T19:00:00.060301', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:00:01,065][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 21.58% examples, 1231211 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:00:02,075][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 43.94% examples, 1295124 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:03,076][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 67.24% examples, 1319764 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:04,085][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 91.43% examples, 1326016 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:04,419][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5795785 effective words) took 4.4s, 1330465 effective words/s
[2023-02-07 19:00:05,425][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 23.79% examples, 1362943 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:06,430][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 46.76% examples, 1373488 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:07,430][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 76.51% examples, 1492735 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:08,240][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5795785 effective words) took 3.8s, 1517700 effective words/s
[2023-02-07 19:00:09,245][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 27.11% examples, 1572945 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:10,247][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 53.21% examples, 1576104 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:11,251][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 81.03% examples, 1571653 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:11,925][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5795785 effective words) took 3.7s, 1573546 effective words/s
[2023-02-07 19:00:12,931][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 27.23% examples, 1582097 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:13,934][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 54.04% examples, 1597415 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:14,938][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 82.56% examples, 1603839 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:00:15,528][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5795785 effective words) took 3.6s, 1609555 effective words/s
[2023-02-07 19:00:16,531][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 25.70% examples, 1486412 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:17,538][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 49.09% examples, 1446193 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:00:18,544][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 73.84% examples, 1440683 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:19,549][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 99.72% examples, 1436942 words/s, in_qsize 2, out_qsize 1
[2023-02-07 19:00:19,558][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5795785 effective words) took 4.0s, 1438874 effective words/s
[2023-02-07 19:00:20,559][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 24.26% examples, 1396103 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:21,567][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 47.74% examples, 1409973 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:22,569][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 72.92% examples, 1425957 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:23,569][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 98.53% examples, 1425115 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:23,623][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5795785 effective words) took 4.1s, 1426221 effective words/s
[2023-02-07 19:00:24,629][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 24.96% examples, 1430862 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:25,631][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.45% examples, 1584912 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:26,632][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 86.15% examples, 1673601 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:27,039][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5795785 effective words) took 3.4s, 1697754 effective words/s
[2023-02-07 19:00:28,043][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 30.92% examples, 1802298 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:29,047][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 59.69% examples, 1755092 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:30,051][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 88.64% examples, 1716471 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:30,428][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5795785 effective words) took 3.4s, 1710759 effective words/s
[2023-02-07 19:00:31,430][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 28.34% examples, 1644453 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:32,432][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 54.77% examples, 1619931 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:33,433][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 84.03% examples, 1637879 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:33,968][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5795785 effective words) took 3.5s, 1638256 effective words/s
[2023-02-07 19:00:34,971][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 28.06% examples, 1633659 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:35,972][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 55.45% examples, 1642112 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:36,974][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 84.89% examples, 1651994 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:37,473][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5795785 effective words) took 3.5s, 1654318 effective words/s
[2023-02-07 19:00:38,479][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 28.58% examples, 1655201 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:39,480][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 55.82% examples, 1651876 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:40,482][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 84.89% examples, 1650141 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:40,976][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5795785 effective words) took 3.5s, 1655158 effective words/s
[2023-02-07 19:00:41,986][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 28.89% examples, 1666920 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:00:42,993][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 56.83% examples, 1672875 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:43,995][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 86.25% examples, 1669757 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:00:44,442][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5795785 effective words) took 3.5s, 1673093 effective words/s
[2023-02-07 19:00:45,458][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 28.34% examples, 1621674 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:00:46,465][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 55.57% examples, 1631753 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:47,470][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 84.89% examples, 1640529 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:47,968][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5795785 effective words) took 3.5s, 1644518 effective words/s
[2023-02-07 19:00:48,974][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 28.34% examples, 1637538 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:49,976][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 55.57% examples, 1643649 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:00:50,982][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 84.89% examples, 1648035 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:00:51,479][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5795785 effective words) took 3.5s, 1651550 effective words/s
[2023-02-07 19:00:52,480][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 28.34% examples, 1644859 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:53,482][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 55.76% examples, 1652554 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:54,483][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 84.99% examples, 1656292 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:00:54,974][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5795785 effective words) took 3.5s, 1658667 effective words/s
[2023-02-07 19:00:54,975][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86936775 effective words) took 54.9s, 1583117 effective words/s', 'datetime': '2023-02-07T19:00:54.975663', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:00:54.975 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:00:59,513][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185930-olhhpwuf/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:00:59.513429', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:00:59,514][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185930-olhhpwuf/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 19:00:59,571][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185930-olhhpwuf/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 19:00:59,623][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:00:59,668][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_185930-olhhpwuf/files/../tmp/embedding_model.pt
2023-02-07 19:00:59.670 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:01:01.756 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:01:02.464 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:01:04.803 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0936237762126864, 'test_mae': 0.8161183559547173, 'test_r2': -3.197669966107317}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.8
wandb: percentage 0.0
wandb:   test_mae 0.81612
wandb:   test_mse 1.09362
wandb:    test_r2 -3.19767
wandb: 
wandb: üöÄ View run skilled-sweep-24 at: https://wandb.ai/xiaoqiz/mof2vec/runs/olhhpwuf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_185930-olhhpwuf/logs
wandb: Agent Starting Run: 7snlzssx with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 942
wandb: 	model.gensim.alpha: 0.0027432483619574673
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.9099651820649156
wandb: 	model.gensim.vector_size: 353
wandb: 	model.gensim.window: 12
wandb: 	model.sklearn.learning_rate: 0.1295330807734821
wandb: 	model.sklearn.max_depth: 68
wandb: 	model.sklearn.min_child_weight: 0.01801632804008957
wandb: 	model.sklearn.n_estimators: 1685
wandb: 	model.sklearn.num_leaves: 57
wandb: 	model.sklearn.reg_alpha: 0.09422005074689715
wandb: 	model.sklearn.reg_lambda: 0.007748472758426423
wandb: 	model.sklearn.subsample: 0.7888438850496882
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190115-7snlzssx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-25
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/7snlzssx
2023-02-07 19:01:23.582 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:01:23.583 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 942 for sweep.
2023-02-07 19:01:23.583 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0027432483619574673 for sweep.
2023-02-07 19:01:23.583 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:01:23.583 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 19:01:23.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9099651820649156 for sweep.
2023-02-07 19:01:23.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 353 for sweep.
2023-02-07 19:01:23.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 12 for sweep.
2023-02-07 19:01:23.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.1295330807734821 for sweep.
2023-02-07 19:01:23.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 68 for sweep.
2023-02-07 19:01:23.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.01801632804008957 for sweep.
2023-02-07 19:01:23.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1685 for sweep.
2023-02-07 19:01:23.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 57 for sweep.
2023-02-07 19:01:23.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.09422005074689715 for sweep.
2023-02-07 19:01:23.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.007748472758426423 for sweep.
2023-02-07 19:01:23.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7888438850496882 for sweep.
2023-02-07 19:01:23.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:01:23.593 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190115-7snlzssx/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 942, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 353, 'window': 12, 'min_count': 9, 'dm': 1, 'sample': 0.9099651820649156, 'workers': 4, 'alpha': 0.0027432483619574673, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1685, 'max_depth': 68, 'num_leaves': 57, 'reg_alpha': 0.09422005074689715, 'reg_lambda': 0.007748472758426423, 'subsample': 0.7888438850496882, 'min_child_weight': 0.01801632804008957, 'n_jobs': 4, 'learning_rate': 0.1295330807734821}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:25, 126.51it/s]  1%|          | 30/3257 [00:00<00:21, 148.11it/s]  1%|‚ñè         | 46/3257 [00:00<00:20, 153.04it/s]  2%|‚ñè         | 62/3257 [00:00<00:20, 153.27it/s]  2%|‚ñè         | 80/3257 [00:00<00:19, 160.99it/s]  3%|‚ñé         | 97/3257 [00:00<00:19, 158.55it/s]  3%|‚ñé         | 113/3257 [00:00<00:20, 156.00it/s]  4%|‚ñç         | 131/3257 [00:00<00:19, 160.49it/s]  5%|‚ñç         | 150/3257 [00:00<00:18, 167.58it/s]  5%|‚ñå         | 167/3257 [00:01<00:20, 148.80it/s]  6%|‚ñå         | 183/3257 [00:01<00:21, 143.24it/s]  6%|‚ñå         | 198/3257 [00:01<00:21, 141.67it/s]  7%|‚ñã         | 214/3257 [00:01<00:20, 145.37it/s]  7%|‚ñã         | 230/3257 [00:01<00:20, 149.01it/s]  8%|‚ñä         | 246/3257 [00:01<00:20, 144.88it/s]  8%|‚ñä         | 261/3257 [00:01<00:22, 133.82it/s]  9%|‚ñä         | 279/3257 [00:01<00:20, 145.33it/s]  9%|‚ñâ         | 295/3257 [00:01<00:20, 147.82it/s] 10%|‚ñâ         | 310/3257 [00:02<00:20, 140.62it/s] 10%|‚ñà         | 326/3257 [00:02<00:20, 144.74it/s] 10%|‚ñà         | 341/3257 [00:02<00:21, 133.99it/s] 11%|‚ñà         | 356/3257 [00:02<00:21, 137.91it/s] 11%|‚ñà‚ñè        | 370/3257 [00:02<00:21, 135.11it/s] 12%|‚ñà‚ñè        | 384/3257 [00:02<00:22, 126.29it/s] 12%|‚ñà‚ñè        | 397/3257 [00:02<00:22, 124.71it/s] 13%|‚ñà‚ñé        | 412/3257 [00:02<00:21, 131.40it/s] 13%|‚ñà‚ñé        | 426/3257 [00:03<00:24, 114.60it/s] 13%|‚ñà‚ñé        | 438/3257 [00:03<00:24, 115.20it/s] 14%|‚ñà‚ñç        | 451/3257 [00:03<00:23, 117.94it/s] 14%|‚ñà‚ñç        | 467/3257 [00:03<00:21, 128.75it/s] 15%|‚ñà‚ñç        | 481/3257 [00:03<00:22, 122.59it/s] 15%|‚ñà‚ñå        | 498/3257 [00:03<00:20, 133.39it/s] 16%|‚ñà‚ñå        | 513/3257 [00:03<00:20, 135.53it/s] 16%|‚ñà‚ñå        | 527/3257 [00:03<00:21, 129.52it/s] 17%|‚ñà‚ñã        | 543/3257 [00:03<00:20, 134.58it/s] 17%|‚ñà‚ñã        | 557/3257 [00:04<00:20, 133.84it/s] 18%|‚ñà‚ñä        | 571/3257 [00:04<00:23, 115.43it/s] 18%|‚ñà‚ñä        | 589/3257 [00:04<00:20, 131.08it/s] 19%|‚ñà‚ñä        | 610/3257 [00:04<00:17, 149.32it/s] 19%|‚ñà‚ñâ        | 626/3257 [00:04<00:17, 152.04it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:04<00:16, 159.55it/s] 20%|‚ñà‚ñà        | 661/3257 [00:04<00:17, 150.33it/s] 21%|‚ñà‚ñà        | 682/3257 [00:04<00:15, 165.44it/s] 21%|‚ñà‚ñà‚ñè       | 699/3257 [00:04<00:16, 158.03it/s] 22%|‚ñà‚ñà‚ñè       | 719/3257 [00:05<00:15, 167.03it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:05<00:16, 154.28it/s] 23%|‚ñà‚ñà‚ñé       | 752/3257 [00:05<00:16, 155.29it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:05<00:15, 159.07it/s] 24%|‚ñà‚ñà‚ñç       | 787/3257 [00:05<00:16, 148.00it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:16, 151.50it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:16, 148.39it/s] 26%|‚ñà‚ñà‚ñå       | 835/3257 [00:05<00:16, 143.75it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:05<00:17, 135.20it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:06<00:17, 139.96it/s] 27%|‚ñà‚ñà‚ñã       | 881/3257 [00:06<00:17, 139.31it/s] 28%|‚ñà‚ñà‚ñä       | 897/3257 [00:06<00:16, 144.24it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:06<00:16, 144.22it/s] 29%|‚ñà‚ñà‚ñä       | 932/3257 [00:06<00:15, 150.90it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:06<00:15, 153.23it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:06<00:14, 157.39it/s] 30%|‚ñà‚ñà‚ñà       | 982/3257 [00:06<00:15, 151.21it/s] 31%|‚ñà‚ñà‚ñà       | 998/3257 [00:06<00:15, 146.60it/s] 31%|‚ñà‚ñà‚ñà       | 1013/3257 [00:07<00:15, 144.90it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1028/3257 [00:07<00:15, 142.33it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1043/3257 [00:07<00:15, 140.09it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1059/3257 [00:07<00:15, 144.67it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1079/3257 [00:07<00:13, 158.77it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1095/3257 [00:07<00:15, 137.92it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1110/3257 [00:07<00:15, 140.79it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1125/3257 [00:07<00:16, 131.51it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:08<00:16, 126.84it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1152/3257 [00:08<00:17, 123.66it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1168/3257 [00:08<00:15, 132.17it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1182/3257 [00:08<00:17, 118.04it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1195/3257 [00:08<00:29, 69.40it/s]  37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:08<00:27, 74.61it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1217/3257 [00:08<00:24, 83.08it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1234/3257 [00:09<00:19, 101.74it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:09<00:19, 105.71it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1260/3257 [00:09<00:18, 110.81it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1273/3257 [00:09<00:17, 114.58it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1286/3257 [00:09<00:18, 106.06it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1299/3257 [00:09<00:17, 111.28it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:09<00:16, 116.82it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:09<00:15, 120.60it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1343/3257 [00:09<00:14, 128.28it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1357/3257 [00:10<00:15, 125.05it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:10<00:15, 122.17it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1383/3257 [00:10<00:15, 118.55it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1398/3257 [00:10<00:14, 126.14it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1413/3257 [00:10<00:13, 132.42it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1429/3257 [00:10<00:13, 138.75it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1443/3257 [00:10<00:13, 135.70it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1461/3257 [00:10<00:12, 147.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1479/3257 [00:10<00:11, 156.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1500/3257 [00:11<00:10, 171.88it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1518/3257 [00:11<00:10, 173.81it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1536/3257 [00:11<00:10, 158.51it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1553/3257 [00:11<00:10, 157.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1572/3257 [00:11<00:10, 165.11it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1589/3257 [00:11<00:10, 165.15it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1609/3257 [00:11<00:09, 173.22it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1629/3257 [00:11<00:09, 178.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1647/3257 [00:11<00:09, 162.02it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1664/3257 [00:12<00:10, 155.24it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1680/3257 [00:12<00:10, 155.20it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1696/3257 [00:12<00:10, 154.09it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1714/3257 [00:12<00:09, 160.79it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:12<00:10, 146.17it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1746/3257 [00:12<00:10, 146.43it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1764/3257 [00:12<00:09, 153.47it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1782/3257 [00:12<00:09, 159.85it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1799/3257 [00:12<00:09, 157.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1815/3257 [00:13<00:09, 150.82it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1831/3257 [00:13<00:09, 146.68it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1848/3257 [00:13<00:09, 152.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1867/3257 [00:13<00:08, 161.77it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1884/3257 [00:13<00:08, 156.79it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1900/3257 [00:13<00:08, 156.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1917/3257 [00:13<00:08, 157.85it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:13<00:07, 167.15it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:13<00:06, 185.85it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1980/3257 [00:14<00:07, 175.98it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1998/3257 [00:14<00:07, 168.94it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2016/3257 [00:14<00:08, 154.25it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:14<00:08, 152.35it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2049/3257 [00:14<00:08, 138.02it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2064/3257 [00:14<00:09, 129.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2078/3257 [00:14<00:09, 130.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2093/3257 [00:14<00:08, 133.80it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2107/3257 [00:14<00:08, 130.79it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:15<00:09, 121.00it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2135/3257 [00:15<00:08, 125.29it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2148/3257 [00:15<00:09, 118.43it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:15<00:08, 124.73it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:15<00:08, 127.28it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2192/3257 [00:15<00:08, 129.45it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2206/3257 [00:15<00:08, 130.13it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2220/3257 [00:15<00:08, 128.56it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2234/3257 [00:16<00:07, 130.92it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2248/3257 [00:16<00:08, 123.69it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2261/3257 [00:16<00:07, 124.66it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2274/3257 [00:16<00:08, 117.55it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2291/3257 [00:16<00:07, 130.25it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2305/3257 [00:16<00:07, 129.33it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2321/3257 [00:16<00:06, 135.97it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:16<00:06, 140.16it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2358/3257 [00:16<00:05, 158.06it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2374/3257 [00:17<00:06, 143.54it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2391/3257 [00:17<00:05, 150.05it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2407/3257 [00:17<00:06, 137.20it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2423/3257 [00:17<00:05, 141.90it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2438/3257 [00:17<00:05, 140.68it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2453/3257 [00:17<00:05, 142.81it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:17<00:04, 163.29it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2497/3257 [00:17<00:04, 175.74it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2515/3257 [00:18<00:07, 104.03it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2536/3257 [00:18<00:05, 123.24it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2552/3257 [00:18<00:05, 130.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2568/3257 [00:18<00:05, 127.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2584/3257 [00:18<00:05, 134.52it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2601/3257 [00:18<00:04, 142.83it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2624/3257 [00:18<00:03, 164.85it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2642/3257 [00:18<00:03, 164.70it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2660/3257 [00:19<00:03, 155.78it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2678/3257 [00:19<00:03, 161.59it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2695/3257 [00:19<00:03, 154.97it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2711/3257 [00:19<00:03, 144.79it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2730/3257 [00:19<00:03, 155.36it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2750/3257 [00:19<00:03, 166.67it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2768/3257 [00:19<00:03, 160.72it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2789/3257 [00:19<00:02, 173.24it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:19<00:02, 166.83it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2824/3257 [00:20<00:02, 159.41it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:20<00:02, 164.64it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2864/3257 [00:20<00:02, 179.30it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2884/3257 [00:20<00:02, 184.14it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:20<00:02, 155.09it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:20<00:02, 155.08it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2937/3257 [00:20<00:02, 151.01it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2953/3257 [00:20<00:02, 138.81it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:20<00:02, 141.27it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:21<00:02, 134.70it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3002/3257 [00:21<00:01, 144.02it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3017/3257 [00:21<00:01, 141.89it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3034/3257 [00:21<00:01, 147.81it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3051/3257 [00:21<00:01, 152.87it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3070/3257 [00:21<00:01, 162.60it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3087/3257 [00:21<00:01, 157.28it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3106/3257 [00:21<00:00, 165.35it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3123/3257 [00:21<00:00, 166.40it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3140/3257 [00:22<00:00, 154.27it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3156/3257 [00:22<00:00, 149.95it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3172/3257 [00:22<00:00, 148.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3188/3257 [00:22<00:00, 143.16it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3204/3257 [00:22<00:00, 146.89it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3219/3257 [00:22<00:00, 137.91it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:22<00:00, 151.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3255/3257 [00:22<00:00, 151.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 142.30it/s]
2023-02-07 19:01:47.443 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:01:47,445][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d353,n5,w12,mc9,s0.909965,t4>', 'datetime': '2023-02-07T19:01:47.444979', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:01:47,445][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:01:47,445][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:01:48,006][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 19:01:48,006][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:01:48,064][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 18315 unique words (33.88% of original 54054, drops 35739)', 'datetime': '2023-02-07T19:01:48.064810', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:01:48,065][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 6422560 word corpus (98.04% of original 6550866, drops 128306)', 'datetime': '2023-02-07T19:01:48.065184', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:01:48,129][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 19:01:48,131][gensim.models.word2vec][INFO] - sample=0.909965 downsamples 0 most-common words
[2023-02-07 19:01:48,131][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6422560 word corpus (100.0%% of prior 6422560)', 'datetime': '2023-02-07T19:01:48.131272', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:01:48,236][gensim.models.word2vec][INFO] - estimated required memory for 18315 words and 353 dimensions: 66129344 bytes
[2023-02-07 19:01:48,237][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:01:48,265][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18315 vocabulary and 353 features, using sg=0 hs=0 sample=0.9099651820649156 negative=5 window=12 shrink_windows=True', 'datetime': '2023-02-07T19:01:48.265929', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:01:49,271][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 17.38% examples, 1081247 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:01:50,273][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 34.33% examples, 1101780 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:01:51,273][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 50.72% examples, 1094698 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:01:52,274][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 67.70% examples, 1097180 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:01:53,276][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 85.66% examples, 1097857 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:01:53,948][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6368654 effective words) took 5.7s, 1121124 effective words/s
[2023-02-07 19:01:54,949][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 20.20% examples, 1268229 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:01:55,950][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 38.53% examples, 1253915 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:01:56,953][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 57.45% examples, 1244562 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:01:57,955][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 77.06% examples, 1238991 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:01:58,960][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 97.14% examples, 1236479 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:01:59,102][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6368654 effective words) took 5.2s, 1235980 effective words/s
[2023-02-07 19:02:00,122][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 19.74% examples, 1204445 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:01,131][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 38.01% examples, 1217628 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:02,134][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 56.74% examples, 1220234 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:03,148][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 76.70% examples, 1222572 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:04,157][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 97.14% examples, 1226173 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:04,289][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6368654 effective words) took 5.2s, 1228090 effective words/s
[2023-02-07 19:02:05,303][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 19.77% examples, 1215550 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:06,303][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 38.19% examples, 1233984 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:07,307][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 57.72% examples, 1245602 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:08,314][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 78.02% examples, 1247286 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:09,327][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 98.34% examples, 1245409 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:09,403][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6368654 effective words) took 5.1s, 1245726 effective words/s
[2023-02-07 19:02:10,410][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 18.18% examples, 1129458 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:11,411][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 35.19% examples, 1135039 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:12,413][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 53.02% examples, 1145880 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:13,424][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 70.95% examples, 1147815 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:14,431][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 89.99% examples, 1146110 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:14,954][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6368654 effective words) took 5.5s, 1147678 effective words/s
[2023-02-07 19:02:15,958][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 18.18% examples, 1134426 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:16,964][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 35.92% examples, 1155611 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:17,968][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 53.61% examples, 1161819 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:18,969][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 75.59% examples, 1217407 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:19,974][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 97.14% examples, 1235125 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:20,108][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6368654 effective words) took 5.2s, 1236209 effective words/s
[2023-02-07 19:02:21,120][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 20.11% examples, 1247894 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:22,123][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.72% examples, 1250671 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:23,129][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 58.27% examples, 1255966 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:24,133][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 78.54% examples, 1255809 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:25,140][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 98.86% examples, 1254082 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:25,178][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6368654 effective words) took 5.1s, 1256615 effective words/s
[2023-02-07 19:02:26,188][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 19.77% examples, 1219545 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:27,190][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 38.19% examples, 1235193 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:02:28,201][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 57.97% examples, 1248999 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:29,210][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 78.42% examples, 1251792 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:30,214][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 99.42% examples, 1258277 words/s, in_qsize 5, out_qsize 0
[2023-02-07 19:02:30,239][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6368654 effective words) took 5.1s, 1258680 effective words/s
[2023-02-07 19:02:31,247][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 20.20% examples, 1260717 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:32,252][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 39.18% examples, 1267025 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:33,257][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 57.35% examples, 1236610 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:34,257][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 75.35% examples, 1214136 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:35,260][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 94.41% examples, 1201946 words/s, in_qsize 7, out_qsize 1
[2023-02-07 19:02:35,543][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6368654 effective words) took 5.3s, 1201226 effective words/s
[2023-02-07 19:02:36,553][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 18.67% examples, 1153675 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:37,558][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.14% examples, 1160072 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:38,565][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 53.91% examples, 1164158 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:39,567][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 72.46% examples, 1165963 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:40,574][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 91.37% examples, 1165966 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:40,977][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6368654 effective words) took 5.4s, 1172258 effective words/s
[2023-02-07 19:02:41,979][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 21.55% examples, 1354150 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:42,990][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 41.30% examples, 1340118 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:43,993][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 61.59% examples, 1321718 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:45,012][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 81.76% examples, 1301140 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:02:45,892][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6368654 effective words) took 4.9s, 1296039 effective words/s
[2023-02-07 19:02:46,902][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 20.11% examples, 1250000 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:47,909][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 39.12% examples, 1262265 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:48,917][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 58.89% examples, 1265820 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:49,922][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 79.28% examples, 1268107 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:50,902][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6368654 effective words) took 5.0s, 1271594 effective words/s
[2023-02-07 19:02:51,905][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 20.54% examples, 1285627 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:52,911][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 39.73% examples, 1295335 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:53,917][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 58.80% examples, 1267425 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:54,919][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 77.96% examples, 1247727 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:55,920][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 96.93% examples, 1232361 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:56,072][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6368654 effective words) took 5.2s, 1232271 effective words/s
[2023-02-07 19:02:57,075][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 18.67% examples, 1161854 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:58,080][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 36.17% examples, 1165608 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:02:59,082][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 54.25% examples, 1174336 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:03:00,091][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 73.10% examples, 1176015 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:03:01,099][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 92.54% examples, 1180547 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:03:01,452][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6368654 effective words) took 5.4s, 1184108 effective words/s
[2023-02-07 19:03:02,455][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 19.86% examples, 1236097 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:03:03,456][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 39.85% examples, 1303786 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:03:04,459][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 60.79% examples, 1308001 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:03:05,478][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 81.76% examples, 1304394 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:03:06,335][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6368654 effective words) took 4.9s, 1305027 effective words/s
[2023-02-07 19:03:06,335][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (95529810 effective words) took 78.1s, 1223651 effective words/s', 'datetime': '2023-02-07T19:03:06.335836', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:03:06.336 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:03:11,657][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190115-7snlzssx/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:03:11.657489', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:03:11,658][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:03:11,747][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190115-7snlzssx/files/../tmp/embedding_model.pt
2023-02-07 19:03:11.748 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:03:13.824 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:03:14.608 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:03:17.091 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1134456393921708, 'test_mae': 0.7982299533084126, 'test_r2': -2.7762394136413513}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.23
wandb: percentage 0.66117
wandb:   test_mae 0.79823
wandb:   test_mse 1.11345
wandb:    test_r2 -2.77624
wandb: 
wandb: üöÄ View run swift-sweep-25 at: https://wandb.ai/xiaoqiz/mof2vec/runs/7snlzssx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_190115-7snlzssx/logs
wandb: Agent Starting Run: esfrgilf with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 608
wandb: 	model.gensim.alpha: 0.5182103523973028
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.25484931986480297
wandb: 	model.gensim.vector_size: 110
wandb: 	model.gensim.window: 19
wandb: 	model.sklearn.learning_rate: 0.0011465061603831285
wandb: 	model.sklearn.max_depth: 86
wandb: 	model.sklearn.min_child_weight: 0.004952416513797874
wandb: 	model.sklearn.n_estimators: 3392
wandb: 	model.sklearn.num_leaves: 465
wandb: 	model.sklearn.reg_alpha: 0.0026574362052478244
wandb: 	model.sklearn.reg_lambda: 0.013412688360791082
wandb: 	model.sklearn.subsample: 0.9566891222763692
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190327-esfrgilf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-26
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/esfrgilf
2023-02-07 19:03:35.977 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 19:03:35.977 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 608 for sweep.
2023-02-07 19:03:35.978 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.5182103523973028 for sweep.
2023-02-07 19:03:35.978 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:03:35.978 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 19:03:35.978 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.25484931986480297 for sweep.
2023-02-07 19:03:35.979 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 110 for sweep.
2023-02-07 19:03:35.979 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 19 for sweep.
2023-02-07 19:03:35.979 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0011465061603831285 for sweep.
2023-02-07 19:03:35.979 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 86 for sweep.
2023-02-07 19:03:35.980 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.004952416513797874 for sweep.
2023-02-07 19:03:35.980 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3392 for sweep.
2023-02-07 19:03:35.981 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 465 for sweep.
2023-02-07 19:03:35.981 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0026574362052478244 for sweep.
2023-02-07 19:03:35.981 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.013412688360791082 for sweep.
2023-02-07 19:03:35.981 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9566891222763692 for sweep.
2023-02-07 19:03:35.982 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:03:35.987 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190327-esfrgilf/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 608, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 110, 'window': 19, 'min_count': 8, 'dm': 0, 'sample': 0.25484931986480297, 'workers': 4, 'alpha': 0.5182103523973028, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3392, 'max_depth': 86, 'num_leaves': 465, 'reg_alpha': 0.0026574362052478244, 'reg_lambda': 0.013412688360791082, 'subsample': 0.9566891222763692, 'min_child_weight': 0.004952416513797874, 'n_jobs': 4, 'learning_rate': 0.0011465061603831285}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 169.74it/s]  1%|          | 36/3257 [00:00<00:18, 176.92it/s]  2%|‚ñè         | 54/3257 [00:00<00:18, 176.06it/s]  2%|‚ñè         | 75/3257 [00:00<00:16, 188.80it/s]  3%|‚ñé         | 94/3257 [00:00<00:16, 187.83it/s]  3%|‚ñé         | 113/3257 [00:00<00:17, 181.33it/s]  4%|‚ñç         | 132/3257 [00:00<00:17, 181.96it/s]  5%|‚ñç         | 152/3257 [00:00<00:16, 186.87it/s]  5%|‚ñå         | 171/3257 [00:00<00:16, 183.54it/s]  6%|‚ñå         | 190/3257 [00:01<00:16, 185.30it/s]  6%|‚ñã         | 209/3257 [00:01<00:16, 185.94it/s]  7%|‚ñã         | 231/3257 [00:01<00:15, 195.51it/s]  8%|‚ñä         | 251/3257 [00:01<00:15, 194.75it/s]  8%|‚ñä         | 271/3257 [00:01<00:15, 187.14it/s]  9%|‚ñâ         | 296/3257 [00:01<00:14, 202.82it/s] 10%|‚ñâ         | 317/3257 [00:01<00:15, 193.55it/s] 10%|‚ñà         | 337/3257 [00:01<00:14, 195.21it/s] 11%|‚ñà         | 359/3257 [00:01<00:14, 197.72it/s] 12%|‚ñà‚ñè        | 379/3257 [00:02<00:15, 184.72it/s] 12%|‚ñà‚ñè        | 398/3257 [00:02<00:15, 183.28it/s] 13%|‚ñà‚ñé        | 419/3257 [00:02<00:14, 189.62it/s] 13%|‚ñà‚ñé        | 439/3257 [00:02<00:17, 163.85it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:16, 170.25it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:15, 173.76it/s] 15%|‚ñà‚ñå        | 500/3257 [00:02<00:15, 181.85it/s] 16%|‚ñà‚ñå        | 519/3257 [00:02<00:22, 121.59it/s] 16%|‚ñà‚ñã        | 536/3257 [00:03<00:20, 130.60it/s] 17%|‚ñà‚ñã        | 557/3257 [00:03<00:18, 147.37it/s] 18%|‚ñà‚ñä        | 574/3257 [00:03<00:19, 139.77it/s] 18%|‚ñà‚ñä        | 595/3257 [00:03<00:17, 156.35it/s] 19%|‚ñà‚ñâ        | 617/3257 [00:03<00:15, 171.42it/s] 20%|‚ñà‚ñâ        | 636/3257 [00:03<00:15, 174.34it/s] 20%|‚ñà‚ñà        | 655/3257 [00:03<00:15, 162.97it/s] 21%|‚ñà‚ñà        | 673/3257 [00:03<00:15, 165.98it/s] 21%|‚ñà‚ñà        | 691/3257 [00:03<00:15, 162.94it/s] 22%|‚ñà‚ñà‚ñè       | 710/3257 [00:04<00:15, 168.98it/s] 22%|‚ñà‚ñà‚ñè       | 728/3257 [00:04<00:15, 164.13it/s] 23%|‚ñà‚ñà‚ñé       | 745/3257 [00:04<00:15, 164.53it/s] 24%|‚ñà‚ñà‚ñé       | 766/3257 [00:04<00:14, 175.71it/s] 24%|‚ñà‚ñà‚ñç       | 784/3257 [00:04<00:14, 167.44it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:04<00:14, 174.95it/s] 25%|‚ñà‚ñà‚ñå       | 822/3257 [00:04<00:13, 174.25it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:04<00:14, 167.07it/s] 26%|‚ñà‚ñà‚ñã       | 857/3257 [00:04<00:14, 165.44it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:05<00:14, 165.23it/s] 27%|‚ñà‚ñà‚ñã       | 894/3257 [00:05<00:13, 169.12it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:05<00:13, 173.52it/s] 29%|‚ñà‚ñà‚ñä       | 933/3257 [00:05<00:13, 177.99it/s] 29%|‚ñà‚ñà‚ñâ       | 955/3257 [00:05<00:12, 189.16it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:05<00:12, 185.67it/s] 30%|‚ñà‚ñà‚ñà       | 993/3257 [00:05<00:12, 178.85it/s] 31%|‚ñà‚ñà‚ñà       | 1014/3257 [00:05<00:12, 185.41it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1036/3257 [00:05<00:11, 193.18it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1058/3257 [00:06<00:11, 199.26it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1081/3257 [00:06<00:10, 207.88it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:06<00:09, 216.47it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1127/3257 [00:06<00:09, 215.10it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1149/3257 [00:06<00:10, 209.79it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:06<00:09, 219.70it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1197/3257 [00:06<00:09, 208.35it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:06<00:09, 205.06it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:06<00:09, 220.23it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1270/3257 [00:06<00:08, 228.04it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1293/3257 [00:07<00:09, 205.31it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1316/3257 [00:07<00:09, 210.51it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1341/3257 [00:07<00:08, 220.00it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:07<00:08, 212.81it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:07<00:09, 207.84it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:07<00:08, 221.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1436/3257 [00:07<00:08, 224.80it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:07<00:07, 234.84it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1488/3257 [00:07<00:07, 239.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:08<00:07, 241.77it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1538/3257 [00:08<00:07, 219.23it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1561/3257 [00:08<00:07, 213.66it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1583/3257 [00:08<00:07, 210.14it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1606/3257 [00:08<00:07, 214.63it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1631/3257 [00:08<00:07, 224.51it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:08<00:07, 207.64it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:08<00:07, 197.80it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1697/3257 [00:09<00:07, 197.99it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1718/3257 [00:09<00:07, 197.38it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1738/3257 [00:09<00:08, 185.26it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1762/3257 [00:09<00:07, 198.91it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1784/3257 [00:09<00:07, 203.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1805/3257 [00:09<00:07, 200.18it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:09<00:11, 126.10it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1848/3257 [00:09<00:09, 143.44it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1871/3257 [00:10<00:08, 161.20it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1891/3257 [00:10<00:08, 170.06it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:10<00:07, 182.36it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1939/3257 [00:10<00:06, 193.75it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:10<00:06, 207.32it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1987/3257 [00:10<00:06, 203.60it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2010/3257 [00:10<00:05, 208.58it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:10<00:05, 211.36it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:10<00:06, 195.74it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2076/3257 [00:11<00:06, 192.57it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2096/3257 [00:11<00:06, 186.98it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2118/3257 [00:11<00:05, 195.09it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2138/3257 [00:11<00:06, 186.34it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2157/3257 [00:11<00:05, 186.23it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:11<00:05, 192.77it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2200/3257 [00:11<00:05, 200.22it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2221/3257 [00:11<00:05, 193.61it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2241/3257 [00:11<00:05, 182.64it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2262/3257 [00:12<00:05, 188.40it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2282/3257 [00:12<00:05, 189.02it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2303/3257 [00:12<00:04, 194.32it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2329/3257 [00:12<00:04, 211.77it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2355/3257 [00:12<00:04, 224.62it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2378/3257 [00:12<00:03, 220.05it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:12<00:03, 226.68it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2427/3257 [00:12<00:03, 212.96it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2449/3257 [00:12<00:04, 194.84it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:13<00:03, 209.54it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2498/3257 [00:13<00:03, 213.15it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2521/3257 [00:13<00:03, 216.97it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2543/3257 [00:13<00:03, 215.40it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2565/3257 [00:13<00:03, 204.40it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:13<00:03, 196.29it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2609/3257 [00:13<00:03, 205.20it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2635/3257 [00:13<00:02, 218.72it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2658/3257 [00:13<00:02, 201.58it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2681/3257 [00:14<00:02, 208.27it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2703/3257 [00:14<00:02, 190.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2723/3257 [00:14<00:02, 188.73it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2748/3257 [00:14<00:02, 204.45it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2769/3257 [00:14<00:02, 197.83it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2794/3257 [00:14<00:02, 211.07it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2816/3257 [00:14<00:02, 204.69it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:14<00:02, 198.70it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2863/3257 [00:14<00:01, 213.98it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2888/3257 [00:15<00:01, 220.97it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2911/3257 [00:15<00:01, 209.24it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2933/3257 [00:15<00:01, 210.00it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2955/3257 [00:15<00:01, 201.62it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:15<00:01, 200.59it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3000/3257 [00:15<00:01, 210.14it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3022/3257 [00:15<00:01, 209.87it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:15<00:00, 224.11it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3076/3257 [00:15<00:00, 239.31it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3101/3257 [00:16<00:00, 231.67it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3125/3257 [00:16<00:00, 216.70it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3147/3257 [00:16<00:00, 190.63it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3167/3257 [00:16<00:00, 183.06it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3186/3257 [00:16<00:00, 98.10it/s]  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3206/3257 [00:16<00:00, 114.63it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3223/3257 [00:17<00:00, 121.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:17<00:00, 138.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 188.77it/s]
2023-02-07 19:03:53.877 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:03:53,878][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d110,n5,mc8,s0.254849,t4>', 'datetime': '2023-02-07T19:03:53.878256', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:03:53,878][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:03:53,878][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:03:54,306][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 19:03:54,307][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:03:54,336][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 9584 unique words (44.17% of original 21699, drops 12115)', 'datetime': '2023-02-07T19:03:54.336914', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:03:54,337][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 4331919 word corpus (99.19% of original 4367244, drops 35325)', 'datetime': '2023-02-07T19:03:54.337372', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:03:54,372][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 19:03:54,373][gensim.models.word2vec][INFO] - sample=0.254849 downsamples 0 most-common words
[2023-02-07 19:03:54,373][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4331919 word corpus (100.0%% of prior 4331919)', 'datetime': '2023-02-07T19:03:54.373761', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:03:54,432][gensim.models.word2vec][INFO] - estimated required memory for 9584 words and 110 dimensions: 15310400 bytes
[2023-02-07 19:03:54,432][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:03:54,440][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 9584 vocabulary and 110 features, using sg=1 hs=0 sample=0.25484931986480297 negative=5 window=19 shrink_windows=True', 'datetime': '2023-02-07T19:03:54.440156', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:03:55,322][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4333519 effective words) took 0.9s, 4928349 effective words/s
[2023-02-07 19:03:56,191][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4333519 effective words) took 0.9s, 4999586 effective words/s
[2023-02-07 19:03:57,067][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4333519 effective words) took 0.9s, 4954027 effective words/s
[2023-02-07 19:03:57,929][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4333519 effective words) took 0.9s, 5035304 effective words/s
[2023-02-07 19:03:58,799][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4333519 effective words) took 0.9s, 4989107 effective words/s
[2023-02-07 19:03:59,664][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4333519 effective words) took 0.9s, 5019043 effective words/s
[2023-02-07 19:04:00,533][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4333519 effective words) took 0.9s, 4995677 effective words/s
[2023-02-07 19:04:01,265][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4333519 effective words) took 0.7s, 5936272 effective words/s
[2023-02-07 19:04:01,969][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4333519 effective words) took 0.7s, 6171908 effective words/s
[2023-02-07 19:04:02,723][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4333519 effective words) took 0.8s, 5752591 effective words/s
[2023-02-07 19:04:03,486][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4333519 effective words) took 0.8s, 5688507 effective words/s
[2023-02-07 19:04:04,250][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4333519 effective words) took 0.8s, 5684920 effective words/s
[2023-02-07 19:04:05,011][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4333519 effective words) took 0.8s, 5702175 effective words/s
[2023-02-07 19:04:05,779][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4333519 effective words) took 0.8s, 5652254 effective words/s
[2023-02-07 19:04:06,538][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4333519 effective words) took 0.8s, 5719490 effective words/s
[2023-02-07 19:04:06,539][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65002785 effective words) took 12.1s, 5372751 effective words/s', 'datetime': '2023-02-07T19:04:06.539165', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:04:06.539 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:04:08,005][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190327-esfrgilf/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:04:08.005860', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:04:08,006][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:04:08,026][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190327-esfrgilf/files/../tmp/embedding_model.pt
2023-02-07 19:04:08.026 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:04:09.209 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:04:09.648 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:04:10.453 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.188440728001401, 'test_mae': 0.8534448483696013, 'test_r2': -4.73860673179453}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.01
wandb: percentage 0.55832
wandb:   test_mae 0.85344
wandb:   test_mse 1.18844
wandb:    test_r2 -4.73861
wandb: 
wandb: üöÄ View run lunar-sweep-26 at: https://wandb.ai/xiaoqiz/mof2vec/runs/esfrgilf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_190327-esfrgilf/logs
wandb: Agent Starting Run: gwdz2afw with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 800
wandb: 	model.gensim.alpha: 0.011910080082790906
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.8679450468905474
wandb: 	model.gensim.vector_size: 253
wandb: 	model.gensim.window: 3
wandb: 	model.sklearn.learning_rate: 0.053314987821632354
wandb: 	model.sklearn.max_depth: 20
wandb: 	model.sklearn.min_child_weight: 0.06317967734482718
wandb: 	model.sklearn.n_estimators: 944
wandb: 	model.sklearn.num_leaves: 338
wandb: 	model.sklearn.reg_alpha: 0.010105598952773198
wandb: 	model.sklearn.reg_lambda: 0.04443940423233702
wandb: 	model.sklearn.subsample: 0.809506326997905
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190424-gwdz2afw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-27
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/gwdz2afw
2023-02-07 19:04:32.273 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 19:04:32.274 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 800 for sweep.
2023-02-07 19:04:32.274 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.011910080082790906 for sweep.
2023-02-07 19:04:32.275 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:04:32.275 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 19:04:32.275 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8679450468905474 for sweep.
2023-02-07 19:04:32.275 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 253 for sweep.
2023-02-07 19:04:32.276 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 3 for sweep.
2023-02-07 19:04:32.276 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.053314987821632354 for sweep.
2023-02-07 19:04:32.276 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 20 for sweep.
2023-02-07 19:04:32.276 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.06317967734482718 for sweep.
2023-02-07 19:04:32.277 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 944 for sweep.
2023-02-07 19:04:32.277 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 338 for sweep.
2023-02-07 19:04:32.277 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.010105598952773198 for sweep.
2023-02-07 19:04:32.277 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.04443940423233702 for sweep.
2023-02-07 19:04:32.278 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.809506326997905 for sweep.
2023-02-07 19:04:32.278 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:04:32.289 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190424-gwdz2afw/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 800, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 253, 'window': 3, 'min_count': 10, 'dm': 0, 'sample': 0.8679450468905474, 'workers': 4, 'alpha': 0.011910080082790906, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 944, 'max_depth': 20, 'num_leaves': 338, 'reg_alpha': 0.010105598952773198, 'reg_lambda': 0.04443940423233702, 'subsample': 0.809506326997905, 'min_child_weight': 0.06317967734482718, 'n_jobs': 4, 'learning_rate': 0.053314987821632354}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 166.19it/s]  1%|          | 36/3257 [00:00<00:18, 178.00it/s]  2%|‚ñè         | 54/3257 [00:00<00:18, 177.84it/s]  2%|‚ñè         | 74/3257 [00:00<00:17, 184.67it/s]  3%|‚ñé         | 94/3257 [00:00<00:16, 186.99it/s]  3%|‚ñé         | 113/3257 [00:00<00:17, 181.22it/s]  4%|‚ñç         | 133/3257 [00:00<00:16, 185.97it/s]  5%|‚ñç         | 154/3257 [00:00<00:16, 190.41it/s]  5%|‚ñå         | 174/3257 [00:00<00:16, 184.98it/s]  6%|‚ñå         | 196/3257 [00:01<00:15, 192.87it/s]  7%|‚ñã         | 218/3257 [00:01<00:15, 198.45it/s]  7%|‚ñã         | 242/3257 [00:01<00:14, 209.00it/s]  8%|‚ñä         | 263/3257 [00:01<00:14, 201.28it/s]  9%|‚ñâ         | 288/3257 [00:01<00:13, 214.88it/s] 10%|‚ñâ         | 310/3257 [00:01<00:14, 208.81it/s] 10%|‚ñà         | 332/3257 [00:01<00:14, 208.76it/s] 11%|‚ñà         | 353/3257 [00:01<00:14, 204.01it/s] 11%|‚ñà‚ñè        | 374/3257 [00:01<00:14, 203.39it/s] 12%|‚ñà‚ñè        | 395/3257 [00:02<00:15, 187.41it/s] 13%|‚ñà‚ñé        | 417/3257 [00:02<00:14, 194.23it/s] 13%|‚ñà‚ñé        | 437/3257 [00:02<00:16, 170.63it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:15, 180.84it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:15, 182.56it/s] 15%|‚ñà‚ñå        | 501/3257 [00:02<00:14, 191.60it/s] 16%|‚ñà‚ñå        | 522/3257 [00:02<00:14, 192.11it/s] 17%|‚ñà‚ñã        | 543/3257 [00:02<00:13, 194.83it/s] 17%|‚ñà‚ñã        | 563/3257 [00:02<00:14, 180.16it/s] 18%|‚ñà‚ñä        | 582/3257 [00:03<00:15, 177.86it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:14, 187.35it/s] 19%|‚ñà‚ñâ        | 623/3257 [00:03<00:14, 186.36it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:13, 189.43it/s] 20%|‚ñà‚ñà        | 665/3257 [00:03<00:14, 181.40it/s] 21%|‚ñà‚ñà        | 684/3257 [00:03<00:14, 182.08it/s] 22%|‚ñà‚ñà‚ñè       | 703/3257 [00:03<00:14, 181.73it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:03<00:13, 181.39it/s] 23%|‚ñà‚ñà‚ñé       | 741/3257 [00:03<00:14, 175.50it/s] 23%|‚ñà‚ñà‚ñé       | 764/3257 [00:04<00:13, 189.13it/s] 24%|‚ñà‚ñà‚ñç       | 784/3257 [00:04<00:13, 183.16it/s] 25%|‚ñà‚ñà‚ñç       | 805/3257 [00:04<00:12, 190.37it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:04<00:13, 178.95it/s] 26%|‚ñà‚ñà‚ñå       | 844/3257 [00:04<00:13, 176.06it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:04<00:13, 179.51it/s] 27%|‚ñà‚ñà‚ñã       | 883/3257 [00:04<00:13, 177.38it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:04<00:12, 188.92it/s] 29%|‚ñà‚ñà‚ñä       | 930/3257 [00:04<00:11, 205.06it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:05<00:10, 219.17it/s] 30%|‚ñà‚ñà‚ñà       | 980/3257 [00:05<00:10, 221.17it/s] 31%|‚ñà‚ñà‚ñà       | 1005/3257 [00:05<00:09, 228.62it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1028/3257 [00:05<00:10, 221.75it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:05<00:10, 218.33it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1079/3257 [00:05<00:09, 235.39it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1103/3257 [00:05<00:09, 226.12it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1126/3257 [00:05<00:09, 223.69it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1149/3257 [00:05<00:09, 217.18it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:05<00:09, 224.06it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1198/3257 [00:06<00:09, 209.05it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1220/3257 [00:06<00:10, 202.93it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:06<00:09, 218.39it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1270/3257 [00:06<00:13, 149.71it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:06<00:13, 150.78it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1312/3257 [00:06<00:11, 170.19it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1336/3257 [00:06<00:10, 185.87it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1357/3257 [00:07<00:09, 190.65it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1378/3257 [00:07<00:09, 195.63it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1400/3257 [00:07<00:09, 201.36it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1424/3257 [00:07<00:08, 212.09it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1449/3257 [00:07<00:08, 221.72it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:07<00:07, 229.00it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1499/3257 [00:07<00:07, 233.76it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1523/3257 [00:07<00:07, 219.52it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:07<00:08, 210.27it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1570/3257 [00:07<00:07, 215.73it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1592/3257 [00:08<00:07, 213.25it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:08<00:07, 221.54it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1640/3257 [00:08<00:07, 218.29it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:08<00:07, 208.11it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1683/3257 [00:08<00:07, 204.20it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:08<00:07, 213.71it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:08<00:07, 206.25it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1750/3257 [00:08<00:07, 207.22it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1774/3257 [00:08<00:07, 211.28it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1797/3257 [00:09<00:06, 215.53it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1819/3257 [00:09<00:06, 213.98it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1841/3257 [00:09<00:06, 213.47it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1865/3257 [00:09<00:06, 219.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1888/3257 [00:09<00:06, 215.25it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1913/3257 [00:09<00:06, 223.82it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1936/3257 [00:09<00:05, 225.53it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:09<00:05, 239.30it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1989/3257 [00:09<00:05, 225.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2012/3257 [00:10<00:05, 222.80it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:10<00:05, 224.77it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2058/3257 [00:10<00:05, 208.38it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2081/3257 [00:10<00:05, 213.15it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2103/3257 [00:10<00:05, 207.05it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2124/3257 [00:10<00:05, 203.45it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2145/3257 [00:10<00:05, 201.15it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2170/3257 [00:10<00:05, 213.70it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2193/3257 [00:10<00:04, 215.71it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2215/3257 [00:11<00:04, 211.04it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:11<00:04, 211.19it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:11<00:04, 209.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2282/3257 [00:11<00:04, 209.50it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2305/3257 [00:11<00:04, 215.02it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2334/3257 [00:11<00:03, 234.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2361/3257 [00:11<00:03, 242.62it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2387/3257 [00:11<00:03, 247.04it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2412/3257 [00:11<00:03, 235.69it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2436/3257 [00:11<00:03, 224.03it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2459/3257 [00:12<00:05, 136.63it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2484/3257 [00:12<00:04, 157.01it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:12<00:04, 185.23it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:12<00:03, 198.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2563/3257 [00:12<00:03, 201.85it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:12<00:03, 202.62it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:12<00:02, 222.19it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2640/3257 [00:13<00:02, 228.31it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2664/3257 [00:13<00:02, 216.75it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:13<00:02, 226.58it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2714/3257 [00:13<00:02, 207.22it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2740/3257 [00:13<00:02, 219.80it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2763/3257 [00:13<00:02, 221.11it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2786/3257 [00:13<00:02, 219.26it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2809/3257 [00:13<00:02, 210.69it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2831/3257 [00:13<00:02, 190.93it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2851/3257 [00:14<00:02, 191.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2877/3257 [00:14<00:01, 209.74it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2899/3257 [00:14<00:01, 194.20it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2919/3257 [00:14<00:01, 192.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2939/3257 [00:14<00:01, 189.56it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2959/3257 [00:14<00:01, 176.49it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2978/3257 [00:14<00:01, 178.16it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2999/3257 [00:14<00:01, 186.11it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:14<00:01, 182.45it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3040/3257 [00:15<00:01, 191.37it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:15<00:00, 199.62it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3084/3257 [00:15<00:00, 199.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3105/3257 [00:15<00:00, 202.08it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:15<00:00, 203.39it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3148/3257 [00:15<00:00, 190.24it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3168/3257 [00:15<00:00, 192.66it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3188/3257 [00:15<00:00, 185.04it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3208/3257 [00:15<00:00, 185.91it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3227/3257 [00:16<00:00, 184.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3251/3257 [00:16<00:00, 199.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 200.79it/s]
2023-02-07 19:04:49.141 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:04:49,142][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d253,n5,mc10,s0.867945,t4>', 'datetime': '2023-02-07T19:04:49.142840', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:04:49,143][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:04:49,143][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:04:49,569][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 19:04:49,570][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:04:49,595][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 7882 unique words (36.32% of original 21699, drops 13817)', 'datetime': '2023-02-07T19:04:49.595812', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:04:49,596][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 4318111 word corpus (98.87% of original 4367244, drops 49133)', 'datetime': '2023-02-07T19:04:49.596251', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:04:49,625][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 19:04:49,627][gensim.models.word2vec][INFO] - sample=0.867945 downsamples 0 most-common words
[2023-02-07 19:04:49,628][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4318111 word corpus (100.0%% of prior 4318111)', 'datetime': '2023-02-07T19:04:49.628127', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:04:49,677][gensim.models.word2vec][INFO] - estimated required memory for 7882 words and 253 dimensions: 23841652 bytes
[2023-02-07 19:04:49,677][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:04:49,691][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 7882 vocabulary and 253 features, using sg=1 hs=0 sample=0.8679450468905474 negative=5 window=3 shrink_windows=True', 'datetime': '2023-02-07T19:04:49.691866', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:04:50,705][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 45.81% examples, 1995135 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:51,708][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 95.15% examples, 2046383 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:51,797][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4319715 effective words) took 2.1s, 2054424 effective words/s
[2023-02-07 19:04:52,802][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 52.32% examples, 2307923 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:53,670][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4319715 effective words) took 1.9s, 2309084 effective words/s
[2023-02-07 19:04:54,675][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 51.64% examples, 2278581 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:55,399][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4319715 effective words) took 1.7s, 2502004 effective words/s
[2023-02-07 19:04:56,404][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 65.89% examples, 2906874 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:56,872][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4319715 effective words) took 1.5s, 2938979 effective words/s
[2023-02-07 19:04:57,876][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 64.32% examples, 2824946 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:04:58,442][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4319715 effective words) took 1.6s, 2756558 effective words/s
[2023-02-07 19:04:59,448][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 58.86% examples, 2596534 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:00,115][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4319715 effective words) took 1.7s, 2586849 effective words/s
[2023-02-07 19:05:01,119][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 56.34% examples, 2494113 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:01,820][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4319715 effective words) took 1.7s, 2536383 effective words/s
[2023-02-07 19:05:02,826][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 60.02% examples, 2628262 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:03,475][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4319715 effective words) took 1.7s, 2612081 effective words/s
[2023-02-07 19:05:04,478][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 58.21% examples, 2571060 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:05,135][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4319715 effective words) took 1.7s, 2604197 effective words/s
[2023-02-07 19:05:06,138][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 58.86% examples, 2600937 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:06,792][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4319715 effective words) took 1.7s, 2610505 effective words/s
[2023-02-07 19:05:07,793][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 58.52% examples, 2583009 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:08,464][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4319715 effective words) took 1.7s, 2584977 effective words/s
[2023-02-07 19:05:09,465][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 58.21% examples, 2574468 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:10,140][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4319715 effective words) took 1.7s, 2579013 effective words/s
[2023-02-07 19:05:11,147][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 58.86% examples, 2588991 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:11,805][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4319715 effective words) took 1.7s, 2597192 effective words/s
[2023-02-07 19:05:12,806][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 58.03% examples, 2566515 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:13,481][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4319715 effective words) took 1.7s, 2580112 effective words/s
[2023-02-07 19:05:14,489][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 58.03% examples, 2548912 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:15,170][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4319715 effective words) took 1.7s, 2558877 effective words/s
[2023-02-07 19:05:15,171][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (64795725 effective words) took 25.5s, 2543147 effective words/s', 'datetime': '2023-02-07T19:05:15.170956', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:05:15.171 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:05:17,426][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190424-gwdz2afw/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:05:17.426613', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:05:17,427][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:05:17,469][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190424-gwdz2afw/files/../tmp/embedding_model.pt
2023-02-07 19:05:17.470 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:05:19.162 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:05:19.767 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:05:21.515 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9318771465594476, 'test_mae': 0.732262302807138, 'test_r2': -2.4281902181528023}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.8
wandb: percentage 0.63676
wandb:   test_mae 0.73226
wandb:   test_mse 0.93188
wandb:    test_r2 -2.42819
wandb: 
wandb: üöÄ View run fanciful-sweep-27 at: https://wandb.ai/xiaoqiz/mof2vec/runs/gwdz2afw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_190424-gwdz2afw/logs
wandb: Agent Starting Run: 95vmr4tc with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 211
wandb: 	model.gensim.alpha: 0.10654071014921015
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.5310591672194016
wandb: 	model.gensim.vector_size: 272
wandb: 	model.gensim.window: 17
wandb: 	model.sklearn.learning_rate: 0.00211138824043358
wandb: 	model.sklearn.max_depth: 15
wandb: 	model.sklearn.min_child_weight: 0.05076576870055133
wandb: 	model.sklearn.n_estimators: 491
wandb: 	model.sklearn.num_leaves: 376
wandb: 	model.sklearn.reg_alpha: 0.026981619205033672
wandb: 	model.sklearn.reg_lambda: 0.007071312222028358
wandb: 	model.sklearn.subsample: 0.4838764693432947
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190532-95vmr4tc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-28
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/95vmr4tc
2023-02-07 19:05:40.334 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 19:05:40.335 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 211 for sweep.
2023-02-07 19:05:40.335 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.10654071014921015 for sweep.
2023-02-07 19:05:40.336 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:05:40.336 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 19:05:40.337 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5310591672194016 for sweep.
2023-02-07 19:05:40.337 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 272 for sweep.
2023-02-07 19:05:40.337 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 17 for sweep.
2023-02-07 19:05:40.337 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.00211138824043358 for sweep.
2023-02-07 19:05:40.337 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 15 for sweep.
2023-02-07 19:05:40.338 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05076576870055133 for sweep.
2023-02-07 19:05:40.338 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 491 for sweep.
2023-02-07 19:05:40.338 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 376 for sweep.
2023-02-07 19:05:40.338 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.026981619205033672 for sweep.
2023-02-07 19:05:40.339 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.007071312222028358 for sweep.
2023-02-07 19:05:40.339 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.4838764693432947 for sweep.
2023-02-07 19:05:40.339 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:05:40.344 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190532-95vmr4tc/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 211, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 272, 'window': 17, 'min_count': 7, 'dm': 1, 'sample': 0.5310591672194016, 'workers': 4, 'alpha': 0.10654071014921015, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 491, 'max_depth': 15, 'num_leaves': 376, 'reg_alpha': 0.026981619205033672, 'reg_lambda': 0.007071312222028358, 'subsample': 0.4838764693432947, 'min_child_weight': 0.05076576870055133, 'n_jobs': 4, 'learning_rate': 0.00211138824043358}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 19/3257 [00:00<00:17, 184.10it/s]  1%|‚ñè         | 41/3257 [00:00<00:16, 200.31it/s]  2%|‚ñè         | 63/3257 [00:00<00:15, 208.03it/s]  3%|‚ñé         | 88/3257 [00:00<00:14, 222.16it/s]  3%|‚ñé         | 111/3257 [00:00<00:15, 201.87it/s]  4%|‚ñç         | 135/3257 [00:00<00:14, 211.62it/s]  5%|‚ñç         | 159/3257 [00:00<00:14, 219.14it/s]  6%|‚ñå         | 182/3257 [00:00<00:14, 217.60it/s]  7%|‚ñã         | 212/3257 [00:00<00:12, 241.31it/s]  7%|‚ñã         | 243/3257 [00:01<00:11, 258.32it/s]  8%|‚ñä         | 269/3257 [00:01<00:11, 258.06it/s]  9%|‚ñâ         | 300/3257 [00:01<00:10, 271.04it/s] 10%|‚ñà         | 331/3257 [00:01<00:10, 281.33it/s] 11%|‚ñà         | 360/3257 [00:01<00:10, 274.05it/s] 12%|‚ñà‚ñè        | 388/3257 [00:01<00:11, 260.19it/s] 13%|‚ñà‚ñé        | 419/3257 [00:01<00:10, 272.19it/s] 14%|‚ñà‚ñé        | 447/3257 [00:01<00:15, 184.53it/s] 15%|‚ñà‚ñç        | 476/3257 [00:02<00:13, 206.49it/s] 15%|‚ñà‚ñå        | 504/3257 [00:02<00:12, 223.31it/s] 16%|‚ñà‚ñã        | 531/3257 [00:02<00:11, 234.03it/s] 17%|‚ñà‚ñã        | 558/3257 [00:02<00:11, 239.70it/s] 18%|‚ñà‚ñä        | 584/3257 [00:02<00:11, 236.18it/s] 19%|‚ñà‚ñâ        | 613/3257 [00:02<00:10, 250.28it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:02<00:10, 252.73it/s] 20%|‚ñà‚ñà        | 665/3257 [00:02<00:10, 237.70it/s] 21%|‚ñà‚ñà        | 690/3257 [00:02<00:10, 240.83it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:03<00:10, 249.28it/s] 23%|‚ñà‚ñà‚ñé       | 744/3257 [00:03<00:10, 235.61it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:03<00:10, 246.83it/s] 25%|‚ñà‚ñà‚ñç       | 800/3257 [00:03<00:09, 252.27it/s] 25%|‚ñà‚ñà‚ñå       | 826/3257 [00:03<00:10, 242.72it/s] 26%|‚ñà‚ñà‚ñå       | 851/3257 [00:03<00:10, 239.03it/s] 27%|‚ñà‚ñà‚ñã       | 876/3257 [00:03<00:09, 241.43it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:03<00:09, 250.65it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:03<00:09, 251.17it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:03<00:08, 259.05it/s] 30%|‚ñà‚ñà‚ñà       | 985/3257 [00:04<00:08, 257.08it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:04<00:09, 244.97it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1036/3257 [00:04<00:09, 240.51it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1061/3257 [00:04<00:09, 233.92it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1086/3257 [00:04<00:09, 237.76it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1111/3257 [00:04<00:08, 241.03it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1136/3257 [00:04<00:09, 233.42it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1161/3257 [00:04<00:08, 237.73it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:04<00:08, 231.36it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1209/3257 [00:05<00:09, 222.50it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1239/3257 [00:05<00:08, 242.88it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1264/3257 [00:05<00:08, 242.90it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1289/3257 [00:05<00:08, 226.59it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1316/3257 [00:05<00:08, 236.67it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:05<00:07, 246.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1369/3257 [00:05<00:07, 240.13it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1394/3257 [00:05<00:08, 224.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:05<00:07, 235.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1446/3257 [00:06<00:07, 228.64it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1472/3257 [00:06<00:07, 232.95it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:06<00:07, 232.35it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1520/3257 [00:06<00:07, 222.30it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1543/3257 [00:06<00:07, 219.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1566/3257 [00:06<00:07, 213.65it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1588/3257 [00:06<00:07, 208.65it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1613/3257 [00:06<00:07, 219.55it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1636/3257 [00:07<00:11, 136.04it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:07<00:10, 148.91it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:07<00:10, 157.50it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1699/3257 [00:07<00:09, 173.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1721/3257 [00:07<00:08, 184.32it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1742/3257 [00:07<00:08, 176.68it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1767/3257 [00:07<00:07, 194.75it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:07<00:07, 203.98it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1812/3257 [00:08<00:07, 198.90it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1833/3257 [00:08<00:07, 201.80it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1857/3257 [00:08<00:06, 210.44it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1882/3257 [00:08<00:06, 220.62it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1905/3257 [00:08<00:06, 220.22it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1928/3257 [00:08<00:06, 214.85it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1959/3257 [00:08<00:05, 240.92it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1984/3257 [00:08<00:05, 226.14it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:08<00:05, 229.87it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:08<00:05, 234.56it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2057/3257 [00:09<00:05, 223.43it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2084/3257 [00:09<00:04, 235.05it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2112/3257 [00:09<00:04, 244.03it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:09<00:04, 243.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:09<00:04, 247.57it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2192/3257 [00:09<00:04, 259.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:09<00:03, 261.52it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2246/3257 [00:09<00:03, 259.13it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2272/3257 [00:09<00:03, 255.77it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:10<00:03, 263.91it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2334/3257 [00:10<00:03, 281.46it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2365/3257 [00:10<00:03, 289.44it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2395/3257 [00:10<00:02, 290.54it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2425/3257 [00:10<00:03, 273.14it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2453/3257 [00:10<00:03, 251.93it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2482/3257 [00:10<00:02, 260.28it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2513/3257 [00:10<00:02, 272.38it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2541/3257 [00:10<00:02, 263.84it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2568/3257 [00:11<00:02, 247.73it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2594/3257 [00:11<00:02, 243.12it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2628/3257 [00:11<00:02, 265.41it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2655/3257 [00:11<00:02, 255.96it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2681/3257 [00:11<00:02, 249.71it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2707/3257 [00:11<00:02, 231.55it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:11<00:02, 232.16it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2760/3257 [00:11<00:02, 244.80it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2785/3257 [00:11<00:01, 245.13it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2811/3257 [00:12<00:01, 249.29it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:12<00:01, 238.83it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2867/3257 [00:12<00:01, 255.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2893/3257 [00:12<00:01, 253.31it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:12<00:01, 255.97it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2946/3257 [00:12<00:01, 247.85it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2972/3257 [00:12<00:01, 248.00it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2997/3257 [00:12<00:01, 231.94it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3021/3257 [00:12<00:01, 227.74it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3044/3257 [00:13<00:01, 133.27it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3068/3257 [00:13<00:01, 153.29it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3090/3257 [00:13<00:01, 166.20it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3116/3257 [00:13<00:00, 186.00it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3138/3257 [00:13<00:00, 190.92it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3160/3257 [00:13<00:00, 192.42it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3181/3257 [00:13<00:00, 189.00it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:14<00:00, 202.23it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3229/3257 [00:14<00:00, 204.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:14<00:00, 211.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:14<00:00, 228.56it/s]
2023-02-07 19:05:55.115 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:05:55,116][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d272,n5,w17,mc7,s0.531059,t4>', 'datetime': '2023-02-07T19:05:55.116363', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:05:55,116][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:05:55,116][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:05:55,462][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 19:05:55,462][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:05:55,481][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 6087 unique words (46.60% of original 13061, drops 6974)', 'datetime': '2023-02-07T19:05:55.481230', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:05:55,482][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 3619677 word corpus (99.46% of original 3639370, drops 19693)', 'datetime': '2023-02-07T19:05:55.482304', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:05:55,504][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 19:05:55,504][gensim.models.word2vec][INFO] - sample=0.531059 downsamples 0 most-common words
[2023-02-07 19:05:55,504][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3619677 word corpus (100.0%% of prior 3619677)', 'datetime': '2023-02-07T19:05:55.504866', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:05:55,541][gensim.models.word2vec][INFO] - estimated required memory for 6087 words and 272 dimensions: 20483828 bytes
[2023-02-07 19:05:55,542][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:05:55,553][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 6087 vocabulary and 272 features, using sg=0 hs=0 sample=0.5310591672194016 negative=5 window=17 shrink_windows=True', 'datetime': '2023-02-07T19:05:55.553530', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:05:56,561][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 36.44% examples, 1341092 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:57,562][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 79.55% examples, 1455026 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:05:58,057][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3622934 effective words) took 2.5s, 1448532 effective words/s
[2023-02-07 19:05:59,064][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 39.21% examples, 1452675 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:00,065][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 78.35% examples, 1428501 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:00,639][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3622934 effective words) took 2.6s, 1404019 effective words/s
[2023-02-07 19:06:01,644][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 34.42% examples, 1262150 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:02,650][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 69.05% examples, 1273310 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:06:03,375][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3622934 effective words) took 2.7s, 1325038 effective words/s
[2023-02-07 19:06:04,377][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 40.71% examples, 1514519 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:06:05,381][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 80.29% examples, 1465616 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:06:05,848][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3622934 effective words) took 2.5s, 1466060 effective words/s
[2023-02-07 19:06:06,855][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 35.98% examples, 1316681 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:07,856][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 70.77% examples, 1306787 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:08,650][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3622934 effective words) took 2.8s, 1293638 effective words/s
[2023-02-07 19:06:09,661][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 36.66% examples, 1344685 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:06:10,664][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 78.35% examples, 1424140 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:06:11,193][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3622934 effective words) took 2.5s, 1425713 effective words/s
[2023-02-07 19:06:12,199][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.50% examples, 1422496 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:13,208][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 74.79% examples, 1368147 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:13,868][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3622934 effective words) took 2.7s, 1355195 effective words/s
[2023-02-07 19:06:14,872][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 34.63% examples, 1272483 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:15,873][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 71.72% examples, 1322663 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:16,488][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3622934 effective words) took 2.6s, 1383871 effective words/s
[2023-02-07 19:06:17,492][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 38.99% examples, 1441458 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:18,507][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 78.08% examples, 1415972 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:19,054][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3622934 effective words) took 2.6s, 1412850 effective words/s
[2023-02-07 19:06:20,066][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.60% examples, 1343319 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:21,082][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 75.99% examples, 1378183 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:21,664][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3622934 effective words) took 2.6s, 1388820 effective words/s
[2023-02-07 19:06:22,667][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 37.58% examples, 1388808 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:23,669][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 77.22% examples, 1412617 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:24,228][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3622934 effective words) took 2.6s, 1414292 effective words/s
[2023-02-07 19:06:25,232][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 38.07% examples, 1406832 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:26,234][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 75.99% examples, 1392877 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:26,821][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3622934 effective words) took 2.6s, 1398086 effective words/s
[2023-02-07 19:06:27,829][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 37.58% examples, 1380777 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:28,832][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 78.08% examples, 1421793 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:29,370][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3622934 effective words) took 2.5s, 1421756 effective words/s
[2023-02-07 19:06:30,372][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 38.44% examples, 1425402 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:31,373][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 77.53% examples, 1418499 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:06:31,979][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3622934 effective words) took 2.6s, 1389844 effective words/s
[2023-02-07 19:06:32,984][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 34.63% examples, 1270825 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:06:33,985][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 68.99% examples, 1276953 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:06:34,818][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3622934 effective words) took 2.8s, 1276880 effective words/s
[2023-02-07 19:06:34,819][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54344010 effective words) took 39.3s, 1384001 effective words/s', 'datetime': '2023-02-07T19:06:34.819887', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:06:34.820 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:06:37,726][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190532-95vmr4tc/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:06:37.726684', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:06:37,727][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:06:37,772][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190532-95vmr4tc/files/../tmp/embedding_model.pt
2023-02-07 19:06:37.772 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:06:39.661 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:06:40.230 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:06:42.097 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.2097242722289807, 'test_mae': 0.8657807013465583, 'test_r2': -4.228089372216749}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.0
wandb: percentage 0.53396
wandb:   test_mae 0.86578
wandb:   test_mse 1.20972
wandb:    test_r2 -4.22809
wandb: 
wandb: üöÄ View run vibrant-sweep-28 at: https://wandb.ai/xiaoqiz/mof2vec/runs/95vmr4tc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_190532-95vmr4tc/logs
wandb: Agent Starting Run: zw01cl87 with config:
wandb: 	data.data.wl_step: 1
wandb: 	data.nn.batch_size: 595
wandb: 	model.gensim.alpha: 0.0039366831291288585
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.24906795861002184
wandb: 	model.gensim.vector_size: 80
wandb: 	model.gensim.window: 9
wandb: 	model.sklearn.learning_rate: 0.0021057025525934585
wandb: 	model.sklearn.max_depth: 22
wandb: 	model.sklearn.min_child_weight: 0.029325570651887303
wandb: 	model.sklearn.n_estimators: 4068
wandb: 	model.sklearn.num_leaves: 117
wandb: 	model.sklearn.reg_alpha: 0.009202556399178578
wandb: 	model.sklearn.reg_lambda: 0.017999267189965924
wandb: 	model.sklearn.subsample: 0.8199691748090994
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190651-zw01cl87
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-29
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/zw01cl87
2023-02-07 19:07:00.249 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 1 for sweep.
2023-02-07 19:07:00.250 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 595 for sweep.
2023-02-07 19:07:00.250 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0039366831291288585 for sweep.
2023-02-07 19:07:00.251 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:07:00.251 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 19:07:00.251 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.24906795861002184 for sweep.
2023-02-07 19:07:00.251 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 80 for sweep.
2023-02-07 19:07:00.252 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 9 for sweep.
2023-02-07 19:07:00.252 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0021057025525934585 for sweep.
2023-02-07 19:07:00.252 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 22 for sweep.
2023-02-07 19:07:00.252 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.029325570651887303 for sweep.
2023-02-07 19:07:00.253 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4068 for sweep.
2023-02-07 19:07:00.253 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 117 for sweep.
2023-02-07 19:07:00.253 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.009202556399178578 for sweep.
2023-02-07 19:07:00.253 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.017999267189965924 for sweep.
2023-02-07 19:07:00.254 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8199691748090994 for sweep.
2023-02-07 19:07:00.254 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:07:00.261 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 1}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190651-zw01cl87/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 595, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 80, 'window': 9, 'min_count': 3, 'dm': 0, 'sample': 0.24906795861002184, 'workers': 4, 'alpha': 0.0039366831291288585, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4068, 'max_depth': 22, 'num_leaves': 117, 'reg_alpha': 0.009202556399178578, 'reg_lambda': 0.017999267189965924, 'subsample': 0.8199691748090994, 'min_child_weight': 0.029325570651887303, 'n_jobs': 4, 'learning_rate': 0.0021057025525934585}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 31/3257 [00:00<00:10, 307.42it/s]  2%|‚ñè         | 62/3257 [00:00<00:10, 308.27it/s]  3%|‚ñé         | 94/3257 [00:00<00:10, 313.59it/s]  4%|‚ñç         | 126/3257 [00:00<00:10, 301.10it/s]  5%|‚ñç         | 160/3257 [00:00<00:09, 312.54it/s]  6%|‚ñå         | 192/3257 [00:00<00:09, 313.32it/s]  7%|‚ñã         | 229/3257 [00:00<00:09, 329.34it/s]  8%|‚ñä         | 262/3257 [00:00<00:09, 319.53it/s]  9%|‚ñâ         | 300/3257 [00:00<00:08, 334.12it/s] 10%|‚ñà         | 335/3257 [00:01<00:08, 335.53it/s] 11%|‚ñà‚ñè        | 369/3257 [00:01<00:08, 333.38it/s] 12%|‚ñà‚ñè        | 403/3257 [00:01<00:08, 319.06it/s] 13%|‚ñà‚ñé        | 436/3257 [00:01<00:09, 305.26it/s] 15%|‚ñà‚ñç        | 480/3257 [00:01<00:08, 341.93it/s] 16%|‚ñà‚ñå        | 527/3257 [00:01<00:07, 375.89it/s] 18%|‚ñà‚ñä        | 570/3257 [00:01<00:06, 388.83it/s] 19%|‚ñà‚ñâ        | 614/3257 [00:01<00:06, 403.34it/s] 20%|‚ñà‚ñà        | 655/3257 [00:01<00:06, 402.51it/s] 21%|‚ñà‚ñà‚ñè       | 696/3257 [00:01<00:06, 402.85it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:02<00:06, 404.56it/s] 24%|‚ñà‚ñà‚ñç       | 782/3257 [00:02<00:05, 412.77it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:02<00:05, 415.18it/s] 27%|‚ñà‚ñà‚ñã       | 867/3257 [00:02<00:05, 404.76it/s] 28%|‚ñà‚ñà‚ñä       | 912/3257 [00:02<00:05, 417.26it/s] 29%|‚ñà‚ñà‚ñâ       | 955/3257 [00:02<00:05, 420.26it/s] 31%|‚ñà‚ñà‚ñà       | 998/3257 [00:02<00:05, 404.38it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1039/3257 [00:02<00:05, 391.50it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:02<00:05, 390.01it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1121/3257 [00:03<00:05, 393.79it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1162/3257 [00:03<00:05, 397.26it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1202/3257 [00:03<00:07, 263.53it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:03<00:06, 290.45it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1278/3257 [00:03<00:06, 303.56it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1316/3257 [00:03<00:06, 320.55it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1356/3257 [00:03<00:05, 339.98it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1393/3257 [00:03<00:05, 347.02it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1435/3257 [00:04<00:04, 364.43it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1478/3257 [00:04<00:04, 381.14it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1519/3257 [00:04<00:04, 381.03it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1558/3257 [00:04<00:04, 366.23it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:04<00:04, 367.56it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:04<00:04, 368.71it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1672/3257 [00:04<00:04, 361.41it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1711/3257 [00:04<00:04, 369.27it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1749/3257 [00:04<00:04, 353.77it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1791/3257 [00:04<00:03, 370.14it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1829/3257 [00:05<00:03, 363.77it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1870/3257 [00:05<00:03, 376.50it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1912/3257 [00:05<00:03, 387.83it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1957/3257 [00:05<00:03, 404.15it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:05<00:03, 408.22it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2040/3257 [00:05<00:02, 406.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2081/3257 [00:05<00:02, 396.02it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:05<00:02, 381.58it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2160/3257 [00:05<00:02, 382.52it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2202/3257 [00:06<00:02, 391.90it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2242/3257 [00:06<00:02, 386.22it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2282/3257 [00:06<00:02, 389.81it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2326/3257 [00:06<00:02, 403.07it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2371/3257 [00:06<00:02, 412.62it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2413/3257 [00:06<00:02, 410.90it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2455/3257 [00:06<00:02, 397.01it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2501/3257 [00:06<00:01, 414.69it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2543/3257 [00:06<00:01, 413.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2585/3257 [00:07<00:02, 281.57it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2632/3257 [00:07<00:01, 321.70it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2671/3257 [00:07<00:01, 336.70it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:07<00:01, 343.91it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2754/3257 [00:07<00:01, 370.68it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2796/3257 [00:07<00:01, 382.77it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:07<00:01, 384.31it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:07<00:00, 407.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:07<00:00, 405.89it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2970/3257 [00:08<00:00, 397.31it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:08<00:00, 396.96it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3055/3257 [00:08<00:00, 405.24it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3099/3257 [00:08<00:00, 413.00it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3143/3257 [00:08<00:00, 417.72it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:08<00:00, 412.64it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3228/3257 [00:08<00:00, 417.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:08<00:00, 372.21it/s]
2023-02-07 19:07:09.201 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:07:09,202][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d80,n5,mc3,s0.249068,t4>', 'datetime': '2023-02-07T19:07:09.202515', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:07:09,203][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:07:09,203][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:07:09,337][gensim.models.doc2vec][INFO] - collected 924 word types and 3257 unique tags from a corpus of 3257 examples and 1455748 words
[2023-02-07 19:07:09,338][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:07:09,340][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 768 unique words (83.12% of original 924, drops 156)', 'datetime': '2023-02-07T19:07:09.340307', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:07:09,340][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 1455479 word corpus (99.98% of original 1455748, drops 269)', 'datetime': '2023-02-07T19:07:09.340491', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:07:09,343][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 924 items
[2023-02-07 19:07:09,343][gensim.models.word2vec][INFO] - sample=0.249068 downsamples 0 most-common words
[2023-02-07 19:07:09,343][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 1455479 word corpus (100.0%% of prior 1455479)', 'datetime': '2023-02-07T19:07:09.343384', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:07:09,348][gensim.models.word2vec][INFO] - estimated required memory for 768 words and 80 dimensions: 2569160 bytes
[2023-02-07 19:07:09,348][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:07:09,349][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 768 vocabulary and 80 features, using sg=1 hs=0 sample=0.24906795861002184 negative=5 window=9 shrink_windows=True', 'datetime': '2023-02-07T19:07:09.349763', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:07:09,914][gensim.models.word2vec][INFO] - EPOCH 0: training on 1455748 raw words (1458736 effective words) took 0.6s, 2596527 effective words/s
[2023-02-07 19:07:10,346][gensim.models.word2vec][INFO] - EPOCH 1: training on 1455748 raw words (1458736 effective words) took 0.4s, 3381274 effective words/s
[2023-02-07 19:07:10,751][gensim.models.word2vec][INFO] - EPOCH 2: training on 1455748 raw words (1458736 effective words) took 0.4s, 3615773 effective words/s
[2023-02-07 19:07:11,163][gensim.models.word2vec][INFO] - EPOCH 3: training on 1455748 raw words (1458736 effective words) took 0.4s, 3552567 effective words/s
[2023-02-07 19:07:11,573][gensim.models.word2vec][INFO] - EPOCH 4: training on 1455748 raw words (1458736 effective words) took 0.4s, 3564430 effective words/s
[2023-02-07 19:07:11,983][gensim.models.word2vec][INFO] - EPOCH 5: training on 1455748 raw words (1458736 effective words) took 0.4s, 3572048 effective words/s
[2023-02-07 19:07:12,394][gensim.models.word2vec][INFO] - EPOCH 6: training on 1455748 raw words (1458736 effective words) took 0.4s, 3562049 effective words/s
[2023-02-07 19:07:12,800][gensim.models.word2vec][INFO] - EPOCH 7: training on 1455748 raw words (1458736 effective words) took 0.4s, 3608761 effective words/s
[2023-02-07 19:07:13,206][gensim.models.word2vec][INFO] - EPOCH 8: training on 1455748 raw words (1458736 effective words) took 0.4s, 3603052 effective words/s
[2023-02-07 19:07:13,617][gensim.models.word2vec][INFO] - EPOCH 9: training on 1455748 raw words (1458736 effective words) took 0.4s, 3564263 effective words/s
[2023-02-07 19:07:14,057][gensim.models.word2vec][INFO] - EPOCH 10: training on 1455748 raw words (1458736 effective words) took 0.4s, 3323388 effective words/s
[2023-02-07 19:07:14,499][gensim.models.word2vec][INFO] - EPOCH 11: training on 1455748 raw words (1458736 effective words) took 0.4s, 3318423 effective words/s
[2023-02-07 19:07:14,939][gensim.models.word2vec][INFO] - EPOCH 12: training on 1455748 raw words (1458736 effective words) took 0.4s, 3320659 effective words/s
[2023-02-07 19:07:15,386][gensim.models.word2vec][INFO] - EPOCH 13: training on 1455748 raw words (1458736 effective words) took 0.4s, 3279718 effective words/s
[2023-02-07 19:07:15,835][gensim.models.word2vec][INFO] - EPOCH 14: training on 1455748 raw words (1458736 effective words) took 0.4s, 3265793 effective words/s
[2023-02-07 19:07:15,835][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 21836220 raw words (21881040 effective words) took 6.5s, 3374263 effective words/s', 'datetime': '2023-02-07T19:07:15.835528', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:07:15.835 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:07:16,473][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190651-zw01cl87/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:07:16.473346', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:07:16,473][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:07:16,480][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190651-zw01cl87/files/../tmp/embedding_model.pt
2023-02-07 19:07:16.480 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:07:17.603 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:07:18.106 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:07:18.740 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9295821771377801, 'test_mae': 0.7348959596336253, 'test_r2': -2.1833823386238715}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.42
wandb: percentage 0.16883
wandb:   test_mae 0.7349
wandb:   test_mse 0.92958
wandb:    test_r2 -2.18338
wandb: 
wandb: üöÄ View run drawn-sweep-29 at: https://wandb.ai/xiaoqiz/mof2vec/runs/zw01cl87
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_190651-zw01cl87/logs
wandb: Agent Starting Run: tm4ua85s with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 505
wandb: 	model.gensim.alpha: 0.0014210844313640057
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.2858639044181347
wandb: 	model.gensim.vector_size: 365
wandb: 	model.gensim.window: 4
wandb: 	model.sklearn.learning_rate: 0.05749896072560153
wandb: 	model.sklearn.max_depth: 48
wandb: 	model.sklearn.min_child_weight: 0.07190221421907404
wandb: 	model.sklearn.n_estimators: 1578
wandb: 	model.sklearn.num_leaves: 443
wandb: 	model.sklearn.reg_alpha: 0.003913265917957322
wandb: 	model.sklearn.reg_lambda: 0.03679096540790606
wandb: 	model.sklearn.subsample: 0.2610657996147932
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190733-tm4ua85s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/tm4ua85s
2023-02-07 19:07:42.191 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:07:42.192 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 505 for sweep.
2023-02-07 19:07:42.192 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0014210844313640057 for sweep.
2023-02-07 19:07:42.193 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:07:42.193 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 19:07:42.193 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2858639044181347 for sweep.
2023-02-07 19:07:42.195 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 365 for sweep.
2023-02-07 19:07:42.195 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 4 for sweep.
2023-02-07 19:07:42.195 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.05749896072560153 for sweep.
2023-02-07 19:07:42.195 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 48 for sweep.
2023-02-07 19:07:42.195 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.07190221421907404 for sweep.
2023-02-07 19:07:42.196 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1578 for sweep.
2023-02-07 19:07:42.196 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 443 for sweep.
2023-02-07 19:07:42.196 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.003913265917957322 for sweep.
2023-02-07 19:07:42.196 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.03679096540790606 for sweep.
2023-02-07 19:07:42.196 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2610657996147932 for sweep.
2023-02-07 19:07:42.197 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:07:42.204 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190733-tm4ua85s/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 505, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 365, 'window': 4, 'min_count': 1, 'dm': 0, 'sample': 0.2858639044181347, 'workers': 4, 'alpha': 0.0014210844313640057, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1578, 'max_depth': 48, 'num_leaves': 443, 'reg_alpha': 0.003913265917957322, 'reg_lambda': 0.03679096540790606, 'subsample': 0.2610657996147932, 'min_child_weight': 0.07190221421907404, 'n_jobs': 4, 'learning_rate': 0.05749896072560153}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 19/3257 [00:00<00:17, 186.38it/s]  1%|‚ñè         | 41/3257 [00:00<00:16, 200.37it/s]  2%|‚ñè         | 62/3257 [00:00<00:16, 198.43it/s]  3%|‚ñé         | 84/3257 [00:00<00:15, 204.23it/s]  3%|‚ñé         | 105/3257 [00:00<00:16, 194.73it/s]  4%|‚ñç         | 125/3257 [00:00<00:16, 187.62it/s]  5%|‚ñç         | 149/3257 [00:00<00:15, 200.37it/s]  5%|‚ñå         | 170/3257 [00:00<00:15, 194.83it/s]  6%|‚ñå         | 190/3257 [00:00<00:15, 196.04it/s]  6%|‚ñã         | 211/3257 [00:01<00:15, 197.11it/s]  7%|‚ñã         | 234/3257 [00:01<00:14, 204.94it/s]  8%|‚ñä         | 255/3257 [00:01<00:14, 201.20it/s]  8%|‚ñä         | 276/3257 [00:01<00:14, 199.72it/s]  9%|‚ñâ         | 298/3257 [00:01<00:14, 203.92it/s] 10%|‚ñâ         | 319/3257 [00:01<00:14, 199.49it/s] 10%|‚ñà         | 339/3257 [00:01<00:15, 194.48it/s] 11%|‚ñà         | 360/3257 [00:01<00:14, 197.15it/s] 12%|‚ñà‚ñè        | 380/3257 [00:01<00:15, 185.88it/s] 12%|‚ñà‚ñè        | 399/3257 [00:02<00:15, 182.87it/s] 13%|‚ñà‚ñé        | 420/3257 [00:02<00:14, 189.92it/s] 14%|‚ñà‚ñé        | 440/3257 [00:02<00:16, 167.73it/s] 14%|‚ñà‚ñç        | 460/3257 [00:02<00:16, 174.78it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:15, 175.10it/s] 15%|‚ñà‚ñå        | 501/3257 [00:02<00:14, 186.44it/s] 16%|‚ñà‚ñå        | 522/3257 [00:02<00:14, 191.85it/s] 17%|‚ñà‚ñã        | 543/3257 [00:02<00:13, 195.49it/s] 17%|‚ñà‚ñã        | 563/3257 [00:02<00:14, 181.24it/s] 18%|‚ñà‚ñä        | 582/3257 [00:03<00:15, 177.26it/s] 18%|‚ñà‚ñä        | 601/3257 [00:03<00:20, 129.47it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:18, 140.73it/s] 20%|‚ñà‚ñâ        | 642/3257 [00:03<00:16, 158.75it/s] 20%|‚ñà‚ñà        | 660/3257 [00:03<00:16, 157.12it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:15, 167.64it/s] 22%|‚ñà‚ñà‚ñè       | 703/3257 [00:03<00:14, 175.88it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:03<00:14, 178.83it/s] 23%|‚ñà‚ñà‚ñé       | 741/3257 [00:04<00:14, 172.02it/s] 23%|‚ñà‚ñà‚ñé       | 763/3257 [00:04<00:13, 184.22it/s] 24%|‚ñà‚ñà‚ñç       | 782/3257 [00:04<00:13, 180.52it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:04<00:13, 187.48it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:04<00:13, 178.72it/s] 26%|‚ñà‚ñà‚ñå       | 842/3257 [00:04<00:13, 173.25it/s] 26%|‚ñà‚ñà‚ñã       | 863/3257 [00:04<00:13, 182.80it/s] 27%|‚ñà‚ñà‚ñã       | 882/3257 [00:04<00:13, 178.95it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:04<00:12, 188.50it/s] 28%|‚ñà‚ñà‚ñä       | 925/3257 [00:05<00:12, 189.40it/s] 29%|‚ñà‚ñà‚ñâ       | 945/3257 [00:05<00:12, 188.51it/s] 30%|‚ñà‚ñà‚ñâ       | 967/3257 [00:05<00:11, 193.20it/s] 30%|‚ñà‚ñà‚ñà       | 987/3257 [00:05<00:12, 184.95it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:05<00:12, 182.39it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:05<00:12, 183.70it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:05<00:12, 181.06it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:05<00:11, 186.55it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1086/3257 [00:05<00:11, 186.87it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:06<00:11, 187.71it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:06<00:11, 185.68it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:06<00:11, 180.55it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1164/3257 [00:06<00:11, 187.84it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1183/3257 [00:06<00:11, 176.00it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1201/3257 [00:06<00:12, 160.98it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:06<00:12, 165.67it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:06<00:11, 182.18it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1261/3257 [00:06<00:10, 183.56it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1280/3257 [00:07<00:11, 174.11it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1298/3257 [00:07<00:11, 171.54it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1319/3257 [00:07<00:10, 180.66it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:07<00:10, 184.32it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1358/3257 [00:07<00:10, 179.44it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1377/3257 [00:07<00:10, 178.14it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1395/3257 [00:07<00:10, 178.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1420/3257 [00:07<00:09, 197.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1440/3257 [00:07<00:09, 192.10it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1465/3257 [00:07<00:08, 207.75it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1486/3257 [00:08<00:08, 207.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:08<00:07, 218.41it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1533/3257 [00:08<00:08, 197.85it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1554/3257 [00:08<00:08, 189.51it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:08<00:08, 189.77it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:08<00:08, 194.99it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1618/3257 [00:08<00:08, 200.75it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:08<00:08, 193.13it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1659/3257 [00:08<00:08, 187.09it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1678/3257 [00:09<00:08, 181.96it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:09<00:08, 191.33it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1721/3257 [00:09<00:07, 194.76it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1741/3257 [00:09<00:08, 176.14it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1761/3257 [00:09<00:08, 180.73it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1780/3257 [00:09<00:08, 178.19it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1799/3257 [00:09<00:08, 177.33it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1817/3257 [00:10<00:14, 99.09it/s]  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1832/3257 [00:10<00:13, 107.47it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1850/3257 [00:10<00:11, 121.75it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:10<00:10, 136.62it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1886/3257 [00:10<00:09, 144.71it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1905/3257 [00:10<00:08, 154.47it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1922/3257 [00:10<00:08, 155.16it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1945/3257 [00:10<00:07, 174.37it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1967/3257 [00:10<00:06, 186.76it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1987/3257 [00:11<00:07, 176.33it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2006/3257 [00:11<00:06, 179.15it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2025/3257 [00:11<00:06, 181.84it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2044/3257 [00:11<00:06, 177.25it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2062/3257 [00:11<00:07, 161.21it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2082/3257 [00:11<00:06, 170.14it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:11<00:07, 160.18it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:11<00:07, 161.15it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:12<00:07, 159.80it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:12<00:07, 157.04it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2173/3257 [00:12<00:06, 163.37it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2190/3257 [00:12<00:06, 162.62it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2207/3257 [00:12<00:06, 163.89it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2224/3257 [00:12<00:06, 163.11it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2241/3257 [00:12<00:06, 158.70it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:12<00:06, 160.83it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:12<00:06, 149.73it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2298/3257 [00:13<00:05, 166.56it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:13<00:05, 165.96it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:13<00:05, 180.05it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:13<00:04, 189.72it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2380/3257 [00:13<00:04, 191.01it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2400/3257 [00:13<00:04, 190.77it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2420/3257 [00:13<00:04, 180.43it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2439/3257 [00:13<00:04, 172.37it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2457/3257 [00:13<00:04, 170.32it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2477/3257 [00:14<00:04, 178.23it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2497/3257 [00:14<00:04, 183.21it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2518/3257 [00:14<00:03, 190.37it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2538/3257 [00:14<00:03, 192.97it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2558/3257 [00:14<00:03, 179.24it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2577/3257 [00:14<00:03, 170.08it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2595/3257 [00:14<00:03, 167.21it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2619/3257 [00:14<00:03, 186.33it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2640/3257 [00:14<00:03, 188.77it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2660/3257 [00:15<00:03, 174.19it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2680/3257 [00:15<00:03, 179.25it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2699/3257 [00:15<00:03, 165.78it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2716/3257 [00:15<00:03, 160.40it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2739/3257 [00:15<00:02, 178.73it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2758/3257 [00:15<00:02, 179.45it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2777/3257 [00:15<00:02, 171.39it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2799/3257 [00:15<00:02, 184.47it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2818/3257 [00:15<00:02, 174.96it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2836/3257 [00:16<00:02, 170.61it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2858/3257 [00:16<00:02, 183.77it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2882/3257 [00:16<00:01, 199.50it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:16<00:01, 180.19it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2924/3257 [00:16<00:01, 187.47it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2944/3257 [00:16<00:01, 170.32it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2962/3257 [00:16<00:01, 172.11it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2980/3257 [00:16<00:01, 166.92it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3000/3257 [00:16<00:01, 174.64it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:17<00:01, 170.25it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3039/3257 [00:17<00:01, 179.76it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3062/3257 [00:17<00:01, 193.13it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:17<00:00, 188.75it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3103/3257 [00:17<00:00, 194.07it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3124/3257 [00:17<00:00, 198.21it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3144/3257 [00:17<00:00, 183.65it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3163/3257 [00:17<00:00, 183.30it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3182/3257 [00:18<00:00, 106.00it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3208/3257 [00:18<00:00, 134.12it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3233/3257 [00:18<00:00, 157.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 175.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 176.20it/s]
2023-02-07 19:08:01.293 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:08:01,295][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d365,n5,s0.285864,t4>', 'datetime': '2023-02-07T19:08:01.295113', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:08:01,295][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:08:01,295][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:08:01,793][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:08:01,793][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:08:01,875][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 31803 unique words (100.00% of original 31803, drops 0)', 'datetime': '2023-02-07T19:08:01.875580', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:08:01,875][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 5095118 word corpus (100.00% of original 5095118, drops 0)', 'datetime': '2023-02-07T19:08:01.875954', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:08:01,984][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:08:01,985][gensim.models.word2vec][INFO] - sample=0.285864 downsamples 0 most-common words
[2023-02-07 19:08:01,985][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5095118 word corpus (100.0%% of prior 5095118)', 'datetime': '2023-02-07T19:08:01.985624', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:08:02,172][gensim.models.word2vec][INFO] - estimated required memory for 31803 words and 365 dimensions: 114172880 bytes
[2023-02-07 19:08:02,172][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:08:02,222][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 31803 vocabulary and 365 features, using sg=1 hs=0 sample=0.2858639044181347 negative=5 window=4 shrink_windows=True', 'datetime': '2023-02-07T19:08:02.222553', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:08:03,234][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 32.91% examples, 1673357 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:04,235][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 66.04% examples, 1707519 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:05,180][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5086629 effective words) took 3.0s, 1721190 effective words/s
[2023-02-07 19:08:06,183][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 34.48% examples, 1774999 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:07,184][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 69.20% examples, 1795520 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:08,005][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5086629 effective words) took 2.8s, 1801449 effective words/s
[2023-02-07 19:08:09,018][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 35.06% examples, 1793063 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:10,022][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 70.65% examples, 1825746 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:08:10,809][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5086629 effective words) took 2.8s, 1815773 effective words/s
[2023-02-07 19:08:11,817][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 30.95% examples, 1579148 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:12,826][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 61.84% examples, 1584675 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:08:13,827][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 94.01% examples, 1590963 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:14,004][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5086629 effective words) took 3.2s, 1593774 effective words/s
[2023-02-07 19:08:15,013][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 30.95% examples, 1577226 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:16,019][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 62.39% examples, 1597058 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:17,020][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 94.60% examples, 1600684 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:17,174][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5086629 effective words) took 3.2s, 1605504 effective words/s
[2023-02-07 19:08:18,187][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 31.56% examples, 1604634 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:19,188][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 62.60% examples, 1606313 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:20,112][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5086629 effective words) took 2.9s, 1732615 effective words/s
[2023-02-07 19:08:21,116][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 36.69% examples, 1904095 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:22,120][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 72.43% examples, 1864551 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:22,862][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5086629 effective words) took 2.7s, 1851136 effective words/s
[2023-02-07 19:08:23,865][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 35.06% examples, 1809251 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:08:24,866][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 69.73% examples, 1813774 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:25,658][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5086629 effective words) took 2.8s, 1819780 effective words/s
[2023-02-07 19:08:26,668][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 35.06% examples, 1796150 words/s, in_qsize 6, out_qsize 3
[2023-02-07 19:08:27,673][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 70.86% examples, 1831155 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:28,421][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5086629 effective words) took 2.8s, 1841873 effective words/s
[2023-02-07 19:08:29,428][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.32% examples, 1873579 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:30,435][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 67.79% examples, 1749000 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:31,399][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5086629 effective words) took 3.0s, 1709446 effective words/s
[2023-02-07 19:08:32,404][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 31.01% examples, 1589058 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:33,410][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 62.76% examples, 1612956 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:34,420][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 96.04% examples, 1618542 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:08:34,532][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5086629 effective words) took 3.1s, 1624721 effective words/s
[2023-02-07 19:08:35,535][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 31.72% examples, 1628645 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:36,537][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 63.22% examples, 1633945 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:37,538][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 96.47% examples, 1634248 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:37,643][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5086629 effective words) took 3.1s, 1635700 effective words/s
[2023-02-07 19:08:38,649][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 35.06% examples, 1804437 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:39,650][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 74.27% examples, 1910872 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:40,325][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5086629 effective words) took 2.7s, 1897950 effective words/s
[2023-02-07 19:08:41,340][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 35.06% examples, 1790879 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:42,343][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 69.73% examples, 1803044 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:43,141][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5086629 effective words) took 2.8s, 1808169 effective words/s
[2023-02-07 19:08:44,151][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 35.06% examples, 1797600 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:08:45,160][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 70.37% examples, 1814145 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:08:45,937][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5086629 effective words) took 2.8s, 1820613 effective words/s
[2023-02-07 19:08:45,938][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76299435 effective words) took 43.7s, 1745373 effective words/s', 'datetime': '2023-02-07T19:08:45.938231', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:08:45.938 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:08:49,760][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190733-tm4ua85s/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:08:49.760645', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:08:49,761][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190733-tm4ua85s/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 19:08:49,808][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190733-tm4ua85s/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 19:08:49,855][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:08:49,893][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190733-tm4ua85s/files/../tmp/embedding_model.pt
2023-02-07 19:08:49.894 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:08:52.223 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:08:53.021 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:08:55.573 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9505680224198213, 'test_mae': 0.7420928639594031, 'test_r2': -1.9239448286698893}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.42
wandb: percentage 0.0
wandb:   test_mae 0.74209
wandb:   test_mse 0.95057
wandb:    test_r2 -1.92394
wandb: 
wandb: üöÄ View run serene-sweep-30 at: https://wandb.ai/xiaoqiz/mof2vec/runs/tm4ua85s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_190733-tm4ua85s/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: s7n2m0fl with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 163
wandb: 	model.gensim.alpha: 0.00037466870960831
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.7476797670272899
wandb: 	model.gensim.vector_size: 263
wandb: 	model.gensim.window: 13
wandb: 	model.sklearn.learning_rate: 0.05392815360610149
wandb: 	model.sklearn.max_depth: 50
wandb: 	model.sklearn.min_child_weight: 0.06853151486486424
wandb: 	model.sklearn.n_estimators: 3689
wandb: 	model.sklearn.num_leaves: 164
wandb: 	model.sklearn.reg_alpha: 0.7475962961258431
wandb: 	model.sklearn.reg_lambda: 0.0558789670172986
wandb: 	model.sklearn.subsample: 0.3910899244819595
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190914-s7n2m0fl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/s7n2m0fl
2023-02-07 19:09:21.963 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:09:21.964 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 163 for sweep.
2023-02-07 19:09:21.964 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.00037466870960831 for sweep.
2023-02-07 19:09:21.964 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:09:21.964 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 19:09:21.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7476797670272899 for sweep.
2023-02-07 19:09:21.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 263 for sweep.
2023-02-07 19:09:21.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 13 for sweep.
2023-02-07 19:09:21.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.05392815360610149 for sweep.
2023-02-07 19:09:21.966 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 50 for sweep.
2023-02-07 19:09:21.966 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.06853151486486424 for sweep.
2023-02-07 19:09:21.966 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3689 for sweep.
2023-02-07 19:09:21.966 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 164 for sweep.
2023-02-07 19:09:21.966 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.7475962961258431 for sweep.
2023-02-07 19:09:21.967 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0558789670172986 for sweep.
2023-02-07 19:09:21.967 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.3910899244819595 for sweep.
2023-02-07 19:09:21.967 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:09:21.972 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190914-s7n2m0fl/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 163, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 263, 'window': 13, 'min_count': 10, 'dm': 1, 'sample': 0.7476797670272899, 'workers': 4, 'alpha': 0.00037466870960831, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3689, 'max_depth': 50, 'num_leaves': 164, 'reg_alpha': 0.7475962961258431, 'reg_lambda': 0.0558789670172986, 'subsample': 0.3910899244819595, 'min_child_weight': 0.06853151486486424, 'n_jobs': 4, 'learning_rate': 0.05392815360610149}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 166.94it/s]  1%|          | 35/3257 [00:00<00:18, 171.99it/s]  2%|‚ñè         | 53/3257 [00:00<00:18, 171.33it/s]  2%|‚ñè         | 73/3257 [00:00<00:17, 180.55it/s]  3%|‚ñé         | 93/3257 [00:00<00:17, 185.34it/s]  3%|‚ñé         | 112/3257 [00:00<00:18, 171.04it/s]  4%|‚ñç         | 132/3257 [00:00<00:17, 177.49it/s]  5%|‚ñç         | 152/3257 [00:00<00:16, 182.77it/s]  5%|‚ñå         | 171/3257 [00:00<00:17, 176.97it/s]  6%|‚ñå         | 191/3257 [00:01<00:16, 181.95it/s]  6%|‚ñã         | 210/3257 [00:01<00:16, 180.02it/s]  7%|‚ñã         | 232/3257 [00:01<00:15, 190.21it/s]  8%|‚ñä         | 252/3257 [00:01<00:15, 189.05it/s]  8%|‚ñä         | 271/3257 [00:01<00:16, 180.94it/s]  9%|‚ñâ         | 296/3257 [00:01<00:14, 198.60it/s] 10%|‚ñâ         | 316/3257 [00:01<00:15, 187.46it/s] 10%|‚ñà         | 337/3257 [00:01<00:15, 191.83it/s] 11%|‚ñà         | 358/3257 [00:01<00:14, 194.91it/s] 12%|‚ñà‚ñè        | 378/3257 [00:02<00:16, 175.80it/s] 12%|‚ñà‚ñè        | 397/3257 [00:02<00:16, 178.23it/s] 13%|‚ñà‚ñé        | 417/3257 [00:02<00:15, 183.95it/s] 13%|‚ñà‚ñé        | 436/3257 [00:02<00:18, 156.54it/s] 14%|‚ñà‚ñç        | 457/3257 [00:02<00:16, 168.53it/s] 15%|‚ñà‚ñç        | 476/3257 [00:02<00:16, 172.74it/s] 15%|‚ñà‚ñå        | 496/3257 [00:02<00:15, 179.39it/s] 16%|‚ñà‚ñå        | 517/3257 [00:02<00:14, 184.94it/s] 16%|‚ñà‚ñã        | 536/3257 [00:02<00:14, 184.26it/s] 17%|‚ñà‚ñã        | 556/3257 [00:03<00:14, 185.95it/s] 18%|‚ñà‚ñä        | 575/3257 [00:03<00:16, 163.16it/s] 18%|‚ñà‚ñä        | 597/3257 [00:03<00:14, 178.09it/s] 19%|‚ñà‚ñâ        | 619/3257 [00:03<00:13, 189.21it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:03<00:14, 181.83it/s] 20%|‚ñà‚ñà        | 658/3257 [00:03<00:15, 166.87it/s] 21%|‚ñà‚ñà        | 679/3257 [00:03<00:14, 176.43it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:03<00:15, 169.65it/s] 22%|‚ñà‚ñà‚ñè       | 719/3257 [00:04<00:14, 177.89it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:04<00:15, 162.22it/s] 23%|‚ñà‚ñà‚ñé       | 758/3257 [00:04<00:14, 171.66it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:04<00:14, 168.52it/s] 24%|‚ñà‚ñà‚ñç       | 796/3257 [00:04<00:14, 174.21it/s] 25%|‚ñà‚ñà‚ñç       | 814/3257 [00:04<00:14, 174.43it/s] 26%|‚ñà‚ñà‚ñå       | 832/3257 [00:04<00:14, 170.44it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:04<00:14, 162.39it/s] 27%|‚ñà‚ñà‚ñã       | 869/3257 [00:04<00:14, 169.07it/s] 27%|‚ñà‚ñà‚ñã       | 887/3257 [00:05<00:13, 169.74it/s] 28%|‚ñà‚ñà‚ñä       | 908/3257 [00:05<00:13, 178.82it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:05<00:12, 184.25it/s] 29%|‚ñà‚ñà‚ñâ       | 947/3257 [00:05<00:12, 183.33it/s] 30%|‚ñà‚ñà‚ñâ       | 967/3257 [00:05<00:12, 184.81it/s] 30%|‚ñà‚ñà‚ñà       | 986/3257 [00:05<00:12, 176.13it/s] 31%|‚ñà‚ñà‚ñà       | 1005/3257 [00:05<00:12, 179.42it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1024/3257 [00:05<00:12, 179.65it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1043/3257 [00:05<00:13, 160.32it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:06<00:13, 166.29it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:19, 111.42it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1099/3257 [00:06<00:17, 126.89it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:06<00:15, 138.63it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1134/3257 [00:06<00:14, 144.01it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1151/3257 [00:06<00:14, 148.06it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:06<00:12, 160.93it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1189/3257 [00:06<00:13, 148.43it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1206/3257 [00:07<00:13, 153.94it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1225/3257 [00:07<00:12, 163.40it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:07<00:11, 170.88it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1266/3257 [00:07<00:11, 180.52it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1285/3257 [00:07<00:12, 163.14it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1304/3257 [00:07<00:11, 167.40it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1324/3257 [00:07<00:11, 175.62it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:07<00:10, 181.70it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1363/3257 [00:07<00:10, 179.36it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1382/3257 [00:08<00:11, 167.06it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:08<00:10, 171.04it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:08<00:10, 181.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1442/3257 [00:08<00:09, 181.96it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1466/3257 [00:08<00:09, 196.41it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1486/3257 [00:08<00:09, 194.48it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1510/3257 [00:08<00:08, 206.61it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1531/3257 [00:08<00:09, 184.65it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:08<00:09, 178.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1569/3257 [00:09<00:09, 177.70it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1588/3257 [00:09<00:09, 174.03it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1609/3257 [00:09<00:09, 182.65it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1630/3257 [00:09<00:08, 188.62it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:09<00:09, 172.65it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:09<00:09, 172.13it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1686/3257 [00:09<00:09, 171.78it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1706/3257 [00:09<00:08, 179.13it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1726/3257 [00:09<00:08, 184.82it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:10<00:09, 163.68it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1765/3257 [00:10<00:08, 173.30it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1787/3257 [00:10<00:07, 184.52it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1806/3257 [00:10<00:08, 177.70it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1825/3257 [00:10<00:08, 177.89it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1844/3257 [00:10<00:07, 179.03it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1863/3257 [00:10<00:07, 180.83it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1883/3257 [00:10<00:07, 181.90it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1902/3257 [00:10<00:07, 183.48it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1921/3257 [00:11<00:07, 178.35it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1946/3257 [00:11<00:06, 198.65it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1971/3257 [00:11<00:06, 210.99it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1993/3257 [00:11<00:06, 198.01it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2014/3257 [00:11<00:06, 194.54it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2036/3257 [00:11<00:06, 200.26it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2057/3257 [00:11<00:06, 180.52it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2076/3257 [00:11<00:06, 182.05it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2095/3257 [00:11<00:06, 179.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2114/3257 [00:12<00:06, 180.45it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2133/3257 [00:12<00:06, 165.49it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2150/3257 [00:12<00:06, 162.78it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2172/3257 [00:12<00:06, 176.71it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2190/3257 [00:12<00:06, 174.85it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:12<00:06, 171.75it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2228/3257 [00:12<00:05, 176.02it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2246/3257 [00:12<00:05, 172.74it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2265/3257 [00:12<00:05, 176.48it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2283/3257 [00:13<00:05, 176.28it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2302/3257 [00:13<00:05, 179.28it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2328/3257 [00:13<00:04, 200.33it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2353/3257 [00:13<00:04, 211.16it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2375/3257 [00:13<00:04, 204.61it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:13<00:04, 210.90it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2421/3257 [00:13<00:04, 198.62it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2442/3257 [00:14<00:07, 109.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2463/3257 [00:14<00:06, 126.76it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2483/3257 [00:14<00:05, 141.00it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:14<00:04, 161.66it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2528/3257 [00:14<00:04, 173.01it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2550/3257 [00:14<00:03, 182.78it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2571/3257 [00:14<00:03, 173.91it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2590/3257 [00:14<00:03, 171.77it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2617/3257 [00:14<00:03, 195.77it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2640/3257 [00:15<00:03, 200.71it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2661/3257 [00:15<00:03, 185.41it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2682/3257 [00:15<00:02, 191.74it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2702/3257 [00:15<00:03, 175.40it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2721/3257 [00:15<00:03, 176.07it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2746/3257 [00:15<00:02, 193.53it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2766/3257 [00:15<00:02, 193.48it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2786/3257 [00:15<00:02, 194.94it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:15<00:02, 192.25it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2827/3257 [00:16<00:02, 184.15it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2846/3257 [00:16<00:02, 183.62it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2873/3257 [00:16<00:01, 206.30it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2894/3257 [00:16<00:01, 193.55it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:16<00:01, 196.12it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2936/3257 [00:16<00:01, 195.62it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2956/3257 [00:16<00:01, 180.55it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:16<00:01, 184.46it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2996/3257 [00:16<00:01, 187.32it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:17<00:01, 190.70it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3039/3257 [00:17<00:01, 199.58it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3064/3257 [00:17<00:00, 212.34it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3086/3257 [00:17<00:00, 203.75it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3109/3257 [00:17<00:00, 208.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3130/3257 [00:17<00:00, 207.79it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3151/3257 [00:17<00:00, 194.32it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3172/3257 [00:17<00:00, 197.37it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3192/3257 [00:17<00:00, 195.71it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3212/3257 [00:18<00:00, 192.15it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3234/3257 [00:18<00:00, 197.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3254/3257 [00:18<00:00, 197.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 178.32it/s]
2023-02-07 19:09:40.983 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:09:40,985][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d263,n5,w13,mc10,s0.74768,t4>', 'datetime': '2023-02-07T19:09:40.985246', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:09:40,985][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:09:40,985][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:09:41,504][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:09:41,505][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:09:41,547][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 14497 unique words (33.95% of original 42701, drops 28204)', 'datetime': '2023-02-07T19:09:41.547459', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:09:41,548][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 5720668 word corpus (98.24% of original 5822992, drops 102324)', 'datetime': '2023-02-07T19:09:41.548853', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:09:41,597][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:09:41,597][gensim.models.word2vec][INFO] - sample=0.74768 downsamples 0 most-common words
[2023-02-07 19:09:41,598][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5720668 word corpus (100.0%% of prior 5720668)', 'datetime': '2023-02-07T19:09:41.597983', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:09:41,682][gensim.models.word2vec][INFO] - estimated required memory for 14497 words and 263 dimensions: 41827952 bytes
[2023-02-07 19:09:41,682][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:09:41,700][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14497 vocabulary and 263 features, using sg=0 hs=0 sample=0.7476797670272899 negative=5 window=13 shrink_windows=True', 'datetime': '2023-02-07T19:09:41.700134', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:09:42,719][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 22.60% examples, 1260039 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:43,734][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 44.61% examples, 1279696 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:44,738][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 66.99% examples, 1284192 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:45,741][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 89.90% examples, 1275753 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:46,168][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5694995 effective words) took 4.5s, 1275330 effective words/s
[2023-02-07 19:09:47,179][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 22.11% examples, 1232108 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:48,185][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 43.35% examples, 1258488 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:49,187][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 66.38% examples, 1279520 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:50,188][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 89.90% examples, 1282582 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:50,611][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5694995 effective words) took 4.4s, 1282374 effective words/s
[2023-02-07 19:09:51,615][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 22.78% examples, 1286481 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:52,615][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 44.67% examples, 1299298 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:09:53,616][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 71.26% examples, 1379627 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:54,564][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5694995 effective words) took 4.0s, 1441666 effective words/s
[2023-02-07 19:09:55,572][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 27.23% examples, 1551862 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:56,576][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 54.77% examples, 1586030 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:57,580][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 81.46% examples, 1552410 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:09:58,337][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5694995 effective words) took 3.8s, 1509798 effective words/s
[2023-02-07 19:09:59,343][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 23.61% examples, 1324851 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:00,344][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 48.45% examples, 1406703 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:01,348][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 77.10% examples, 1475092 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:02,196][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5694995 effective words) took 3.9s, 1476641 effective words/s
[2023-02-07 19:10:03,201][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 25.42% examples, 1442151 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:04,208][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 50.45% examples, 1459181 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:05,212][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 75.41% examples, 1446797 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:10:06,205][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5694995 effective words) took 4.0s, 1420914 effective words/s
[2023-02-07 19:10:07,214][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 23.15% examples, 1303207 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:08,219][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 46.61% examples, 1340735 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:09,220][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 74.36% examples, 1425494 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:10,173][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5694995 effective words) took 4.0s, 1436224 effective words/s
[2023-02-07 19:10:11,177][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 25.42% examples, 1442909 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:12,180][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 49.40% examples, 1432823 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:13,184][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 72.43% examples, 1390799 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:14,186][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 96.07% examples, 1364821 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:10:14,346][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5694995 effective words) took 4.2s, 1365073 effective words/s
[2023-02-07 19:10:15,353][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 24.04% examples, 1359225 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:16,354][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 51.06% examples, 1481009 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:10:17,361][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 77.10% examples, 1473327 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:10:18,199][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5694995 effective words) took 3.9s, 1478800 effective words/s
[2023-02-07 19:10:19,210][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 23.92% examples, 1343313 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:10:20,218][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 46.36% examples, 1329203 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:21,220][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 68.84% examples, 1327270 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:22,224][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 96.07% examples, 1360417 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:22,358][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5694995 effective words) took 4.2s, 1369855 effective words/s
[2023-02-07 19:10:23,366][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 26.99% examples, 1535097 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:24,379][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 52.59% examples, 1515328 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:25,381][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 78.05% examples, 1485258 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:10:26,273][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5694995 effective words) took 3.9s, 1455149 effective words/s
[2023-02-07 19:10:27,285][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 23.15% examples, 1299640 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:28,287][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 46.12% examples, 1326966 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:29,289][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 73.81% examples, 1412953 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:10:30,270][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5694995 effective words) took 4.0s, 1425846 effective words/s
[2023-02-07 19:10:31,275][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 25.30% examples, 1434431 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:32,286][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 47.37% examples, 1366249 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:33,286][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 69.88% examples, 1352891 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:34,298][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 94.53% examples, 1340209 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:10:34,469][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5694995 effective words) took 4.2s, 1356644 effective words/s
[2023-02-07 19:10:35,478][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 28.34% examples, 1607992 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:36,479][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 53.18% examples, 1542338 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:37,482][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 79.15% examples, 1513941 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:38,270][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5694995 effective words) took 3.8s, 1499247 effective words/s
[2023-02-07 19:10:39,272][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 25.15% examples, 1422341 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:40,273][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 49.68% examples, 1440222 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:41,274][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 74.76% examples, 1440545 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:10:42,202][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5694995 effective words) took 3.9s, 1448574 effective words/s
[2023-02-07 19:10:42,203][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85424925 effective words) took 60.5s, 1411918 effective words/s', 'datetime': '2023-02-07T19:10:42.203261', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:10:42.203 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:10:46,636][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190914-s7n2m0fl/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:10:46.636071', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:10:46,636][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:10:46,686][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_190914-s7n2m0fl/files/../tmp/embedding_model.pt
2023-02-07 19:10:46.686 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:10:48.496 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:10:49.096 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:10:50.877 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1396459288730476, 'test_mae': 0.8186745135787806, 'test_r2': -3.129763704661893}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.1
wandb: percentage 0.6605
wandb:   test_mae 0.81867
wandb:   test_mse 1.13965
wandb:    test_r2 -3.12976
wandb: 
wandb: üöÄ View run peach-sweep-31 at: https://wandb.ai/xiaoqiz/mof2vec/runs/s7n2m0fl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_190914-s7n2m0fl/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 6lejsat4 with config:
wandb: 	data.data.wl_step: 3
wandb: 	data.nn.batch_size: 478
wandb: 	model.gensim.alpha: 0.0006734772898720208
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.2917543930716804
wandb: 	model.gensim.vector_size: 431
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.0005997315233143936
wandb: 	model.sklearn.max_depth: 24
wandb: 	model.sklearn.min_child_weight: 0.05469600338502428
wandb: 	model.sklearn.n_estimators: 2275
wandb: 	model.sklearn.num_leaves: 346
wandb: 	model.sklearn.reg_alpha: 0.27817620330712955
wandb: 	model.sklearn.reg_lambda: 0.06241854132120104
wandb: 	model.sklearn.subsample: 0.8461145520575468
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191109-6lejsat4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-32
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/6lejsat4
2023-02-07 19:11:17.578 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 3 for sweep.
2023-02-07 19:11:17.578 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 478 for sweep.
2023-02-07 19:11:17.579 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0006734772898720208 for sweep.
2023-02-07 19:11:17.579 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:11:17.579 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 19:11:17.580 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.2917543930716804 for sweep.
2023-02-07 19:11:17.580 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 431 for sweep.
2023-02-07 19:11:17.580 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 19:11:17.580 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0005997315233143936 for sweep.
2023-02-07 19:11:17.581 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 24 for sweep.
2023-02-07 19:11:17.581 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05469600338502428 for sweep.
2023-02-07 19:11:17.581 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2275 for sweep.
2023-02-07 19:11:17.581 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 346 for sweep.
2023-02-07 19:11:17.582 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.27817620330712955 for sweep.
2023-02-07 19:11:17.582 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.06241854132120104 for sweep.
2023-02-07 19:11:17.582 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8461145520575468 for sweep.
2023-02-07 19:11:17.582 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:11:17.591 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 3}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191109-6lejsat4/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 478, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 431, 'window': 11, 'min_count': 7, 'dm': 1, 'sample': 0.2917543930716804, 'workers': 4, 'alpha': 0.0006734772898720208, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2275, 'max_depth': 24, 'num_leaves': 346, 'reg_alpha': 0.27817620330712955, 'reg_lambda': 0.06241854132120104, 'subsample': 0.8461145520575468, 'min_child_weight': 0.05469600338502428, 'n_jobs': 4, 'learning_rate': 0.0005997315233143936}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 24/3257 [00:00<00:13, 236.54it/s]  2%|‚ñè         | 50/3257 [00:00<00:13, 241.64it/s]  2%|‚ñè         | 75/3257 [00:00<00:12, 245.02it/s]  3%|‚ñé         | 101/3257 [00:00<00:12, 249.55it/s]  4%|‚ñç         | 126/3257 [00:00<00:12, 240.93it/s]  5%|‚ñç         | 154/3257 [00:00<00:12, 249.27it/s]  5%|‚ñå         | 179/3257 [00:00<00:12, 243.30it/s]  6%|‚ñã         | 207/3257 [00:00<00:12, 252.97it/s]  7%|‚ñã         | 237/3257 [00:00<00:11, 264.48it/s]  8%|‚ñä         | 264/3257 [00:01<00:11, 263.31it/s]  9%|‚ñâ         | 295/3257 [00:01<00:10, 274.94it/s] 10%|‚ñâ         | 323/3257 [00:01<00:10, 269.23it/s] 11%|‚ñà         | 350/3257 [00:01<00:11, 258.63it/s] 12%|‚ñà‚ñè        | 376/3257 [00:01<00:11, 256.60it/s] 12%|‚ñà‚ñè        | 402/3257 [00:01<00:11, 250.97it/s] 13%|‚ñà‚ñé        | 428/3257 [00:01<00:11, 240.11it/s] 14%|‚ñà‚ñç        | 459/3257 [00:01<00:10, 259.12it/s] 15%|‚ñà‚ñå        | 493/3257 [00:01<00:09, 279.93it/s] 16%|‚ñà‚ñå        | 527/3257 [00:02<00:09, 294.74it/s] 17%|‚ñà‚ñã        | 558/3257 [00:02<00:09, 296.33it/s] 18%|‚ñà‚ñä        | 589/3257 [00:02<00:09, 296.43it/s] 19%|‚ñà‚ñâ        | 622/3257 [00:02<00:08, 303.39it/s] 20%|‚ñà‚ñà        | 653/3257 [00:02<00:11, 218.79it/s] 21%|‚ñà‚ñà        | 683/3257 [00:02<00:11, 230.28it/s] 22%|‚ñà‚ñà‚ñè       | 719/3257 [00:02<00:09, 261.19it/s] 23%|‚ñà‚ñà‚ñé       | 748/3257 [00:02<00:09, 263.12it/s] 24%|‚ñà‚ñà‚ñç       | 779/3257 [00:02<00:09, 274.09it/s] 25%|‚ñà‚ñà‚ñç       | 809/3257 [00:03<00:08, 279.85it/s] 26%|‚ñà‚ñà‚ñå       | 839/3257 [00:03<00:08, 277.99it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:03<00:08, 273.41it/s] 28%|‚ñà‚ñà‚ñä       | 899/3257 [00:03<00:08, 283.14it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:03<00:07, 291.60it/s] 30%|‚ñà‚ñà‚ñâ       | 964/3257 [00:03<00:07, 302.51it/s] 31%|‚ñà‚ñà‚ñà       | 995/3257 [00:03<00:07, 288.26it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:03<00:07, 290.22it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1055/3257 [00:03<00:07, 277.94it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1084/3257 [00:04<00:07, 280.73it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:04<00:07, 284.96it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:04<00:07, 274.75it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1174/3257 [00:04<00:07, 280.73it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1203/3257 [00:04<00:07, 259.78it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:04<00:07, 270.59it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:04<00:07, 274.23it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:04<00:07, 265.85it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:04<00:07, 276.33it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:05<00:06, 280.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1379/3257 [00:05<00:06, 282.36it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1408/3257 [00:05<00:06, 277.37it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:05<00:06, 285.34it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1473/3257 [00:05<00:05, 300.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1508/3257 [00:05<00:05, 314.85it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1540/3257 [00:05<00:05, 294.52it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1570/3257 [00:05<00:05, 295.07it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1601/3257 [00:05<00:05, 297.25it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1633/3257 [00:05<00:05, 302.16it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1664/3257 [00:06<00:05, 274.73it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1693/3257 [00:06<00:05, 277.25it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:06<00:05, 283.25it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1752/3257 [00:06<00:05, 272.93it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1785/3257 [00:06<00:05, 285.69it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:06<00:07, 189.94it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1842/3257 [00:06<00:06, 208.19it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1873/3257 [00:07<00:05, 231.23it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1904/3257 [00:07<00:05, 248.79it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1934/3257 [00:07<00:05, 261.78it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1972/3257 [00:07<00:04, 292.47it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2003/3257 [00:07<00:04, 288.67it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2034/3257 [00:07<00:04, 293.34it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2065/3257 [00:07<00:04, 274.94it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2096/3257 [00:07<00:04, 277.60it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2125/3257 [00:07<00:04, 274.20it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2153/3257 [00:07<00:04, 275.04it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2182/3257 [00:08<00:03, 278.37it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2211/3257 [00:08<00:03, 276.04it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2239/3257 [00:08<00:03, 267.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2266/3257 [00:08<00:03, 264.37it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2293/3257 [00:08<00:03, 262.26it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2320/3257 [00:08<00:03, 258.37it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2352/3257 [00:08<00:03, 275.44it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2380/3257 [00:08<00:03, 273.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2408/3257 [00:08<00:03, 270.36it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2436/3257 [00:09<00:03, 265.62it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2464/3257 [00:09<00:02, 269.23it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2494/3257 [00:09<00:02, 277.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2526/3257 [00:09<00:02, 285.45it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2555/3257 [00:09<00:02, 283.53it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2584/3257 [00:09<00:02, 265.76it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2615/3257 [00:09<00:02, 276.88it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2643/3257 [00:09<00:02, 275.09it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2671/3257 [00:09<00:02, 267.68it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2698/3257 [00:10<00:02, 253.42it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2724/3257 [00:10<00:02, 253.79it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:10<00:01, 268.73it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2784/3257 [00:10<00:01, 269.03it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:10<00:01, 270.35it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2841/3257 [00:10<00:01, 261.65it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2877/3257 [00:10<00:01, 289.04it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:10<00:01, 270.14it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2936/3257 [00:10<00:01, 273.93it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2964/3257 [00:10<00:01, 269.65it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2992/3257 [00:11<00:01, 264.81it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3022/3257 [00:11<00:00, 274.17it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3056/3257 [00:11<00:00, 291.43it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3087/3257 [00:11<00:00, 294.61it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3121/3257 [00:11<00:00, 307.50it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3152/3257 [00:11<00:00, 290.87it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3182/3257 [00:11<00:00, 281.56it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:11<00:00, 282.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3245/3257 [00:11<00:00, 291.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:11<00:00, 271.95it/s]
2023-02-07 19:11:29.956 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:11:29,957][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d431,n5,w11,mc7,s0.291754,t4>', 'datetime': '2023-02-07T19:11:29.957292', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:11:29,958][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:11:29,958][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:11:30,213][gensim.models.doc2vec][INFO] - collected 6662 word types and 3257 unique tags from a corpus of 3257 examples and 2911496 words
[2023-02-07 19:11:30,213][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:11:30,222][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 3228 unique words (48.45% of original 6662, drops 3434)', 'datetime': '2023-02-07T19:11:30.222710', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:11:30,223][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 2901608 word corpus (99.66% of original 2911496, drops 9888)', 'datetime': '2023-02-07T19:11:30.223028', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:11:30,234][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 6662 items
[2023-02-07 19:11:30,234][gensim.models.word2vec][INFO] - sample=0.291754 downsamples 0 most-common words
[2023-02-07 19:11:30,234][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2901608 word corpus (100.0%% of prior 2901608)', 'datetime': '2023-02-07T19:11:30.234455', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:11:30,253][gensim.models.word2vec][INFO] - estimated required memory for 3228 words and 431 dimensions: 19010612 bytes
[2023-02-07 19:11:30,253][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:11:30,263][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 3228 vocabulary and 431 features, using sg=0 hs=0 sample=0.2917543930716804 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T19:11:30.263252', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:11:31,274][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 27.42% examples, 794786 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:32,275][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 55.08% examples, 815646 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:33,283][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 85.32% examples, 829176 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:33,736][gensim.models.word2vec][INFO] - EPOCH 0: training on 2911496 raw words (2904865 effective words) took 3.5s, 837019 effective words/s
[2023-02-07 19:11:34,752][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 29.05% examples, 836467 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:35,762][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 58.46% examples, 860057 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:36,772][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 90.02% examples, 866989 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:37,065][gensim.models.word2vec][INFO] - EPOCH 1: training on 2911496 raw words (2904865 effective words) took 3.3s, 873172 effective words/s
[2023-02-07 19:11:38,068][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 29.78% examples, 866817 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:39,069][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 58.64% examples, 870171 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:40,071][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 93.49% examples, 908402 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:40,237][gensim.models.word2vec][INFO] - EPOCH 2: training on 2911496 raw words (2904865 effective words) took 3.2s, 916324 effective words/s
[2023-02-07 19:11:41,254][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 32.15% examples, 927759 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:42,266][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 64.26% examples, 937269 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:43,278][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 98.13% examples, 938454 words/s, in_qsize 6, out_qsize 0
[2023-02-07 19:11:43,319][gensim.models.word2vec][INFO] - EPOCH 3: training on 2911496 raw words (2904865 effective words) took 3.1s, 943061 effective words/s
[2023-02-07 19:11:44,333][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 31.32% examples, 908235 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:45,339][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 63.92% examples, 936842 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:46,341][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 97.08% examples, 934609 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:46,418][gensim.models.word2vec][INFO] - EPOCH 4: training on 2911496 raw words (2904865 effective words) took 3.1s, 938082 effective words/s
[2023-02-07 19:11:47,420][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 31.32% examples, 919199 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:48,427][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 63.22% examples, 932186 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:49,427][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 97.39% examples, 941747 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:49,485][gensim.models.word2vec][INFO] - EPOCH 5: training on 2911496 raw words (2904865 effective words) took 3.1s, 947597 effective words/s
[2023-02-07 19:11:50,496][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 33.13% examples, 960781 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:51,515][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 63.59% examples, 927153 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:52,532][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 96.16% examples, 918085 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:52,642][gensim.models.word2vec][INFO] - EPOCH 6: training on 2911496 raw words (2904865 effective words) took 3.2s, 920729 effective words/s
[2023-02-07 19:11:53,649][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 30.00% examples, 867251 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:54,652][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 59.20% examples, 876228 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:55,658][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 91.34% examples, 886253 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:55,907][gensim.models.word2vec][INFO] - EPOCH 7: training on 2911496 raw words (2904865 effective words) took 3.3s, 890069 effective words/s
[2023-02-07 19:11:56,930][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 30.00% examples, 854346 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:11:57,937][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 60.06% examples, 877014 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:58,940][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 92.39% examples, 891049 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:11:59,148][gensim.models.word2vec][INFO] - EPOCH 8: training on 2911496 raw words (2904865 effective words) took 3.2s, 896982 effective words/s
[2023-02-07 19:12:00,163][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 34.23% examples, 994722 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:12:01,179][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 66.04% examples, 966890 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:12:02,155][gensim.models.word2vec][INFO] - EPOCH 9: training on 2911496 raw words (2904865 effective words) took 3.0s, 966915 effective words/s
[2023-02-07 19:12:03,159][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 31.93% examples, 935210 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:04,172][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 64.26% examples, 942911 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:12:05,172][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 97.91% examples, 945428 words/s, in_qsize 6, out_qsize 0
[2023-02-07 19:12:05,209][gensim.models.word2vec][INFO] - EPOCH 10: training on 2911496 raw words (2904865 effective words) took 3.1s, 951701 effective words/s
[2023-02-07 19:12:06,214][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 31.47% examples, 916532 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:12:07,230][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 63.56% examples, 931687 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:12:08,230][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 98.13% examples, 944362 words/s, in_qsize 6, out_qsize 0
[2023-02-07 19:12:08,277][gensim.models.word2vec][INFO] - EPOCH 11: training on 2911496 raw words (2904865 effective words) took 3.1s, 947085 effective words/s
[2023-02-07 19:12:09,291][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 32.15% examples, 929777 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:12:10,300][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 64.45% examples, 944330 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:11,301][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 97.08% examples, 933869 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:12:11,381][gensim.models.word2vec][INFO] - EPOCH 12: training on 2911496 raw words (2904865 effective words) took 3.1s, 936339 effective words/s
[2023-02-07 19:12:12,400][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 31.10% examples, 895861 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:13,402][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 63.00% examples, 922656 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:12:14,405][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 95.30% examples, 919165 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:14,518][gensim.models.word2vec][INFO] - EPOCH 13: training on 2911496 raw words (2904865 effective words) took 3.1s, 926623 effective words/s
[2023-02-07 19:12:15,524][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 30.89% examples, 897629 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:12:16,525][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 61.50% examples, 905723 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:12:17,536][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 93.00% examples, 901617 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:12:17,723][gensim.models.word2vec][INFO] - EPOCH 14: training on 2911496 raw words (2904865 effective words) took 3.2s, 906955 effective words/s
[2023-02-07 19:12:17,724][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 43672440 raw words (43572975 effective words) took 47.5s, 918077 effective words/s', 'datetime': '2023-02-07T19:12:17.724771', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:12:17.725 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:12:20,166][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191109-6lejsat4/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:12:20.166508', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:12:20,167][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:12:20,206][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191109-6lejsat4/files/../tmp/embedding_model.pt
2023-02-07 19:12:20.206 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:12:22.576 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:12:23.393 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:12:26.229 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0228426280520118, 'test_mae': 0.7861970875617916, 'test_r2': -2.0901469064934535}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.12
wandb: percentage 0.51546
wandb:   test_mae 0.7862
wandb:   test_mse 1.02284
wandb:    test_r2 -2.09015
wandb: 
wandb: üöÄ View run fallen-sweep-32 at: https://wandb.ai/xiaoqiz/mof2vec/runs/6lejsat4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_191109-6lejsat4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jxdo4iba with config:
wandb: 	data.data.wl_step: 1
wandb: 	data.nn.batch_size: 705
wandb: 	model.gensim.alpha: 0.06788991787511309
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.5074981797765659
wandb: 	model.gensim.vector_size: 488
wandb: 	model.gensim.window: 10
wandb: 	model.sklearn.learning_rate: 0.08155768942079906
wandb: 	model.sklearn.max_depth: 65
wandb: 	model.sklearn.min_child_weight: 0.09895117025465318
wandb: 	model.sklearn.n_estimators: 2405
wandb: 	model.sklearn.num_leaves: 92
wandb: 	model.sklearn.reg_alpha: 0.40673049746863194
wandb: 	model.sklearn.reg_lambda: 0.002823699817178554
wandb: 	model.sklearn.subsample: 0.7024845171859759
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191244-jxdo4iba
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-33
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/jxdo4iba
2023-02-07 19:12:52.872 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 1 for sweep.
2023-02-07 19:12:52.872 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 705 for sweep.
2023-02-07 19:12:52.873 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.06788991787511309 for sweep.
2023-02-07 19:12:52.873 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:12:52.873 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 19:12:52.874 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5074981797765659 for sweep.
2023-02-07 19:12:52.874 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 488 for sweep.
2023-02-07 19:12:52.874 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 10 for sweep.
2023-02-07 19:12:52.874 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.08155768942079906 for sweep.
2023-02-07 19:12:52.875 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 65 for sweep.
2023-02-07 19:12:52.875 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.09895117025465318 for sweep.
2023-02-07 19:12:52.875 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2405 for sweep.
2023-02-07 19:12:52.875 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 92 for sweep.
2023-02-07 19:12:52.876 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.40673049746863194 for sweep.
2023-02-07 19:12:52.876 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.002823699817178554 for sweep.
2023-02-07 19:12:52.876 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7024845171859759 for sweep.
2023-02-07 19:12:52.876 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:12:52.881 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 1}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191244-jxdo4iba/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 705, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 488, 'window': 10, 'min_count': 10, 'dm': 0, 'sample': 0.5074981797765659, 'workers': 4, 'alpha': 0.06788991787511309, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2405, 'max_depth': 65, 'num_leaves': 92, 'reg_alpha': 0.40673049746863194, 'reg_lambda': 0.002823699817178554, 'subsample': 0.7024845171859759, 'min_child_weight': 0.09895117025465318, 'n_jobs': 4, 'learning_rate': 0.08155768942079906}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 33/3257 [00:00<00:10, 314.42it/s]  2%|‚ñè         | 67/3257 [00:00<00:09, 323.38it/s]  3%|‚ñé         | 102/3257 [00:00<00:09, 332.59it/s]  4%|‚ñç         | 136/3257 [00:00<00:09, 326.59it/s]  5%|‚ñå         | 170/3257 [00:00<00:09, 329.19it/s]  6%|‚ñå         | 203/3257 [00:00<00:09, 327.07it/s]  7%|‚ñã         | 243/3257 [00:00<00:08, 347.22it/s]  9%|‚ñä         | 279/3257 [00:00<00:08, 350.78it/s] 10%|‚ñâ         | 315/3257 [00:00<00:08, 343.22it/s] 11%|‚ñà         | 350/3257 [00:01<00:08, 339.58it/s] 12%|‚ñà‚ñè        | 384/3257 [00:01<00:08, 332.14it/s] 13%|‚ñà‚ñé        | 418/3257 [00:01<00:08, 330.04it/s] 14%|‚ñà‚ñç        | 452/3257 [00:01<00:09, 304.08it/s] 15%|‚ñà‚ñç        | 485/3257 [00:01<00:08, 310.94it/s] 16%|‚ñà‚ñå        | 520/3257 [00:01<00:08, 321.45it/s] 17%|‚ñà‚ñã        | 554/3257 [00:01<00:08, 325.86it/s] 18%|‚ñà‚ñä        | 587/3257 [00:01<00:08, 313.07it/s] 19%|‚ñà‚ñâ        | 622/3257 [00:01<00:08, 320.56it/s] 20%|‚ñà‚ñà        | 656/3257 [00:02<00:08, 322.77it/s] 21%|‚ñà‚ñà        | 690/3257 [00:02<00:07, 326.92it/s] 22%|‚ñà‚ñà‚ñè       | 724/3257 [00:02<00:07, 327.01it/s] 23%|‚ñà‚ñà‚ñé       | 758/3257 [00:02<00:07, 330.05it/s] 24%|‚ñà‚ñà‚ñç       | 792/3257 [00:02<00:07, 330.12it/s] 25%|‚ñà‚ñà‚ñå       | 826/3257 [00:02<00:07, 326.32it/s] 26%|‚ñà‚ñà‚ñã       | 859/3257 [00:02<00:07, 322.93it/s] 27%|‚ñà‚ñà‚ñã       | 893/3257 [00:02<00:07, 327.72it/s] 29%|‚ñà‚ñà‚ñä       | 930/3257 [00:02<00:06, 339.07it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:02<00:06, 343.58it/s] 31%|‚ñà‚ñà‚ñà       | 1001/3257 [00:03<00:06, 342.76it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1036/3257 [00:03<00:06, 335.89it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1070/3257 [00:03<00:06, 335.97it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1104/3257 [00:03<00:06, 335.64it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:03<00:06, 334.91it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:03<00:06, 336.87it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1209/3257 [00:03<00:06, 318.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1246/3257 [00:03<00:06, 331.46it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1280/3257 [00:03<00:06, 321.55it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:04<00:08, 216.12it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:04<00:07, 256.88it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1401/3257 [00:04<00:06, 304.67it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:04<00:05, 354.54it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1505/3257 [00:04<00:04, 399.24it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1549/3257 [00:04<00:04, 403.03it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:04<00:04, 413.87it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:04<00:03, 423.92it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1683/3257 [00:04<00:03, 422.88it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:05<00:03, 431.31it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1776/3257 [00:05<00:03, 440.41it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1824/3257 [00:05<00:03, 449.59it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1871/3257 [00:05<00:03, 454.50it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1917/3257 [00:05<00:02, 450.45it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1971/3257 [00:05<00:02, 474.52it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2019/3257 [00:05<00:02, 468.94it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2067/3257 [00:05<00:02, 442.25it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2112/3257 [00:05<00:02, 443.66it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2157/3257 [00:06<00:02, 432.92it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:06<00:02, 440.38it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2249/3257 [00:06<00:02, 433.71it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2293/3257 [00:06<00:02, 430.53it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2341/3257 [00:06<00:02, 442.54it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2390/3257 [00:06<00:01, 456.07it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2436/3257 [00:06<00:01, 434.02it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:06<00:01, 436.70it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2528/3257 [00:06<00:01, 445.02it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:06<00:01, 429.41it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2617/3257 [00:07<00:01, 431.65it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2661/3257 [00:07<00:01, 413.82it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2703/3257 [00:07<00:01, 408.52it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2749/3257 [00:07<00:01, 422.61it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:07<00:01, 289.86it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2831/3257 [00:07<00:01, 311.06it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2877/3257 [00:07<00:01, 345.31it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:07<00:00, 355.57it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2955/3257 [00:08<00:00, 358.02it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2998/3257 [00:08<00:00, 377.07it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3040/3257 [00:08<00:00, 388.32it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3084/3257 [00:08<00:00, 402.73it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:08<00:00, 410.46it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3169/3257 [00:08<00:00, 396.59it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3210/3257 [00:08<00:00, 390.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:08<00:00, 390.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:08<00:00, 368.88it/s]
2023-02-07 19:13:01.890 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:13:01,891][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d488,n5,mc10,s0.507498,t4>', 'datetime': '2023-02-07T19:13:01.891492', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:13:01,891][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:13:01,892][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:13:02,025][gensim.models.doc2vec][INFO] - collected 924 word types and 3257 unique tags from a corpus of 3257 examples and 1455748 words
[2023-02-07 19:13:02,025][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:13:02,027][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 456 unique words (49.35% of original 924, drops 468)', 'datetime': '2023-02-07T19:13:02.027163', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:13:02,027][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 1453848 word corpus (99.87% of original 1455748, drops 1900)', 'datetime': '2023-02-07T19:13:02.027329', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:13:02,028][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 924 items
[2023-02-07 19:13:02,029][gensim.models.word2vec][INFO] - sample=0.507498 downsamples 0 most-common words
[2023-02-07 19:13:02,029][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 1453848 word corpus (100.0%% of prior 1453848)', 'datetime': '2023-02-07T19:13:02.029202', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:13:02,032][gensim.models.word2vec][INFO] - estimated required memory for 456 words and 488 dimensions: 9017288 bytes
[2023-02-07 19:13:02,033][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:13:02,039][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 456 vocabulary and 488 features, using sg=1 hs=0 sample=0.5074981797765659 negative=5 window=10 shrink_windows=True', 'datetime': '2023-02-07T19:13:02.039683', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:13:02,680][gensim.models.word2vec][INFO] - EPOCH 0: training on 1455748 raw words (1457105 effective words) took 0.6s, 2282410 effective words/s
[2023-02-07 19:13:03,265][gensim.models.word2vec][INFO] - EPOCH 1: training on 1455748 raw words (1457105 effective words) took 0.6s, 2496752 effective words/s
[2023-02-07 19:13:03,855][gensim.models.word2vec][INFO] - EPOCH 2: training on 1455748 raw words (1457105 effective words) took 0.6s, 2476813 effective words/s
[2023-02-07 19:13:04,438][gensim.models.word2vec][INFO] - EPOCH 3: training on 1455748 raw words (1457105 effective words) took 0.6s, 2501313 effective words/s
[2023-02-07 19:13:05,026][gensim.models.word2vec][INFO] - EPOCH 4: training on 1455748 raw words (1457105 effective words) took 0.6s, 2486550 effective words/s
[2023-02-07 19:13:05,611][gensim.models.word2vec][INFO] - EPOCH 5: training on 1455748 raw words (1457105 effective words) took 0.6s, 2496896 effective words/s
[2023-02-07 19:13:06,203][gensim.models.word2vec][INFO] - EPOCH 6: training on 1455748 raw words (1457105 effective words) took 0.6s, 2467423 effective words/s
[2023-02-07 19:13:06,811][gensim.models.word2vec][INFO] - EPOCH 7: training on 1455748 raw words (1457105 effective words) took 0.6s, 2400866 effective words/s
[2023-02-07 19:13:07,466][gensim.models.word2vec][INFO] - EPOCH 8: training on 1455748 raw words (1457105 effective words) took 0.7s, 2234146 effective words/s
[2023-02-07 19:13:08,125][gensim.models.word2vec][INFO] - EPOCH 9: training on 1455748 raw words (1457105 effective words) took 0.7s, 2217468 effective words/s
[2023-02-07 19:13:08,803][gensim.models.word2vec][INFO] - EPOCH 10: training on 1455748 raw words (1457105 effective words) took 0.7s, 2153594 effective words/s
[2023-02-07 19:13:09,474][gensim.models.word2vec][INFO] - EPOCH 11: training on 1455748 raw words (1457105 effective words) took 0.7s, 2178121 effective words/s
[2023-02-07 19:13:10,166][gensim.models.word2vec][INFO] - EPOCH 12: training on 1455748 raw words (1457105 effective words) took 0.7s, 2110039 effective words/s
[2023-02-07 19:13:10,884][gensim.models.word2vec][INFO] - EPOCH 13: training on 1455748 raw words (1457105 effective words) took 0.7s, 2035734 effective words/s
[2023-02-07 19:13:11,615][gensim.models.word2vec][INFO] - EPOCH 14: training on 1455748 raw words (1457105 effective words) took 0.7s, 1997138 effective words/s
[2023-02-07 19:13:11,615][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 21836220 raw words (21856575 effective words) took 9.6s, 2282441 effective words/s', 'datetime': '2023-02-07T19:13:11.615962', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:13:11.616 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:13:12,435][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191244-jxdo4iba/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:13:12.435486', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:13:12,436][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:13:12,454][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191244-jxdo4iba/files/../tmp/embedding_model.pt
2023-02-07 19:13:12.454 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:13:15.116 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:13:15.910 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:13:19.145 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9672311505703834, 'test_mae': 0.7691250952200656, 'test_r2': -2.0038566827230753}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.71
wandb: percentage 0.50649
wandb:   test_mae 0.76913
wandb:   test_mse 0.96723
wandb:    test_r2 -2.00386
wandb: 
wandb: üöÄ View run icy-sweep-33 at: https://wandb.ai/xiaoqiz/mof2vec/runs/jxdo4iba
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_191244-jxdo4iba/logs
wandb: Agent Starting Run: ouuwxs5v with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 353
wandb: 	model.gensim.alpha: 0.6926228589587414
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.236877985188759
wandb: 	model.gensim.vector_size: 155
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.02398560413758941
wandb: 	model.sklearn.max_depth: 78
wandb: 	model.sklearn.min_child_weight: 0.052063353024846645
wandb: 	model.sklearn.n_estimators: 4027
wandb: 	model.sklearn.num_leaves: 460
wandb: 	model.sklearn.reg_alpha: 0.07763190609762952
wandb: 	model.sklearn.reg_lambda: 0.09027558417029186
wandb: 	model.sklearn.subsample: 0.80400446352293
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191332-ouuwxs5v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-34
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/ouuwxs5v
2023-02-07 19:13:40.133 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 19:13:40.134 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 353 for sweep.
2023-02-07 19:13:40.134 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.6926228589587414 for sweep.
2023-02-07 19:13:40.134 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:13:40.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 19:13:40.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.236877985188759 for sweep.
2023-02-07 19:13:40.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 155 for sweep.
2023-02-07 19:13:40.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 19:13:40.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.02398560413758941 for sweep.
2023-02-07 19:13:40.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 78 for sweep.
2023-02-07 19:13:40.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.052063353024846645 for sweep.
2023-02-07 19:13:40.137 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4027 for sweep.
2023-02-07 19:13:40.137 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 460 for sweep.
2023-02-07 19:13:40.137 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.07763190609762952 for sweep.
2023-02-07 19:13:40.137 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.09027558417029186 for sweep.
2023-02-07 19:13:40.138 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.80400446352293 for sweep.
2023-02-07 19:13:40.138 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:13:40.141 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191332-ouuwxs5v/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 353, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 155, 'window': 8, 'min_count': 5, 'dm': 1, 'sample': 0.236877985188759, 'workers': 4, 'alpha': 0.6926228589587414, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4027, 'max_depth': 78, 'num_leaves': 460, 'reg_alpha': 0.07763190609762952, 'reg_lambda': 0.09027558417029186, 'subsample': 0.80400446352293, 'min_child_weight': 0.052063353024846645, 'n_jobs': 4, 'learning_rate': 0.02398560413758941}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 20/3257 [00:00<00:16, 197.48it/s]  1%|‚ñè         | 41/3257 [00:00<00:15, 204.41it/s]  2%|‚ñè         | 63/3257 [00:00<00:15, 211.09it/s]  3%|‚ñé         | 88/3257 [00:00<00:14, 224.91it/s]  3%|‚ñé         | 111/3257 [00:00<00:15, 207.00it/s]  4%|‚ñç         | 134/3257 [00:00<00:14, 213.06it/s]  5%|‚ñç         | 158/3257 [00:00<00:14, 216.45it/s]  6%|‚ñå         | 180/3257 [00:00<00:14, 208.59it/s]  6%|‚ñå         | 202/3257 [00:00<00:14, 211.44it/s]  7%|‚ñã         | 230/3257 [00:01<00:13, 230.57it/s]  8%|‚ñä         | 254/3257 [00:01<00:13, 224.09it/s]  9%|‚ñä         | 278/3257 [00:01<00:13, 228.36it/s]  9%|‚ñâ         | 301/3257 [00:01<00:13, 225.04it/s] 10%|‚ñà         | 327/3257 [00:01<00:12, 233.70it/s] 11%|‚ñà         | 351/3257 [00:01<00:13, 221.53it/s] 12%|‚ñà‚ñè        | 375/3257 [00:01<00:13, 219.35it/s] 12%|‚ñà‚ñè        | 398/3257 [00:01<00:13, 210.99it/s] 13%|‚ñà‚ñé        | 421/3257 [00:01<00:13, 215.32it/s] 14%|‚ñà‚ñé        | 443/3257 [00:02<00:14, 195.71it/s] 14%|‚ñà‚ñç        | 467/3257 [00:02<00:13, 205.69it/s] 15%|‚ñà‚ñç        | 488/3257 [00:02<00:13, 206.25it/s] 16%|‚ñà‚ñå        | 513/3257 [00:02<00:12, 217.39it/s] 16%|‚ñà‚ñã        | 535/3257 [00:02<00:12, 215.85it/s] 17%|‚ñà‚ñã        | 558/3257 [00:02<00:12, 207.65it/s] 18%|‚ñà‚ñä        | 579/3257 [00:02<00:13, 198.30it/s] 19%|‚ñà‚ñä        | 604/3257 [00:02<00:12, 209.45it/s] 19%|‚ñà‚ñâ        | 626/3257 [00:02<00:12, 210.98it/s] 20%|‚ñà‚ñâ        | 649/3257 [00:03<00:12, 213.17it/s] 21%|‚ñà‚ñà        | 671/3257 [00:03<00:12, 211.77it/s] 21%|‚ñà‚ñà‚ñè       | 693/3257 [00:03<00:12, 208.15it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:03<00:11, 216.85it/s] 23%|‚ñà‚ñà‚ñé       | 739/3257 [00:03<00:12, 200.63it/s] 23%|‚ñà‚ñà‚ñé       | 760/3257 [00:03<00:16, 148.32it/s] 24%|‚ñà‚ñà‚ñç       | 781/3257 [00:03<00:15, 160.94it/s] 25%|‚ñà‚ñà‚ñç       | 805/3257 [00:03<00:13, 179.31it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:04<00:13, 178.49it/s] 26%|‚ñà‚ñà‚ñå       | 845/3257 [00:04<00:13, 178.48it/s] 27%|‚ñà‚ñà‚ñã       | 867/3257 [00:04<00:12, 189.26it/s] 27%|‚ñà‚ñà‚ñã       | 887/3257 [00:04<00:12, 191.81it/s] 28%|‚ñà‚ñà‚ñä       | 911/3257 [00:04<00:11, 205.30it/s] 29%|‚ñà‚ñà‚ñä       | 932/3257 [00:04<00:11, 203.75it/s] 29%|‚ñà‚ñà‚ñâ       | 957/3257 [00:04<00:10, 215.20it/s] 30%|‚ñà‚ñà‚ñà       | 979/3257 [00:04<00:10, 213.98it/s] 31%|‚ñà‚ñà‚ñà       | 1001/3257 [00:04<00:10, 214.33it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1024/3257 [00:04<00:10, 218.65it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:05<00:10, 203.09it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1071/3257 [00:05<00:10, 214.32it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1093/3257 [00:05<00:10, 207.97it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:05<00:09, 214.48it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:05<00:10, 210.67it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1162/3257 [00:05<00:09, 214.64it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1184/3257 [00:05<00:10, 202.21it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:05<00:10, 193.80it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1231/3257 [00:05<00:09, 211.61it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1253/3257 [00:06<00:09, 210.14it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:06<00:09, 207.21it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1296/3257 [00:06<00:09, 201.13it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:06<00:09, 210.45it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1347/3257 [00:06<00:08, 222.77it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:06<00:08, 212.63it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1392/3257 [00:06<00:08, 211.94it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:06<00:07, 235.05it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1446/3257 [00:06<00:07, 232.67it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:07<00:07, 246.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1501/3257 [00:07<00:06, 251.28it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1527/3257 [00:07<00:07, 234.69it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1551/3257 [00:07<00:07, 226.76it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:07<00:07, 225.15it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1598/3257 [00:07<00:07, 228.27it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1621/3257 [00:07<00:07, 228.68it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1644/3257 [00:07<00:07, 224.40it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1667/3257 [00:07<00:07, 216.43it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:08<00:07, 215.65it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:08<00:06, 222.61it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1738/3257 [00:08<00:07, 207.64it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:08<00:06, 218.21it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:08<00:06, 231.16it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:08<00:06, 221.26it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1839/3257 [00:08<00:06, 227.00it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1865/3257 [00:08<00:05, 235.18it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1889/3257 [00:08<00:05, 233.12it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:09<00:05, 231.77it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1943/3257 [00:09<00:05, 242.44it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1972/3257 [00:09<00:05, 255.30it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1998/3257 [00:09<00:05, 245.95it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2023/3257 [00:09<00:05, 246.04it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2048/3257 [00:09<00:07, 152.30it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2070/3257 [00:09<00:07, 165.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2096/3257 [00:09<00:06, 181.77it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:10<00:05, 191.32it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2142/3257 [00:10<00:05, 196.01it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:10<00:05, 206.10it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2190/3257 [00:10<00:04, 214.18it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2213/3257 [00:10<00:04, 211.96it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:10<00:04, 218.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:10<00:04, 213.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2282/3257 [00:10<00:04, 213.37it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2307/3257 [00:10<00:04, 223.39it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:11<00:03, 240.35it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2367/3257 [00:11<00:03, 252.67it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2396/3257 [00:11<00:03, 262.36it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2423/3257 [00:11<00:03, 247.89it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2449/3257 [00:11<00:03, 230.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2478/3257 [00:11<00:03, 244.87it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:11<00:02, 256.38it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2534/3257 [00:11<00:02, 260.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2561/3257 [00:11<00:02, 241.91it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:12<00:02, 230.10it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:12<00:02, 243.45it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2641/3257 [00:12<00:02, 248.96it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2667/3257 [00:12<00:02, 235.13it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2692/3257 [00:12<00:02, 236.41it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2716/3257 [00:12<00:02, 210.53it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2746/3257 [00:12<00:02, 231.99it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2770/3257 [00:12<00:02, 227.88it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2799/3257 [00:12<00:01, 243.95it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2824/3257 [00:13<00:01, 228.09it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2850/3257 [00:13<00:01, 234.81it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2881/3257 [00:13<00:01, 255.03it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:13<00:01, 237.25it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2932/3257 [00:13<00:01, 239.07it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2957/3257 [00:13<00:01, 224.08it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2980/3257 [00:13<00:01, 225.61it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:13<00:01, 227.54it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3027/3257 [00:13<00:01, 226.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3053/3257 [00:14<00:00, 234.86it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3080/3257 [00:14<00:00, 243.80it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3107/3257 [00:14<00:00, 248.47it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3132/3257 [00:14<00:00, 244.30it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3157/3257 [00:14<00:00, 234.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3181/3257 [00:14<00:00, 224.68it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:14<00:00, 230.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3231/3257 [00:14<00:00, 230.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3255/3257 [00:14<00:00, 233.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:14<00:00, 218.87it/s]
2023-02-07 19:13:55.623 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:13:55,624][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d155,n5,w8,mc5,s0.236878,t4>', 'datetime': '2023-02-07T19:13:55.624671', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:13:55,625][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:13:55,625][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:13:56,023][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 19:13:56,023][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:13:56,055][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11219 unique words (51.70% of original 21699, drops 10480)', 'datetime': '2023-02-07T19:13:56.055640', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:13:56,055][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 4341582 word corpus (99.41% of original 4367244, drops 25662)', 'datetime': '2023-02-07T19:13:56.055925', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:13:56,094][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 19:13:56,095][gensim.models.word2vec][INFO] - sample=0.236878 downsamples 0 most-common words
[2023-02-07 19:13:56,096][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4341582 word corpus (100.0%% of prior 4341582)', 'datetime': '2023-02-07T19:13:56.096079', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:13:56,163][gensim.models.word2vec][INFO] - estimated required memory for 11219 words and 155 dimensions: 22191800 bytes
[2023-02-07 19:13:56,163][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:13:56,172][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11219 vocabulary and 155 features, using sg=0 hs=0 sample=0.236877985188759 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T19:13:56.172161', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:13:57,175][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 50.38% examples, 2228263 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:13:58,117][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4343128 effective words) took 1.9s, 2234773 effective words/s
[2023-02-07 19:13:59,121][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 51.43% examples, 2279843 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:00,020][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4343128 effective words) took 1.9s, 2284157 effective words/s
[2023-02-07 19:14:01,021][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 50.54% examples, 2239479 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:01,927][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4343128 effective words) took 1.9s, 2278717 effective words/s
[2023-02-07 19:14:02,929][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 48.33% examples, 2143070 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:03,933][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 98.62% examples, 2139603 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:03,957][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4343128 effective words) took 2.0s, 2141046 effective words/s
[2023-02-07 19:14:04,961][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 46.95% examples, 2077140 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:05,964][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 96.87% examples, 2100361 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:14:06,022][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4343128 effective words) took 2.1s, 2105963 effective words/s
[2023-02-07 19:14:07,024][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 47.37% examples, 2099069 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:08,033][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 96.81% examples, 2095136 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:08,091][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4343128 effective words) took 2.1s, 2100883 effective words/s
[2023-02-07 19:14:09,096][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 46.98% examples, 2073833 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:10,099][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 96.81% examples, 2098431 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:14:10,154][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4343128 effective words) took 2.1s, 2106465 effective words/s
[2023-02-07 19:14:11,156][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 53.05% examples, 2363155 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:11,906][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4343128 effective words) took 1.7s, 2482018 effective words/s
[2023-02-07 19:14:12,909][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 56.52% examples, 2517090 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:13,616][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4343128 effective words) took 1.7s, 2542162 effective words/s
[2023-02-07 19:14:14,622][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 57.32% examples, 2534156 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:15,479][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4343128 effective words) took 1.9s, 2333077 effective words/s
[2023-02-07 19:14:16,485][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 46.98% examples, 2069644 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:17,486][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 99.57% examples, 2155097 words/s, in_qsize 3, out_qsize 1
[2023-02-07 19:14:17,495][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4343128 effective words) took 2.0s, 2155357 effective words/s
[2023-02-07 19:14:18,497][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 57.32% examples, 2542284 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:19,231][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4343128 effective words) took 1.7s, 2503409 effective words/s
[2023-02-07 19:14:20,236][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 51.64% examples, 2285232 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:21,136][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4343128 effective words) took 1.9s, 2280893 effective words/s
[2023-02-07 19:14:22,139][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 52.29% examples, 2321055 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:23,142][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 100.00% examples, 2166607 words/s, in_qsize 0, out_qsize 1
[2023-02-07 19:14:23,143][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4343128 effective words) took 2.0s, 2166112 effective words/s
[2023-02-07 19:14:24,145][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 44.03% examples, 1961429 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:25,145][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 91.40% examples, 1999088 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:14:25,310][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4343128 effective words) took 2.2s, 2004998 effective words/s
[2023-02-07 19:14:25,311][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65146920 effective words) took 29.1s, 2235730 effective words/s', 'datetime': '2023-02-07T19:14:25.311498', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:14:25.311 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:14:27,603][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191332-ouuwxs5v/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:14:27.603172', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:14:27,603][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:14:27,633][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191332-ouuwxs5v/files/../tmp/embedding_model.pt
2023-02-07 19:14:27.633 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:14:28.973 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:14:29.530 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:14:30.635 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.3366645533874069, 'test_mae': 0.908239423543032, 'test_r2': -4.749169648366239}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.0
wandb: percentage 0.48297
wandb:   test_mae 0.90824
wandb:   test_mse 1.33666
wandb:    test_r2 -4.74917
wandb: 
wandb: üöÄ View run driven-sweep-34 at: https://wandb.ai/xiaoqiz/mof2vec/runs/ouuwxs5v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_191332-ouuwxs5v/logs
wandb: Agent Starting Run: iznskq42 with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 802
wandb: 	model.gensim.alpha: 0.04034244278320624
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.9234460644497562
wandb: 	model.gensim.vector_size: 444
wandb: 	model.gensim.window: 18
wandb: 	model.sklearn.learning_rate: 0.022560925233881975
wandb: 	model.sklearn.max_depth: 86
wandb: 	model.sklearn.min_child_weight: 0.014708972425851636
wandb: 	model.sklearn.n_estimators: 1589
wandb: 	model.sklearn.num_leaves: 413
wandb: 	model.sklearn.reg_alpha: 0.0062238822527794875
wandb: 	model.sklearn.reg_lambda: 0.01988126829733044
wandb: 	model.sklearn.subsample: 0.9415549881968464
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191446-iznskq42
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-35
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/iznskq42
2023-02-07 19:14:54.094 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 19:14:54.095 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 802 for sweep.
2023-02-07 19:14:54.095 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.04034244278320624 for sweep.
2023-02-07 19:14:54.095 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:14:54.096 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 19:14:54.096 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9234460644497562 for sweep.
2023-02-07 19:14:54.096 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 444 for sweep.
2023-02-07 19:14:54.096 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 18 for sweep.
2023-02-07 19:14:54.097 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.022560925233881975 for sweep.
2023-02-07 19:14:54.097 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 86 for sweep.
2023-02-07 19:14:54.097 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.014708972425851636 for sweep.
2023-02-07 19:14:54.097 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1589 for sweep.
2023-02-07 19:14:54.098 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 413 for sweep.
2023-02-07 19:14:54.098 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0062238822527794875 for sweep.
2023-02-07 19:14:54.098 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.01988126829733044 for sweep.
2023-02-07 19:14:54.098 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9415549881968464 for sweep.
2023-02-07 19:14:54.098 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:14:54.105 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191446-iznskq42/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 802, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 444, 'window': 18, 'min_count': 5, 'dm': 0, 'sample': 0.9234460644497562, 'workers': 4, 'alpha': 0.04034244278320624, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1589, 'max_depth': 86, 'num_leaves': 413, 'reg_alpha': 0.0062238822527794875, 'reg_lambda': 0.01988126829733044, 'subsample': 0.9415549881968464, 'min_child_weight': 0.014708972425851636, 'n_jobs': 4, 'learning_rate': 0.022560925233881975}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 20/3257 [00:00<00:16, 198.95it/s]  1%|‚ñè         | 42/3257 [00:00<00:15, 210.55it/s]  2%|‚ñè         | 67/3257 [00:00<00:14, 216.37it/s]  3%|‚ñé         | 92/3257 [00:00<00:13, 228.38it/s]  4%|‚ñé         | 115/3257 [00:00<00:14, 221.69it/s]  4%|‚ñç         | 140/3257 [00:00<00:13, 228.67it/s]  5%|‚ñå         | 163/3257 [00:00<00:20, 153.84it/s]  6%|‚ñå         | 189/3257 [00:00<00:17, 177.08it/s]  7%|‚ñã         | 214/3257 [00:01<00:15, 194.50it/s]  7%|‚ñã         | 241/3257 [00:01<00:14, 214.07it/s]  8%|‚ñä         | 265/3257 [00:01<00:13, 216.79it/s]  9%|‚ñâ         | 295/3257 [00:01<00:12, 239.55it/s] 10%|‚ñâ         | 321/3257 [00:01<00:12, 237.84it/s] 11%|‚ñà         | 346/3257 [00:01<00:12, 234.83it/s] 11%|‚ñà‚ñè        | 373/3257 [00:01<00:11, 240.57it/s] 12%|‚ñà‚ñè        | 398/3257 [00:01<00:12, 222.15it/s] 13%|‚ñà‚ñé        | 421/3257 [00:01<00:12, 223.26it/s] 14%|‚ñà‚ñé        | 444/3257 [00:02<00:13, 204.59it/s] 14%|‚ñà‚ñç        | 469/3257 [00:02<00:12, 215.93it/s] 15%|‚ñà‚ñå        | 492/3257 [00:02<00:12, 219.15it/s] 16%|‚ñà‚ñå        | 518/3257 [00:02<00:11, 230.05it/s] 17%|‚ñà‚ñã        | 542/3257 [00:02<00:11, 232.66it/s] 17%|‚ñà‚ñã        | 566/3257 [00:02<00:12, 216.92it/s] 18%|‚ñà‚ñä        | 589/3257 [00:02<00:12, 212.13it/s] 19%|‚ñà‚ñâ        | 616/3257 [00:02<00:11, 227.32it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:02<00:11, 221.22it/s] 20%|‚ñà‚ñà        | 663/3257 [00:03<00:12, 209.57it/s] 21%|‚ñà‚ñà        | 686/3257 [00:03<00:12, 213.63it/s] 22%|‚ñà‚ñà‚ñè       | 713/3257 [00:03<00:11, 227.74it/s] 23%|‚ñà‚ñà‚ñé       | 737/3257 [00:03<00:11, 214.64it/s] 23%|‚ñà‚ñà‚ñé       | 762/3257 [00:03<00:11, 223.20it/s] 24%|‚ñà‚ñà‚ñç       | 785/3257 [00:03<00:11, 218.61it/s] 25%|‚ñà‚ñà‚ñç       | 808/3257 [00:03<00:11, 221.78it/s] 26%|‚ñà‚ñà‚ñå       | 831/3257 [00:03<00:11, 216.15it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:03<00:11, 209.52it/s] 27%|‚ñà‚ñà‚ñã       | 876/3257 [00:04<00:11, 212.13it/s] 28%|‚ñà‚ñà‚ñä       | 902/3257 [00:04<00:10, 225.20it/s] 28%|‚ñà‚ñà‚ñä       | 926/3257 [00:04<00:10, 228.70it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:04<00:10, 224.17it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:04<00:09, 229.91it/s] 31%|‚ñà‚ñà‚ñà       | 998/3257 [00:04<00:10, 222.95it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1022/3257 [00:04<00:09, 225.36it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1045/3257 [00:04<00:10, 207.81it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1068/3257 [00:04<00:10, 213.00it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:05<00:10, 211.94it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:05<00:09, 220.93it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1140/3257 [00:05<00:09, 217.15it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1165/3257 [00:05<00:09, 225.12it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:05<00:10, 202.54it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1209/3257 [00:05<00:10, 203.37it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1237/3257 [00:05<00:09, 223.52it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1260/3257 [00:05<00:09, 221.20it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1283/3257 [00:05<00:09, 211.04it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1306/3257 [00:06<00:09, 215.71it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:06<00:13, 144.30it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1351/3257 [00:06<00:11, 161.37it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1373/3257 [00:06<00:10, 174.10it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1396/3257 [00:06<00:09, 187.75it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:06<00:08, 207.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1449/3257 [00:06<00:08, 220.11it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1476/3257 [00:06<00:07, 232.80it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1504/3257 [00:07<00:07, 244.14it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:07<00:07, 230.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1554/3257 [00:07<00:07, 222.48it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1577/3257 [00:07<00:07, 222.70it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1604/3257 [00:07<00:07, 235.52it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1631/3257 [00:07<00:06, 242.53it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1656/3257 [00:07<00:06, 229.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1680/3257 [00:07<00:07, 222.73it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1705/3257 [00:07<00:06, 228.12it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:08<00:06, 220.35it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1752/3257 [00:08<00:06, 220.32it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:08<00:06, 231.11it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1805/3257 [00:08<00:06, 232.97it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1829/3257 [00:08<00:06, 226.14it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1856/3257 [00:08<00:05, 236.58it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1882/3257 [00:08<00:05, 242.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1907/3257 [00:08<00:05, 244.17it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1932/3257 [00:08<00:05, 237.86it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:08<00:04, 258.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1991/3257 [00:09<00:05, 251.28it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2017/3257 [00:09<00:04, 250.84it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2043/3257 [00:09<00:04, 244.42it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2068/3257 [00:09<00:05, 228.02it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2094/3257 [00:09<00:04, 236.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2118/3257 [00:09<00:04, 234.21it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2142/3257 [00:09<00:05, 218.12it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:09<00:04, 222.83it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2189/3257 [00:09<00:04, 224.61it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2212/3257 [00:10<00:04, 222.53it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:10<00:04, 226.85it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2261/3257 [00:10<00:04, 225.11it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2286/3257 [00:10<00:04, 230.62it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2310/3257 [00:10<00:04, 230.21it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2342/3257 [00:10<00:03, 254.76it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2371/3257 [00:10<00:03, 260.59it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:10<00:03, 265.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2426/3257 [00:10<00:03, 237.52it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2451/3257 [00:11<00:03, 208.34it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:11<00:03, 217.82it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2499/3257 [00:11<00:03, 220.65it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2523/3257 [00:11<00:03, 223.69it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2546/3257 [00:11<00:03, 221.54it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2569/3257 [00:11<00:03, 201.78it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2590/3257 [00:11<00:03, 196.29it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2616/3257 [00:11<00:03, 212.58it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2638/3257 [00:12<00:04, 124.50it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2657/3257 [00:12<00:04, 134.93it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2678/3257 [00:12<00:03, 150.00it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2697/3257 [00:12<00:03, 158.34it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2716/3257 [00:12<00:03, 155.43it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:12<00:02, 177.99it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:12<00:02, 179.76it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2781/3257 [00:13<00:02, 181.84it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2804/3257 [00:13<00:02, 194.58it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2825/3257 [00:13<00:02, 183.82it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2844/3257 [00:13<00:02, 184.42it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:13<00:01, 208.66it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2894/3257 [00:13<00:01, 199.10it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:13<00:01, 202.66it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2937/3257 [00:13<00:01, 203.33it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2958/3257 [00:13<00:01, 188.32it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2979/3257 [00:14<00:01, 192.42it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3002/3257 [00:14<00:01, 200.40it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3023/3257 [00:14<00:01, 197.45it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3047/3257 [00:14<00:01, 208.43it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3070/3257 [00:14<00:00, 214.13it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3092/3257 [00:14<00:00, 209.47it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:14<00:00, 222.67it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3141/3257 [00:14<00:00, 212.90it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3163/3257 [00:14<00:00, 204.88it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3184/3257 [00:14<00:00, 194.06it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:15<00:00, 199.89it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3228/3257 [00:15<00:00, 195.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:15<00:00, 201.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:15<00:00, 212.28it/s]
2023-02-07 19:15:10.109 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:15:10,110][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d444,n5,mc5,s0.923446,t4>', 'datetime': '2023-02-07T19:15:10.110763', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:15:10,112][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:15:10,112][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:15:10,548][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 19:15:10,548][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:15:10,582][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11219 unique words (51.70% of original 21699, drops 10480)', 'datetime': '2023-02-07T19:15:10.582527', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:15:10,583][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 4341582 word corpus (99.41% of original 4367244, drops 25662)', 'datetime': '2023-02-07T19:15:10.583010', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:15:10,623][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 19:15:10,624][gensim.models.word2vec][INFO] - sample=0.923446 downsamples 0 most-common words
[2023-02-07 19:15:10,624][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4341582 word corpus (100.0%% of prior 4341582)', 'datetime': '2023-02-07T19:15:10.624440', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:15:10,694][gensim.models.word2vec][INFO] - estimated required memory for 11219 words and 444 dimensions: 51895220 bytes
[2023-02-07 19:15:10,696][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:15:10,726][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11219 vocabulary and 444 features, using sg=1 hs=0 sample=0.9234460644497562 negative=5 window=18 shrink_windows=True', 'datetime': '2023-02-07T19:15:10.726367', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:15:11,731][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 37.21% examples, 1657155 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:12,735][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 75.53% examples, 1660137 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:13,339][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4343128 effective words) took 2.6s, 1663948 effective words/s
[2023-02-07 19:15:14,348][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 49.49% examples, 2175636 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:15,348][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 96.59% examples, 2092582 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:15,422][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4343128 effective words) took 2.1s, 2086596 effective words/s
[2023-02-07 19:15:16,425][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 44.83% examples, 1988298 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:17,427][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 91.07% examples, 1987455 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:17,610][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4343128 effective words) took 2.2s, 1986658 effective words/s
[2023-02-07 19:15:18,614][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 44.83% examples, 1983941 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:15:19,616][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 91.25% examples, 1990164 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:19,793][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4343128 effective words) took 2.2s, 1990663 effective words/s
[2023-02-07 19:15:20,803][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 45.81% examples, 2008746 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:15:21,808][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 93.00% examples, 2019434 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:21,940][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4343128 effective words) took 2.1s, 2024333 effective words/s
[2023-02-07 19:15:22,945][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 44.83% examples, 1984835 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:23,947][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 91.40% examples, 1995695 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:24,111][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4343128 effective words) took 2.2s, 2002963 effective words/s
[2023-02-07 19:15:25,121][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 45.81% examples, 2011455 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:26,121][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 93.92% examples, 2039478 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:26,243][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4343128 effective words) took 2.1s, 2039372 effective words/s
[2023-02-07 19:15:27,256][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 44.83% examples, 1966992 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:15:28,261][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 86.52% examples, 1881030 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:15:28,561][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4343128 effective words) took 2.3s, 1874803 effective words/s
[2023-02-07 19:15:29,575][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 40.93% examples, 1807818 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:30,581][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 83.51% examples, 1818871 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:30,958][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4343128 effective words) took 2.4s, 1814086 effective words/s
[2023-02-07 19:15:31,961][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 40.01% examples, 1787850 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:32,962][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 82.47% examples, 1807400 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:33,355][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4343128 effective words) took 2.4s, 1813555 effective words/s
[2023-02-07 19:15:34,360][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 40.44% examples, 1806624 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:35,366][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 82.68% examples, 1802990 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:35,702][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4343128 effective words) took 2.3s, 1854241 effective words/s
[2023-02-07 19:15:36,709][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 50.35% examples, 2209008 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:37,709][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 97.27% examples, 2108057 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:37,765][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4343128 effective words) took 2.1s, 2106193 effective words/s
[2023-02-07 19:15:38,767][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 44.83% examples, 1988698 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:39,768][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 91.40% examples, 1999100 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:39,938][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4343128 effective words) took 2.2s, 2000728 effective words/s
[2023-02-07 19:15:40,941][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 44.55% examples, 1979648 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:41,941][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 90.33% examples, 1971524 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:42,137][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4343128 effective words) took 2.2s, 1977066 effective words/s
[2023-02-07 19:15:43,146][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 44.83% examples, 1977769 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:44,153][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 91.25% examples, 1982841 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:15:44,331][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4343128 effective words) took 2.2s, 1982201 effective words/s
[2023-02-07 19:15:44,332][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65146920 effective words) took 33.6s, 1938575 effective words/s', 'datetime': '2023-02-07T19:15:44.332407', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:15:44.332 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:15:47,235][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191446-iznskq42/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:15:47.235353', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:15:47,237][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:15:47,308][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191446-iznskq42/files/../tmp/embedding_model.pt
2023-02-07 19:15:47.308 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:15:49.826 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:15:50.683 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:15:53.656 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9366447441272985, 'test_mae': 0.7408190399316922, 'test_r2': -2.0642210120202438}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.96
wandb: percentage 0.48297
wandb:   test_mae 0.74082
wandb:   test_mse 0.93664
wandb:    test_r2 -2.06422
wandb: 
wandb: üöÄ View run stilted-sweep-35 at: https://wandb.ai/xiaoqiz/mof2vec/runs/iznskq42
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_191446-iznskq42/logs
wandb: Agent Starting Run: rwo69sl3 with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 823
wandb: 	model.gensim.alpha: 0.005578871803737623
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.3579257110579656
wandb: 	model.gensim.vector_size: 415
wandb: 	model.gensim.window: 17
wandb: 	model.sklearn.learning_rate: 0.006553342736221507
wandb: 	model.sklearn.max_depth: 28
wandb: 	model.sklearn.min_child_weight: 0.032761074141410614
wandb: 	model.sklearn.n_estimators: 641
wandb: 	model.sklearn.num_leaves: 191
wandb: 	model.sklearn.reg_alpha: 0.10162014213762705
wandb: 	model.sklearn.reg_lambda: 0.17393768144502933
wandb: 	model.sklearn.subsample: 0.9826588105230932
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191604-rwo69sl3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-36
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/rwo69sl3
2023-02-07 19:16:13.035 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:16:13.035 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 823 for sweep.
2023-02-07 19:16:13.036 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.005578871803737623 for sweep.
2023-02-07 19:16:13.036 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:16:13.036 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 19:16:13.036 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.3579257110579656 for sweep.
2023-02-07 19:16:13.037 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 415 for sweep.
2023-02-07 19:16:13.037 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 17 for sweep.
2023-02-07 19:16:13.037 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.006553342736221507 for sweep.
2023-02-07 19:16:13.037 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 28 for sweep.
2023-02-07 19:16:13.038 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.032761074141410614 for sweep.
2023-02-07 19:16:13.038 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 641 for sweep.
2023-02-07 19:16:13.038 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 191 for sweep.
2023-02-07 19:16:13.039 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.10162014213762705 for sweep.
2023-02-07 19:16:13.039 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.17393768144502933 for sweep.
2023-02-07 19:16:13.039 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9826588105230932 for sweep.
2023-02-07 19:16:13.039 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:16:13.046 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191604-rwo69sl3/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 823, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 415, 'window': 17, 'min_count': 5, 'dm': 0, 'sample': 0.3579257110579656, 'workers': 4, 'alpha': 0.005578871803737623, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 641, 'max_depth': 28, 'num_leaves': 191, 'reg_alpha': 0.10162014213762705, 'reg_lambda': 0.17393768144502933, 'subsample': 0.9826588105230932, 'min_child_weight': 0.032761074141410614, 'n_jobs': 4, 'learning_rate': 0.006553342736221507}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:21, 154.01it/s]  1%|          | 34/3257 [00:00<00:20, 159.90it/s]  2%|‚ñè         | 51/3257 [00:00<00:19, 163.81it/s]  2%|‚ñè         | 68/3257 [00:00<00:20, 159.19it/s]  3%|‚ñé         | 89/3257 [00:00<00:18, 175.73it/s]  3%|‚ñé         | 107/3257 [00:00<00:20, 156.37it/s]  4%|‚ñç         | 124/3257 [00:00<00:19, 157.52it/s]  4%|‚ñç         | 145/3257 [00:00<00:18, 171.36it/s]  5%|‚ñå         | 163/3257 [00:01<00:19, 160.02it/s]  6%|‚ñå         | 180/3257 [00:01<00:19, 161.93it/s]  6%|‚ñå         | 201/3257 [00:01<00:18, 168.10it/s]  7%|‚ñã         | 223/3257 [00:01<00:16, 181.51it/s]  7%|‚ñã         | 243/3257 [00:01<00:16, 185.17it/s]  8%|‚ñä         | 262/3257 [00:01<00:17, 175.84it/s]  9%|‚ñâ         | 289/3257 [00:01<00:14, 200.97it/s] 10%|‚ñâ         | 310/3257 [00:01<00:14, 202.51it/s] 10%|‚ñà         | 332/3257 [00:01<00:14, 207.03it/s] 11%|‚ñà         | 354/3257 [00:01<00:13, 209.94it/s] 12%|‚ñà‚ñè        | 376/3257 [00:02<00:14, 204.17it/s] 12%|‚ñà‚ñè        | 397/3257 [00:02<00:14, 201.99it/s] 13%|‚ñà‚ñé        | 420/3257 [00:02<00:13, 203.75it/s] 14%|‚ñà‚ñé        | 441/3257 [00:02<00:15, 181.34it/s] 14%|‚ñà‚ñç        | 462/3257 [00:02<00:14, 188.81it/s] 15%|‚ñà‚ñç        | 482/3257 [00:02<00:14, 189.72it/s] 16%|‚ñà‚ñå        | 505/3257 [00:02<00:13, 200.76it/s] 16%|‚ñà‚ñå        | 526/3257 [00:02<00:13, 198.42it/s] 17%|‚ñà‚ñã        | 547/3257 [00:02<00:13, 196.44it/s] 17%|‚ñà‚ñã        | 567/3257 [00:03<00:20, 133.99it/s] 18%|‚ñà‚ñä        | 585/3257 [00:03<00:18, 143.04it/s] 19%|‚ñà‚ñä        | 606/3257 [00:03<00:16, 158.03it/s] 19%|‚ñà‚ñâ        | 624/3257 [00:03<00:16, 162.74it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:15, 169.49it/s] 20%|‚ñà‚ñà        | 663/3257 [00:03<00:15, 168.02it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:14, 172.69it/s] 22%|‚ñà‚ñà‚ñè       | 703/3257 [00:03<00:14, 179.97it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:04<00:14, 179.70it/s] 23%|‚ñà‚ñà‚ñé       | 741/3257 [00:04<00:14, 171.45it/s] 23%|‚ñà‚ñà‚ñé       | 764/3257 [00:04<00:13, 186.20it/s] 24%|‚ñà‚ñà‚ñç       | 783/3257 [00:04<00:13, 176.91it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:13, 182.04it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:04<00:13, 177.96it/s] 26%|‚ñà‚ñà‚ñå       | 843/3257 [00:04<00:14, 171.73it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:04<00:13, 177.55it/s] 27%|‚ñà‚ñà‚ñã       | 882/3257 [00:04<00:13, 176.17it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:12, 187.16it/s] 28%|‚ñà‚ñà‚ñä       | 926/3257 [00:05<00:12, 191.90it/s] 29%|‚ñà‚ñà‚ñâ       | 946/3257 [00:05<00:12, 187.47it/s] 30%|‚ñà‚ñà‚ñâ       | 967/3257 [00:05<00:11, 191.19it/s] 30%|‚ñà‚ñà‚ñà       | 987/3257 [00:05<00:12, 182.33it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:05<00:12, 176.73it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:05<00:12, 178.01it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1045/3257 [00:05<00:12, 174.82it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1065/3257 [00:05<00:12, 181.43it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1084/3257 [00:06<00:12, 180.67it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1103/3257 [00:06<00:11, 181.41it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1122/3257 [00:06<00:11, 178.77it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1140/3257 [00:06<00:12, 173.18it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1160/3257 [00:06<00:11, 179.10it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1178/3257 [00:06<00:12, 169.93it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1196/3257 [00:06<00:12, 164.51it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1213/3257 [00:06<00:12, 160.65it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1237/3257 [00:06<00:11, 182.37it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1256/3257 [00:07<00:11, 179.37it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:07<00:11, 176.21it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1293/3257 [00:07<00:11, 168.83it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1312/3257 [00:07<00:11, 174.51it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1331/3257 [00:07<00:10, 177.86it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:07<00:10, 178.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:07<00:10, 179.65it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1389/3257 [00:07<00:10, 173.79it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1413/3257 [00:07<00:09, 192.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1434/3257 [00:08<00:09, 194.45it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1459/3257 [00:08<00:08, 209.30it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1481/3257 [00:08<00:08, 206.20it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1504/3257 [00:08<00:08, 212.96it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1526/3257 [00:08<00:08, 195.44it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:08<00:09, 182.34it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1565/3257 [00:08<00:09, 183.93it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1584/3257 [00:08<00:09, 185.05it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1605/3257 [00:08<00:08, 187.68it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1627/3257 [00:09<00:08, 196.76it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1647/3257 [00:09<00:08, 182.36it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1666/3257 [00:09<00:09, 176.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1684/3257 [00:09<00:09, 173.50it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1705/3257 [00:09<00:08, 181.59it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1725/3257 [00:09<00:08, 186.32it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:09<00:09, 167.12it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1765/3257 [00:09<00:08, 176.30it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1787/3257 [00:09<00:07, 187.77it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1807/3257 [00:10<00:08, 176.71it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:10<00:07, 179.42it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1848/3257 [00:10<00:07, 184.94it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:10<00:07, 190.97it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1889/3257 [00:10<00:11, 118.92it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1910/3257 [00:10<00:09, 136.38it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1928/3257 [00:10<00:09, 145.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1957/3257 [00:11<00:07, 177.83it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1978/3257 [00:11<00:07, 180.41it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2001/3257 [00:11<00:06, 190.83it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2023/3257 [00:11<00:06, 196.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2044/3257 [00:11<00:06, 191.53it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2064/3257 [00:11<00:06, 170.94it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:11<00:06, 171.54it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2101/3257 [00:11<00:07, 162.66it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:11<00:07, 160.25it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:12<00:07, 158.89it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:12<00:07, 155.13it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2173/3257 [00:12<00:06, 162.72it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2190/3257 [00:12<00:06, 160.45it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2207/3257 [00:12<00:06, 161.54it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2224/3257 [00:12<00:06, 161.65it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2241/3257 [00:12<00:06, 154.96it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:12<00:06, 159.18it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:12<00:06, 148.07it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2297/3257 [00:13<00:05, 165.87it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:13<00:05, 165.65it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:13<00:05, 179.48it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:13<00:04, 188.99it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2380/3257 [00:13<00:04, 187.92it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2400/3257 [00:13<00:04, 190.06it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2420/3257 [00:13<00:04, 177.38it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2438/3257 [00:13<00:04, 169.63it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2456/3257 [00:13<00:04, 168.03it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2477/3257 [00:14<00:04, 178.58it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2497/3257 [00:14<00:04, 183.61it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2517/3257 [00:14<00:03, 187.41it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2537/3257 [00:14<00:03, 190.59it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2557/3257 [00:14<00:03, 176.38it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2575/3257 [00:14<00:04, 165.88it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2592/3257 [00:14<00:04, 159.30it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2616/3257 [00:14<00:03, 179.60it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2637/3257 [00:14<00:03, 186.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:15<00:03, 177.33it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2674/3257 [00:15<00:03, 171.76it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:15<00:03, 169.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2712/3257 [00:15<00:03, 156.28it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:15<00:03, 162.69it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2753/3257 [00:15<00:02, 174.81it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2771/3257 [00:15<00:02, 167.73it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:15<00:02, 176.82it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2810/3257 [00:15<00:02, 176.20it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2828/3257 [00:16<00:02, 165.67it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2845/3257 [00:16<00:02, 163.02it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2871/3257 [00:16<00:02, 188.67it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2891/3257 [00:16<00:01, 184.65it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2910/3257 [00:16<00:01, 174.11it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2929/3257 [00:16<00:01, 174.94it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:16<00:01, 168.57it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:16<00:01, 171.34it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:16<00:01, 161.00it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3005/3257 [00:17<00:01, 173.44it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3023/3257 [00:17<00:01, 168.75it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3045/3257 [00:17<00:01, 182.59it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3066/3257 [00:17<00:01, 189.30it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3086/3257 [00:17<00:00, 186.00it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3107/3257 [00:17<00:00, 190.94it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:17<00:00, 188.92it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3146/3257 [00:17<00:00, 173.04it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3164/3257 [00:17<00:00, 172.01it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3182/3257 [00:18<00:00, 163.48it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:18<00:00, 174.80it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3221/3257 [00:18<00:00, 167.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3242/3257 [00:18<00:00, 178.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 175.95it/s]
2023-02-07 19:16:32.462 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:16:32,463][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d415,n5,mc5,s0.357926,t4>', 'datetime': '2023-02-07T19:16:32.463536', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:16:32,464][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:16:32,464][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:16:33,026][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:16:33,026][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:16:33,080][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 21312 unique words (49.91% of original 42701, drops 21389)', 'datetime': '2023-02-07T19:16:33.079976', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:16:33,080][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5769229 word corpus (99.08% of original 5822992, drops 53763)', 'datetime': '2023-02-07T19:16:33.080191', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:16:33,146][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:16:33,147][gensim.models.word2vec][INFO] - sample=0.357926 downsamples 0 most-common words
[2023-02-07 19:16:33,147][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5769229 word corpus (100.0%% of prior 5769229)', 'datetime': '2023-02-07T19:16:33.147614', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:16:33,262][gensim.models.word2vec][INFO] - estimated required memory for 21312 words and 415 dimensions: 87469860 bytes
[2023-02-07 19:16:33,263][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:16:33,300][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 21312 vocabulary and 415 features, using sg=1 hs=0 sample=0.3579257110579656 negative=5 window=17 shrink_windows=True', 'datetime': '2023-02-07T19:16:33.300191', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:16:34,304][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 30.03% examples, 1723423 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:16:35,308][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 57.48% examples, 1680890 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:36,313][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 86.58% examples, 1664351 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:36,749][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5743174 effective words) took 3.4s, 1665947 effective words/s
[2023-02-07 19:16:37,753][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 30.70% examples, 1769348 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:38,757][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 60.76% examples, 1768333 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:39,764][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 91.77% examples, 1763140 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:40,004][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5743174 effective words) took 3.3s, 1765408 effective words/s
[2023-02-07 19:16:41,009][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 30.89% examples, 1776352 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:42,009][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 61.41% examples, 1787473 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:43,012][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 93.74% examples, 1798911 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:43,213][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5743174 effective words) took 3.2s, 1790693 effective words/s
[2023-02-07 19:16:44,224][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 28.00% examples, 1599024 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:45,233][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 55.39% examples, 1611613 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:46,234][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 83.57% examples, 1608273 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:46,787][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5743174 effective words) took 3.6s, 1607840 effective words/s
[2023-02-07 19:16:47,797][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 28.00% examples, 1600791 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:48,800][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 54.77% examples, 1599344 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:49,802][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 82.84% examples, 1596171 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:16:50,380][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5743174 effective words) took 3.6s, 1599620 effective words/s
[2023-02-07 19:16:51,382][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 27.82% examples, 1603840 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:52,391][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 61.71% examples, 1791774 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:53,396][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 95.98% examples, 1829180 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:53,519][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5743174 effective words) took 3.1s, 1830779 effective words/s
[2023-02-07 19:16:54,529][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 30.92% examples, 1776309 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:55,530][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 61.90% examples, 1796289 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:56,534][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 94.01% examples, 1797646 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:56,709][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5743174 effective words) took 3.2s, 1801424 effective words/s
[2023-02-07 19:16:57,716][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 30.92% examples, 1780385 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:58,718][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 62.36% examples, 1806704 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:59,721][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 95.00% examples, 1816916 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:16:59,869][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5743174 effective words) took 3.2s, 1818397 effective words/s
[2023-02-07 19:17:00,874][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 32.51% examples, 1883455 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:01,883][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 61.90% examples, 1792931 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:02,892][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 90.64% examples, 1735093 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:17:03,194][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5743174 effective words) took 3.3s, 1727798 effective words/s
[2023-02-07 19:17:04,207][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 28.00% examples, 1596250 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:17:05,211][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 55.27% examples, 1613088 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:06,224][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 84.22% examples, 1612402 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:06,751][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5743174 effective words) took 3.6s, 1615505 effective words/s
[2023-02-07 19:17:07,757][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 28.00% examples, 1607472 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:08,759][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 55.45% examples, 1625062 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:09,760][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 84.59% examples, 1629526 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:10,156][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5743174 effective words) took 3.4s, 1687575 effective words/s
[2023-02-07 19:17:11,162][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 35.31% examples, 2051279 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:12,162][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 66.99% examples, 1961583 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:13,148][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5743174 effective words) took 3.0s, 1920617 effective words/s
[2023-02-07 19:17:14,162][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 31.65% examples, 1804329 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:17:15,168][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 63.00% examples, 1822323 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:16,176][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 95.98% examples, 1821176 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:16,299][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5743174 effective words) took 3.1s, 1823463 effective words/s
[2023-02-07 19:17:17,305][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 32.02% examples, 1859055 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:17:18,307][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 64.17% examples, 1870172 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:19,315][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 97.11% examples, 1854276 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:19,405][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5743174 effective words) took 3.1s, 1850962 effective words/s
[2023-02-07 19:17:20,413][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 28.06% examples, 1616816 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:21,414][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 55.20% examples, 1617339 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:17:22,423][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 84.22% examples, 1619423 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:17:22,954][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5743174 effective words) took 3.5s, 1620060 effective words/s
[2023-02-07 19:17:22,955][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86147610 effective words) took 49.7s, 1734932 effective words/s', 'datetime': '2023-02-07T19:17:22.955266', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:17:22.955 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:17:28,101][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191604-rwo69sl3/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:17:28.101228', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:17:28,102][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:17:28,204][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191604-rwo69sl3/files/../tmp/embedding_model.pt
2023-02-07 19:17:28.204 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:17:30.403 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:17:31.171 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:17:33.992 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9144787725274822, 'test_mae': 0.7309070489615019, 'test_r2': -1.7616014453593483}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.8
wandb: percentage 0.5009
wandb:   test_mae 0.73091
wandb:   test_mse 0.91448
wandb:    test_r2 -1.7616
wandb: 
wandb: üöÄ View run good-sweep-36 at: https://wandb.ai/xiaoqiz/mof2vec/runs/rwo69sl3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_191604-rwo69sl3/logs
wandb: Agent Starting Run: w07y1plv with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 501
wandb: 	model.gensim.alpha: 0.025455462730801705
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.725006920834484
wandb: 	model.gensim.vector_size: 304
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.05306760929540673
wandb: 	model.sklearn.max_depth: 31
wandb: 	model.sklearn.min_child_weight: 0.029782553255246452
wandb: 	model.sklearn.n_estimators: 2252
wandb: 	model.sklearn.num_leaves: 7
wandb: 	model.sklearn.reg_alpha: 0.005956765427780697
wandb: 	model.sklearn.reg_lambda: 0.026672103633974154
wandb: 	model.sklearn.subsample: 0.5616910767197211
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191745-w07y1plv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-37
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/w07y1plv
2023-02-07 19:17:53.833 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:17:53.834 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 501 for sweep.
2023-02-07 19:17:53.834 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.025455462730801705 for sweep.
2023-02-07 19:17:53.834 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:17:53.835 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 19:17:53.835 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.725006920834484 for sweep.
2023-02-07 19:17:53.835 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 304 for sweep.
2023-02-07 19:17:53.835 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 19:17:53.836 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.05306760929540673 for sweep.
2023-02-07 19:17:53.836 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 31 for sweep.
2023-02-07 19:17:53.836 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.029782553255246452 for sweep.
2023-02-07 19:17:53.836 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2252 for sweep.
2023-02-07 19:17:53.836 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 7 for sweep.
2023-02-07 19:17:53.837 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.005956765427780697 for sweep.
2023-02-07 19:17:53.837 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.026672103633974154 for sweep.
2023-02-07 19:17:53.837 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5616910767197211 for sweep.
2023-02-07 19:17:53.837 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:17:53.842 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191745-w07y1plv/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 501, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 304, 'window': 2, 'min_count': 6, 'dm': 0, 'sample': 0.725006920834484, 'workers': 4, 'alpha': 0.025455462730801705, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2252, 'max_depth': 31, 'num_leaves': 7, 'reg_alpha': 0.005956765427780697, 'reg_lambda': 0.026672103633974154, 'subsample': 0.5616910767197211, 'min_child_weight': 0.029782553255246452, 'n_jobs': 4, 'learning_rate': 0.05306760929540673}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:19, 169.05it/s]  1%|          | 39/3257 [00:00<00:17, 188.65it/s]  2%|‚ñè         | 58/3257 [00:00<00:27, 117.90it/s]  2%|‚ñè         | 79/3257 [00:00<00:22, 143.41it/s]  3%|‚ñé         | 97/3257 [00:00<00:20, 153.50it/s]  4%|‚ñé         | 115/3257 [00:00<00:19, 157.81it/s]  4%|‚ñç         | 134/3257 [00:00<00:18, 165.79it/s]  5%|‚ñç         | 155/3257 [00:00<00:17, 177.18it/s]  5%|‚ñå         | 174/3257 [00:01<00:17, 172.66it/s]  6%|‚ñå         | 195/3257 [00:01<00:16, 183.13it/s]  7%|‚ñã         | 216/3257 [00:01<00:16, 189.25it/s]  7%|‚ñã         | 238/3257 [00:01<00:15, 197.88it/s]  8%|‚ñä         | 259/3257 [00:01<00:15, 197.20it/s]  9%|‚ñä         | 284/3257 [00:01<00:14, 210.68it/s]  9%|‚ñâ         | 306/3257 [00:01<00:14, 197.61it/s] 10%|‚ñà         | 328/3257 [00:01<00:14, 202.66it/s] 11%|‚ñà         | 349/3257 [00:01<00:14, 197.06it/s] 11%|‚ñà‚ñè        | 372/3257 [00:02<00:14, 206.01it/s] 12%|‚ñà‚ñè        | 393/3257 [00:02<00:15, 188.71it/s] 13%|‚ñà‚ñé        | 415/3257 [00:02<00:14, 196.69it/s] 13%|‚ñà‚ñé        | 436/3257 [00:02<00:16, 166.41it/s] 14%|‚ñà‚ñç        | 457/3257 [00:02<00:15, 177.14it/s] 15%|‚ñà‚ñç        | 476/3257 [00:02<00:15, 180.36it/s] 15%|‚ñà‚ñå        | 498/3257 [00:02<00:14, 188.73it/s] 16%|‚ñà‚ñå        | 520/3257 [00:02<00:13, 195.88it/s] 17%|‚ñà‚ñã        | 541/3257 [00:02<00:13, 198.78it/s] 17%|‚ñà‚ñã        | 562/3257 [00:03<00:14, 186.34it/s] 18%|‚ñà‚ñä        | 582/3257 [00:03<00:14, 180.86it/s] 19%|‚ñà‚ñä        | 605/3257 [00:03<00:13, 192.98it/s] 19%|‚ñà‚ñâ        | 625/3257 [00:03<00:13, 193.55it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:13, 193.67it/s] 20%|‚ñà‚ñà        | 665/3257 [00:03<00:13, 186.37it/s] 21%|‚ñà‚ñà        | 685/3257 [00:03<00:13, 186.86it/s] 22%|‚ñà‚ñà‚ñè       | 707/3257 [00:03<00:13, 195.60it/s] 22%|‚ñà‚ñà‚ñè       | 727/3257 [00:03<00:13, 189.00it/s] 23%|‚ñà‚ñà‚ñé       | 747/3257 [00:04<00:13, 184.22it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:04<00:12, 193.43it/s] 24%|‚ñà‚ñà‚ñç       | 790/3257 [00:04<00:13, 186.34it/s] 25%|‚ñà‚ñà‚ñç       | 809/3257 [00:04<00:13, 187.03it/s] 25%|‚ñà‚ñà‚ñå       | 828/3257 [00:04<00:13, 182.76it/s] 26%|‚ñà‚ñà‚ñå       | 847/3257 [00:04<00:13, 173.44it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:04<00:13, 176.46it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:04<00:13, 171.24it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:04<00:12, 187.47it/s] 29%|‚ñà‚ñà‚ñä       | 929/3257 [00:05<00:11, 195.74it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:05<00:11, 193.15it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:05<00:11, 194.04it/s] 30%|‚ñà‚ñà‚ñà       | 990/3257 [00:05<00:12, 187.13it/s] 31%|‚ñà‚ñà‚ñà       | 1009/3257 [00:05<00:12, 181.85it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1028/3257 [00:05<00:12, 177.82it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:05<00:12, 176.59it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1065/3257 [00:05<00:12, 178.40it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1083/3257 [00:05<00:12, 175.87it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1102/3257 [00:06<00:11, 179.59it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1120/3257 [00:06<00:12, 176.34it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1138/3257 [00:06<00:11, 177.16it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1156/3257 [00:06<00:11, 175.22it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:06<00:11, 176.35it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1193/3257 [00:06<00:12, 164.66it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:06<00:12, 160.35it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:06<00:11, 176.24it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1250/3257 [00:06<00:11, 173.38it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:06<00:11, 177.31it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1289/3257 [00:07<00:12, 163.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:07<00:11, 167.03it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:07<00:11, 171.19it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1349/3257 [00:07<00:10, 180.51it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1368/3257 [00:07<00:16, 117.76it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1384/3257 [00:07<00:14, 126.14it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1405/3257 [00:07<00:12, 144.55it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1426/3257 [00:08<00:11, 159.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1446/3257 [00:08<00:10, 169.72it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1471/3257 [00:08<00:09, 188.38it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1492/3257 [00:08<00:09, 193.64it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:08<00:08, 196.10it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1534/3257 [00:08<00:09, 177.35it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1553/3257 [00:08<00:09, 170.77it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:08<00:09, 176.00it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1593/3257 [00:08<00:09, 176.74it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:09<00:08, 187.57it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:09<00:09, 177.36it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:09<00:09, 176.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1672/3257 [00:09<00:09, 169.75it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:09<00:09, 171.43it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1712/3257 [00:09<00:08, 184.12it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:09<00:09, 168.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1750/3257 [00:09<00:08, 172.16it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1770/3257 [00:09<00:08, 179.14it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:10<00:07, 183.87it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1809/3257 [00:10<00:08, 173.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:10<00:08, 172.74it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:10<00:07, 181.36it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1870/3257 [00:10<00:07, 189.21it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1890/3257 [00:10<00:07, 190.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1911/3257 [00:10<00:06, 196.07it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:10<00:06, 191.71it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1960/3257 [00:10<00:05, 219.19it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1983/3257 [00:11<00:06, 201.55it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2005/3257 [00:11<00:06, 205.28it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2029/3257 [00:11<00:05, 211.76it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2051/3257 [00:11<00:06, 188.39it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2071/3257 [00:11<00:06, 184.58it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:11<00:06, 187.10it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2111/3257 [00:11<00:06, 184.96it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2130/3257 [00:11<00:06, 170.92it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2148/3257 [00:11<00:06, 168.68it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:12<00:06, 178.05it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2188/3257 [00:12<00:05, 179.03it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2208/3257 [00:12<00:05, 184.24it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2227/3257 [00:12<00:05, 183.52it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2246/3257 [00:12<00:05, 180.55it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2265/3257 [00:12<00:05, 182.65it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2284/3257 [00:12<00:05, 183.42it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2303/3257 [00:12<00:05, 183.99it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2327/3257 [00:12<00:04, 199.26it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2353/3257 [00:12<00:04, 213.51it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2375/3257 [00:13<00:04, 209.14it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:13<00:03, 216.77it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2421/3257 [00:13<00:04, 205.02it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2442/3257 [00:13<00:04, 191.43it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2464/3257 [00:13<00:03, 198.93it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2485/3257 [00:13<00:03, 198.95it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2511/3257 [00:13<00:03, 215.63it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2535/3257 [00:13<00:03, 221.01it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2558/3257 [00:14<00:03, 205.02it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2579/3257 [00:14<00:03, 190.46it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2599/3257 [00:14<00:03, 192.81it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2628/3257 [00:14<00:02, 216.09it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2650/3257 [00:14<00:02, 203.05it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2672/3257 [00:14<00:02, 207.14it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2693/3257 [00:14<00:02, 206.16it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2714/3257 [00:14<00:02, 182.25it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2737/3257 [00:14<00:02, 192.12it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2758/3257 [00:15<00:02, 194.70it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2778/3257 [00:15<00:02, 188.66it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:15<00:02, 201.40it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2824/3257 [00:15<00:02, 187.23it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2844/3257 [00:15<00:02, 187.56it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:15<00:01, 212.58it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2894/3257 [00:15<00:03, 114.18it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:16<00:02, 131.06it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2936/3257 [00:16<00:02, 144.65it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2955/3257 [00:16<00:02, 149.72it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:16<00:01, 159.87it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2997/3257 [00:16<00:01, 171.69it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:16<00:01, 177.20it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3043/3257 [00:16<00:01, 194.91it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3068/3257 [00:16<00:00, 207.67it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3090/3257 [00:16<00:00, 209.18it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3116/3257 [00:17<00:00, 221.62it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3139/3257 [00:17<00:00, 213.95it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3161/3257 [00:17<00:00, 205.36it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3182/3257 [00:17<00:00, 192.46it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:17<00:00, 200.89it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3228/3257 [00:17<00:00, 200.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:17<00:00, 204.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 183.32it/s]
2023-02-07 19:18:12.338 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:18:12,339][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d304,n5,mc6,s0.725007,t4>', 'datetime': '2023-02-07T19:18:12.339394', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:18:12,340][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:18:12,340][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:18:12,858][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:18:12,858][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:18:12,916][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 20659 unique words (48.38% of original 42701, drops 22042)', 'datetime': '2023-02-07T19:18:12.916232', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:18:12,916][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 5765964 word corpus (99.02% of original 5822992, drops 57028)', 'datetime': '2023-02-07T19:18:12.916661', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:18:12,987][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:18:12,990][gensim.models.word2vec][INFO] - sample=0.725007 downsamples 0 most-common words
[2023-02-07 19:18:12,991][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5765964 word corpus (100.0%% of prior 5765964)', 'datetime': '2023-02-07T19:18:12.991156', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:18:13,109][gensim.models.word2vec][INFO] - estimated required memory for 20659 words and 304 dimensions: 65184100 bytes
[2023-02-07 19:18:13,110][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:18:13,140][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 20659 vocabulary and 304 features, using sg=1 hs=0 sample=0.725006920834484 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T19:18:13.140263', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:18:14,142][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 34.26% examples, 1987460 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:15,145][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 68.04% examples, 1990078 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:16,015][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5739976 effective words) took 2.9s, 1998332 effective words/s
[2023-02-07 19:18:17,018][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 37.09% examples, 2182339 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:18:18,023][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 73.81% examples, 2139362 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:18,697][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5739976 effective words) took 2.7s, 2141706 effective words/s
[2023-02-07 19:18:19,702][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 36.97% examples, 2168796 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:20,710][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 76.14% examples, 2203766 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:21,293][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5739976 effective words) took 2.6s, 2213501 effective words/s
[2023-02-07 19:18:22,296][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 45.23% examples, 2645260 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:23,303][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 98.89% examples, 2832168 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:18:23,315][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5739976 effective words) took 2.0s, 2841926 effective words/s
[2023-02-07 19:18:24,317][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 49.77% examples, 2905722 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:25,288][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5739976 effective words) took 2.0s, 2910749 effective words/s
[2023-02-07 19:18:26,298][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 49.09% examples, 2850986 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:18:27,299][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 90.64% examples, 2606810 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:27,504][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5739976 effective words) took 2.2s, 2591530 effective words/s
[2023-02-07 19:18:28,520][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 39.94% examples, 2326359 words/s, in_qsize 8, out_qsize 2
[2023-02-07 19:18:29,520][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 88.64% examples, 2540676 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:29,737][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5739976 effective words) took 2.2s, 2573109 effective words/s
[2023-02-07 19:18:30,740][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 48.08% examples, 2821933 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:31,743][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 92.42% examples, 2663077 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:31,900][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5739976 effective words) took 2.2s, 2656041 effective words/s
[2023-02-07 19:18:32,902][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 42.59% examples, 2519099 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:33,905][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 87.81% examples, 2536296 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:34,211][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5739976 effective words) took 2.3s, 2485566 effective words/s
[2023-02-07 19:18:35,214][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.63% examples, 2154056 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:36,217][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 74.03% examples, 2151337 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:36,876][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5739976 effective words) took 2.7s, 2155949 effective words/s
[2023-02-07 19:18:37,879][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 49.09% examples, 2876649 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:18:38,887][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 93.74% examples, 2690887 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:18:39,018][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5739976 effective words) took 2.1s, 2683418 effective words/s
[2023-02-07 19:18:40,021][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 42.09% examples, 2482581 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:41,030][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 84.22% examples, 2425679 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:18:41,419][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5739976 effective words) took 2.4s, 2392266 effective words/s
[2023-02-07 19:18:42,429][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 36.97% examples, 2156729 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:43,432][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 75.19% examples, 2181614 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:18:44,006][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5739976 effective words) took 2.6s, 2220438 effective words/s
[2023-02-07 19:18:45,008][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 48.08% examples, 2822247 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:46,011][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 91.62% examples, 2645184 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:46,183][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5739976 effective words) took 2.2s, 2638514 effective words/s
[2023-02-07 19:18:47,188][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 42.22% examples, 2483623 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:48,189][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 81.55% examples, 2354365 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:18:48,660][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5739976 effective words) took 2.5s, 2319206 effective words/s
[2023-02-07 19:18:48,660][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86099640 effective words) took 35.5s, 2423959 effective words/s', 'datetime': '2023-02-07T19:18:48.660926', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:18:48.661 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:18:51,995][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191745-w07y1plv/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:18:51.995756', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:18:51,997][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:18:52,085][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191745-w07y1plv/files/../tmp/embedding_model.pt
2023-02-07 19:18:52.086 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:18:54.004 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:18:54.726 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:18:56.784 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9167427483741931, 'test_mae': 0.7242879615696661, 'test_r2': -1.7269964918700818}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.94
wandb: percentage 0.51619
wandb:   test_mae 0.72429
wandb:   test_mse 0.91674
wandb:    test_r2 -1.727
wandb: 
wandb: üöÄ View run fresh-sweep-37 at: https://wandb.ai/xiaoqiz/mof2vec/runs/w07y1plv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_191745-w07y1plv/logs
wandb: Agent Starting Run: dnfpruu3 with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 435
wandb: 	model.gensim.alpha: 0.025447703930943543
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.5243195557650715
wandb: 	model.gensim.vector_size: 115
wandb: 	model.gensim.window: 17
wandb: 	model.sklearn.learning_rate: 0.0004415794866460818
wandb: 	model.sklearn.max_depth: 43
wandb: 	model.sklearn.min_child_weight: 0.0367809091593387
wandb: 	model.sklearn.n_estimators: 3833
wandb: 	model.sklearn.num_leaves: 197
wandb: 	model.sklearn.reg_alpha: 0.03725049759009748
wandb: 	model.sklearn.reg_lambda: 0.8802620123677346
wandb: 	model.sklearn.subsample: 0.7971326583168126
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191909-dnfpruu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-38
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/dnfpruu3
2023-02-07 19:19:17.152 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:19:17.153 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 435 for sweep.
2023-02-07 19:19:17.153 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.025447703930943543 for sweep.
2023-02-07 19:19:17.153 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:19:17.154 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 19:19:17.154 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5243195557650715 for sweep.
2023-02-07 19:19:17.154 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 115 for sweep.
2023-02-07 19:19:17.154 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 17 for sweep.
2023-02-07 19:19:17.155 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0004415794866460818 for sweep.
2023-02-07 19:19:17.155 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 43 for sweep.
2023-02-07 19:19:17.155 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0367809091593387 for sweep.
2023-02-07 19:19:17.155 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3833 for sweep.
2023-02-07 19:19:17.155 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 197 for sweep.
2023-02-07 19:19:17.156 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.03725049759009748 for sweep.
2023-02-07 19:19:17.156 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.8802620123677346 for sweep.
2023-02-07 19:19:17.156 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7971326583168126 for sweep.
2023-02-07 19:19:17.156 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:19:17.166 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191909-dnfpruu3/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 435, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 115, 'window': 17, 'min_count': 9, 'dm': 0, 'sample': 0.5243195557650715, 'workers': 4, 'alpha': 0.025447703930943543, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3833, 'max_depth': 43, 'num_leaves': 197, 'reg_alpha': 0.03725049759009748, 'reg_lambda': 0.8802620123677346, 'subsample': 0.7971326583168126, 'min_child_weight': 0.0367809091593387, 'n_jobs': 4, 'learning_rate': 0.0004415794866460818}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 138.58it/s]  1%|          | 31/3257 [00:00<00:20, 153.78it/s]  1%|‚ñè         | 47/3257 [00:00<00:21, 152.79it/s]  2%|‚ñè         | 63/3257 [00:00<00:21, 151.21it/s]  2%|‚ñè         | 80/3257 [00:00<00:20, 155.19it/s]  3%|‚ñé         | 96/3257 [00:00<00:20, 152.86it/s]  3%|‚ñé         | 112/3257 [00:00<00:21, 149.08it/s]  4%|‚ñç         | 130/3257 [00:00<00:19, 157.92it/s]  5%|‚ñç         | 148/3257 [00:00<00:18, 163.98it/s]  5%|‚ñå         | 165/3257 [00:01<00:19, 155.54it/s]  6%|‚ñå         | 181/3257 [00:01<00:19, 155.77it/s]  6%|‚ñå         | 200/3257 [00:01<00:18, 164.81it/s]  7%|‚ñã         | 218/3257 [00:01<00:18, 168.65it/s]  7%|‚ñã         | 237/3257 [00:01<00:17, 172.13it/s]  8%|‚ñä         | 256/3257 [00:01<00:17, 175.74it/s]  8%|‚ñä         | 274/3257 [00:01<00:17, 173.24it/s]  9%|‚ñâ         | 296/3257 [00:01<00:16, 183.26it/s] 10%|‚ñâ         | 315/3257 [00:01<00:16, 174.22it/s] 10%|‚ñà         | 335/3257 [00:02<00:16, 179.26it/s] 11%|‚ñà         | 354/3257 [00:02<00:16, 176.94it/s] 11%|‚ñà‚ñè        | 372/3257 [00:02<00:16, 176.66it/s] 12%|‚ñà‚ñè        | 390/3257 [00:02<00:17, 159.54it/s] 13%|‚ñà‚ñé        | 408/3257 [00:02<00:17, 163.56it/s] 13%|‚ñà‚ñé        | 425/3257 [00:02<00:18, 150.97it/s] 14%|‚ñà‚ñé        | 441/3257 [00:02<00:19, 145.43it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:18, 151.22it/s] 15%|‚ñà‚ñç        | 478/3257 [00:02<00:17, 160.04it/s] 15%|‚ñà‚ñå        | 495/3257 [00:03<00:17, 161.11it/s] 16%|‚ñà‚ñå        | 514/3257 [00:03<00:16, 167.73it/s] 16%|‚ñà‚ñã        | 531/3257 [00:03<00:16, 164.54it/s] 17%|‚ñà‚ñã        | 548/3257 [00:03<00:16, 164.81it/s] 17%|‚ñà‚ñã        | 565/3257 [00:03<00:17, 151.44it/s] 18%|‚ñà‚ñä        | 581/3257 [00:03<00:18, 146.25it/s] 18%|‚ñà‚ñä        | 600/3257 [00:03<00:16, 156.66it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:17, 155.00it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:03<00:15, 164.04it/s] 20%|‚ñà‚ñà        | 656/3257 [00:04<00:17, 151.86it/s] 21%|‚ñà‚ñà        | 674/3257 [00:04<00:16, 158.12it/s] 21%|‚ñà‚ñà        | 691/3257 [00:04<00:16, 152.67it/s] 22%|‚ñà‚ñà‚ñè       | 709/3257 [00:04<00:15, 159.82it/s] 22%|‚ñà‚ñà‚ñè       | 726/3257 [00:04<00:16, 151.31it/s] 23%|‚ñà‚ñà‚ñé       | 742/3257 [00:04<00:16, 147.97it/s] 23%|‚ñà‚ñà‚ñé       | 761/3257 [00:04<00:15, 158.71it/s] 24%|‚ñà‚ñà‚ñç       | 778/3257 [00:04<00:15, 155.70it/s] 24%|‚ñà‚ñà‚ñç       | 795/3257 [00:04<00:15, 158.60it/s] 25%|‚ñà‚ñà‚ñç       | 812/3257 [00:05<00:15, 160.14it/s] 25%|‚ñà‚ñà‚ñå       | 829/3257 [00:05<00:15, 152.51it/s] 26%|‚ñà‚ñà‚ñå       | 845/3257 [00:05<00:25, 93.22it/s]  26%|‚ñà‚ñà‚ñã       | 863/3257 [00:05<00:21, 109.31it/s] 27%|‚ñà‚ñà‚ñã       | 877/3257 [00:05<00:21, 112.66it/s] 27%|‚ñà‚ñà‚ñã       | 895/3257 [00:05<00:18, 127.24it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:05<00:17, 137.58it/s] 29%|‚ñà‚ñà‚ñä       | 932/3257 [00:06<00:15, 146.11it/s] 29%|‚ñà‚ñà‚ñâ       | 950/3257 [00:06<00:14, 154.14it/s] 30%|‚ñà‚ñà‚ñâ       | 967/3257 [00:06<00:14, 158.03it/s] 30%|‚ñà‚ñà‚ñà       | 984/3257 [00:06<00:14, 157.34it/s] 31%|‚ñà‚ñà‚ñà       | 1001/3257 [00:06<00:14, 153.95it/s] 31%|‚ñà‚ñà‚ñà       | 1017/3257 [00:06<00:14, 152.39it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1033/3257 [00:06<00:15, 145.96it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1048/3257 [00:06<00:15, 145.43it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1065/3257 [00:06<00:14, 150.21it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1081/3257 [00:07<00:14, 150.44it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:07<00:14, 152.39it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:07<00:13, 157.94it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1131/3257 [00:07<00:13, 152.55it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1149/3257 [00:07<00:13, 159.68it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1172/3257 [00:07<00:11, 179.18it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:07<00:12, 167.87it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1209/3257 [00:07<00:12, 168.00it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:07<00:10, 186.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1253/3257 [00:08<00:10, 188.87it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1274/3257 [00:08<00:10, 193.34it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1294/3257 [00:08<00:10, 179.84it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1314/3257 [00:08<00:10, 184.28it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:08<00:09, 196.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1359/3257 [00:08<00:10, 189.19it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1379/3257 [00:08<00:09, 188.49it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1398/3257 [00:08<00:10, 185.24it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:08<00:09, 198.05it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1442/3257 [00:09<00:09, 189.96it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1466/3257 [00:09<00:08, 200.48it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1487/3257 [00:09<00:08, 199.73it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:09<00:08, 209.73it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1533/3257 [00:09<00:09, 186.50it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1553/3257 [00:09<00:09, 175.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1573/3257 [00:09<00:09, 181.67it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1592/3257 [00:09<00:09, 179.85it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1613/3257 [00:09<00:08, 187.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1633/3257 [00:10<00:08, 190.10it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1653/3257 [00:10<00:09, 169.03it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1671/3257 [00:10<00:09, 165.22it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1689/3257 [00:10<00:09, 168.54it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:10<00:09, 170.18it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1727/3257 [00:10<00:08, 177.99it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1746/3257 [00:10<00:09, 161.04it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1765/3257 [00:10<00:08, 168.24it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1785/3257 [00:10<00:08, 176.88it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1804/3257 [00:11<00:08, 179.12it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1823/3257 [00:11<00:08, 176.80it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1841/3257 [00:11<00:08, 174.69it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1859/3257 [00:11<00:07, 174.86it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1880/3257 [00:11<00:07, 184.34it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:11<00:07, 184.70it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1918/3257 [00:11<00:07, 183.68it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1944/3257 [00:11<00:06, 203.61it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1967/3257 [00:11<00:06, 210.51it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1989/3257 [00:11<00:06, 196.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2009/3257 [00:12<00:06, 197.12it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2032/3257 [00:12<00:06, 204.04it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2053/3257 [00:12<00:06, 179.89it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2072/3257 [00:12<00:06, 176.28it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2092/3257 [00:12<00:06, 181.81it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2111/3257 [00:12<00:10, 106.32it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2126/3257 [00:13<00:10, 112.88it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:13<00:09, 121.28it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:13<00:07, 143.82it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2184/3257 [00:13<00:07, 151.25it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2205/3257 [00:13<00:06, 165.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2224/3257 [00:13<00:06, 167.62it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2242/3257 [00:13<00:06, 164.19it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:13<00:06, 166.01it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2278/3257 [00:13<00:05, 164.97it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:14<00:05, 175.74it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2322/3257 [00:14<00:04, 189.69it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2348/3257 [00:14<00:04, 207.69it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2370/3257 [00:14<00:04, 210.22it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2393/3257 [00:14<00:04, 214.93it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2415/3257 [00:14<00:04, 199.81it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2436/3257 [00:14<00:04, 188.93it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2456/3257 [00:14<00:04, 188.25it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2478/3257 [00:14<00:03, 195.21it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2501/3257 [00:14<00:03, 204.33it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2523/3257 [00:15<00:03, 207.36it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2544/3257 [00:15<00:03, 206.53it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2565/3257 [00:15<00:03, 190.45it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2585/3257 [00:15<00:03, 181.01it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2608/3257 [00:15<00:03, 193.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2633/3257 [00:15<00:02, 208.70it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2655/3257 [00:15<00:03, 197.69it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2676/3257 [00:15<00:03, 192.79it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2696/3257 [00:16<00:03, 185.68it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2715/3257 [00:16<00:03, 168.19it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:16<00:02, 189.66it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:16<00:02, 187.33it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2781/3257 [00:16<00:02, 186.42it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2805/3257 [00:16<00:02, 198.27it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2826/3257 [00:16<00:02, 182.26it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2845/3257 [00:16<00:02, 180.11it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:16<00:01, 204.18it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2893/3257 [00:17<00:01, 194.29it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2914/3257 [00:17<00:01, 196.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2934/3257 [00:17<00:01, 190.60it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2954/3257 [00:17<00:01, 181.77it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2975/3257 [00:17<00:01, 188.43it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2995/3257 [00:17<00:01, 180.72it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:17<00:01, 186.82it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3039/3257 [00:17<00:01, 195.45it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:17<00:00, 207.41it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3084/3257 [00:18<00:00, 206.47it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3107/3257 [00:18<00:00, 210.78it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3129/3257 [00:18<00:00, 208.49it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3150/3257 [00:18<00:00, 192.77it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3171/3257 [00:18<00:00, 196.65it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3191/3257 [00:18<00:00, 191.76it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3211/3257 [00:18<00:00, 187.42it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3231/3257 [00:18<00:00, 190.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:18<00:00, 192.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 172.20it/s]
2023-02-07 19:19:36.851 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:19:36,853][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d115,n5,mc9,s0.52432,t4>', 'datetime': '2023-02-07T19:19:36.853067', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:19:36,853][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:19:36,853][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:19:37,371][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:19:37,371][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:19:37,424][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 14828 unique words (34.73% of original 42701, drops 27873)', 'datetime': '2023-02-07T19:19:37.424501', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:19:37,424][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 5723647 word corpus (98.29% of original 5822992, drops 99345)', 'datetime': '2023-02-07T19:19:37.424953', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:19:37,480][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:19:37,481][gensim.models.word2vec][INFO] - sample=0.52432 downsamples 0 most-common words
[2023-02-07 19:19:37,481][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5723647 word corpus (100.0%% of prior 5723647)', 'datetime': '2023-02-07T19:19:37.481926', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:19:37,575][gensim.models.word2vec][INFO] - estimated required memory for 14828 words and 115 dimensions: 23205380 bytes
[2023-02-07 19:19:37,576][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:19:37,586][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14828 vocabulary and 115 features, using sg=1 hs=0 sample=0.5243195557650715 negative=5 window=17 shrink_windows=True', 'datetime': '2023-02-07T19:19:37.586829', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:19:38,591][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 44.67% examples, 2598655 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:39,591][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 92.42% examples, 2646238 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:19:39,737][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5697932 effective words) took 2.1s, 2654181 effective words/s
[2023-02-07 19:19:40,741][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 49.55% examples, 2868493 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:19:41,743][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 99.75% examples, 2837552 words/s, in_qsize 1, out_qsize 1
[2023-02-07 19:19:41,744][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5697932 effective words) took 2.0s, 2840967 effective words/s
[2023-02-07 19:19:42,746][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 49.28% examples, 2865460 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:43,723][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5697932 effective words) took 2.0s, 2881962 effective words/s
[2023-02-07 19:19:44,725][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 50.14% examples, 2905841 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:45,674][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5697932 effective words) took 1.9s, 2923495 effective words/s
[2023-02-07 19:19:46,676][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 64.63% examples, 3751868 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:19:47,226][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5697932 effective words) took 1.5s, 3676255 effective words/s
[2023-02-07 19:19:48,229][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 57.48% examples, 3341757 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:48,932][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5697932 effective words) took 1.7s, 3341355 effective words/s
[2023-02-07 19:19:49,934][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 57.60% examples, 3354336 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:50,622][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5697932 effective words) took 1.7s, 3373584 effective words/s
[2023-02-07 19:19:51,626][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 58.21% examples, 3382479 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:52,304][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5697932 effective words) took 1.7s, 3392140 effective words/s
[2023-02-07 19:19:53,305][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 58.34% examples, 3396562 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:53,987][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5697932 effective words) took 1.7s, 3386876 effective words/s
[2023-02-07 19:19:54,990][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 58.80% examples, 3411136 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:55,654][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5697932 effective words) took 1.7s, 3422039 effective words/s
[2023-02-07 19:19:56,655][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 58.80% examples, 3417656 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:57,295][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5697932 effective words) took 1.6s, 3473432 effective words/s
[2023-02-07 19:19:58,298][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 51.92% examples, 3027651 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:19:59,181][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5697932 effective words) took 1.9s, 3026203 effective words/s
[2023-02-07 19:20:00,183][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 51.21% examples, 2978277 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:20:01,090][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5697932 effective words) took 1.9s, 2986929 effective words/s
[2023-02-07 19:20:02,093][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 51.21% examples, 2977785 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:20:03,007][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5697932 effective words) took 1.9s, 2975606 effective words/s
[2023-02-07 19:20:04,011][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 50.60% examples, 2935908 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:20:04,932][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5697932 effective words) took 1.9s, 2962963 effective words/s
[2023-02-07 19:20:04,933][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85468980 effective words) took 27.3s, 3125457 effective words/s', 'datetime': '2023-02-07T19:20:04.933379', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:20:04.933 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:20:07,250][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191909-dnfpruu3/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:20:07.250417', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:20:07,251][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:20:07,282][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_191909-dnfpruu3/files/../tmp/embedding_model.pt
2023-02-07 19:20:07.282 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:20:08.556 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:20:09.014 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:20:09.851 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9678051359177051, 'test_mae': 0.7580747970499875, 'test_r2': -2.0138301227028257}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.91
wandb: percentage 0.65275
wandb:   test_mae 0.75807
wandb:   test_mse 0.96781
wandb:    test_r2 -2.01383
wandb: 
wandb: üöÄ View run fresh-sweep-38 at: https://wandb.ai/xiaoqiz/mof2vec/runs/dnfpruu3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_191909-dnfpruu3/logs
wandb: Agent Starting Run: joiydkh3 with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 455
wandb: 	model.gensim.alpha: 0.0007163517251419243
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.42932537112596486
wandb: 	model.gensim.vector_size: 454
wandb: 	model.gensim.window: 13
wandb: 	model.sklearn.learning_rate: 0.8177307669639482
wandb: 	model.sklearn.max_depth: 43
wandb: 	model.sklearn.min_child_weight: 0.03205705248281852
wandb: 	model.sklearn.n_estimators: 4149
wandb: 	model.sklearn.num_leaves: 42
wandb: 	model.sklearn.reg_alpha: 0.023990002413007756
wandb: 	model.sklearn.reg_lambda: 0.04513913555885642
wandb: 	model.sklearn.subsample: 0.994872364417072
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192023-joiydkh3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-39
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/joiydkh3
2023-02-07 19:20:31.582 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:20:31.583 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 455 for sweep.
2023-02-07 19:20:31.583 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0007163517251419243 for sweep.
2023-02-07 19:20:31.583 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:20:31.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 19:20:31.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.42932537112596486 for sweep.
2023-02-07 19:20:31.584 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 454 for sweep.
2023-02-07 19:20:31.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 13 for sweep.
2023-02-07 19:20:31.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.8177307669639482 for sweep.
2023-02-07 19:20:31.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 43 for sweep.
2023-02-07 19:20:31.585 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03205705248281852 for sweep.
2023-02-07 19:20:31.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4149 for sweep.
2023-02-07 19:20:31.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 42 for sweep.
2023-02-07 19:20:31.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.023990002413007756 for sweep.
2023-02-07 19:20:31.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.04513913555885642 for sweep.
2023-02-07 19:20:31.586 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.994872364417072 for sweep.
2023-02-07 19:20:31.587 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:20:31.592 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192023-joiydkh3/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 455, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 454, 'window': 13, 'min_count': 8, 'dm': 1, 'sample': 0.42932537112596486, 'workers': 4, 'alpha': 0.0007163517251419243, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4149, 'max_depth': 43, 'num_leaves': 42, 'reg_alpha': 0.023990002413007756, 'reg_lambda': 0.04513913555885642, 'subsample': 0.994872364417072, 'min_child_weight': 0.03205705248281852, 'n_jobs': 4, 'learning_rate': 0.8177307669639482}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:20, 157.49it/s]  1%|          | 34/3257 [00:00<00:19, 164.29it/s]  2%|‚ñè         | 53/3257 [00:00<00:19, 167.78it/s]  2%|‚ñè         | 71/3257 [00:00<00:18, 171.88it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 174.85it/s]  3%|‚ñé         | 108/3257 [00:00<00:18, 169.29it/s]  4%|‚ñç         | 126/3257 [00:00<00:18, 170.01it/s]  5%|‚ñç         | 149/3257 [00:00<00:16, 185.38it/s]  5%|‚ñå         | 168/3257 [00:00<00:17, 178.93it/s]  6%|‚ñå         | 186/3257 [00:01<00:17, 177.57it/s]  6%|‚ñã         | 204/3257 [00:01<00:17, 176.47it/s]  7%|‚ñã         | 228/3257 [00:01<00:15, 194.24it/s]  8%|‚ñä         | 248/3257 [00:01<00:21, 137.49it/s]  8%|‚ñä         | 265/3257 [00:01<00:20, 142.88it/s]  9%|‚ñâ         | 289/3257 [00:01<00:17, 166.33it/s]  9%|‚ñâ         | 308/3257 [00:01<00:17, 171.87it/s] 10%|‚ñà         | 329/3257 [00:01<00:16, 181.76it/s] 11%|‚ñà         | 349/3257 [00:02<00:16, 178.07it/s] 11%|‚ñà‚ñè        | 371/3257 [00:02<00:15, 187.76it/s] 12%|‚ñà‚ñè        | 391/3257 [00:02<00:15, 179.18it/s] 13%|‚ñà‚ñé        | 413/3257 [00:02<00:14, 190.10it/s] 13%|‚ñà‚ñé        | 433/3257 [00:02<00:18, 156.16it/s] 14%|‚ñà‚ñç        | 450/3257 [00:02<00:17, 159.07it/s] 14%|‚ñà‚ñç        | 469/3257 [00:02<00:16, 166.01it/s] 15%|‚ñà‚ñç        | 487/3257 [00:02<00:17, 159.71it/s] 16%|‚ñà‚ñå        | 506/3257 [00:02<00:16, 167.49it/s] 16%|‚ñà‚ñå        | 524/3257 [00:03<00:16, 167.00it/s] 17%|‚ñà‚ñã        | 542/3257 [00:03<00:16, 168.94it/s] 17%|‚ñà‚ñã        | 560/3257 [00:03<00:17, 153.52it/s] 18%|‚ñà‚ñä        | 576/3257 [00:03<00:18, 144.83it/s] 18%|‚ñà‚ñä        | 594/3257 [00:03<00:17, 153.46it/s] 19%|‚ñà‚ñâ        | 612/3257 [00:03<00:16, 159.67it/s] 19%|‚ñà‚ñâ        | 629/3257 [00:03<00:16, 159.07it/s] 20%|‚ñà‚ñâ        | 646/3257 [00:03<00:17, 153.19it/s] 20%|‚ñà‚ñà        | 662/3257 [00:04<00:17, 146.45it/s] 21%|‚ñà‚ñà        | 682/3257 [00:04<00:16, 159.38it/s] 21%|‚ñà‚ñà‚ñè       | 699/3257 [00:04<00:16, 150.50it/s] 22%|‚ñà‚ñà‚ñè       | 719/3257 [00:04<00:15, 161.33it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:04<00:16, 148.94it/s] 23%|‚ñà‚ñà‚ñé       | 753/3257 [00:04<00:16, 152.59it/s] 24%|‚ñà‚ñà‚ñé       | 771/3257 [00:04<00:15, 159.65it/s] 24%|‚ñà‚ñà‚ñç       | 788/3257 [00:04<00:16, 153.84it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:15, 155.04it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:05<00:15, 153.94it/s] 26%|‚ñà‚ñà‚ñå       | 839/3257 [00:05<00:15, 154.48it/s] 26%|‚ñà‚ñà‚ñã       | 855/3257 [00:05<00:16, 149.09it/s] 27%|‚ñà‚ñà‚ñã       | 872/3257 [00:05<00:15, 154.69it/s] 27%|‚ñà‚ñà‚ñã       | 888/3257 [00:05<00:15, 150.80it/s] 28%|‚ñà‚ñà‚ñä       | 906/3257 [00:05<00:14, 158.70it/s] 28%|‚ñà‚ñà‚ñä       | 924/3257 [00:05<00:14, 162.51it/s] 29%|‚ñà‚ñà‚ñâ       | 941/3257 [00:05<00:14, 158.20it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:05<00:14, 163.67it/s] 30%|‚ñà‚ñà‚ñâ       | 977/3257 [00:05<00:13, 167.59it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:06<00:14, 157.98it/s] 31%|‚ñà‚ñà‚ñà       | 1010/3257 [00:06<00:14, 153.19it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:06<00:14, 151.65it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1043/3257 [00:06<00:14, 147.69it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1060/3257 [00:06<00:14, 153.52it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:14, 152.14it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:06<00:14, 154.07it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:06<00:13, 159.45it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1132/3257 [00:07<00:14, 149.40it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1148/3257 [00:07<00:14, 146.85it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1169/3257 [00:07<00:12, 162.91it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1186/3257 [00:07<00:13, 149.34it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1202/3257 [00:07<00:14, 139.60it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:07<00:14, 142.30it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1239/3257 [00:07<00:12, 159.85it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1256/3257 [00:07<00:13, 153.85it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1273/3257 [00:07<00:12, 156.45it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1289/3257 [00:08<00:13, 143.01it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1305/3257 [00:08<00:13, 146.97it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:08<00:12, 150.46it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1341/3257 [00:08<00:11, 162.23it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1358/3257 [00:08<00:21, 90.20it/s]  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1373/3257 [00:08<00:18, 100.59it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:08<00:16, 109.97it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1408/3257 [00:09<00:14, 129.37it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1426/3257 [00:09<00:12, 141.17it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1443/3257 [00:09<00:12, 146.69it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1465/3257 [00:09<00:10, 164.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1483/3257 [00:09<00:10, 168.33it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1503/3257 [00:09<00:10, 175.05it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1522/3257 [00:09<00:10, 162.45it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1539/3257 [00:09<00:10, 158.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1556/3257 [00:09<00:11, 154.12it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:10<00:10, 158.79it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:10<00:10, 157.43it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1609/3257 [00:10<00:10, 163.45it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1627/3257 [00:10<00:09, 167.65it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1644/3257 [00:10<00:10, 156.20it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:10<00:10, 155.52it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1679/3257 [00:10<00:09, 162.24it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:10<00:09, 172.60it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1721/3257 [00:10<00:08, 182.51it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1740/3257 [00:11<00:08, 174.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:11<00:07, 188.54it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1786/3257 [00:11<00:07, 199.03it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1807/3257 [00:11<00:07, 190.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:11<00:07, 191.66it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1852/3257 [00:11<00:06, 203.46it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1875/3257 [00:11<00:06, 210.22it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:11<00:06, 199.57it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1918/3257 [00:11<00:06, 194.85it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1945/3257 [00:12<00:06, 211.28it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1971/3257 [00:12<00:05, 222.08it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1994/3257 [00:12<00:06, 208.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2016/3257 [00:12<00:06, 201.07it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2038/3257 [00:12<00:06, 201.91it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2059/3257 [00:12<00:06, 178.99it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2078/3257 [00:12<00:06, 181.23it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2097/3257 [00:12<00:06, 175.89it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:12<00:06, 179.86it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:13<00:06, 169.54it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:13<00:06, 166.70it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2175/3257 [00:13<00:06, 177.85it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2194/3257 [00:13<00:06, 174.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2212/3257 [00:13<00:06, 167.90it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2232/3257 [00:13<00:05, 176.36it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2250/3257 [00:13<00:05, 170.63it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2268/3257 [00:13<00:05, 171.65it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2287/3257 [00:13<00:05, 176.75it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2305/3257 [00:14<00:05, 177.11it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2328/3257 [00:14<00:04, 192.43it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2352/3257 [00:14<00:04, 204.26it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2373/3257 [00:14<00:04, 194.53it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:14<00:04, 203.69it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2418/3257 [00:14<00:04, 190.26it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2438/3257 [00:14<00:04, 182.05it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2457/3257 [00:14<00:04, 181.24it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2478/3257 [00:14<00:04, 186.84it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2499/3257 [00:15<00:03, 192.68it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2520/3257 [00:15<00:03, 196.39it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:15<00:03, 195.56it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2560/3257 [00:15<00:03, 186.62it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2579/3257 [00:15<00:03, 172.00it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2598/3257 [00:15<00:03, 175.64it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2625/3257 [00:15<00:03, 201.19it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2646/3257 [00:15<00:03, 192.24it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2666/3257 [00:15<00:03, 183.82it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:16<00:03, 187.82it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2706/3257 [00:16<00:03, 172.42it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2724/3257 [00:16<00:03, 167.87it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2747/3257 [00:16<00:02, 184.20it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2766/3257 [00:16<00:02, 183.53it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2785/3257 [00:16<00:04, 99.15it/s]  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2806/3257 [00:17<00:03, 117.47it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:17<00:03, 127.17it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2840/3257 [00:17<00:03, 132.34it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2864/3257 [00:17<00:02, 156.78it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:17<00:02, 170.12it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2905/3257 [00:17<00:02, 162.93it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2927/3257 [00:17<00:01, 177.08it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2946/3257 [00:17<00:01, 163.90it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:17<00:01, 171.44it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:18<00:01, 162.96it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3007/3257 [00:18<00:01, 180.33it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:18<00:01, 177.36it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:18<00:01, 187.78it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:18<00:00, 203.75it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3096/3257 [00:18<00:00, 196.31it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3121/3257 [00:18<00:00, 208.78it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3143/3257 [00:18<00:00, 193.06it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3163/3257 [00:18<00:00, 190.28it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:19<00:00, 179.16it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3205/3257 [00:19<00:00, 188.80it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3225/3257 [00:19<00:00, 181.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3248/3257 [00:19<00:00, 193.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 167.28it/s]
2023-02-07 19:20:51.833 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:20:51,834][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d454,n5,w13,mc8,s0.429325,t4>', 'datetime': '2023-02-07T19:20:51.834251', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:20:51,834][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:20:51,834][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:20:52,430][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:20:52,430][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:20:52,488][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 18271 unique words (42.79% of original 42701, drops 24430)', 'datetime': '2023-02-07T19:20:52.488419', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:20:52,490][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 5751191 word corpus (98.77% of original 5822992, drops 71801)', 'datetime': '2023-02-07T19:20:52.490567', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:20:52,557][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:20:52,558][gensim.models.word2vec][INFO] - sample=0.429325 downsamples 0 most-common words
[2023-02-07 19:20:52,558][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5751191 word corpus (100.0%% of prior 5751191)', 'datetime': '2023-02-07T19:20:52.558883', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:20:52,681][gensim.models.word2vec][INFO] - estimated required memory for 18271 words and 454 dimensions: 82061884 bytes
[2023-02-07 19:20:52,682][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:20:52,727][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18271 vocabulary and 454 features, using sg=0 hs=0 sample=0.42932537112596486 negative=5 window=13 shrink_windows=True', 'datetime': '2023-02-07T19:20:52.727469', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:20:53,755][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 14.00% examples, 765285 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:20:54,760][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 28.00% examples, 792835 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:20:55,763][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 41.48% examples, 805742 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:20:56,768][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 56.25% examples, 816662 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:20:57,768][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 71.26% examples, 826447 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:20:58,768][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 86.80% examples, 829146 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:20:59,601][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5725443 effective words) took 6.9s, 833359 effective words/s
[2023-02-07 19:21:00,615][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 17.22% examples, 945733 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:21:01,622][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 33.25% examples, 955422 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:02,622][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 49.40% examples, 956678 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:03,648][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 65.83% examples, 952070 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:04,653][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 82.99% examples, 950853 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:05,618][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5725443 effective words) took 6.0s, 951807 effective words/s
[2023-02-07 19:21:06,621][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 16.89% examples, 938965 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:07,621][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 32.88% examples, 951221 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:08,633][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 49.09% examples, 952453 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:09,639][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 65.34% examples, 948914 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:10,649][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 81.39% examples, 933603 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:11,652][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 97.24% examples, 924838 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:11,814][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5725443 effective words) took 6.2s, 924298 effective words/s
[2023-02-07 19:21:12,821][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 16.00% examples, 882581 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:13,851][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 30.92% examples, 878374 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:14,852][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 46.15% examples, 884748 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:15,857][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 61.71% examples, 888379 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:16,865][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 78.05% examples, 893794 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:17,866][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 95.00% examples, 901422 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:18,125][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5725443 effective words) took 6.3s, 907591 effective words/s
[2023-02-07 19:21:19,128][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 18.24% examples, 1023443 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:20,134][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 34.85% examples, 1007847 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:21,141][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 51.21% examples, 994018 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:22,148][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 68.04% examples, 988965 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:23,150][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 86.00% examples, 987294 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:23,944][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5725443 effective words) took 5.8s, 984112 effective words/s
[2023-02-07 19:21:24,958][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 17.50% examples, 969682 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:25,964][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 33.71% examples, 969208 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:26,965][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 50.02% examples, 964086 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:21:27,968][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 65.49% examples, 950270 words/s, in_qsize 7, out_qsize 1
[2023-02-07 19:21:28,970][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 82.04% examples, 941954 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:29,972][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 98.68% examples, 939737 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:30,046][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5725443 effective words) took 6.1s, 938670 effective words/s
[2023-02-07 19:21:31,048][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 16.27% examples, 904447 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:32,070][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 31.65% examples, 900882 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:33,072][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 47.04% examples, 907288 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:34,077][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 62.67% examples, 903321 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:35,078][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 78.81% examples, 906670 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:36,079][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 98.13% examples, 932113 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:36,177][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5725443 effective words) took 6.1s, 934050 effective words/s
[2023-02-07 19:21:37,182][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 17.50% examples, 977967 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:38,195][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 33.71% examples, 969803 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:39,199][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 50.54% examples, 976421 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:40,202][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 67.24% examples, 976408 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:41,203][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 84.89% examples, 975882 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:42,036][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5725443 effective words) took 5.9s, 977401 effective words/s
[2023-02-07 19:21:43,043][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 17.65% examples, 983404 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:21:44,058][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 33.71% examples, 968218 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:45,069][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 49.09% examples, 947134 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:46,072][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 64.75% examples, 935366 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:47,085][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 81.39% examples, 930444 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:48,091][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 97.88% examples, 927186 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:48,209][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5725443 effective words) took 6.2s, 927789 effective words/s
[2023-02-07 19:21:49,214][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 16.27% examples, 902433 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:50,231][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 31.65% examples, 902043 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:51,234][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 47.04% examples, 907646 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:52,236][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 63.65% examples, 921974 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:53,238][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 83.33% examples, 959378 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:54,068][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5725443 effective words) took 5.9s, 977610 effective words/s
[2023-02-07 19:21:55,073][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 19.01% examples, 1055236 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:56,073][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 35.71% examples, 1034045 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:21:57,076][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 52.59% examples, 1023259 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:58,078][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 69.67% examples, 1017098 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:59,089][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 88.36% examples, 1013097 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:21:59,720][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5725443 effective words) took 5.7s, 1013198 effective words/s
[2023-02-07 19:22:00,726][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 17.84% examples, 1002670 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:01,728][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 34.85% examples, 1008799 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:02,729][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 51.77% examples, 1008222 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:03,740][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 69.42% examples, 1010031 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:22:04,744][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 88.12% examples, 1010489 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:05,392][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5725443 effective words) took 5.7s, 1009780 effective words/s
[2023-02-07 19:22:06,395][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 17.84% examples, 1005443 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:07,409][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 34.45% examples, 990827 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:22:08,411][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 51.49% examples, 998844 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:09,417][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 68.59% examples, 997121 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:10,419][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 87.07% examples, 1001656 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:11,106][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5725443 effective words) took 5.7s, 1002147 effective words/s
[2023-02-07 19:22:12,116][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 17.50% examples, 972820 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:22:13,123][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 34.33% examples, 987211 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:14,135][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 51.06% examples, 986604 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:15,141][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 68.53% examples, 992643 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:22:16,149][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 86.95% examples, 996694 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:16,850][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5725443 effective words) took 5.7s, 997074 effective words/s
[2023-02-07 19:22:17,858][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 17.65% examples, 982710 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:22:18,868][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 34.85% examples, 1003800 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:19,870][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 51.77% examples, 1004684 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:20,880][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 69.14% examples, 1004053 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:22:21,894][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 87.07% examples, 998472 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:22:22,641][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5725443 effective words) took 5.8s, 989078 effective words/s
[2023-02-07 19:22:22,641][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85881645 effective words) took 89.9s, 955166 effective words/s', 'datetime': '2023-02-07T19:22:22.641788', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:22:22.642 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:22:29,359][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192023-joiydkh3/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:22:29.359670', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:22:29,361][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:22:29,457][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192023-joiydkh3/files/../tmp/embedding_model.pt
2023-02-07 19:22:29.458 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:22:31.712 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:22:32.490 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:22:35.225 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1043034712893622, 'test_mae': 0.8086417731057647, 'test_r2': -3.6765058231792045}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.17
wandb: percentage 0.57212
wandb:   test_mae 0.80864
wandb:   test_mse 1.1043
wandb:    test_r2 -3.67651
wandb: 
wandb: üöÄ View run lively-sweep-39 at: https://wandb.ai/xiaoqiz/mof2vec/runs/joiydkh3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_192023-joiydkh3/logs
wandb: Agent Starting Run: hxf06oq1 with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 550
wandb: 	model.gensim.alpha: 0.0005798374923723422
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.9355855307967575
wandb: 	model.gensim.vector_size: 242
wandb: 	model.gensim.window: 13
wandb: 	model.sklearn.learning_rate: 0.5120025691015881
wandb: 	model.sklearn.max_depth: 16
wandb: 	model.sklearn.min_child_weight: 0.0952527855332912
wandb: 	model.sklearn.n_estimators: 482
wandb: 	model.sklearn.num_leaves: 208
wandb: 	model.sklearn.reg_alpha: 0.032680758140161116
wandb: 	model.sklearn.reg_lambda: 0.15639743499228942
wandb: 	model.sklearn.subsample: 0.2660687677365459
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192247-hxf06oq1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-40
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/hxf06oq1
2023-02-07 19:22:56.447 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 19:22:56.447 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 550 for sweep.
2023-02-07 19:22:56.448 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0005798374923723422 for sweep.
2023-02-07 19:22:56.448 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:22:56.448 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 19:22:56.448 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9355855307967575 for sweep.
2023-02-07 19:22:56.449 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 242 for sweep.
2023-02-07 19:22:56.449 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 13 for sweep.
2023-02-07 19:22:56.449 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.5120025691015881 for sweep.
2023-02-07 19:22:56.450 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 16 for sweep.
2023-02-07 19:22:56.450 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0952527855332912 for sweep.
2023-02-07 19:22:56.450 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 482 for sweep.
2023-02-07 19:22:56.450 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 208 for sweep.
2023-02-07 19:22:56.450 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.032680758140161116 for sweep.
2023-02-07 19:22:56.451 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.15639743499228942 for sweep.
2023-02-07 19:22:56.451 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2660687677365459 for sweep.
2023-02-07 19:22:56.451 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:22:56.457 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192247-hxf06oq1/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 550, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 242, 'window': 13, 'min_count': 10, 'dm': 0, 'sample': 0.9355855307967575, 'workers': 4, 'alpha': 0.0005798374923723422, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 482, 'max_depth': 16, 'num_leaves': 208, 'reg_alpha': 0.032680758140161116, 'reg_lambda': 0.15639743499228942, 'subsample': 0.2660687677365459, 'min_child_weight': 0.0952527855332912, 'n_jobs': 4, 'learning_rate': 0.5120025691015881}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 21/3257 [00:00<00:15, 207.36it/s]  1%|‚ñè         | 42/3257 [00:00<00:15, 205.49it/s]  2%|‚ñè         | 67/3257 [00:00<00:15, 209.35it/s]  3%|‚ñé         | 91/3257 [00:00<00:14, 219.21it/s]  3%|‚ñé         | 113/3257 [00:00<00:14, 215.46it/s]  4%|‚ñç         | 136/3257 [00:00<00:14, 218.02it/s]  5%|‚ñç         | 160/3257 [00:00<00:13, 224.10it/s]  6%|‚ñå         | 183/3257 [00:00<00:13, 219.93it/s]  6%|‚ñã         | 206/3257 [00:00<00:13, 219.00it/s]  7%|‚ñã         | 234/3257 [00:01<00:12, 235.68it/s]  8%|‚ñä         | 258/3257 [00:01<00:12, 231.82it/s]  9%|‚ñâ         | 291/3257 [00:01<00:11, 258.84it/s] 10%|‚ñâ         | 323/3257 [00:01<00:10, 275.46it/s] 11%|‚ñà         | 352/3257 [00:01<00:10, 276.88it/s] 12%|‚ñà‚ñè        | 380/3257 [00:01<00:10, 276.67it/s] 13%|‚ñà‚ñé        | 411/3257 [00:01<00:10, 282.64it/s] 14%|‚ñà‚ñé        | 440/3257 [00:01<00:10, 259.65it/s] 14%|‚ñà‚ñç        | 472/3257 [00:01<00:10, 274.35it/s] 15%|‚ñà‚ñå        | 503/3257 [00:02<00:09, 282.98it/s] 16%|‚ñà‚ñã        | 532/3257 [00:02<00:09, 284.58it/s] 17%|‚ñà‚ñã        | 561/3257 [00:02<00:09, 274.46it/s] 18%|‚ñà‚ñä        | 589/3257 [00:02<00:10, 265.59it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:02<00:09, 269.74it/s] 20%|‚ñà‚ñâ        | 648/3257 [00:02<00:09, 268.22it/s] 21%|‚ñà‚ñà        | 675/3257 [00:02<00:09, 266.69it/s] 22%|‚ñà‚ñà‚ñè       | 702/3257 [00:02<00:09, 259.17it/s] 22%|‚ñà‚ñà‚ñè       | 728/3257 [00:02<00:09, 256.15it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:02<00:09, 254.50it/s] 24%|‚ñà‚ñà‚ñç       | 780/3257 [00:03<00:14, 174.30it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:03<00:12, 191.45it/s] 25%|‚ñà‚ñà‚ñå       | 830/3257 [00:03<00:11, 202.51it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:03<00:11, 206.73it/s] 27%|‚ñà‚ñà‚ñã       | 877/3257 [00:03<00:11, 213.78it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:03<00:10, 234.79it/s] 29%|‚ñà‚ñà‚ñä       | 933/3257 [00:03<00:09, 240.69it/s] 30%|‚ñà‚ñà‚ñâ       | 963/3257 [00:03<00:08, 255.77it/s] 30%|‚ñà‚ñà‚ñà       | 990/3257 [00:04<00:08, 254.18it/s] 31%|‚ñà‚ñà‚ñà       | 1016/3257 [00:04<00:09, 243.13it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:04<00:10, 220.82it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1064/3257 [00:04<00:09, 221.82it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1087/3257 [00:04<00:09, 220.36it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1110/3257 [00:04<00:09, 220.31it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1133/3257 [00:04<00:10, 207.93it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1155/3257 [00:04<00:10, 207.72it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1176/3257 [00:04<00:10, 207.13it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1197/3257 [00:05<00:10, 195.77it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1217/3257 [00:05<00:10, 191.53it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:05<00:09, 207.98it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1266/3257 [00:05<00:09, 213.80it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:05<00:10, 194.77it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:05<00:09, 196.71it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1333/3257 [00:05<00:09, 206.97it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:05<00:09, 203.11it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1375/3257 [00:05<00:09, 203.96it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1396/3257 [00:06<00:09, 204.76it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:06<00:08, 218.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1444/3257 [00:06<00:08, 215.36it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1469/3257 [00:06<00:07, 225.07it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1492/3257 [00:06<00:07, 222.68it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1515/3257 [00:06<00:07, 223.80it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1538/3257 [00:06<00:08, 206.65it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1559/3257 [00:06<00:08, 203.26it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1580/3257 [00:06<00:08, 202.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1604/3257 [00:07<00:07, 210.80it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1627/3257 [00:07<00:07, 215.99it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1649/3257 [00:07<00:08, 200.66it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:07<00:07, 214.28it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1701/3257 [00:07<00:06, 228.28it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:07<00:06, 229.52it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1753/3257 [00:07<00:06, 233.08it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1784/3257 [00:07<00:05, 254.47it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1810/3257 [00:07<00:05, 252.15it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1838/3257 [00:07<00:05, 259.88it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:08<00:05, 267.47it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:08<00:05, 268.88it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1924/3257 [00:08<00:04, 268.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:08<00:04, 293.64it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1991/3257 [00:08<00:04, 285.35it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2020/3257 [00:08<00:04, 284.86it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2049/3257 [00:08<00:04, 264.70it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2076/3257 [00:08<00:04, 260.63it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2103/3257 [00:08<00:04, 253.17it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2129/3257 [00:09<00:04, 247.45it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:09<00:06, 158.24it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:09<00:05, 179.63it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:09<00:05, 197.50it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:09<00:04, 214.83it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2262/3257 [00:09<00:04, 223.20it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2290/3257 [00:09<00:04, 237.17it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2316/3257 [00:10<00:03, 239.88it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2344/3257 [00:10<00:03, 249.61it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2370/3257 [00:10<00:03, 246.74it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2396/3257 [00:10<00:03, 248.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:10<00:03, 232.05it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2446/3257 [00:10<00:03, 219.52it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2471/3257 [00:10<00:03, 226.79it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2495/3257 [00:10<00:03, 225.66it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2520/3257 [00:10<00:03, 231.21it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2544/3257 [00:10<00:03, 230.10it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2568/3257 [00:11<00:03, 214.35it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2590/3257 [00:11<00:03, 208.60it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2618/3257 [00:11<00:02, 227.63it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2642/3257 [00:11<00:02, 227.15it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2665/3257 [00:11<00:02, 218.50it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:11<00:02, 226.44it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2713/3257 [00:11<00:02, 202.66it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2738/3257 [00:11<00:02, 215.18it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:12<00:02, 218.19it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2785/3257 [00:12<00:02, 223.68it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2808/3257 [00:12<00:02, 222.04it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2831/3257 [00:12<00:02, 212.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2855/3257 [00:12<00:01, 218.83it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:12<00:01, 237.45it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2910/3257 [00:12<00:01, 224.78it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2933/3257 [00:12<00:01, 224.36it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2956/3257 [00:12<00:01, 213.41it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2978/3257 [00:12<00:01, 215.11it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3003/3257 [00:13<00:01, 224.89it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3027/3257 [00:13<00:01, 227.90it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3061/3257 [00:13<00:00, 259.94it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3091/3257 [00:13<00:00, 268.78it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3126/3257 [00:13<00:00, 292.41it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3156/3257 [00:13<00:00, 278.69it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:13<00:00, 271.76it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:13<00:00, 269.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3245/3257 [00:13<00:00, 284.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:13<00:00, 232.97it/s]
2023-02-07 19:23:10.882 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:23:10,883][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d242,n5,mc10,s0.935586,t4>', 'datetime': '2023-02-07T19:23:10.883198', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:23:10,883][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:23:10,883][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:23:11,210][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 19:23:11,210][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:23:11,224][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 4982 unique words (38.14% of original 13061, drops 8079)', 'datetime': '2023-02-07T19:23:11.224851', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:23:11,225][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 3610861 word corpus (99.22% of original 3639370, drops 28509)', 'datetime': '2023-02-07T19:23:11.225173', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:23:11,242][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 19:23:11,243][gensim.models.word2vec][INFO] - sample=0.935586 downsamples 0 most-common words
[2023-02-07 19:23:11,243][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3610861 word corpus (100.0%% of prior 3610861)', 'datetime': '2023-02-07T19:23:11.243434', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:23:11,272][gensim.models.word2vec][INFO] - estimated required memory for 4982 words and 242 dimensions: 15940328 bytes
[2023-02-07 19:23:11,272][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:23:11,279][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 4982 vocabulary and 242 features, using sg=1 hs=0 sample=0.9355855307967575 negative=5 window=13 shrink_windows=True', 'datetime': '2023-02-07T19:23:11.279832', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:23:12,283][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 59.66% examples, 2196711 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:12,943][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3614118 effective words) took 1.7s, 2174949 effective words/s
[2023-02-07 19:23:13,951][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 57.35% examples, 2108011 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:14,640][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3614118 effective words) took 1.7s, 2131478 effective words/s
[2023-02-07 19:23:15,645][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 58.24% examples, 2150874 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:16,309][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3614118 effective words) took 1.7s, 2167975 effective words/s
[2023-02-07 19:23:17,312][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 58.00% examples, 2145096 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:17,990][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3614118 effective words) took 1.7s, 2152656 effective words/s
[2023-02-07 19:23:18,997][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 58.80% examples, 2159440 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:19,665][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3614118 effective words) took 1.7s, 2159360 effective words/s
[2023-02-07 19:23:20,671][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 58.00% examples, 2137695 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:21,350][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3614118 effective words) took 1.7s, 2147044 effective words/s
[2023-02-07 19:23:22,353][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 59.20% examples, 2186609 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:22,985][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3614118 effective words) took 1.6s, 2211762 effective words/s
[2023-02-07 19:23:23,995][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 60.58% examples, 2207958 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:24,606][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3614118 effective words) took 1.6s, 2232625 effective words/s
[2023-02-07 19:23:25,613][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 53.73% examples, 1984100 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:26,430][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3614118 effective words) took 1.8s, 1983480 effective words/s
[2023-02-07 19:23:27,434][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 53.52% examples, 1980258 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:28,239][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3614118 effective words) took 1.8s, 1999928 effective words/s
[2023-02-07 19:23:29,244][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 54.04% examples, 1999188 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:30,033][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3614118 effective words) took 1.8s, 2016728 effective words/s
[2023-02-07 19:23:31,037][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 54.59% examples, 2020616 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:31,827][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3614118 effective words) took 1.8s, 2017335 effective words/s
[2023-02-07 19:23:32,831][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 54.04% examples, 2000533 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:33,550][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3614118 effective words) took 1.7s, 2100435 effective words/s
[2023-02-07 19:23:34,554][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 63.68% examples, 2335035 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:35,143][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3614118 effective words) took 1.6s, 2270785 effective words/s
[2023-02-07 19:23:36,150][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 58.21% examples, 2141829 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:23:36,824][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3614118 effective words) took 1.7s, 2152892 effective words/s
[2023-02-07 19:23:36,825][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54211770 effective words) took 25.5s, 2122224 effective words/s', 'datetime': '2023-02-07T19:23:36.824992', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:23:36.825 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:23:38,565][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192247-hxf06oq1/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:23:38.565050', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:23:38,566][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:23:38,593][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192247-hxf06oq1/files/../tmp/embedding_model.pt
2023-02-07 19:23:38.594 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:23:40.216 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:23:40.800 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:23:42.425 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0547607591134032, 'test_mae': 0.7567828078668541, 'test_r2': -2.7180137108287865}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.23
wandb: percentage 0.61856
wandb:   test_mae 0.75678
wandb:   test_mse 1.05476
wandb:    test_r2 -2.71801
wandb: 
wandb: üöÄ View run radiant-sweep-40 at: https://wandb.ai/xiaoqiz/mof2vec/runs/hxf06oq1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_192247-hxf06oq1/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wl0e36kn with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 579
wandb: 	model.gensim.alpha: 0.026113255780166503
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.8885393077690706
wandb: 	model.gensim.vector_size: 387
wandb: 	model.gensim.window: 7
wandb: 	model.sklearn.learning_rate: 0.002482866557555937
wandb: 	model.sklearn.max_depth: 35
wandb: 	model.sklearn.min_child_weight: 0.08961790700508496
wandb: 	model.sklearn.n_estimators: 492
wandb: 	model.sklearn.num_leaves: 182
wandb: 	model.sklearn.reg_alpha: 0.05469857533426592
wandb: 	model.sklearn.reg_lambda: 0.01676494552573218
wandb: 	model.sklearn.subsample: 0.8551036481835541
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192401-wl0e36kn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-41
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/wl0e36kn
2023-02-07 19:24:09.903 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 19:24:09.904 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 579 for sweep.
2023-02-07 19:24:09.904 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.026113255780166503 for sweep.
2023-02-07 19:24:09.905 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:24:09.905 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 19:24:09.905 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8885393077690706 for sweep.
2023-02-07 19:24:09.905 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 387 for sweep.
2023-02-07 19:24:09.906 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 7 for sweep.
2023-02-07 19:24:09.906 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.002482866557555937 for sweep.
2023-02-07 19:24:09.906 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 35 for sweep.
2023-02-07 19:24:09.907 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08961790700508496 for sweep.
2023-02-07 19:24:09.907 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 492 for sweep.
2023-02-07 19:24:09.907 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 182 for sweep.
2023-02-07 19:24:09.907 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.05469857533426592 for sweep.
2023-02-07 19:24:09.908 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.01676494552573218 for sweep.
2023-02-07 19:24:09.908 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8551036481835541 for sweep.
2023-02-07 19:24:09.908 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:24:09.913 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192401-wl0e36kn/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 579, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 387, 'window': 7, 'min_count': 2, 'dm': 1, 'sample': 0.8885393077690706, 'workers': 4, 'alpha': 0.026113255780166503, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 492, 'max_depth': 35, 'num_leaves': 182, 'reg_alpha': 0.05469857533426592, 'reg_lambda': 0.01676494552573218, 'subsample': 0.8551036481835541, 'min_child_weight': 0.08961790700508496, 'n_jobs': 4, 'learning_rate': 0.002482866557555937}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 175.41it/s]  1%|‚ñè         | 41/3257 [00:00<00:16, 195.43it/s]  2%|‚ñè         | 61/3257 [00:00<00:16, 194.27it/s]  3%|‚ñé         | 84/3257 [00:00<00:15, 206.45it/s]  3%|‚ñé         | 105/3257 [00:00<00:15, 200.90it/s]  4%|‚ñç         | 126/3257 [00:00<00:15, 196.09it/s]  5%|‚ñç         | 151/3257 [00:00<00:14, 208.35it/s]  5%|‚ñå         | 172/3257 [00:00<00:15, 202.88it/s]  6%|‚ñå         | 193/3257 [00:00<00:14, 204.79it/s]  7%|‚ñã         | 216/3257 [00:01<00:14, 208.27it/s]  7%|‚ñã         | 239/3257 [00:01<00:14, 214.09it/s]  8%|‚ñä         | 261/3257 [00:01<00:14, 209.20it/s]  9%|‚ñâ         | 288/3257 [00:01<00:13, 225.60it/s] 10%|‚ñâ         | 311/3257 [00:01<00:13, 220.08it/s] 10%|‚ñà         | 334/3257 [00:01<00:13, 219.46it/s] 11%|‚ñà         | 356/3257 [00:01<00:13, 218.25it/s] 12%|‚ñà‚ñè        | 378/3257 [00:01<00:14, 202.20it/s] 12%|‚ñà‚ñè        | 399/3257 [00:02<00:21, 133.75it/s] 13%|‚ñà‚ñé        | 420/3257 [00:02<00:19, 149.24it/s] 13%|‚ñà‚ñé        | 438/3257 [00:02<00:19, 145.45it/s] 14%|‚ñà‚ñç        | 460/3257 [00:02<00:17, 161.76it/s] 15%|‚ñà‚ñç        | 480/3257 [00:02<00:16, 169.60it/s] 16%|‚ñà‚ñå        | 505/3257 [00:02<00:14, 189.64it/s] 16%|‚ñà‚ñå        | 526/3257 [00:02<00:14, 194.98it/s] 17%|‚ñà‚ñã        | 547/3257 [00:02<00:13, 197.63it/s] 17%|‚ñà‚ñã        | 568/3257 [00:02<00:13, 193.18it/s] 18%|‚ñà‚ñä        | 588/3257 [00:03<00:14, 190.41it/s] 19%|‚ñà‚ñâ        | 611/3257 [00:03<00:13, 201.49it/s] 19%|‚ñà‚ñâ        | 633/3257 [00:03<00:12, 206.32it/s] 20%|‚ñà‚ñà        | 654/3257 [00:03<00:13, 195.31it/s] 21%|‚ñà‚ñà        | 674/3257 [00:03<00:13, 195.40it/s] 21%|‚ñà‚ñà‚ñè       | 694/3257 [00:03<00:13, 193.75it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:03<00:12, 200.73it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:03<00:13, 185.41it/s] 23%|‚ñà‚ñà‚ñé       | 761/3257 [00:03<00:12, 197.31it/s] 24%|‚ñà‚ñà‚ñç       | 782/3257 [00:04<00:12, 194.09it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:04<00:12, 199.83it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:04<00:12, 188.60it/s] 26%|‚ñà‚ñà‚ñå       | 845/3257 [00:04<00:12, 188.29it/s] 27%|‚ñà‚ñà‚ñã       | 870/3257 [00:04<00:11, 204.37it/s] 27%|‚ñà‚ñà‚ñã       | 894/3257 [00:04<00:11, 212.96it/s] 28%|‚ñà‚ñà‚ñä       | 921/3257 [00:04<00:10, 228.85it/s] 29%|‚ñà‚ñà‚ñâ       | 945/3257 [00:04<00:09, 231.43it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:04<00:09, 233.44it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:05<00:09, 228.24it/s] 31%|‚ñà‚ñà‚ñà       | 1017/3257 [00:05<00:09, 227.67it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1040/3257 [00:05<00:10, 219.26it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1063/3257 [00:05<00:10, 218.15it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:05<00:09, 223.96it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:05<00:09, 226.15it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1135/3257 [00:05<00:09, 217.69it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1157/3257 [00:05<00:09, 216.49it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1179/3257 [00:05<00:09, 208.72it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1200/3257 [00:06<00:10, 200.39it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1221/3257 [00:06<00:10, 202.70it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:06<00:09, 217.61it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:06<00:09, 219.07it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1293/3257 [00:06<00:09, 202.00it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1316/3257 [00:06<00:09, 208.21it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1342/3257 [00:06<00:08, 219.42it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1365/3257 [00:06<00:08, 213.04it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1387/3257 [00:06<00:09, 207.75it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1413/3257 [00:06<00:08, 222.21it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1437/3257 [00:07<00:08, 225.91it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:07<00:07, 234.63it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1487/3257 [00:07<00:07, 233.47it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:07<00:07, 239.80it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1538/3257 [00:07<00:07, 222.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1561/3257 [00:07<00:07, 218.18it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1584/3257 [00:07<00:07, 219.56it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1609/3257 [00:07<00:07, 227.57it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:07<00:07, 224.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:08<00:07, 221.39it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1680/3257 [00:08<00:07, 219.59it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1703/3257 [00:08<00:06, 222.38it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:08<00:11, 137.69it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1748/3257 [00:08<00:10, 149.58it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1772/3257 [00:08<00:08, 169.37it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:08<00:07, 185.32it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1818/3257 [00:09<00:07, 193.64it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1842/3257 [00:09<00:06, 203.63it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1868/3257 [00:09<00:06, 217.77it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1891/3257 [00:09<00:06, 213.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:09<00:06, 217.82it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1944/3257 [00:09<00:05, 233.83it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1972/3257 [00:09<00:05, 245.78it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1997/3257 [00:09<00:05, 236.17it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:09<00:05, 238.12it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2047/3257 [00:09<00:05, 222.85it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2070/3257 [00:10<00:05, 214.15it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2095/3257 [00:10<00:05, 221.50it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2118/3257 [00:10<00:05, 223.02it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2141/3257 [00:10<00:05, 207.81it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:10<00:05, 208.12it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:10<00:05, 210.14it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:10<00:04, 212.88it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2233/3257 [00:10<00:04, 219.45it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2256/3257 [00:10<00:04, 215.51it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2278/3257 [00:11<00:04, 211.52it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2303/3257 [00:11<00:04, 222.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2333/3257 [00:11<00:03, 242.24it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2361/3257 [00:11<00:03, 251.35it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2389/3257 [00:11<00:03, 257.53it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2415/3257 [00:11<00:03, 244.35it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:11<00:03, 233.82it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2464/3257 [00:11<00:03, 233.27it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2490/3257 [00:11<00:03, 238.26it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2519/3257 [00:12<00:02, 251.37it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2545/3257 [00:12<00:02, 252.57it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2571/3257 [00:12<00:02, 230.54it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2595/3257 [00:12<00:02, 227.40it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2628/3257 [00:12<00:02, 252.67it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:12<00:02, 240.75it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2679/3257 [00:12<00:02, 241.03it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:12<00:02, 225.23it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2729/3257 [00:12<00:02, 230.81it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2755/3257 [00:13<00:02, 238.79it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2780/3257 [00:13<00:02, 228.72it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:13<00:01, 239.26it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2832/3257 [00:13<00:01, 230.52it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2859/3257 [00:13<00:01, 241.02it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2888/3257 [00:13<00:01, 251.92it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2914/3257 [00:13<00:01, 244.75it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2939/3257 [00:13<00:01, 242.83it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2964/3257 [00:13<00:01, 233.58it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2988/3257 [00:14<00:01, 222.61it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:14<00:01, 233.96it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3044/3257 [00:14<00:00, 245.91it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3074/3257 [00:14<00:00, 260.16it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3101/3257 [00:14<00:00, 254.77it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3129/3257 [00:14<00:00, 259.13it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3156/3257 [00:14<00:00, 243.18it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3181/3257 [00:14<00:00, 233.41it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3205/3257 [00:15<00:00, 144.95it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3228/3257 [00:15<00:00, 161.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:15<00:00, 174.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:15<00:00, 211.86it/s]
2023-02-07 19:24:25.913 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:24:25,914][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d387,n5,w7,mc2,s0.888539,t4>', 'datetime': '2023-02-07T19:24:25.914907', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:24:25,915][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:24:25,915][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:24:26,358][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 19:24:26,359][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:24:26,411][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 18495 unique words (85.23% of original 21699, drops 3204)', 'datetime': '2023-02-07T19:24:26.411764', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:24:26,412][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 4364040 word corpus (99.93% of original 4367244, drops 3204)', 'datetime': '2023-02-07T19:24:26.412184', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:24:26,480][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 19:24:26,481][gensim.models.word2vec][INFO] - sample=0.888539 downsamples 0 most-common words
[2023-02-07 19:24:26,481][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4364040 word corpus (100.0%% of prior 4364040)', 'datetime': '2023-02-07T19:24:26.481714', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:24:26,596][gensim.models.word2vec][INFO] - estimated required memory for 18495 words and 387 dimensions: 72201256 bytes
[2023-02-07 19:24:26,596][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:24:26,636][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18495 vocabulary and 387 features, using sg=0 hs=0 sample=0.8885393077690706 negative=5 window=7 shrink_windows=True', 'datetime': '2023-02-07T19:24:26.636768', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:24:27,645][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 27.76% examples, 1207507 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:28,655][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 56.34% examples, 1252717 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:24:29,663][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 86.95% examples, 1266797 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:24:30,083][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4365521 effective words) took 3.4s, 1267604 effective words/s
[2023-02-07 19:24:31,105][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 29.51% examples, 1265977 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:32,112][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 58.03% examples, 1278917 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:33,122][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 88.89% examples, 1286436 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:33,460][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4365521 effective words) took 3.4s, 1293355 effective words/s
[2023-02-07 19:24:34,467][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 33.16% examples, 1461776 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:24:35,471][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 67.06% examples, 1487221 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:36,426][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4365521 effective words) took 3.0s, 1473386 effective words/s
[2023-02-07 19:24:37,436][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 32.39% examples, 1417462 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:38,446][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 65.09% examples, 1436732 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:39,449][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 99.66% examples, 1438864 words/s, in_qsize 2, out_qsize 1
[2023-02-07 19:24:39,457][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4365521 effective words) took 3.0s, 1440955 effective words/s
[2023-02-07 19:24:40,461][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 32.61% examples, 1433745 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:41,465][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 65.27% examples, 1449725 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:42,466][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 99.94% examples, 1448141 words/s, in_qsize 1, out_qsize 1
[2023-02-07 19:24:42,472][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4365521 effective words) took 3.0s, 1448504 effective words/s
[2023-02-07 19:24:43,473][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 32.61% examples, 1437574 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:44,474][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 64.32% examples, 1428723 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:45,474][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 96.28% examples, 1401224 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:45,588][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4365521 effective words) took 3.1s, 1401399 effective words/s
[2023-02-07 19:24:46,596][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 29.51% examples, 1284348 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:47,608][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 60.02% examples, 1321541 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:24:48,609][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 91.07% examples, 1325625 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:48,882][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4365521 effective words) took 3.3s, 1326278 effective words/s
[2023-02-07 19:24:49,898][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 30.30% examples, 1308394 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:24:50,899][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 60.67% examples, 1335911 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:51,900][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 91.77% examples, 1338881 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:52,139][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4365521 effective words) took 3.3s, 1341014 effective words/s
[2023-02-07 19:24:53,145][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 33.22% examples, 1461104 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:24:54,147][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 68.07% examples, 1515878 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:24:55,042][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4365521 effective words) took 2.9s, 1505252 effective words/s
[2023-02-07 19:24:56,051][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 33.16% examples, 1456236 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:24:57,059][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 66.84% examples, 1476831 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:24:57,996][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4365521 effective words) took 3.0s, 1478519 effective words/s
[2023-02-07 19:24:59,002][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 33.25% examples, 1468593 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:00,004][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 65.89% examples, 1466067 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:00,960][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4365521 effective words) took 3.0s, 1473330 effective words/s
[2023-02-07 19:25:01,964][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 33.16% examples, 1464511 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:02,966][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 66.17% examples, 1472396 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:03,972][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 98.74% examples, 1434593 words/s, in_qsize 6, out_qsize 0
[2023-02-07 19:25:04,006][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4365521 effective words) took 3.0s, 1433964 effective words/s
[2023-02-07 19:25:05,015][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 30.98% examples, 1353582 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:06,018][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 61.50% examples, 1357120 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:07,032][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 93.00% examples, 1351019 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:07,228][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4365521 effective words) took 3.2s, 1355596 effective words/s
[2023-02-07 19:25:08,243][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 30.30% examples, 1310855 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:25:09,247][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 60.98% examples, 1343234 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:10,249][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 92.57% examples, 1347552 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:10,463][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4365521 effective words) took 3.2s, 1350480 effective words/s
[2023-02-07 19:25:11,465][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 31.59% examples, 1392258 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:12,466][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 67.45% examples, 1502100 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:25:13,357][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4365521 effective words) took 2.9s, 1509447 effective words/s
[2023-02-07 19:25:13,358][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65482815 effective words) took 46.7s, 1401576 effective words/s', 'datetime': '2023-02-07T19:25:13.358106', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:25:13.358 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:25:16,651][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192401-wl0e36kn/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:25:16.651271', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:25:16,652][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:25:16,746][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192401-wl0e36kn/files/../tmp/embedding_model.pt
2023-02-07 19:25:16.746 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:25:18.903 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:25:19.639 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:25:22.372 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0941526339986594, 'test_mae': 0.8132243683458837, 'test_r2': -3.3269109547998674}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.83
wandb: percentage 0.14766
wandb:   test_mae 0.81322
wandb:   test_mse 1.09415
wandb:    test_r2 -3.32691
wandb: 
wandb: üöÄ View run absurd-sweep-41 at: https://wandb.ai/xiaoqiz/mof2vec/runs/wl0e36kn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_192401-wl0e36kn/logs
wandb: Agent Starting Run: glqz8hd4 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 243
wandb: 	model.gensim.alpha: 0.5037605842962127
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.9546102800589532
wandb: 	model.gensim.vector_size: 40
wandb: 	model.gensim.window: 5
wandb: 	model.sklearn.learning_rate: 0.3967075903840643
wandb: 	model.sklearn.max_depth: 39
wandb: 	model.sklearn.min_child_weight: 0.05153336326327396
wandb: 	model.sklearn.n_estimators: 927
wandb: 	model.sklearn.num_leaves: 159
wandb: 	model.sklearn.reg_alpha: 0.004478483044033906
wandb: 	model.sklearn.reg_lambda: 0.17737390878730597
wandb: 	model.sklearn.subsample: 0.953343789576576
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192532-glqz8hd4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-42
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/glqz8hd4
2023-02-07 19:25:41.014 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:25:41.015 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 243 for sweep.
2023-02-07 19:25:41.015 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.5037605842962127 for sweep.
2023-02-07 19:25:41.015 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:25:41.016 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 19:25:41.016 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9546102800589532 for sweep.
2023-02-07 19:25:41.016 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 40 for sweep.
2023-02-07 19:25:41.016 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 5 for sweep.
2023-02-07 19:25:41.017 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.3967075903840643 for sweep.
2023-02-07 19:25:41.017 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 39 for sweep.
2023-02-07 19:25:41.017 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05153336326327396 for sweep.
2023-02-07 19:25:41.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 927 for sweep.
2023-02-07 19:25:41.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 159 for sweep.
2023-02-07 19:25:41.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004478483044033906 for sweep.
2023-02-07 19:25:41.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.17737390878730597 for sweep.
2023-02-07 19:25:41.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.953343789576576 for sweep.
2023-02-07 19:25:41.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:25:41.025 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192532-glqz8hd4/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 243, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 40, 'window': 5, 'min_count': 3, 'dm': 1, 'sample': 0.9546102800589532, 'workers': 4, 'alpha': 0.5037605842962127, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 927, 'max_depth': 39, 'num_leaves': 159, 'reg_alpha': 0.004478483044033906, 'reg_lambda': 0.17737390878730597, 'subsample': 0.953343789576576, 'min_child_weight': 0.05153336326327396, 'n_jobs': 4, 'learning_rate': 0.3967075903840643}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:20, 160.43it/s]  1%|          | 35/3257 [00:00<00:18, 170.78it/s]  2%|‚ñè         | 53/3257 [00:00<00:18, 169.75it/s]  2%|‚ñè         | 72/3257 [00:00<00:18, 176.05it/s]  3%|‚ñé         | 91/3257 [00:00<00:17, 180.49it/s]  3%|‚ñé         | 110/3257 [00:00<00:18, 172.54it/s]  4%|‚ñç         | 130/3257 [00:00<00:17, 180.86it/s]  5%|‚ñç         | 151/3257 [00:00<00:16, 185.73it/s]  5%|‚ñå         | 170/3257 [00:00<00:16, 184.97it/s]  6%|‚ñå         | 189/3257 [00:01<00:16, 182.72it/s]  6%|‚ñã         | 208/3257 [00:01<00:16, 183.07it/s]  7%|‚ñã         | 231/3257 [00:01<00:15, 196.63it/s]  8%|‚ñä         | 251/3257 [00:01<00:15, 196.25it/s]  8%|‚ñä         | 271/3257 [00:01<00:15, 188.40it/s]  9%|‚ñâ         | 296/3257 [00:01<00:14, 202.22it/s] 10%|‚ñâ         | 317/3257 [00:01<00:15, 192.14it/s] 10%|‚ñà         | 337/3257 [00:01<00:15, 191.71it/s] 11%|‚ñà         | 358/3257 [00:01<00:14, 195.68it/s] 12%|‚ñà‚ñè        | 378/3257 [00:02<00:16, 179.44it/s] 12%|‚ñà‚ñè        | 397/3257 [00:02<00:16, 178.51it/s] 13%|‚ñà‚ñé        | 416/3257 [00:02<00:15, 180.06it/s] 13%|‚ñà‚ñé        | 435/3257 [00:02<00:18, 151.21it/s] 14%|‚ñà‚ñç        | 455/3257 [00:02<00:17, 163.20it/s] 15%|‚ñà‚ñç        | 474/3257 [00:02<00:16, 166.85it/s] 15%|‚ñà‚ñå        | 492/3257 [00:02<00:16, 168.61it/s] 16%|‚ñà‚ñå        | 512/3257 [00:02<00:15, 175.66it/s] 16%|‚ñà‚ñã        | 530/3257 [00:02<00:15, 171.85it/s] 17%|‚ñà‚ñã        | 548/3257 [00:03<00:15, 170.03it/s] 17%|‚ñà‚ñã        | 566/3257 [00:03<00:16, 162.80it/s] 18%|‚ñà‚ñä        | 583/3257 [00:03<00:16, 160.91it/s] 18%|‚ñà‚ñä        | 602/3257 [00:03<00:15, 168.77it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:15, 168.06it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:03<00:14, 175.08it/s] 20%|‚ñà‚ñà        | 658/3257 [00:03<00:16, 160.35it/s] 21%|‚ñà‚ñà        | 678/3257 [00:03<00:15, 170.37it/s] 21%|‚ñà‚ñà‚ñè       | 696/3257 [00:03<00:15, 164.76it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:14, 176.60it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:04<00:15, 164.22it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:04<00:14, 168.27it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:04<00:14, 172.86it/s] 24%|‚ñà‚ñà‚ñç       | 791/3257 [00:04<00:14, 173.86it/s] 25%|‚ñà‚ñà‚ñç       | 809/3257 [00:04<00:14, 171.02it/s] 25%|‚ñà‚ñà‚ñå       | 827/3257 [00:04<00:14, 168.50it/s] 26%|‚ñà‚ñà‚ñå       | 844/3257 [00:04<00:14, 162.31it/s] 26%|‚ñà‚ñà‚ñã       | 863/3257 [00:04<00:14, 169.81it/s] 27%|‚ñà‚ñà‚ñã       | 881/3257 [00:05<00:14, 164.05it/s] 28%|‚ñà‚ñà‚ñä       | 901/3257 [00:05<00:13, 173.57it/s] 28%|‚ñà‚ñà‚ñä       | 919/3257 [00:05<00:13, 174.38it/s] 29%|‚ñà‚ñà‚ñâ       | 941/3257 [00:05<00:12, 185.32it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:05<00:11, 203.15it/s] 30%|‚ñà‚ñà‚ñà       | 987/3257 [00:05<00:11, 200.58it/s] 31%|‚ñà‚ñà‚ñà       | 1008/3257 [00:05<00:11, 199.82it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1030/3257 [00:05<00:10, 203.36it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:05<00:10, 200.57it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1078/3257 [00:05<00:09, 218.58it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1100/3257 [00:06<00:10, 208.67it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1121/3257 [00:06<00:10, 204.79it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1142/3257 [00:06<00:15, 134.43it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1165/3257 [00:06<00:13, 154.12it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1184/3257 [00:06<00:13, 154.55it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1202/3257 [00:06<00:13, 155.27it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1223/3257 [00:06<00:12, 168.45it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:07<00:11, 179.59it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1266/3257 [00:07<00:10, 186.62it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1286/3257 [00:07<00:11, 172.16it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1307/3257 [00:07<00:10, 180.74it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:07<00:10, 186.10it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:07<00:10, 188.32it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:07<00:10, 187.07it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1389/3257 [00:07<00:10, 182.82it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1415/3257 [00:07<00:09, 203.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1436/3257 [00:08<00:08, 202.49it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:08<00:08, 213.18it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1482/3257 [00:08<00:08, 211.55it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1507/3257 [00:08<00:08, 218.60it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1529/3257 [00:08<00:08, 201.74it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:08<00:08, 192.85it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1570/3257 [00:08<00:08, 189.90it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1590/3257 [00:08<00:08, 189.80it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1613/3257 [00:08<00:08, 199.81it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:09<00:08, 190.27it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:09<00:08, 188.27it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1673/3257 [00:09<00:08, 182.02it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:09<00:08, 180.99it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:09<00:08, 189.03it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1734/3257 [00:09<00:08, 173.11it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1757/3257 [00:09<00:07, 187.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1777/3257 [00:09<00:07, 189.31it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1799/3257 [00:09<00:07, 196.47it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1819/3257 [00:10<00:07, 195.24it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1839/3257 [00:10<00:07, 194.43it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1859/3257 [00:10<00:07, 195.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1881/3257 [00:10<00:06, 201.36it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1902/3257 [00:10<00:06, 199.25it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1922/3257 [00:10<00:06, 195.72it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1949/3257 [00:10<00:06, 216.45it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:10<00:05, 222.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1997/3257 [00:10<00:05, 217.44it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2019/3257 [00:10<00:05, 216.19it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2041/3257 [00:11<00:05, 207.48it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2062/3257 [00:11<00:06, 193.16it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2084/3257 [00:11<00:05, 199.38it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2105/3257 [00:11<00:05, 198.13it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2125/3257 [00:11<00:06, 188.48it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2144/3257 [00:11<00:06, 183.43it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:11<00:05, 195.64it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2189/3257 [00:11<00:05, 198.14it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:11<00:05, 196.93it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2231/3257 [00:12<00:05, 203.46it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2252/3257 [00:12<00:05, 200.08it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2273/3257 [00:12<00:08, 118.96it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2298/3257 [00:12<00:06, 143.74it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2321/3257 [00:12<00:05, 162.32it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2349/3257 [00:12<00:04, 189.57it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2372/3257 [00:12<00:04, 197.16it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:13<00:04, 209.53it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:13<00:04, 201.69it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2444/3257 [00:13<00:04, 195.02it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2469/3257 [00:13<00:03, 209.08it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2493/3257 [00:13<00:03, 215.97it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2519/3257 [00:13<00:03, 226.75it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2543/3257 [00:13<00:03, 227.55it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2567/3257 [00:13<00:03, 213.24it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2589/3257 [00:13<00:03, 190.34it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:14<00:03, 204.32it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2636/3257 [00:14<00:03, 205.88it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2658/3257 [00:14<00:03, 187.55it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2678/3257 [00:14<00:03, 187.87it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2698/3257 [00:14<00:03, 173.28it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2716/3257 [00:14<00:03, 165.77it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2740/3257 [00:14<00:02, 184.28it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2760/3257 [00:14<00:02, 187.00it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2780/3257 [00:15<00:02, 180.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2802/3257 [00:15<00:02, 189.80it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2822/3257 [00:15<00:02, 180.97it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2841/3257 [00:15<00:02, 172.11it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2866/3257 [00:15<00:02, 192.05it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2887/3257 [00:15<00:01, 195.92it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:15<00:01, 182.38it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:15<00:01, 186.97it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:15<00:01, 178.14it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:16<00:01, 180.76it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:16<00:01, 172.30it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3008/3257 [00:16<00:01, 184.50it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3027/3257 [00:16<00:01, 180.67it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:16<00:01, 188.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3073/3257 [00:16<00:00, 201.78it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3094/3257 [00:16<00:00, 195.07it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:16<00:00, 203.14it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3139/3257 [00:16<00:00, 196.13it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3159/3257 [00:17<00:00, 186.19it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3178/3257 [00:17<00:00, 174.33it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3201/3257 [00:17<00:00, 185.96it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3220/3257 [00:17<00:00, 179.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:17<00:00, 190.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 185.40it/s]
2023-02-07 19:25:59.379 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:25:59,380][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d40,n5,w5,mc3,s0.95461,t4>', 'datetime': '2023-02-07T19:25:59.380801', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:25:59,381][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:25:59,381][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:25:59,890][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:25:59,890][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:25:59,960][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 22723 unique words (71.45% of original 31803, drops 9080)', 'datetime': '2023-02-07T19:25:59.960717', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:25:59,961][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 5081575 word corpus (99.73% of original 5095118, drops 13543)', 'datetime': '2023-02-07T19:25:59.961189', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:26:00,047][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:26:00,050][gensim.models.word2vec][INFO] - sample=0.95461 downsamples 0 most-common words
[2023-02-07 19:26:00,050][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5081575 word corpus (100.0%% of prior 5081575)', 'datetime': '2023-02-07T19:26:00.050503', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:26:00,193][gensim.models.word2vec][INFO] - estimated required memory for 22723 words and 40 dimensions: 19805380 bytes
[2023-02-07 19:26:00,194][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:26:00,199][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 22723 vocabulary and 40 features, using sg=0 hs=0 sample=0.9546102800589532 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-07T19:26:00.199357', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:26:01,202][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 58.12% examples, 3015746 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:01,877][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5073452 effective words) took 1.7s, 3029999 effective words/s
[2023-02-07 19:26:02,879][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 60.73% examples, 3128261 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:03,441][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5073452 effective words) took 1.6s, 3246369 effective words/s
[2023-02-07 19:26:04,443][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 78.69% examples, 4032969 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:04,700][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5073452 effective words) took 1.3s, 4036356 effective words/s
[2023-02-07 19:26:05,702][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 79.12% examples, 4054586 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:05,957][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5073452 effective words) took 1.3s, 4037224 effective words/s
[2023-02-07 19:26:06,959][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 75.22% examples, 3878431 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:07,278][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5073452 effective words) took 1.3s, 3845241 effective words/s
[2023-02-07 19:26:08,283][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 69.88% examples, 3620715 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:08,693][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5073452 effective words) took 1.4s, 3587937 effective words/s
[2023-02-07 19:26:09,695][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 65.06% examples, 3357962 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:10,173][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5073452 effective words) took 1.5s, 3432372 effective words/s
[2023-02-07 19:26:11,176][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 68.50% examples, 3541023 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:11,601][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5073452 effective words) took 1.4s, 3556218 effective words/s
[2023-02-07 19:26:12,602][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 68.01% examples, 3528210 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:13,028][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5073452 effective words) took 1.4s, 3558143 effective words/s
[2023-02-07 19:26:14,031][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 67.70% examples, 3499150 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:14,479][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5073452 effective words) took 1.4s, 3500094 effective words/s
[2023-02-07 19:26:15,481][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 67.79% examples, 3507501 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:15,928][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5073452 effective words) took 1.4s, 3504733 effective words/s
[2023-02-07 19:26:16,931][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 68.01% examples, 3522245 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:17,376][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5073452 effective words) took 1.4s, 3506591 effective words/s
[2023-02-07 19:26:18,380][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 69.02% examples, 3569765 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:18,796][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5073452 effective words) took 1.4s, 3576454 effective words/s
[2023-02-07 19:26:19,803][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 67.85% examples, 3500156 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:20,257][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5073452 effective words) took 1.5s, 3474558 effective words/s
[2023-02-07 19:26:21,263][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 67.85% examples, 3504107 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:26:21,701][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5073452 effective words) took 1.4s, 3515408 effective words/s
[2023-02-07 19:26:21,702][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76101780 effective words) took 21.5s, 3539187 effective words/s', 'datetime': '2023-02-07T19:26:21.702418', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:26:21.702 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:26:23,734][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192532-glqz8hd4/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:26:23.734829', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:26:23,735][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:26:23,766][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192532-glqz8hd4/files/../tmp/embedding_model.pt
2023-02-07 19:26:23.766 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:26:24.746 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:26:25.116 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:26:25.461 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.2525010844927356, 'test_mae': 0.8809551951801119, 'test_r2': -4.08907583305903}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.0
wandb: percentage 0.28551
wandb:   test_mae 0.88096
wandb:   test_mse 1.2525
wandb:    test_r2 -4.08908
wandb: 
wandb: üöÄ View run rural-sweep-42 at: https://wandb.ai/xiaoqiz/mof2vec/runs/glqz8hd4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_192532-glqz8hd4/logs
wandb: Agent Starting Run: u1iss2qe with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 216
wandb: 	model.gensim.alpha: 0.03570927354191802
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.5051081261868333
wandb: 	model.gensim.vector_size: 323
wandb: 	model.gensim.window: 20
wandb: 	model.sklearn.learning_rate: 0.6833863334332232
wandb: 	model.sklearn.max_depth: 21
wandb: 	model.sklearn.min_child_weight: 0.031550438411013584
wandb: 	model.sklearn.n_estimators: 561
wandb: 	model.sklearn.num_leaves: 238
wandb: 	model.sklearn.reg_alpha: 0.45704658016873617
wandb: 	model.sklearn.reg_lambda: 0.004814597314546215
wandb: 	model.sklearn.subsample: 0.7463743145055426
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192638-u1iss2qe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-43
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/u1iss2qe
2023-02-07 19:26:46.035 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:26:46.035 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 216 for sweep.
2023-02-07 19:26:46.036 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.03570927354191802 for sweep.
2023-02-07 19:26:46.036 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:26:46.036 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 19:26:46.037 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5051081261868333 for sweep.
2023-02-07 19:26:46.037 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 323 for sweep.
2023-02-07 19:26:46.037 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 20 for sweep.
2023-02-07 19:26:46.037 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.6833863334332232 for sweep.
2023-02-07 19:26:46.038 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 21 for sweep.
2023-02-07 19:26:46.038 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.031550438411013584 for sweep.
2023-02-07 19:26:46.038 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 561 for sweep.
2023-02-07 19:26:46.038 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 238 for sweep.
2023-02-07 19:26:46.039 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.45704658016873617 for sweep.
2023-02-07 19:26:46.039 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.004814597314546215 for sweep.
2023-02-07 19:26:46.039 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7463743145055426 for sweep.
2023-02-07 19:26:46.039 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:26:46.043 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192638-u1iss2qe/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 216, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 323, 'window': 20, 'min_count': 7, 'dm': 0, 'sample': 0.5051081261868333, 'workers': 4, 'alpha': 0.03570927354191802, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 561, 'max_depth': 21, 'num_leaves': 238, 'reg_alpha': 0.45704658016873617, 'reg_lambda': 0.004814597314546215, 'subsample': 0.7463743145055426, 'min_child_weight': 0.031550438411013584, 'n_jobs': 4, 'learning_rate': 0.6833863334332232}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 138.16it/s]  1%|          | 30/3257 [00:00<00:21, 150.08it/s]  1%|‚ñè         | 46/3257 [00:00<00:21, 151.99it/s]  2%|‚ñè         | 62/3257 [00:00<00:21, 148.15it/s]  2%|‚ñè         | 79/3257 [00:00<00:20, 154.24it/s]  3%|‚ñé         | 95/3257 [00:00<00:20, 152.42it/s]  3%|‚ñé         | 111/3257 [00:00<00:21, 143.60it/s]  4%|‚ñç         | 127/3257 [00:00<00:21, 148.04it/s]  4%|‚ñç         | 146/3257 [00:00<00:19, 159.48it/s]  5%|‚ñå         | 163/3257 [00:01<00:21, 146.57it/s]  5%|‚ñå         | 179/3257 [00:01<00:20, 147.88it/s]  6%|‚ñå         | 197/3257 [00:01<00:19, 154.30it/s]  7%|‚ñã         | 216/3257 [00:01<00:19, 159.76it/s]  7%|‚ñã         | 236/3257 [00:01<00:18, 167.63it/s]  8%|‚ñä         | 253/3257 [00:01<00:18, 163.19it/s]  8%|‚ñä         | 270/3257 [00:01<00:18, 160.14it/s]  9%|‚ñâ         | 293/3257 [00:01<00:16, 179.56it/s] 10%|‚ñâ         | 312/3257 [00:01<00:17, 172.69it/s] 10%|‚ñà         | 333/3257 [00:02<00:15, 182.87it/s] 11%|‚ñà         | 352/3257 [00:02<00:16, 179.75it/s] 11%|‚ñà‚ñè        | 373/3257 [00:02<00:15, 184.93it/s] 12%|‚ñà‚ñè        | 392/3257 [00:02<00:16, 169.18it/s] 13%|‚ñà‚ñé        | 410/3257 [00:02<00:21, 131.26it/s] 13%|‚ñà‚ñé        | 425/3257 [00:02<00:21, 131.31it/s] 14%|‚ñà‚ñé        | 440/3257 [00:02<00:21, 133.77it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:18, 147.58it/s] 15%|‚ñà‚ñç        | 479/3257 [00:03<00:17, 159.42it/s] 15%|‚ñà‚ñå        | 502/3257 [00:03<00:15, 177.61it/s] 16%|‚ñà‚ñå        | 522/3257 [00:03<00:14, 182.93it/s] 17%|‚ñà‚ñã        | 542/3257 [00:03<00:14, 186.38it/s] 17%|‚ñà‚ñã        | 561/3257 [00:03<00:15, 172.50it/s] 18%|‚ñà‚ñä        | 579/3257 [00:03<00:16, 162.04it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:15, 170.36it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:15, 167.93it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:03<00:14, 175.23it/s] 20%|‚ñà‚ñà        | 658/3257 [00:04<00:16, 157.83it/s] 21%|‚ñà‚ñà        | 677/3257 [00:04<00:15, 165.32it/s] 21%|‚ñà‚ñà‚ñè       | 694/3257 [00:04<00:15, 163.95it/s] 22%|‚ñà‚ñà‚ñè       | 713/3257 [00:04<00:14, 170.40it/s] 22%|‚ñà‚ñà‚ñè       | 731/3257 [00:04<00:15, 159.00it/s] 23%|‚ñà‚ñà‚ñé       | 748/3257 [00:04<00:15, 158.19it/s] 24%|‚ñà‚ñà‚ñé       | 768/3257 [00:04<00:14, 167.53it/s] 24%|‚ñà‚ñà‚ñç       | 785/3257 [00:04<00:15, 155.40it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:04<00:15, 160.08it/s] 25%|‚ñà‚ñà‚ñå       | 821/3257 [00:05<00:15, 156.76it/s] 26%|‚ñà‚ñà‚ñå       | 837/3257 [00:05<00:16, 149.57it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:05<00:16, 144.14it/s] 27%|‚ñà‚ñà‚ñã       | 870/3257 [00:05<00:15, 150.48it/s] 27%|‚ñà‚ñà‚ñã       | 886/3257 [00:05<00:16, 147.74it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:14, 158.56it/s] 28%|‚ñà‚ñà‚ñä       | 923/3257 [00:05<00:14, 162.94it/s] 29%|‚ñà‚ñà‚ñâ       | 940/3257 [00:05<00:14, 156.86it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:05<00:14, 162.12it/s] 30%|‚ñà‚ñà‚ñà       | 978/3257 [00:06<00:13, 168.59it/s] 31%|‚ñà‚ñà‚ñà       | 995/3257 [00:06<00:14, 156.10it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:06<00:14, 155.20it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:06<00:14, 150.89it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1043/3257 [00:06<00:14, 150.14it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1061/3257 [00:06<00:14, 155.09it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:14, 154.78it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1096/3257 [00:06<00:14, 151.27it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:07<00:14, 152.41it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1128/3257 [00:07<00:15, 138.48it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:07<00:15, 137.22it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1158/3257 [00:07<00:15, 138.05it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:07<00:14, 140.48it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:07<00:17, 120.93it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1201/3257 [00:07<00:17, 120.13it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1215/3257 [00:07<00:16, 124.36it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:07<00:14, 135.53it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:08<00:15, 133.36it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:08<00:14, 137.19it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1276/3257 [00:08<00:15, 130.85it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:08<00:15, 125.99it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1303/3257 [00:08<00:15, 125.89it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1318/3257 [00:08<00:14, 131.38it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1333/3257 [00:08<00:14, 135.50it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1349/3257 [00:08<00:13, 138.88it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1363/3257 [00:08<00:13, 135.54it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1377/3257 [00:09<00:14, 130.15it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1391/3257 [00:09<00:14, 128.77it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1407/3257 [00:09<00:13, 135.68it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:09<00:12, 141.57it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1438/3257 [00:09<00:12, 142.78it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1457/3257 [00:09<00:11, 155.53it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1473/3257 [00:09<00:11, 153.93it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1489/3257 [00:09<00:11, 152.28it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1507/3257 [00:09<00:11, 157.36it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1523/3257 [00:10<00:18, 93.67it/s]  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1537/3257 [00:10<00:16, 102.12it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1552/3257 [00:10<00:15, 112.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1569/3257 [00:10<00:13, 125.15it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1585/3257 [00:10<00:12, 131.33it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1604/3257 [00:10<00:11, 146.18it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1621/3257 [00:10<00:10, 149.36it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1637/3257 [00:10<00:11, 146.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1653/3257 [00:11<00:11, 145.15it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:11<00:11, 142.36it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1683/3257 [00:11<00:11, 141.05it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:11<00:10, 148.48it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1716/3257 [00:11<00:10, 146.77it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:11<00:10, 142.07it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1746/3257 [00:11<00:10, 142.50it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:11<00:10, 146.63it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:11<00:09, 148.43it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:12<00:09, 152.29it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1812/3257 [00:12<00:09, 146.14it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:12<00:09, 145.35it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:12<00:09, 153.16it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1865/3257 [00:12<00:08, 163.14it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1882/3257 [00:12<00:08, 165.04it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:12<00:08, 159.53it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:12<00:08, 161.36it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1936/3257 [00:12<00:07, 172.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1958/3257 [00:13<00:06, 185.79it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1977/3257 [00:13<00:07, 177.15it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1996/3257 [00:13<00:07, 178.06it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2014/3257 [00:13<00:07, 174.23it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2034/3257 [00:13<00:06, 177.34it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:13<00:07, 153.89it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2068/3257 [00:13<00:08, 141.64it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:13<00:08, 142.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2098/3257 [00:13<00:08, 136.98it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:14<00:07, 146.05it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:14<00:08, 132.94it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2146/3257 [00:14<00:08, 128.67it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:14<00:07, 139.02it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:14<00:07, 141.19it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2193/3257 [00:14<00:07, 143.45it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2208/3257 [00:14<00:07, 144.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2223/3257 [00:14<00:07, 144.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:14<00:07, 137.96it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2254/3257 [00:15<00:07, 143.12it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2269/3257 [00:15<00:07, 140.93it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2284/3257 [00:15<00:06, 141.97it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:15<00:06, 141.84it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2316/3257 [00:15<00:06, 148.31it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2336/3257 [00:15<00:05, 162.79it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2358/3257 [00:15<00:05, 178.77it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2376/3257 [00:15<00:05, 163.00it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2396/3257 [00:15<00:05, 172.13it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2414/3257 [00:16<00:05, 157.19it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2431/3257 [00:16<00:05, 147.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2447/3257 [00:16<00:05, 147.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2464/3257 [00:16<00:05, 151.92it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2480/3257 [00:16<00:05, 153.50it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2498/3257 [00:16<00:04, 158.13it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2519/3257 [00:16<00:04, 170.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:16<00:04, 178.40it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2558/3257 [00:16<00:03, 177.30it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2576/3257 [00:17<00:04, 168.62it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2593/3257 [00:17<00:03, 168.03it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2619/3257 [00:17<00:03, 194.10it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2640/3257 [00:17<00:03, 198.41it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2660/3257 [00:17<00:03, 183.97it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2681/3257 [00:17<00:03, 189.72it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2701/3257 [00:17<00:03, 167.40it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:17<00:03, 166.59it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2742/3257 [00:17<00:02, 181.39it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:18<00:02, 180.43it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2780/3257 [00:18<00:02, 179.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:18<00:02, 190.07it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:18<00:02, 181.84it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:18<00:02, 168.32it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2866/3257 [00:18<00:02, 186.47it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:18<00:01, 187.80it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:18<00:02, 172.99it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:19<00:01, 176.01it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2946/3257 [00:19<00:01, 170.48it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2965/3257 [00:19<00:01, 175.30it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2983/3257 [00:19<00:01, 163.97it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:19<00:01, 172.82it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3022/3257 [00:19<00:02, 87.24it/s]  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3041/3257 [00:20<00:02, 103.05it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3059/3257 [00:20<00:01, 117.00it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3078/3257 [00:20<00:01, 131.08it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3095/3257 [00:20<00:01, 133.67it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3114/3257 [00:20<00:00, 146.72it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3131/3257 [00:20<00:00, 146.30it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3147/3257 [00:20<00:00, 142.54it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3163/3257 [00:20<00:00, 146.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3179/3257 [00:20<00:00, 137.62it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3197/3257 [00:21<00:00, 148.07it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:21<00:00, 141.60it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3231/3257 [00:21<00:00, 150.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3250/3257 [00:21<00:00, 160.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 152.04it/s]
2023-02-07 19:27:08.428 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:27:08,430][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d323,n5,mc7,s0.505108,t4>', 'datetime': '2023-02-07T19:27:08.429969', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:27:08,430][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:27:08,430][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:27:09,059][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 19:27:09,060][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:27:09,123][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 23400 unique words (43.29% of original 54054, drops 30654)', 'datetime': '2023-02-07T19:27:09.123186', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:27:09,124][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 6462689 word corpus (98.65% of original 6550866, drops 88177)', 'datetime': '2023-02-07T19:27:09.124114', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:27:09,196][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 19:27:09,197][gensim.models.word2vec][INFO] - sample=0.505108 downsamples 0 most-common words
[2023-02-07 19:27:09,197][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6462689 word corpus (100.0%% of prior 6462689)', 'datetime': '2023-02-07T19:27:09.197280', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:27:09,326][gensim.models.word2vec][INFO] - estimated required memory for 23400 words and 323 dimensions: 77025044 bytes
[2023-02-07 19:27:09,327][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:27:09,359][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 23400 vocabulary and 323 features, using sg=1 hs=0 sample=0.5051081261868333 negative=5 window=20 shrink_windows=True', 'datetime': '2023-02-07T19:27:09.359419', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:27:10,362][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 36.17% examples, 2350147 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:11,369][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 70.43% examples, 2296671 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:12,195][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6408417 effective words) took 2.8s, 2261046 effective words/s
[2023-02-07 19:27:13,200][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 32.91% examples, 2131330 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:14,208][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 64.60% examples, 2096764 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:15,210][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 98.34% examples, 2094945 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:27:15,242][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6408417 effective words) took 3.0s, 2104800 effective words/s
[2023-02-07 19:27:16,248][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 42.22% examples, 2767098 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:17,250][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 81.46% examples, 2622636 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:17,708][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6408417 effective words) took 2.5s, 2600140 effective words/s
[2023-02-07 19:27:18,711][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 35.00% examples, 2268901 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:27:19,717][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 68.19% examples, 2219541 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:27:20,602][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6408417 effective words) took 2.9s, 2214974 effective words/s
[2023-02-07 19:27:21,606][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 38.38% examples, 2511930 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:22,609][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 83.33% examples, 2692057 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:22,998][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6408417 effective words) took 2.4s, 2677022 effective words/s
[2023-02-07 19:27:24,003][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 38.72% examples, 2525175 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:27:25,005][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 78.23% examples, 2522842 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:25,555][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6408417 effective words) took 2.6s, 2508018 effective words/s
[2023-02-07 19:27:26,557][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.81% examples, 2537711 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:27,558][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 77.37% examples, 2502539 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:28,119][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6408417 effective words) took 2.6s, 2500970 effective words/s
[2023-02-07 19:27:29,126][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 37.55% examples, 2450472 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:30,129][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 76.30% examples, 2468246 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:30,700][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6408417 effective words) took 2.6s, 2483460 effective words/s
[2023-02-07 19:27:31,707][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 38.62% examples, 2518515 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:32,711][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 78.54% examples, 2529952 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:33,233][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6408417 effective words) took 2.5s, 2531854 effective words/s
[2023-02-07 19:27:34,238][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 39.12% examples, 2550368 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:35,239][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 79.37% examples, 2567034 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:35,718][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6408417 effective words) took 2.5s, 2580031 effective words/s
[2023-02-07 19:27:36,727][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 38.19% examples, 2481058 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:37,730][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 72.64% examples, 2351061 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:38,484][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6408417 effective words) took 2.8s, 2318648 effective words/s
[2023-02-07 19:27:39,489][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 34.82% examples, 2252821 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:40,490][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 68.71% examples, 2244113 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:41,346][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6408417 effective words) took 2.9s, 2240222 effective words/s
[2023-02-07 19:27:42,349][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 33.74% examples, 2187195 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:43,355][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 67.09% examples, 2187860 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:44,257][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6408417 effective words) took 2.9s, 2202956 effective words/s
[2023-02-07 19:27:45,265][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 37.55% examples, 2451023 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:46,268][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 82.32% examples, 2647938 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:46,699][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6408417 effective words) took 2.4s, 2627175 effective words/s
[2023-02-07 19:27:47,704][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 37.18% examples, 2429873 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:27:48,708][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 74.33% examples, 2405159 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:27:49,359][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6408417 effective words) took 2.7s, 2410234 effective words/s
[2023-02-07 19:27:49,360][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (96126255 effective words) took 40.0s, 2403157 effective words/s', 'datetime': '2023-02-07T19:27:49.360327', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:27:49.360 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:27:52,877][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192638-u1iss2qe/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:27:52.877399', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:27:52,878][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:27:52,973][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192638-u1iss2qe/files/../tmp/embedding_model.pt
2023-02-07 19:27:52.974 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:27:54.954 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:27:55.616 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:27:57.704 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0452320674840052, 'test_mae': 0.7931082139443035, 'test_r2': -3.059306409284466}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.014 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: | 0.014 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.94
wandb: percentage 0.5671
wandb:   test_mae 0.79311
wandb:   test_mse 1.04523
wandb:    test_r2 -3.05931
wandb: 
wandb: üöÄ View run colorful-sweep-43 at: https://wandb.ai/xiaoqiz/mof2vec/runs/u1iss2qe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_192638-u1iss2qe/logs
wandb: Agent Starting Run: u4qr7lxa with config:
wandb: 	data.data.wl_step: 3
wandb: 	data.nn.batch_size: 558
wandb: 	model.gensim.alpha: 0.003357676046931892
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.583488090058567
wandb: 	model.gensim.vector_size: 121
wandb: 	model.gensim.window: 18
wandb: 	model.sklearn.learning_rate: 0.00041140443612330336
wandb: 	model.sklearn.max_depth: 90
wandb: 	model.sklearn.min_child_weight: 0.05508550066879806
wandb: 	model.sklearn.n_estimators: 4485
wandb: 	model.sklearn.num_leaves: 144
wandb: 	model.sklearn.reg_alpha: 0.006568158330008708
wandb: 	model.sklearn.reg_lambda: 0.017508092475739902
wandb: 	model.sklearn.subsample: 0.6277514228883759
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192806-u4qr7lxa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-44
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/u4qr7lxa
2023-02-07 19:28:14.270 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 3 for sweep.
2023-02-07 19:28:14.270 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 558 for sweep.
2023-02-07 19:28:14.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.003357676046931892 for sweep.
2023-02-07 19:28:14.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:28:14.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 19:28:14.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.583488090058567 for sweep.
2023-02-07 19:28:14.272 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 121 for sweep.
2023-02-07 19:28:14.272 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 18 for sweep.
2023-02-07 19:28:14.272 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.00041140443612330336 for sweep.
2023-02-07 19:28:14.272 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 90 for sweep.
2023-02-07 19:28:14.273 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05508550066879806 for sweep.
2023-02-07 19:28:14.273 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4485 for sweep.
2023-02-07 19:28:14.273 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 144 for sweep.
2023-02-07 19:28:14.274 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.006568158330008708 for sweep.
2023-02-07 19:28:14.274 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.017508092475739902 for sweep.
2023-02-07 19:28:14.274 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6277514228883759 for sweep.
2023-02-07 19:28:14.274 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:28:14.279 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 3}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192806-u4qr7lxa/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 558, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 121, 'window': 18, 'min_count': 7, 'dm': 0, 'sample': 0.583488090058567, 'workers': 4, 'alpha': 0.003357676046931892, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4485, 'max_depth': 90, 'num_leaves': 144, 'reg_alpha': 0.006568158330008708, 'reg_lambda': 0.017508092475739902, 'subsample': 0.6277514228883759, 'min_child_weight': 0.05508550066879806, 'n_jobs': 4, 'learning_rate': 0.00041140443612330336}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 28/3257 [00:00<00:11, 276.83it/s]  2%|‚ñè         | 56/3257 [00:00<00:12, 261.62it/s]  3%|‚ñé         | 90/3257 [00:00<00:11, 284.68it/s]  4%|‚ñé         | 119/3257 [00:00<00:11, 277.65it/s]  5%|‚ñç         | 151/3257 [00:00<00:10, 287.28it/s]  6%|‚ñå         | 180/3257 [00:00<00:11, 279.18it/s]  7%|‚ñã         | 212/3257 [00:00<00:10, 290.96it/s]  8%|‚ñä         | 245/3257 [00:00<00:09, 302.05it/s]  9%|‚ñä         | 277/3257 [00:00<00:09, 306.92it/s]  9%|‚ñâ         | 309/3257 [00:01<00:09, 310.23it/s] 10%|‚ñà         | 341/3257 [00:01<00:09, 305.03it/s] 11%|‚ñà‚ñè        | 374/3257 [00:01<00:09, 311.09it/s] 12%|‚ñà‚ñè        | 406/3257 [00:01<00:09, 297.60it/s] 13%|‚ñà‚ñé        | 436/3257 [00:01<00:10, 272.56it/s] 14%|‚ñà‚ñç        | 469/3257 [00:01<00:09, 287.46it/s] 15%|‚ñà‚ñå        | 500/3257 [00:01<00:09, 291.73it/s] 16%|‚ñà‚ñã        | 531/3257 [00:01<00:09, 293.81it/s] 17%|‚ñà‚ñã        | 561/3257 [00:01<00:09, 277.95it/s] 18%|‚ñà‚ñä        | 590/3257 [00:02<00:09, 270.07it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:02<00:09, 275.76it/s] 20%|‚ñà‚ñâ        | 649/3257 [00:02<00:09, 279.39it/s] 21%|‚ñà‚ñà        | 678/3257 [00:02<00:09, 278.96it/s] 22%|‚ñà‚ñà‚ñè       | 707/3257 [00:02<00:09, 277.19it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:02<00:09, 276.85it/s] 23%|‚ñà‚ñà‚ñé       | 763/3257 [00:02<00:09, 274.32it/s] 24%|‚ñà‚ñà‚ñç       | 791/3257 [00:02<00:09, 270.36it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:02<00:08, 273.25it/s] 26%|‚ñà‚ñà‚ñå       | 848/3257 [00:03<00:09, 255.39it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:03<00:09, 257.61it/s] 28%|‚ñà‚ñà‚ñä       | 903/3257 [00:03<00:08, 263.06it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:03<00:08, 265.00it/s] 30%|‚ñà‚ñà‚ñâ       | 962/3257 [00:03<00:08, 277.73it/s] 30%|‚ñà‚ñà‚ñà       | 990/3257 [00:03<00:08, 276.55it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1020/3257 [00:03<00:07, 281.68it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1049/3257 [00:03<00:12, 170.49it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1073/3257 [00:04<00:11, 183.69it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1096/3257 [00:04<00:11, 189.76it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1119/3257 [00:04<00:10, 195.28it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1141/3257 [00:04<00:10, 201.20it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1167/3257 [00:04<00:09, 216.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:04<00:10, 202.35it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1213/3257 [00:04<00:10, 203.99it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:04<00:09, 222.50it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1265/3257 [00:04<00:08, 224.48it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:05<00:09, 209.29it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1310/3257 [00:05<00:09, 211.41it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1337/3257 [00:05<00:08, 227.37it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1361/3257 [00:05<00:08, 224.96it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1384/3257 [00:05<00:08, 218.41it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1410/3257 [00:05<00:08, 229.06it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1437/3257 [00:05<00:07, 239.30it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1464/3257 [00:05<00:07, 247.47it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1489/3257 [00:05<00:07, 244.44it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1516/3257 [00:05<00:06, 250.37it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1542/3257 [00:06<00:07, 232.16it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1566/3257 [00:06<00:07, 229.04it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1590/3257 [00:06<00:07, 231.32it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:06<00:06, 235.21it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:06<00:07, 226.92it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:06<00:07, 218.03it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1684/3257 [00:06<00:07, 215.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:06<00:06, 221.92it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:06<00:07, 215.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1754/3257 [00:07<00:06, 218.17it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:07<00:06, 226.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1804/3257 [00:07<00:06, 232.67it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:07<00:06, 222.51it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1853/3257 [00:07<00:06, 230.08it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:07<00:05, 237.90it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1903/3257 [00:07<00:05, 235.94it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1927/3257 [00:07<00:05, 234.54it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1957/3257 [00:07<00:05, 253.36it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1983/3257 [00:08<00:05, 244.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2009/3257 [00:08<00:05, 248.28it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:08<00:04, 250.08it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2061/3257 [00:08<00:05, 226.86it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:08<00:05, 229.88it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2109/3257 [00:08<00:04, 231.90it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2133/3257 [00:08<00:05, 221.59it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2156/3257 [00:08<00:05, 220.00it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:08<00:04, 226.10it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2206/3257 [00:09<00:04, 227.67it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2229/3257 [00:09<00:04, 227.40it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2252/3257 [00:09<00:04, 225.05it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:09<00:04, 215.11it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:09<00:04, 224.26it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2330/3257 [00:09<00:03, 241.24it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:09<00:03, 249.30it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2386/3257 [00:09<00:03, 251.69it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2412/3257 [00:10<00:05, 144.42it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2433/3257 [00:10<00:05, 156.27it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2457/3257 [00:10<00:04, 173.46it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2482/3257 [00:10<00:04, 190.75it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2511/3257 [00:10<00:03, 214.86it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2539/3257 [00:10<00:03, 229.67it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2565/3257 [00:10<00:03, 225.87it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2590/3257 [00:10<00:03, 217.81it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2620/3257 [00:10<00:02, 237.80it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2645/3257 [00:11<00:02, 237.58it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2670/3257 [00:11<00:02, 237.19it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2695/3257 [00:11<00:02, 232.87it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:11<00:02, 221.45it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2747/3257 [00:11<00:02, 235.23it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2771/3257 [00:11<00:02, 230.68it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2799/3257 [00:11<00:01, 242.23it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2824/3257 [00:11<00:01, 229.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2851/3257 [00:11<00:01, 238.19it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2887/3257 [00:12<00:01, 271.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2915/3257 [00:12<00:01, 271.02it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2943/3257 [00:12<00:01, 268.47it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2974/3257 [00:12<00:01, 278.08it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3003/3257 [00:12<00:00, 278.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3034/3257 [00:12<00:00, 287.45it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3068/3257 [00:12<00:00, 301.73it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3099/3257 [00:12<00:00, 303.93it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3132/3257 [00:12<00:00, 310.81it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3164/3257 [00:12<00:00, 302.74it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3195/3257 [00:13<00:00, 302.07it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3226/3257 [00:13<00:00, 291.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:13<00:00, 297.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:13<00:00, 244.57it/s]
2023-02-07 19:28:27.956 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:28:27,957][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d121,n5,mc7,s0.583488,t4>', 'datetime': '2023-02-07T19:28:27.957842', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:28:27,958][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:28:27,958][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:28:28,234][gensim.models.doc2vec][INFO] - collected 6662 word types and 3257 unique tags from a corpus of 3257 examples and 2911496 words
[2023-02-07 19:28:28,234][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:28:28,243][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 3228 unique words (48.45% of original 6662, drops 3434)', 'datetime': '2023-02-07T19:28:28.243760', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:28:28,244][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 2901608 word corpus (99.66% of original 2911496, drops 9888)', 'datetime': '2023-02-07T19:28:28.244077', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:28:28,254][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 6662 items
[2023-02-07 19:28:28,255][gensim.models.word2vec][INFO] - sample=0.583488 downsamples 0 most-common words
[2023-02-07 19:28:28,255][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2901608 word corpus (100.0%% of prior 2901608)', 'datetime': '2023-02-07T19:28:28.255423', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:28:28,274][gensim.models.word2vec][INFO] - estimated required memory for 3228 words and 121 dimensions: 6966492 bytes
[2023-02-07 19:28:28,274][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:28:28,277][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 3228 vocabulary and 121 features, using sg=1 hs=0 sample=0.583488090058567 negative=5 window=18 shrink_windows=True', 'datetime': '2023-02-07T19:28:28.277660', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:28:29,281][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 90.94% examples, 2659638 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:28:29,366][gensim.models.word2vec][INFO] - EPOCH 0: training on 2911496 raw words (2904865 effective words) took 1.1s, 2674375 effective words/s
[2023-02-07 19:28:30,351][gensim.models.word2vec][INFO] - EPOCH 1: training on 2911496 raw words (2904865 effective words) took 1.0s, 2954914 effective words/s
[2023-02-07 19:28:31,327][gensim.models.word2vec][INFO] - EPOCH 2: training on 2911496 raw words (2904865 effective words) took 1.0s, 2982012 effective words/s
[2023-02-07 19:28:32,298][gensim.models.word2vec][INFO] - EPOCH 3: training on 2911496 raw words (2904865 effective words) took 1.0s, 2994787 effective words/s
[2023-02-07 19:28:33,267][gensim.models.word2vec][INFO] - EPOCH 4: training on 2911496 raw words (2904865 effective words) took 1.0s, 3001239 effective words/s
[2023-02-07 19:28:34,248][gensim.models.word2vec][INFO] - EPOCH 5: training on 2911496 raw words (2904865 effective words) took 1.0s, 2966880 effective words/s
[2023-02-07 19:28:35,216][gensim.models.word2vec][INFO] - EPOCH 6: training on 2911496 raw words (2904865 effective words) took 1.0s, 3003463 effective words/s
[2023-02-07 19:28:36,174][gensim.models.word2vec][INFO] - EPOCH 7: training on 2911496 raw words (2904865 effective words) took 1.0s, 3037092 effective words/s
[2023-02-07 19:28:37,113][gensim.models.word2vec][INFO] - EPOCH 8: training on 2911496 raw words (2904865 effective words) took 0.9s, 3098552 effective words/s
[2023-02-07 19:28:38,117][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 96.47% examples, 2796843 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:28:38,149][gensim.models.word2vec][INFO] - EPOCH 9: training on 2911496 raw words (2904865 effective words) took 1.0s, 2807203 effective words/s
[2023-02-07 19:28:39,154][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 95.46% examples, 2768145 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:28:39,196][gensim.models.word2vec][INFO] - EPOCH 10: training on 2911496 raw words (2904865 effective words) took 1.0s, 2778424 effective words/s
[2023-02-07 19:28:40,203][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 95.03% examples, 2757161 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:28:40,248][gensim.models.word2vec][INFO] - EPOCH 11: training on 2911496 raw words (2904865 effective words) took 1.0s, 2768737 effective words/s
[2023-02-07 19:28:41,250][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 95.46% examples, 2776316 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:28:41,290][gensim.models.word2vec][INFO] - EPOCH 12: training on 2911496 raw words (2904865 effective words) took 1.0s, 2792113 effective words/s
[2023-02-07 19:28:42,293][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 96.16% examples, 2795314 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:28:42,329][gensim.models.word2vec][INFO] - EPOCH 13: training on 2911496 raw words (2904865 effective words) took 1.0s, 2804140 effective words/s
[2023-02-07 19:28:43,333][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 96.71% examples, 2806768 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:28:43,362][gensim.models.word2vec][INFO] - EPOCH 14: training on 2911496 raw words (2904865 effective words) took 1.0s, 2816342 effective words/s
[2023-02-07 19:28:43,362][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 43672440 raw words (43572975 effective words) took 15.1s, 2888730 effective words/s', 'datetime': '2023-02-07T19:28:43.362772', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:28:43.363 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:28:44,732][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192806-u4qr7lxa/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:28:44.732613', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:28:44,734][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:28:44,751][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192806-u4qr7lxa/files/../tmp/embedding_model.pt
2023-02-07 19:28:44.752 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:28:45.986 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:28:46.389 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:28:47.236 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.988711876909379, 'test_mae': 0.76323162855729, 'test_r2': -2.182434544783906}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.62
wandb: percentage 0.51546
wandb:   test_mae 0.76323
wandb:   test_mse 0.98871
wandb:    test_r2 -2.18243
wandb: 
wandb: üöÄ View run hardy-sweep-44 at: https://wandb.ai/xiaoqiz/mof2vec/runs/u4qr7lxa
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_192806-u4qr7lxa/logs
wandb: Agent Starting Run: mtu8xv1a with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 325
wandb: 	model.gensim.alpha: 0.044663843682422065
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.7068086749711868
wandb: 	model.gensim.vector_size: 353
wandb: 	model.gensim.window: 12
wandb: 	model.sklearn.learning_rate: 0.7800534314525686
wandb: 	model.sklearn.max_depth: 90
wandb: 	model.sklearn.min_child_weight: 0.027094313645382204
wandb: 	model.sklearn.n_estimators: 2037
wandb: 	model.sklearn.num_leaves: 33
wandb: 	model.sklearn.reg_alpha: 0.003780032796311232
wandb: 	model.sklearn.reg_lambda: 0.45892664714348463
wandb: 	model.sklearn.subsample: 0.2874656703812301
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192859-mtu8xv1a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-45
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/mtu8xv1a
2023-02-07 19:29:07.791 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:29:07.792 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 325 for sweep.
2023-02-07 19:29:07.792 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.044663843682422065 for sweep.
2023-02-07 19:29:07.792 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:29:07.792 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 19:29:07.793 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7068086749711868 for sweep.
2023-02-07 19:29:07.793 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 353 for sweep.
2023-02-07 19:29:07.793 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 12 for sweep.
2023-02-07 19:29:07.793 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.7800534314525686 for sweep.
2023-02-07 19:29:07.793 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 90 for sweep.
2023-02-07 19:29:07.794 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.027094313645382204 for sweep.
2023-02-07 19:29:07.794 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2037 for sweep.
2023-02-07 19:29:07.794 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 33 for sweep.
2023-02-07 19:29:07.794 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.003780032796311232 for sweep.
2023-02-07 19:29:07.795 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.45892664714348463 for sweep.
2023-02-07 19:29:07.795 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2874656703812301 for sweep.
2023-02-07 19:29:07.795 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:29:07.801 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192859-mtu8xv1a/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 325, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 353, 'window': 12, 'min_count': 9, 'dm': 0, 'sample': 0.7068086749711868, 'workers': 4, 'alpha': 0.044663843682422065, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2037, 'max_depth': 90, 'num_leaves': 33, 'reg_alpha': 0.003780032796311232, 'reg_lambda': 0.45892664714348463, 'subsample': 0.2874656703812301, 'min_child_weight': 0.027094313645382204, 'n_jobs': 4, 'learning_rate': 0.7800534314525686}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:19, 169.62it/s]  1%|          | 39/3257 [00:00<00:16, 190.49it/s]  2%|‚ñè         | 59/3257 [00:00<00:17, 182.91it/s]  3%|‚ñé         | 82/3257 [00:00<00:16, 197.50it/s]  3%|‚ñé         | 102/3257 [00:00<00:16, 195.46it/s]  4%|‚ñé         | 122/3257 [00:00<00:17, 181.59it/s]  4%|‚ñç         | 146/3257 [00:00<00:15, 197.37it/s]  5%|‚ñå         | 166/3257 [00:00<00:16, 188.95it/s]  6%|‚ñå         | 188/3257 [00:00<00:15, 197.08it/s]  6%|‚ñã         | 211/3257 [00:01<00:14, 204.10it/s]  7%|‚ñã         | 236/3257 [00:01<00:14, 214.01it/s]  8%|‚ñä         | 258/3257 [00:01<00:14, 208.49it/s]  9%|‚ñä         | 282/3257 [00:01<00:13, 217.38it/s]  9%|‚ñâ         | 304/3257 [00:01<00:14, 210.18it/s] 10%|‚ñà         | 328/3257 [00:01<00:13, 216.43it/s] 11%|‚ñà         | 350/3257 [00:01<00:13, 208.92it/s] 11%|‚ñà‚ñè        | 373/3257 [00:01<00:13, 213.58it/s] 12%|‚ñà‚ñè        | 395/3257 [00:01<00:14, 198.73it/s] 13%|‚ñà‚ñé        | 419/3257 [00:02<00:13, 208.17it/s] 14%|‚ñà‚ñé        | 441/3257 [00:02<00:15, 181.26it/s] 14%|‚ñà‚ñç        | 461/3257 [00:02<00:20, 133.66it/s] 15%|‚ñà‚ñç        | 480/3257 [00:02<00:19, 143.12it/s] 15%|‚ñà‚ñå        | 504/3257 [00:02<00:16, 162.55it/s] 16%|‚ñà‚ñå        | 524/3257 [00:02<00:16, 170.58it/s] 17%|‚ñà‚ñã        | 546/3257 [00:02<00:15, 176.02it/s] 17%|‚ñà‚ñã        | 565/3257 [00:03<00:15, 172.58it/s] 18%|‚ñà‚ñä        | 583/3257 [00:03<00:15, 171.75it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:14, 179.25it/s] 19%|‚ñà‚ñâ        | 624/3257 [00:03<00:14, 184.63it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:13, 187.31it/s] 20%|‚ñà‚ñà        | 664/3257 [00:03<00:14, 180.64it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:14, 183.22it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:03<00:13, 189.42it/s] 22%|‚ñà‚ñà‚ñè       | 724/3257 [00:03<00:13, 186.80it/s] 23%|‚ñà‚ñà‚ñé       | 743/3257 [00:03<00:13, 184.39it/s] 23%|‚ñà‚ñà‚ñé       | 765/3257 [00:04<00:12, 193.87it/s] 24%|‚ñà‚ñà‚ñç       | 785/3257 [00:04<00:13, 186.75it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:12, 189.66it/s] 25%|‚ñà‚ñà‚ñå       | 826/3257 [00:04<00:12, 187.62it/s] 26%|‚ñà‚ñà‚ñå       | 845/3257 [00:04<00:13, 179.21it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:04<00:12, 184.98it/s] 27%|‚ñà‚ñà‚ñã       | 885/3257 [00:04<00:13, 179.67it/s] 28%|‚ñà‚ñà‚ñä       | 909/3257 [00:04<00:12, 194.93it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:04<00:11, 200.59it/s] 29%|‚ñà‚ñà‚ñâ       | 953/3257 [00:05<00:11, 205.62it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:05<00:11, 206.13it/s] 31%|‚ñà‚ñà‚ñà       | 995/3257 [00:05<00:12, 185.70it/s] 31%|‚ñà‚ñà‚ñà       | 1014/3257 [00:05<00:12, 179.39it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1033/3257 [00:05<00:13, 168.72it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:05<00:13, 163.34it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1071/3257 [00:05<00:12, 170.71it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1089/3257 [00:05<00:12, 168.42it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1106/3257 [00:05<00:12, 167.78it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:06<00:13, 161.42it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1140/3257 [00:06<00:13, 158.31it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1158/3257 [00:06<00:12, 162.69it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:06<00:12, 162.38it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1192/3257 [00:06<00:13, 151.06it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1208/3257 [00:06<00:13, 148.22it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1228/3257 [00:06<00:12, 162.06it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:06<00:12, 160.51it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1263/3257 [00:06<00:12, 164.75it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1280/3257 [00:07<00:12, 153.90it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1296/3257 [00:07<00:12, 150.85it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:07<00:12, 154.17it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1331/3257 [00:07<00:12, 160.45it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:07<00:11, 162.11it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1367/3257 [00:07<00:11, 162.35it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1384/3257 [00:07<00:11, 157.84it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:07<00:11, 162.89it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:07<00:10, 173.23it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1441/3257 [00:08<00:10, 172.86it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1464/3257 [00:08<00:09, 188.27it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1483/3257 [00:08<00:09, 187.27it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1504/3257 [00:08<00:09, 191.22it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1524/3257 [00:08<00:09, 175.92it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1542/3257 [00:08<00:10, 169.43it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1560/3257 [00:08<00:10, 162.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1577/3257 [00:08<00:10, 160.22it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:08<00:09, 167.31it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1616/3257 [00:09<00:09, 173.19it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:09<00:09, 163.63it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1651/3257 [00:09<00:10, 156.18it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1667/3257 [00:09<00:10, 154.23it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1683/3257 [00:09<00:10, 153.00it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1701/3257 [00:09<00:09, 158.24it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1719/3257 [00:09<00:09, 162.77it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1736/3257 [00:09<00:10, 149.50it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1752/3257 [00:10<00:16, 90.76it/s]  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:10<00:13, 108.17it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:10<00:11, 125.14it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1806/3257 [00:10<00:11, 130.87it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1825/3257 [00:10<00:09, 143.23it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1842/3257 [00:10<00:09, 150.07it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1859/3257 [00:10<00:09, 152.47it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:10<00:08, 164.88it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:11<00:08, 164.26it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:11<00:07, 169.67it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1936/3257 [00:11<00:07, 177.44it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1959/3257 [00:11<00:06, 192.26it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1979/3257 [00:11<00:07, 182.09it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1998/3257 [00:11<00:06, 184.18it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2017/3257 [00:11<00:06, 180.21it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2036/3257 [00:11<00:06, 182.31it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:11<00:07, 167.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2073/3257 [00:12<00:07, 167.21it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:12<00:06, 169.18it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2109/3257 [00:12<00:06, 166.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2126/3257 [00:12<00:07, 158.02it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:12<00:07, 154.41it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2162/3257 [00:12<00:06, 162.98it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:12<00:06, 167.32it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2201/3257 [00:12<00:06, 175.63it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:12<00:06, 167.93it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:13<00:06, 168.47it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2254/3257 [00:13<00:06, 165.96it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2271/3257 [00:13<00:06, 158.51it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2291/3257 [00:13<00:05, 169.16it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2310/3257 [00:13<00:05, 174.72it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2338/3257 [00:13<00:04, 204.57it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2365/3257 [00:13<00:04, 222.92it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2391/3257 [00:13<00:03, 232.80it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2415/3257 [00:13<00:03, 221.57it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2438/3257 [00:14<00:03, 213.80it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2461/3257 [00:14<00:03, 218.25it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2485/3257 [00:14<00:03, 221.14it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:14<00:03, 237.53it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:14<00:03, 238.50it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2564/3257 [00:14<00:03, 230.13it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2588/3257 [00:14<00:03, 211.94it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2616/3257 [00:14<00:02, 229.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2641/3257 [00:14<00:02, 232.66it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2665/3257 [00:15<00:02, 218.68it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2689/3257 [00:15<00:02, 223.40it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2712/3257 [00:15<00:02, 198.44it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2735/3257 [00:15<00:02, 205.64it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2760/3257 [00:15<00:02, 216.97it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2783/3257 [00:15<00:02, 212.23it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:15<00:02, 215.08it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2829/3257 [00:15<00:02, 202.59it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2852/3257 [00:15<00:01, 209.00it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2881/3257 [00:16<00:01, 228.59it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2905/3257 [00:16<00:01, 208.49it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:16<00:01, 213.40it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:16<00:01, 199.99it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2974/3257 [00:16<00:01, 207.73it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2996/3257 [00:16<00:01, 202.53it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:16<00:01, 206.53it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3045/3257 [00:16<00:00, 223.26it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3070/3257 [00:16<00:00, 230.63it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3094/3257 [00:17<00:00, 224.85it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3119/3257 [00:17<00:00, 231.34it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3143/3257 [00:17<00:00, 119.25it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3164/3257 [00:17<00:00, 134.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:17<00:00, 143.66it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3205/3257 [00:17<00:00, 159.47it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3225/3257 [00:17<00:00, 163.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3250/3257 [00:18<00:00, 184.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 179.67it/s]
2023-02-07 19:29:26.572 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:29:26,573][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d353,n5,mc9,s0.706809,t4>', 'datetime': '2023-02-07T19:29:26.573921', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:29:26,574][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:29:26,574][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:29:27,037][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:29:27,037][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:29:27,074][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 11387 unique words (35.80% of original 31803, drops 20416)', 'datetime': '2023-02-07T19:29:27.074106', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:29:27,074][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 5023141 word corpus (98.59% of original 5095118, drops 71977)', 'datetime': '2023-02-07T19:29:27.074443', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:29:27,113][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:29:27,114][gensim.models.word2vec][INFO] - sample=0.706809 downsamples 0 most-common words
[2023-02-07 19:29:27,114][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5023141 word corpus (100.0%% of prior 5023141)', 'datetime': '2023-02-07T19:29:27.114877', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:29:27,180][gensim.models.word2vec][INFO] - estimated required memory for 11387 words and 353 dimensions: 43100672 bytes
[2023-02-07 19:29:27,181][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:29:27,203][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11387 vocabulary and 353 features, using sg=1 hs=0 sample=0.7068086749711868 negative=5 window=12 shrink_windows=True', 'datetime': '2023-02-07T19:29:27.203130', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:29:28,205][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 42.09% examples, 2174737 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:29,208][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 86.21% examples, 2174483 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:29,500][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5015324 effective words) took 2.3s, 2185472 effective words/s
[2023-02-07 19:29:30,501][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 47.37% examples, 2423482 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:31,505][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 89.93% examples, 2265204 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:31,728][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5015324 effective words) took 2.2s, 2251629 effective words/s
[2023-02-07 19:29:32,730][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 41.23% examples, 2121850 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:29:33,735][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 84.28% examples, 2127516 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:34,082][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5015324 effective words) took 2.4s, 2131855 effective words/s
[2023-02-07 19:29:35,084][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 42.40% examples, 2193555 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:36,085][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 86.40% examples, 2182204 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:36,386][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5015324 effective words) took 2.3s, 2179191 effective words/s
[2023-02-07 19:29:37,389][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 42.55% examples, 2200976 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:38,394][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 86.67% examples, 2183696 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:38,678][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5015324 effective words) took 2.3s, 2190166 effective words/s
[2023-02-07 19:29:39,682][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 49.25% examples, 2515263 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:40,648][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5015324 effective words) took 2.0s, 2548066 effective words/s
[2023-02-07 19:29:41,650][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 48.30% examples, 2472152 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:42,655][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 97.88% examples, 2452468 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:42,691][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5015324 effective words) took 2.0s, 2457513 effective words/s
[2023-02-07 19:29:43,694][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 47.22% examples, 2413865 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:29:44,694][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 96.59% examples, 2423357 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:44,754][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5015324 effective words) took 2.1s, 2432353 effective words/s
[2023-02-07 19:29:45,762][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 48.36% examples, 2463931 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:46,764][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 99.48% examples, 2482600 words/s, in_qsize 3, out_qsize 1
[2023-02-07 19:29:46,770][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5015324 effective words) took 2.0s, 2489027 effective words/s
[2023-02-07 19:29:47,778][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 48.57% examples, 2475890 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:48,780][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 96.19% examples, 2403656 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:48,858][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5015324 effective words) took 2.1s, 2403245 effective words/s
[2023-02-07 19:29:49,864][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 42.40% examples, 2183887 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:50,866][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 86.67% examples, 2185003 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:51,156][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5015324 effective words) took 2.3s, 2184624 effective words/s
[2023-02-07 19:29:52,164][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 42.40% examples, 2180409 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:53,167][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 86.77% examples, 2185770 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:53,453][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5015324 effective words) took 2.3s, 2185257 effective words/s
[2023-02-07 19:29:54,455][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 42.28% examples, 2183066 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:55,458][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 85.82% examples, 2165471 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:55,764][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5015324 effective words) took 2.3s, 2171544 effective words/s
[2023-02-07 19:29:56,769][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 42.55% examples, 2198042 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:57,770][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 97.88% examples, 2453695 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:57,803][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5015324 effective words) took 2.0s, 2462324 effective words/s
[2023-02-07 19:29:58,806][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 53.18% examples, 2729843 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:29:59,683][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5015324 effective words) took 1.9s, 2668693 effective words/s
[2023-02-07 19:29:59,684][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75229860 effective words) took 32.5s, 2316142 effective words/s', 'datetime': '2023-02-07T19:29:59.684234', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:29:59.684 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:30:02,132][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192859-mtu8xv1a/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:30:02.131976', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:30:02,132][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:30:02,232][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_192859-mtu8xv1a/files/../tmp/embedding_model.pt
2023-02-07 19:30:02.232 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:30:04.226 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:30:04.927 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:30:07.281 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9929354274354216, 'test_mae': 0.7566683614637955, 'test_r2': -2.656076560355511}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.93
wandb: percentage 0.64195
wandb:   test_mae 0.75667
wandb:   test_mse 0.99294
wandb:    test_r2 -2.65608
wandb: 
wandb: üöÄ View run peach-sweep-45 at: https://wandb.ai/xiaoqiz/mof2vec/runs/mtu8xv1a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_192859-mtu8xv1a/logs
wandb: Agent Starting Run: 26v9tnpw with config:
wandb: 	data.data.wl_step: 1
wandb: 	data.nn.batch_size: 90
wandb: 	model.gensim.alpha: 0.0006569017251415229
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.9393164040860212
wandb: 	model.gensim.vector_size: 239
wandb: 	model.gensim.window: 7
wandb: 	model.sklearn.learning_rate: 0.002328756457575758
wandb: 	model.sklearn.max_depth: 22
wandb: 	model.sklearn.min_child_weight: 0.023120175740486568
wandb: 	model.sklearn.n_estimators: 1899
wandb: 	model.sklearn.num_leaves: 232
wandb: 	model.sklearn.reg_alpha: 0.7271354025551086
wandb: 	model.sklearn.reg_lambda: 0.031243696603585985
wandb: 	model.sklearn.subsample: 0.9068709562979144
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193015-26v9tnpw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-46
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/26v9tnpw
2023-02-07 19:30:24.017 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 1 for sweep.
2023-02-07 19:30:24.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 90 for sweep.
2023-02-07 19:30:24.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0006569017251415229 for sweep.
2023-02-07 19:30:24.018 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:30:24.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 19:30:24.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9393164040860212 for sweep.
2023-02-07 19:30:24.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 239 for sweep.
2023-02-07 19:30:24.019 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 7 for sweep.
2023-02-07 19:30:24.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.002328756457575758 for sweep.
2023-02-07 19:30:24.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 22 for sweep.
2023-02-07 19:30:24.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.023120175740486568 for sweep.
2023-02-07 19:30:24.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1899 for sweep.
2023-02-07 19:30:24.020 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 232 for sweep.
2023-02-07 19:30:24.021 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.7271354025551086 for sweep.
2023-02-07 19:30:24.021 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.031243696603585985 for sweep.
2023-02-07 19:30:24.021 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9068709562979144 for sweep.
2023-02-07 19:30:24.021 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:30:24.030 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 1}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193015-26v9tnpw/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 90, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 239, 'window': 7, 'min_count': 6, 'dm': 0, 'sample': 0.9393164040860212, 'workers': 4, 'alpha': 0.0006569017251415229, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1899, 'max_depth': 22, 'num_leaves': 232, 'reg_alpha': 0.7271354025551086, 'reg_lambda': 0.031243696603585985, 'subsample': 0.9068709562979144, 'min_child_weight': 0.023120175740486568, 'n_jobs': 4, 'learning_rate': 0.002328756457575758}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 36/3257 [00:00<00:08, 358.82it/s]  2%|‚ñè         | 75/3257 [00:00<00:08, 371.89it/s]  3%|‚ñé         | 113/3257 [00:00<00:08, 367.90it/s]  5%|‚ñç         | 154/3257 [00:00<00:08, 384.05it/s]  6%|‚ñå         | 194/3257 [00:00<00:07, 386.56it/s]  7%|‚ñã         | 239/3257 [00:00<00:07, 406.00it/s]  9%|‚ñä         | 283/3257 [00:00<00:07, 416.17it/s] 10%|‚ñâ         | 325/3257 [00:00<00:07, 415.80it/s] 11%|‚ñà‚ñè        | 367/3257 [00:00<00:07, 400.14it/s] 13%|‚ñà‚ñé        | 408/3257 [00:01<00:07, 397.10it/s] 14%|‚ñà‚ñç        | 448/3257 [00:01<00:07, 378.17it/s] 15%|‚ñà‚ñç        | 488/3257 [00:01<00:07, 383.49it/s] 16%|‚ñà‚ñã        | 531/3257 [00:01<00:06, 393.89it/s] 18%|‚ñà‚ñä        | 571/3257 [00:01<00:07, 381.55it/s] 19%|‚ñà‚ñâ        | 617/3257 [00:01<00:06, 402.86it/s] 20%|‚ñà‚ñà        | 658/3257 [00:01<00:06, 382.59it/s] 21%|‚ñà‚ñà‚ñè       | 697/3257 [00:01<00:06, 379.12it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:01<00:06, 380.83it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:01<00:06, 385.82it/s] 25%|‚ñà‚ñà‚ñå       | 817/3257 [00:02<00:06, 390.81it/s] 26%|‚ñà‚ñà‚ñã       | 857/3257 [00:02<00:07, 340.61it/s] 27%|‚ñà‚ñà‚ñã       | 893/3257 [00:02<00:07, 328.23it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:02<00:07, 332.61it/s] 30%|‚ñà‚ñà‚ñâ       | 962/3257 [00:02<00:06, 328.20it/s] 31%|‚ñà‚ñà‚ñà       | 996/3257 [00:02<00:07, 312.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1028/3257 [00:02<00:07, 302.02it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1059/3257 [00:02<00:07, 294.42it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1090/3257 [00:03<00:07, 295.79it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1121/3257 [00:03<00:07, 299.52it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1152/3257 [00:03<00:07, 293.54it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1182/3257 [00:03<00:07, 293.01it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1212/3257 [00:03<00:11, 185.88it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1244/3257 [00:03<00:09, 212.54it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1274/3257 [00:03<00:08, 231.88it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1302/3257 [00:03<00:08, 234.09it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1336/3257 [00:04<00:07, 259.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1366/3257 [00:04<00:07, 267.96it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1397/3257 [00:04<00:06, 278.29it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1434/3257 [00:04<00:06, 303.70it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1466/3257 [00:04<00:05, 307.88it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1501/3257 [00:04<00:05, 317.84it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1534/3257 [00:04<00:05, 305.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1566/3257 [00:04<00:05, 308.37it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1598/3257 [00:04<00:05, 310.55it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:05<00:05, 319.34it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1667/3257 [00:05<00:05, 297.70it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1698/3257 [00:05<00:05, 289.33it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:05<00:05, 285.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1757/3257 [00:05<00:05, 285.45it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:05<00:04, 297.46it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1820/3257 [00:05<00:04, 296.28it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1850/3257 [00:05<00:04, 285.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1883/3257 [00:05<00:04, 297.55it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:05<00:04, 303.26it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:06<00:04, 323.79it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1987/3257 [00:06<00:03, 318.06it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:06<00:03, 324.90it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:06<00:03, 308.96it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2087/3257 [00:06<00:03, 301.59it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2119/3257 [00:06<00:03, 305.78it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2150/3257 [00:06<00:03, 290.69it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2183/3257 [00:06<00:03, 301.55it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2215/3257 [00:06<00:03, 305.78it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2246/3257 [00:07<00:03, 302.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2277/3257 [00:07<00:03, 295.30it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2310/3257 [00:07<00:03, 304.68it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2349/3257 [00:07<00:02, 329.02it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2384/3257 [00:07<00:02, 333.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2418/3257 [00:07<00:02, 318.87it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2451/3257 [00:07<00:02, 302.12it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2489/3257 [00:07<00:02, 323.04it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2525/3257 [00:07<00:02, 332.73it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2559/3257 [00:08<00:02, 329.79it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2593/3257 [00:08<00:02, 316.90it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2633/3257 [00:08<00:01, 339.83it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2668/3257 [00:08<00:02, 213.47it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2698/3257 [00:08<00:02, 230.89it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2730/3257 [00:08<00:02, 250.28it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2763/3257 [00:08<00:01, 268.67it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2797/3257 [00:08<00:01, 285.99it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2829/3257 [00:09<00:01, 287.46it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2869/3257 [00:09<00:01, 317.64it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:09<00:01, 317.16it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2936/3257 [00:09<00:01, 318.42it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:09<00:00, 309.85it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3001/3257 [00:09<00:00, 310.11it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3033/3257 [00:09<00:00, 311.12it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3070/3257 [00:09<00:00, 326.58it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3106/3257 [00:09<00:00, 335.93it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3140/3257 [00:09<00:00, 331.74it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3174/3257 [00:10<00:00, 332.28it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3208/3257 [00:10<00:00, 328.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:10<00:00, 333.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:10<00:00, 314.80it/s]
2023-02-07 19:30:34.563 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:30:34,564][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d239,n5,mc6,s0.939316,t4>', 'datetime': '2023-02-07T19:30:34.564239', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:30:34,564][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:30:34,564][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:30:34,683][gensim.models.doc2vec][INFO] - collected 924 word types and 3257 unique tags from a corpus of 3257 examples and 1455748 words
[2023-02-07 19:30:34,683][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:30:34,685][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 585 unique words (63.31% of original 924, drops 339)', 'datetime': '2023-02-07T19:30:34.685254', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:30:34,685][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 1454759 word corpus (99.93% of original 1455748, drops 989)', 'datetime': '2023-02-07T19:30:34.685398', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:30:34,687][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 924 items
[2023-02-07 19:30:34,687][gensim.models.word2vec][INFO] - sample=0.939316 downsamples 0 most-common words
[2023-02-07 19:30:34,688][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 1454759 word corpus (100.0%% of prior 1454759)', 'datetime': '2023-02-07T19:30:34.688038', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:30:34,691][gensim.models.word2vec][INFO] - estimated required memory for 585 words and 239 dimensions: 5176112 bytes
[2023-02-07 19:30:34,691][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:30:34,694][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 585 vocabulary and 239 features, using sg=1 hs=0 sample=0.9393164040860212 negative=5 window=7 shrink_windows=True', 'datetime': '2023-02-07T19:30:34.694703', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:30:35,524][gensim.models.word2vec][INFO] - EPOCH 0: training on 1455748 raw words (1458016 effective words) took 0.8s, 1758801 effective words/s
[2023-02-07 19:30:36,397][gensim.models.word2vec][INFO] - EPOCH 1: training on 1455748 raw words (1458016 effective words) took 0.9s, 1673309 effective words/s
[2023-02-07 19:30:37,273][gensim.models.word2vec][INFO] - EPOCH 2: training on 1455748 raw words (1458016 effective words) took 0.9s, 1667740 effective words/s
[2023-02-07 19:30:38,125][gensim.models.word2vec][INFO] - EPOCH 3: training on 1455748 raw words (1458016 effective words) took 0.9s, 1713732 effective words/s
[2023-02-07 19:30:39,123][gensim.models.word2vec][INFO] - EPOCH 4: training on 1455748 raw words (1458016 effective words) took 1.0s, 1464774 effective words/s
[2023-02-07 19:30:40,123][gensim.models.word2vec][INFO] - EPOCH 5: training on 1455748 raw words (1458016 effective words) took 1.0s, 1459781 effective words/s
[2023-02-07 19:30:41,083][gensim.models.word2vec][INFO] - EPOCH 6: training on 1455748 raw words (1458016 effective words) took 1.0s, 1522269 effective words/s
[2023-02-07 19:30:41,952][gensim.models.word2vec][INFO] - EPOCH 7: training on 1455748 raw words (1458016 effective words) took 0.9s, 1682514 effective words/s
[2023-02-07 19:30:42,841][gensim.models.word2vec][INFO] - EPOCH 8: training on 1455748 raw words (1458016 effective words) took 0.9s, 1642762 effective words/s
[2023-02-07 19:30:43,810][gensim.models.word2vec][INFO] - EPOCH 9: training on 1455748 raw words (1458016 effective words) took 1.0s, 1508351 effective words/s
[2023-02-07 19:30:44,799][gensim.models.word2vec][INFO] - EPOCH 10: training on 1455748 raw words (1458016 effective words) took 1.0s, 1477336 effective words/s
[2023-02-07 19:30:45,761][gensim.models.word2vec][INFO] - EPOCH 11: training on 1455748 raw words (1458016 effective words) took 1.0s, 1518284 effective words/s
[2023-02-07 19:30:46,775][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 97.91% examples, 1409839 words/s, in_qsize 4, out_qsize 0
[2023-02-07 19:30:46,780][gensim.models.word2vec][INFO] - EPOCH 12: training on 1455748 raw words (1458016 effective words) took 1.0s, 1433678 effective words/s
[2023-02-07 19:30:47,783][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 97.61% examples, 1424660 words/s, in_qsize 4, out_qsize 0
[2023-02-07 19:30:47,791][gensim.models.word2vec][INFO] - EPOCH 13: training on 1455748 raw words (1458016 effective words) took 1.0s, 1445043 effective words/s
[2023-02-07 19:30:48,796][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 96.47% examples, 1402592 words/s, in_qsize 6, out_qsize 0
[2023-02-07 19:30:48,823][gensim.models.word2vec][INFO] - EPOCH 14: training on 1455748 raw words (1458016 effective words) took 1.0s, 1415313 effective words/s
[2023-02-07 19:30:48,823][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 21836220 raw words (21870240 effective words) took 14.1s, 1547925 effective words/s', 'datetime': '2023-02-07T19:30:48.823640', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:30:48.823 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:30:49,469][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193015-26v9tnpw/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:30:49.469899', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:30:49,470][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:30:49,483][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193015-26v9tnpw/files/../tmp/embedding_model.pt
2023-02-07 19:30:49.483 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:30:50.973 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:30:51.608 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:30:53.229 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0993786874688054, 'test_mae': 0.8158253859614302, 'test_r2': -3.2175987400422237}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.16
wandb: percentage 0.36688
wandb:   test_mae 0.81583
wandb:   test_mse 1.09938
wandb:    test_r2 -3.2176
wandb: 
wandb: üöÄ View run avid-sweep-46 at: https://wandb.ai/xiaoqiz/mof2vec/runs/26v9tnpw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_193015-26v9tnpw/logs
wandb: Agent Starting Run: 1o1akd9x with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 339
wandb: 	model.gensim.alpha: 0.005980399589866711
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 3
wandb: 	model.gensim.sample: 0.9614841663991702
wandb: 	model.gensim.vector_size: 97
wandb: 	model.gensim.window: 1
wandb: 	model.sklearn.learning_rate: 0.0011918559881422203
wandb: 	model.sklearn.max_depth: 56
wandb: 	model.sklearn.min_child_weight: 0.057201174358726674
wandb: 	model.sklearn.n_estimators: 1884
wandb: 	model.sklearn.num_leaves: 351
wandb: 	model.sklearn.reg_alpha: 0.042519765582636225
wandb: 	model.sklearn.reg_lambda: 0.9468565743053206
wandb: 	model.sklearn.subsample: 0.706486677202528
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193104-1o1akd9x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-47
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/1o1akd9x
2023-02-07 19:31:12.545 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:31:12.546 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 339 for sweep.
2023-02-07 19:31:12.546 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.005980399589866711 for sweep.
2023-02-07 19:31:12.547 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:31:12.547 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 3 for sweep.
2023-02-07 19:31:12.547 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9614841663991702 for sweep.
2023-02-07 19:31:12.547 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 97 for sweep.
2023-02-07 19:31:12.547 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 1 for sweep.
2023-02-07 19:31:12.548 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0011918559881422203 for sweep.
2023-02-07 19:31:12.548 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 56 for sweep.
2023-02-07 19:31:12.548 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.057201174358726674 for sweep.
2023-02-07 19:31:12.548 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1884 for sweep.
2023-02-07 19:31:12.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 351 for sweep.
2023-02-07 19:31:12.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.042519765582636225 for sweep.
2023-02-07 19:31:12.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.9468565743053206 for sweep.
2023-02-07 19:31:12.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.706486677202528 for sweep.
2023-02-07 19:31:12.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:31:12.556 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193104-1o1akd9x/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 339, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 97, 'window': 1, 'min_count': 3, 'dm': 1, 'sample': 0.9614841663991702, 'workers': 4, 'alpha': 0.005980399589866711, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1884, 'max_depth': 56, 'num_leaves': 351, 'reg_alpha': 0.042519765582636225, 'reg_lambda': 0.9468565743053206, 'subsample': 0.706486677202528, 'min_child_weight': 0.057201174358726674, 'n_jobs': 4, 'learning_rate': 0.0011918559881422203}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:20, 156.27it/s]  1%|          | 34/3257 [00:00<00:20, 156.31it/s]  2%|‚ñè         | 51/3257 [00:00<00:20, 159.72it/s]  2%|‚ñè         | 67/3257 [00:00<00:20, 155.27it/s]  3%|‚ñé         | 89/3257 [00:00<00:18, 172.61it/s]  3%|‚ñé         | 107/3257 [00:00<00:20, 155.63it/s]  4%|‚ñç         | 125/3257 [00:00<00:19, 158.43it/s]  4%|‚ñç         | 145/3257 [00:00<00:18, 168.93it/s]  5%|‚ñå         | 163/3257 [00:01<00:19, 158.76it/s]  6%|‚ñå         | 180/3257 [00:01<00:19, 159.05it/s]  6%|‚ñå         | 198/3257 [00:01<00:18, 164.21it/s]  7%|‚ñã         | 216/3257 [00:01<00:18, 166.34it/s]  7%|‚ñã         | 236/3257 [00:01<00:17, 174.81it/s]  8%|‚ñä         | 254/3257 [00:01<00:17, 171.32it/s]  8%|‚ñä         | 272/3257 [00:01<00:17, 167.38it/s]  9%|‚ñâ         | 294/3257 [00:01<00:16, 181.99it/s] 10%|‚ñâ         | 313/3257 [00:01<00:17, 166.69it/s] 10%|‚ñà         | 333/3257 [00:01<00:16, 174.87it/s] 11%|‚ñà         | 351/3257 [00:02<00:17, 166.86it/s] 11%|‚ñà‚ñè        | 368/3257 [00:02<00:17, 167.52it/s] 12%|‚ñà‚ñè        | 385/3257 [00:02<00:17, 161.49it/s] 12%|‚ñà‚ñè        | 402/3257 [00:02<00:17, 161.72it/s] 13%|‚ñà‚ñé        | 420/3257 [00:02<00:17, 162.42it/s] 13%|‚ñà‚ñé        | 437/3257 [00:02<00:20, 140.33it/s] 14%|‚ñà‚ñç        | 455/3257 [00:02<00:18, 149.47it/s] 15%|‚ñà‚ñç        | 473/3257 [00:02<00:17, 156.60it/s] 15%|‚ñà‚ñå        | 490/3257 [00:03<00:18, 152.60it/s] 16%|‚ñà‚ñå        | 509/3257 [00:03<00:16, 161.83it/s] 16%|‚ñà‚ñå        | 526/3257 [00:03<00:17, 152.32it/s] 17%|‚ñà‚ñã        | 543/3257 [00:03<00:17, 157.00it/s] 17%|‚ñà‚ñã        | 559/3257 [00:03<00:18, 144.83it/s] 18%|‚ñà‚ñä        | 574/3257 [00:03<00:19, 139.97it/s] 18%|‚ñà‚ñä        | 592/3257 [00:03<00:17, 150.26it/s] 19%|‚ñà‚ñâ        | 611/3257 [00:03<00:16, 160.12it/s] 19%|‚ñà‚ñâ        | 628/3257 [00:03<00:16, 156.36it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:04<00:16, 156.09it/s] 20%|‚ñà‚ñà        | 660/3257 [00:04<00:18, 137.62it/s] 21%|‚ñà‚ñà        | 678/3257 [00:04<00:17, 148.45it/s] 21%|‚ñà‚ñà‚ñè       | 694/3257 [00:04<00:17, 146.69it/s] 22%|‚ñà‚ñà‚ñè       | 710/3257 [00:04<00:17, 149.07it/s] 22%|‚ñà‚ñà‚ñè       | 726/3257 [00:04<00:25, 98.07it/s]  23%|‚ñà‚ñà‚ñé       | 739/3257 [00:04<00:24, 103.37it/s] 23%|‚ñà‚ñà‚ñé       | 756/3257 [00:05<00:21, 117.77it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:05<00:19, 126.50it/s] 24%|‚ñà‚ñà‚ñç       | 788/3257 [00:05<00:19, 129.24it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:17, 136.96it/s] 25%|‚ñà‚ñà‚ñå       | 819/3257 [00:05<00:17, 139.07it/s] 26%|‚ñà‚ñà‚ñå       | 834/3257 [00:05<00:17, 138.23it/s] 26%|‚ñà‚ñà‚ñå       | 849/3257 [00:05<00:18, 129.90it/s] 27%|‚ñà‚ñà‚ñã       | 865/3257 [00:05<00:17, 137.23it/s] 27%|‚ñà‚ñà‚ñã       | 880/3257 [00:05<00:17, 137.57it/s] 27%|‚ñà‚ñà‚ñã       | 895/3257 [00:05<00:16, 140.81it/s] 28%|‚ñà‚ñà‚ñä       | 913/3257 [00:06<00:15, 151.23it/s] 29%|‚ñà‚ñà‚ñä       | 929/3257 [00:06<00:15, 152.72it/s] 29%|‚ñà‚ñà‚ñâ       | 945/3257 [00:06<00:15, 149.83it/s] 30%|‚ñà‚ñà‚ñâ       | 962/3257 [00:06<00:14, 154.75it/s] 30%|‚ñà‚ñà‚ñà       | 978/3257 [00:06<00:14, 154.53it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:06<00:15, 143.63it/s] 31%|‚ñà‚ñà‚ñà       | 1009/3257 [00:06<00:15, 141.12it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1026/3257 [00:06<00:15, 146.25it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:06<00:16, 132.44it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1056/3257 [00:07<00:16, 134.56it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1074/3257 [00:07<00:14, 146.45it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1089/3257 [00:07<00:15, 143.78it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1104/3257 [00:07<00:14, 143.70it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1119/3257 [00:07<00:14, 142.63it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1135/3257 [00:07<00:14, 147.01it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1150/3257 [00:07<00:14, 142.98it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:13, 153.92it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1186/3257 [00:07<00:14, 143.87it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1201/3257 [00:08<00:15, 132.12it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1216/3257 [00:08<00:15, 135.71it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1234/3257 [00:08<00:13, 146.73it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1249/3257 [00:08<00:14, 141.39it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1268/3257 [00:08<00:12, 153.81it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1284/3257 [00:08<00:14, 134.01it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1298/3257 [00:08<00:14, 134.20it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1315/3257 [00:08<00:13, 142.00it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1330/3257 [00:09<00:13, 143.67it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1347/3257 [00:09<00:12, 150.92it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1363/3257 [00:09<00:13, 141.90it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1378/3257 [00:09<00:14, 130.15it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1392/3257 [00:09<00:15, 122.26it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1408/3257 [00:09<00:14, 130.88it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:09<00:14, 130.48it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1437/3257 [00:09<00:13, 131.63it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:09<00:13, 133.18it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1467/3257 [00:10<00:13, 136.95it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1481/3257 [00:10<00:13, 133.14it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:10<00:13, 134.66it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1512/3257 [00:10<00:12, 138.33it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1526/3257 [00:10<00:13, 125.29it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1539/3257 [00:10<00:14, 120.87it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1552/3257 [00:10<00:14, 119.26it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1565/3257 [00:10<00:14, 118.60it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1577/3257 [00:10<00:14, 117.42it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:11<00:13, 120.75it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1605/3257 [00:11<00:13, 124.03it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:11<00:12, 127.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1633/3257 [00:11<00:12, 130.95it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1647/3257 [00:11<00:13, 115.32it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:11<00:13, 117.92it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:11<00:13, 119.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1687/3257 [00:11<00:13, 119.34it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1701/3257 [00:11<00:12, 124.38it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:12<00:12, 126.93it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:12<00:12, 122.41it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1741/3257 [00:12<00:13, 116.51it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1756/3257 [00:12<00:11, 125.56it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:12<00:11, 130.08it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1787/3257 [00:12<00:10, 136.55it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1801/3257 [00:12<00:10, 132.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1815/3257 [00:12<00:11, 125.47it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:12<00:11, 122.15it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1844/3257 [00:13<00:10, 131.21it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1858/3257 [00:13<00:11, 124.81it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1875/3257 [00:13<00:10, 135.92it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1889/3257 [00:13<00:10, 133.08it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1903/3257 [00:13<00:10, 132.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1917/3257 [00:13<00:10, 130.07it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:13<00:10, 130.92it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1951/3257 [00:13<00:08, 149.47it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1968/3257 [00:13<00:08, 154.38it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1984/3257 [00:14<00:09, 140.29it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2001/3257 [00:14<00:16, 78.00it/s]  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2015/3257 [00:14<00:14, 87.69it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:14<00:11, 103.36it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2047/3257 [00:14<00:11, 104.72it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2060/3257 [00:14<00:11, 102.60it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2077/3257 [00:15<00:10, 117.19it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:15<00:09, 120.14it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2105/3257 [00:15<00:09, 121.16it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:15<00:09, 119.84it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2133/3257 [00:15<00:09, 119.04it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2146/3257 [00:15<00:09, 116.21it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2161/3257 [00:15<00:08, 124.80it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:15<00:08, 130.54it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2192/3257 [00:15<00:08, 131.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2206/3257 [00:16<00:07, 132.82it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2220/3257 [00:16<00:07, 131.53it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2234/3257 [00:16<00:07, 132.73it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2248/3257 [00:16<00:08, 122.59it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2261/3257 [00:16<00:08, 123.41it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2274/3257 [00:16<00:08, 113.96it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2291/3257 [00:16<00:07, 125.75it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2304/3257 [00:16<00:07, 124.51it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2321/3257 [00:17<00:06, 135.44it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2338/3257 [00:17<00:06, 143.75it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2357/3257 [00:17<00:05, 154.75it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2373/3257 [00:17<00:06, 142.30it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2393/3257 [00:17<00:05, 155.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2409/3257 [00:17<00:05, 151.15it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2428/3257 [00:17<00:05, 157.61it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2444/3257 [00:17<00:05, 153.79it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2463/3257 [00:17<00:04, 163.11it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:17<00:04, 166.71it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2502/3257 [00:18<00:04, 177.26it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2520/3257 [00:18<00:04, 175.89it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:18<00:04, 176.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2558/3257 [00:18<00:04, 172.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2576/3257 [00:18<00:04, 165.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2593/3257 [00:18<00:04, 160.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2616/3257 [00:18<00:03, 179.74it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2636/3257 [00:18<00:03, 184.27it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2655/3257 [00:18<00:03, 170.49it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:19<00:03, 167.28it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:19<00:03, 167.83it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2707/3257 [00:19<00:03, 147.89it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2723/3257 [00:19<00:03, 145.88it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2745/3257 [00:19<00:03, 164.71it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2762/3257 [00:19<00:03, 161.83it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:19<00:02, 162.70it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2800/3257 [00:19<00:02, 174.87it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2818/3257 [00:20<00:02, 158.58it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2835/3257 [00:20<00:02, 156.38it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:20<00:02, 160.06it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2879/3257 [00:20<00:02, 185.47it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2898/3257 [00:20<00:02, 162.94it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2915/3257 [00:20<00:02, 163.19it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2932/3257 [00:20<00:02, 160.29it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2949/3257 [00:20<00:02, 148.69it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2967/3257 [00:20<00:01, 155.82it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2983/3257 [00:21<00:01, 146.37it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3002/3257 [00:21<00:01, 157.09it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3019/3257 [00:21<00:01, 153.31it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3039/3257 [00:21<00:01, 163.90it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3061/3257 [00:21<00:01, 177.91it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3080/3257 [00:21<00:01, 176.41it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3098/3257 [00:21<00:00, 169.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:21<00:00, 177.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3136/3257 [00:21<00:00, 166.61it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3153/3257 [00:22<00:00, 157.50it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3170/3257 [00:22<00:00, 160.11it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3187/3257 [00:22<00:00, 151.65it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3205/3257 [00:22<00:00, 158.91it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3222/3257 [00:22<00:00, 150.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3242/3257 [00:22<00:00, 162.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 143.27it/s]
2023-02-07 19:31:36.185 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:31:36,186][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d97,n5,w1,mc3,s0.961484,t4>', 'datetime': '2023-02-07T19:31:36.186625', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:31:36,187][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:31:36,187][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:31:36,798][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 19:31:36,799][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:31:36,911][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 38627 unique words (71.46% of original 54054, drops 15427)', 'datetime': '2023-02-07T19:31:36.911902', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:31:36,913][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 6527597 word corpus (99.64% of original 6550866, drops 23269)', 'datetime': '2023-02-07T19:31:36.913214', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:31:37,047][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 19:31:37,049][gensim.models.word2vec][INFO] - sample=0.961484 downsamples 0 most-common words
[2023-02-07 19:31:37,049][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6527597 word corpus (100.0%% of prior 6527597)', 'datetime': '2023-02-07T19:31:37.049454', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:31:37,286][gensim.models.word2vec][INFO] - estimated required memory for 38627 words and 97 dimensions: 51203168 bytes
[2023-02-07 19:31:37,287][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:31:37,304][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 38627 vocabulary and 97 features, using sg=0 hs=0 sample=0.9614841663991702 negative=5 window=1 shrink_windows=True', 'datetime': '2023-02-07T19:31:37.304646', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:31:38,307][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 40.93% examples, 2717310 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:39,308][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 86.67% examples, 2826011 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:31:39,579][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6472763 effective words) took 2.3s, 2848783 effective words/s
[2023-02-07 19:31:40,583][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 46.45% examples, 3044555 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:31:41,586][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 95.79% examples, 3093223 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:41,667][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6472763 effective words) took 2.1s, 3101478 effective words/s
[2023-02-07 19:31:42,669][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 49.25% examples, 3247567 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:31:43,671][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 96.53% examples, 3125074 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:31:43,750][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6472763 effective words) took 2.1s, 3110290 effective words/s
[2023-02-07 19:31:44,753][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 41.94% examples, 2785293 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:45,755][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 85.39% examples, 2784747 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:31:46,092][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6472763 effective words) took 2.3s, 2765660 effective words/s
[2023-02-07 19:31:47,095][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 41.88% examples, 2780557 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:31:48,096][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 84.86% examples, 2765460 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:48,443][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6472763 effective words) took 2.3s, 2755594 effective words/s
[2023-02-07 19:31:49,446][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 41.45% examples, 2751683 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:50,448][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 85.66% examples, 2789399 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:50,757][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6472763 effective words) took 2.3s, 2799206 effective words/s
[2023-02-07 19:31:51,759][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 46.64% examples, 3070227 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:52,635][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6472763 effective words) took 1.9s, 3450398 effective words/s
[2023-02-07 19:31:53,639][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 51.89% examples, 3423558 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:31:54,566][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6472763 effective words) took 1.9s, 3352566 effective words/s
[2023-02-07 19:31:55,572][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 49.06% examples, 3231055 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:31:56,559][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6472763 effective words) took 2.0s, 3253572 effective words/s
[2023-02-07 19:31:57,561][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 48.73% examples, 3218554 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:31:58,551][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6472763 effective words) took 2.0s, 3250729 effective words/s
[2023-02-07 19:31:59,554][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 49.06% examples, 3233840 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:00,525][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6472763 effective words) took 2.0s, 3281160 effective words/s
[2023-02-07 19:32:01,531][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 51.64% examples, 3401350 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:02,409][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6472763 effective words) took 1.9s, 3439805 effective words/s
[2023-02-07 19:32:03,412][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 50.94% examples, 3356173 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:32:04,414][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 95.61% examples, 3090167 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:32:04,507][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6472763 effective words) took 2.1s, 3086923 effective words/s
[2023-02-07 19:32:05,514][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 43.41% examples, 2869965 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:32:06,516][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 88.79% examples, 2881882 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:32:06,757][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6472763 effective words) took 2.2s, 2880846 effective words/s
[2023-02-07 19:32:07,762][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 42.98% examples, 2857077 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:32:08,764][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 88.61% examples, 2877560 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:32:09,005][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6472763 effective words) took 2.2s, 2885788 effective words/s
[2023-02-07 19:32:09,005][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (97091445 effective words) took 31.7s, 3062827 effective words/s', 'datetime': '2023-02-07T19:32:09.005718', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:32:09.005 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:32:12,203][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193104-1o1akd9x/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:32:12.203864', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:32:12,205][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:32:12,262][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193104-1o1akd9x/files/../tmp/embedding_model.pt
2023-02-07 19:32:12.262 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:32:13.412 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:32:13.864 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:32:14.641 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0057273408340783, 'test_mae': 0.7679769532537899, 'test_r2': -2.578419070176006}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.77
wandb: percentage 0.2854
wandb:   test_mae 0.76798
wandb:   test_mse 1.00573
wandb:    test_r2 -2.57842
wandb: 
wandb: üöÄ View run hardy-sweep-47 at: https://wandb.ai/xiaoqiz/mof2vec/runs/1o1akd9x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_193104-1o1akd9x/logs
wandb: Agent Starting Run: di0ry3mq with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 277
wandb: 	model.gensim.alpha: 0.0752839045699744
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.5609999458070636
wandb: 	model.gensim.vector_size: 380
wandb: 	model.gensim.window: 10
wandb: 	model.sklearn.learning_rate: 0.04287379806300537
wandb: 	model.sklearn.max_depth: 28
wandb: 	model.sklearn.min_child_weight: 0.03804270330176541
wandb: 	model.sklearn.n_estimators: 2001
wandb: 	model.sklearn.num_leaves: 153
wandb: 	model.sklearn.reg_alpha: 0.004751228677650784
wandb: 	model.sklearn.reg_lambda: 0.02640839300130265
wandb: 	model.sklearn.subsample: 0.2630762726990053
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193228-di0ry3mq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-48
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/di0ry3mq
2023-02-07 19:32:36.651 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:32:36.652 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 277 for sweep.
2023-02-07 19:32:36.652 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0752839045699744 for sweep.
2023-02-07 19:32:36.652 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:32:36.653 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 19:32:36.653 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5609999458070636 for sweep.
2023-02-07 19:32:36.653 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 380 for sweep.
2023-02-07 19:32:36.653 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 10 for sweep.
2023-02-07 19:32:36.654 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.04287379806300537 for sweep.
2023-02-07 19:32:36.654 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 28 for sweep.
2023-02-07 19:32:36.654 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03804270330176541 for sweep.
2023-02-07 19:32:36.654 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2001 for sweep.
2023-02-07 19:32:36.655 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 153 for sweep.
2023-02-07 19:32:36.655 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004751228677650784 for sweep.
2023-02-07 19:32:36.655 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.02640839300130265 for sweep.
2023-02-07 19:32:36.655 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2630762726990053 for sweep.
2023-02-07 19:32:36.655 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:32:36.664 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193228-di0ry3mq/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 277, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 380, 'window': 10, 'min_count': 9, 'dm': 1, 'sample': 0.5609999458070636, 'workers': 4, 'alpha': 0.0752839045699744, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2001, 'max_depth': 28, 'num_leaves': 153, 'reg_alpha': 0.004751228677650784, 'reg_lambda': 0.02640839300130265, 'subsample': 0.2630762726990053, 'min_child_weight': 0.03804270330176541, 'n_jobs': 4, 'learning_rate': 0.04287379806300537}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 4/3257 [00:00<02:29, 21.69it/s]  1%|          | 23/3257 [00:00<00:34, 93.80it/s]  1%|          | 39/3257 [00:00<00:27, 118.80it/s]  2%|‚ñè         | 55/3257 [00:00<00:24, 129.69it/s]  2%|‚ñè         | 74/3257 [00:00<00:21, 147.82it/s]  3%|‚ñé         | 92/3257 [00:00<00:20, 157.40it/s]  3%|‚ñé         | 109/3257 [00:00<00:20, 150.41it/s]  4%|‚ñç         | 126/3257 [00:00<00:20, 155.71it/s]  4%|‚ñç         | 146/3257 [00:01<00:18, 168.72it/s]  5%|‚ñå         | 164/3257 [00:01<00:19, 159.35it/s]  6%|‚ñå         | 181/3257 [00:01<00:19, 161.61it/s]  6%|‚ñå         | 201/3257 [00:01<00:18, 166.23it/s]  7%|‚ñã         | 226/3257 [00:01<00:16, 188.45it/s]  8%|‚ñä         | 246/3257 [00:01<00:16, 186.31it/s]  8%|‚ñä         | 265/3257 [00:01<00:16, 179.42it/s]  9%|‚ñâ         | 290/3257 [00:01<00:15, 196.22it/s] 10%|‚ñâ         | 310/3257 [00:01<00:15, 188.42it/s] 10%|‚ñà         | 329/3257 [00:02<00:15, 186.15it/s] 11%|‚ñà         | 348/3257 [00:02<00:16, 175.63it/s] 11%|‚ñà‚ñè        | 367/3257 [00:02<00:16, 176.58it/s] 12%|‚ñà‚ñè        | 385/3257 [00:02<00:16, 172.08it/s] 12%|‚ñà‚ñè        | 403/3257 [00:02<00:16, 171.93it/s] 13%|‚ñà‚ñé        | 421/3257 [00:02<00:16, 170.92it/s] 13%|‚ñà‚ñé        | 439/3257 [00:02<00:18, 151.00it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:17, 161.69it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:16, 166.87it/s] 15%|‚ñà‚ñå        | 500/3257 [00:03<00:15, 176.36it/s] 16%|‚ñà‚ñå        | 520/3257 [00:03<00:15, 180.87it/s] 17%|‚ñà‚ñã        | 539/3257 [00:03<00:15, 177.49it/s] 17%|‚ñà‚ñã        | 558/3257 [00:03<00:15, 169.55it/s] 18%|‚ñà‚ñä        | 576/3257 [00:03<00:16, 160.12it/s] 18%|‚ñà‚ñä        | 596/3257 [00:03<00:15, 169.12it/s] 19%|‚ñà‚ñâ        | 614/3257 [00:03<00:15, 170.08it/s] 19%|‚ñà‚ñâ        | 632/3257 [00:03<00:16, 162.63it/s] 20%|‚ñà‚ñâ        | 649/3257 [00:03<00:17, 150.08it/s] 20%|‚ñà‚ñà        | 665/3257 [00:04<00:18, 140.43it/s] 21%|‚ñà‚ñà        | 682/3257 [00:04<00:17, 147.42it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:04<00:18, 134.92it/s] 22%|‚ñà‚ñà‚ñè       | 716/3257 [00:04<00:17, 144.68it/s] 22%|‚ñà‚ñà‚ñè       | 731/3257 [00:04<00:18, 133.85it/s] 23%|‚ñà‚ñà‚ñé       | 745/3257 [00:04<00:19, 131.66it/s] 23%|‚ñà‚ñà‚ñé       | 761/3257 [00:04<00:18, 138.19it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:04<00:18, 133.78it/s] 24%|‚ñà‚ñà‚ñç       | 792/3257 [00:05<00:17, 138.19it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:05<00:17, 136.96it/s] 25%|‚ñà‚ñà‚ñå       | 821/3257 [00:05<00:17, 140.53it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:05<00:17, 134.73it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:05<00:18, 130.59it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:05<00:17, 135.60it/s] 27%|‚ñà‚ñà‚ñã       | 880/3257 [00:05<00:17, 133.56it/s] 27%|‚ñà‚ñà‚ñã       | 895/3257 [00:05<00:17, 136.67it/s] 28%|‚ñà‚ñà‚ñä       | 912/3257 [00:05<00:16, 144.69it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:06<00:15, 145.88it/s] 29%|‚ñà‚ñà‚ñâ       | 943/3257 [00:06<00:16, 139.85it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:06<00:16, 142.52it/s] 30%|‚ñà‚ñà‚ñâ       | 975/3257 [00:06<00:15, 145.81it/s] 30%|‚ñà‚ñà‚ñà       | 990/3257 [00:06<00:16, 139.48it/s] 31%|‚ñà‚ñà‚ñà       | 1005/3257 [00:06<00:15, 141.78it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1020/3257 [00:06<00:15, 142.74it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1035/3257 [00:06<00:16, 134.96it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1049/3257 [00:06<00:16, 133.00it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1064/3257 [00:07<00:16, 136.96it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:15, 137.41it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:07<00:15, 137.75it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1111/3257 [00:07<00:14, 145.96it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1126/3257 [00:07<00:15, 137.20it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1140/3257 [00:07<00:15, 133.45it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1154/3257 [00:07<00:15, 134.96it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:07<00:14, 141.34it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1186/3257 [00:07<00:15, 133.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1200/3257 [00:08<00:16, 127.05it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1213/3257 [00:08<00:16, 124.93it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:08<00:14, 140.24it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:08<00:14, 139.07it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:08<00:14, 141.84it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:08<00:14, 133.51it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:08<00:15, 129.47it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1305/3257 [00:09<00:24, 78.76it/s]  41%|‚ñà‚ñà‚ñà‚ñà      | 1320/3257 [00:09<00:21, 91.95it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1333/3257 [00:09<00:19, 99.90it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1349/3257 [00:09<00:16, 112.62it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1363/3257 [00:09<00:16, 117.90it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1377/3257 [00:09<00:16, 117.13it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1390/3257 [00:09<00:15, 118.71it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1408/3257 [00:09<00:13, 134.91it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:09<00:13, 139.05it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1438/3257 [00:09<00:12, 140.69it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1457/3257 [00:10<00:11, 153.80it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1473/3257 [00:10<00:11, 151.70it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1490/3257 [00:10<00:11, 154.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1508/3257 [00:10<00:10, 161.54it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1525/3257 [00:10<00:11, 145.24it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1540/3257 [00:10<00:12, 142.75it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:10<00:12, 136.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1572/3257 [00:10<00:11, 142.71it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1587/3257 [00:11<00:12, 138.41it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1604/3257 [00:11<00:11, 146.53it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:11<00:11, 146.46it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:11<00:11, 142.05it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1649/3257 [00:11<00:11, 139.18it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1664/3257 [00:11<00:11, 139.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1678/3257 [00:11<00:11, 139.10it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:11<00:11, 139.06it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1711/3257 [00:11<00:10, 153.29it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:11<00:10, 152.33it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:12<00:09, 153.98it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1765/3257 [00:12<00:08, 168.69it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1787/3257 [00:12<00:08, 182.17it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1806/3257 [00:12<00:08, 177.88it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:12<00:08, 178.50it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:12<00:07, 181.65it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:12<00:07, 190.69it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1890/3257 [00:12<00:07, 195.11it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1911/3257 [00:12<00:06, 198.00it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:13<00:06, 189.93it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1957/3257 [00:13<00:06, 209.07it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1979/3257 [00:13<00:06, 197.90it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2000/3257 [00:13<00:06, 199.17it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2021/3257 [00:13<00:06, 200.71it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2042/3257 [00:13<00:06, 187.38it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2061/3257 [00:13<00:07, 167.69it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2082/3257 [00:13<00:06, 176.84it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2101/3257 [00:13<00:06, 168.65it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:14<00:06, 168.02it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2138/3257 [00:14<00:06, 166.62it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2155/3257 [00:14<00:06, 163.14it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2176/3257 [00:14<00:06, 175.16it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2194/3257 [00:14<00:06, 167.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2211/3257 [00:14<00:06, 157.65it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2230/3257 [00:14<00:06, 166.17it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2247/3257 [00:14<00:06, 162.06it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2265/3257 [00:14<00:06, 164.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2282/3257 [00:15<00:06, 161.09it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:15<00:05, 162.66it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2318/3257 [00:15<00:05, 169.09it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2339/3257 [00:15<00:05, 180.67it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:15<00:04, 188.04it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2380/3257 [00:15<00:04, 189.46it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2400/3257 [00:15<00:04, 191.42it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2420/3257 [00:15<00:04, 179.65it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2439/3257 [00:15<00:04, 170.57it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2457/3257 [00:16<00:04, 169.95it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2477/3257 [00:16<00:04, 178.15it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2498/3257 [00:16<00:04, 184.43it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2519/3257 [00:16<00:03, 188.12it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:16<00:03, 187.99it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2559/3257 [00:16<00:03, 179.31it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2578/3257 [00:16<00:03, 173.78it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2596/3257 [00:16<00:03, 168.14it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2621/3257 [00:16<00:03, 190.26it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2641/3257 [00:17<00:03, 190.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2661/3257 [00:17<00:06, 98.44it/s]  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2681/3257 [00:17<00:04, 115.46it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2698/3257 [00:17<00:04, 120.82it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2715/3257 [00:17<00:04, 126.50it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2739/3257 [00:17<00:03, 151.72it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2758/3257 [00:18<00:03, 159.43it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2776/3257 [00:18<00:03, 159.26it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2799/3257 [00:18<00:02, 177.58it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2818/3257 [00:18<00:02, 168.98it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2836/3257 [00:18<00:02, 167.36it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2857/3257 [00:18<00:02, 178.23it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2882/3257 [00:18<00:01, 196.20it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:18<00:01, 178.35it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2924/3257 [00:18<00:01, 185.16it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2944/3257 [00:19<00:01, 170.20it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2964/3257 [00:19<00:01, 177.47it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2983/3257 [00:19<00:01, 167.98it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:19<00:01, 178.66it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3023/3257 [00:19<00:01, 176.82it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3046/3257 [00:19<00:01, 190.96it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3068/3257 [00:19<00:00, 197.70it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3089/3257 [00:19<00:00, 190.56it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3111/3257 [00:19<00:00, 197.55it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3131/3257 [00:20<00:00, 195.59it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3151/3257 [00:20<00:00, 182.33it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3171/3257 [00:20<00:00, 184.91it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3190/3257 [00:20<00:00, 180.11it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3209/3257 [00:20<00:00, 176.32it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3228/3257 [00:20<00:00, 177.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3252/3257 [00:20<00:00, 195.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 157.13it/s]
2023-02-07 19:32:58.203 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:32:58,205][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d380,n5,w10,mc9,s0.561,t4>', 'datetime': '2023-02-07T19:32:58.204974', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:32:58,205][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:32:58,205][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:32:58,800][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:32:58,800][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:32:58,851][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 14828 unique words (34.73% of original 42701, drops 27873)', 'datetime': '2023-02-07T19:32:58.851845', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:32:58,853][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 5723647 word corpus (98.29% of original 5822992, drops 99345)', 'datetime': '2023-02-07T19:32:58.853419', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:32:58,908][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:32:58,910][gensim.models.word2vec][INFO] - sample=0.561 downsamples 0 most-common words
[2023-02-07 19:32:58,910][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5723647 word corpus (100.0%% of prior 5723647)', 'datetime': '2023-02-07T19:32:58.910590', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:32:59,004][gensim.models.word2vec][INFO] - estimated required memory for 14828 words and 380 dimensions: 58093160 bytes
[2023-02-07 19:32:59,005][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:32:59,046][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14828 vocabulary and 380 features, using sg=0 hs=0 sample=0.5609999458070636 negative=5 window=10 shrink_windows=True', 'datetime': '2023-02-07T19:32:59.046793', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:33:00,071][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 19.71% examples, 1074211 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:01,093][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 38.29% examples, 1092390 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:02,105][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 57.48% examples, 1095534 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:03,114][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 77.77% examples, 1100673 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:04,124][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 98.34% examples, 1105209 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:04,199][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5697932 effective words) took 5.1s, 1106554 effective words/s
[2023-02-07 19:33:05,211][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 20.14% examples, 1121315 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:06,211][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 39.51% examples, 1151436 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:07,211][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 64.54% examples, 1244871 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:08,218][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 89.13% examples, 1273299 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:08,663][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5697932 effective words) took 4.5s, 1276985 effective words/s
[2023-02-07 19:33:09,669][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 23.61% examples, 1326141 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:10,675][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 46.12% examples, 1328816 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:11,675][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 68.99% examples, 1334695 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:12,676][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 93.40% examples, 1333041 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:12,926][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5697932 effective words) took 4.3s, 1337190 effective words/s
[2023-02-07 19:33:13,930][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 23.61% examples, 1328172 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:14,936][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 46.79% examples, 1352399 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:15,941][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 70.22% examples, 1356712 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:16,943][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 92.42% examples, 1319281 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:17,273][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5697932 effective words) took 4.3s, 1311377 effective words/s
[2023-02-07 19:33:18,285][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 21.40% examples, 1194410 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:19,288][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 41.20% examples, 1197029 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:20,291][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 62.70% examples, 1201014 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:21,296][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 84.22% examples, 1204548 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:22,005][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5697932 effective words) took 4.7s, 1204714 effective words/s
[2023-02-07 19:33:23,019][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 21.40% examples, 1192453 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:24,025][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 41.42% examples, 1200900 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:25,026][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 66.93% examples, 1289394 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:26,026][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 92.60% examples, 1322115 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:26,301][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5697932 effective words) took 4.3s, 1327319 effective words/s
[2023-02-07 19:33:27,307][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 23.92% examples, 1350771 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:28,307][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 46.64% examples, 1350519 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:29,307][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 69.57% examples, 1349066 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:30,319][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 94.53% examples, 1344288 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:30,531][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5697932 effective words) took 4.2s, 1347479 effective words/s
[2023-02-07 19:33:31,535][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 23.61% examples, 1328997 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:32,536][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 46.45% examples, 1342420 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:33,538][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 68.84% examples, 1334029 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:34,544][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 91.34% examples, 1306086 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:34,930][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5697932 effective words) took 4.4s, 1295678 effective words/s
[2023-02-07 19:33:35,944][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 21.40% examples, 1193536 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:36,957][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 41.42% examples, 1197254 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:37,960][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 62.70% examples, 1197167 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:38,962][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 83.85% examples, 1198223 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:39,686][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5697932 effective words) took 4.8s, 1198996 effective words/s
[2023-02-07 19:33:40,690][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 21.31% examples, 1196798 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:41,691][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 41.85% examples, 1223347 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:42,695][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 68.04% examples, 1316514 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:43,697][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 92.48% examples, 1323932 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:43,974][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5697932 effective words) took 4.3s, 1329876 effective words/s
[2023-02-07 19:33:44,981][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 23.70% examples, 1334471 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:45,988][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 46.61% examples, 1341245 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:47,000][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 69.88% examples, 1349035 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:33:48,013][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 95.18% examples, 1346175 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:48,193][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5697932 effective words) took 4.2s, 1351224 effective words/s
[2023-02-07 19:33:49,197][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 24.04% examples, 1363500 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:50,204][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 47.71% examples, 1382998 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:51,220][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 68.65% examples, 1320011 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:52,224][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 91.03% examples, 1295351 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:52,624][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5697932 effective words) took 4.4s, 1286462 effective words/s
[2023-02-07 19:33:53,639][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 21.40% examples, 1191098 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:54,639][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 41.08% examples, 1192250 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:55,640][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 61.90% examples, 1188309 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:56,646][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 83.33% examples, 1194193 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:57,392][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5697932 effective words) took 4.8s, 1195579 effective words/s
[2023-02-07 19:33:58,409][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 21.40% examples, 1187939 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:33:59,413][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 46.15% examples, 1323958 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:00,418][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 73.38% examples, 1401644 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:01,367][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5697932 effective words) took 4.0s, 1434159 effective words/s
[2023-02-07 19:34:02,379][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 25.85% examples, 1465412 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:34:03,379][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 49.28% examples, 1425609 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:04,385][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 73.84% examples, 1415676 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:05,388][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 98.68% examples, 1402335 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:34:05,434][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5697932 effective words) took 4.1s, 1401853 effective words/s
[2023-02-07 19:34:05,434][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85468980 effective words) took 66.4s, 1287431 effective words/s', 'datetime': '2023-02-07T19:34:05.434517', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:34:05.434 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:34:10,243][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193228-di0ry3mq/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:34:10.243667', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:34:10,244][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:34:10,321][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193228-di0ry3mq/files/../tmp/embedding_model.pt
2023-02-07 19:34:10.322 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:34:12.402 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:34:13.136 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:34:15.965 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1154927020297392, 'test_mae': 0.8006571670708481, 'test_r2': -2.989887320239487}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.36
wandb: percentage 0.65275
wandb:   test_mae 0.80066
wandb:   test_mse 1.11549
wandb:    test_r2 -2.98989
wandb: 
wandb: üöÄ View run pleasant-sweep-48 at: https://wandb.ai/xiaoqiz/mof2vec/runs/di0ry3mq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_193228-di0ry3mq/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: b39hnvdp with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 231
wandb: 	model.gensim.alpha: 0.0024390768419227295
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.3303493781912714
wandb: 	model.gensim.vector_size: 15
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.015442513542652666
wandb: 	model.sklearn.max_depth: 100
wandb: 	model.sklearn.min_child_weight: 0.08768616797484478
wandb: 	model.sklearn.n_estimators: 1446
wandb: 	model.sklearn.num_leaves: 101
wandb: 	model.sklearn.reg_alpha: 0.006381804541390355
wandb: 	model.sklearn.reg_lambda: 0.07723973519781371
wandb: 	model.sklearn.subsample: 0.24080414371526537
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193434-b39hnvdp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-49
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/b39hnvdp
2023-02-07 19:34:42.390 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:34:42.391 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 231 for sweep.
2023-02-07 19:34:42.391 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0024390768419227295 for sweep.
2023-02-07 19:34:42.391 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:34:42.392 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 19:34:42.392 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.3303493781912714 for sweep.
2023-02-07 19:34:42.392 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 15 for sweep.
2023-02-07 19:34:42.392 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 19:34:42.392 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.015442513542652666 for sweep.
2023-02-07 19:34:42.393 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 100 for sweep.
2023-02-07 19:34:42.393 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.08768616797484478 for sweep.
2023-02-07 19:34:42.393 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1446 for sweep.
2023-02-07 19:34:42.393 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 101 for sweep.
2023-02-07 19:34:42.393 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.006381804541390355 for sweep.
2023-02-07 19:34:42.394 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.07723973519781371 for sweep.
2023-02-07 19:34:42.394 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.24080414371526537 for sweep.
2023-02-07 19:34:42.394 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:34:42.398 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193434-b39hnvdp/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 231, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 15, 'window': 2, 'min_count': 6, 'dm': 1, 'sample': 0.3303493781912714, 'workers': 4, 'alpha': 0.0024390768419227295, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1446, 'max_depth': 100, 'num_leaves': 101, 'reg_alpha': 0.006381804541390355, 'reg_lambda': 0.07723973519781371, 'subsample': 0.24080414371526537, 'min_child_weight': 0.08768616797484478, 'n_jobs': 4, 'learning_rate': 0.015442513542652666}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 176.54it/s]  1%|          | 38/3257 [00:00<00:17, 188.32it/s]  2%|‚ñè         | 57/3257 [00:00<00:17, 181.21it/s]  2%|‚ñè         | 79/3257 [00:00<00:16, 192.71it/s]  3%|‚ñé         | 99/3257 [00:00<00:16, 192.54it/s]  4%|‚ñé         | 119/3257 [00:00<00:16, 188.90it/s]  4%|‚ñç         | 141/3257 [00:00<00:15, 198.15it/s]  5%|‚ñç         | 161/3257 [00:00<00:15, 196.85it/s]  6%|‚ñå         | 181/3257 [00:00<00:15, 192.70it/s]  6%|‚ñå         | 202/3257 [00:01<00:15, 197.79it/s]  7%|‚ñã         | 231/3257 [00:01<00:13, 224.11it/s]  8%|‚ñä         | 254/3257 [00:01<00:13, 221.64it/s]  9%|‚ñä         | 279/3257 [00:01<00:12, 229.09it/s]  9%|‚ñâ         | 303/3257 [00:01<00:12, 231.20it/s] 10%|‚ñà         | 328/3257 [00:01<00:12, 230.89it/s] 11%|‚ñà         | 352/3257 [00:01<00:13, 221.93it/s] 12%|‚ñà‚ñè        | 375/3257 [00:01<00:13, 216.26it/s] 12%|‚ñà‚ñè        | 397/3257 [00:01<00:13, 209.03it/s] 13%|‚ñà‚ñé        | 420/3257 [00:02<00:13, 209.23it/s] 14%|‚ñà‚ñé        | 441/3257 [00:02<00:15, 186.51it/s] 14%|‚ñà‚ñç        | 464/3257 [00:02<00:14, 196.35it/s] 15%|‚ñà‚ñç        | 485/3257 [00:02<00:14, 196.60it/s] 16%|‚ñà‚ñå        | 510/3257 [00:02<00:13, 209.43it/s] 16%|‚ñà‚ñã        | 532/3257 [00:02<00:13, 202.84it/s] 17%|‚ñà‚ñã        | 555/3257 [00:02<00:12, 209.69it/s] 18%|‚ñà‚ñä        | 577/3257 [00:02<00:14, 182.89it/s] 18%|‚ñà‚ñä        | 601/3257 [00:02<00:13, 196.04it/s] 19%|‚ñà‚ñâ        | 622/3257 [00:03<00:13, 193.52it/s] 20%|‚ñà‚ñâ        | 642/3257 [00:03<00:18, 138.54it/s] 20%|‚ñà‚ñà        | 659/3257 [00:03<00:18, 141.18it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:16, 156.72it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:03<00:15, 168.22it/s] 22%|‚ñà‚ñà‚ñè       | 723/3257 [00:03<00:14, 173.08it/s] 23%|‚ñà‚ñà‚ñé       | 742/3257 [00:03<00:14, 174.53it/s] 24%|‚ñà‚ñà‚ñé       | 767/3257 [00:03<00:12, 194.59it/s] 24%|‚ñà‚ñà‚ñç       | 788/3257 [00:04<00:13, 188.20it/s] 25%|‚ñà‚ñà‚ñç       | 809/3257 [00:04<00:12, 194.07it/s] 25%|‚ñà‚ñà‚ñå       | 829/3257 [00:04<00:12, 189.23it/s] 26%|‚ñà‚ñà‚ñå       | 849/3257 [00:04<00:13, 183.33it/s] 27%|‚ñà‚ñà‚ñã       | 870/3257 [00:04<00:12, 189.82it/s] 27%|‚ñà‚ñà‚ñã       | 891/3257 [00:04<00:12, 191.89it/s] 28%|‚ñà‚ñà‚ñä       | 913/3257 [00:04<00:11, 198.18it/s] 29%|‚ñà‚ñà‚ñä       | 933/3257 [00:04<00:12, 180.21it/s] 29%|‚ñà‚ñà‚ñâ       | 952/3257 [00:04<00:13, 176.41it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:05<00:13, 172.79it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:05<00:13, 162.15it/s] 31%|‚ñà‚ñà‚ñà       | 1005/3257 [00:05<00:13, 162.38it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1022/3257 [00:05<00:13, 161.05it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1039/3257 [00:05<00:15, 147.70it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1055/3257 [00:05<00:14, 147.34it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1074/3257 [00:05<00:13, 158.52it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:05<00:14, 152.68it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1110/3257 [00:05<00:13, 162.05it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1127/3257 [00:06<00:14, 151.58it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:06<00:13, 152.94it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1160/3257 [00:06<00:13, 156.05it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1176/3257 [00:06<00:13, 152.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1192/3257 [00:06<00:14, 142.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:06<00:14, 138.11it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1222/3257 [00:06<00:14, 139.70it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:06<00:13, 152.69it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:07<00:13, 148.23it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:07<00:13, 148.05it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1287/3257 [00:07<00:14, 136.60it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1304/3257 [00:07<00:13, 143.49it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1322/3257 [00:07<00:12, 153.21it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1340/3257 [00:07<00:12, 158.98it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1357/3257 [00:07<00:12, 153.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1373/3257 [00:07<00:12, 149.74it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1389/3257 [00:07<00:12, 148.82it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1416/3257 [00:08<00:10, 181.23it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1437/3257 [00:08<00:09, 188.00it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1461/3257 [00:08<00:08, 200.73it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1483/3257 [00:08<00:08, 205.63it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1507/3257 [00:08<00:08, 214.85it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1529/3257 [00:08<00:08, 198.57it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:08<00:08, 194.97it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1570/3257 [00:08<00:08, 196.00it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1590/3257 [00:08<00:08, 195.74it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1611/3257 [00:08<00:08, 199.31it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:09<00:08, 192.00it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:09<00:08, 191.13it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:09<00:08, 185.17it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1693/3257 [00:09<00:08, 184.95it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:09<00:08, 192.25it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1735/3257 [00:09<00:08, 176.47it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1757/3257 [00:09<00:08, 187.26it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:09<00:07, 193.12it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1800/3257 [00:09<00:07, 197.30it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:10<00:07, 197.50it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1841/3257 [00:10<00:07, 197.02it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1861/3257 [00:10<00:07, 197.16it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1883/3257 [00:10<00:06, 198.21it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1904/3257 [00:10<00:06, 200.10it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1925/3257 [00:10<00:10, 121.69it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1953/3257 [00:10<00:08, 152.96it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1976/3257 [00:11<00:07, 169.76it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1997/3257 [00:11<00:07, 179.20it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2019/3257 [00:11<00:06, 188.49it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2040/3257 [00:11<00:06, 185.62it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2060/3257 [00:11<00:07, 165.56it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2081/3257 [00:11<00:06, 175.02it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:11<00:07, 163.03it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:11<00:06, 163.31it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:11<00:06, 162.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:12<00:07, 156.04it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2173/3257 [00:12<00:06, 163.13it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2190/3257 [00:12<00:06, 159.21it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2207/3257 [00:12<00:06, 160.68it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2224/3257 [00:12<00:06, 157.60it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2240/3257 [00:12<00:06, 149.08it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:12<00:06, 157.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:12<00:06, 147.09it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2297/3257 [00:12<00:05, 164.26it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2314/3257 [00:13<00:05, 164.62it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2335/3257 [00:13<00:05, 175.56it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2357/3257 [00:13<00:04, 186.18it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2376/3257 [00:13<00:04, 176.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:13<00:04, 183.59it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2416/3257 [00:13<00:04, 169.53it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2434/3257 [00:13<00:05, 159.53it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2451/3257 [00:13<00:05, 155.04it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2473/3257 [00:13<00:04, 170.18it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2491/3257 [00:14<00:04, 168.74it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2512/3257 [00:14<00:04, 178.04it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2532/3257 [00:14<00:03, 183.37it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2551/3257 [00:14<00:03, 178.03it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2569/3257 [00:14<00:04, 164.20it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2589/3257 [00:14<00:03, 172.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2617/3257 [00:14<00:03, 201.78it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2642/3257 [00:14<00:02, 211.70it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2664/3257 [00:14<00:02, 204.18it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2688/3257 [00:15<00:02, 213.10it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2710/3257 [00:15<00:02, 192.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2735/3257 [00:15<00:02, 206.83it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:15<00:02, 214.49it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2783/3257 [00:15<00:02, 213.09it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:15<00:02, 214.16it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2829/3257 [00:15<00:02, 201.87it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:15<00:01, 209.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2882/3257 [00:15<00:01, 230.13it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:16<00:01, 210.71it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:16<00:01, 209.91it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:16<00:01, 197.26it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2972/3257 [00:16<00:01, 201.42it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2993/3257 [00:16<00:01, 190.75it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:16<00:01, 200.26it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3039/3257 [00:16<00:01, 208.26it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3066/3257 [00:16<00:00, 222.62it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3089/3257 [00:17<00:00, 218.98it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3116/3257 [00:17<00:00, 232.02it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3140/3257 [00:17<00:00, 223.34it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3163/3257 [00:17<00:00, 218.37it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:17<00:00, 209.77it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:17<00:00, 204.37it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3228/3257 [00:17<00:00, 194.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3249/3257 [00:17<00:00, 196.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 182.50it/s]
2023-02-07 19:35:01.058 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:35:01,060][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d15,n5,w2,mc6,s0.330349,t4>', 'datetime': '2023-02-07T19:35:01.060097', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:35:01,060][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:35:01,061][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:35:01,597][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:35:01,598][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:35:01,647][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 15588 unique words (49.01% of original 31803, drops 16215)', 'datetime': '2023-02-07T19:35:01.647063', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:35:01,647][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 5053508 word corpus (99.18% of original 5095118, drops 41610)', 'datetime': '2023-02-07T19:35:01.647502', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:35:01,703][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:35:01,704][gensim.models.word2vec][INFO] - sample=0.330349 downsamples 0 most-common words
[2023-02-07 19:35:01,705][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5053508 word corpus (100.0%% of prior 5053508)', 'datetime': '2023-02-07T19:35:01.705135', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:35:01,803][gensim.models.word2vec][INFO] - estimated required memory for 15588 words and 15 dimensions: 10511380 bytes
[2023-02-07 19:35:01,803][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:35:01,805][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 15588 vocabulary and 15 features, using sg=0 hs=0 sample=0.3303493781912714 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T19:35:01.805818', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:35:02,812][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 54.04% examples, 2786852 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:03,483][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5045550 effective words) took 1.7s, 3013671 effective words/s
[2023-02-07 19:35:04,487][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 68.01% examples, 3499356 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:04,944][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5045550 effective words) took 1.5s, 3458022 effective words/s
[2023-02-07 19:35:05,946][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 67.06% examples, 3452577 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:06,462][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5045550 effective words) took 1.5s, 3326632 effective words/s
[2023-02-07 19:35:07,466][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 59.47% examples, 3054225 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:08,111][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5045550 effective words) took 1.6s, 3061849 effective words/s
[2023-02-07 19:35:09,121][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 59.47% examples, 3039697 words/s, in_qsize 7, out_qsize 1
[2023-02-07 19:35:09,661][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5045550 effective words) took 1.5s, 3259524 effective words/s
[2023-02-07 19:35:10,662][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 72.52% examples, 3717792 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:11,039][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5045550 effective words) took 1.4s, 3663853 effective words/s
[2023-02-07 19:35:12,042][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 66.75% examples, 3438055 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:12,508][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5045550 effective words) took 1.5s, 3440815 effective words/s
[2023-02-07 19:35:13,513][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 66.56% examples, 3419077 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:13,975][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5045550 effective words) took 1.5s, 3442454 effective words/s
[2023-02-07 19:35:14,978][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 66.04% examples, 3401296 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:15,454][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5045550 effective words) took 1.5s, 3417352 effective words/s
[2023-02-07 19:35:16,456][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 65.77% examples, 3385638 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:16,934][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5045550 effective words) took 1.5s, 3411805 effective words/s
[2023-02-07 19:35:17,938][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 67.30% examples, 3458659 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:35:18,384][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5045550 effective words) took 1.4s, 3484015 effective words/s
[2023-02-07 19:35:19,390][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 68.65% examples, 3523875 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:19,814][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5045550 effective words) took 1.4s, 3533438 effective words/s
[2023-02-07 19:35:20,818][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 67.85% examples, 3492143 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:21,246][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5045550 effective words) took 1.4s, 3527658 effective words/s
[2023-02-07 19:35:22,248][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 68.71% examples, 3543532 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:35:22,676][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5045550 effective words) took 1.4s, 3531347 effective words/s
[2023-02-07 19:35:23,680][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 69.02% examples, 3553433 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:35:24,112][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5045550 effective words) took 1.4s, 3517913 effective words/s
[2023-02-07 19:35:24,113][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75683250 effective words) took 22.3s, 3392937 effective words/s', 'datetime': '2023-02-07T19:35:24.113175', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:35:24.113 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:35:26,306][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193434-b39hnvdp/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:35:26.306277', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:35:26,307][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:35:26,322][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193434-b39hnvdp/files/../tmp/embedding_model.pt
2023-02-07 19:35:26.323 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:35:27.311 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:35:27.682 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:35:27.867 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.251615319777832, 'test_mae': 0.875548031478206, 'test_r2': -3.4149230777085764}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.31
wandb: percentage 0.50986
wandb:   test_mae 0.87555
wandb:   test_mse 1.25162
wandb:    test_r2 -3.41492
wandb: 
wandb: üöÄ View run pretty-sweep-49 at: https://wandb.ai/xiaoqiz/mof2vec/runs/b39hnvdp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_193434-b39hnvdp/logs
wandb: Agent Starting Run: insy68cg with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 499
wandb: 	model.gensim.alpha: 0.48905936538257777
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.3845808704221443
wandb: 	model.gensim.vector_size: 327
wandb: 	model.gensim.window: 20
wandb: 	model.sklearn.learning_rate: 0.11455164515709704
wandb: 	model.sklearn.max_depth: 81
wandb: 	model.sklearn.min_child_weight: 0.018275123200093484
wandb: 	model.sklearn.n_estimators: 2478
wandb: 	model.sklearn.num_leaves: 140
wandb: 	model.sklearn.reg_alpha: 0.16239324798026883
wandb: 	model.sklearn.reg_lambda: 0.005915689934433636
wandb: 	model.sklearn.subsample: 0.4366063818288761
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193538-insy68cg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-50
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/insy68cg
2023-02-07 19:35:46.698 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:35:46.699 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 499 for sweep.
2023-02-07 19:35:46.699 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.48905936538257777 for sweep.
2023-02-07 19:35:46.700 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:35:46.700 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 19:35:46.700 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.3845808704221443 for sweep.
2023-02-07 19:35:46.700 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 327 for sweep.
2023-02-07 19:35:46.701 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 20 for sweep.
2023-02-07 19:35:46.701 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.11455164515709704 for sweep.
2023-02-07 19:35:46.701 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 81 for sweep.
2023-02-07 19:35:46.701 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.018275123200093484 for sweep.
2023-02-07 19:35:46.702 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2478 for sweep.
2023-02-07 19:35:46.703 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 140 for sweep.
2023-02-07 19:35:46.703 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.16239324798026883 for sweep.
2023-02-07 19:35:46.703 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.005915689934433636 for sweep.
2023-02-07 19:35:46.703 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.4366063818288761 for sweep.
2023-02-07 19:35:46.704 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:35:46.713 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193538-insy68cg/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 499, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 327, 'window': 20, 'min_count': 2, 'dm': 1, 'sample': 0.3845808704221443, 'workers': 4, 'alpha': 0.48905936538257777, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2478, 'max_depth': 81, 'num_leaves': 140, 'reg_alpha': 0.16239324798026883, 'reg_lambda': 0.005915689934433636, 'subsample': 0.4366063818288761, 'min_child_weight': 0.018275123200093484, 'n_jobs': 4, 'learning_rate': 0.11455164515709704}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:21, 147.91it/s]  1%|          | 33/3257 [00:00<00:20, 160.80it/s]  2%|‚ñè         | 50/3257 [00:00<00:20, 158.27it/s]  2%|‚ñè         | 67/3257 [00:00<00:20, 153.15it/s]  3%|‚ñé         | 87/3257 [00:00<00:18, 167.36it/s]  3%|‚ñé         | 104/3257 [00:00<00:19, 161.46it/s]  4%|‚ñé         | 121/3257 [00:00<00:20, 153.57it/s]  4%|‚ñç         | 137/3257 [00:01<00:29, 106.23it/s]  5%|‚ñç         | 154/3257 [00:01<00:25, 119.40it/s]  5%|‚ñå         | 170/3257 [00:01<00:23, 128.74it/s]  6%|‚ñå         | 187/3257 [00:01<00:22, 137.15it/s]  6%|‚ñå         | 203/3257 [00:01<00:21, 142.15it/s]  7%|‚ñã         | 226/3257 [00:01<00:18, 165.15it/s]  7%|‚ñã         | 244/3257 [00:01<00:18, 164.36it/s]  8%|‚ñä         | 262/3257 [00:01<00:18, 158.12it/s]  9%|‚ñä         | 284/3257 [00:01<00:17, 172.98it/s]  9%|‚ñâ         | 302/3257 [00:02<00:17, 167.09it/s] 10%|‚ñâ         | 321/3257 [00:02<00:17, 172.49it/s] 10%|‚ñà         | 339/3257 [00:02<00:17, 168.06it/s] 11%|‚ñà         | 358/3257 [00:02<00:16, 173.47it/s] 12%|‚ñà‚ñè        | 376/3257 [00:02<00:17, 163.42it/s] 12%|‚ñà‚ñè        | 393/3257 [00:02<00:18, 155.29it/s] 13%|‚ñà‚ñé        | 411/3257 [00:02<00:17, 161.03it/s] 13%|‚ñà‚ñé        | 428/3257 [00:02<00:19, 142.44it/s] 14%|‚ñà‚ñé        | 443/3257 [00:02<00:19, 144.12it/s] 14%|‚ñà‚ñç        | 460/3257 [00:03<00:18, 150.51it/s] 15%|‚ñà‚ñç        | 477/3257 [00:03<00:17, 154.65it/s] 15%|‚ñà‚ñå        | 494/3257 [00:03<00:17, 158.88it/s] 16%|‚ñà‚ñå        | 513/3257 [00:03<00:16, 166.04it/s] 16%|‚ñà‚ñã        | 530/3257 [00:03<00:16, 164.47it/s] 17%|‚ñà‚ñã        | 547/3257 [00:03<00:16, 161.42it/s] 17%|‚ñà‚ñã        | 564/3257 [00:03<00:17, 152.12it/s] 18%|‚ñà‚ñä        | 580/3257 [00:03<00:17, 150.30it/s] 18%|‚ñà‚ñä        | 597/3257 [00:03<00:17, 155.02it/s] 19%|‚ñà‚ñâ        | 615/3257 [00:03<00:16, 160.98it/s] 19%|‚ñà‚ñâ        | 632/3257 [00:04<00:16, 162.18it/s] 20%|‚ñà‚ñâ        | 649/3257 [00:04<00:16, 154.70it/s] 20%|‚ñà‚ñà        | 665/3257 [00:04<00:17, 146.82it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:17, 150.11it/s] 21%|‚ñà‚ñà‚ñè       | 699/3257 [00:04<00:16, 150.69it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:15, 161.01it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:04<00:16, 154.96it/s] 23%|‚ñà‚ñà‚ñé       | 751/3257 [00:04<00:16, 149.41it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:05<00:15, 156.58it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:05<00:16, 152.97it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:15, 158.22it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:15, 157.54it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:05<00:16, 149.68it/s] 26%|‚ñà‚ñà‚ñå       | 852/3257 [00:05<00:16, 143.81it/s] 27%|‚ñà‚ñà‚ñã       | 869/3257 [00:05<00:15, 149.32it/s] 27%|‚ñà‚ñà‚ñã       | 885/3257 [00:05<00:16, 147.15it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:14, 159.59it/s] 28%|‚ñà‚ñà‚ñä       | 923/3257 [00:05<00:14, 163.40it/s] 29%|‚ñà‚ñà‚ñâ       | 940/3257 [00:06<00:14, 161.57it/s] 29%|‚ñà‚ñà‚ñâ       | 958/3257 [00:06<00:13, 165.46it/s] 30%|‚ñà‚ñà‚ñâ       | 975/3257 [00:06<00:13, 163.61it/s] 30%|‚ñà‚ñà‚ñà       | 992/3257 [00:06<00:14, 156.32it/s] 31%|‚ñà‚ñà‚ñà       | 1008/3257 [00:06<00:14, 151.41it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:06<00:14, 155.95it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:06<00:15, 146.06it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:06<00:13, 162.77it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1083/3257 [00:06<00:12, 174.62it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1103/3257 [00:07<00:11, 179.87it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:07<00:11, 184.53it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1142/3257 [00:07<00:11, 183.19it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1165/3257 [00:07<00:10, 196.08it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:07<00:11, 182.62it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:07<00:11, 176.73it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1225/3257 [00:07<00:10, 185.03it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:07<00:10, 194.62it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1268/3257 [00:07<00:10, 198.03it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:08<00:11, 174.61it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1307/3257 [00:08<00:11, 177.04it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1327/3257 [00:08<00:10, 182.73it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:08<00:10, 181.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1365/3257 [00:08<00:10, 175.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1383/3257 [00:08<00:11, 169.63it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1404/3257 [00:08<00:10, 178.71it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1426/3257 [00:08<00:09, 188.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1445/3257 [00:08<00:09, 186.13it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1468/3257 [00:09<00:09, 196.57it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1488/3257 [00:09<00:09, 195.59it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:09<00:13, 130.26it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1528/3257 [00:09<00:13, 132.67it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1544/3257 [00:09<00:12, 135.16it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1564/3257 [00:09<00:11, 149.66it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1581/3257 [00:09<00:11, 150.62it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1602/3257 [00:09<00:09, 165.63it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1621/3257 [00:10<00:09, 169.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:10<00:09, 170.46it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:10<00:09, 163.70it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:10<00:09, 164.16it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:10<00:09, 163.35it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1713/3257 [00:10<00:08, 177.29it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:10<00:09, 166.67it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1749/3257 [00:10<00:08, 170.34it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1768/3257 [00:10<00:08, 174.35it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1788/3257 [00:11<00:08, 181.41it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1807/3257 [00:11<00:08, 170.68it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:11<00:08, 174.57it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1845/3257 [00:11<00:07, 178.48it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1868/3257 [00:11<00:07, 190.69it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1888/3257 [00:11<00:07, 184.63it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1908/3257 [00:11<00:07, 188.83it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1927/3257 [00:11<00:07, 183.83it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1953/3257 [00:11<00:06, 204.30it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:12<00:06, 200.81it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1995/3257 [00:12<00:06, 194.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2015/3257 [00:12<00:06, 187.88it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2036/3257 [00:12<00:06, 193.07it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2056/3257 [00:12<00:06, 176.85it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2075/3257 [00:12<00:06, 179.01it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2094/3257 [00:12<00:06, 179.93it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2113/3257 [00:12<00:06, 178.97it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:12<00:06, 168.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2150/3257 [00:13<00:06, 168.03it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2173/3257 [00:13<00:05, 182.69it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2192/3257 [00:13<00:05, 183.03it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2211/3257 [00:13<00:06, 173.88it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2232/3257 [00:13<00:05, 182.74it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2251/3257 [00:13<00:05, 176.39it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:13<00:05, 174.68it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2291/3257 [00:13<00:05, 181.00it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2310/3257 [00:13<00:05, 182.82it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2335/3257 [00:14<00:04, 200.03it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:14<00:04, 206.13it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2382/3257 [00:14<00:04, 208.97it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2405/3257 [00:14<00:04, 203.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2426/3257 [00:14<00:04, 204.82it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2447/3257 [00:14<00:04, 191.03it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2469/3257 [00:14<00:03, 198.94it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2490/3257 [00:14<00:03, 198.99it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:14<00:03, 210.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2537/3257 [00:15<00:03, 214.82it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2559/3257 [00:15<00:03, 197.83it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2580/3257 [00:15<00:03, 188.61it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:15<00:03, 190.42it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2626/3257 [00:15<00:03, 208.71it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2648/3257 [00:15<00:03, 194.45it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2668/3257 [00:15<00:03, 195.05it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2689/3257 [00:15<00:02, 198.98it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2710/3257 [00:15<00:03, 173.07it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:16<00:02, 182.29it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:16<00:02, 194.96it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2777/3257 [00:16<00:02, 188.39it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2802/3257 [00:16<00:02, 202.90it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:16<00:02, 195.04it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2843/3257 [00:16<00:02, 187.09it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:16<00:01, 210.54it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2894/3257 [00:17<00:02, 127.75it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:17<00:02, 143.77it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2938/3257 [00:17<00:02, 158.47it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2957/3257 [00:17<00:01, 157.50it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2978/3257 [00:17<00:01, 168.51it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3002/3257 [00:17<00:01, 185.73it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3023/3257 [00:17<00:01, 188.79it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:17<00:01, 204.76it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:17<00:00, 218.29it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3098/3257 [00:18<00:00, 216.80it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3123/3257 [00:18<00:00, 226.04it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3146/3257 [00:18<00:00, 194.02it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3167/3257 [00:18<00:00, 187.72it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3187/3257 [00:18<00:00, 177.63it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:18<00:00, 178.46it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3226/3257 [00:18<00:00, 173.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3246/3257 [00:18<00:00, 179.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 171.89it/s]
2023-02-07 19:36:06.440 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:36:06,441][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d327,n5,w20,mc2,s0.384581,t4>', 'datetime': '2023-02-07T19:36:06.441899', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:36:06,442][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:36:06,442][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:36:06,987][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:36:06,987][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:36:07,068][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 27186 unique words (85.48% of original 31803, drops 4617)', 'datetime': '2023-02-07T19:36:07.068897', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:36:07,069][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5090501 word corpus (99.91% of original 5095118, drops 4617)', 'datetime': '2023-02-07T19:36:07.069322', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:36:07,170][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:36:07,171][gensim.models.word2vec][INFO] - sample=0.384581 downsamples 0 most-common words
[2023-02-07 19:36:07,172][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5090501 word corpus (100.0%% of prior 5090501)', 'datetime': '2023-02-07T19:36:07.172039', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:36:07,345][gensim.models.word2vec][INFO] - estimated required memory for 27186 words and 327 dimensions: 89623132 bytes
[2023-02-07 19:36:07,347][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:36:07,393][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 27186 vocabulary and 327 features, using sg=0 hs=0 sample=0.3845808704221443 negative=5 window=20 shrink_windows=True', 'datetime': '2023-02-07T19:36:07.393750', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:36:08,400][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 18.39% examples, 910169 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:09,414][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 35.74% examples, 915914 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:10,417][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 53.85% examples, 929538 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:11,417][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 72.52% examples, 931575 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:12,420][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 91.50% examples, 932536 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:12,822][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5082292 effective words) took 5.4s, 936650 effective words/s
[2023-02-07 19:36:13,835][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 20.94% examples, 1035037 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:14,845][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 41.23% examples, 1064007 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:15,846][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 61.59% examples, 1052575 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:16,859][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 81.98% examples, 1041223 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:17,731][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5082292 effective words) took 4.9s, 1035760 effective words/s
[2023-02-07 19:36:18,737][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 20.05% examples, 995203 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:19,738][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 38.75% examples, 1005236 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:20,748][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 58.80% examples, 1011283 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:21,761][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 79.12% examples, 1009793 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:22,738][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5082292 effective words) took 5.0s, 1015610 effective words/s
[2023-02-07 19:36:23,741][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 20.29% examples, 1016090 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:24,743][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 39.18% examples, 1020078 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:25,749][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 57.45% examples, 992221 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:26,761][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 76.54% examples, 980056 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:27,769][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 96.38% examples, 974363 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:27,960][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5082292 effective words) took 5.2s, 973438 effective words/s
[2023-02-07 19:36:28,965][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 18.39% examples, 911775 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:29,965][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 36.20% examples, 936770 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:30,971][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 53.85% examples, 933336 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:31,973][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 73.17% examples, 941133 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:32,975][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 92.78% examples, 947568 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:33,250][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5082292 effective words) took 5.3s, 961264 effective words/s
[2023-02-07 19:36:34,258][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 21.52% examples, 1075556 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:35,258][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 40.96% examples, 1062944 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:36,273][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 61.28% examples, 1046401 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:37,280][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 82.19% examples, 1044818 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:38,134][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5082292 effective words) took 4.9s, 1040831 effective words/s
[2023-02-07 19:36:39,144][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 20.39% examples, 1016417 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:40,148][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 39.27% examples, 1018922 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:41,150][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 59.47% examples, 1023920 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:42,155][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 80.38% examples, 1025414 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:43,054][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5082292 effective words) took 4.9s, 1033405 effective words/s
[2023-02-07 19:36:44,061][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 19.01% examples, 934545 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:45,070][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 36.11% examples, 926432 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:46,075][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 54.04% examples, 932026 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:47,085][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 72.92% examples, 934305 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:48,087][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 91.80% examples, 934876 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:48,480][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5082292 effective words) took 5.4s, 937079 effective words/s
[2023-02-07 19:36:49,490][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 19.01% examples, 931292 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:50,490][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 36.48% examples, 945317 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:51,491][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 54.59% examples, 943895 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:52,498][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 77.06% examples, 985984 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:53,499][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 98.86% examples, 1003172 words/s, in_qsize 6, out_qsize 0
[2023-02-07 19:36:53,543][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5082292 effective words) took 5.1s, 1004019 effective words/s
[2023-02-07 19:36:54,546][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 20.48% examples, 1026619 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:55,549][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 39.39% examples, 1027510 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:56,550][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 58.86% examples, 1017885 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:36:57,563][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 79.77% examples, 1021036 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:36:58,513][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5082292 effective words) took 5.0s, 1023063 effective words/s
[2023-02-07 19:36:59,519][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 20.11% examples, 1001876 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:00,527][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 39.51% examples, 1027404 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:37:01,528][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 60.06% examples, 1029633 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:37:02,534][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 78.91% examples, 1009488 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:03,540][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 98.43% examples, 996101 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:03,621][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5082292 effective words) took 5.1s, 995382 effective words/s
[2023-02-07 19:37:04,624][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 18.58% examples, 921351 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:37:05,627][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 36.20% examples, 936026 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:06,640][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 54.59% examples, 941675 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:07,641][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 73.44% examples, 941462 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:08,654][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 92.48% examples, 940733 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:37:09,011][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5082292 effective words) took 5.4s, 943318 effective words/s
[2023-02-07 19:37:10,033][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 19.65% examples, 955887 words/s, in_qsize 7, out_qsize 1
[2023-02-07 19:37:11,035][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 40.50% examples, 1047336 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:37:12,041][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 61.59% examples, 1050990 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:13,047][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 82.07% examples, 1043072 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:13,893][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5082292 effective words) took 4.9s, 1041846 effective words/s
[2023-02-07 19:37:14,897][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 20.11% examples, 1004436 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:37:15,898][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 39.27% examples, 1023637 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:16,930][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 59.47% examples, 1016718 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:37:17,938][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 81.24% examples, 1029958 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:37:18,812][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5082292 effective words) took 4.9s, 1033567 effective words/s
[2023-02-07 19:37:19,823][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 20.29% examples, 1008590 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:20,833][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 38.07% examples, 978823 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:21,837][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 56.09% examples, 966865 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:37:22,842][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 74.92% examples, 960471 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:23,843][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 94.20% examples, 954991 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:37:24,122][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5082292 effective words) took 5.3s, 957461 effective words/s
[2023-02-07 19:37:24,123][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76234380 effective words) took 76.7s, 993546 effective words/s', 'datetime': '2023-02-07T19:37:24.123862', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:37:24.124 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:37:29,333][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193538-insy68cg/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:37:29.332978', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:37:29,333][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:37:29,448][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193538-insy68cg/files/../tmp/embedding_model.pt
2023-02-07 19:37:29.449 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:37:31.430 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:37:32.116 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:37:34.196 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.2027770481984013, 'test_mae': 0.8549711009933173, 'test_r2': -4.100558002012998}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.0
wandb: percentage 0.14517
wandb:   test_mae 0.85497
wandb:   test_mse 1.20278
wandb:    test_r2 -4.10056
wandb: 
wandb: üöÄ View run toasty-sweep-50 at: https://wandb.ai/xiaoqiz/mof2vec/runs/insy68cg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_193538-insy68cg/logs
wandb: Agent Starting Run: ukj1v1od with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 984
wandb: 	model.gensim.alpha: 0.3174830974326535
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 2
wandb: 	model.gensim.sample: 0.7381333305408877
wandb: 	model.gensim.vector_size: 217
wandb: 	model.gensim.window: 14
wandb: 	model.sklearn.learning_rate: 0.024541218115649837
wandb: 	model.sklearn.max_depth: 24
wandb: 	model.sklearn.min_child_weight: 0.010530092871494472
wandb: 	model.sklearn.n_estimators: 4782
wandb: 	model.sklearn.num_leaves: 73
wandb: 	model.sklearn.reg_alpha: 0.18627736055561028
wandb: 	model.sklearn.reg_lambda: 0.006452747205987265
wandb: 	model.sklearn.subsample: 0.7272544709843511
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193746-ukj1v1od
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-51
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/ukj1v1od
2023-02-07 19:37:56.250 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:37:56.251 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 984 for sweep.
2023-02-07 19:37:56.251 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.3174830974326535 for sweep.
2023-02-07 19:37:56.251 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:37:56.252 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 2 for sweep.
2023-02-07 19:37:56.252 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7381333305408877 for sweep.
2023-02-07 19:37:56.252 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 217 for sweep.
2023-02-07 19:37:56.252 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 14 for sweep.
2023-02-07 19:37:56.253 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.024541218115649837 for sweep.
2023-02-07 19:37:56.253 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 24 for sweep.
2023-02-07 19:37:56.253 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.010530092871494472 for sweep.
2023-02-07 19:37:56.253 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 4782 for sweep.
2023-02-07 19:37:56.254 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 73 for sweep.
2023-02-07 19:37:56.254 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.18627736055561028 for sweep.
2023-02-07 19:37:56.254 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.006452747205987265 for sweep.
2023-02-07 19:37:56.254 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7272544709843511 for sweep.
2023-02-07 19:37:56.255 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:37:56.261 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193746-ukj1v1od/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 984, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 217, 'window': 14, 'min_count': 2, 'dm': 1, 'sample': 0.7381333305408877, 'workers': 4, 'alpha': 0.3174830974326535, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 4782, 'max_depth': 24, 'num_leaves': 73, 'reg_alpha': 0.18627736055561028, 'reg_lambda': 0.006452747205987265, 'subsample': 0.7272544709843511, 'min_child_weight': 0.010530092871494472, 'n_jobs': 4, 'learning_rate': 0.024541218115649837}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:21, 149.63it/s]  1%|          | 33/3257 [00:00<00:19, 164.05it/s]  2%|‚ñè         | 50/3257 [00:00<00:20, 155.19it/s]  2%|‚ñè         | 67/3257 [00:00<00:21, 150.47it/s]  3%|‚ñé         | 86/3257 [00:00<00:19, 163.38it/s]  3%|‚ñé         | 103/3257 [00:00<00:19, 159.68it/s]  4%|‚ñé         | 120/3257 [00:00<00:20, 151.90it/s]  4%|‚ñç         | 137/3257 [00:00<00:19, 156.88it/s]  5%|‚ñç         | 155/3257 [00:00<00:19, 162.52it/s]  5%|‚ñå         | 172/3257 [00:01<00:19, 157.98it/s]  6%|‚ñå         | 189/3257 [00:01<00:19, 160.57it/s]  6%|‚ñã         | 206/3257 [00:01<00:19, 158.13it/s]  7%|‚ñã         | 228/3257 [00:01<00:17, 174.89it/s]  8%|‚ñä         | 246/3257 [00:01<00:17, 174.65it/s]  8%|‚ñä         | 264/3257 [00:01<00:17, 167.03it/s]  9%|‚ñâ         | 286/3257 [00:01<00:16, 180.43it/s]  9%|‚ñâ         | 305/3257 [00:01<00:16, 174.59it/s] 10%|‚ñâ         | 325/3257 [00:01<00:16, 181.32it/s] 11%|‚ñà         | 344/3257 [00:02<00:16, 172.79it/s] 11%|‚ñà         | 364/3257 [00:02<00:16, 178.66it/s] 12%|‚ñà‚ñè        | 383/3257 [00:02<00:16, 174.49it/s] 12%|‚ñà‚ñè        | 401/3257 [00:02<00:16, 173.06it/s] 13%|‚ñà‚ñé        | 419/3257 [00:02<00:16, 173.00it/s] 13%|‚ñà‚ñé        | 437/3257 [00:02<00:19, 145.18it/s] 14%|‚ñà‚ñç        | 455/3257 [00:02<00:18, 152.66it/s] 15%|‚ñà‚ñç        | 473/3257 [00:02<00:17, 158.97it/s] 15%|‚ñà‚ñå        | 490/3257 [00:02<00:17, 157.10it/s] 16%|‚ñà‚ñå        | 510/3257 [00:03<00:16, 167.01it/s] 16%|‚ñà‚ñå        | 528/3257 [00:03<00:16, 163.91it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:16, 167.09it/s] 17%|‚ñà‚ñã        | 563/3257 [00:03<00:17, 158.35it/s] 18%|‚ñà‚ñä        | 580/3257 [00:03<00:16, 157.98it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:16, 164.78it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:16, 163.73it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:03<00:15, 170.81it/s] 20%|‚ñà‚ñà        | 658/3257 [00:04<00:16, 158.26it/s] 21%|‚ñà‚ñà        | 678/3257 [00:04<00:15, 167.57it/s] 21%|‚ñà‚ñà‚ñè       | 696/3257 [00:04<00:15, 161.85it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:04<00:14, 173.89it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:04<00:15, 166.98it/s] 23%|‚ñà‚ñà‚ñé       | 752/3257 [00:04<00:15, 160.76it/s] 24%|‚ñà‚ñà‚ñé       | 771/3257 [00:04<00:14, 166.78it/s] 24%|‚ñà‚ñà‚ñç       | 788/3257 [00:04<00:15, 162.49it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:15, 159.26it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:05<00:15, 155.64it/s] 26%|‚ñà‚ñà‚ñå       | 839/3257 [00:05<00:24, 99.40it/s]  26%|‚ñà‚ñà‚ñå       | 854/3257 [00:05<00:21, 109.29it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:05<00:18, 130.67it/s] 27%|‚ñà‚ñà‚ñã       | 895/3257 [00:05<00:16, 146.58it/s] 28%|‚ñà‚ñà‚ñä       | 917/3257 [00:05<00:14, 164.78it/s] 29%|‚ñà‚ñà‚ñâ       | 938/3257 [00:05<00:13, 176.69it/s] 30%|‚ñà‚ñà‚ñâ       | 961/3257 [00:05<00:12, 188.74it/s] 30%|‚ñà‚ñà‚ñà       | 981/3257 [00:06<00:12, 188.43it/s] 31%|‚ñà‚ñà‚ñà       | 1001/3257 [00:06<00:11, 191.18it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1024/3257 [00:06<00:11, 201.46it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1045/3257 [00:06<00:11, 192.18it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1068/3257 [00:06<00:10, 202.28it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:06<00:10, 202.61it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:06<00:10, 211.68it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1137/3257 [00:06<00:10, 201.54it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1158/3257 [00:06<00:10, 198.59it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1179/3257 [00:07<00:10, 192.38it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1199/3257 [00:07<00:10, 189.56it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:07<00:10, 188.90it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:07<00:09, 208.00it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:07<00:09, 215.88it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1293/3257 [00:07<00:09, 198.81it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1315/3257 [00:07<00:09, 203.06it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:07<00:09, 207.71it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1360/3257 [00:07<00:09, 199.07it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1381/3257 [00:08<00:09, 192.40it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1403/3257 [00:08<00:09, 198.23it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1430/3257 [00:08<00:08, 216.84it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:08<00:08, 215.47it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:08<00:08, 216.11it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:08<00:08, 215.81it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1518/3257 [00:08<00:08, 216.12it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1540/3257 [00:08<00:08, 201.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1561/3257 [00:08<00:08, 198.04it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1581/3257 [00:09<00:09, 185.41it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1601/3257 [00:09<00:08, 187.61it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:09<00:08, 186.56it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:09<00:08, 186.12it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1658/3257 [00:09<00:08, 185.18it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:09<00:08, 178.97it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1697/3257 [00:09<00:08, 184.41it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1716/3257 [00:09<00:08, 184.21it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1735/3257 [00:09<00:08, 173.64it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1757/3257 [00:09<00:08, 186.11it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1777/3257 [00:10<00:07, 189.13it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1798/3257 [00:10<00:07, 193.06it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1818/3257 [00:10<00:07, 190.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1838/3257 [00:10<00:07, 186.80it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1858/3257 [00:10<00:07, 186.26it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1880/3257 [00:10<00:07, 195.54it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1900/3257 [00:10<00:07, 192.74it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1920/3257 [00:10<00:06, 191.08it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1947/3257 [00:10<00:06, 212.18it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1972/3257 [00:11<00:05, 221.95it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1995/3257 [00:11<00:05, 210.90it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2017/3257 [00:11<00:06, 204.24it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2038/3257 [00:11<00:09, 123.74it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:11<00:09, 129.84it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2075/3257 [00:11<00:08, 142.81it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2095/3257 [00:11<00:07, 153.29it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2115/3257 [00:12<00:06, 163.69it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2133/3257 [00:12<00:07, 158.71it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2151/3257 [00:12<00:06, 163.84it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2173/3257 [00:12<00:06, 177.05it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2192/3257 [00:12<00:05, 178.82it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2211/3257 [00:12<00:06, 169.71it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2230/3257 [00:12<00:05, 173.13it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2248/3257 [00:12<00:06, 166.81it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2268/3257 [00:12<00:05, 173.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2288/3257 [00:13<00:05, 179.71it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2307/3257 [00:13<00:05, 180.63it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2333/3257 [00:13<00:04, 201.12it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2359/3257 [00:13<00:04, 218.01it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2381/3257 [00:13<00:04, 207.39it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:13<00:04, 210.92it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2426/3257 [00:13<00:04, 199.34it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2447/3257 [00:13<00:04, 189.80it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2469/3257 [00:13<00:03, 197.41it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2489/3257 [00:14<00:03, 197.75it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:14<00:03, 209.37it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2537/3257 [00:14<00:03, 212.87it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2559/3257 [00:14<00:03, 196.08it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2579/3257 [00:14<00:03, 184.28it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2599/3257 [00:14<00:03, 187.52it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2627/3257 [00:14<00:02, 212.15it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2649/3257 [00:14<00:03, 200.46it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2670/3257 [00:14<00:02, 196.48it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2691/3257 [00:15<00:02, 197.80it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2711/3257 [00:15<00:03, 176.10it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:15<00:02, 182.75it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2755/3257 [00:15<00:02, 195.34it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2775/3257 [00:15<00:02, 183.01it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2799/3257 [00:15<00:02, 198.27it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2820/3257 [00:15<00:02, 188.94it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2840/3257 [00:15<00:02, 179.15it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2865/3257 [00:15<00:01, 197.42it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:16<00:01, 198.56it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:16<00:01, 187.96it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:16<00:01, 191.88it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2948/3257 [00:16<00:01, 182.97it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2968/3257 [00:16<00:01, 187.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2987/3257 [00:16<00:01, 175.98it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:16<00:01, 192.53it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3031/3257 [00:16<00:01, 189.46it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3053/3257 [00:16<00:01, 197.86it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3076/3257 [00:17<00:00, 205.45it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3097/3257 [00:17<00:00, 195.00it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3121/3257 [00:17<00:00, 205.54it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3142/3257 [00:17<00:00, 194.16it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3162/3257 [00:17<00:00, 186.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3181/3257 [00:17<00:00, 173.41it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:17<00:00, 183.94it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3222/3257 [00:17<00:00, 181.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3245/3257 [00:17<00:00, 193.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 180.74it/s]
2023-02-07 19:38:14.996 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:38:14,996][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d217,n5,w14,mc2,s0.738133,t4>', 'datetime': '2023-02-07T19:38:14.996942', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:38:14,997][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:38:14,997][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:38:15,469][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:38:15,470][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:38:15,543][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 27186 unique words (85.48% of original 31803, drops 4617)', 'datetime': '2023-02-07T19:38:15.543482', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:38:15,543][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 5090501 word corpus (99.91% of original 5095118, drops 4617)', 'datetime': '2023-02-07T19:38:15.543863', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:38:15,640][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:38:15,640][gensim.models.word2vec][INFO] - sample=0.738133 downsamples 0 most-common words
[2023-02-07 19:38:15,641][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5090501 word corpus (100.0%% of prior 5090501)', 'datetime': '2023-02-07T19:38:15.641022', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:38:15,800][gensim.models.word2vec][INFO] - estimated required memory for 27186 words and 217 dimensions: 64266372 bytes
[2023-02-07 19:38:15,801][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:38:15,828][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 27186 vocabulary and 217 features, using sg=0 hs=0 sample=0.7381333305408877 negative=5 window=14 shrink_windows=True', 'datetime': '2023-02-07T19:38:15.828288', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:38:16,832][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 29.66% examples, 1506570 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:17,834][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 58.12% examples, 1508159 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:18,835][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 88.42% examples, 1502899 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:19,210][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5082292 effective words) took 3.4s, 1503834 effective words/s
[2023-02-07 19:38:20,221][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 29.51% examples, 1485233 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:38:21,222][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 57.29% examples, 1480749 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:22,234][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 87.53% examples, 1484912 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:38:22,628][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5082292 effective words) took 3.4s, 1487565 effective words/s
[2023-02-07 19:38:23,631][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 28.55% examples, 1453897 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:24,638][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 56.83% examples, 1473713 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:25,641][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 86.92% examples, 1481182 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:26,061][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5082292 effective words) took 3.4s, 1481548 effective words/s
[2023-02-07 19:38:27,074][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 28.65% examples, 1449226 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:28,074][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 57.78% examples, 1492570 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:29,082][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 88.70% examples, 1499735 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:29,437][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5082292 effective words) took 3.4s, 1506230 effective words/s
[2023-02-07 19:38:30,443][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 29.32% examples, 1486713 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:31,445][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 57.29% examples, 1483840 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:32,452][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 84.99% examples, 1447080 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:32,959][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5082292 effective words) took 3.5s, 1443837 effective words/s
[2023-02-07 19:38:33,968][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 27.14% examples, 1384448 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:34,976][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 53.85% examples, 1393546 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:38:35,978][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 81.70% examples, 1389423 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:36,620][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5082292 effective words) took 3.7s, 1389055 effective words/s
[2023-02-07 19:38:37,623][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 27.02% examples, 1382933 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:38,625][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.18% examples, 1384159 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:39,630][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 81.98% examples, 1396392 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:38:40,134][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5082292 effective words) took 3.5s, 1447456 effective words/s
[2023-02-07 19:38:41,137][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 33.59% examples, 1728921 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:42,141][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 65.77% examples, 1700846 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:43,097][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5082292 effective words) took 3.0s, 1715890 effective words/s
[2023-02-07 19:38:44,105][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 29.08% examples, 1473377 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:45,115][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 55.76% examples, 1439905 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:38:46,117][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 84.99% examples, 1444609 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:46,558][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5082292 effective words) took 3.5s, 1469142 effective words/s
[2023-02-07 19:38:47,563][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 33.34% examples, 1700474 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:48,568][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 63.37% examples, 1632375 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:49,568][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 93.74% examples, 1590809 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:49,752][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5082292 effective words) took 3.2s, 1592261 effective words/s
[2023-02-07 19:38:50,759][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 30.37% examples, 1542528 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:51,761][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 56.83% examples, 1473573 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:52,763][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 84.03% examples, 1433293 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:53,310][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5082292 effective words) took 3.6s, 1428981 effective words/s
[2023-02-07 19:38:54,313][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 27.66% examples, 1409416 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:55,318][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 59.75% examples, 1542421 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:56,319][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 90.51% examples, 1540682 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:56,610][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5082292 effective words) took 3.3s, 1540933 effective words/s
[2023-02-07 19:38:57,613][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 30.06% examples, 1532979 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:58,616][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 56.37% examples, 1466761 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:38:59,629][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 84.03% examples, 1429742 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:00,186][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5082292 effective words) took 3.6s, 1422155 effective words/s
[2023-02-07 19:39:01,188][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 27.02% examples, 1383025 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:02,193][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 59.47% examples, 1538669 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:39:03,195][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 90.48% examples, 1537281 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:03,499][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5082292 effective words) took 3.3s, 1535088 effective words/s
[2023-02-07 19:39:04,506][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 29.51% examples, 1491329 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:05,516][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 55.11% examples, 1421525 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:06,519][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 82.68% examples, 1402565 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:39:07,164][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5082292 effective words) took 3.7s, 1387362 effective words/s
[2023-02-07 19:39:07,164][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76234380 effective words) took 51.3s, 1485031 effective words/s', 'datetime': '2023-02-07T19:39:07.164730', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:39:07.165 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:39:10,993][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193746-ukj1v1od/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:39:10.993615', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:39:10,994][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:39:11,097][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193746-ukj1v1od/files/../tmp/embedding_model.pt
2023-02-07 19:39:11.098 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:39:12.871 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:39:13.495 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:39:14.875 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.2744865723263943, 'test_mae': 0.8826692463155904, 'test_r2': -4.618308471233451}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.0
wandb: percentage 0.14517
wandb:   test_mae 0.88267
wandb:   test_mse 1.27449
wandb:    test_r2 -4.61831
wandb: 
wandb: üöÄ View run helpful-sweep-51 at: https://wandb.ai/xiaoqiz/mof2vec/runs/ukj1v1od
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_193746-ukj1v1od/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: k75i6mky with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 93
wandb: 	model.gensim.alpha: 0.8772629369092166
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.8297418249658646
wandb: 	model.gensim.vector_size: 79
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.4820042698333494
wandb: 	model.sklearn.max_depth: 32
wandb: 	model.sklearn.min_child_weight: 0.0039810712222940635
wandb: 	model.sklearn.n_estimators: 2509
wandb: 	model.sklearn.num_leaves: 229
wandb: 	model.sklearn.reg_alpha: 0.3269733488372804
wandb: 	model.sklearn.reg_lambda: 0.005835173891767857
wandb: 	model.sklearn.subsample: 0.2227534310675796
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193933-k75i6mky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-52
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/k75i6mky
2023-02-07 19:39:42.004 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 19:39:42.005 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 93 for sweep.
2023-02-07 19:39:42.005 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.8772629369092166 for sweep.
2023-02-07 19:39:42.005 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:39:42.006 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 19:39:42.006 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8297418249658646 for sweep.
2023-02-07 19:39:42.006 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 79 for sweep.
2023-02-07 19:39:42.006 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 19:39:42.006 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.4820042698333494 for sweep.
2023-02-07 19:39:42.007 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 32 for sweep.
2023-02-07 19:39:42.007 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0039810712222940635 for sweep.
2023-02-07 19:39:42.007 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2509 for sweep.
2023-02-07 19:39:42.007 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 229 for sweep.
2023-02-07 19:39:42.008 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.3269733488372804 for sweep.
2023-02-07 19:39:42.008 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.005835173891767857 for sweep.
2023-02-07 19:39:42.008 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.2227534310675796 for sweep.
2023-02-07 19:39:42.009 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:39:42.017 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193933-k75i6mky/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 93, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 79, 'window': 11, 'min_count': 5, 'dm': 0, 'sample': 0.8297418249658646, 'workers': 4, 'alpha': 0.8772629369092166, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2509, 'max_depth': 32, 'num_leaves': 229, 'reg_alpha': 0.3269733488372804, 'reg_lambda': 0.005835173891767857, 'subsample': 0.2227534310675796, 'min_child_weight': 0.0039810712222940635, 'n_jobs': 4, 'learning_rate': 0.4820042698333494}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 24/3257 [00:00<00:13, 234.18it/s]  2%|‚ñè         | 49/3257 [00:00<00:13, 240.76it/s]  2%|‚ñè         | 74/3257 [00:00<00:13, 242.47it/s]  3%|‚ñé         | 99/3257 [00:00<00:20, 152.55it/s]  4%|‚ñé         | 121/3257 [00:00<00:18, 167.54it/s]  5%|‚ñç         | 150/3257 [00:00<00:15, 199.30it/s]  5%|‚ñå         | 173/3257 [00:00<00:14, 206.22it/s]  6%|‚ñå         | 200/3257 [00:00<00:13, 223.96it/s]  7%|‚ñã         | 230/3257 [00:01<00:12, 239.36it/s]  8%|‚ñä         | 256/3257 [00:01<00:12, 239.24it/s]  9%|‚ñä         | 283/3257 [00:01<00:12, 246.82it/s]  9%|‚ñâ         | 309/3257 [00:01<00:12, 242.02it/s] 10%|‚ñà         | 334/3257 [00:01<00:11, 243.94it/s] 11%|‚ñà         | 361/3257 [00:01<00:11, 250.98it/s] 12%|‚ñà‚ñè        | 387/3257 [00:01<00:12, 238.65it/s] 13%|‚ñà‚ñé        | 412/3257 [00:01<00:11, 241.23it/s] 13%|‚ñà‚ñé        | 437/3257 [00:01<00:13, 215.12it/s] 14%|‚ñà‚ñç        | 464/3257 [00:02<00:12, 229.07it/s] 15%|‚ñà‚ñç        | 488/3257 [00:02<00:12, 230.09it/s] 16%|‚ñà‚ñå        | 517/3257 [00:02<00:11, 245.54it/s] 17%|‚ñà‚ñã        | 543/3257 [00:02<00:10, 248.68it/s] 17%|‚ñà‚ñã        | 569/3257 [00:02<00:11, 234.05it/s] 18%|‚ñà‚ñä        | 593/3257 [00:02<00:11, 227.05it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:02<00:11, 232.05it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:02<00:11, 231.54it/s] 21%|‚ñà‚ñà        | 669/3257 [00:02<00:11, 225.96it/s] 21%|‚ñà‚ñà        | 692/3257 [00:03<00:11, 224.20it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:03<00:10, 231.94it/s] 23%|‚ñà‚ñà‚ñé       | 742/3257 [00:03<00:11, 216.15it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:03<00:10, 228.67it/s] 24%|‚ñà‚ñà‚ñç       | 794/3257 [00:03<00:10, 227.36it/s] 25%|‚ñà‚ñà‚ñå       | 818/3257 [00:03<00:10, 229.91it/s] 26%|‚ñà‚ñà‚ñå       | 842/3257 [00:03<00:11, 218.75it/s] 27%|‚ñà‚ñà‚ñã       | 865/3257 [00:03<00:10, 219.76it/s] 27%|‚ñà‚ñà‚ñã       | 888/3257 [00:03<00:10, 220.55it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:04<00:10, 230.52it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:04<00:09, 235.83it/s] 30%|‚ñà‚ñà‚ñâ       | 967/3257 [00:04<00:09, 245.97it/s] 30%|‚ñà‚ñà‚ñà       | 992/3257 [00:04<00:09, 236.09it/s] 31%|‚ñà‚ñà‚ñà       | 1016/3257 [00:04<00:09, 233.00it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1040/3257 [00:04<00:09, 227.58it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1063/3257 [00:04<00:09, 226.22it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1087/3257 [00:04<00:09, 229.18it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:04<00:09, 232.46it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1136/3257 [00:04<00:09, 226.66it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1159/3257 [00:05<00:09, 227.08it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1182/3257 [00:05<00:09, 218.74it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:05<00:09, 211.36it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1230/3257 [00:05<00:09, 224.94it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1254/3257 [00:05<00:08, 228.53it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:05<00:08, 220.07it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1300/3257 [00:05<00:08, 219.99it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1327/3257 [00:05<00:08, 233.35it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1351/3257 [00:05<00:08, 227.99it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1374/3257 [00:06<00:08, 221.60it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1401/3257 [00:06<00:07, 232.57it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1425/3257 [00:06<00:10, 169.97it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1453/3257 [00:06<00:09, 193.83it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1481/3257 [00:06<00:08, 214.34it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1510/3257 [00:06<00:07, 233.47it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1536/3257 [00:06<00:08, 208.04it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1559/3257 [00:06<00:08, 202.57it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1581/3257 [00:07<00:08, 200.57it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1603/3257 [00:07<00:08, 205.23it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1625/3257 [00:07<00:07, 207.51it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1647/3257 [00:07<00:07, 201.44it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:07<00:08, 195.13it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1688/3257 [00:07<00:08, 193.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:07<00:07, 193.96it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:07<00:08, 188.44it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1748/3257 [00:07<00:07, 189.44it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1770/3257 [00:08<00:07, 196.18it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:08<00:07, 196.63it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1810/3257 [00:08<00:07, 186.43it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1829/3257 [00:08<00:07, 185.31it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1851/3257 [00:08<00:07, 194.01it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1873/3257 [00:08<00:06, 201.31it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1894/3257 [00:08<00:06, 197.48it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:08<00:06, 200.44it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1938/3257 [00:08<00:06, 204.88it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1963/3257 [00:09<00:05, 217.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1985/3257 [00:09<00:06, 207.15it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2006/3257 [00:09<00:06, 207.89it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2029/3257 [00:09<00:05, 212.31it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2051/3257 [00:09<00:06, 192.91it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2071/3257 [00:09<00:06, 191.76it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2092/3257 [00:09<00:05, 195.09it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2112/3257 [00:09<00:06, 189.18it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:09<00:06, 180.20it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2151/3257 [00:10<00:06, 180.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2173/3257 [00:10<00:05, 190.14it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2193/3257 [00:10<00:05, 189.67it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2213/3257 [00:10<00:05, 185.57it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:10<00:05, 193.64it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2256/3257 [00:10<00:05, 191.49it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:10<00:05, 184.77it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:10<00:04, 196.78it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2322/3257 [00:10<00:04, 205.16it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2345/3257 [00:10<00:04, 212.23it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2367/3257 [00:11<00:04, 211.13it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2392/3257 [00:11<00:03, 220.07it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2415/3257 [00:11<00:04, 203.88it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2436/3257 [00:11<00:04, 193.53it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2456/3257 [00:11<00:04, 190.28it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2479/3257 [00:11<00:03, 198.67it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2502/3257 [00:11<00:03, 205.51it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2523/3257 [00:11<00:03, 205.69it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2545/3257 [00:11<00:03, 208.03it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2566/3257 [00:12<00:03, 195.62it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:12<00:03, 190.22it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2610/3257 [00:12<00:03, 202.39it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:12<00:02, 210.33it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:12<00:02, 201.71it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2677/3257 [00:12<00:02, 198.52it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2697/3257 [00:12<00:02, 191.18it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2717/3257 [00:13<00:05, 103.19it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:13<00:04, 126.94it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:13<00:03, 138.34it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:13<00:03, 147.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:13<00:02, 167.04it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:13<00:02, 171.39it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:13<00:02, 171.19it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2866/3257 [00:13<00:02, 188.95it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2889/3257 [00:14<00:01, 197.02it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2910/3257 [00:14<00:01, 192.24it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2930/3257 [00:14<00:01, 188.60it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:14<00:01, 182.94it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2972/3257 [00:14<00:01, 190.36it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2992/3257 [00:14<00:01, 183.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:14<00:01, 194.48it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3037/3257 [00:14<00:01, 198.68it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3060/3257 [00:14<00:00, 206.24it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3084/3257 [00:15<00:00, 214.34it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3112/3257 [00:15<00:00, 232.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3138/3257 [00:15<00:00, 239.90it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3163/3257 [00:15<00:00, 242.82it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3188/3257 [00:15<00:00, 240.56it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3214/3257 [00:15<00:00, 242.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:15<00:00, 259.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:15<00:00, 207.85it/s]
2023-02-07 19:39:58.123 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:39:58,124][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d79,n5,mc5,s0.829742,t4>', 'datetime': '2023-02-07T19:39:58.124841', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:39:58,125][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:39:58,125][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:39:58,442][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 19:39:58,442][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:39:58,461][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 6948 unique words (53.20% of original 13061, drops 6113)', 'datetime': '2023-02-07T19:39:58.461640', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:39:58,461][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 3624596 word corpus (99.59% of original 3639370, drops 14774)', 'datetime': '2023-02-07T19:39:58.461971', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:39:58,485][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 19:39:58,485][gensim.models.word2vec][INFO] - sample=0.829742 downsamples 0 most-common words
[2023-02-07 19:39:58,486][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3624596 word corpus (100.0%% of prior 3624596)', 'datetime': '2023-02-07T19:39:58.486046', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:39:58,526][gensim.models.word2vec][INFO] - estimated required memory for 6948 words and 79 dimensions: 9545748 bytes
[2023-02-07 19:39:58,527][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:39:58,530][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 6948 vocabulary and 79 features, using sg=1 hs=0 sample=0.8297418249658646 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T19:39:58.530433', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:39:59,122][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3627853 effective words) took 0.6s, 6150782 effective words/s
[2023-02-07 19:39:59,726][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3627853 effective words) took 0.6s, 6020127 effective words/s
[2023-02-07 19:40:00,340][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3627853 effective words) took 0.6s, 5933255 effective words/s
[2023-02-07 19:40:00,941][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3627853 effective words) took 0.6s, 6043631 effective words/s
[2023-02-07 19:40:01,547][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3627853 effective words) took 0.6s, 5998083 effective words/s
[2023-02-07 19:40:02,149][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3627853 effective words) took 0.6s, 6043892 effective words/s
[2023-02-07 19:40:02,760][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3627853 effective words) took 0.6s, 5948636 effective words/s
[2023-02-07 19:40:03,362][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3627853 effective words) took 0.6s, 6045269 effective words/s
[2023-02-07 19:40:03,963][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3627853 effective words) took 0.6s, 6047431 effective words/s
[2023-02-07 19:40:04,562][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3627853 effective words) took 0.6s, 6074727 effective words/s
[2023-02-07 19:40:05,159][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3627853 effective words) took 0.6s, 6094697 effective words/s
[2023-02-07 19:40:05,755][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3627853 effective words) took 0.6s, 6097657 effective words/s
[2023-02-07 19:40:06,349][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3627853 effective words) took 0.6s, 6122680 effective words/s
[2023-02-07 19:40:06,939][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3627853 effective words) took 0.6s, 6161326 effective words/s
[2023-02-07 19:40:07,531][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3627853 effective words) took 0.6s, 6143011 effective words/s
[2023-02-07 19:40:07,531][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54417795 effective words) took 9.0s, 6046349 effective words/s', 'datetime': '2023-02-07T19:40:07.531693', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:40:07.531 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:40:08,678][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193933-k75i6mky/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:40:08.678164', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:40:08,678][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:40:08,699][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_193933-k75i6mky/files/../tmp/embedding_model.pt
2023-02-07 19:40:08.700 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:40:09.889 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:40:10.355 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:40:10.965 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.3742631544343489, 'test_mae': 0.9243481415638163, 'test_r2': -3.7337070520178353}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.0
wandb: percentage 0.46803
wandb:   test_mae 0.92435
wandb:   test_mse 1.37426
wandb:    test_r2 -3.73371
wandb: 
wandb: üöÄ View run youthful-sweep-52 at: https://wandb.ai/xiaoqiz/mof2vec/runs/k75i6mky
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_193933-k75i6mky/logs
wandb: Agent Starting Run: 4p4bt8br with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 913
wandb: 	model.gensim.alpha: 0.002691187127096861
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.4907495040994137
wandb: 	model.gensim.vector_size: 393
wandb: 	model.gensim.window: 13
wandb: 	model.sklearn.learning_rate: 0.0007724949792951947
wandb: 	model.sklearn.max_depth: 35
wandb: 	model.sklearn.min_child_weight: 0.0742757596788031
wandb: 	model.sklearn.n_estimators: 1784
wandb: 	model.sklearn.num_leaves: 71
wandb: 	model.sklearn.reg_alpha: 0.003650336917552097
wandb: 	model.sklearn.reg_lambda: 0.06449542667905339
wandb: 	model.sklearn.subsample: 0.7326742328777307
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194020-4p4bt8br
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-53
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/4p4bt8br
2023-02-07 19:40:29.378 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 19:40:29.379 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 913 for sweep.
2023-02-07 19:40:29.380 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.002691187127096861 for sweep.
2023-02-07 19:40:29.380 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:40:29.380 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 19:40:29.381 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4907495040994137 for sweep.
2023-02-07 19:40:29.381 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 393 for sweep.
2023-02-07 19:40:29.381 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 13 for sweep.
2023-02-07 19:40:29.382 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0007724949792951947 for sweep.
2023-02-07 19:40:29.382 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 35 for sweep.
2023-02-07 19:40:29.382 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0742757596788031 for sweep.
2023-02-07 19:40:29.382 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1784 for sweep.
2023-02-07 19:40:29.382 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 71 for sweep.
2023-02-07 19:40:29.383 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.003650336917552097 for sweep.
2023-02-07 19:40:29.383 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.06449542667905339 for sweep.
2023-02-07 19:40:29.383 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7326742328777307 for sweep.
2023-02-07 19:40:29.383 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:40:29.394 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194020-4p4bt8br/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 913, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 393, 'window': 13, 'min_count': 9, 'dm': 0, 'sample': 0.4907495040994137, 'workers': 4, 'alpha': 0.002691187127096861, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1784, 'max_depth': 35, 'num_leaves': 71, 'reg_alpha': 0.003650336917552097, 'reg_lambda': 0.06449542667905339, 'subsample': 0.7326742328777307, 'min_child_weight': 0.0742757596788031, 'n_jobs': 4, 'learning_rate': 0.0007724949792951947}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:22, 146.15it/s]  1%|          | 32/3257 [00:00<00:20, 156.55it/s]  1%|‚ñè         | 48/3257 [00:00<00:21, 148.43it/s]  2%|‚ñè         | 63/3257 [00:00<00:21, 146.34it/s]  2%|‚ñè         | 79/3257 [00:00<00:21, 151.02it/s]  3%|‚ñé         | 95/3257 [00:00<00:21, 145.59it/s]  3%|‚ñé         | 110/3257 [00:00<00:22, 138.34it/s]  4%|‚ñç         | 125/3257 [00:00<00:22, 141.32it/s]  4%|‚ñç         | 143/3257 [00:00<00:20, 152.27it/s]  5%|‚ñç         | 159/3257 [00:01<00:20, 148.33it/s]  5%|‚ñå         | 174/3257 [00:01<00:21, 142.01it/s]  6%|‚ñå         | 192/3257 [00:01<00:20, 151.79it/s]  6%|‚ñã         | 208/3257 [00:01<00:20, 151.36it/s]  7%|‚ñã         | 227/3257 [00:01<00:18, 160.32it/s]  7%|‚ñã         | 244/3257 [00:01<00:19, 155.87it/s]  8%|‚ñä         | 260/3257 [00:01<00:20, 148.06it/s]  9%|‚ñä         | 279/3257 [00:01<00:19, 156.68it/s]  9%|‚ñâ         | 296/3257 [00:01<00:18, 158.65it/s] 10%|‚ñâ         | 312/3257 [00:02<00:19, 149.49it/s] 10%|‚ñà         | 330/3257 [00:02<00:18, 156.70it/s] 11%|‚ñà         | 346/3257 [00:02<00:19, 149.58it/s] 11%|‚ñà         | 362/3257 [00:02<00:19, 151.97it/s] 12%|‚ñà‚ñè        | 378/3257 [00:02<00:19, 144.19it/s] 12%|‚ñà‚ñè        | 393/3257 [00:02<00:20, 140.95it/s] 13%|‚ñà‚ñé        | 410/3257 [00:02<00:19, 148.16it/s] 13%|‚ñà‚ñé        | 425/3257 [00:02<00:21, 134.18it/s] 13%|‚ñà‚ñé        | 439/3257 [00:03<00:22, 126.60it/s] 14%|‚ñà‚ñç        | 455/3257 [00:03<00:20, 133.95it/s] 14%|‚ñà‚ñç        | 470/3257 [00:03<00:20, 136.68it/s] 15%|‚ñà‚ñç        | 484/3257 [00:03<00:20, 133.06it/s] 15%|‚ñà‚ñå        | 501/3257 [00:03<00:19, 141.86it/s] 16%|‚ñà‚ñå        | 517/3257 [00:03<00:19, 143.83it/s] 16%|‚ñà‚ñã        | 532/3257 [00:03<00:19, 138.10it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:19, 137.88it/s] 17%|‚ñà‚ñã        | 560/3257 [00:03<00:20, 131.38it/s] 18%|‚ñà‚ñä        | 574/3257 [00:04<00:21, 126.70it/s] 18%|‚ñà‚ñä        | 589/3257 [00:04<00:20, 131.99it/s] 19%|‚ñà‚ñä        | 605/3257 [00:04<00:19, 138.38it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:04<00:18, 139.26it/s] 19%|‚ñà‚ñâ        | 635/3257 [00:04<00:27, 95.86it/s]  20%|‚ñà‚ñâ        | 647/3257 [00:04<00:26, 99.45it/s] 20%|‚ñà‚ñà        | 659/3257 [00:04<00:25, 102.53it/s] 21%|‚ñà‚ñà        | 676/3257 [00:04<00:22, 117.05it/s] 21%|‚ñà‚ñà        | 689/3257 [00:05<00:21, 118.33it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:05<00:20, 126.06it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:05<00:18, 134.11it/s] 23%|‚ñà‚ñà‚ñé       | 734/3257 [00:05<00:18, 134.45it/s] 23%|‚ñà‚ñà‚ñé       | 748/3257 [00:05<00:19, 131.59it/s] 23%|‚ñà‚ñà‚ñé       | 764/3257 [00:05<00:17, 139.47it/s] 24%|‚ñà‚ñà‚ñç       | 779/3257 [00:05<00:18, 134.25it/s] 24%|‚ñà‚ñà‚ñç       | 793/3257 [00:05<00:18, 135.36it/s] 25%|‚ñà‚ñà‚ñç       | 807/3257 [00:05<00:18, 135.98it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:05<00:17, 137.49it/s] 26%|‚ñà‚ñà‚ñå       | 838/3257 [00:06<00:17, 140.29it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:06<00:17, 139.18it/s] 27%|‚ñà‚ñà‚ñã       | 873/3257 [00:06<00:15, 156.10it/s] 27%|‚ñà‚ñà‚ñã       | 892/3257 [00:06<00:14, 163.91it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:06<00:13, 172.40it/s] 29%|‚ñà‚ñà‚ñä       | 934/3257 [00:06<00:12, 179.85it/s] 29%|‚ñà‚ñà‚ñâ       | 957/3257 [00:06<00:11, 192.52it/s] 30%|‚ñà‚ñà‚ñâ       | 977/3257 [00:06<00:11, 191.22it/s] 31%|‚ñà‚ñà‚ñà       | 997/3257 [00:06<00:12, 182.07it/s] 31%|‚ñà‚ñà‚ñà       | 1016/3257 [00:07<00:12, 184.00it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1035/3257 [00:07<00:12, 181.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1054/3257 [00:07<00:12, 178.36it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1076/3257 [00:07<00:11, 189.85it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1096/3257 [00:07<00:12, 175.88it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:07<00:12, 175.38it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1133/3257 [00:07<00:12, 165.97it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1150/3257 [00:07<00:13, 160.95it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:07<00:12, 172.00it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1189/3257 [00:08<00:13, 154.20it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:08<00:13, 154.86it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1222/3257 [00:08<00:12, 157.85it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:08<00:12, 167.17it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1259/3257 [00:08<00:12, 163.68it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1276/3257 [00:08<00:12, 157.37it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:08<00:13, 149.12it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:08<00:12, 152.00it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1325/3257 [00:08<00:12, 156.23it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1343/3257 [00:09<00:11, 161.92it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1360/3257 [00:09<00:11, 159.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1376/3257 [00:09<00:11, 157.80it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1392/3257 [00:09<00:11, 158.04it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1413/3257 [00:09<00:10, 171.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:09<00:10, 176.87it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:09<00:10, 179.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1472/3257 [00:09<00:09, 180.01it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1491/3257 [00:09<00:09, 178.55it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:10<00:09, 181.41it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:10<00:10, 163.10it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1547/3257 [00:10<00:11, 152.77it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1565/3257 [00:10<00:10, 156.65it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1581/3257 [00:10<00:10, 155.02it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1600/3257 [00:10<00:10, 163.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1618/3257 [00:10<00:09, 166.92it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:10<00:10, 158.48it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1652/3257 [00:10<00:10, 154.96it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:11<00:10, 155.82it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1684/3257 [00:11<00:10, 154.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1703/3257 [00:11<00:09, 164.27it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1720/3257 [00:11<00:09, 163.26it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1737/3257 [00:11<00:10, 148.95it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1756/3257 [00:11<00:09, 159.03it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1774/3257 [00:11<00:09, 163.04it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1793/3257 [00:11<00:08, 168.94it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1811/3257 [00:11<00:09, 157.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:12<00:09, 155.12it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:12<00:08, 161.14it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1867/3257 [00:12<00:07, 174.04it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1885/3257 [00:12<00:08, 167.48it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1903/3257 [00:12<00:08, 169.24it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1921/3257 [00:12<00:13, 98.93it/s]  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1943/3257 [00:12<00:10, 121.33it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:13<00:09, 138.72it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1983/3257 [00:13<00:08, 142.26it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2003/3257 [00:13<00:08, 154.68it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2021/3257 [00:13<00:07, 161.06it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2039/3257 [00:13<00:07, 158.38it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2056/3257 [00:13<00:08, 149.72it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2073/3257 [00:13<00:07, 154.69it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:13<00:07, 159.96it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2108/3257 [00:13<00:07, 160.97it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2125/3257 [00:14<00:07, 152.81it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2142/3257 [00:14<00:07, 155.89it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2160/3257 [00:14<00:06, 157.96it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2179/3257 [00:14<00:06, 165.92it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2197/3257 [00:14<00:06, 168.16it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2214/3257 [00:14<00:06, 159.84it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2235/3257 [00:14<00:05, 172.80it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2253/3257 [00:14<00:05, 167.85it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:14<00:05, 165.92it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2290/3257 [00:15<00:05, 173.65it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2308/3257 [00:15<00:05, 174.08it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2335/3257 [00:15<00:04, 198.23it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:15<00:04, 205.81it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2381/3257 [00:15<00:04, 206.39it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2402/3257 [00:15<00:04, 206.21it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2423/3257 [00:15<00:04, 193.58it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:15<00:04, 182.50it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2468/3257 [00:15<00:03, 199.34it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2489/3257 [00:15<00:03, 200.16it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2510/3257 [00:16<00:03, 200.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2531/3257 [00:16<00:03, 190.00it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2551/3257 [00:16<00:04, 175.04it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2569/3257 [00:16<00:04, 155.14it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:16<00:04, 151.26it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2603/3257 [00:16<00:04, 155.05it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2625/3257 [00:16<00:03, 171.56it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2643/3257 [00:16<00:03, 165.69it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2660/3257 [00:17<00:03, 155.16it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2679/3257 [00:17<00:03, 161.89it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2696/3257 [00:17<00:03, 154.07it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2712/3257 [00:17<00:03, 142.49it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2729/3257 [00:17<00:03, 148.68it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2747/3257 [00:17<00:03, 154.30it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2763/3257 [00:17<00:03, 151.56it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:17<00:03, 149.41it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2797/3257 [00:17<00:02, 157.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:18<00:02, 151.32it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2829/3257 [00:18<00:03, 138.13it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2844/3257 [00:18<00:02, 140.20it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2865/3257 [00:18<00:02, 158.65it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2885/3257 [00:18<00:02, 168.01it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:18<00:02, 148.86it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:18<00:02, 152.25it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2936/3257 [00:18<00:02, 150.17it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2952/3257 [00:19<00:02, 139.15it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:19<00:01, 145.81it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:19<00:01, 138.44it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3003/3257 [00:19<00:01, 149.94it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3019/3257 [00:19<00:01, 146.80it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3037/3257 [00:19<00:01, 154.58it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3053/3257 [00:19<00:01, 155.06it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3072/3257 [00:19<00:01, 163.49it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3089/3257 [00:19<00:01, 158.12it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3107/3257 [00:20<00:00, 162.96it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3124/3257 [00:20<00:00, 163.39it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3141/3257 [00:20<00:00, 152.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3157/3257 [00:20<00:00, 147.65it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3172/3257 [00:20<00:00, 145.99it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3187/3257 [00:20<00:00, 143.06it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3204/3257 [00:20<00:00, 149.24it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3219/3257 [00:20<00:00, 142.87it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3238/3257 [00:20<00:00, 155.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3254/3257 [00:21<00:00, 154.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 154.92it/s]
2023-02-07 19:40:51.359 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:40:51,361][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d393,n5,mc9,s0.49075,t4>', 'datetime': '2023-02-07T19:40:51.361253', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:40:51,362][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:40:51,363][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:40:51,970][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 19:40:51,971][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:40:52,020][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 14828 unique words (34.73% of original 42701, drops 27873)', 'datetime': '2023-02-07T19:40:52.020692', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:40:52,021][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 5723647 word corpus (98.29% of original 5822992, drops 99345)', 'datetime': '2023-02-07T19:40:52.021120', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:40:52,074][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 19:40:52,076][gensim.models.word2vec][INFO] - sample=0.49075 downsamples 0 most-common words
[2023-02-07 19:40:52,076][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5723647 word corpus (100.0%% of prior 5723647)', 'datetime': '2023-02-07T19:40:52.076651', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:40:52,171][gensim.models.word2vec][INFO] - estimated required memory for 14828 words and 393 dimensions: 59804636 bytes
[2023-02-07 19:40:52,171][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:40:52,204][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14828 vocabulary and 393 features, using sg=1 hs=0 sample=0.4907495040994137 negative=5 window=13 shrink_windows=True', 'datetime': '2023-02-07T19:40:52.204044', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:40:53,213][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 28.00% examples, 1591754 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:40:54,216][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 60.30% examples, 1736491 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:40:55,220][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 96.07% examples, 1817689 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:40:55,338][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5697932 effective words) took 3.1s, 1819630 effective words/s
[2023-02-07 19:40:56,340][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 33.13% examples, 1903602 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:40:57,342][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 65.77% examples, 1910031 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:40:58,317][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5697932 effective words) took 3.0s, 1913880 effective words/s
[2023-02-07 19:40:59,320][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 33.16% examples, 1913561 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:00,328][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 65.83% examples, 1909157 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:01,305][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5697932 effective words) took 3.0s, 1908559 effective words/s
[2023-02-07 19:41:02,308][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 34.02% examples, 1958802 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:03,312][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 68.04% examples, 1973682 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:04,265][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5697932 effective words) took 3.0s, 1926272 effective words/s
[2023-02-07 19:41:05,268][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 29.57% examples, 1686190 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:06,275][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 58.15% examples, 1688862 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:07,278][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 89.13% examples, 1698811 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:07,617][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5697932 effective words) took 3.3s, 1701328 effective words/s
[2023-02-07 19:41:08,622][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 29.81% examples, 1701267 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:09,626][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 58.80% examples, 1704305 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:10,629][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 89.13% examples, 1699769 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:10,967][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5697932 effective words) took 3.3s, 1702466 effective words/s
[2023-02-07 19:41:11,970][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 29.57% examples, 1687154 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:12,972][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 65.37% examples, 1897478 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:13,906][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5697932 effective words) took 2.9s, 1940664 effective words/s
[2023-02-07 19:41:14,914][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 33.71% examples, 1935604 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:15,921][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 66.99% examples, 1937876 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:41:16,860][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5697932 effective words) took 3.0s, 1930216 effective words/s
[2023-02-07 19:41:17,870][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 33.25% examples, 1908462 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:41:18,872][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 65.83% examples, 1908347 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:41:19,827][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5697932 effective words) took 3.0s, 1922666 effective words/s
[2023-02-07 19:41:20,833][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 34.33% examples, 1972254 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:21,838][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 68.65% examples, 1987699 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:22,818][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5697932 effective words) took 3.0s, 1906578 effective words/s
[2023-02-07 19:41:23,826][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 30.40% examples, 1726565 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:24,826][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 59.69% examples, 1725862 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:25,839][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 90.48% examples, 1716868 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:41:26,127][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5697932 effective words) took 3.3s, 1722792 effective words/s
[2023-02-07 19:41:27,136][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 30.33% examples, 1729613 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:28,143][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 60.58% examples, 1741148 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:29,143][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 91.62% examples, 1746981 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:29,390][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5697932 effective words) took 3.3s, 1747881 effective words/s
[2023-02-07 19:41:30,404][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 30.92% examples, 1757139 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:41:31,407][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 69.48% examples, 2008697 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:32,236][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5697932 effective words) took 2.8s, 2003219 effective words/s
[2023-02-07 19:41:33,242][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 34.45% examples, 1980764 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:34,244][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 68.35% examples, 1982274 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:35,124][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5697932 effective words) took 2.9s, 1974736 effective words/s
[2023-02-07 19:41:36,126][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 34.26% examples, 1971887 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:37,129][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 67.79% examples, 1966831 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:41:38,008][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5697932 effective words) took 2.9s, 1976208 effective words/s
[2023-02-07 19:41:38,009][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85468980 effective words) took 45.8s, 1865938 effective words/s', 'datetime': '2023-02-07T19:41:38.009348', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:41:38.010 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:41:42,228][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194020-4p4bt8br/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:41:42.228611', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:41:42,229][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:41:42,319][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194020-4p4bt8br/files/../tmp/embedding_model.pt
2023-02-07 19:41:42.319 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:41:44.778 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:41:45.593 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:41:48.290 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0413746881981791, 'test_mae': 0.7897953848623059, 'test_r2': -2.371393430382191}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.6
wandb: percentage 0.65275
wandb:   test_mae 0.7898
wandb:   test_mse 1.04137
wandb:    test_r2 -2.37139
wandb: 
wandb: üöÄ View run balmy-sweep-53 at: https://wandb.ai/xiaoqiz/mof2vec/runs/4p4bt8br
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_194020-4p4bt8br/logs
wandb: Agent Starting Run: 4pk33kv4 with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 361
wandb: 	model.gensim.alpha: 0.000498655049747631
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.5377031447096976
wandb: 	model.gensim.vector_size: 283
wandb: 	model.gensim.window: 7
wandb: 	model.sklearn.learning_rate: 0.06017351191200085
wandb: 	model.sklearn.max_depth: 24
wandb: 	model.sklearn.min_child_weight: 0.03776852700819249
wandb: 	model.sklearn.n_estimators: 1952
wandb: 	model.sklearn.num_leaves: 44
wandb: 	model.sklearn.reg_alpha: 0.014409587173047106
wandb: 	model.sklearn.reg_lambda: 0.5188143930574112
wandb: 	model.sklearn.subsample: 0.9359934402474088
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194201-4pk33kv4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-54
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/4pk33kv4
2023-02-07 19:42:09.990 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:42:09.990 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 361 for sweep.
2023-02-07 19:42:09.990 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.000498655049747631 for sweep.
2023-02-07 19:42:09.991 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:42:09.992 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 19:42:09.992 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5377031447096976 for sweep.
2023-02-07 19:42:09.992 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 283 for sweep.
2023-02-07 19:42:09.992 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 7 for sweep.
2023-02-07 19:42:09.993 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.06017351191200085 for sweep.
2023-02-07 19:42:09.993 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 24 for sweep.
2023-02-07 19:42:09.993 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03776852700819249 for sweep.
2023-02-07 19:42:09.993 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1952 for sweep.
2023-02-07 19:42:09.994 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 44 for sweep.
2023-02-07 19:42:09.994 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.014409587173047106 for sweep.
2023-02-07 19:42:09.994 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.5188143930574112 for sweep.
2023-02-07 19:42:09.994 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9359934402474088 for sweep.
2023-02-07 19:42:09.995 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:42:10.001 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194201-4pk33kv4/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 361, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 283, 'window': 7, 'min_count': 6, 'dm': 0, 'sample': 0.5377031447096976, 'workers': 4, 'alpha': 0.000498655049747631, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1952, 'max_depth': 24, 'num_leaves': 44, 'reg_alpha': 0.014409587173047106, 'reg_lambda': 0.5188143930574112, 'subsample': 0.9359934402474088, 'min_child_weight': 0.03776852700819249, 'n_jobs': 4, 'learning_rate': 0.06017351191200085}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:20, 154.75it/s]  1%|          | 33/3257 [00:00<00:20, 158.63it/s]  2%|‚ñè         | 49/3257 [00:00<00:20, 153.67it/s]  2%|‚ñè         | 67/3257 [00:00<00:21, 149.53it/s]  3%|‚ñé         | 89/3257 [00:00<00:18, 170.45it/s]  3%|‚ñé         | 107/3257 [00:00<00:20, 153.95it/s]  4%|‚ñç         | 124/3257 [00:00<00:20, 156.11it/s]  4%|‚ñç         | 145/3257 [00:00<00:18, 168.30it/s]  5%|‚ñå         | 163/3257 [00:01<00:26, 116.24it/s]  6%|‚ñå         | 180/3257 [00:01<00:24, 127.77it/s]  6%|‚ñå         | 200/3257 [00:01<00:21, 144.66it/s]  7%|‚ñã         | 219/3257 [00:01<00:19, 153.71it/s]  7%|‚ñã         | 238/3257 [00:01<00:18, 162.37it/s]  8%|‚ñä         | 257/3257 [00:01<00:17, 167.25it/s]  8%|‚ñä         | 275/3257 [00:01<00:17, 168.83it/s]  9%|‚ñâ         | 297/3257 [00:01<00:16, 178.67it/s] 10%|‚ñâ         | 316/3257 [00:02<00:16, 173.28it/s] 10%|‚ñà         | 336/3257 [00:02<00:16, 179.03it/s] 11%|‚ñà         | 356/3257 [00:02<00:15, 183.65it/s] 12%|‚ñà‚ñè        | 375/3257 [00:02<00:16, 170.42it/s] 12%|‚ñà‚ñè        | 393/3257 [00:02<00:17, 160.02it/s] 13%|‚ñà‚ñé        | 413/3257 [00:02<00:16, 170.08it/s] 13%|‚ñà‚ñé        | 431/3257 [00:02<00:19, 147.79it/s] 14%|‚ñà‚ñé        | 447/3257 [00:02<00:18, 149.01it/s] 14%|‚ñà‚ñç        | 466/3257 [00:02<00:17, 159.11it/s] 15%|‚ñà‚ñç        | 483/3257 [00:03<00:18, 153.62it/s] 15%|‚ñà‚ñå        | 503/3257 [00:03<00:16, 165.86it/s] 16%|‚ñà‚ñå        | 520/3257 [00:03<00:16, 165.34it/s] 16%|‚ñà‚ñã        | 537/3257 [00:03<00:16, 163.99it/s] 17%|‚ñà‚ñã        | 554/3257 [00:03<00:16, 163.26it/s] 18%|‚ñà‚ñä        | 571/3257 [00:03<00:18, 141.57it/s] 18%|‚ñà‚ñä        | 588/3257 [00:03<00:17, 148.54it/s] 19%|‚ñà‚ñä        | 605/3257 [00:03<00:17, 153.01it/s] 19%|‚ñà‚ñâ        | 621/3257 [00:03<00:17, 153.25it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:04<00:16, 160.02it/s] 20%|‚ñà‚ñà        | 657/3257 [00:04<00:18, 143.78it/s] 21%|‚ñà‚ñà        | 676/3257 [00:04<00:16, 154.05it/s] 21%|‚ñà‚ñà        | 692/3257 [00:04<00:17, 150.67it/s] 22%|‚ñà‚ñà‚ñè       | 710/3257 [00:04<00:16, 157.11it/s] 22%|‚ñà‚ñà‚ñè       | 726/3257 [00:04<00:17, 147.41it/s] 23%|‚ñà‚ñà‚ñé       | 741/3257 [00:04<00:17, 143.28it/s] 23%|‚ñà‚ñà‚ñé       | 760/3257 [00:04<00:16, 155.50it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:04<00:16, 152.04it/s] 24%|‚ñà‚ñà‚ñç       | 793/3257 [00:05<00:15, 156.63it/s] 25%|‚ñà‚ñà‚ñç       | 809/3257 [00:05<00:15, 156.10it/s] 25%|‚ñà‚ñà‚ñå       | 825/3257 [00:05<00:16, 151.18it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:05<00:16, 144.22it/s] 26%|‚ñà‚ñà‚ñã       | 858/3257 [00:05<00:15, 151.04it/s] 27%|‚ñà‚ñà‚ñã       | 874/3257 [00:05<00:15, 152.43it/s] 27%|‚ñà‚ñà‚ñã       | 890/3257 [00:05<00:15, 150.86it/s] 28%|‚ñà‚ñà‚ñä       | 908/3257 [00:05<00:14, 157.24it/s] 28%|‚ñà‚ñà‚ñä       | 926/3257 [00:05<00:14, 163.72it/s] 29%|‚ñà‚ñà‚ñâ       | 943/3257 [00:06<00:14, 158.99it/s] 29%|‚ñà‚ñà‚ñâ       | 960/3257 [00:06<00:14, 161.44it/s] 30%|‚ñà‚ñà‚ñâ       | 977/3257 [00:06<00:13, 163.79it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:06<00:15, 150.49it/s] 31%|‚ñà‚ñà‚ñà       | 1010/3257 [00:06<00:15, 147.35it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:06<00:15, 146.28it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1042/3257 [00:06<00:15, 143.67it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1059/3257 [00:06<00:14, 150.28it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:14, 151.25it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:07<00:14, 154.27it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:07<00:13, 159.22it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1132/3257 [00:07<00:14, 149.45it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1148/3257 [00:07<00:14, 148.25it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:13, 158.80it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1186/3257 [00:07<00:13, 150.13it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1202/3257 [00:07<00:14, 138.91it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:07<00:14, 142.01it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1240/3257 [00:08<00:12, 162.16it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:08<00:13, 152.97it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1274/3257 [00:08<00:12, 156.26it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:08<00:13, 143.26it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1306/3257 [00:08<00:13, 147.31it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1324/3257 [00:08<00:12, 154.26it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1342/3257 [00:08<00:11, 161.01it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1359/3257 [00:08<00:12, 157.11it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1375/3257 [00:08<00:12, 156.01it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1391/3257 [00:08<00:12, 154.54it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:09<00:10, 170.17it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:09<00:10, 172.02it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:09<00:10, 178.18it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1472/3257 [00:09<00:09, 182.35it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1491/3257 [00:09<00:09, 184.53it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:09<00:14, 118.89it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1526/3257 [00:09<00:14, 120.26it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1541/3257 [00:10<00:13, 125.86it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1556/3257 [00:10<00:13, 128.95it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:10<00:12, 139.77it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:10<00:11, 146.21it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1609/3257 [00:10<00:10, 155.08it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1627/3257 [00:10<00:10, 161.43it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1644/3257 [00:10<00:10, 150.45it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1660/3257 [00:10<00:10, 150.38it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:10<00:10, 144.39it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:11<00:10, 147.41it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1712/3257 [00:11<00:09, 161.36it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:11<00:10, 150.09it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:11<00:10, 149.54it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:11<00:09, 155.83it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1783/3257 [00:11<00:08, 166.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1800/3257 [00:11<00:08, 164.39it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1817/3257 [00:11<00:08, 161.76it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1834/3257 [00:11<00:09, 157.62it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1852/3257 [00:12<00:08, 161.12it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1871/3257 [00:12<00:08, 169.06it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1889/3257 [00:12<00:08, 167.55it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1908/3257 [00:12<00:07, 170.92it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1926/3257 [00:12<00:08, 161.49it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1949/3257 [00:12<00:07, 179.43it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1970/3257 [00:12<00:06, 187.63it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1989/3257 [00:12<00:07, 172.20it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2007/3257 [00:12<00:07, 172.58it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2027/3257 [00:12<00:06, 179.35it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2046/3257 [00:13<00:07, 170.24it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2064/3257 [00:13<00:07, 152.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2082/3257 [00:13<00:07, 159.31it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2099/3257 [00:13<00:07, 152.19it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:13<00:07, 159.21it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:13<00:07, 147.19it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2150/3257 [00:13<00:07, 145.26it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:13<00:07, 154.15it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2184/3257 [00:14<00:07, 152.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2202/3257 [00:14<00:06, 159.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:14<00:06, 155.86it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:14<00:06, 158.15it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2252/3257 [00:14<00:06, 154.34it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:14<00:06, 154.51it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2289/3257 [00:14<00:05, 163.60it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2306/3257 [00:14<00:05, 164.50it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2328/3257 [00:14<00:05, 179.44it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2349/3257 [00:15<00:04, 187.23it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2368/3257 [00:15<00:04, 181.66it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2390/3257 [00:15<00:04, 189.52it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2410/3257 [00:15<00:04, 173.81it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2428/3257 [00:15<00:04, 171.42it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2446/3257 [00:15<00:04, 163.07it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2463/3257 [00:15<00:04, 163.91it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:15<00:04, 165.10it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2501/3257 [00:15<00:04, 174.43it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2519/3257 [00:16<00:04, 173.46it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:16<00:04, 176.27it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2558/3257 [00:16<00:04, 172.46it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2576/3257 [00:16<00:04, 159.93it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2593/3257 [00:16<00:04, 156.57it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2617/3257 [00:16<00:03, 179.06it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2637/3257 [00:16<00:03, 182.73it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:16<00:03, 171.96it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2674/3257 [00:16<00:03, 165.80it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:17<00:03, 164.99it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2711/3257 [00:17<00:03, 151.49it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2730/3257 [00:17<00:03, 160.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2749/3257 [00:17<00:03, 167.69it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2767/3257 [00:17<00:02, 168.52it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2785/3257 [00:17<00:02, 166.19it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2804/3257 [00:17<00:02, 172.62it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2822/3257 [00:17<00:02, 164.14it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2839/3257 [00:17<00:02, 155.54it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2861/3257 [00:18<00:02, 172.71it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2883/3257 [00:18<00:02, 184.61it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2902/3257 [00:18<00:02, 163.56it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:18<00:03, 93.67it/s]  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2936/3257 [00:18<00:03, 104.33it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:18<00:02, 109.30it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:19<00:02, 125.10it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:19<00:02, 127.70it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:19<00:01, 143.85it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3020/3257 [00:19<00:01, 147.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3040/3257 [00:19<00:01, 160.69it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3061/3257 [00:19<00:01, 172.87it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3080/3257 [00:19<00:01, 174.78it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3098/3257 [00:19<00:00, 172.16it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:19<00:00, 178.31it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3137/3257 [00:20<00:00, 169.27it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3155/3257 [00:20<00:00, 163.34it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3172/3257 [00:20<00:00, 164.41it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3189/3257 [00:20<00:00, 160.55it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:20<00:00, 158.55it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3223/3257 [00:20<00:00, 150.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:20<00:00, 164.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 156.95it/s]
2023-02-07 19:42:31.624 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:42:31,626][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d283,n5,mc6,s0.537703,t4>', 'datetime': '2023-02-07T19:42:31.626587', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:42:31,626][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:42:31,626][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:42:32,230][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 19:42:32,230][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:42:32,304][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 25857 unique words (47.84% of original 54054, drops 28197)', 'datetime': '2023-02-07T19:42:32.304083', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:42:32,305][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 6477431 word corpus (98.88% of original 6550866, drops 73435)', 'datetime': '2023-02-07T19:42:32.305493', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:42:32,394][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 19:42:32,396][gensim.models.word2vec][INFO] - sample=0.537703 downsamples 0 most-common words
[2023-02-07 19:42:32,396][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6477431 word corpus (100.0%% of prior 6477431)', 'datetime': '2023-02-07T19:42:32.396278', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:42:32,549][gensim.models.word2vec][INFO] - estimated required memory for 25857 words and 283 dimensions: 75807072 bytes
[2023-02-07 19:42:32,549][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:42:32,584][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 25857 vocabulary and 283 features, using sg=1 hs=0 sample=0.5377031447096976 negative=5 window=7 shrink_windows=True', 'datetime': '2023-02-07T19:42:32.584016', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:42:33,590][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 29.54% examples, 1890233 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:34,594][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 55.48% examples, 1818265 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:35,603][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 83.33% examples, 1793451 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:36,179][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6423064 effective words) took 3.6s, 1787740 effective words/s
[2023-02-07 19:42:37,194][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 27.17% examples, 1737467 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:38,194][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 53.76% examples, 1757722 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:39,195][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 81.15% examples, 1744695 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:39,861][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6423064 effective words) took 3.7s, 1745817 effective words/s
[2023-02-07 19:42:40,864][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 26.90% examples, 1735889 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:42:41,867][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 53.61% examples, 1760684 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:42,875][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 89.99% examples, 1928983 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:43,138][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6423064 effective words) took 3.3s, 1961469 effective words/s
[2023-02-07 19:42:44,145][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 33.68% examples, 2175644 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:45,148][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 66.96% examples, 2185608 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:46,148][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 100.00% examples, 2134882 words/s, in_qsize 0, out_qsize 1
[2023-02-07 19:42:46,149][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6423064 effective words) took 3.0s, 2134567 effective words/s
[2023-02-07 19:42:47,162][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 27.17% examples, 1740014 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:42:48,165][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 53.21% examples, 1738490 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:49,165][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 84.96% examples, 1825889 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:49,586][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6423064 effective words) took 3.4s, 1870092 effective words/s
[2023-02-07 19:42:50,594][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 31.81% examples, 2048999 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:51,595][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 60.98% examples, 1982749 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:42:52,597][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 91.34% examples, 1962149 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:52,865][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6423064 effective words) took 3.3s, 1959869 effective words/s
[2023-02-07 19:42:53,884][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 27.85% examples, 1763826 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:54,888][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 52.16% examples, 1694627 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:55,895][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 78.02% examples, 1671172 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:42:56,692][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6423064 effective words) took 3.8s, 1679047 effective words/s
[2023-02-07 19:42:57,694][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 32.39% examples, 2103322 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:58,696][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 60.42% examples, 1965971 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:42:59,697][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 88.82% examples, 1912068 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:00,051][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6423064 effective words) took 3.4s, 1912976 effective words/s
[2023-02-07 19:43:01,058][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 25.79% examples, 1649037 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:02,063][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 50.45% examples, 1643032 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:03,069][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 76.30% examples, 1648494 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:03,815][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6423064 effective words) took 3.8s, 1707629 effective words/s
[2023-02-07 19:43:04,824][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 31.65% examples, 2025935 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:05,824][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 59.96% examples, 1949197 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:06,827][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 88.73% examples, 1901690 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:07,243][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6423064 effective words) took 3.4s, 1874525 effective words/s
[2023-02-07 19:43:08,258][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 25.76% examples, 1633340 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:43:09,260][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 50.72% examples, 1646830 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:10,269][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 81.15% examples, 1738556 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:10,825][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6423064 effective words) took 3.6s, 1794268 effective words/s
[2023-02-07 19:43:11,834][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 29.08% examples, 1857096 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:12,834][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 57.14% examples, 1868055 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:13,842][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 83.33% examples, 1794459 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:14,443][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6423064 effective words) took 3.6s, 1775908 effective words/s
[2023-02-07 19:43:15,449][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 25.79% examples, 1649690 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:16,455][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 55.08% examples, 1798898 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:17,459][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 88.09% examples, 1888973 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:17,848][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6423064 effective words) took 3.4s, 1887955 effective words/s
[2023-02-07 19:43:18,860][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 29.08% examples, 1850960 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:19,862][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 56.83% examples, 1855462 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:20,864][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 86.34% examples, 1853128 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:21,314][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6423064 effective words) took 3.5s, 1853707 effective words/s
[2023-02-07 19:43:22,324][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 28.55% examples, 1820372 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:23,330][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 56.09% examples, 1831631 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:24,331][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 85.78% examples, 1842220 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:43:24,801][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6423064 effective words) took 3.5s, 1842752 effective words/s
[2023-02-07 19:43:24,802][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (96345960 effective words) took 52.2s, 1845078 effective words/s', 'datetime': '2023-02-07T19:43:24.802231', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:43:24.802 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:43:29,186][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194201-4pk33kv4/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:43:29.186358', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:43:29,188][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:43:29,288][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194201-4pk33kv4/files/../tmp/embedding_model.pt
2023-02-07 19:43:29.288 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:43:31.142 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:43:31.865 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:43:33.854 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1473813293587765, 'test_mae': 0.8265633353152158, 'test_r2': -2.718131844352675}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.19
wandb: percentage 0.52165
wandb:   test_mae 0.82656
wandb:   test_mse 1.14738
wandb:    test_r2 -2.71813
wandb: 
wandb: üöÄ View run trim-sweep-54 at: https://wandb.ai/xiaoqiz/mof2vec/runs/4pk33kv4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_194201-4pk33kv4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nzyatonk with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 595
wandb: 	model.gensim.alpha: 0.004294064759661603
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.6475590309481809
wandb: 	model.gensim.vector_size: 332
wandb: 	model.gensim.window: 3
wandb: 	model.sklearn.learning_rate: 0.1065869279907525
wandb: 	model.sklearn.max_depth: 13
wandb: 	model.sklearn.min_child_weight: 0.045224578190777555
wandb: 	model.sklearn.n_estimators: 3017
wandb: 	model.sklearn.num_leaves: 208
wandb: 	model.sklearn.reg_alpha: 0.003702388959026533
wandb: 	model.sklearn.reg_lambda: 0.009151577596888423
wandb: 	model.sklearn.subsample: 0.6003641107655212
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194354-nzyatonk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-55
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/nzyatonk
2023-02-07 19:44:04.770 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:44:04.771 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 595 for sweep.
2023-02-07 19:44:04.771 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.004294064759661603 for sweep.
2023-02-07 19:44:04.771 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:44:04.772 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 19:44:04.772 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6475590309481809 for sweep.
2023-02-07 19:44:04.773 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 332 for sweep.
2023-02-07 19:44:04.773 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 3 for sweep.
2023-02-07 19:44:04.773 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.1065869279907525 for sweep.
2023-02-07 19:44:04.774 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 13 for sweep.
2023-02-07 19:44:04.774 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.045224578190777555 for sweep.
2023-02-07 19:44:04.774 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3017 for sweep.
2023-02-07 19:44:04.774 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 208 for sweep.
2023-02-07 19:44:04.774 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.003702388959026533 for sweep.
2023-02-07 19:44:04.775 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.009151577596888423 for sweep.
2023-02-07 19:44:04.775 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6003641107655212 for sweep.
2023-02-07 19:44:04.775 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:44:04.782 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194354-nzyatonk/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 595, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 332, 'window': 3, 'min_count': 7, 'dm': 0, 'sample': 0.6475590309481809, 'workers': 4, 'alpha': 0.004294064759661603, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3017, 'max_depth': 13, 'num_leaves': 208, 'reg_alpha': 0.003702388959026533, 'reg_lambda': 0.009151577596888423, 'subsample': 0.6003641107655212, 'min_child_weight': 0.045224578190777555, 'n_jobs': 4, 'learning_rate': 0.1065869279907525}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 139.12it/s]  1%|          | 32/3257 [00:00<00:20, 160.78it/s]  2%|‚ñè         | 49/3257 [00:00<00:20, 153.75it/s]  2%|‚ñè         | 65/3257 [00:00<00:20, 155.39it/s]  2%|‚ñè         | 81/3257 [00:00<00:20, 155.57it/s]  3%|‚ñé         | 97/3257 [00:00<00:20, 152.89it/s]  3%|‚ñé         | 113/3257 [00:00<00:20, 151.71it/s]  4%|‚ñç         | 130/3257 [00:00<00:19, 156.68it/s]  5%|‚ñç         | 149/3257 [00:00<00:19, 163.15it/s]  5%|‚ñå         | 166/3257 [00:01<00:19, 160.95it/s]  6%|‚ñå         | 183/3257 [00:01<00:18, 163.47it/s]  6%|‚ñå         | 201/3257 [00:01<00:18, 162.82it/s]  7%|‚ñã         | 221/3257 [00:01<00:17, 172.19it/s]  7%|‚ñã         | 243/3257 [00:01<00:16, 183.06it/s]  8%|‚ñä         | 262/3257 [00:01<00:17, 173.91it/s]  9%|‚ñâ         | 285/3257 [00:01<00:15, 186.56it/s]  9%|‚ñâ         | 304/3257 [00:01<00:16, 174.44it/s] 10%|‚ñâ         | 325/3257 [00:01<00:15, 183.26it/s] 11%|‚ñà         | 344/3257 [00:02<00:17, 169.83it/s] 11%|‚ñà         | 362/3257 [00:02<00:16, 171.22it/s] 12%|‚ñà‚ñè        | 380/3257 [00:02<00:17, 162.83it/s] 12%|‚ñà‚ñè        | 397/3257 [00:02<00:17, 161.63it/s] 13%|‚ñà‚ñé        | 417/3257 [00:02<00:16, 170.12it/s] 13%|‚ñà‚ñé        | 435/3257 [00:02<00:19, 141.82it/s] 14%|‚ñà‚ñç        | 453/3257 [00:02<00:18, 150.61it/s] 15%|‚ñà‚ñç        | 474/3257 [00:02<00:17, 161.55it/s] 15%|‚ñà‚ñå        | 491/3257 [00:03<00:17, 160.23it/s] 16%|‚ñà‚ñå        | 511/3257 [00:03<00:16, 169.50it/s] 16%|‚ñà‚ñå        | 529/3257 [00:03<00:16, 161.46it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:16, 162.60it/s] 17%|‚ñà‚ñã        | 563/3257 [00:03<00:17, 151.49it/s] 18%|‚ñà‚ñä        | 579/3257 [00:03<00:17, 150.46it/s] 18%|‚ñà‚ñä        | 598/3257 [00:03<00:16, 161.06it/s] 19%|‚ñà‚ñâ        | 617/3257 [00:03<00:15, 168.80it/s] 19%|‚ñà‚ñâ        | 635/3257 [00:03<00:15, 167.24it/s] 20%|‚ñà‚ñà        | 652/3257 [00:04<00:17, 153.21it/s] 21%|‚ñà‚ñà        | 668/3257 [00:04<00:17, 149.18it/s] 21%|‚ñà‚ñà        | 684/3257 [00:04<00:17, 149.34it/s] 21%|‚ñà‚ñà‚ñè       | 700/3257 [00:04<00:16, 150.57it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:04<00:15, 159.32it/s] 23%|‚ñà‚ñà‚ñé       | 737/3257 [00:04<00:16, 149.50it/s] 23%|‚ñà‚ñà‚ñé       | 753/3257 [00:04<00:16, 152.14it/s] 24%|‚ñà‚ñà‚ñé       | 771/3257 [00:04<00:15, 158.49it/s] 24%|‚ñà‚ñà‚ñç       | 787/3257 [00:04<00:16, 152.95it/s] 25%|‚ñà‚ñà‚ñç       | 805/3257 [00:05<00:15, 159.82it/s] 25%|‚ñà‚ñà‚ñå       | 822/3257 [00:05<00:15, 154.70it/s] 26%|‚ñà‚ñà‚ñå       | 838/3257 [00:05<00:16, 147.85it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:05<00:16, 143.95it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:05<00:15, 151.00it/s] 27%|‚ñà‚ñà‚ñã       | 887/3257 [00:05<00:23, 100.77it/s] 28%|‚ñà‚ñà‚ñä       | 906/3257 [00:05<00:19, 118.48it/s] 28%|‚ñà‚ñà‚ñä       | 925/3257 [00:05<00:17, 133.06it/s] 29%|‚ñà‚ñà‚ñâ       | 941/3257 [00:06<00:16, 137.95it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:06<00:15, 148.56it/s] 30%|‚ñà‚ñà‚ñà       | 978/3257 [00:06<00:14, 156.11it/s] 31%|‚ñà‚ñà‚ñà       | 995/3257 [00:06<00:15, 142.75it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:06<00:16, 138.80it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:06<00:16, 134.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:06<00:16, 130.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1056/3257 [00:06<00:16, 134.07it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1072/3257 [00:06<00:15, 140.71it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1087/3257 [00:07<00:15, 137.95it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1101/3257 [00:07<00:16, 134.57it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1116/3257 [00:07<00:15, 137.39it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1130/3257 [00:07<00:16, 130.26it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:07<00:16, 129.02it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1159/3257 [00:07<00:15, 133.66it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:07<00:15, 131.22it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:07<00:16, 124.09it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1200/3257 [00:08<00:17, 118.20it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1212/3257 [00:08<00:17, 118.36it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1230/3257 [00:08<00:15, 134.52it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1244/3257 [00:08<00:15, 133.60it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:08<00:15, 131.75it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:08<00:14, 133.21it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1286/3257 [00:08<00:16, 121.86it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1300/3257 [00:08<00:15, 125.54it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1314/3257 [00:08<00:15, 127.59it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:08<00:14, 129.78it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:09<00:13, 138.22it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1358/3257 [00:09<00:14, 132.01it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1372/3257 [00:09<00:14, 128.65it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:09<00:14, 128.70it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:09<00:13, 135.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:09<00:12, 151.62it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1438/3257 [00:09<00:12, 143.45it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1457/3257 [00:09<00:11, 155.64it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1473/3257 [00:09<00:11, 152.45it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1489/3257 [00:10<00:11, 152.74it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1507/3257 [00:10<00:10, 159.17it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1524/3257 [00:10<00:12, 143.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1539/3257 [00:10<00:12, 134.92it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1553/3257 [00:10<00:13, 131.01it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1570/3257 [00:10<00:12, 138.60it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1585/3257 [00:10<00:12, 135.14it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1601/3257 [00:10<00:11, 139.91it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:11<00:11, 142.99it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:11<00:11, 135.80it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1648/3257 [00:11<00:12, 133.19it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:11<00:12, 132.22it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:11<00:12, 127.86it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:11<00:12, 128.66it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1705/3257 [00:11<00:11, 133.01it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1719/3257 [00:11<00:11, 131.37it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1733/3257 [00:11<00:12, 119.67it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1747/3257 [00:12<00:12, 124.80it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1762/3257 [00:12<00:11, 131.55it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1776/3257 [00:12<00:11, 131.19it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:12<00:10, 138.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1806/3257 [00:12<00:11, 131.74it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:12<00:10, 133.11it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1835/3257 [00:12<00:11, 126.55it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:12<00:10, 129.87it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1865/3257 [00:12<00:10, 137.75it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1880/3257 [00:13<00:09, 139.19it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:13<00:09, 136.22it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1911/3257 [00:13<00:09, 140.57it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1926/3257 [00:13<00:10, 132.84it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1945/3257 [00:13<00:09, 144.85it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1963/3257 [00:13<00:08, 153.10it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1979/3257 [00:13<00:08, 143.89it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1994/3257 [00:13<00:08, 144.95it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2009/3257 [00:13<00:08, 139.65it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2025/3257 [00:14<00:08, 145.24it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2040/3257 [00:14<00:08, 137.47it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2054/3257 [00:14<00:08, 136.47it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2068/3257 [00:14<00:08, 133.26it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:14<00:08, 135.10it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2097/3257 [00:14<00:08, 135.07it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:14<00:07, 149.85it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2133/3257 [00:14<00:07, 145.29it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2148/3257 [00:14<00:07, 145.34it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:15<00:12, 89.32it/s]  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:15<00:10, 105.96it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2200/3257 [00:15<00:08, 123.97it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2217/3257 [00:15<00:07, 133.19it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2235/3257 [00:15<00:07, 143.56it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2251/3257 [00:15<00:07, 141.89it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2267/3257 [00:15<00:06, 144.26it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2283/3257 [00:15<00:06, 146.68it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2300/3257 [00:16<00:06, 151.25it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2320/3257 [00:16<00:05, 164.29it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2340/3257 [00:16<00:05, 172.42it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:16<00:05, 174.79it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2378/3257 [00:16<00:05, 174.90it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2398/3257 [00:16<00:04, 179.63it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2417/3257 [00:16<00:04, 169.69it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2435/3257 [00:16<00:05, 157.43it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2452/3257 [00:16<00:05, 150.90it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2473/3257 [00:17<00:04, 162.98it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2490/3257 [00:17<00:04, 156.34it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2509/3257 [00:17<00:04, 163.26it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2526/3257 [00:17<00:04, 162.05it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2543/3257 [00:17<00:04, 162.74it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2560/3257 [00:17<00:04, 152.53it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2576/3257 [00:17<00:04, 141.24it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2591/3257 [00:17<00:04, 138.23it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2612/3257 [00:18<00:04, 157.05it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2631/3257 [00:18<00:03, 165.04it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2648/3257 [00:18<00:03, 157.88it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2665/3257 [00:18<00:03, 154.76it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2681/3257 [00:18<00:03, 154.86it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2697/3257 [00:18<00:03, 147.23it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2712/3257 [00:18<00:04, 135.29it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2729/3257 [00:18<00:03, 143.82it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2746/3257 [00:18<00:03, 148.34it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2762/3257 [00:19<00:03, 146.35it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2777/3257 [00:19<00:03, 145.88it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2797/3257 [00:19<00:02, 160.16it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2814/3257 [00:19<00:02, 153.99it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2830/3257 [00:19<00:03, 141.29it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2845/3257 [00:19<00:02, 143.39it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2866/3257 [00:19<00:02, 160.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2885/3257 [00:19<00:02, 168.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:19<00:02, 148.24it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:20<00:02, 153.32it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2936/3257 [00:20<00:02, 150.83it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2952/3257 [00:20<00:02, 140.79it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:20<00:01, 146.87it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:20<00:01, 140.25it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3003/3257 [00:20<00:01, 151.24it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3019/3257 [00:20<00:01, 147.31it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3038/3257 [00:20<00:01, 157.39it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3055/3257 [00:20<00:01, 159.60it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:21<00:01, 166.69it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3092/3257 [00:21<00:01, 157.77it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3112/3257 [00:21<00:00, 167.33it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3129/3257 [00:21<00:00, 165.57it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3146/3257 [00:21<00:00, 153.21it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3163/3257 [00:21<00:00, 154.67it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3179/3257 [00:21<00:00, 144.83it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3200/3257 [00:21<00:00, 161.16it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3217/3257 [00:21<00:00, 151.76it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3237/3257 [00:22<00:00, 162.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3254/3257 [00:22<00:00, 160.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 146.59it/s]
2023-02-07 19:44:27.980 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:44:27,982][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d332,n5,mc7,s0.647559,t4>', 'datetime': '2023-02-07T19:44:27.981906', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:44:27,982][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:44:27,982][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:44:28,600][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 19:44:28,601][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:44:28,670][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 23400 unique words (43.29% of original 54054, drops 30654)', 'datetime': '2023-02-07T19:44:28.670412', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:44:28,670][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 6462689 word corpus (98.65% of original 6550866, drops 88177)', 'datetime': '2023-02-07T19:44:28.670771', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:44:28,751][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 19:44:28,752][gensim.models.word2vec][INFO] - sample=0.647559 downsamples 0 most-common words
[2023-02-07 19:44:28,752][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6462689 word corpus (100.0%% of prior 6462689)', 'datetime': '2023-02-07T19:44:28.752967', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:44:28,890][gensim.models.word2vec][INFO] - estimated required memory for 23400 words and 332 dimensions: 78827096 bytes
[2023-02-07 19:44:28,890][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:44:28,927][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 23400 vocabulary and 332 features, using sg=1 hs=0 sample=0.6475590309481809 negative=5 window=3 shrink_windows=True', 'datetime': '2023-02-07T19:44:28.927828', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:44:29,933][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 30.89% examples, 1982095 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:44:30,934][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 57.84% examples, 1890349 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:31,938][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 85.94% examples, 1844645 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:32,427][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6408417 effective words) took 3.5s, 1832526 effective words/s
[2023-02-07 19:44:33,442][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 29.05% examples, 1845419 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:44:34,446][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 57.02% examples, 1853788 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:35,448][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 86.83% examples, 1860014 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:35,867][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6408417 effective words) took 3.4s, 1864406 effective words/s
[2023-02-07 19:44:36,874][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 29.08% examples, 1857396 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:37,876][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 57.45% examples, 1874601 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:44:38,881][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 89.25% examples, 1912147 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:39,138][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6408417 effective words) took 3.3s, 1960492 effective words/s
[2023-02-07 19:44:40,142][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 36.57% examples, 2375771 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:41,145][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 69.42% examples, 2265705 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:42,005][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6408417 effective words) took 2.9s, 2235690 effective words/s
[2023-02-07 19:44:43,017][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 33.68% examples, 2162446 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:44,019][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 66.87% examples, 2173961 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:44:44,955][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6408417 effective words) took 2.9s, 2174102 effective words/s
[2023-02-07 19:44:45,960][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 33.68% examples, 2175314 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:46,962][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 66.96% examples, 2185085 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:47,867][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6408417 effective words) took 2.9s, 2202457 effective words/s
[2023-02-07 19:44:48,870][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 35.34% examples, 2297857 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:49,871][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 64.66% examples, 2105274 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:50,871][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 95.79% examples, 2045203 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:51,006][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6408417 effective words) took 3.1s, 2042283 effective words/s
[2023-02-07 19:44:52,017][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 30.12% examples, 1925894 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:53,021][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 59.26% examples, 1928485 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:54,022][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 90.02% examples, 1926427 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:54,329][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6408417 effective words) took 3.3s, 1930073 effective words/s
[2023-02-07 19:44:55,333][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 29.75% examples, 1904182 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:56,336][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 58.80% examples, 1916785 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:57,338][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 89.90% examples, 1927999 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:57,611][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6408417 effective words) took 3.3s, 1953786 effective words/s
[2023-02-07 19:44:58,615][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 39.39% examples, 2588809 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:44:59,616][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 74.36% examples, 2414268 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:45:00,333][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6408417 effective words) took 2.7s, 2356848 effective words/s
[2023-02-07 19:45:01,335][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 34.26% examples, 2214913 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:45:02,336][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 67.27% examples, 2197615 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:45:03,241][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6408417 effective words) took 2.9s, 2205365 effective words/s
[2023-02-07 19:45:04,246][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 34.26% examples, 2213541 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:45:05,248][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 68.01% examples, 2220697 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:45:06,128][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6408417 effective words) took 2.9s, 2222202 effective words/s
[2023-02-07 19:45:07,137][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 35.34% examples, 2289571 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:45:08,139][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 67.70% examples, 2204598 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:45:09,139][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 99.51% examples, 2121182 words/s, in_qsize 4, out_qsize 0
[2023-02-07 19:45:09,149][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6408417 effective words) took 3.0s, 2124696 effective words/s
[2023-02-07 19:45:10,158][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 30.06% examples, 1919337 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:45:11,162][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 59.75% examples, 1938063 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:45:12,173][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 90.97% examples, 1939191 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:45:12,447][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6408417 effective words) took 3.3s, 1943706 effective words/s
[2023-02-07 19:45:13,455][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 30.61% examples, 1959248 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:45:14,457][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 60.67% examples, 1965349 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:45:15,459][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 91.16% examples, 1953968 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:45:15,724][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6408417 effective words) took 3.3s, 1957154 effective words/s
[2023-02-07 19:45:15,724][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (96126255 effective words) took 46.8s, 2054142 effective words/s', 'datetime': '2023-02-07T19:45:15.724552', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:45:15.724 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:45:19,369][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194354-nzyatonk/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:45:19.369187', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:45:19,371][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:45:19,468][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194354-nzyatonk/files/../tmp/embedding_model.pt
2023-02-07 19:45:19.469 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:45:21.504 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:45:22.188 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:45:24.436 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0602500051736476, 'test_mae': 0.8029451926518802, 'test_r2': -2.1832170635541743}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.77
wandb: percentage 0.5671
wandb:   test_mae 0.80295
wandb:   test_mse 1.06025
wandb:    test_r2 -2.18322
wandb: 
wandb: üöÄ View run prime-sweep-55 at: https://wandb.ai/xiaoqiz/mof2vec/runs/nzyatonk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_194354-nzyatonk/logs
wandb: Agent Starting Run: 6yacmgce with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 838
wandb: 	model.gensim.alpha: 0.0012433101731370358
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.7686090522981699
wandb: 	model.gensim.vector_size: 470
wandb: 	model.gensim.window: 12
wandb: 	model.sklearn.learning_rate: 0.0006327201562181061
wandb: 	model.sklearn.max_depth: 24
wandb: 	model.sklearn.min_child_weight: 0.05833876029854012
wandb: 	model.sklearn.n_estimators: 1886
wandb: 	model.sklearn.num_leaves: 272
wandb: 	model.sklearn.reg_alpha: 0.1758467351479825
wandb: 	model.sklearn.reg_lambda: 0.260202415841155
wandb: 	model.sklearn.subsample: 0.9024012081983124
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194536-6yacmgce
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-56
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/6yacmgce
2023-02-07 19:45:44.202 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:45:44.202 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 838 for sweep.
2023-02-07 19:45:44.203 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0012433101731370358 for sweep.
2023-02-07 19:45:44.203 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:45:44.203 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 19:45:44.203 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7686090522981699 for sweep.
2023-02-07 19:45:44.204 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 470 for sweep.
2023-02-07 19:45:44.204 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 12 for sweep.
2023-02-07 19:45:44.204 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0006327201562181061 for sweep.
2023-02-07 19:45:44.205 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 24 for sweep.
2023-02-07 19:45:44.205 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05833876029854012 for sweep.
2023-02-07 19:45:44.205 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1886 for sweep.
2023-02-07 19:45:44.206 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 272 for sweep.
2023-02-07 19:45:44.206 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.1758467351479825 for sweep.
2023-02-07 19:45:44.206 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.260202415841155 for sweep.
2023-02-07 19:45:44.206 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9024012081983124 for sweep.
2023-02-07 19:45:44.207 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:45:44.216 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194536-6yacmgce/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 838, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 470, 'window': 12, 'min_count': 8, 'dm': 0, 'sample': 0.7686090522981699, 'workers': 4, 'alpha': 0.0012433101731370358, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1886, 'max_depth': 24, 'num_leaves': 272, 'reg_alpha': 0.1758467351479825, 'reg_lambda': 0.260202415841155, 'subsample': 0.9024012081983124, 'min_child_weight': 0.05833876029854012, 'n_jobs': 4, 'learning_rate': 0.0006327201562181061}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:22, 144.16it/s]  1%|          | 33/3257 [00:00<00:20, 158.76it/s]  2%|‚ñè         | 50/3257 [00:00<00:19, 160.53it/s]  2%|‚ñè         | 67/3257 [00:00<00:20, 158.48it/s]  3%|‚ñé         | 89/3257 [00:00<00:18, 174.89it/s]  3%|‚ñé         | 107/3257 [00:00<00:19, 159.06it/s]  4%|‚ñç         | 124/3257 [00:00<00:19, 161.30it/s]  4%|‚ñç         | 145/3257 [00:00<00:17, 174.04it/s]  5%|‚ñå         | 163/3257 [00:00<00:18, 166.38it/s]  6%|‚ñå         | 180/3257 [00:01<00:18, 164.98it/s]  6%|‚ñå         | 199/3257 [00:01<00:17, 171.83it/s]  7%|‚ñã         | 217/3257 [00:01<00:17, 173.71it/s]  7%|‚ñã         | 237/3257 [00:01<00:16, 179.61it/s]  8%|‚ñä         | 256/3257 [00:01<00:16, 180.68it/s]  8%|‚ñä         | 275/3257 [00:01<00:16, 180.24it/s]  9%|‚ñâ         | 297/3257 [00:01<00:15, 187.01it/s] 10%|‚ñâ         | 316/3257 [00:01<00:16, 179.16it/s] 10%|‚ñà         | 336/3257 [00:01<00:16, 181.97it/s] 11%|‚ñà         | 355/3257 [00:02<00:24, 118.25it/s] 11%|‚ñà‚ñè        | 372/3257 [00:02<00:22, 128.28it/s] 12%|‚ñà‚ñè        | 388/3257 [00:02<00:22, 126.33it/s] 13%|‚ñà‚ñé        | 408/3257 [00:02<00:20, 141.74it/s] 13%|‚ñà‚ñé        | 424/3257 [00:02<00:19, 144.83it/s] 14%|‚ñà‚ñé        | 440/3257 [00:02<00:20, 134.42it/s] 14%|‚ñà‚ñç        | 458/3257 [00:02<00:19, 144.70it/s] 15%|‚ñà‚ñç        | 476/3257 [00:03<00:18, 152.40it/s] 15%|‚ñà‚ñå        | 493/3257 [00:03<00:17, 156.29it/s] 16%|‚ñà‚ñå        | 513/3257 [00:03<00:16, 166.23it/s] 16%|‚ñà‚ñã        | 531/3257 [00:03<00:16, 165.20it/s] 17%|‚ñà‚ñã        | 550/3257 [00:03<00:16, 168.28it/s] 17%|‚ñà‚ñã        | 568/3257 [00:03<00:16, 159.09it/s] 18%|‚ñà‚ñä        | 585/3257 [00:03<00:17, 152.22it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:16, 157.47it/s] 19%|‚ñà‚ñâ        | 621/3257 [00:03<00:16, 159.80it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:04<00:15, 166.70it/s] 20%|‚ñà‚ñà        | 658/3257 [00:04<00:16, 157.08it/s] 21%|‚ñà‚ñà        | 676/3257 [00:04<00:15, 162.11it/s] 21%|‚ñà‚ñà‚ñè       | 693/3257 [00:04<00:16, 157.64it/s] 22%|‚ñà‚ñà‚ñè       | 711/3257 [00:04<00:15, 162.45it/s] 22%|‚ñà‚ñà‚ñè       | 728/3257 [00:04<00:16, 154.70it/s] 23%|‚ñà‚ñà‚ñé       | 744/3257 [00:04<00:16, 155.20it/s] 23%|‚ñà‚ñà‚ñé       | 763/3257 [00:04<00:15, 163.85it/s] 24%|‚ñà‚ñà‚ñç       | 780/3257 [00:04<00:15, 159.00it/s] 24%|‚ñà‚ñà‚ñç       | 797/3257 [00:05<00:15, 161.65it/s] 25%|‚ñà‚ñà‚ñç       | 814/3257 [00:05<00:15, 161.90it/s] 26%|‚ñà‚ñà‚ñå       | 831/3257 [00:05<00:15, 156.20it/s] 26%|‚ñà‚ñà‚ñå       | 847/3257 [00:05<00:16, 150.17it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:05<00:15, 154.46it/s] 27%|‚ñà‚ñà‚ñã       | 880/3257 [00:05<00:15, 152.41it/s] 28%|‚ñà‚ñà‚ñä       | 899/3257 [00:05<00:14, 162.31it/s] 28%|‚ñà‚ñà‚ñä       | 916/3257 [00:05<00:14, 160.48it/s] 29%|‚ñà‚ñà‚ñä       | 935/3257 [00:05<00:13, 168.21it/s] 29%|‚ñà‚ñà‚ñâ       | 955/3257 [00:05<00:12, 177.15it/s] 30%|‚ñà‚ñà‚ñâ       | 973/3257 [00:06<00:13, 170.25it/s] 30%|‚ñà‚ñà‚ñà       | 991/3257 [00:06<00:13, 166.07it/s] 31%|‚ñà‚ñà‚ñà       | 1008/3257 [00:06<00:13, 160.88it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:06<00:13, 159.86it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1045/3257 [00:06<00:13, 165.13it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:06<00:12, 180.45it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:06<00:11, 188.19it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1110/3257 [00:06<00:10, 196.52it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1130/3257 [00:06<00:11, 192.57it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1150/3257 [00:07<00:11, 187.66it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1174/3257 [00:07<00:10, 202.33it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1195/3257 [00:07<00:11, 186.79it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1215/3257 [00:07<00:11, 184.53it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:07<00:09, 204.35it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:07<00:10, 195.70it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1282/3257 [00:07<00:10, 183.22it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1301/3257 [00:07<00:10, 183.85it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1322/3257 [00:07<00:10, 190.77it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:08<00:09, 196.81it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:08<00:09, 190.43it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1384/3257 [00:08<00:10, 183.23it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1408/3257 [00:08<00:09, 197.63it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:08<00:09, 201.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1454/3257 [00:08<00:08, 206.63it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1475/3257 [00:08<00:13, 131.05it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:09<00:11, 147.09it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1518/3257 [00:09<00:10, 161.77it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1537/3257 [00:09<00:11, 155.77it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:09<00:10, 161.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:09<00:10, 167.03it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1597/3257 [00:09<00:09, 180.02it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:09<00:08, 188.84it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:09<00:08, 184.87it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1658/3257 [00:09<00:08, 180.05it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:10<00:09, 173.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1698/3257 [00:10<00:08, 182.51it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1717/3257 [00:10<00:08, 181.58it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1736/3257 [00:10<00:08, 171.36it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1757/3257 [00:10<00:08, 180.97it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1778/3257 [00:10<00:07, 188.72it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1798/3257 [00:10<00:07, 191.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1818/3257 [00:10<00:07, 189.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1838/3257 [00:10<00:07, 185.95it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1858/3257 [00:10<00:07, 188.06it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1881/3257 [00:11<00:06, 199.97it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1902/3257 [00:11<00:06, 200.40it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1923/3257 [00:11<00:06, 196.72it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1950/3257 [00:11<00:06, 216.51it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1974/3257 [00:11<00:05, 217.05it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1996/3257 [00:11<00:05, 213.22it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2018/3257 [00:11<00:06, 206.05it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2039/3257 [00:11<00:05, 206.12it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2060/3257 [00:11<00:06, 183.73it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:12<00:06, 195.12it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2103/3257 [00:12<00:05, 193.98it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2123/3257 [00:12<00:06, 183.53it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:12<00:06, 179.86it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:12<00:05, 192.46it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2186/3257 [00:12<00:05, 190.55it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2207/3257 [00:12<00:05, 195.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2227/3257 [00:12<00:05, 194.07it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2247/3257 [00:12<00:05, 192.11it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2267/3257 [00:13<00:05, 193.01it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2287/3257 [00:13<00:04, 194.92it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2307/3257 [00:13<00:04, 192.42it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2334/3257 [00:13<00:04, 214.02it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:13<00:04, 220.56it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2383/3257 [00:13<00:03, 218.56it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2405/3257 [00:13<00:04, 210.24it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2427/3257 [00:13<00:03, 211.37it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2449/3257 [00:13<00:04, 188.26it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2474/3257 [00:14<00:03, 204.57it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2496/3257 [00:14<00:03, 204.27it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2519/3257 [00:14<00:03, 209.56it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2541/3257 [00:14<00:03, 208.77it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2563/3257 [00:14<00:03, 201.24it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2584/3257 [00:14<00:03, 194.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2607/3257 [00:14<00:03, 203.29it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:14<00:02, 219.57it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2657/3257 [00:14<00:03, 195.80it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2678/3257 [00:15<00:03, 186.93it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2698/3257 [00:15<00:03, 169.05it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2716/3257 [00:15<00:03, 158.83it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2738/3257 [00:15<00:03, 172.45it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:15<00:02, 173.90it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:15<00:02, 163.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:15<00:02, 173.23it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:15<00:02, 169.85it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2831/3257 [00:16<00:02, 157.84it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2849/3257 [00:16<00:02, 162.69it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:16<00:02, 178.77it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2891/3257 [00:16<00:02, 177.29it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2909/3257 [00:16<00:02, 168.16it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:16<00:01, 170.35it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2946/3257 [00:16<00:01, 161.96it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2963/3257 [00:17<00:03, 87.29it/s]  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2978/3257 [00:17<00:02, 97.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2996/3257 [00:17<00:02, 113.08it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3015/3257 [00:17<00:01, 128.31it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3033/3257 [00:17<00:01, 139.16it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3051/3257 [00:17<00:01, 148.77it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3071/3257 [00:17<00:01, 162.15it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3089/3257 [00:17<00:01, 162.78it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3109/3257 [00:17<00:00, 168.95it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3128/3257 [00:18<00:00, 171.29it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3146/3257 [00:18<00:00, 161.44it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3163/3257 [00:18<00:00, 162.60it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3180/3257 [00:18<00:00, 153.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3200/3257 [00:18<00:00, 165.39it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3217/3257 [00:18<00:00, 157.34it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:18<00:00, 172.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 172.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 172.58it/s]
2023-02-07 19:46:03.869 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:46:03,870][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d470,n5,mc8,s0.768609,t4>', 'datetime': '2023-02-07T19:46:03.870229', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:46:03,870][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:46:03,870][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:46:04,398][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:46:04,399][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:46:04,444][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 13798 unique words (43.39% of original 31803, drops 18005)', 'datetime': '2023-02-07T19:46:04.444480', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:46:04,446][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 5042429 word corpus (98.97% of original 5095118, drops 52689)', 'datetime': '2023-02-07T19:46:04.446859', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:46:04,497][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:46:04,499][gensim.models.word2vec][INFO] - sample=0.768609 downsamples 0 most-common words
[2023-02-07 19:46:04,500][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5042429 word corpus (100.0%% of prior 5042429)', 'datetime': '2023-02-07T19:46:04.500180', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:46:04,588][gensim.models.word2vec][INFO] - estimated required memory for 13798 words and 470 dimensions: 65554040 bytes
[2023-02-07 19:46:04,588][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:46:04,628][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 13798 vocabulary and 470 features, using sg=1 hs=0 sample=0.7686090522981699 negative=5 window=12 shrink_windows=True', 'datetime': '2023-02-07T19:46:04.628876', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:46:05,635][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 27.42% examples, 1386811 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:06,640][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 54.59% examples, 1402047 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:07,640][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 84.99% examples, 1436076 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:08,037][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5034594 effective words) took 3.4s, 1478644 effective words/s
[2023-02-07 19:46:09,052][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 35.77% examples, 1806906 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:10,053][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 72.21% examples, 1833898 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:10,813][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5034594 effective words) took 2.8s, 1814340 effective words/s
[2023-02-07 19:46:11,823][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 30.95% examples, 1561075 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:12,831][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 61.84% examples, 1567723 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:46:13,841][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 92.78% examples, 1555392 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:14,043][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5034594 effective words) took 3.2s, 1560003 effective words/s
[2023-02-07 19:46:15,046][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 31.01% examples, 1576586 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:16,048][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 62.45% examples, 1592135 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:17,049][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 94.20% examples, 1583617 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:17,219][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5034594 effective words) took 3.2s, 1586020 effective words/s
[2023-02-07 19:46:18,222][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 30.89% examples, 1562546 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:19,236][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 61.84% examples, 1568972 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:20,241][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 94.20% examples, 1575935 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:20,408][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5034594 effective words) took 3.2s, 1580298 effective words/s
[2023-02-07 19:46:21,415][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 30.95% examples, 1564196 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:22,423][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 61.84% examples, 1568927 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:23,425][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 93.80% examples, 1571373 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:23,604][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5034594 effective words) took 3.2s, 1575785 effective words/s
[2023-02-07 19:46:24,611][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 30.89% examples, 1555638 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:25,611][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 61.59% examples, 1571961 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:26,613][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 93.06% examples, 1567549 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:26,809][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5034594 effective words) took 3.2s, 1571676 effective words/s
[2023-02-07 19:46:27,819][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 30.95% examples, 1561129 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:28,819][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 62.39% examples, 1585925 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:29,821][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 94.20% examples, 1580770 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:29,993][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5034594 effective words) took 3.2s, 1582360 effective words/s
[2023-02-07 19:46:31,002][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 30.70% examples, 1545944 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:32,006][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 60.73% examples, 1545930 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:33,013][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 92.14% examples, 1547250 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:33,236][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5034594 effective words) took 3.2s, 1553784 effective words/s
[2023-02-07 19:46:34,241][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 31.01% examples, 1575270 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:35,242][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 62.45% examples, 1592331 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:36,245][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 94.60% examples, 1588269 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:36,397][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5034594 effective words) took 3.2s, 1594587 effective words/s
[2023-02-07 19:46:37,400][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 31.26% examples, 1586527 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:38,407][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 59.47% examples, 1522114 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:39,408][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 89.62% examples, 1508195 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:39,735][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5034594 effective words) took 3.3s, 1509028 effective words/s
[2023-02-07 19:46:40,744][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 29.51% examples, 1475588 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:41,754][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 57.91% examples, 1479630 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:42,754][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 88.58% examples, 1484729 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:43,130][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5034594 effective words) took 3.4s, 1483843 effective words/s
[2023-02-07 19:46:44,145][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 29.51% examples, 1467077 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:45,156][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 57.91% examples, 1474034 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:46,160][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 89.62% examples, 1498781 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:46,412][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5034594 effective words) took 3.3s, 1534792 effective words/s
[2023-02-07 19:46:47,428][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 35.89% examples, 1806345 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:48,429][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 70.37% examples, 1797217 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:49,219][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5034594 effective words) took 2.8s, 1794614 effective words/s
[2023-02-07 19:46:50,221][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 33.83% examples, 1725498 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:46:51,225][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 63.00% examples, 1609858 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:52,230][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 93.52% examples, 1572095 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:46:52,431][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5034594 effective words) took 3.2s, 1568138 effective words/s
[2023-02-07 19:46:52,432][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75518910 effective words) took 47.8s, 1579794 effective words/s', 'datetime': '2023-02-07T19:46:52.432428', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:46:52.432 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:46:55,655][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194536-6yacmgce/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:46:55.655753', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:46:55,656][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:46:55,739][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194536-6yacmgce/files/../tmp/embedding_model.pt
2023-02-07 19:46:55.739 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:46:58.091 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:46:58.876 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:47:02.014 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0608145037484997, 'test_mae': 0.7941593857356376, 'test_r2': -1.9618525283989183}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.44
wandb: percentage 0.56614
wandb:   test_mae 0.79416
wandb:   test_mse 1.06081
wandb:    test_r2 -1.96185
wandb: 
wandb: üöÄ View run soft-sweep-56 at: https://wandb.ai/xiaoqiz/mof2vec/runs/6yacmgce
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_194536-6yacmgce/logs
wandb: Agent Starting Run: 2vychemk with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 929
wandb: 	model.gensim.alpha: 0.0003740797662051408
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 4
wandb: 	model.gensim.sample: 0.20795641776681395
wandb: 	model.gensim.vector_size: 266
wandb: 	model.gensim.window: 13
wandb: 	model.sklearn.learning_rate: 0.0019863748013216735
wandb: 	model.sklearn.max_depth: 42
wandb: 	model.sklearn.min_child_weight: 0.07712259151524685
wandb: 	model.sklearn.n_estimators: 2394
wandb: 	model.sklearn.num_leaves: 241
wandb: 	model.sklearn.reg_alpha: 0.005830147951591475
wandb: 	model.sklearn.reg_lambda: 0.03889542686149804
wandb: 	model.sklearn.subsample: 0.8480741374702583
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194711-2vychemk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-57
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/2vychemk
2023-02-07 19:47:19.863 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 19:47:19.864 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 929 for sweep.
2023-02-07 19:47:19.864 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0003740797662051408 for sweep.
2023-02-07 19:47:19.864 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:47:19.865 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 4 for sweep.
2023-02-07 19:47:19.865 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.20795641776681395 for sweep.
2023-02-07 19:47:19.865 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 266 for sweep.
2023-02-07 19:47:19.865 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 13 for sweep.
2023-02-07 19:47:19.866 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0019863748013216735 for sweep.
2023-02-07 19:47:19.866 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 42 for sweep.
2023-02-07 19:47:19.866 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.07712259151524685 for sweep.
2023-02-07 19:47:19.867 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2394 for sweep.
2023-02-07 19:47:19.867 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 241 for sweep.
2023-02-07 19:47:19.868 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.005830147951591475 for sweep.
2023-02-07 19:47:19.868 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.03889542686149804 for sweep.
2023-02-07 19:47:19.868 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8480741374702583 for sweep.
2023-02-07 19:47:19.868 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:47:19.875 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194711-2vychemk/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 929, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 266, 'window': 13, 'min_count': 4, 'dm': 0, 'sample': 0.20795641776681395, 'workers': 4, 'alpha': 0.0003740797662051408, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2394, 'max_depth': 42, 'num_leaves': 241, 'reg_alpha': 0.005830147951591475, 'reg_lambda': 0.03889542686149804, 'subsample': 0.8480741374702583, 'min_child_weight': 0.07712259151524685, 'n_jobs': 4, 'learning_rate': 0.0019863748013216735}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 175.17it/s]  1%|          | 38/3257 [00:00<00:17, 188.78it/s]  2%|‚ñè         | 57/3257 [00:00<00:17, 185.23it/s]  2%|‚ñè         | 80/3257 [00:00<00:15, 200.74it/s]  3%|‚ñé         | 101/3257 [00:00<00:15, 201.01it/s]  4%|‚ñé         | 122/3257 [00:00<00:16, 190.02it/s]  4%|‚ñç         | 146/3257 [00:00<00:15, 204.77it/s]  5%|‚ñå         | 167/3257 [00:00<00:15, 197.47it/s]  6%|‚ñå         | 188/3257 [00:00<00:15, 199.17it/s]  6%|‚ñã         | 209/3257 [00:01<00:15, 199.34it/s]  7%|‚ñã         | 234/3257 [00:01<00:14, 213.19it/s]  8%|‚ñä         | 256/3257 [00:01<00:14, 210.28it/s]  9%|‚ñä         | 282/3257 [00:01<00:13, 221.31it/s]  9%|‚ñâ         | 305/3257 [00:01<00:13, 223.48it/s] 10%|‚ñà         | 331/3257 [00:01<00:12, 230.96it/s] 11%|‚ñà         | 355/3257 [00:01<00:13, 222.76it/s] 12%|‚ñà‚ñè        | 380/3257 [00:01<00:12, 228.23it/s] 12%|‚ñà‚ñè        | 406/3257 [00:01<00:12, 235.48it/s] 13%|‚ñà‚ñé        | 430/3257 [00:02<00:12, 224.13it/s] 14%|‚ñà‚ñç        | 457/3257 [00:02<00:11, 235.42it/s] 15%|‚ñà‚ñç        | 483/3257 [00:02<00:11, 241.83it/s] 16%|‚ñà‚ñå        | 513/3257 [00:02<00:10, 256.02it/s] 17%|‚ñà‚ñã        | 540/3257 [00:02<00:10, 259.66it/s] 17%|‚ñà‚ñã        | 567/3257 [00:02<00:10, 246.39it/s] 18%|‚ñà‚ñä        | 593/3257 [00:02<00:10, 249.83it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:02<00:10, 254.62it/s] 20%|‚ñà‚ñâ        | 649/3257 [00:02<00:09, 262.56it/s] 21%|‚ñà‚ñà        | 676/3257 [00:02<00:10, 251.91it/s] 22%|‚ñà‚ñà‚ñè       | 702/3257 [00:03<00:10, 241.24it/s] 22%|‚ñà‚ñà‚ñè       | 727/3257 [00:03<00:10, 234.92it/s] 23%|‚ñà‚ñà‚ñé       | 751/3257 [00:03<00:10, 230.93it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:03<00:10, 235.19it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:03<00:09, 246.17it/s] 25%|‚ñà‚ñà‚ñå       | 829/3257 [00:03<00:10, 237.43it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:03<00:10, 226.56it/s] 27%|‚ñà‚ñà‚ñã       | 876/3257 [00:03<00:10, 226.70it/s] 28%|‚ñà‚ñà‚ñä       | 902/3257 [00:03<00:10, 235.48it/s] 28%|‚ñà‚ñà‚ñä       | 926/3257 [00:04<00:14, 164.02it/s] 29%|‚ñà‚ñà‚ñâ       | 951/3257 [00:04<00:12, 182.78it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:04<00:11, 192.85it/s] 31%|‚ñà‚ñà‚ñà       | 996/3257 [00:04<00:11, 195.47it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1020/3257 [00:04<00:10, 206.93it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1042/3257 [00:04<00:11, 199.06it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:04<00:10, 210.70it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1090/3257 [00:04<00:10, 215.02it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1113/3257 [00:05<00:09, 218.61it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1136/3257 [00:05<00:10, 211.64it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1158/3257 [00:05<00:09, 210.54it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1180/3257 [00:05<00:10, 204.58it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1201/3257 [00:05<00:10, 195.97it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1225/3257 [00:05<00:09, 207.34it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1249/3257 [00:05<00:09, 215.89it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1273/3257 [00:05<00:08, 221.26it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1296/3257 [00:05<00:09, 204.44it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1319/3257 [00:06<00:09, 209.94it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1343/3257 [00:06<00:08, 217.63it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1366/3257 [00:06<00:09, 210.07it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:06<00:08, 210.36it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1417/3257 [00:06<00:07, 232.46it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1441/3257 [00:06<00:07, 230.05it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1471/3257 [00:06<00:07, 248.38it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1497/3257 [00:06<00:07, 249.02it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1523/3257 [00:06<00:07, 240.51it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1548/3257 [00:07<00:07, 227.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:07<00:07, 235.03it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1598/3257 [00:07<00:07, 235.13it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1626/3257 [00:07<00:06, 247.44it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1651/3257 [00:07<00:06, 233.00it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1675/3257 [00:07<00:06, 226.77it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:07<00:06, 231.02it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1727/3257 [00:07<00:06, 239.66it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1752/3257 [00:07<00:06, 224.58it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1777/3257 [00:08<00:06, 229.52it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1801/3257 [00:08<00:06, 230.66it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1825/3257 [00:08<00:06, 226.45it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1848/3257 [00:08<00:06, 225.37it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1875/3257 [00:08<00:05, 236.36it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:08<00:05, 229.29it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1923/3257 [00:08<00:05, 227.30it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1956/3257 [00:08<00:05, 256.07it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:08<00:05, 251.93it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:08<00:05, 247.14it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:09<00:04, 253.44it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2061/3257 [00:09<00:05, 231.52it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2087/3257 [00:09<00:04, 237.37it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2112/3257 [00:09<00:04, 240.52it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:09<00:04, 228.88it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2161/3257 [00:09<00:04, 224.73it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:09<00:04, 227.62it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:10<00:07, 148.56it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2234/3257 [00:10<00:06, 169.30it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2255/3257 [00:10<00:05, 176.97it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:10<00:05, 181.41it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2303/3257 [00:10<00:04, 203.59it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2333/3257 [00:10<00:04, 228.89it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2362/3257 [00:10<00:03, 244.26it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2390/3257 [00:10<00:03, 253.66it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2417/3257 [00:10<00:03, 245.58it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:11<00:03, 228.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2472/3257 [00:11<00:03, 243.95it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2498/3257 [00:11<00:03, 244.32it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2525/3257 [00:11<00:02, 250.63it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2551/3257 [00:11<00:02, 244.76it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2576/3257 [00:11<00:03, 222.62it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2599/3257 [00:11<00:02, 223.05it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2631/3257 [00:11<00:02, 247.86it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2657/3257 [00:11<00:02, 238.18it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2682/3257 [00:11<00:02, 237.32it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2706/3257 [00:12<00:02, 225.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2729/3257 [00:12<00:02, 226.02it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2754/3257 [00:12<00:02, 231.06it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2778/3257 [00:12<00:02, 225.09it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2806/3257 [00:12<00:01, 237.80it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2830/3257 [00:12<00:01, 224.50it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2855/3257 [00:12<00:01, 231.30it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:12<00:01, 249.93it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2912/3257 [00:12<00:01, 241.60it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2937/3257 [00:13<00:01, 240.04it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2962/3257 [00:13<00:01, 232.29it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2986/3257 [00:13<00:01, 224.93it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3013/3257 [00:13<00:01, 237.08it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3039/3257 [00:13<00:00, 240.60it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3068/3257 [00:13<00:00, 252.31it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3094/3257 [00:13<00:00, 249.26it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3123/3257 [00:13<00:00, 260.11it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3150/3257 [00:13<00:00, 236.36it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3175/3257 [00:14<00:00, 235.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3200/3257 [00:14<00:00, 238.37it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3225/3257 [00:14<00:00, 230.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:14<00:00, 241.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:14<00:00, 225.96it/s]
2023-02-07 19:47:34.759 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:47:34,760][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d266,n5,mc4,s0.207956,t4>', 'datetime': '2023-02-07T19:47:34.760796', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:47:34,761][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:47:34,761][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:47:35,076][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 19:47:35,077][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:47:35,101][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 retains 8978 unique words (68.74% of original 13061, drops 4083)', 'datetime': '2023-02-07T19:47:35.101610', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:47:35,102][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 leaves 3632716 word corpus (99.82% of original 3639370, drops 6654)', 'datetime': '2023-02-07T19:47:35.102833', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:47:35,134][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 19:47:35,134][gensim.models.word2vec][INFO] - sample=0.207956 downsamples 0 most-common words
[2023-02-07 19:47:35,134][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3632716 word corpus (100.0%% of prior 3632716)', 'datetime': '2023-02-07T19:47:35.134934', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:47:35,187][gensim.models.word2vec][INFO] - estimated required memory for 8978 words and 266 dimensions: 27711032 bytes
[2023-02-07 19:47:35,188][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:47:35,199][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 8978 vocabulary and 266 features, using sg=1 hs=0 sample=0.20795641776681395 negative=5 window=13 shrink_windows=True', 'datetime': '2023-02-07T19:47:35.199867', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:47:36,207][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 57.35% examples, 2121518 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:36,983][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3635973 effective words) took 1.8s, 2041075 effective words/s
[2023-02-07 19:47:37,987][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 51.61% examples, 1917204 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:38,880][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3635973 effective words) took 1.9s, 1919915 effective words/s
[2023-02-07 19:47:39,886][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 51.61% examples, 1914382 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:47:40,780][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3635973 effective words) took 1.9s, 1916382 effective words/s
[2023-02-07 19:47:41,783][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 51.86% examples, 1928191 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:42,661][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3635973 effective words) took 1.9s, 1935556 effective words/s
[2023-02-07 19:47:43,665][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 52.13% examples, 1936200 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:44,530][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3635973 effective words) took 1.9s, 1948239 effective words/s
[2023-02-07 19:47:45,535][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 62.27% examples, 2292335 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:47:46,133][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3635973 effective words) took 1.6s, 2272400 effective words/s
[2023-02-07 19:47:47,142][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 55.14% examples, 2041738 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:47,903][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3635973 effective words) took 1.8s, 2056944 effective words/s
[2023-02-07 19:47:48,909][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 55.51% examples, 2063322 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:49,662][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3635973 effective words) took 1.8s, 2068982 effective words/s
[2023-02-07 19:47:50,665][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 54.93% examples, 2042604 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:47:51,442][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3635973 effective words) took 1.8s, 2044969 effective words/s
[2023-02-07 19:47:52,445][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 55.51% examples, 2070495 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:47:53,191][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3635973 effective words) took 1.7s, 2081250 effective words/s
[2023-02-07 19:47:54,196][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 56.19% examples, 2093474 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:54,924][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3635973 effective words) took 1.7s, 2101506 effective words/s
[2023-02-07 19:47:55,930][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 56.19% examples, 2090669 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:47:56,664][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3635973 effective words) took 1.7s, 2092465 effective words/s
[2023-02-07 19:47:57,666][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 56.77% examples, 2116421 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:47:58,373][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3635973 effective words) took 1.7s, 2129323 effective words/s
[2023-02-07 19:47:59,378][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 52.53% examples, 1949920 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:48:00,246][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3635973 effective words) took 1.9s, 1944495 effective words/s
[2023-02-07 19:48:01,248][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 52.13% examples, 1938787 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:02,122][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3635973 effective words) took 1.9s, 1940048 effective words/s
[2023-02-07 19:48:02,122][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54539595 effective words) took 26.9s, 2025799 effective words/s', 'datetime': '2023-02-07T19:48:02.122774', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:48:02.123 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:48:04,221][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194711-2vychemk/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:48:04.221252', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:48:04,221][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:48:04,270][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194711-2vychemk/files/../tmp/embedding_model.pt
2023-02-07 19:48:04.271 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:48:06.181 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:48:06.832 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:48:08.473 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0626866542442392, 'test_mae': 0.7992672829265974, 'test_r2': -2.813575006589863}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.04
wandb: percentage 0.31261
wandb:   test_mae 0.79927
wandb:   test_mse 1.06269
wandb:    test_r2 -2.81358
wandb: 
wandb: üöÄ View run neat-sweep-57 at: https://wandb.ai/xiaoqiz/mof2vec/runs/2vychemk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_194711-2vychemk/logs
wandb: Agent Starting Run: iw8hnj62 with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 910
wandb: 	model.gensim.alpha: 0.003317762236654017
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.6534497305605058
wandb: 	model.gensim.vector_size: 403
wandb: 	model.gensim.window: 12
wandb: 	model.sklearn.learning_rate: 0.0028826092743603235
wandb: 	model.sklearn.max_depth: 28
wandb: 	model.sklearn.min_child_weight: 0.03061707621442745
wandb: 	model.sklearn.n_estimators: 3179
wandb: 	model.sklearn.num_leaves: 287
wandb: 	model.sklearn.reg_alpha: 0.002736601046328425
wandb: 	model.sklearn.reg_lambda: 0.1163097417451998
wandb: 	model.sklearn.subsample: 0.8890305772377103
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194820-iw8hnj62
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-58
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/iw8hnj62
2023-02-07 19:48:28.908 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 19:48:28.909 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 910 for sweep.
2023-02-07 19:48:28.909 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.003317762236654017 for sweep.
2023-02-07 19:48:28.910 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 19:48:28.910 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 19:48:28.910 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6534497305605058 for sweep.
2023-02-07 19:48:28.910 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 403 for sweep.
2023-02-07 19:48:28.911 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 12 for sweep.
2023-02-07 19:48:28.911 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0028826092743603235 for sweep.
2023-02-07 19:48:28.911 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 28 for sweep.
2023-02-07 19:48:28.911 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03061707621442745 for sweep.
2023-02-07 19:48:28.911 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 3179 for sweep.
2023-02-07 19:48:28.912 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 287 for sweep.
2023-02-07 19:48:28.912 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.002736601046328425 for sweep.
2023-02-07 19:48:28.912 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.1163097417451998 for sweep.
2023-02-07 19:48:28.912 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8890305772377103 for sweep.
2023-02-07 19:48:28.913 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:48:28.920 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194820-iw8hnj62/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 910, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 403, 'window': 12, 'min_count': 10, 'dm': 1, 'sample': 0.6534497305605058, 'workers': 4, 'alpha': 0.003317762236654017, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 3179, 'max_depth': 28, 'num_leaves': 287, 'reg_alpha': 0.002736601046328425, 'reg_lambda': 0.1163097417451998, 'subsample': 0.8890305772377103, 'min_child_weight': 0.03061707621442745, 'n_jobs': 4, 'learning_rate': 0.0028826092743603235}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 22/3257 [00:00<00:14, 218.85it/s]  1%|‚ñè         | 45/3257 [00:00<00:14, 225.37it/s]  2%|‚ñè         | 68/3257 [00:00<00:14, 226.79it/s]  3%|‚ñé         | 94/3257 [00:00<00:13, 235.23it/s]  4%|‚ñé         | 118/3257 [00:00<00:13, 230.47it/s]  5%|‚ñç         | 147/3257 [00:00<00:12, 246.64it/s]  5%|‚ñå         | 172/3257 [00:00<00:12, 242.20it/s]  6%|‚ñå         | 197/3257 [00:00<00:12, 243.83it/s]  7%|‚ñã         | 222/3257 [00:00<00:12, 243.95it/s]  8%|‚ñä         | 250/3257 [00:01<00:11, 253.03it/s]  8%|‚ñä         | 276/3257 [00:01<00:11, 254.16it/s]  9%|‚ñâ         | 304/3257 [00:01<00:11, 257.89it/s] 10%|‚ñà         | 334/3257 [00:01<00:10, 266.91it/s] 11%|‚ñà         | 361/3257 [00:01<00:15, 186.26it/s] 12%|‚ñà‚ñè        | 384/3257 [00:01<00:14, 195.37it/s] 13%|‚ñà‚ñé        | 409/3257 [00:01<00:13, 208.52it/s] 13%|‚ñà‚ñé        | 432/3257 [00:01<00:14, 201.37it/s] 14%|‚ñà‚ñç        | 457/3257 [00:02<00:13, 213.41it/s] 15%|‚ñà‚ñç        | 480/3257 [00:02<00:12, 217.44it/s] 16%|‚ñà‚ñå        | 510/3257 [00:02<00:11, 238.92it/s] 16%|‚ñà‚ñã        | 535/3257 [00:02<00:11, 240.52it/s] 17%|‚ñà‚ñã        | 560/3257 [00:02<00:11, 228.88it/s] 18%|‚ñà‚ñä        | 584/3257 [00:02<00:11, 224.42it/s] 19%|‚ñà‚ñä        | 610/3257 [00:02<00:11, 234.20it/s] 20%|‚ñà‚ñâ        | 636/3257 [00:02<00:10, 240.55it/s] 20%|‚ñà‚ñà        | 661/3257 [00:02<00:11, 219.10it/s] 21%|‚ñà‚ñà        | 685/3257 [00:03<00:11, 222.20it/s] 22%|‚ñà‚ñà‚ñè       | 711/3257 [00:03<00:10, 231.79it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:03<00:11, 225.90it/s] 23%|‚ñà‚ñà‚ñé       | 759/3257 [00:03<00:11, 225.76it/s] 24%|‚ñà‚ñà‚ñç       | 782/3257 [00:03<00:11, 223.12it/s] 25%|‚ñà‚ñà‚ñç       | 807/3257 [00:03<00:10, 229.13it/s] 26%|‚ñà‚ñà‚ñå       | 831/3257 [00:03<00:10, 227.08it/s] 26%|‚ñà‚ñà‚ñå       | 854/3257 [00:03<00:11, 216.79it/s] 27%|‚ñà‚ñà‚ñã       | 876/3257 [00:03<00:11, 214.84it/s] 28%|‚ñà‚ñà‚ñä       | 898/3257 [00:03<00:11, 214.34it/s] 28%|‚ñà‚ñà‚ñä       | 924/3257 [00:04<00:10, 225.18it/s] 29%|‚ñà‚ñà‚ñâ       | 947/3257 [00:04<00:10, 222.33it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:04<00:10, 223.83it/s] 30%|‚ñà‚ñà‚ñà       | 993/3257 [00:04<00:10, 216.67it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:04<00:10, 214.09it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1037/3257 [00:04<00:10, 212.57it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1059/3257 [00:04<00:10, 209.08it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1082/3257 [00:04<00:10, 212.97it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:04<00:09, 215.23it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1127/3257 [00:05<00:10, 210.67it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1149/3257 [00:05<00:10, 206.10it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1174/3257 [00:05<00:09, 218.03it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1196/3257 [00:05<00:10, 200.81it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:05<00:09, 204.49it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:05<00:09, 219.54it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:05<00:08, 225.48it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1294/3257 [00:05<00:09, 208.24it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1318/3257 [00:05<00:08, 215.55it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1343/3257 [00:06<00:08, 224.73it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1366/3257 [00:06<00:08, 218.94it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1389/3257 [00:06<00:08, 214.30it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1420/3257 [00:06<00:07, 239.87it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1445/3257 [00:06<00:07, 235.40it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1473/3257 [00:06<00:07, 247.77it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1501/3257 [00:06<00:06, 256.64it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1527/3257 [00:06<00:10, 163.40it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1548/3257 [00:07<00:10, 170.80it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:07<00:08, 189.16it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1599/3257 [00:07<00:08, 203.55it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1623/3257 [00:07<00:07, 212.09it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1647/3257 [00:07<00:07, 216.05it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1670/3257 [00:07<00:07, 217.88it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1693/3257 [00:07<00:07, 214.34it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1717/3257 [00:07<00:06, 221.32it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1740/3257 [00:07<00:07, 210.58it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1766/3257 [00:08<00:06, 222.26it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1793/3257 [00:08<00:06, 234.83it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1817/3257 [00:08<00:06, 231.04it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1843/3257 [00:08<00:05, 237.92it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1867/3257 [00:08<00:05, 232.40it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1891/3257 [00:08<00:06, 215.26it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1914/3257 [00:08<00:06, 219.10it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:08<00:06, 206.50it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1962/3257 [00:08<00:05, 217.90it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1985/3257 [00:09<00:06, 204.18it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2006/3257 [00:09<00:06, 205.45it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2029/3257 [00:09<00:05, 209.78it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2051/3257 [00:09<00:06, 191.79it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2071/3257 [00:09<00:06, 187.50it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2091/3257 [00:09<00:06, 190.64it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2111/3257 [00:09<00:05, 191.16it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2131/3257 [00:09<00:06, 178.71it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2150/3257 [00:09<00:06, 180.09it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2172/3257 [00:10<00:05, 189.72it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2192/3257 [00:10<00:05, 190.40it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2212/3257 [00:10<00:05, 183.68it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2233/3257 [00:10<00:05, 189.63it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2253/3257 [00:10<00:05, 187.28it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2272/3257 [00:10<00:05, 180.06it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2294/3257 [00:10<00:05, 191.14it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2314/3257 [00:10<00:04, 192.33it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:10<00:04, 203.01it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2361/3257 [00:10<00:04, 211.63it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2383/3257 [00:11<00:04, 209.35it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2405/3257 [00:11<00:04, 203.49it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2426/3257 [00:11<00:04, 202.74it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2447/3257 [00:11<00:04, 192.15it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2468/3257 [00:11<00:04, 196.78it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2488/3257 [00:11<00:03, 195.49it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2510/3257 [00:11<00:03, 201.21it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2531/3257 [00:11<00:03, 201.95it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2552/3257 [00:11<00:03, 196.29it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:12<00:03, 182.49it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2591/3257 [00:12<00:03, 178.91it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2615/3257 [00:12<00:03, 194.23it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2637/3257 [00:12<00:03, 199.66it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2658/3257 [00:12<00:03, 186.97it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2679/3257 [00:12<00:02, 193.00it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2699/3257 [00:12<00:03, 180.10it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2718/3257 [00:12<00:03, 176.22it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2742/3257 [00:12<00:02, 191.39it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2762/3257 [00:13<00:02, 189.77it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2782/3257 [00:13<00:02, 190.86it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2804/3257 [00:13<00:02, 198.43it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2824/3257 [00:13<00:02, 181.10it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2843/3257 [00:13<00:04, 100.15it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2866/3257 [00:13<00:03, 122.78it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2888/3257 [00:14<00:02, 140.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:14<00:02, 147.53it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:14<00:02, 159.18it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:14<00:01, 161.15it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2967/3257 [00:14<00:01, 167.57it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2986/3257 [00:14<00:01, 169.58it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:14<00:01, 187.87it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3031/3257 [00:14<00:01, 184.94it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3054/3257 [00:14<00:01, 194.95it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3076/3257 [00:15<00:00, 201.62it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3097/3257 [00:15<00:00, 195.83it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3121/3257 [00:15<00:00, 206.85it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3142/3257 [00:15<00:00, 201.72it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3163/3257 [00:15<00:00, 194.87it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:15<00:00, 186.05it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3206/3257 [00:15<00:00, 196.30it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3226/3257 [00:15<00:00, 187.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3252/3257 [00:15<00:00, 205.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:15<00:00, 204.32it/s]
2023-02-07 19:48:45.373 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:48:45,374][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d403,n5,w12,mc10,s0.65345,t4>', 'datetime': '2023-02-07T19:48:45.374861', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:48:45,375][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:48:45,375][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:48:45,705][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 19:48:45,706][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:48:45,721][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 4982 unique words (38.14% of original 13061, drops 8079)', 'datetime': '2023-02-07T19:48:45.721260', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:48:45,721][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 3610861 word corpus (99.22% of original 3639370, drops 28509)', 'datetime': '2023-02-07T19:48:45.721444', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:48:45,737][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 19:48:45,737][gensim.models.word2vec][INFO] - sample=0.65345 downsamples 0 most-common words
[2023-02-07 19:48:45,737][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3610861 word corpus (100.0%% of prior 3610861)', 'datetime': '2023-02-07T19:48:45.737763', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:48:45,765][gensim.models.word2vec][INFO] - estimated required memory for 4982 words and 403 dimensions: 24454652 bytes
[2023-02-07 19:48:45,765][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:48:45,779][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 4982 vocabulary and 403 features, using sg=0 hs=0 sample=0.6534497305605058 negative=5 window=12 shrink_windows=True', 'datetime': '2023-02-07T19:48:45.779415', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:48:46,800][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 27.66% examples, 985819 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:48:47,802][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 54.01% examples, 991414 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:48:48,811][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 82.68% examples, 993592 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:48:49,417][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3614118 effective words) took 3.6s, 994191 effective words/s
[2023-02-07 19:48:50,419][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 26.68% examples, 969001 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:51,424][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 52.53% examples, 967920 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:48:52,432][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 81.21% examples, 982133 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:53,076][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3614118 effective words) took 3.7s, 988179 effective words/s
[2023-02-07 19:48:54,092][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 27.66% examples, 990167 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:55,096][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 54.31% examples, 998033 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:48:56,100][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 82.87% examples, 1001921 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:48:56,742][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3614118 effective words) took 3.7s, 986460 effective words/s
[2023-02-07 19:48:57,752][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 25.33% examples, 909184 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:48:58,758][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 49.95% examples, 911187 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:48:59,783][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 75.93% examples, 916722 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:00,683][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3614118 effective words) took 3.9s, 917694 effective words/s
[2023-02-07 19:49:01,693][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 25.18% examples, 899234 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:02,694][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 49.95% examples, 913326 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:49:03,696][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 75.25% examples, 918988 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:04,566][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3614118 effective words) took 3.9s, 931391 effective words/s
[2023-02-07 19:49:05,578][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 30.03% examples, 1075268 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:06,586][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 57.35% examples, 1050842 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:49:07,591][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 85.20% examples, 1029052 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:08,104][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3614118 effective words) took 3.5s, 1021967 effective words/s
[2023-02-07 19:49:09,108][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 27.33% examples, 992597 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:10,121][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.21% examples, 980750 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:11,123][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 81.98% examples, 990187 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:49:11,744][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3614118 effective words) took 3.6s, 993462 effective words/s
[2023-02-07 19:49:12,748][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 27.11% examples, 983763 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:49:13,750][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 53.42% examples, 990793 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:14,752][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 82.87% examples, 1007233 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:15,389][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3614118 effective words) took 3.6s, 992023 effective words/s
[2023-02-07 19:49:16,394][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 25.94% examples, 940674 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:17,398][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 51.12% examples, 942231 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:18,399][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 77.56% examples, 941220 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:49:19,238][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3614118 effective words) took 3.8s, 939757 effective words/s
[2023-02-07 19:49:20,240][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 25.79% examples, 933339 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:21,240][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 50.20% examples, 926296 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:22,250][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 77.22% examples, 937700 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:23,091][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3614118 effective words) took 3.9s, 938523 effective words/s
[2023-02-07 19:49:24,108][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 29.75% examples, 1060954 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:25,117][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 57.35% examples, 1047748 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:26,122][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 85.66% examples, 1030170 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:26,600][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3614118 effective words) took 3.5s, 1030599 effective words/s
[2023-02-07 19:49:27,616][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 27.66% examples, 989502 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:49:28,621][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 54.04% examples, 992661 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:49:29,626][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 82.74% examples, 997636 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:30,207][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3614118 effective words) took 3.6s, 1002384 effective words/s
[2023-02-07 19:49:31,223][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 27.66% examples, 990290 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:32,224][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 54.59% examples, 1003826 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:33,247][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 83.88% examples, 1008877 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:49:33,831][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3614118 effective words) took 3.6s, 997746 effective words/s
[2023-02-07 19:49:34,835][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 25.79% examples, 932136 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:35,848][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 50.94% examples, 933813 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:49:36,849][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 77.22% examples, 935788 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:49:37,696][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3614118 effective words) took 3.9s, 935732 effective words/s
[2023-02-07 19:49:38,719][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 25.79% examples, 914185 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:39,727][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 51.12% examples, 931544 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:40,743][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 77.56% examples, 929671 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:49:41,519][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3614118 effective words) took 3.8s, 945716 effective words/s
[2023-02-07 19:49:41,520][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54211770 effective words) took 55.7s, 972570 effective words/s', 'datetime': '2023-02-07T19:49:41.520362', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:49:41.520 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:49:44,694][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194820-iw8hnj62/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:49:44.694485', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:49:44,695][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:49:44,734][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_194820-iw8hnj62/files/../tmp/embedding_model.pt
2023-02-07 19:49:44.734 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:49:46.981 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:49:47.752 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:49:50.447 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0602992258066368, 'test_mae': 0.7837529983714314, 'test_r2': -2.6126567395609945}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.032 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.032 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.31
wandb: percentage 0.61856
wandb:   test_mae 0.78375
wandb:   test_mse 1.0603
wandb:    test_r2 -2.61266
wandb: 
wandb: üöÄ View run stoic-sweep-58 at: https://wandb.ai/xiaoqiz/mof2vec/runs/iw8hnj62
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_194820-iw8hnj62/logs
wandb: Agent Starting Run: f9uy1mx3 with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 301
wandb: 	model.gensim.alpha: 0.00783523905275517
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.8299946500438466
wandb: 	model.gensim.vector_size: 325
wandb: 	model.gensim.window: 1
wandb: 	model.sklearn.learning_rate: 0.048896000697283136
wandb: 	model.sklearn.max_depth: 62
wandb: 	model.sklearn.min_child_weight: 0.03502848735671506
wandb: 	model.sklearn.n_estimators: 1182
wandb: 	model.sklearn.num_leaves: 113
wandb: 	model.sklearn.reg_alpha: 0.002832772986234042
wandb: 	model.sklearn.reg_lambda: 0.034904906470422464
wandb: 	model.sklearn.subsample: 0.6022698983521259
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195001-f9uy1mx3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-59
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/f9uy1mx3
2023-02-07 19:50:10.082 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:50:10.083 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 301 for sweep.
2023-02-07 19:50:10.083 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.00783523905275517 for sweep.
2023-02-07 19:50:10.083 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:50:10.084 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 19:50:10.084 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8299946500438466 for sweep.
2023-02-07 19:50:10.084 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 325 for sweep.
2023-02-07 19:50:10.084 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 1 for sweep.
2023-02-07 19:50:10.085 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.048896000697283136 for sweep.
2023-02-07 19:50:10.085 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 62 for sweep.
2023-02-07 19:50:10.086 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03502848735671506 for sweep.
2023-02-07 19:50:10.086 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1182 for sweep.
2023-02-07 19:50:10.086 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 113 for sweep.
2023-02-07 19:50:10.086 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.002832772986234042 for sweep.
2023-02-07 19:50:10.087 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.034904906470422464 for sweep.
2023-02-07 19:50:10.087 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6022698983521259 for sweep.
2023-02-07 19:50:10.087 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:50:10.098 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195001-f9uy1mx3/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 301, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 325, 'window': 1, 'min_count': 6, 'dm': 0, 'sample': 0.8299946500438466, 'workers': 4, 'alpha': 0.00783523905275517, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1182, 'max_depth': 62, 'num_leaves': 113, 'reg_alpha': 0.002832772986234042, 'reg_lambda': 0.034904906470422464, 'subsample': 0.6022698983521259, 'min_child_weight': 0.03502848735671506, 'n_jobs': 4, 'learning_rate': 0.048896000697283136}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:26, 122.47it/s]  1%|          | 29/3257 [00:00<00:22, 141.91it/s]  1%|‚ñè         | 44/3257 [00:00<00:23, 139.01it/s]  2%|‚ñè         | 58/3257 [00:00<00:23, 135.00it/s]  2%|‚ñè         | 74/3257 [00:00<00:22, 142.86it/s]  3%|‚ñé         | 90/3257 [00:00<00:21, 145.67it/s]  3%|‚ñé         | 105/3257 [00:00<00:22, 142.89it/s]  4%|‚ñé         | 120/3257 [00:00<00:22, 139.89it/s]  4%|‚ñç         | 135/3257 [00:00<00:22, 139.41it/s]  5%|‚ñç         | 152/3257 [00:01<00:21, 144.72it/s]  5%|‚ñå         | 167/3257 [00:01<00:22, 139.07it/s]  6%|‚ñå         | 181/3257 [00:01<00:22, 137.95it/s]  6%|‚ñå         | 198/3257 [00:01<00:20, 145.68it/s]  7%|‚ñã         | 216/3257 [00:01<00:20, 150.38it/s]  7%|‚ñã         | 234/3257 [00:01<00:19, 157.54it/s]  8%|‚ñä         | 250/3257 [00:01<00:19, 153.21it/s]  8%|‚ñä         | 266/3257 [00:01<00:20, 148.23it/s]  9%|‚ñâ         | 287/3257 [00:01<00:18, 162.20it/s]  9%|‚ñâ         | 304/3257 [00:02<00:19, 155.03it/s] 10%|‚ñâ         | 321/3257 [00:02<00:18, 157.94it/s] 10%|‚ñà         | 337/3257 [00:02<00:19, 152.01it/s] 11%|‚ñà         | 353/3257 [00:02<00:19, 148.48it/s] 11%|‚ñà‚ñè        | 368/3257 [00:02<00:19, 148.73it/s] 12%|‚ñà‚ñè        | 383/3257 [00:02<00:20, 142.48it/s] 12%|‚ñà‚ñè        | 398/3257 [00:02<00:21, 135.86it/s] 13%|‚ñà‚ñé        | 415/3257 [00:02<00:19, 142.66it/s] 13%|‚ñà‚ñé        | 430/3257 [00:03<00:23, 121.97it/s] 14%|‚ñà‚ñé        | 443/3257 [00:03<00:22, 123.74it/s] 14%|‚ñà‚ñç        | 458/3257 [00:03<00:21, 130.34it/s] 15%|‚ñà‚ñç        | 474/3257 [00:03<00:20, 134.74it/s] 15%|‚ñà‚ñç        | 488/3257 [00:03<00:20, 132.04it/s] 15%|‚ñà‚ñå        | 504/3257 [00:03<00:19, 138.93it/s] 16%|‚ñà‚ñå        | 520/3257 [00:03<00:19, 142.50it/s] 16%|‚ñà‚ñã        | 535/3257 [00:03<00:19, 138.71it/s] 17%|‚ñà‚ñã        | 550/3257 [00:03<00:19, 138.15it/s] 17%|‚ñà‚ñã        | 564/3257 [00:04<00:21, 125.57it/s] 18%|‚ñà‚ñä        | 577/3257 [00:04<00:22, 121.45it/s] 18%|‚ñà‚ñä        | 592/3257 [00:04<00:20, 128.41it/s] 19%|‚ñà‚ñä        | 607/3257 [00:04<00:19, 134.01it/s] 19%|‚ñà‚ñâ        | 621/3257 [00:04<00:19, 134.03it/s] 20%|‚ñà‚ñâ        | 638/3257 [00:04<00:18, 142.70it/s] 20%|‚ñà‚ñà        | 653/3257 [00:04<00:19, 135.45it/s] 20%|‚ñà‚ñà        | 667/3257 [00:04<00:20, 128.41it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:20, 126.35it/s] 21%|‚ñà‚ñà‚ñè       | 697/3257 [00:05<00:19, 129.01it/s] 22%|‚ñà‚ñà‚ñè       | 714/3257 [00:05<00:18, 138.25it/s] 22%|‚ñà‚ñà‚ñè       | 728/3257 [00:05<00:19, 128.98it/s] 23%|‚ñà‚ñà‚ñé       | 742/3257 [00:05<00:19, 126.51it/s] 23%|‚ñà‚ñà‚ñé       | 760/3257 [00:05<00:17, 139.77it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:05<00:17, 143.97it/s] 24%|‚ñà‚ñà‚ñç       | 794/3257 [00:05<00:16, 152.46it/s] 25%|‚ñà‚ñà‚ñç       | 810/3257 [00:05<00:22, 107.53it/s] 25%|‚ñà‚ñà‚ñå       | 824/3257 [00:06<00:21, 114.37it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:06<00:19, 125.05it/s] 26%|‚ñà‚ñà‚ñã       | 857/3257 [00:06<00:17, 135.39it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:06<00:16, 147.20it/s] 27%|‚ñà‚ñà‚ñã       | 894/3257 [00:06<00:15, 155.47it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:06<00:14, 162.32it/s] 29%|‚ñà‚ñà‚ñä       | 933/3257 [00:06<00:13, 169.49it/s] 29%|‚ñà‚ñà‚ñâ       | 952/3257 [00:06<00:13, 174.46it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:06<00:13, 174.44it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:06<00:13, 167.64it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:07<00:13, 166.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:07<00:13, 167.40it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1044/3257 [00:07<00:13, 165.00it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:07<00:13, 167.71it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:12, 167.81it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1098/3257 [00:07<00:12, 169.27it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:07<00:12, 170.08it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1135/3257 [00:07<00:12, 166.37it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1152/3257 [00:07<00:12, 162.39it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:08<00:12, 166.96it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:08<00:13, 150.07it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:08<00:13, 152.47it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1221/3257 [00:08<00:12, 156.97it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:08<00:11, 171.64it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1261/3257 [00:08<00:12, 165.62it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1278/3257 [00:08<00:13, 149.81it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1294/3257 [00:08<00:13, 146.49it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:09<00:13, 146.08it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:09<00:12, 155.62it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1347/3257 [00:09<00:11, 163.51it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:09<00:11, 158.08it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1380/3257 [00:09<00:11, 157.44it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1396/3257 [00:09<00:11, 155.68it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1417/3257 [00:09<00:10, 170.47it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1435/3257 [00:09<00:10, 168.29it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1456/3257 [00:09<00:10, 178.41it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1475/3257 [00:09<00:09, 178.96it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1494/3257 [00:10<00:09, 180.62it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:10<00:09, 181.09it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1532/3257 [00:10<00:10, 168.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:10<00:10, 160.78it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1567/3257 [00:10<00:10, 162.75it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1584/3257 [00:10<00:10, 162.57it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1603/3257 [00:10<00:09, 168.21it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1620/3257 [00:10<00:09, 167.91it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1637/3257 [00:10<00:10, 160.75it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:11<00:10, 152.23it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1670/3257 [00:11<00:10, 147.73it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1685/3257 [00:11<00:10, 145.72it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1703/3257 [00:11<00:10, 154.07it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1720/3257 [00:11<00:09, 155.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1736/3257 [00:11<00:10, 143.31it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1754/3257 [00:11<00:09, 151.12it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1774/3257 [00:11<00:09, 159.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1793/3257 [00:11<00:08, 166.80it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1810/3257 [00:12<00:09, 158.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:12<00:08, 160.56it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1845/3257 [00:12<00:08, 165.13it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1863/3257 [00:12<00:08, 168.55it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1881/3257 [00:12<00:08, 169.72it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:12<00:08, 165.09it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:12<00:08, 166.21it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1935/3257 [00:12<00:07, 172.16it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1957/3257 [00:12<00:07, 185.68it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1976/3257 [00:13<00:07, 181.73it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1995/3257 [00:13<00:07, 176.02it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2013/3257 [00:13<00:07, 165.29it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:13<00:07, 168.75it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2050/3257 [00:13<00:07, 156.06it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2066/3257 [00:13<00:12, 92.31it/s]  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:13<00:11, 104.84it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2098/3257 [00:14<00:10, 113.15it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:14<00:08, 128.46it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:14<00:08, 125.44it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2146/3257 [00:14<00:08, 127.69it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:14<00:07, 143.44it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2182/3257 [00:14<00:07, 141.20it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2202/3257 [00:14<00:06, 155.52it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:14<00:06, 154.59it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:14<00:06, 156.57it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2252/3257 [00:15<00:06, 151.95it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2268/3257 [00:15<00:06, 151.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2284/3257 [00:15<00:06, 153.31it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2300/3257 [00:15<00:06, 151.63it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2319/3257 [00:15<00:05, 162.02it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2338/3257 [00:15<00:05, 169.60it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:15<00:05, 177.54it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2380/3257 [00:15<00:04, 181.79it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:15<00:04, 183.99it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2418/3257 [00:16<00:04, 172.58it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2436/3257 [00:16<00:05, 161.21it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2453/3257 [00:16<00:04, 160.86it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:16<00:04, 173.16it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2494/3257 [00:16<00:04, 177.81it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:16<00:04, 183.08it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2535/3257 [00:16<00:03, 187.43it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2554/3257 [00:16<00:04, 171.05it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:16<00:04, 159.49it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2589/3257 [00:17<00:04, 154.76it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2610/3257 [00:17<00:03, 168.48it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2631/3257 [00:17<00:03, 176.61it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2649/3257 [00:17<00:03, 165.38it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2666/3257 [00:17<00:03, 163.00it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2686/3257 [00:17<00:03, 172.17it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:17<00:03, 151.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2720/3257 [00:17<00:03, 149.82it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:17<00:03, 165.21it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2760/3257 [00:18<00:02, 169.95it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2778/3257 [00:18<00:02, 160.86it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2799/3257 [00:18<00:02, 173.31it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2817/3257 [00:18<00:02, 163.33it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2834/3257 [00:18<00:02, 159.66it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:18<00:02, 164.88it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2879/3257 [00:18<00:02, 188.84it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2899/3257 [00:18<00:02, 168.23it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2917/3257 [00:19<00:02, 166.62it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2935/3257 [00:19<00:01, 167.67it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2953/3257 [00:19<00:01, 158.83it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2971/3257 [00:19<00:01, 164.30it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2988/3257 [00:19<00:01, 155.37it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:19<00:01, 173.19it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3029/3257 [00:19<00:01, 168.97it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:19<00:01, 177.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3073/3257 [00:19<00:00, 193.96it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3093/3257 [00:20<00:00, 186.75it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3117/3257 [00:20<00:00, 200.86it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3138/3257 [00:20<00:00, 189.04it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3158/3257 [00:20<00:00, 180.25it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3177/3257 [00:20<00:00, 170.56it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3197/3257 [00:20<00:00, 175.29it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3215/3257 [00:20<00:00, 167.99it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3237/3257 [00:20<00:00, 181.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3256/3257 [00:20<00:00, 180.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 155.50it/s]
2023-02-07 19:50:31.959 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:50:31,960][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d325,n5,mc6,s0.829995,t4>', 'datetime': '2023-02-07T19:50:31.960193', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:50:31,961][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:50:31,961][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:50:32,544][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 19:50:32,546][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:50:32,619][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 25857 unique words (47.84% of original 54054, drops 28197)', 'datetime': '2023-02-07T19:50:32.619520', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:50:32,619][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 6477431 word corpus (98.88% of original 6550866, drops 73435)', 'datetime': '2023-02-07T19:50:32.619783', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:50:32,708][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 19:50:32,710][gensim.models.word2vec][INFO] - sample=0.829995 downsamples 0 most-common words
[2023-02-07 19:50:32,710][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6477431 word corpus (100.0%% of prior 6477431)', 'datetime': '2023-02-07T19:50:32.710252', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:50:32,863][gensim.models.word2vec][INFO] - estimated required memory for 25857 words and 325 dimensions: 85042200 bytes
[2023-02-07 19:50:32,863][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:50:32,899][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 25857 vocabulary and 325 features, using sg=1 hs=0 sample=0.8299946500438466 negative=5 window=1 shrink_windows=True', 'datetime': '2023-02-07T19:50:32.899738', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:50:33,906][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 30.06% examples, 1930711 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:34,906][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 60.98% examples, 1986356 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:35,907][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 94.01% examples, 2016121 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:36,081][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6423064 effective words) took 3.2s, 2020407 effective words/s
[2023-02-07 19:50:37,086][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 35.77% examples, 2322014 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:38,087][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 69.88% examples, 2294904 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:38,890][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6423064 effective words) took 2.8s, 2289276 effective words/s
[2023-02-07 19:50:39,893][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 35.19% examples, 2291541 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:40,894][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 70.16% examples, 2299224 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:41,673][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6423064 effective words) took 2.8s, 2309545 effective words/s
[2023-02-07 19:50:42,676][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 36.08% examples, 2346266 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:43,679][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 72.06% examples, 2348811 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:50:44,413][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6423064 effective words) took 2.7s, 2346168 effective words/s
[2023-02-07 19:50:45,421][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 33.87% examples, 2181413 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:46,425][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 65.58% examples, 2137748 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:50:47,426][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 99.66% examples, 2125034 words/s, in_qsize 3, out_qsize 1
[2023-02-07 19:50:47,433][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6423064 effective words) took 3.0s, 2127366 effective words/s
[2023-02-07 19:50:48,437][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 32.39% examples, 2099795 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:49,443][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 64.66% examples, 2104606 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:50,446][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 98.62% examples, 2107429 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:50,480][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6423064 effective words) took 3.0s, 2109530 effective words/s
[2023-02-07 19:50:51,485][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 33.34% examples, 2158990 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:52,490][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 65.80% examples, 2152990 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:53,440][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6423064 effective words) took 3.0s, 2173057 effective words/s
[2023-02-07 19:50:54,442][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 42.98% examples, 2834617 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:55,444][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 86.34% examples, 2789808 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:55,751][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6423064 effective words) took 2.3s, 2781843 effective words/s
[2023-02-07 19:50:56,755][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 41.63% examples, 2743671 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:57,759][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 82.84% examples, 2679038 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:50:58,235][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6423064 effective words) took 2.5s, 2586394 effective words/s
[2023-02-07 19:50:59,238][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 33.87% examples, 2195717 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:51:00,239][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 68.65% examples, 2248479 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:51:00,974][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6423064 effective words) took 2.7s, 2347404 effective words/s
[2023-02-07 19:51:01,976][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 41.45% examples, 2735751 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:51:02,982][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 80.66% examples, 2602856 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:51:03,474][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6423064 effective words) took 2.5s, 2570741 effective words/s
[2023-02-07 19:51:04,476][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 37.55% examples, 2469003 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:51:05,478][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 75.47% examples, 2460054 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:51:06,175][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6423064 effective words) took 2.7s, 2379523 effective words/s
[2023-02-07 19:51:07,182][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 32.91% examples, 2132985 words/s, in_qsize 7, out_qsize 1
[2023-02-07 19:51:08,187][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 65.98% examples, 2153598 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:51:08,999][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6423064 effective words) took 2.8s, 2276759 effective words/s
[2023-02-07 19:51:10,005][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 39.30% examples, 2580799 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:51:11,010][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 77.96% examples, 2515959 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:51:11,566][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6423064 effective words) took 2.6s, 2505255 effective words/s
[2023-02-07 19:51:12,573][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 36.08% examples, 2335035 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:51:13,573][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 68.99% examples, 2257316 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:51:14,454][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6423064 effective words) took 2.9s, 2225618 effective words/s
[2023-02-07 19:51:14,454][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (96345960 effective words) took 41.6s, 2318531 effective words/s', 'datetime': '2023-02-07T19:51:14.454875', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:51:14.455 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:51:18,221][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195001-f9uy1mx3/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:51:18.221752', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:51:18,222][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:51:18,326][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195001-f9uy1mx3/files/../tmp/embedding_model.pt
2023-02-07 19:51:18.326 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:51:20.423 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:51:21.153 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:51:23.298 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9178863476950551, 'test_mae': 0.7437269724676946, 'test_r2': -1.9212527373313755}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.84
wandb: percentage 0.52165
wandb:   test_mae 0.74373
wandb:   test_mse 0.91789
wandb:    test_r2 -1.92125
wandb: 
wandb: üöÄ View run peach-sweep-59 at: https://wandb.ai/xiaoqiz/mof2vec/runs/f9uy1mx3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195001-f9uy1mx3/logs
wandb: Agent Starting Run: chkq9tuo with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 540
wandb: 	model.gensim.alpha: 0.026340465938311176
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.9719685591756076
wandb: 	model.gensim.vector_size: 387
wandb: 	model.gensim.window: 14
wandb: 	model.sklearn.learning_rate: 0.018448599977715092
wandb: 	model.sklearn.max_depth: 86
wandb: 	model.sklearn.min_child_weight: 0.03170546717514289
wandb: 	model.sklearn.n_estimators: 1344
wandb: 	model.sklearn.num_leaves: 276
wandb: 	model.sklearn.reg_alpha: 0.015115159961174369
wandb: 	model.sklearn.reg_lambda: 0.033990265621662234
wandb: 	model.sklearn.subsample: 0.7275788294374244
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195135-chkq9tuo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-60
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/chkq9tuo
2023-02-07 19:51:44.270 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 19:51:44.270 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 540 for sweep.
2023-02-07 19:51:44.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.026340465938311176 for sweep.
2023-02-07 19:51:44.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:51:44.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 19:51:44.271 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9719685591756076 for sweep.
2023-02-07 19:51:44.272 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 387 for sweep.
2023-02-07 19:51:44.272 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 14 for sweep.
2023-02-07 19:51:44.272 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.018448599977715092 for sweep.
2023-02-07 19:51:44.272 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 86 for sweep.
2023-02-07 19:51:44.273 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03170546717514289 for sweep.
2023-02-07 19:51:44.273 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1344 for sweep.
2023-02-07 19:51:44.273 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 276 for sweep.
2023-02-07 19:51:44.273 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.015115159961174369 for sweep.
2023-02-07 19:51:44.273 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.033990265621662234 for sweep.
2023-02-07 19:51:44.274 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7275788294374244 for sweep.
2023-02-07 19:51:44.274 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:51:44.280 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195135-chkq9tuo/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 540, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 387, 'window': 14, 'min_count': 10, 'dm': 0, 'sample': 0.9719685591756076, 'workers': 4, 'alpha': 0.026340465938311176, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1344, 'max_depth': 86, 'num_leaves': 276, 'reg_alpha': 0.015115159961174369, 'reg_lambda': 0.033990265621662234, 'subsample': 0.7275788294374244, 'min_child_weight': 0.03170546717514289, 'n_jobs': 4, 'learning_rate': 0.018448599977715092}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:20, 155.57it/s]  1%|          | 34/3257 [00:00<00:20, 158.55it/s]  2%|‚ñè         | 51/3257 [00:00<00:19, 162.90it/s]  2%|‚ñè         | 68/3257 [00:00<00:20, 158.91it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 169.98it/s]  3%|‚ñé         | 107/3257 [00:00<00:19, 160.65it/s]  4%|‚ñç         | 124/3257 [00:00<00:19, 161.61it/s]  4%|‚ñç         | 145/3257 [00:00<00:17, 174.15it/s]  5%|‚ñå         | 163/3257 [00:00<00:18, 162.97it/s]  6%|‚ñå         | 180/3257 [00:01<00:18, 162.95it/s]  6%|‚ñå         | 199/3257 [00:01<00:17, 170.26it/s]  7%|‚ñã         | 217/3257 [00:01<00:24, 122.80it/s]  7%|‚ñã         | 237/3257 [00:01<00:22, 136.72it/s]  8%|‚ñä         | 256/3257 [00:01<00:20, 149.09it/s]  8%|‚ñä         | 275/3257 [00:01<00:18, 158.13it/s]  9%|‚ñâ         | 297/3257 [00:01<00:17, 171.74it/s] 10%|‚ñâ         | 316/3257 [00:01<00:17, 168.64it/s] 10%|‚ñà         | 336/3257 [00:02<00:16, 173.53it/s] 11%|‚ñà         | 356/3257 [00:02<00:16, 179.36it/s] 12%|‚ñà‚ñè        | 375/3257 [00:02<00:16, 172.28it/s] 12%|‚ñà‚ñè        | 393/3257 [00:02<00:17, 165.27it/s] 13%|‚ñà‚ñé        | 414/3257 [00:02<00:16, 175.70it/s] 13%|‚ñà‚ñé        | 432/3257 [00:02<00:18, 155.80it/s] 14%|‚ñà‚ñç        | 449/3257 [00:02<00:18, 155.56it/s] 14%|‚ñà‚ñç        | 469/3257 [00:02<00:16, 166.37it/s] 15%|‚ñà‚ñç        | 487/3257 [00:03<00:17, 162.29it/s] 16%|‚ñà‚ñå        | 509/3257 [00:03<00:15, 176.96it/s] 16%|‚ñà‚ñå        | 528/3257 [00:03<00:15, 171.41it/s] 17%|‚ñà‚ñã        | 548/3257 [00:03<00:15, 177.71it/s] 17%|‚ñà‚ñã        | 566/3257 [00:03<00:16, 166.65it/s] 18%|‚ñà‚ñä        | 583/3257 [00:03<00:16, 162.11it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:15, 169.56it/s] 19%|‚ñà‚ñâ        | 622/3257 [00:03<00:16, 158.34it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:03<00:16, 161.55it/s] 20%|‚ñà‚ñà        | 657/3257 [00:04<00:18, 140.22it/s] 21%|‚ñà‚ñà        | 673/3257 [00:04<00:17, 144.39it/s] 21%|‚ñà‚ñà        | 688/3257 [00:04<00:18, 135.74it/s] 22%|‚ñà‚ñà‚ñè       | 703/3257 [00:04<00:18, 138.23it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:04<00:17, 143.02it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:04<00:17, 141.70it/s] 23%|‚ñà‚ñà‚ñé       | 750/3257 [00:04<00:18, 131.95it/s] 24%|‚ñà‚ñà‚ñé       | 769/3257 [00:04<00:17, 145.37it/s] 24%|‚ñà‚ñà‚ñç       | 784/3257 [00:05<00:18, 134.86it/s] 25%|‚ñà‚ñà‚ñç       | 801/3257 [00:05<00:17, 143.35it/s] 25%|‚ñà‚ñà‚ñå       | 816/3257 [00:05<00:17, 142.18it/s] 26%|‚ñà‚ñà‚ñå       | 831/3257 [00:05<00:17, 135.43it/s] 26%|‚ñà‚ñà‚ñå       | 845/3257 [00:05<00:18, 129.35it/s] 26%|‚ñà‚ñà‚ñã       | 861/3257 [00:05<00:17, 136.87it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:05<00:17, 134.97it/s] 27%|‚ñà‚ñà‚ñã       | 890/3257 [00:05<00:17, 137.02it/s] 28%|‚ñà‚ñà‚ñä       | 907/3257 [00:05<00:16, 143.18it/s] 28%|‚ñà‚ñà‚ñä       | 923/3257 [00:05<00:15, 147.55it/s] 29%|‚ñà‚ñà‚ñâ       | 938/3257 [00:06<00:16, 142.97it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:06<00:15, 149.97it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:06<00:15, 145.08it/s] 30%|‚ñà‚ñà‚ñà       | 987/3257 [00:06<00:15, 142.13it/s] 31%|‚ñà‚ñà‚ñà       | 1002/3257 [00:06<00:15, 142.31it/s] 31%|‚ñà‚ñà‚ñà       | 1017/3257 [00:06<00:15, 141.35it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1032/3257 [00:06<00:16, 134.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:06<00:17, 128.64it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1060/3257 [00:07<00:16, 131.11it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1077/3257 [00:07<00:15, 141.45it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1092/3257 [00:07<00:16, 128.35it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1109/3257 [00:07<00:15, 137.80it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:07<00:16, 133.04it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:07<00:15, 133.03it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1153/3257 [00:07<00:15, 131.90it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:15, 137.16it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1184/3257 [00:07<00:16, 125.22it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1197/3257 [00:08<00:16, 121.84it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:08<00:17, 117.08it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1227/3257 [00:08<00:15, 129.27it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:08<00:14, 134.61it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1256/3257 [00:08<00:14, 133.85it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:08<00:14, 137.44it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1285/3257 [00:08<00:15, 124.48it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1300/3257 [00:08<00:14, 130.62it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1314/3257 [00:08<00:14, 132.43it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1329/3257 [00:09<00:14, 135.52it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1345/3257 [00:09<00:13, 140.65it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1360/3257 [00:09<00:14, 135.24it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1374/3257 [00:09<00:14, 130.69it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:09<00:14, 127.96it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1405/3257 [00:09<00:13, 138.90it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:09<00:12, 145.64it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1438/3257 [00:09<00:12, 144.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1458/3257 [00:09<00:11, 160.20it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1475/3257 [00:10<00:11, 157.11it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1492/3257 [00:10<00:11, 159.28it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1510/3257 [00:10<00:10, 162.88it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1527/3257 [00:10<00:11, 145.79it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1542/3257 [00:10<00:12, 141.11it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1557/3257 [00:10<00:12, 135.74it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1571/3257 [00:11<00:21, 78.44it/s]  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1584/3257 [00:11<00:19, 87.32it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1600/3257 [00:11<00:16, 101.32it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1616/3257 [00:11<00:14, 114.33it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1632/3257 [00:11<00:13, 124.13it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1647/3257 [00:11<00:13, 117.68it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:11<00:13, 119.64it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1675/3257 [00:11<00:12, 123.26it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1689/3257 [00:11<00:12, 127.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1704/3257 [00:11<00:11, 132.57it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1719/3257 [00:12<00:11, 136.49it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1733/3257 [00:12<00:11, 132.90it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1751/3257 [00:12<00:10, 145.33it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:12<00:09, 158.89it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1791/3257 [00:12<00:08, 170.61it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1809/3257 [00:12<00:09, 159.25it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:12<00:08, 164.18it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:12<00:08, 166.84it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:12<00:07, 175.57it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1887/3257 [00:13<00:07, 175.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1908/3257 [00:13<00:07, 183.83it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1927/3257 [00:13<00:07, 175.32it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1951/3257 [00:13<00:06, 191.70it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1972/3257 [00:13<00:06, 196.62it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1992/3257 [00:13<00:06, 184.36it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2011/3257 [00:13<00:06, 179.49it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:13<00:06, 183.26it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:13<00:07, 167.99it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2070/3257 [00:14<00:07, 163.37it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2088/3257 [00:14<00:07, 166.03it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2105/3257 [00:14<00:07, 163.30it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2122/3257 [00:14<00:07, 151.35it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2140/3257 [00:14<00:07, 157.54it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2156/3257 [00:14<00:07, 153.88it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2175/3257 [00:14<00:06, 163.01it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2192/3257 [00:14<00:06, 156.66it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:14<00:06, 152.69it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2227/3257 [00:15<00:06, 160.02it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2244/3257 [00:15<00:06, 156.74it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2261/3257 [00:15<00:06, 159.42it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2278/3257 [00:15<00:06, 153.80it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:15<00:05, 162.19it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2320/3257 [00:15<00:05, 174.60it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2340/3257 [00:15<00:05, 181.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:15<00:04, 185.65it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2379/3257 [00:15<00:04, 186.87it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:16<00:04, 187.64it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2418/3257 [00:16<00:04, 174.60it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2436/3257 [00:16<00:04, 164.32it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2453/3257 [00:16<00:04, 163.99it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:16<00:04, 178.37it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2494/3257 [00:16<00:04, 181.33it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:16<00:03, 185.84it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2535/3257 [00:16<00:03, 190.67it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2555/3257 [00:16<00:04, 170.82it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:17<00:04, 161.38it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2590/3257 [00:17<00:04, 155.21it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:17<00:03, 175.81it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:17<00:03, 179.81it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2653/3257 [00:17<00:03, 168.94it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2671/3257 [00:17<00:03, 171.50it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2689/3257 [00:17<00:03, 173.28it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2707/3257 [00:17<00:03, 152.56it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2723/3257 [00:18<00:03, 151.44it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2745/3257 [00:18<00:03, 168.56it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2763/3257 [00:18<00:03, 162.99it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2780/3257 [00:18<00:02, 160.73it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2801/3257 [00:18<00:02, 173.16it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2819/3257 [00:18<00:02, 161.67it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2836/3257 [00:18<00:02, 154.30it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2855/3257 [00:18<00:02, 163.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2880/3257 [00:18<00:02, 186.24it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2899/3257 [00:19<00:02, 170.16it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2917/3257 [00:19<00:01, 170.11it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2935/3257 [00:19<00:01, 169.44it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2953/3257 [00:19<00:01, 160.06it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2972/3257 [00:19<00:01, 166.11it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2989/3257 [00:19<00:01, 156.79it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:19<00:01, 172.62it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3029/3257 [00:20<00:02, 87.53it/s]  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:20<00:01, 105.60it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3071/3257 [00:20<00:01, 127.31it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3089/3257 [00:20<00:01, 136.06it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:20<00:00, 151.51it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3129/3257 [00:20<00:00, 160.43it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3148/3257 [00:20<00:00, 154.85it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:20<00:00, 156.56it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:21<00:00, 153.10it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:21<00:00, 162.46it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3220/3257 [00:21<00:00, 156.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3241/3257 [00:21<00:00, 169.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 151.64it/s]
2023-02-07 19:52:06.599 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:52:06,600][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d387,n5,mc10,s0.971969,t4>', 'datetime': '2023-02-07T19:52:06.600682', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:52:06,600][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:52:06,601][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:52:07,195][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 19:52:07,196][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:52:07,251][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 17915 unique words (33.14% of original 54054, drops 36139)', 'datetime': '2023-02-07T19:52:07.251897', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:52:07,252][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 6418960 word corpus (97.99% of original 6550866, drops 131906)', 'datetime': '2023-02-07T19:52:07.252288', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:52:07,314][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 19:52:07,315][gensim.models.word2vec][INFO] - sample=0.971969 downsamples 0 most-common words
[2023-02-07 19:52:07,315][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6418960 word corpus (100.0%% of prior 6418960)', 'datetime': '2023-02-07T19:52:07.315802', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:52:07,420][gensim.models.word2vec][INFO] - estimated required memory for 17915 words and 387 dimensions: 70115576 bytes
[2023-02-07 19:52:07,420][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:52:07,456][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 17915 vocabulary and 387 features, using sg=1 hs=0 sample=0.9719685591756076 negative=5 window=14 shrink_windows=True', 'datetime': '2023-02-07T19:52:07.456865', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:52:08,462][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 30.52% examples, 1949104 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:09,469][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 62.39% examples, 2002441 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:10,472][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 90.45% examples, 1922071 words/s, in_qsize 5, out_qsize 2
[2023-02-07 19:52:10,791][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6365106 effective words) took 3.3s, 1910913 effective words/s
[2023-02-07 19:52:11,794][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 31.04% examples, 1988478 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:12,796][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 59.96% examples, 1936993 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:13,801][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 89.25% examples, 1902218 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:14,135][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6365106 effective words) took 3.3s, 1904745 effective words/s
[2023-02-07 19:52:15,143][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 30.12% examples, 1923479 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:16,149][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 60.18% examples, 1936390 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:17,154][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 90.82% examples, 1933106 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:17,425][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6365106 effective words) took 3.3s, 1937838 effective words/s
[2023-02-07 19:52:18,427][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 32.27% examples, 2077784 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:19,429][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 69.14% examples, 2245383 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:20,261][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6365106 effective words) took 2.8s, 2245505 effective words/s
[2023-02-07 19:52:21,267][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 35.00% examples, 2251457 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:22,268][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 69.42% examples, 2252456 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:23,093][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6365106 effective words) took 2.8s, 2249604 effective words/s
[2023-02-07 19:52:24,104][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 35.06% examples, 2239573 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:25,105][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 68.99% examples, 2233526 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:25,949][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6365106 effective words) took 2.9s, 2230604 effective words/s
[2023-02-07 19:52:26,955][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 34.57% examples, 2216988 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:52:27,958][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 68.84% examples, 2231823 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:28,788][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6365106 effective words) took 2.8s, 2243344 effective words/s
[2023-02-07 19:52:29,791][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 36.17% examples, 2335240 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:30,792][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 67.39% examples, 2186748 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:31,766][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6365106 effective words) took 3.0s, 2139040 effective words/s
[2023-02-07 19:52:32,768][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 31.44% examples, 2008234 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:33,772][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 62.27% examples, 2003612 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:34,775][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 94.32% examples, 2002287 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:34,941][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6365106 effective words) took 3.2s, 2006010 effective words/s
[2023-02-07 19:52:35,946][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 31.50% examples, 2009305 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:36,950][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 62.85% examples, 2026245 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:37,951][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 95.27% examples, 2019380 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:38,095][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6365106 effective words) took 3.2s, 2019447 effective words/s
[2023-02-07 19:52:39,101][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 35.06% examples, 2247652 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:52:40,104][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 71.05% examples, 2300676 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:40,879][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6365106 effective words) took 2.8s, 2287409 effective words/s
[2023-02-07 19:52:41,887][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 34.82% examples, 2229438 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:42,891][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 69.14% examples, 2238186 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:43,734][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6365106 effective words) took 2.9s, 2231438 effective words/s
[2023-02-07 19:52:44,740][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 34.33% examples, 2198729 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:45,740][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 67.70% examples, 2191925 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:46,639][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6365106 effective words) took 2.9s, 2192323 effective words/s
[2023-02-07 19:52:47,643][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 34.33% examples, 2204198 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:48,644][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 68.28% examples, 2214840 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:49,497][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6365106 effective words) took 2.9s, 2228578 effective words/s
[2023-02-07 19:52:50,500][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 32.39% examples, 2083242 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:51,502][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 63.49% examples, 2054585 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:52,506][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 95.61% examples, 2025389 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:52:52,640][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6365106 effective words) took 3.1s, 2025943 effective words/s
[2023-02-07 19:52:52,641][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (95476590 effective words) took 45.2s, 2113100 effective words/s', 'datetime': '2023-02-07T19:52:52.641380', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:52:52.641 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:52:57,060][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195135-chkq9tuo/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:52:57.060352', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:52:57,062][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:52:57,160][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195135-chkq9tuo/files/../tmp/embedding_model.pt
2023-02-07 19:52:57.160 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:52:59.311 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:53:00.026 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:53:02.632 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9854401032990852, 'test_mae': 0.7392896659260878, 'test_r2': -2.531915156326037}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.91
wandb: percentage 0.66857
wandb:   test_mae 0.73929
wandb:   test_mse 0.98544
wandb:    test_r2 -2.53192
wandb: 
wandb: üöÄ View run hearty-sweep-60 at: https://wandb.ai/xiaoqiz/mof2vec/runs/chkq9tuo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195135-chkq9tuo/logs
wandb: Agent Starting Run: vxdtkg62 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 888
wandb: 	model.gensim.alpha: 0.0013856121055079438
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.42441969767967447
wandb: 	model.gensim.vector_size: 238
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.02722058391630004
wandb: 	model.sklearn.max_depth: 38
wandb: 	model.sklearn.min_child_weight: 0.034320946820163595
wandb: 	model.sklearn.n_estimators: 957
wandb: 	model.sklearn.num_leaves: 305
wandb: 	model.sklearn.reg_alpha: 0.0028294426740838796
wandb: 	model.sklearn.reg_lambda: 0.040708391932613365
wandb: 	model.sklearn.subsample: 0.6909383278050103
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195316-vxdtkg62
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-61
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/vxdtkg62
2023-02-07 19:53:24.523 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:53:24.524 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 888 for sweep.
2023-02-07 19:53:24.524 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0013856121055079438 for sweep.
2023-02-07 19:53:24.524 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:53:24.524 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 19:53:24.525 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.42441969767967447 for sweep.
2023-02-07 19:53:24.525 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 238 for sweep.
2023-02-07 19:53:24.526 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 19:53:24.526 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.02722058391630004 for sweep.
2023-02-07 19:53:24.526 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 38 for sweep.
2023-02-07 19:53:24.526 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.034320946820163595 for sweep.
2023-02-07 19:53:24.526 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 957 for sweep.
2023-02-07 19:53:24.527 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 305 for sweep.
2023-02-07 19:53:24.527 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0028294426740838796 for sweep.
2023-02-07 19:53:24.527 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.040708391932613365 for sweep.
2023-02-07 19:53:24.527 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6909383278050103 for sweep.
2023-02-07 19:53:24.528 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:53:24.533 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195316-vxdtkg62/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 888, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 238, 'window': 8, 'min_count': 1, 'dm': 0, 'sample': 0.42441969767967447, 'workers': 4, 'alpha': 0.0013856121055079438, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 957, 'max_depth': 38, 'num_leaves': 305, 'reg_alpha': 0.0028294426740838796, 'reg_lambda': 0.040708391932613365, 'subsample': 0.6909383278050103, 'min_child_weight': 0.034320946820163595, 'n_jobs': 4, 'learning_rate': 0.02722058391630004}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 177.53it/s]  1%|          | 40/3257 [00:00<00:16, 198.98it/s]  2%|‚ñè         | 60/3257 [00:00<00:16, 191.15it/s]  3%|‚ñé         | 84/3257 [00:00<00:15, 204.35it/s]  3%|‚ñé         | 105/3257 [00:00<00:16, 195.16it/s]  4%|‚ñç         | 125/3257 [00:00<00:16, 189.58it/s]  5%|‚ñç         | 149/3257 [00:00<00:15, 201.94it/s]  5%|‚ñå         | 170/3257 [00:00<00:15, 193.76it/s]  6%|‚ñå         | 192/3257 [00:00<00:15, 199.20it/s]  7%|‚ñã         | 214/3257 [00:01<00:14, 204.69it/s]  7%|‚ñã         | 236/3257 [00:01<00:14, 208.70it/s]  8%|‚ñä         | 257/3257 [00:01<00:14, 205.27it/s]  9%|‚ñä         | 282/3257 [00:01<00:13, 218.20it/s]  9%|‚ñâ         | 304/3257 [00:01<00:13, 212.94it/s] 10%|‚ñà         | 328/3257 [00:01<00:13, 220.68it/s] 11%|‚ñà         | 351/3257 [00:01<00:14, 201.10it/s] 11%|‚ñà‚ñè        | 372/3257 [00:01<00:14, 195.30it/s] 12%|‚ñà‚ñè        | 392/3257 [00:01<00:16, 172.38it/s] 13%|‚ñà‚ñé        | 411/3257 [00:02<00:16, 173.61it/s] 13%|‚ñà‚ñé        | 429/3257 [00:02<00:18, 153.38it/s] 14%|‚ñà‚ñé        | 446/3257 [00:02<00:18, 155.97it/s] 14%|‚ñà‚ñç        | 464/3257 [00:02<00:17, 161.04it/s] 15%|‚ñà‚ñç        | 481/3257 [00:02<00:18, 153.85it/s] 15%|‚ñà‚ñå        | 501/3257 [00:02<00:16, 165.33it/s] 16%|‚ñà‚ñå        | 519/3257 [00:02<00:16, 167.63it/s] 16%|‚ñà‚ñã        | 537/3257 [00:02<00:16, 166.08it/s] 17%|‚ñà‚ñã        | 556/3257 [00:03<00:15, 170.62it/s] 18%|‚ñà‚ñä        | 574/3257 [00:03<00:18, 146.82it/s] 18%|‚ñà‚ñä        | 593/3257 [00:03<00:17, 156.55it/s] 19%|‚ñà‚ñâ        | 611/3257 [00:03<00:16, 162.50it/s] 19%|‚ñà‚ñâ        | 628/3257 [00:03<00:16, 161.66it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:16, 158.42it/s] 20%|‚ñà‚ñà        | 662/3257 [00:03<00:17, 148.42it/s] 21%|‚ñà‚ñà        | 681/3257 [00:03<00:16, 158.93it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:03<00:17, 149.03it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:15, 160.58it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:04<00:16, 157.51it/s] 23%|‚ñà‚ñà‚ñé       | 751/3257 [00:04<00:16, 152.98it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:04<00:15, 162.39it/s] 24%|‚ñà‚ñà‚ñç       | 787/3257 [00:04<00:15, 158.19it/s] 25%|‚ñà‚ñà‚ñç       | 805/3257 [00:04<00:15, 162.30it/s] 25%|‚ñà‚ñà‚ñå       | 822/3257 [00:04<00:15, 156.55it/s] 26%|‚ñà‚ñà‚ñå       | 838/3257 [00:04<00:16, 150.68it/s] 26%|‚ñà‚ñà‚ñå       | 854/3257 [00:04<00:16, 147.39it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:05<00:15, 151.68it/s] 27%|‚ñà‚ñà‚ñã       | 887/3257 [00:05<00:15, 149.32it/s] 28%|‚ñà‚ñà‚ñä       | 906/3257 [00:05<00:14, 158.64it/s] 28%|‚ñà‚ñà‚ñä       | 925/3257 [00:05<00:14, 166.57it/s] 29%|‚ñà‚ñà‚ñâ       | 942/3257 [00:05<00:14, 164.11it/s] 29%|‚ñà‚ñà‚ñâ       | 960/3257 [00:05<00:13, 167.40it/s] 30%|‚ñà‚ñà‚ñâ       | 977/3257 [00:05<00:13, 166.76it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:05<00:14, 153.54it/s] 31%|‚ñà‚ñà‚ñà       | 1010/3257 [00:05<00:15, 149.59it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:06<00:14, 149.05it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1043/3257 [00:06<00:15, 146.29it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1059/3257 [00:06<00:14, 148.46it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1078/3257 [00:06<00:13, 159.31it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1095/3257 [00:06<00:23, 91.33it/s]  34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:06<00:20, 105.91it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1126/3257 [00:06<00:19, 112.00it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1141/3257 [00:07<00:17, 118.17it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1157/3257 [00:07<00:16, 126.73it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:07<00:15, 134.87it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:07<00:16, 126.22it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1203/3257 [00:07<00:15, 131.12it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:07<00:14, 136.14it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1238/3257 [00:07<00:13, 153.21it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1254/3257 [00:07<00:13, 152.34it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:07<00:12, 154.03it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1287/3257 [00:08<00:14, 140.34it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1303/3257 [00:08<00:13, 145.17it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:08<00:12, 150.32it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:08<00:12, 156.70it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1355/3257 [00:08<00:12, 149.71it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1372/3257 [00:08<00:12, 150.58it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:08<00:12, 148.96it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1408/3257 [00:08<00:11, 162.48it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1427/3257 [00:08<00:10, 168.25it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1444/3257 [00:09<00:10, 165.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:09<00:10, 169.85it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1481/3257 [00:09<00:10, 166.09it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1500/3257 [00:09<00:10, 172.45it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1518/3257 [00:09<00:10, 168.65it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1535/3257 [00:09<00:11, 153.19it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1552/3257 [00:09<00:10, 155.60it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1570/3257 [00:09<00:10, 161.34it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1587/3257 [00:09<00:10, 159.94it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1607/3257 [00:10<00:09, 170.76it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1631/3257 [00:10<00:08, 188.55it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1651/3257 [00:10<00:08, 181.99it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1671/3257 [00:10<00:08, 181.49it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:10<00:08, 187.58it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:10<00:07, 197.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1735/3257 [00:10<00:08, 184.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1759/3257 [00:10<00:07, 198.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1782/3257 [00:10<00:07, 207.40it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:10<00:06, 208.09it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1824/3257 [00:11<00:06, 206.03it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1845/3257 [00:11<00:07, 199.86it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1868/3257 [00:11<00:06, 206.76it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1889/3257 [00:11<00:06, 200.21it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1911/3257 [00:11<00:06, 205.53it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1932/3257 [00:11<00:06, 203.80it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:11<00:05, 226.12it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1984/3257 [00:11<00:06, 208.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2006/3257 [00:11<00:05, 210.48it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2030/3257 [00:12<00:05, 216.24it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:12<00:06, 192.39it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2072/3257 [00:12<00:06, 188.32it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2092/3257 [00:12<00:06, 189.32it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2112/3257 [00:12<00:06, 184.70it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2131/3257 [00:12<00:06, 173.69it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2149/3257 [00:12<00:06, 173.15it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2171/3257 [00:12<00:05, 185.52it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2190/3257 [00:12<00:05, 182.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:13<00:05, 179.82it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2228/3257 [00:13<00:05, 182.47it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2247/3257 [00:13<00:05, 183.49it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2266/3257 [00:13<00:08, 115.62it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2286/3257 [00:13<00:07, 131.49it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2305/3257 [00:13<00:06, 144.48it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2330/3257 [00:13<00:05, 169.85it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2357/3257 [00:14<00:04, 195.39it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2379/3257 [00:14<00:04, 198.74it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2403/3257 [00:14<00:04, 207.29it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2425/3257 [00:14<00:04, 196.00it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2446/3257 [00:14<00:04, 186.09it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2468/3257 [00:14<00:04, 194.99it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2489/3257 [00:14<00:03, 195.21it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:14<00:03, 206.48it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2538/3257 [00:14<00:03, 214.24it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2560/3257 [00:15<00:03, 202.66it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2581/3257 [00:15<00:03, 193.39it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2601/3257 [00:15<00:03, 194.21it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2627/3257 [00:15<00:02, 211.41it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2649/3257 [00:15<00:03, 199.59it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2670/3257 [00:15<00:02, 199.70it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2691/3257 [00:15<00:02, 201.20it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2712/3257 [00:15<00:03, 179.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2734/3257 [00:15<00:02, 187.72it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:16<00:02, 198.95it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2778/3257 [00:16<00:02, 193.01it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:16<00:02, 208.30it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2825/3257 [00:16<00:02, 193.77it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2845/3257 [00:16<00:02, 194.42it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2873/3257 [00:16<00:01, 217.91it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2896/3257 [00:16<00:01, 200.75it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2918/3257 [00:16<00:01, 205.28it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2939/3257 [00:16<00:01, 203.61it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2960/3257 [00:17<00:01, 191.79it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2980/3257 [00:17<00:01, 191.90it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3002/3257 [00:17<00:01, 199.65it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3023/3257 [00:17<00:01, 194.74it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:17<00:01, 208.05it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3073/3257 [00:17<00:00, 218.60it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3096/3257 [00:17<00:00, 212.79it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3122/3257 [00:17<00:00, 225.74it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3145/3257 [00:17<00:00, 209.59it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3167/3257 [00:18<00:00, 210.34it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3189/3257 [00:18<00:00, 198.24it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3210/3257 [00:18<00:00, 198.49it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3232/3257 [00:18<00:00, 203.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3254/3257 [00:18<00:00, 205.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 176.31it/s]
2023-02-07 19:53:43.700 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:53:43,701][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d238,n5,s0.42442,t4>', 'datetime': '2023-02-07T19:53:43.701517', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:53:43,701][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:53:43,701][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:53:44,239][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:53:44,240][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:53:44,338][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 31803 unique words (100.00% of original 31803, drops 0)', 'datetime': '2023-02-07T19:53:44.338797', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:53:44,339][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 5095118 word corpus (100.00% of original 5095118, drops 0)', 'datetime': '2023-02-07T19:53:44.339280', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:53:44,458][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:53:44,459][gensim.models.word2vec][INFO] - sample=0.42442 downsamples 0 most-common words
[2023-02-07 19:53:44,460][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5095118 word corpus (100.0%% of prior 5095118)', 'datetime': '2023-02-07T19:53:44.460169', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:53:44,666][gensim.models.word2vec][INFO] - estimated required memory for 31803 words and 238 dimensions: 80206476 bytes
[2023-02-07 19:53:44,666][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:53:44,709][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 31803 vocabulary and 238 features, using sg=1 hs=0 sample=0.42441969767967447 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T19:53:44.709313', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:53:45,713][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 36.44% examples, 1889409 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:46,720][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 74.27% examples, 1908278 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:47,370][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5086629 effective words) took 2.7s, 1914351 effective words/s
[2023-02-07 19:53:48,375][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 38.07% examples, 1975511 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:49,379][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 76.54% examples, 1966616 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:49,969][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5086629 effective words) took 2.6s, 1959769 effective words/s
[2023-02-07 19:53:50,981][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 37.64% examples, 1943031 words/s, in_qsize 7, out_qsize 1
[2023-02-07 19:53:51,984][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 76.54% examples, 1960012 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:52,495][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5086629 effective words) took 2.5s, 2015414 effective words/s
[2023-02-07 19:53:53,500][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 48.08% examples, 2495708 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:54,502][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 92.14% examples, 2353927 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:54,666][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5086629 effective words) took 2.2s, 2346704 effective words/s
[2023-02-07 19:53:55,671][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 42.00% examples, 2192248 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:53:56,675][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 86.21% examples, 2203517 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:56,976][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5086629 effective words) took 2.3s, 2205215 effective words/s
[2023-02-07 19:53:57,985][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 42.40% examples, 2207994 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:58,989][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 87.53% examples, 2233502 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:53:59,243][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5086629 effective words) took 2.3s, 2245854 effective words/s
[2023-02-07 19:54:00,250][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 43.23% examples, 2252391 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:01,253][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 89.22% examples, 2277555 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:01,471][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5086629 effective words) took 2.2s, 2286343 effective words/s
[2023-02-07 19:54:02,478][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 38.29% examples, 1986602 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:03,478][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 77.49% examples, 1987365 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:04,036][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5086629 effective words) took 2.6s, 1985496 effective words/s
[2023-02-07 19:54:05,051][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 37.58% examples, 1937866 words/s, in_qsize 7, out_qsize 1
[2023-02-07 19:54:06,061][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 77.06% examples, 1959642 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:54:06,611][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5086629 effective words) took 2.6s, 1977246 effective words/s
[2023-02-07 19:54:07,619][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 38.29% examples, 1982822 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:54:08,620][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 78.17% examples, 2001874 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:09,152][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5086629 effective words) took 2.5s, 2003133 effective words/s
[2023-02-07 19:54:10,155][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 38.47% examples, 2002489 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:11,159][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 90.48% examples, 2308032 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:11,322][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5086629 effective words) took 2.2s, 2347361 effective words/s
[2023-02-07 19:54:12,324][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 51.70% examples, 2688767 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:13,237][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5086629 effective words) took 1.9s, 2657649 effective words/s
[2023-02-07 19:54:14,239][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 45.47% examples, 2360189 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:54:15,243][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 90.33% examples, 2305285 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:15,449][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5086629 effective words) took 2.2s, 2301690 effective words/s
[2023-02-07 19:54:16,457][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 41.23% examples, 2141993 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:54:17,458][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 85.88% examples, 2193779 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:17,753][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5086629 effective words) took 2.3s, 2210686 effective words/s
[2023-02-07 19:54:18,757][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 43.66% examples, 2271324 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:19,757][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 88.58% examples, 2260195 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:54:19,999][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5086629 effective words) took 2.2s, 2266130 effective words/s
[2023-02-07 19:54:20,000][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76299435 effective words) took 35.3s, 2162054 effective words/s', 'datetime': '2023-02-07T19:54:20.000062', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:54:20.000 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:54:22,711][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195316-vxdtkg62/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:54:22.711862', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:54:22,712][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:54:22,805][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195316-vxdtkg62/files/../tmp/embedding_model.pt
2023-02-07 19:54:22.806 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:54:24.423 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:54:25.013 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:54:26.634 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1298301270586493, 'test_mae': 0.8139741187172433, 'test_r2': -2.979961712307498}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.44
wandb: percentage 0.0
wandb:   test_mae 0.81397
wandb:   test_mse 1.12983
wandb:    test_r2 -2.97996
wandb: 
wandb: üöÄ View run blooming-sweep-61 at: https://wandb.ai/xiaoqiz/mof2vec/runs/vxdtkg62
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195316-vxdtkg62/logs
wandb: Agent Starting Run: 2xhck7tf with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 672
wandb: 	model.gensim.alpha: 0.005644435381343682
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.6501020453087741
wandb: 	model.gensim.vector_size: 404
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.02585800258777357
wandb: 	model.sklearn.max_depth: 55
wandb: 	model.sklearn.min_child_weight: 0.0408795227848846
wandb: 	model.sklearn.n_estimators: 2593
wandb: 	model.sklearn.num_leaves: 258
wandb: 	model.sklearn.reg_alpha: 0.0025506217439470644
wandb: 	model.sklearn.reg_lambda: 0.04910696553632825
wandb: 	model.sklearn.subsample: 0.8810851595400573
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195441-2xhck7tf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-62
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/2xhck7tf
2023-02-07 19:54:49.238 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:54:49.239 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 672 for sweep.
2023-02-07 19:54:49.239 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.005644435381343682 for sweep.
2023-02-07 19:54:49.239 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:54:49.239 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 19:54:49.240 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6501020453087741 for sweep.
2023-02-07 19:54:49.240 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 404 for sweep.
2023-02-07 19:54:49.240 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 19:54:49.241 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.02585800258777357 for sweep.
2023-02-07 19:54:49.241 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 55 for sweep.
2023-02-07 19:54:49.241 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0408795227848846 for sweep.
2023-02-07 19:54:49.241 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2593 for sweep.
2023-02-07 19:54:49.241 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 258 for sweep.
2023-02-07 19:54:49.242 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0025506217439470644 for sweep.
2023-02-07 19:54:49.242 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.04910696553632825 for sweep.
2023-02-07 19:54:49.242 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8810851595400573 for sweep.
2023-02-07 19:54:49.242 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:54:49.249 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195441-2xhck7tf/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 672, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 404, 'window': 11, 'min_count': 7, 'dm': 0, 'sample': 0.6501020453087741, 'workers': 4, 'alpha': 0.005644435381343682, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2593, 'max_depth': 55, 'num_leaves': 258, 'reg_alpha': 0.0025506217439470644, 'reg_lambda': 0.04910696553632825, 'subsample': 0.8810851595400573, 'min_child_weight': 0.0408795227848846, 'n_jobs': 4, 'learning_rate': 0.02585800258777357}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 22/3257 [00:00<00:14, 217.26it/s]  1%|‚ñè         | 44/3257 [00:00<00:14, 218.22it/s]  2%|‚ñè         | 67/3257 [00:00<00:15, 212.24it/s]  3%|‚ñé         | 93/3257 [00:00<00:13, 229.08it/s]  4%|‚ñé         | 116/3257 [00:00<00:14, 217.39it/s]  4%|‚ñç         | 141/3257 [00:00<00:13, 225.68it/s]  5%|‚ñå         | 164/3257 [00:00<00:14, 219.45it/s]  6%|‚ñå         | 188/3257 [00:00<00:13, 224.24it/s]  7%|‚ñã         | 212/3257 [00:00<00:13, 226.36it/s]  7%|‚ñã         | 237/3257 [00:01<00:13, 232.27it/s]  8%|‚ñä         | 261/3257 [00:01<00:13, 228.04it/s]  9%|‚ñâ         | 289/3257 [00:01<00:12, 242.44it/s] 10%|‚ñâ         | 314/3257 [00:01<00:13, 223.77it/s] 10%|‚ñà         | 337/3257 [00:01<00:12, 225.20it/s] 11%|‚ñà         | 362/3257 [00:01<00:12, 230.56it/s] 12%|‚ñà‚ñè        | 386/3257 [00:01<00:13, 218.42it/s] 13%|‚ñà‚ñé        | 412/3257 [00:01<00:12, 228.32it/s] 13%|‚ñà‚ñé        | 436/3257 [00:01<00:13, 204.13it/s] 14%|‚ñà‚ñç        | 458/3257 [00:02<00:17, 159.11it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:16, 170.26it/s] 15%|‚ñà‚ñå        | 504/3257 [00:02<00:14, 188.12it/s] 16%|‚ñà‚ñå        | 526/3257 [00:02<00:13, 195.20it/s] 17%|‚ñà‚ñã        | 547/3257 [00:02<00:13, 195.07it/s] 17%|‚ñà‚ñã        | 568/3257 [00:02<00:14, 187.40it/s] 18%|‚ñà‚ñä        | 588/3257 [00:02<00:15, 174.70it/s] 19%|‚ñà‚ñä        | 608/3257 [00:02<00:14, 180.09it/s] 19%|‚ñà‚ñâ        | 627/3257 [00:03<00:14, 177.06it/s] 20%|‚ñà‚ñâ        | 646/3257 [00:03<00:14, 174.13it/s] 20%|‚ñà‚ñà        | 664/3257 [00:03<00:15, 164.06it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:15, 163.62it/s] 21%|‚ñà‚ñà‚ñè       | 700/3257 [00:03<00:15, 164.56it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:03<00:14, 170.37it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:03<00:15, 159.92it/s] 23%|‚ñà‚ñà‚ñé       | 758/3257 [00:03<00:14, 169.34it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:03<00:14, 166.12it/s] 24%|‚ñà‚ñà‚ñç       | 794/3257 [00:04<00:14, 168.87it/s] 25%|‚ñà‚ñà‚ñç       | 812/3257 [00:04<00:14, 168.83it/s] 25%|‚ñà‚ñà‚ñå       | 829/3257 [00:04<00:14, 162.79it/s] 26%|‚ñà‚ñà‚ñå       | 846/3257 [00:04<00:15, 155.88it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:04<00:14, 161.97it/s] 27%|‚ñà‚ñà‚ñã       | 881/3257 [00:04<00:14, 162.67it/s] 28%|‚ñà‚ñà‚ñä       | 901/3257 [00:04<00:13, 172.61it/s] 28%|‚ñà‚ñà‚ñä       | 919/3257 [00:04<00:13, 170.93it/s] 29%|‚ñà‚ñà‚ñâ       | 937/3257 [00:04<00:13, 170.84it/s] 29%|‚ñà‚ñà‚ñâ       | 958/3257 [00:05<00:12, 180.03it/s] 30%|‚ñà‚ñà‚ñà       | 978/3257 [00:05<00:12, 182.66it/s] 31%|‚ñà‚ñà‚ñà       | 997/3257 [00:05<00:12, 181.64it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1019/3257 [00:05<00:11, 192.27it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1039/3257 [00:05<00:11, 186.75it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1060/3257 [00:05<00:11, 191.37it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1081/3257 [00:05<00:11, 195.01it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1103/3257 [00:05<00:10, 199.80it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:05<00:10, 199.62it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:05<00:10, 199.42it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1165/3257 [00:06<00:10, 201.42it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1186/3257 [00:06<00:11, 186.77it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:06<00:11, 178.41it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:06<00:10, 198.52it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1253/3257 [00:06<00:10, 199.12it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:06<00:10, 195.96it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1295/3257 [00:06<00:10, 189.46it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1317/3257 [00:06<00:09, 196.01it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:07<00:09, 199.67it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1360/3257 [00:07<00:09, 190.97it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1380/3257 [00:07<00:09, 189.14it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1399/3257 [00:07<00:09, 187.38it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:07<00:09, 196.23it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1443/3257 [00:07<00:09, 196.51it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1468/3257 [00:07<00:08, 210.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1490/3257 [00:07<00:08, 210.33it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:07<00:08, 214.24it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1535/3257 [00:08<00:13, 128.40it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1554/3257 [00:08<00:12, 139.76it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:08<00:11, 152.37it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1597/3257 [00:08<00:09, 167.24it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:08<00:09, 179.96it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:08<00:08, 183.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1659/3257 [00:08<00:08, 183.13it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1679/3257 [00:08<00:08, 181.41it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:09<00:08, 185.81it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1720/3257 [00:09<00:08, 188.64it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1740/3257 [00:09<00:08, 172.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1762/3257 [00:09<00:08, 184.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1782/3257 [00:09<00:07, 188.66it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1802/3257 [00:09<00:07, 188.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1822/3257 [00:09<00:07, 186.84it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1841/3257 [00:09<00:07, 186.80it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1861/3257 [00:09<00:07, 189.98it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1881/3257 [00:10<00:07, 188.08it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1900/3257 [00:10<00:07, 180.09it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1919/3257 [00:10<00:07, 171.73it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1938/3257 [00:10<00:07, 176.30it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:10<00:06, 188.53it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1980/3257 [00:10<00:07, 176.39it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1998/3257 [00:10<00:07, 177.22it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2016/3257 [00:10<00:07, 169.06it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2034/3257 [00:10<00:07, 169.50it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:11<00:07, 155.54it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2068/3257 [00:11<00:07, 151.32it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:11<00:07, 153.73it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2101/3257 [00:11<00:07, 150.69it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:11<00:07, 151.53it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:11<00:07, 151.44it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2152/3257 [00:11<00:07, 150.16it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:11<00:07, 154.45it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:11<00:07, 150.68it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2203/3257 [00:12<00:06, 158.67it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:12<00:06, 155.00it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:12<00:06, 155.42it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2252/3257 [00:12<00:06, 152.09it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2268/3257 [00:12<00:06, 152.35it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2284/3257 [00:12<00:06, 153.19it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2300/3257 [00:12<00:06, 153.13it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2319/3257 [00:12<00:05, 162.82it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2338/3257 [00:12<00:05, 169.76it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:12<00:04, 179.67it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2378/3257 [00:13<00:04, 177.79it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2403/3257 [00:13<00:04, 197.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2423/3257 [00:13<00:04, 193.37it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:13<00:04, 185.09it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2468/3257 [00:13<00:03, 202.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2491/3257 [00:13<00:03, 208.15it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2519/3257 [00:13<00:03, 224.03it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2542/3257 [00:13<00:03, 225.66it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2565/3257 [00:13<00:03, 218.56it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2587/3257 [00:14<00:03, 208.93it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2612/3257 [00:14<00:02, 219.85it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2637/3257 [00:14<00:02, 228.33it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2660/3257 [00:14<00:02, 205.53it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2682/3257 [00:14<00:02, 208.59it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:14<00:02, 187.49it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2724/3257 [00:14<00:02, 185.18it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2748/3257 [00:14<00:02, 199.07it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2769/3257 [00:14<00:02, 187.65it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:15<00:02, 197.49it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:15<00:02, 195.85it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:15<00:02, 182.04it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:15<00:02, 183.69it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2881/3257 [00:15<00:01, 207.70it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:15<00:01, 192.04it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2926/3257 [00:15<00:01, 201.18it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:16<00:02, 110.48it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2967/3257 [00:16<00:02, 125.28it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:16<00:02, 132.66it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3009/3257 [00:16<00:01, 157.97it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3029/3257 [00:16<00:01, 162.08it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:16<00:01, 169.59it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3070/3257 [00:16<00:01, 178.40it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3090/3257 [00:16<00:00, 174.44it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3109/3257 [00:17<00:00, 178.18it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3128/3257 [00:17<00:00, 178.05it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3147/3257 [00:17<00:00, 164.62it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3164/3257 [00:17<00:00, 163.85it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3181/3257 [00:17<00:00, 157.63it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3201/3257 [00:17<00:00, 165.69it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3218/3257 [00:17<00:00, 158.63it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:17<00:00, 170.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 170.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 181.44it/s]
2023-02-07 19:55:07.999 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:55:08,000][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d404,n5,mc7,s0.650102,t4>', 'datetime': '2023-02-07T19:55:08.000401', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:55:08,002][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:55:08,002][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:55:08,542][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:55:08,543][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:55:08,589][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 14137 unique words (44.45% of original 31803, drops 17666)', 'datetime': '2023-02-07T19:55:08.589110', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:55:08,589][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 5044802 word corpus (99.01% of original 5095118, drops 50316)', 'datetime': '2023-02-07T19:55:08.589576', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:55:08,643][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:55:08,645][gensim.models.word2vec][INFO] - sample=0.650102 downsamples 0 most-common words
[2023-02-07 19:55:08,645][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5044802 word corpus (100.0%% of prior 5044802)', 'datetime': '2023-02-07T19:55:08.645469', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:55:08,735][gensim.models.word2vec][INFO] - estimated required memory for 14137 words and 404 dimensions: 58673996 bytes
[2023-02-07 19:55:08,736][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:55:08,769][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14137 vocabulary and 404 features, using sg=1 hs=0 sample=0.6501020453087741 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T19:55:08.769504', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:55:09,776][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 36.44% examples, 1866132 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:10,778][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 72.52% examples, 1850852 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:11,511][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5036861 effective words) took 2.7s, 1839189 effective words/s
[2023-02-07 19:55:12,520][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 38.29% examples, 1961893 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:13,523][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 73.63% examples, 1869361 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:14,243][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5036861 effective words) took 2.7s, 1845168 effective words/s
[2023-02-07 19:55:15,245][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 34.05% examples, 1735002 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:16,254][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 77.06% examples, 1952442 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:16,795][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5036861 effective words) took 2.6s, 1974548 effective words/s
[2023-02-07 19:55:17,800][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 38.29% examples, 1968606 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:18,816][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 77.06% examples, 1944600 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:19,427][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5036861 effective words) took 2.6s, 1915136 effective words/s
[2023-02-07 19:55:20,440][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 35.06% examples, 1774370 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:21,441][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 69.73% examples, 1787602 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:22,099][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5036861 effective words) took 2.7s, 1886024 effective words/s
[2023-02-07 19:55:23,105][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 43.66% examples, 2245901 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:24,109][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 84.83% examples, 2146724 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:24,461][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5036861 effective words) took 2.4s, 2133588 effective words/s
[2023-02-07 19:55:25,466][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 39.12% examples, 2012583 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:26,467][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 79.12% examples, 2011695 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:26,967][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5036861 effective words) took 2.5s, 2011398 effective words/s
[2023-02-07 19:55:27,972][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 39.18% examples, 2023235 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:28,975][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 79.12% examples, 2010794 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:29,467][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5036861 effective words) took 2.5s, 2017642 effective words/s
[2023-02-07 19:55:30,469][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 39.27% examples, 2031095 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:31,474][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 80.84% examples, 2044984 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:31,919][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5036861 effective words) took 2.5s, 2055696 effective words/s
[2023-02-07 19:55:32,922][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 39.27% examples, 2028912 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:33,932][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 80.75% examples, 2038687 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:34,380][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5036861 effective words) took 2.5s, 2047328 effective words/s
[2023-02-07 19:55:35,391][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 40.50% examples, 2081120 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:36,392][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 82.84% examples, 2098587 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:36,770][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5036861 effective words) took 2.4s, 2110042 effective words/s
[2023-02-07 19:55:37,786][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 35.06% examples, 1771267 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:38,788][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 70.56% examples, 1802085 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:39,555][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5036861 effective words) took 2.8s, 1809900 effective words/s
[2023-02-07 19:55:40,568][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 35.89% examples, 1812843 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:41,570][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 71.11% examples, 1819363 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:42,338][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5036861 effective words) took 2.8s, 1811857 effective words/s
[2023-02-07 19:55:43,350][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 35.06% examples, 1776172 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:44,350][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 70.56% examples, 1806303 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:45,112][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5036861 effective words) took 2.8s, 1817030 effective words/s
[2023-02-07 19:55:46,117][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 42.28% examples, 2190445 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:55:47,118][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 86.21% examples, 2184561 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:55:47,432][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5036861 effective words) took 2.3s, 2174159 effective words/s
[2023-02-07 19:55:47,433][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75552915 effective words) took 38.7s, 1954133 effective words/s', 'datetime': '2023-02-07T19:55:47.433140', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:55:47.434 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:55:50,883][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195441-2xhck7tf/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:55:50.883225', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:55:50,884][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:55:50,961][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195441-2xhck7tf/files/../tmp/embedding_model.pt
2023-02-07 19:55:50.961 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:55:53.202 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:55:53.964 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:55:56.668 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9577523593049893, 'test_mae': 0.7202513013606423, 'test_r2': -1.6297203592010647}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.011 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.76
wandb: percentage 0.55548
wandb:   test_mae 0.72025
wandb:   test_mse 0.95775
wandb:    test_r2 -1.62972
wandb: 
wandb: üöÄ View run apricot-sweep-62 at: https://wandb.ai/xiaoqiz/mof2vec/runs/2xhck7tf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195441-2xhck7tf/logs
wandb: Agent Starting Run: 0ei430c5 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 627
wandb: 	model.gensim.alpha: 0.05305492854770848
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.9895481615603676
wandb: 	model.gensim.vector_size: 392
wandb: 	model.gensim.window: 15
wandb: 	model.sklearn.learning_rate: 0.06659357998289975
wandb: 	model.sklearn.max_depth: 58
wandb: 	model.sklearn.min_child_weight: 0.06427800522749129
wandb: 	model.sklearn.n_estimators: 2354
wandb: 	model.sklearn.num_leaves: 355
wandb: 	model.sklearn.reg_alpha: 0.0053508753683599005
wandb: 	model.sklearn.reg_lambda: 0.039628256984731464
wandb: 	model.sklearn.subsample: 0.8681240700344395
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195606-0ei430c5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-63
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/0ei430c5
2023-02-07 19:56:14.962 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:56:14.963 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 627 for sweep.
2023-02-07 19:56:14.964 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.05305492854770848 for sweep.
2023-02-07 19:56:14.964 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:56:14.964 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 19:56:14.964 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9895481615603676 for sweep.
2023-02-07 19:56:14.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 392 for sweep.
2023-02-07 19:56:14.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 15 for sweep.
2023-02-07 19:56:14.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.06659357998289975 for sweep.
2023-02-07 19:56:14.965 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 58 for sweep.
2023-02-07 19:56:14.966 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.06427800522749129 for sweep.
2023-02-07 19:56:14.966 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2354 for sweep.
2023-02-07 19:56:14.966 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 355 for sweep.
2023-02-07 19:56:14.966 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0053508753683599005 for sweep.
2023-02-07 19:56:14.966 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.039628256984731464 for sweep.
2023-02-07 19:56:14.967 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8681240700344395 for sweep.
2023-02-07 19:56:14.967 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:56:14.975 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195606-0ei430c5/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 627, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 392, 'window': 15, 'min_count': 7, 'dm': 0, 'sample': 0.9895481615603676, 'workers': 4, 'alpha': 0.05305492854770848, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2354, 'max_depth': 58, 'num_leaves': 355, 'reg_alpha': 0.0053508753683599005, 'reg_lambda': 0.039628256984731464, 'subsample': 0.8681240700344395, 'min_child_weight': 0.06427800522749129, 'n_jobs': 4, 'learning_rate': 0.06659357998289975}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:19, 167.70it/s]  1%|          | 39/3257 [00:00<00:17, 189.07it/s]  2%|‚ñè         | 58/3257 [00:00<00:17, 180.86it/s]  2%|‚ñè         | 81/3257 [00:00<00:16, 198.26it/s]  3%|‚ñé         | 101/3257 [00:00<00:16, 194.25it/s]  4%|‚ñé         | 121/3257 [00:00<00:17, 182.46it/s]  4%|‚ñç         | 144/3257 [00:00<00:15, 196.71it/s]  5%|‚ñå         | 164/3257 [00:00<00:16, 187.14it/s]  6%|‚ñå         | 185/3257 [00:00<00:15, 193.39it/s]  6%|‚ñã         | 206/3257 [00:01<00:15, 197.46it/s]  7%|‚ñã         | 231/3257 [00:01<00:14, 209.41it/s]  8%|‚ñä         | 253/3257 [00:01<00:14, 207.08it/s]  8%|‚ñä         | 275/3257 [00:01<00:14, 210.03it/s]  9%|‚ñâ         | 299/3257 [00:01<00:13, 216.98it/s] 10%|‚ñâ         | 321/3257 [00:01<00:13, 217.33it/s] 11%|‚ñà         | 343/3257 [00:01<00:13, 208.84it/s] 11%|‚ñà         | 365/3257 [00:01<00:13, 211.34it/s] 12%|‚ñà‚ñè        | 387/3257 [00:01<00:14, 200.11it/s] 13%|‚ñà‚ñé        | 411/3257 [00:02<00:13, 207.27it/s] 13%|‚ñà‚ñé        | 432/3257 [00:02<00:15, 185.96it/s] 14%|‚ñà‚ñç        | 452/3257 [00:02<00:15, 184.87it/s] 15%|‚ñà‚ñç        | 475/3257 [00:02<00:14, 195.32it/s] 15%|‚ñà‚ñå        | 498/3257 [00:02<00:13, 201.71it/s] 16%|‚ñà‚ñå        | 520/3257 [00:02<00:13, 206.72it/s] 17%|‚ñà‚ñã        | 542/3257 [00:02<00:13, 208.06it/s] 17%|‚ñà‚ñã        | 563/3257 [00:02<00:14, 191.59it/s] 18%|‚ñà‚ñä        | 583/3257 [00:02<00:14, 188.05it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:13, 193.33it/s] 19%|‚ñà‚ñâ        | 625/3257 [00:03<00:13, 195.89it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:13, 196.71it/s] 20%|‚ñà‚ñà        | 665/3257 [00:03<00:13, 188.27it/s] 21%|‚ñà‚ñà        | 685/3257 [00:03<00:13, 187.78it/s] 22%|‚ñà‚ñà‚ñè       | 710/3257 [00:03<00:12, 202.84it/s] 22%|‚ñà‚ñà‚ñè       | 731/3257 [00:03<00:13, 181.18it/s] 23%|‚ñà‚ñà‚ñé       | 750/3257 [00:03<00:14, 170.62it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:03<00:14, 175.29it/s] 24%|‚ñà‚ñà‚ñç       | 788/3257 [00:04<00:14, 164.88it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:14, 163.59it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:04<00:14, 162.30it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:04<00:15, 159.12it/s] 26%|‚ñà‚ñà‚ñã       | 856/3257 [00:04<00:15, 154.10it/s] 27%|‚ñà‚ñà‚ñã       | 872/3257 [00:04<00:24, 98.47it/s]  27%|‚ñà‚ñà‚ñã       | 889/3257 [00:04<00:21, 111.52it/s] 28%|‚ñà‚ñà‚ñä       | 908/3257 [00:05<00:18, 126.74it/s] 28%|‚ñà‚ñà‚ñä       | 925/3257 [00:05<00:17, 136.24it/s] 29%|‚ñà‚ñà‚ñâ       | 941/3257 [00:05<00:16, 139.85it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:05<00:15, 148.22it/s] 30%|‚ñà‚ñà‚ñâ       | 977/3257 [00:05<00:14, 154.77it/s] 31%|‚ñà‚ñà‚ñà       | 994/3257 [00:05<00:15, 147.12it/s] 31%|‚ñà‚ñà‚ñà       | 1010/3257 [00:05<00:15, 146.00it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:05<00:15, 146.12it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1042/3257 [00:05<00:15, 143.87it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1059/3257 [00:06<00:14, 150.15it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:14, 153.16it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:06<00:13, 155.99it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:06<00:13, 159.81it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1132/3257 [00:06<00:14, 149.87it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1148/3257 [00:06<00:14, 148.15it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1168/3257 [00:06<00:12, 161.26it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:06<00:13, 148.34it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1201/3257 [00:07<00:14, 138.80it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:07<00:14, 144.95it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1238/3257 [00:07<00:12, 158.90it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1255/3257 [00:07<00:12, 155.88it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:07<00:12, 157.24it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:07<00:13, 147.68it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1304/3257 [00:07<00:12, 150.71it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:07<00:12, 155.99it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:07<00:11, 161.37it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1356/3257 [00:07<00:12, 154.18it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1372/3257 [00:08<00:12, 152.48it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1388/3257 [00:08<00:12, 151.28it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1407/3257 [00:08<00:11, 161.59it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1426/3257 [00:08<00:10, 168.66it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1443/3257 [00:08<00:10, 168.00it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1465/3257 [00:08<00:09, 181.90it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1484/3257 [00:08<00:09, 179.70it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1504/3257 [00:08<00:09, 185.33it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1523/3257 [00:08<00:10, 170.05it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1541/3257 [00:09<00:10, 164.46it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1558/3257 [00:09<00:10, 158.80it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:09<00:10, 157.52it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:09<00:10, 164.16it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:09<00:09, 174.19it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:09<00:09, 163.99it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1651/3257 [00:09<00:09, 161.06it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:09<00:10, 154.45it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1684/3257 [00:09<00:10, 154.47it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1703/3257 [00:10<00:09, 161.20it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1720/3257 [00:10<00:09, 161.83it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1737/3257 [00:10<00:10, 148.44it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1754/3257 [00:10<00:09, 154.17it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1774/3257 [00:10<00:09, 162.12it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1794/3257 [00:10<00:08, 169.97it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1812/3257 [00:10<00:09, 160.44it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1829/3257 [00:10<00:09, 157.90it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1847/3257 [00:10<00:08, 163.36it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1867/3257 [00:11<00:08, 173.40it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1885/3257 [00:11<00:08, 168.24it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1904/3257 [00:11<00:07, 171.84it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1922/3257 [00:11<00:07, 167.49it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1945/3257 [00:11<00:07, 182.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1968/3257 [00:11<00:06, 193.71it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1988/3257 [00:11<00:07, 179.98it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2007/3257 [00:11<00:06, 179.78it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2027/3257 [00:11<00:06, 184.21it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2046/3257 [00:12<00:06, 183.22it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2065/3257 [00:12<00:06, 176.81it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2086/3257 [00:12<00:06, 185.25it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2108/3257 [00:12<00:05, 192.93it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2128/3257 [00:12<00:05, 189.69it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2148/3257 [00:12<00:05, 186.82it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2172/3257 [00:12<00:05, 201.11it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2193/3257 [00:12<00:05, 202.96it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2214/3257 [00:12<00:05, 199.46it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:13<00:04, 206.46it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2258/3257 [00:13<00:07, 125.85it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:13<00:07, 130.77it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:13<00:06, 153.23it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2324/3257 [00:13<00:05, 175.83it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2350/3257 [00:13<00:04, 195.58it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2372/3257 [00:13<00:04, 198.79it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:13<00:04, 210.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2420/3257 [00:14<00:04, 204.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2442/3257 [00:14<00:04, 194.46it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2465/3257 [00:14<00:03, 203.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2486/3257 [00:14<00:03, 203.29it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2512/3257 [00:14<00:03, 217.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2536/3257 [00:14<00:03, 222.09it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2559/3257 [00:14<00:03, 205.38it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2580/3257 [00:14<00:03, 192.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:14<00:03, 194.30it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2628/3257 [00:15<00:02, 217.10it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2651/3257 [00:15<00:02, 203.22it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2672/3257 [00:15<00:02, 204.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2693/3257 [00:15<00:02, 203.49it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2714/3257 [00:15<00:02, 183.56it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2737/3257 [00:15<00:02, 194.46it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2759/3257 [00:15<00:02, 200.65it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2780/3257 [00:15<00:02, 195.85it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2805/3257 [00:15<00:02, 208.74it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2827/3257 [00:16<00:02, 190.48it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2847/3257 [00:16<00:02, 191.11it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2874/3257 [00:16<00:01, 210.39it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2896/3257 [00:16<00:01, 197.50it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2919/3257 [00:16<00:01, 205.44it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2940/3257 [00:16<00:01, 204.86it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2961/3257 [00:16<00:01, 192.30it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2981/3257 [00:16<00:01, 186.20it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:17<00:01, 195.50it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3024/3257 [00:17<00:01, 190.72it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:17<00:01, 203.31it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3073/3257 [00:17<00:00, 215.76it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3095/3257 [00:17<00:00, 210.99it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3121/3257 [00:17<00:00, 221.95it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3144/3257 [00:17<00:00, 205.47it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:17<00:00, 202.84it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3186/3257 [00:17<00:00, 198.98it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3208/3257 [00:18<00:00, 202.73it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3229/3257 [00:18<00:00, 200.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:18<00:00, 202.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 178.52it/s]
2023-02-07 19:56:33.963 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:56:33,964][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d392,n5,mc7,s0.989548,t4>', 'datetime': '2023-02-07T19:56:33.964439', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:56:33,964][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:56:33,964][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:56:34,434][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:56:34,434][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:56:34,476][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 14137 unique words (44.45% of original 31803, drops 17666)', 'datetime': '2023-02-07T19:56:34.476568', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:56:34,477][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 5044802 word corpus (99.01% of original 5095118, drops 50316)', 'datetime': '2023-02-07T19:56:34.477816', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:56:34,526][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:56:34,527][gensim.models.word2vec][INFO] - sample=0.989548 downsamples 0 most-common words
[2023-02-07 19:56:34,528][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5044802 word corpus (100.0%% of prior 5044802)', 'datetime': '2023-02-07T19:56:34.528735', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:56:34,612][gensim.models.word2vec][INFO] - estimated required memory for 14137 words and 392 dimensions: 57160508 bytes
[2023-02-07 19:56:34,612][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:56:34,641][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14137 vocabulary and 392 features, using sg=1 hs=0 sample=0.9895481615603676 negative=5 window=15 shrink_windows=True', 'datetime': '2023-02-07T19:56:34.641277', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:56:35,647][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 41.85% examples, 2157944 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:36,648][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 85.14% examples, 2160222 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:36,968][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5036861 effective words) took 2.3s, 2166301 effective words/s
[2023-02-07 19:56:37,974][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 48.36% examples, 2483743 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:38,975][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 90.11% examples, 2278470 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:39,198][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5036861 effective words) took 2.2s, 2260990 effective words/s
[2023-02-07 19:56:40,201][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 41.39% examples, 2139273 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:41,203][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 83.14% examples, 2113180 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:41,589][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5036861 effective words) took 2.4s, 2108209 effective words/s
[2023-02-07 19:56:42,592][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 41.23% examples, 2129913 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:43,597][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 84.83% examples, 2149624 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:43,928][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5036861 effective words) took 2.3s, 2155406 effective words/s
[2023-02-07 19:56:44,934][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 42.28% examples, 2184165 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:45,938][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 86.21% examples, 2178795 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:46,234][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5036861 effective words) took 2.3s, 2186167 effective words/s
[2023-02-07 19:56:47,237][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 49.65% examples, 2547936 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:48,184][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5036861 effective words) took 1.9s, 2586180 effective words/s
[2023-02-07 19:56:49,190][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 47.71% examples, 2445734 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:50,200][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 97.36% examples, 2436761 words/s, in_qsize 6, out_qsize 1
[2023-02-07 19:56:50,244][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5036861 effective words) took 2.1s, 2446616 effective words/s
[2023-02-07 19:56:51,254][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 47.71% examples, 2436643 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:52,260][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 97.36% examples, 2437346 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:52,302][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5036861 effective words) took 2.1s, 2449086 effective words/s
[2023-02-07 19:56:53,304][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 48.30% examples, 2482841 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:54,305][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 97.61% examples, 2463500 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:54,348][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5036861 effective words) took 2.0s, 2464047 effective words/s
[2023-02-07 19:56:55,355][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 48.36% examples, 2479556 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:56,355][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 99.11% examples, 2492219 words/s, in_qsize 5, out_qsize 0
[2023-02-07 19:56:56,366][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5036861 effective words) took 2.0s, 2497984 effective words/s
[2023-02-07 19:56:57,369][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 48.08% examples, 2469492 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:56:58,370][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 91.00% examples, 2305731 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:56:58,560][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5036861 effective words) took 2.2s, 2296544 effective words/s
[2023-02-07 19:56:59,568][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 41.85% examples, 2153888 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:57:00,573][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 85.66% examples, 2162289 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:57:00,884][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5036861 effective words) took 2.3s, 2169220 effective words/s
[2023-02-07 19:57:01,895][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 42.40% examples, 2184658 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:57:02,899][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 86.21% examples, 2173635 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:57:03,205][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5036861 effective words) took 2.3s, 2172239 effective words/s
[2023-02-07 19:57:04,208][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 42.28% examples, 2189436 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:57:05,215][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 85.66% examples, 2165314 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:57:05,533][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5036861 effective words) took 2.3s, 2164839 effective words/s
[2023-02-07 19:57:06,540][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 50.63% examples, 2592462 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:57:07,516][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5036861 effective words) took 2.0s, 2543206 effective words/s
[2023-02-07 19:57:07,516][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75552915 effective words) took 32.9s, 2298193 effective words/s', 'datetime': '2023-02-07T19:57:07.516601', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:57:07.517 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:57:10,179][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195606-0ei430c5/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:57:10.179526', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:57:10,180][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:57:10,297][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195606-0ei430c5/files/../tmp/embedding_model.pt
2023-02-07 19:57:10.298 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:57:12.436 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:57:13.188 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:57:15.774 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0430611469878006, 'test_mae': 0.7920480246649929, 'test_r2': -2.479626331545965}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.94
wandb: percentage 0.55548
wandb:   test_mae 0.79205
wandb:   test_mse 1.04306
wandb:    test_r2 -2.47963
wandb: 
wandb: üöÄ View run clean-sweep-63 at: https://wandb.ai/xiaoqiz/mof2vec/runs/0ei430c5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195606-0ei430c5/logs
wandb: Agent Starting Run: 2ys0ad5o with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 774
wandb: 	model.gensim.alpha: 0.008410423863381106
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.5039148786361158
wandb: 	model.gensim.vector_size: 267
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.002434068696208177
wandb: 	model.sklearn.max_depth: 74
wandb: 	model.sklearn.min_child_weight: 0.07536144131253979
wandb: 	model.sklearn.n_estimators: 2272
wandb: 	model.sklearn.num_leaves: 171
wandb: 	model.sklearn.reg_alpha: 0.012679721163939076
wandb: 	model.sklearn.reg_lambda: 0.012494439004140248
wandb: 	model.sklearn.subsample: 0.8469427855660177
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195727-2ys0ad5o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-64
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/2ys0ad5o
2023-02-07 19:57:35.247 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 19:57:35.248 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 774 for sweep.
2023-02-07 19:57:35.248 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.008410423863381106 for sweep.
2023-02-07 19:57:35.249 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:57:35.249 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 19:57:35.250 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5039148786361158 for sweep.
2023-02-07 19:57:35.250 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 267 for sweep.
2023-02-07 19:57:35.250 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 19:57:35.250 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.002434068696208177 for sweep.
2023-02-07 19:57:35.251 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 74 for sweep.
2023-02-07 19:57:35.251 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.07536144131253979 for sweep.
2023-02-07 19:57:35.251 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2272 for sweep.
2023-02-07 19:57:35.251 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 171 for sweep.
2023-02-07 19:57:35.251 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.012679721163939076 for sweep.
2023-02-07 19:57:35.252 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.012494439004140248 for sweep.
2023-02-07 19:57:35.252 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8469427855660177 for sweep.
2023-02-07 19:57:35.252 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:57:35.258 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195727-2ys0ad5o/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 774, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 267, 'window': 8, 'min_count': 10, 'dm': 0, 'sample': 0.5039148786361158, 'workers': 4, 'alpha': 0.008410423863381106, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2272, 'max_depth': 74, 'num_leaves': 171, 'reg_alpha': 0.012679721163939076, 'reg_lambda': 0.012494439004140248, 'subsample': 0.8469427855660177, 'min_child_weight': 0.07536144131253979, 'n_jobs': 4, 'learning_rate': 0.002434068696208177}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:20, 155.72it/s]  1%|          | 34/3257 [00:00<00:19, 161.68it/s]  2%|‚ñè         | 53/3257 [00:00<00:19, 163.93it/s]  2%|‚ñè         | 72/3257 [00:00<00:18, 171.47it/s]  3%|‚ñé         | 91/3257 [00:00<00:18, 174.60it/s]  3%|‚ñé         | 109/3257 [00:00<00:18, 167.58it/s]  4%|‚ñç         | 128/3257 [00:00<00:18, 173.22it/s]  5%|‚ñç         | 149/3257 [00:00<00:17, 182.78it/s]  5%|‚ñå         | 168/3257 [00:00<00:17, 175.47it/s]  6%|‚ñå         | 187/3257 [00:01<00:17, 177.88it/s]  6%|‚ñã         | 205/3257 [00:01<00:17, 175.65it/s]  7%|‚ñã         | 229/3257 [00:01<00:15, 193.01it/s]  8%|‚ñä         | 249/3257 [00:01<00:16, 187.00it/s]  8%|‚ñä         | 268/3257 [00:01<00:16, 181.17it/s]  9%|‚ñâ         | 292/3257 [00:01<00:15, 197.04it/s] 10%|‚ñâ         | 312/3257 [00:01<00:15, 187.25it/s] 10%|‚ñà         | 331/3257 [00:01<00:22, 129.02it/s] 11%|‚ñà         | 348/3257 [00:02<00:21, 136.95it/s] 11%|‚ñà‚ñè        | 368/3257 [00:02<00:19, 150.81it/s] 12%|‚ñà‚ñè        | 386/3257 [00:02<00:18, 152.81it/s] 12%|‚ñà‚ñè        | 407/3257 [00:02<00:17, 165.58it/s] 13%|‚ñà‚ñé        | 425/3257 [00:02<00:17, 161.49it/s] 14%|‚ñà‚ñé        | 442/3257 [00:02<00:17, 160.38it/s] 14%|‚ñà‚ñç        | 461/3257 [00:02<00:16, 167.46it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:16, 169.11it/s] 15%|‚ñà‚ñå        | 501/3257 [00:02<00:15, 180.57it/s] 16%|‚ñà‚ñå        | 521/3257 [00:03<00:14, 184.32it/s] 17%|‚ñà‚ñã        | 541/3257 [00:03<00:14, 187.81it/s] 17%|‚ñà‚ñã        | 560/3257 [00:03<00:15, 174.06it/s] 18%|‚ñà‚ñä        | 578/3257 [00:03<00:15, 170.06it/s] 18%|‚ñà‚ñä        | 600/3257 [00:03<00:14, 183.71it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:14, 181.63it/s] 20%|‚ñà‚ñâ        | 642/3257 [00:03<00:13, 191.34it/s] 20%|‚ñà‚ñà        | 662/3257 [00:03<00:14, 174.89it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:14, 177.32it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:04<00:13, 184.38it/s] 22%|‚ñà‚ñà‚ñè       | 723/3257 [00:04<00:13, 183.35it/s] 23%|‚ñà‚ñà‚ñé       | 742/3257 [00:04<00:14, 179.09it/s] 23%|‚ñà‚ñà‚ñé       | 764/3257 [00:04<00:13, 188.03it/s] 24%|‚ñà‚ñà‚ñç       | 783/3257 [00:04<00:13, 176.76it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:04<00:13, 182.61it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:04<00:13, 177.86it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:04<00:14, 171.22it/s] 26%|‚ñà‚ñà‚ñã       | 859/3257 [00:04<00:13, 173.38it/s] 27%|‚ñà‚ñà‚ñã       | 877/3257 [00:05<00:14, 166.73it/s] 28%|‚ñà‚ñà‚ñä       | 896/3257 [00:05<00:13, 172.40it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:05<00:13, 171.79it/s] 29%|‚ñà‚ñà‚ñä       | 933/3257 [00:05<00:13, 176.00it/s] 29%|‚ñà‚ñà‚ñâ       | 954/3257 [00:05<00:12, 183.84it/s] 30%|‚ñà‚ñà‚ñâ       | 973/3257 [00:05<00:12, 177.06it/s] 30%|‚ñà‚ñà‚ñà       | 991/3257 [00:05<00:13, 170.02it/s] 31%|‚ñà‚ñà‚ñà       | 1009/3257 [00:05<00:13, 169.01it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:05<00:13, 170.21it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1045/3257 [00:06<00:13, 169.53it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1064/3257 [00:06<00:12, 173.47it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1082/3257 [00:06<00:12, 175.14it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1101/3257 [00:06<00:12, 177.26it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1122/3257 [00:06<00:11, 185.51it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:06<00:10, 194.42it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:06<00:09, 211.95it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1192/3257 [00:06<00:10, 203.59it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1214/3257 [00:06<00:09, 206.35it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:06<00:08, 226.54it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1269/3257 [00:07<00:08, 237.46it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1293/3257 [00:07<00:08, 219.75it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:07<00:08, 231.76it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:07<00:07, 241.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1375/3257 [00:07<00:07, 239.36it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1400/3257 [00:07<00:07, 238.99it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1426/3257 [00:07<00:07, 243.46it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:07<00:07, 248.09it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1478/3257 [00:07<00:07, 250.67it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1507/3257 [00:08<00:06, 259.60it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1533/3257 [00:08<00:07, 235.89it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1557/3257 [00:08<00:10, 155.01it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1578/3257 [00:08<00:10, 165.89it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1603/3257 [00:08<00:08, 184.44it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1629/3257 [00:08<00:08, 201.23it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1652/3257 [00:08<00:08, 194.50it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:09<00:08, 195.11it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1695/3257 [00:09<00:08, 194.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1717/3257 [00:09<00:07, 200.71it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1738/3257 [00:09<00:08, 188.42it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:09<00:07, 201.14it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1788/3257 [00:09<00:06, 214.23it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1810/3257 [00:09<00:06, 208.33it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1832/3257 [00:09<00:06, 209.85it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1857/3257 [00:09<00:06, 218.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1881/3257 [00:09<00:06, 224.25it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1904/3257 [00:10<00:06, 224.70it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1927/3257 [00:10<00:05, 222.71it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:10<00:05, 252.99it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1987/3257 [00:10<00:05, 242.63it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2012/3257 [00:10<00:05, 241.07it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2038/3257 [00:10<00:05, 243.15it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2063/3257 [00:10<00:05, 217.41it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2086/3257 [00:10<00:05, 216.35it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2108/3257 [00:10<00:05, 216.78it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2130/3257 [00:11<00:05, 208.94it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2152/3257 [00:11<00:05, 208.64it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:11<00:04, 217.95it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2202/3257 [00:11<00:04, 223.30it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2225/3257 [00:11<00:04, 219.48it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2248/3257 [00:11<00:04, 217.13it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:11<00:04, 214.77it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2294/3257 [00:11<00:04, 221.19it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2317/3257 [00:11<00:04, 223.46it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2350/3257 [00:12<00:03, 253.78it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2376/3257 [00:12<00:03, 252.39it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:12<00:03, 259.71it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2431/3257 [00:12<00:03, 234.22it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2455/3257 [00:12<00:03, 230.01it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2482/3257 [00:12<00:03, 239.48it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2509/3257 [00:12<00:03, 246.94it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2536/3257 [00:12<00:02, 253.14it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2562/3257 [00:12<00:02, 234.90it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:13<00:03, 223.52it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2613/3257 [00:13<00:02, 234.82it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2640/3257 [00:13<00:02, 241.29it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2665/3257 [00:13<00:02, 227.88it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2689/3257 [00:13<00:02, 230.76it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2713/3257 [00:13<00:02, 209.48it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2738/3257 [00:13<00:02, 219.26it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2762/3257 [00:13<00:02, 222.95it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2785/3257 [00:13<00:02, 223.92it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2809/3257 [00:14<00:01, 226.78it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2832/3257 [00:14<00:01, 218.13it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2856/3257 [00:14<00:01, 222.10it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:14<00:02, 150.43it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2905/3257 [00:14<00:02, 157.46it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2930/3257 [00:14<00:01, 176.89it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2951/3257 [00:14<00:01, 184.17it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:14<00:01, 195.04it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3002/3257 [00:15<00:01, 210.06it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3025/3257 [00:15<00:01, 213.10it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3054/3257 [00:15<00:00, 233.70it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:15<00:00, 245.03it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3108/3257 [00:15<00:00, 240.46it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3133/3257 [00:15<00:00, 224.76it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3156/3257 [00:15<00:00, 207.60it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3178/3257 [00:15<00:00, 190.87it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3201/3257 [00:16<00:00, 197.56it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3222/3257 [00:16<00:00, 186.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3245/3257 [00:16<00:00, 195.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 199.63it/s]
2023-02-07 19:57:52.102 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:57:52,103][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d267,n5,mc10,s0.503915,t4>', 'datetime': '2023-02-07T19:57:52.103276', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:57:52,103][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:57:52,103][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:57:52,458][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 19:57:52,459][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:57:52,475][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 4982 unique words (38.14% of original 13061, drops 8079)', 'datetime': '2023-02-07T19:57:52.475907', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:57:52,476][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 3610861 word corpus (99.22% of original 3639370, drops 28509)', 'datetime': '2023-02-07T19:57:52.476400', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:57:52,494][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 19:57:52,495][gensim.models.word2vec][INFO] - sample=0.503915 downsamples 0 most-common words
[2023-02-07 19:57:52,495][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3610861 word corpus (100.0%% of prior 3610861)', 'datetime': '2023-02-07T19:57:52.495848', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:57:52,527][gensim.models.word2vec][INFO] - estimated required memory for 4982 words and 267 dimensions: 17262428 bytes
[2023-02-07 19:57:52,528][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:57:52,537][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 4982 vocabulary and 267 features, using sg=1 hs=0 sample=0.5039148786361158 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T19:57:52.537521', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:57:53,542][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 57.57% examples, 2126970 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:57:54,184][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3614118 effective words) took 1.6s, 2200051 effective words/s
[2023-02-07 19:57:55,190][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 72.18% examples, 2642772 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:57:55,564][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3614118 effective words) took 1.4s, 2623681 effective words/s
[2023-02-07 19:57:56,566][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 69.51% examples, 2569286 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:57:56,968][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3614118 effective words) took 1.4s, 2578411 effective words/s
[2023-02-07 19:57:57,981][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 69.85% examples, 2563829 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:57:58,374][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3614118 effective words) took 1.4s, 2575950 effective words/s
[2023-02-07 19:57:59,378][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 72.64% examples, 2664805 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:57:59,683][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3614118 effective words) took 1.3s, 2767301 effective words/s
[2023-02-07 19:58:00,685][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 81.39% examples, 2967516 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:00,919][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3614118 effective words) took 1.2s, 2926258 effective words/s
[2023-02-07 19:58:01,923][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 75.10% examples, 2752407 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:02,234][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3614118 effective words) took 1.3s, 2753927 effective words/s
[2023-02-07 19:58:03,239][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 74.95% examples, 2747217 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:58:03,546][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3614118 effective words) took 1.3s, 2758307 effective words/s
[2023-02-07 19:58:04,554][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 77.56% examples, 2815619 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:58:04,824][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3614118 effective words) took 1.3s, 2832939 effective words/s
[2023-02-07 19:58:05,833][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 78.08% examples, 2831946 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:58:06,101][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3614118 effective words) took 1.3s, 2834742 effective words/s
[2023-02-07 19:58:07,107][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 78.88% examples, 2874654 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:07,358][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3614118 effective words) took 1.3s, 2881677 effective words/s
[2023-02-07 19:58:08,363][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 75.68% examples, 2768031 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:58:08,694][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3614118 effective words) took 1.3s, 2709220 effective words/s
[2023-02-07 19:58:09,702][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 69.05% examples, 2536725 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:10,113][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3614118 effective words) took 1.4s, 2550668 effective words/s
[2023-02-07 19:58:11,116][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 69.51% examples, 2567951 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:58:11,531][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3614118 effective words) took 1.4s, 2552739 effective words/s
[2023-02-07 19:58:12,533][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 68.16% examples, 2516388 words/s, in_qsize 8, out_qsize 1
[2023-02-07 19:58:12,959][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3614118 effective words) took 1.4s, 2534655 effective words/s
[2023-02-07 19:58:12,960][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54211770 effective words) took 20.4s, 2654548 effective words/s', 'datetime': '2023-02-07T19:58:12.960217', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:58:12.960 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:58:14,912][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195727-2ys0ad5o/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:58:14.912117', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:58:14,913][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:58:14,943][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195727-2ys0ad5o/files/../tmp/embedding_model.pt
2023-02-07 19:58:14.943 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:58:16.814 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:58:17.346 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:58:18.933 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9547980476344401, 'test_mae': 0.7416062216542981, 'test_r2': -1.9571415101749885}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.78
wandb: percentage 0.61856
wandb:   test_mae 0.74161
wandb:   test_mse 0.9548
wandb:    test_r2 -1.95714
wandb: 
wandb: üöÄ View run proud-sweep-64 at: https://wandb.ai/xiaoqiz/mof2vec/runs/2ys0ad5o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195727-2ys0ad5o/logs
wandb: Agent Starting Run: itcpj8xp with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 732
wandb: 	model.gensim.alpha: 0.16548252552206824
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.8191089405972491
wandb: 	model.gensim.vector_size: 173
wandb: 	model.gensim.window: 6
wandb: 	model.sklearn.learning_rate: 0.029510151448065115
wandb: 	model.sklearn.max_depth: 63
wandb: 	model.sklearn.min_child_weight: 0.04985459354538104
wandb: 	model.sklearn.n_estimators: 931
wandb: 	model.sklearn.num_leaves: 376
wandb: 	model.sklearn.reg_alpha: 0.006782090187562443
wandb: 	model.sklearn.reg_lambda: 0.10744384206485769
wandb: 	model.sklearn.subsample: 0.8614910386537487
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195830-itcpj8xp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-65
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/itcpj8xp
2023-02-07 19:58:38.406 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 19:58:38.406 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 732 for sweep.
2023-02-07 19:58:38.407 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.16548252552206824 for sweep.
2023-02-07 19:58:38.407 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:58:38.407 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 19:58:38.407 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8191089405972491 for sweep.
2023-02-07 19:58:38.408 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 173 for sweep.
2023-02-07 19:58:38.408 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 6 for sweep.
2023-02-07 19:58:38.408 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.029510151448065115 for sweep.
2023-02-07 19:58:38.408 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 63 for sweep.
2023-02-07 19:58:38.408 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.04985459354538104 for sweep.
2023-02-07 19:58:38.409 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 931 for sweep.
2023-02-07 19:58:38.409 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 376 for sweep.
2023-02-07 19:58:38.409 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.006782090187562443 for sweep.
2023-02-07 19:58:38.409 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.10744384206485769 for sweep.
2023-02-07 19:58:38.410 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8614910386537487 for sweep.
2023-02-07 19:58:38.410 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:58:38.417 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195830-itcpj8xp/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 732, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 173, 'window': 6, 'min_count': 10, 'dm': 0, 'sample': 0.8191089405972491, 'workers': 4, 'alpha': 0.16548252552206824, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 931, 'max_depth': 63, 'num_leaves': 376, 'reg_alpha': 0.006782090187562443, 'reg_lambda': 0.10744384206485769, 'subsample': 0.8614910386537487, 'min_child_weight': 0.04985459354538104, 'n_jobs': 4, 'learning_rate': 0.029510151448065115}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 23/3257 [00:00<00:14, 225.71it/s]  1%|‚ñè         | 47/3257 [00:00<00:13, 233.31it/s]  2%|‚ñè         | 71/3257 [00:00<00:13, 233.47it/s]  3%|‚ñé         | 97/3257 [00:00<00:13, 242.62it/s]  4%|‚ñé         | 122/3257 [00:00<00:13, 238.59it/s]  5%|‚ñç         | 151/3257 [00:00<00:12, 249.89it/s]  5%|‚ñå         | 176/3257 [00:00<00:12, 237.55it/s]  6%|‚ñå         | 202/3257 [00:00<00:12, 243.09it/s]  7%|‚ñã         | 233/3257 [00:00<00:11, 262.16it/s]  8%|‚ñä         | 260/3257 [00:01<00:11, 254.34it/s]  9%|‚ñâ         | 291/3257 [00:01<00:11, 268.32it/s] 10%|‚ñâ         | 318/3257 [00:01<00:11, 264.04it/s] 11%|‚ñà         | 345/3257 [00:01<00:11, 261.72it/s] 11%|‚ñà‚ñè        | 373/3257 [00:01<00:10, 263.98it/s] 12%|‚ñà‚ñè        | 400/3257 [00:01<00:11, 248.79it/s] 13%|‚ñà‚ñé        | 426/3257 [00:01<00:12, 233.46it/s] 14%|‚ñà‚ñç        | 450/3257 [00:01<00:12, 232.33it/s] 15%|‚ñà‚ñç        | 477/3257 [00:01<00:11, 241.96it/s] 15%|‚ñà‚ñå        | 504/3257 [00:02<00:11, 246.33it/s] 16%|‚ñà‚ñå        | 529/3257 [00:02<00:11, 245.54it/s] 17%|‚ñà‚ñã        | 555/3257 [00:02<00:10, 249.38it/s] 18%|‚ñà‚ñä        | 581/3257 [00:02<00:11, 228.37it/s] 19%|‚ñà‚ñä        | 607/3257 [00:02<00:11, 235.80it/s] 19%|‚ñà‚ñâ        | 633/3257 [00:02<00:10, 240.87it/s] 20%|‚ñà‚ñà        | 658/3257 [00:02<00:11, 223.51it/s] 21%|‚ñà‚ñà        | 683/3257 [00:02<00:11, 224.55it/s] 22%|‚ñà‚ñà‚ñè       | 709/3257 [00:02<00:10, 233.28it/s] 23%|‚ñà‚ñà‚ñé       | 733/3257 [00:03<00:11, 226.85it/s] 23%|‚ñà‚ñà‚ñé       | 757/3257 [00:03<00:10, 228.36it/s] 24%|‚ñà‚ñà‚ñç       | 781/3257 [00:03<00:10, 230.51it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:03<00:10, 234.13it/s] 25%|‚ñà‚ñà‚ñå       | 830/3257 [00:03<00:10, 232.20it/s] 26%|‚ñà‚ñà‚ñå       | 854/3257 [00:03<00:10, 224.08it/s] 27%|‚ñà‚ñà‚ñã       | 877/3257 [00:03<00:15, 158.53it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:03<00:12, 183.73it/s] 29%|‚ñà‚ñà‚ñä       | 930/3257 [00:04<00:11, 198.76it/s] 29%|‚ñà‚ñà‚ñâ       | 953/3257 [00:04<00:11, 205.57it/s] 30%|‚ñà‚ñà‚ñâ       | 977/3257 [00:04<00:10, 213.66it/s] 31%|‚ñà‚ñà‚ñà       | 1000/3257 [00:04<00:10, 212.56it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1024/3257 [00:04<00:10, 219.62it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1047/3257 [00:04<00:10, 206.88it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1072/3257 [00:04<00:10, 217.58it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1095/3257 [00:04<00:10, 213.70it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1119/3257 [00:04<00:09, 217.08it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1142/3257 [00:04<00:09, 220.45it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:05<00:09, 229.47it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:05<00:09, 216.84it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1217/3257 [00:05<00:09, 217.18it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1245/3257 [00:05<00:08, 232.01it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:05<00:08, 236.60it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1295/3257 [00:05<00:08, 224.27it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:05<00:08, 233.40it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1348/3257 [00:05<00:07, 243.25it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1373/3257 [00:05<00:08, 234.50it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1398/3257 [00:06<00:07, 238.32it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1426/3257 [00:06<00:07, 249.65it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1454/3257 [00:06<00:06, 257.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1483/3257 [00:06<00:06, 264.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1512/3257 [00:06<00:06, 268.97it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1539/3257 [00:06<00:06, 248.59it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1565/3257 [00:06<00:06, 244.09it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1590/3257 [00:06<00:06, 244.78it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:06<00:06, 255.03it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1645/3257 [00:07<00:06, 249.98it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1671/3257 [00:07<00:06, 239.17it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1698/3257 [00:07<00:06, 247.61it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1725/3257 [00:07<00:06, 252.83it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1751/3257 [00:07<00:06, 231.42it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1775/3257 [00:07<00:06, 229.17it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1799/3257 [00:07<00:06, 227.38it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1822/3257 [00:07<00:06, 220.84it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1845/3257 [00:07<00:06, 212.19it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:08<00:06, 212.89it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1891/3257 [00:08<00:06, 210.65it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1915/3257 [00:08<00:06, 217.21it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:08<00:06, 212.00it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:08<00:05, 225.47it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1988/3257 [00:08<00:05, 216.91it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2010/3257 [00:08<00:05, 217.08it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:08<00:05, 220.49it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2056/3257 [00:08<00:05, 202.93it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2077/3257 [00:09<00:05, 204.00it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2098/3257 [00:09<00:05, 196.81it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:09<00:05, 199.04it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2141/3257 [00:09<00:05, 195.60it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2162/3257 [00:09<00:05, 198.45it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2183/3257 [00:09<00:05, 199.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2206/3257 [00:09<00:05, 205.72it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2227/3257 [00:09<00:04, 206.23it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2248/3257 [00:10<00:08, 119.05it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2270/3257 [00:10<00:07, 136.43it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2293/3257 [00:10<00:06, 155.91it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:10<00:05, 168.48it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2341/3257 [00:10<00:04, 191.02it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2367/3257 [00:10<00:04, 208.92it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2393/3257 [00:10<00:03, 221.93it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2417/3257 [00:10<00:03, 215.23it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:10<00:03, 212.53it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2463/3257 [00:11<00:03, 216.53it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2486/3257 [00:11<00:03, 220.26it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:11<00:03, 234.67it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2539/3257 [00:11<00:03, 238.45it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2564/3257 [00:11<00:03, 222.03it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2587/3257 [00:11<00:03, 212.24it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2613/3257 [00:11<00:02, 224.62it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2637/3257 [00:11<00:02, 227.06it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2660/3257 [00:11<00:02, 212.29it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2685/3257 [00:12<00:02, 221.31it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2708/3257 [00:12<00:02, 206.13it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2731/3257 [00:12<00:02, 211.68it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:12<00:02, 219.29it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:12<00:02, 215.66it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2805/3257 [00:12<00:01, 226.82it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2828/3257 [00:12<00:02, 212.56it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2850/3257 [00:12<00:01, 210.41it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2879/3257 [00:12<00:01, 230.67it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:13<00:01, 215.23it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:13<00:01, 217.82it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2951/3257 [00:13<00:01, 206.52it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2974/3257 [00:13<00:01, 211.78it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2996/3257 [00:13<00:01, 205.89it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:13<00:01, 209.37it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3043/3257 [00:13<00:00, 219.65it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3068/3257 [00:13<00:00, 227.05it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3091/3257 [00:13<00:00, 222.26it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:14<00:00, 234.75it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3142/3257 [00:14<00:00, 228.32it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:14<00:00, 217.19it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3187/3257 [00:14<00:00, 215.43it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3210/3257 [00:14<00:00, 218.52it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3233/3257 [00:14<00:00, 220.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3256/3257 [00:14<00:00, 223.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:14<00:00, 221.54it/s]
2023-02-07 19:58:53.637 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:58:53,638][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d173,n5,mc10,s0.819109,t4>', 'datetime': '2023-02-07T19:58:53.638551', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:58:53,639][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:58:53,639][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:58:53,983][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 19:58:53,983][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:58:53,999][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 4982 unique words (38.14% of original 13061, drops 8079)', 'datetime': '2023-02-07T19:58:53.999720', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:58:54,000][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 3610861 word corpus (99.22% of original 3639370, drops 28509)', 'datetime': '2023-02-07T19:58:54.000145', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:58:54,019][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 19:58:54,019][gensim.models.word2vec][INFO] - sample=0.819109 downsamples 0 most-common words
[2023-02-07 19:58:54,020][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3610861 word corpus (100.0%% of prior 3610861)', 'datetime': '2023-02-07T19:58:54.020009', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:58:54,049][gensim.models.word2vec][INFO] - estimated required memory for 4982 words and 173 dimensions: 12291332 bytes
[2023-02-07 19:58:54,050][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:58:54,056][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 4982 vocabulary and 173 features, using sg=1 hs=0 sample=0.8191089405972491 negative=5 window=6 shrink_windows=True', 'datetime': '2023-02-07T19:58:54.056460', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:58:54,915][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3614118 effective words) took 0.9s, 4221935 effective words/s
[2023-02-07 19:58:55,688][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3614118 effective words) took 0.8s, 4686138 effective words/s
[2023-02-07 19:58:56,493][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3614118 effective words) took 0.8s, 4492924 effective words/s
[2023-02-07 19:58:57,292][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3614118 effective words) took 0.8s, 4540944 effective words/s
[2023-02-07 19:58:58,088][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3614118 effective words) took 0.8s, 4548685 effective words/s
[2023-02-07 19:58:59,022][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3614118 effective words) took 0.9s, 3873309 effective words/s
[2023-02-07 19:58:59,967][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3614118 effective words) took 0.9s, 3838537 effective words/s
[2023-02-07 19:59:00,889][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3614118 effective words) took 0.9s, 3929822 effective words/s
[2023-02-07 19:59:01,720][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3614118 effective words) took 0.8s, 4355931 effective words/s
[2023-02-07 19:59:02,540][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3614118 effective words) took 0.8s, 4417615 effective words/s
[2023-02-07 19:59:03,431][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3614118 effective words) took 0.9s, 4062743 effective words/s
[2023-02-07 19:59:04,338][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3614118 effective words) took 0.9s, 3991427 effective words/s
[2023-02-07 19:59:05,241][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3614118 effective words) took 0.9s, 4006636 effective words/s
[2023-02-07 19:59:06,185][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3614118 effective words) took 0.9s, 3839449 effective words/s
[2023-02-07 19:59:07,187][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 97.14% examples, 3513991 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:59:07,218][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3614118 effective words) took 1.0s, 3506375 effective words/s
[2023-02-07 19:59:07,218][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54211770 effective words) took 13.2s, 4118954 effective words/s', 'datetime': '2023-02-07T19:59:07.218441', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 19:59:07.219 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 19:59:08,773][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195830-itcpj8xp/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T19:59:08.773932', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 19:59:08,774][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 19:59:08,794][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195830-itcpj8xp/files/../tmp/embedding_model.pt
2023-02-07 19:59:08.795 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 19:59:10.049 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 19:59:10.565 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 19:59:11.726 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.1081012734668876, 'test_mae': 0.8081095924863786, 'test_r2': -3.1433601458483453}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.86
wandb: percentage 0.61856
wandb:   test_mae 0.80811
wandb:   test_mse 1.1081
wandb:    test_r2 -3.14336
wandb: 
wandb: üöÄ View run pious-sweep-65 at: https://wandb.ai/xiaoqiz/mof2vec/runs/itcpj8xp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195830-itcpj8xp/logs
wandb: Agent Starting Run: wf8sr961 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 794
wandb: 	model.gensim.alpha: 0.003479951571198261
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.7111760270401666
wandb: 	model.gensim.vector_size: 412
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.0004474498190927691
wandb: 	model.sklearn.max_depth: 77
wandb: 	model.sklearn.min_child_weight: 0.06960007314239774
wandb: 	model.sklearn.n_estimators: 1856
wandb: 	model.sklearn.num_leaves: 58
wandb: 	model.sklearn.reg_alpha: 0.007294820967256708
wandb: 	model.sklearn.reg_lambda: 0.0288789278363252
wandb: 	model.sklearn.subsample: 0.8717122937516377
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195924-wf8sr961
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-66
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/wf8sr961
2023-02-07 19:59:32.614 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 19:59:32.615 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 794 for sweep.
2023-02-07 19:59:32.615 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.003479951571198261 for sweep.
2023-02-07 19:59:32.616 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 19:59:32.617 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 19:59:32.617 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7111760270401666 for sweep.
2023-02-07 19:59:32.617 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 412 for sweep.
2023-02-07 19:59:32.617 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 19:59:32.617 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0004474498190927691 for sweep.
2023-02-07 19:59:32.618 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 77 for sweep.
2023-02-07 19:59:32.618 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.06960007314239774 for sweep.
2023-02-07 19:59:32.618 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1856 for sweep.
2023-02-07 19:59:32.618 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 58 for sweep.
2023-02-07 19:59:32.619 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.007294820967256708 for sweep.
2023-02-07 19:59:32.619 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0288789278363252 for sweep.
2023-02-07 19:59:32.619 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8717122937516377 for sweep.
2023-02-07 19:59:32.619 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 19:59:32.625 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195924-wf8sr961/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 794, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 412, 'window': 11, 'min_count': 8, 'dm': 0, 'sample': 0.7111760270401666, 'workers': 4, 'alpha': 0.003479951571198261, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1856, 'max_depth': 77, 'num_leaves': 58, 'reg_alpha': 0.007294820967256708, 'reg_lambda': 0.0288789278363252, 'subsample': 0.8717122937516377, 'min_child_weight': 0.06960007314239774, 'n_jobs': 4, 'learning_rate': 0.0004474498190927691}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 179.32it/s]  1%|          | 39/3257 [00:00<00:16, 196.53it/s]  2%|‚ñè         | 59/3257 [00:00<00:16, 191.70it/s]  3%|‚ñé         | 83/3257 [00:00<00:15, 209.66it/s]  3%|‚ñé         | 105/3257 [00:00<00:15, 202.26it/s]  4%|‚ñç         | 126/3257 [00:00<00:15, 198.57it/s]  5%|‚ñç         | 151/3257 [00:00<00:14, 210.85it/s]  5%|‚ñå         | 173/3257 [00:00<00:15, 204.56it/s]  6%|‚ñå         | 196/3257 [00:00<00:14, 210.09it/s]  7%|‚ñã         | 219/3257 [00:01<00:14, 213.26it/s]  7%|‚ñã         | 244/3257 [00:01<00:13, 222.13it/s]  8%|‚ñä         | 267/3257 [00:01<00:14, 210.05it/s]  9%|‚ñâ         | 295/3257 [00:01<00:18, 163.27it/s] 10%|‚ñâ         | 314/3257 [00:01<00:17, 164.95it/s] 10%|‚ñà         | 337/3257 [00:01<00:16, 178.23it/s] 11%|‚ñà         | 359/3257 [00:01<00:15, 186.38it/s] 12%|‚ñà‚ñè        | 379/3257 [00:01<00:16, 179.46it/s] 12%|‚ñà‚ñè        | 398/3257 [00:02<00:15, 181.08it/s] 13%|‚ñà‚ñé        | 419/3257 [00:02<00:15, 187.89it/s] 13%|‚ñà‚ñé        | 439/3257 [00:02<00:17, 165.56it/s] 14%|‚ñà‚ñç        | 460/3257 [00:02<00:15, 176.84it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:15, 178.74it/s] 15%|‚ñà‚ñå        | 501/3257 [00:02<00:14, 188.92it/s] 16%|‚ñà‚ñå        | 522/3257 [00:02<00:14, 189.56it/s] 17%|‚ñà‚ñã        | 544/3257 [00:02<00:13, 197.72it/s] 17%|‚ñà‚ñã        | 565/3257 [00:02<00:14, 180.07it/s] 18%|‚ñà‚ñä        | 584/3257 [00:03<00:14, 179.23it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:14, 182.33it/s] 19%|‚ñà‚ñâ        | 623/3257 [00:03<00:14, 183.19it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:13, 189.16it/s] 20%|‚ñà‚ñà        | 665/3257 [00:03<00:14, 181.25it/s] 21%|‚ñà‚ñà        | 684/3257 [00:03<00:14, 182.05it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:03<00:13, 187.02it/s] 22%|‚ñà‚ñà‚ñè       | 723/3257 [00:03<00:13, 182.18it/s] 23%|‚ñà‚ñà‚ñé       | 742/3257 [00:03<00:14, 175.76it/s] 23%|‚ñà‚ñà‚ñé       | 763/3257 [00:04<00:13, 184.03it/s] 24%|‚ñà‚ñà‚ñç       | 782/3257 [00:04<00:14, 176.59it/s] 25%|‚ñà‚ñà‚ñç       | 803/3257 [00:04<00:13, 185.01it/s] 25%|‚ñà‚ñà‚ñå       | 822/3257 [00:04<00:13, 175.41it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:04<00:14, 171.06it/s] 26%|‚ñà‚ñà‚ñã       | 858/3257 [00:04<00:14, 169.52it/s] 27%|‚ñà‚ñà‚ñã       | 876/3257 [00:04<00:14, 164.87it/s] 27%|‚ñà‚ñà‚ñã       | 894/3257 [00:04<00:14, 167.34it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:04<00:13, 173.56it/s] 29%|‚ñà‚ñà‚ñä       | 933/3257 [00:05<00:13, 176.29it/s] 29%|‚ñà‚ñà‚ñâ       | 955/3257 [00:05<00:12, 188.42it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:05<00:12, 180.78it/s] 30%|‚ñà‚ñà‚ñà       | 993/3257 [00:05<00:12, 176.16it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:05<00:12, 175.53it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1029/3257 [00:05<00:12, 175.53it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1047/3257 [00:05<00:12, 170.46it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:05<00:12, 175.52it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1086/3257 [00:05<00:12, 178.00it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:06<00:11, 179.70it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:06<00:12, 175.49it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1141/3257 [00:06<00:12, 171.17it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1161/3257 [00:06<00:11, 178.39it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1179/3257 [00:06<00:12, 172.89it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1197/3257 [00:06<00:12, 169.82it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1215/3257 [00:06<00:12, 168.01it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1239/3257 [00:06<00:10, 187.90it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:06<00:10, 181.86it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:07<00:11, 179.22it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1296/3257 [00:07<00:11, 173.22it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1316/3257 [00:07<00:10, 179.53it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1336/3257 [00:07<00:10, 184.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1355/3257 [00:07<00:15, 119.83it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1372/3257 [00:07<00:14, 130.02it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1390/3257 [00:07<00:13, 141.38it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1413/3257 [00:07<00:11, 162.08it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1434/3257 [00:08<00:10, 172.11it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1459/3257 [00:08<00:09, 191.45it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1480/3257 [00:08<00:09, 191.62it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1504/3257 [00:08<00:08, 203.39it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1525/3257 [00:08<00:08, 193.67it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1545/3257 [00:08<00:09, 184.99it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1565/3257 [00:08<00:09, 187.94it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1585/3257 [00:08<00:08, 188.32it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1608/3257 [00:08<00:08, 198.29it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1630/3257 [00:08<00:07, 204.43it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1651/3257 [00:09<00:08, 189.25it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1671/3257 [00:09<00:09, 175.71it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1689/3257 [00:09<00:09, 169.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:09<00:09, 166.98it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1724/3257 [00:09<00:09, 165.44it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1741/3257 [00:09<00:10, 144.74it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1760/3257 [00:09<00:09, 154.39it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1776/3257 [00:09<00:09, 153.70it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1793/3257 [00:10<00:09, 157.17it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1809/3257 [00:10<00:09, 148.69it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:10<00:09, 153.91it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1845/3257 [00:10<00:08, 161.94it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1863/3257 [00:10<00:08, 164.87it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1880/3257 [00:10<00:08, 164.12it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:10<00:08, 158.11it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:10<00:08, 158.72it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1935/3257 [00:10<00:07, 166.22it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1957/3257 [00:11<00:07, 181.01it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1976/3257 [00:11<00:07, 178.76it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1994/3257 [00:11<00:07, 175.90it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2012/3257 [00:11<00:07, 165.39it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2032/3257 [00:11<00:07, 172.17it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2050/3257 [00:11<00:07, 154.96it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2066/3257 [00:11<00:07, 150.81it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:11<00:07, 152.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2099/3257 [00:11<00:07, 148.67it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:12<00:07, 156.49it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2133/3257 [00:12<00:07, 147.45it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2148/3257 [00:12<00:07, 144.22it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:12<00:06, 156.89it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2184/3257 [00:12<00:06, 154.39it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2203/3257 [00:12<00:06, 163.75it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2220/3257 [00:12<00:06, 158.31it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:12<00:06, 158.83it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2253/3257 [00:12<00:06, 156.70it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2269/3257 [00:13<00:06, 153.60it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2286/3257 [00:13<00:06, 156.30it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2302/3257 [00:13<00:06, 154.80it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2322/3257 [00:13<00:05, 165.98it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2341/3257 [00:13<00:05, 171.78it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2361/3257 [00:13<00:04, 179.80it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2380/3257 [00:13<00:04, 181.88it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:13<00:04, 183.44it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2418/3257 [00:13<00:04, 169.59it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2436/3257 [00:14<00:05, 159.93it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2453/3257 [00:14<00:05, 157.98it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:14<00:04, 172.24it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2493/3257 [00:14<00:04, 173.57it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:14<00:04, 180.71it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2534/3257 [00:14<00:03, 184.40it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2553/3257 [00:14<00:04, 173.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2571/3257 [00:14<00:04, 159.18it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2588/3257 [00:14<00:04, 156.42it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2607/3257 [00:15<00:03, 165.25it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2629/3257 [00:15<00:03, 177.94it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2648/3257 [00:15<00:03, 171.53it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2666/3257 [00:15<00:03, 165.83it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2685/3257 [00:15<00:03, 171.43it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2703/3257 [00:15<00:03, 151.90it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:15<00:03, 149.39it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2740/3257 [00:15<00:03, 164.46it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:16<00:05, 88.46it/s]  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2772/3257 [00:16<00:04, 98.73it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2793/3257 [00:16<00:03, 119.95it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2810/3257 [00:16<00:03, 129.52it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2826/3257 [00:16<00:03, 133.05it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:16<00:02, 139.43it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2863/3257 [00:16<00:02, 157.49it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2885/3257 [00:16<00:02, 173.88it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2904/3257 [00:17<00:02, 156.72it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2925/3257 [00:17<00:01, 170.40it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2944/3257 [00:17<00:01, 156.55it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2963/3257 [00:17<00:01, 164.63it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2981/3257 [00:17<00:01, 166.70it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3005/3257 [00:17<00:01, 185.99it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:17<00:01, 191.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3052/3257 [00:17<00:00, 210.45it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3079/3257 [00:18<00:00, 225.64it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3103/3257 [00:18<00:00, 229.30it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3128/3257 [00:18<00:00, 234.85it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3152/3257 [00:18<00:00, 220.47it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3176/3257 [00:18<00:00, 221.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3199/3257 [00:18<00:00, 222.01it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3222/3257 [00:18<00:00, 218.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3250/3257 [00:18<00:00, 234.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 173.27it/s]
2023-02-07 19:59:52.086 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 19:59:52,087][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d412,n5,mc8,s0.711176,t4>', 'datetime': '2023-02-07T19:59:52.087904', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 19:59:52,088][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 19:59:52,088][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 19:59:52,551][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 19:59:52,551][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 19:59:52,592][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 13798 unique words (43.39% of original 31803, drops 18005)', 'datetime': '2023-02-07T19:59:52.592712', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:59:52,594][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 5042429 word corpus (98.97% of original 5095118, drops 52689)', 'datetime': '2023-02-07T19:59:52.594326', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:59:52,642][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 19:59:52,643][gensim.models.word2vec][INFO] - sample=0.711176 downsamples 0 most-common words
[2023-02-07 19:59:52,643][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5042429 word corpus (100.0%% of prior 5042429)', 'datetime': '2023-02-07T19:59:52.643643', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 19:59:52,725][gensim.models.word2vec][INFO] - estimated required memory for 13798 words and 412 dimensions: 58396144 bytes
[2023-02-07 19:59:52,725][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 19:59:52,754][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 13798 vocabulary and 412 features, using sg=1 hs=0 sample=0.7111760270401666 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T19:59:52.754352', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 19:59:53,757][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 32.21% examples, 1642458 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:59:54,761][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 65.09% examples, 1668198 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:59:55,736][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5034594 effective words) took 3.0s, 1689397 effective words/s
[2023-02-07 19:59:56,754][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 35.06% examples, 1768355 words/s, in_qsize 7, out_qsize 0
[2023-02-07 19:59:57,758][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 70.37% examples, 1793901 words/s, in_qsize 8, out_qsize 0
[2023-02-07 19:59:58,537][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5034594 effective words) took 2.8s, 1799598 effective words/s
[2023-02-07 19:59:59,543][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 35.06% examples, 1786377 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:00:00,545][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 70.56% examples, 1809843 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:01,300][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5034594 effective words) took 2.8s, 1823203 effective words/s
[2023-02-07 20:00:02,308][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 36.44% examples, 1859802 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:03,315][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 74.27% examples, 1883118 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:03,976][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5034594 effective words) took 2.7s, 1882899 effective words/s
[2023-02-07 20:00:04,983][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 32.02% examples, 1628006 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:05,992][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 63.92% examples, 1627002 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:06,996][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 97.61% examples, 1632388 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:07,058][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5034594 effective words) took 3.1s, 1635036 effective words/s
[2023-02-07 20:00:08,066][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 32.36% examples, 1645125 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:00:09,067][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 64.78% examples, 1657908 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:10,068][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 98.56% examples, 1652732 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:10,097][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5034594 effective words) took 3.0s, 1658733 effective words/s
[2023-02-07 20:00:11,101][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 32.91% examples, 1669539 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:12,107][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 65.09% examples, 1665392 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:12,953][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5034594 effective words) took 2.9s, 1764262 effective words/s
[2023-02-07 20:00:13,954][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 39.02% examples, 2007227 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:14,963][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 76.14% examples, 1934699 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:15,574][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5034594 effective words) took 2.6s, 1921401 effective words/s
[2023-02-07 20:00:16,577][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 36.44% examples, 1869468 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:17,578][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 73.47% examples, 1875954 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:18,263][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5034594 effective words) took 2.7s, 1873530 effective words/s
[2023-02-07 20:00:19,271][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.44% examples, 1860947 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:20,271][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 73.63% examples, 1872047 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:00:20,941][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5034594 effective words) took 2.7s, 1881557 effective words/s
[2023-02-07 20:00:21,945][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 36.44% examples, 1867429 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:22,946][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 74.24% examples, 1892620 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:00:23,580][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5034594 effective words) took 2.6s, 1908760 effective words/s
[2023-02-07 20:00:24,591][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 36.91% examples, 1888977 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:00:25,597][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 69.67% examples, 1779543 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:26,457][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5034594 effective words) took 2.9s, 1750723 effective words/s
[2023-02-07 20:00:27,461][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 32.55% examples, 1655313 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:28,463][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 65.09% examples, 1669037 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:29,456][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5034594 effective words) took 3.0s, 1680213 effective words/s
[2023-02-07 20:00:30,468][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 33.34% examples, 1674436 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:31,469][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 66.29% examples, 1694356 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:32,427][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5034594 effective words) took 3.0s, 1695644 effective words/s
[2023-02-07 20:00:33,437][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 38.29% examples, 1961474 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:34,441][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 79.77% examples, 2020851 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:00:34,934][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5034594 effective words) took 2.5s, 2010697 effective words/s
[2023-02-07 20:00:34,935][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75518910 effective words) took 42.2s, 1790386 effective words/s', 'datetime': '2023-02-07T20:00:34.935018', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:00:34.935 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:00:38,561][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195924-wf8sr961/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:00:38.561737', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:00:38,562][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:00:38,631][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_195924-wf8sr961/files/../tmp/embedding_model.pt
2023-02-07 20:00:38.631 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:00:40.874 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:00:41.630 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:00:44.366 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.907697796263949, 'test_mae': 0.7205815776451233, 'test_r2': -1.8289474091103055}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.78
wandb: percentage 0.56614
wandb:   test_mae 0.72058
wandb:   test_mse 0.9077
wandb:    test_r2 -1.82895
wandb: 
wandb: üöÄ View run wild-sweep-66 at: https://wandb.ai/xiaoqiz/mof2vec/runs/wf8sr961
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_195924-wf8sr961/logs
wandb: Agent Starting Run: cfzhrb1e with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 449
wandb: 	model.gensim.alpha: 0.002169658001742097
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.6414806050046349
wandb: 	model.gensim.vector_size: 476
wandb: 	model.gensim.window: 14
wandb: 	model.sklearn.learning_rate: 0.021961397074520148
wandb: 	model.sklearn.max_depth: 92
wandb: 	model.sklearn.min_child_weight: 0.04671215809330789
wandb: 	model.sklearn.n_estimators: 326
wandb: 	model.sklearn.num_leaves: 207
wandb: 	model.sklearn.reg_alpha: 0.006295443139620975
wandb: 	model.sklearn.reg_lambda: 0.003908104965783085
wandb: 	model.sklearn.subsample: 0.7674844563317189
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200055-cfzhrb1e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-67
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/cfzhrb1e
2023-02-07 20:01:03.452 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:01:03.452 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 449 for sweep.
2023-02-07 20:01:03.453 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.002169658001742097 for sweep.
2023-02-07 20:01:03.453 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:01:03.453 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 20:01:03.454 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6414806050046349 for sweep.
2023-02-07 20:01:03.454 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 476 for sweep.
2023-02-07 20:01:03.454 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 14 for sweep.
2023-02-07 20:01:03.454 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.021961397074520148 for sweep.
2023-02-07 20:01:03.455 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 92 for sweep.
2023-02-07 20:01:03.455 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.04671215809330789 for sweep.
2023-02-07 20:01:03.455 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 326 for sweep.
2023-02-07 20:01:03.455 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 207 for sweep.
2023-02-07 20:01:03.456 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.006295443139620975 for sweep.
2023-02-07 20:01:03.456 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.003908104965783085 for sweep.
2023-02-07 20:01:03.456 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7674844563317189 for sweep.
2023-02-07 20:01:03.456 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:01:03.462 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200055-cfzhrb1e/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 449, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 476, 'window': 14, 'min_count': 7, 'dm': 0, 'sample': 0.6414806050046349, 'workers': 4, 'alpha': 0.002169658001742097, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 326, 'max_depth': 92, 'num_leaves': 207, 'reg_alpha': 0.006295443139620975, 'reg_lambda': 0.003908104965783085, 'subsample': 0.7674844563317189, 'min_child_weight': 0.04671215809330789, 'n_jobs': 4, 'learning_rate': 0.021961397074520148}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:26, 123.65it/s]  1%|          | 29/3257 [00:00<00:22, 142.15it/s]  1%|‚ñè         | 44/3257 [00:00<00:22, 141.80it/s]  2%|‚ñè         | 59/3257 [00:00<00:23, 137.76it/s]  2%|‚ñè         | 76/3257 [00:00<00:21, 148.55it/s]  3%|‚ñé         | 91/3257 [00:00<00:21, 146.50it/s]  3%|‚ñé         | 106/3257 [00:00<00:22, 138.42it/s]  4%|‚ñé         | 122/3257 [00:00<00:21, 143.17it/s]  4%|‚ñç         | 140/3257 [00:00<00:20, 152.56it/s]  5%|‚ñç         | 157/3257 [00:01<00:19, 155.45it/s]  5%|‚ñå         | 173/3257 [00:01<00:21, 144.25it/s]  6%|‚ñå         | 191/3257 [00:01<00:20, 153.15it/s]  6%|‚ñã         | 207/3257 [00:01<00:20, 150.63it/s]  7%|‚ñã         | 229/3257 [00:01<00:17, 168.98it/s]  8%|‚ñä         | 247/3257 [00:01<00:18, 165.95it/s]  8%|‚ñä         | 264/3257 [00:01<00:19, 156.09it/s]  9%|‚ñâ         | 285/3257 [00:01<00:17, 167.09it/s]  9%|‚ñâ         | 302/3257 [00:01<00:18, 159.91it/s] 10%|‚ñâ         | 319/3257 [00:02<00:18, 160.97it/s] 10%|‚ñà         | 336/3257 [00:02<00:18, 160.85it/s] 11%|‚ñà         | 353/3257 [00:02<00:18, 156.67it/s] 11%|‚ñà‚ñè        | 369/3257 [00:02<00:18, 155.13it/s] 12%|‚ñà‚ñè        | 385/3257 [00:02<00:19, 146.46it/s] 12%|‚ñà‚ñè        | 400/3257 [00:02<00:20, 142.28it/s] 13%|‚ñà‚ñé        | 417/3257 [00:02<00:19, 148.74it/s] 13%|‚ñà‚ñé        | 432/3257 [00:02<00:21, 128.66it/s] 14%|‚ñà‚ñé        | 446/3257 [00:03<00:21, 130.31it/s] 14%|‚ñà‚ñç        | 461/3257 [00:03<00:20, 134.42it/s] 15%|‚ñà‚ñç        | 476/3257 [00:03<00:20, 138.67it/s] 15%|‚ñà‚ñå        | 491/3257 [00:03<00:19, 141.07it/s] 16%|‚ñà‚ñå        | 510/3257 [00:03<00:18, 150.87it/s] 16%|‚ñà‚ñå        | 526/3257 [00:03<00:18, 144.98it/s] 17%|‚ñà‚ñã        | 544/3257 [00:03<00:17, 153.70it/s] 17%|‚ñà‚ñã        | 560/3257 [00:03<00:19, 138.11it/s] 18%|‚ñà‚ñä        | 575/3257 [00:03<00:20, 130.06it/s] 18%|‚ñà‚ñä        | 591/3257 [00:04<00:19, 137.47it/s] 19%|‚ñà‚ñä        | 608/3257 [00:04<00:18, 145.65it/s] 19%|‚ñà‚ñâ        | 623/3257 [00:04<00:19, 138.51it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:04<00:18, 145.03it/s] 20%|‚ñà‚ñà        | 655/3257 [00:04<00:19, 133.75it/s] 21%|‚ñà‚ñà        | 669/3257 [00:04<00:19, 134.41it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:19, 129.40it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:04<00:19, 132.68it/s] 22%|‚ñà‚ñà‚ñè       | 716/3257 [00:04<00:17, 144.69it/s] 22%|‚ñà‚ñà‚ñè       | 731/3257 [00:05<00:18, 133.45it/s] 23%|‚ñà‚ñà‚ñé       | 745/3257 [00:05<00:19, 130.94it/s] 23%|‚ñà‚ñà‚ñé       | 762/3257 [00:05<00:17, 140.47it/s] 24%|‚ñà‚ñà‚ñç       | 777/3257 [00:05<00:18, 136.97it/s] 24%|‚ñà‚ñà‚ñç       | 792/3257 [00:05<00:17, 140.48it/s] 25%|‚ñà‚ñà‚ñç       | 807/3257 [00:05<00:17, 139.38it/s] 25%|‚ñà‚ñà‚ñå       | 822/3257 [00:05<00:17, 140.60it/s] 26%|‚ñà‚ñà‚ñå       | 837/3257 [00:05<00:18, 132.54it/s] 26%|‚ñà‚ñà‚ñå       | 851/3257 [00:05<00:18, 128.16it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:06<00:18, 132.50it/s] 27%|‚ñà‚ñà‚ñã       | 880/3257 [00:06<00:29, 81.43it/s]  27%|‚ñà‚ñà‚ñã       | 894/3257 [00:06<00:25, 92.28it/s] 28%|‚ñà‚ñà‚ñä       | 910/3257 [00:06<00:21, 106.79it/s] 28%|‚ñà‚ñà‚ñä       | 926/3257 [00:06<00:19, 118.07it/s] 29%|‚ñà‚ñà‚ñâ       | 940/3257 [00:06<00:18, 122.32it/s] 29%|‚ñà‚ñà‚ñâ       | 957/3257 [00:06<00:17, 131.49it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:07<00:17, 131.24it/s] 30%|‚ñà‚ñà‚ñà       | 986/3257 [00:07<00:17, 131.53it/s] 31%|‚ñà‚ñà‚ñà       | 1001/3257 [00:07<00:16, 134.52it/s] 31%|‚ñà‚ñà‚ñà       | 1016/3257 [00:07<00:16, 137.48it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1031/3257 [00:07<00:15, 140.92it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:07<00:15, 143.42it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1064/3257 [00:07<00:14, 153.94it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:14, 155.32it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1098/3257 [00:07<00:13, 161.99it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:07<00:12, 165.25it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1134/3257 [00:08<00:13, 162.21it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1151/3257 [00:08<00:13, 160.20it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:08<00:12, 171.39it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1189/3257 [00:08<00:13, 152.22it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:08<00:13, 150.69it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1221/3257 [00:08<00:13, 153.10it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:08<00:12, 165.08it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1259/3257 [00:08<00:12, 162.11it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1276/3257 [00:08<00:12, 156.49it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:09<00:13, 149.60it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:09<00:12, 149.99it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1326/3257 [00:09<00:12, 157.86it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1343/3257 [00:09<00:11, 161.26it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1360/3257 [00:09<00:12, 153.10it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1376/3257 [00:09<00:12, 149.57it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1392/3257 [00:09<00:12, 147.93it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:09<00:11, 159.74it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:09<00:11, 163.33it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1451/3257 [00:10<00:10, 170.38it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1471/3257 [00:10<00:10, 176.82it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1489/3257 [00:10<00:10, 171.95it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1508/3257 [00:10<00:09, 176.59it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1526/3257 [00:10<00:10, 159.31it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1543/3257 [00:10<00:10, 156.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1559/3257 [00:10<00:11, 150.69it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:10<00:11, 148.67it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1593/3257 [00:10<00:10, 156.55it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1611/3257 [00:11<00:10, 162.10it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1629/3257 [00:11<00:09, 165.40it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1646/3257 [00:11<00:10, 154.07it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1662/3257 [00:11<00:10, 146.82it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:11<00:10, 147.67it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:11<00:10, 147.89it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1711/3257 [00:11<00:09, 159.02it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:11<00:10, 148.81it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:11<00:10, 144.45it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:12<00:09, 153.78it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1781/3257 [00:12<00:09, 160.36it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1798/3257 [00:12<00:09, 159.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1815/3257 [00:12<00:09, 155.36it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1831/3257 [00:12<00:09, 152.33it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1850/3257 [00:12<00:08, 160.13it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:12<00:08, 165.37it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1886/3257 [00:12<00:08, 164.40it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1904/3257 [00:12<00:08, 165.80it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1921/3257 [00:13<00:08, 161.23it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1945/3257 [00:13<00:07, 179.63it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1967/3257 [00:13<00:06, 190.51it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1987/3257 [00:13<00:07, 178.18it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2006/3257 [00:13<00:07, 178.34it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2025/3257 [00:13<00:06, 180.93it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2044/3257 [00:13<00:07, 172.19it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2062/3257 [00:13<00:07, 155.94it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2082/3257 [00:13<00:07, 165.83it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2099/3257 [00:14<00:07, 156.46it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2119/3257 [00:14<00:06, 166.06it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:14<00:11, 94.27it/s]  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2151/3257 [00:14<00:10, 103.63it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:14<00:09, 118.81it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:14<00:08, 127.37it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2205/3257 [00:14<00:07, 144.23it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2222/3257 [00:15<00:07, 147.55it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2239/3257 [00:15<00:07, 144.20it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:15<00:06, 157.40it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:15<00:06, 149.14it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2298/3257 [00:15<00:05, 167.28it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2316/3257 [00:15<00:05, 168.58it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2340/3257 [00:15<00:04, 186.94it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2362/3257 [00:15<00:04, 195.03it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2382/3257 [00:15<00:04, 195.74it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:16<00:04, 200.24it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2425/3257 [00:16<00:04, 186.00it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2444/3257 [00:16<00:04, 170.61it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2464/3257 [00:16<00:04, 178.24it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2483/3257 [00:16<00:04, 181.15it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:16<00:03, 193.11it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2528/3257 [00:16<00:03, 197.07it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2548/3257 [00:16<00:03, 192.18it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2568/3257 [00:17<00:04, 161.27it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:17<00:04, 157.32it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2603/3257 [00:17<00:04, 158.71it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2623/3257 [00:17<00:03, 169.39it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2641/3257 [00:17<00:03, 166.25it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2658/3257 [00:17<00:03, 150.71it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2675/3257 [00:17<00:03, 153.91it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2692/3257 [00:17<00:03, 157.85it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:17<00:04, 135.64it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2726/3257 [00:18<00:03, 142.23it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2746/3257 [00:18<00:03, 155.02it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2763/3257 [00:18<00:03, 152.23it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:18<00:03, 149.95it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2799/3257 [00:18<00:02, 161.13it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2816/3257 [00:18<00:02, 151.04it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2832/3257 [00:18<00:02, 145.90it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2848/3257 [00:18<00:02, 148.31it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2869/3257 [00:18<00:02, 164.39it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:19<00:02, 162.02it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:19<00:02, 150.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:19<00:02, 154.12it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2936/3257 [00:19<00:02, 152.62it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2952/3257 [00:19<00:02, 141.09it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2970/3257 [00:19<00:01, 149.25it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2986/3257 [00:19<00:01, 140.22it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3007/3257 [00:19<00:01, 157.03it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3024/3257 [00:20<00:01, 148.61it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3043/3257 [00:20<00:01, 159.25it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:20<00:01, 167.59it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3081/3257 [00:20<00:01, 165.42it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3098/3257 [00:20<00:00, 163.31it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:20<00:00, 171.89it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3136/3257 [00:20<00:00, 160.65it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3153/3257 [00:20<00:00, 153.14it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3169/3257 [00:20<00:00, 153.79it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:21<00:00, 147.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:21<00:00, 154.91it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3219/3257 [00:21<00:00, 146.35it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:21<00:00, 158.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3256/3257 [00:21<00:00, 157.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 151.55it/s]
2023-02-07 20:01:25.995 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:01:25,997][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d476,n5,mc7,s0.641481,t4>', 'datetime': '2023-02-07T20:01:25.997092', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:01:25,997][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:01:25,997][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:01:26,704][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:01:26,705][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:01:26,781][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 23400 unique words (43.29% of original 54054, drops 30654)', 'datetime': '2023-02-07T20:01:26.781846', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:01:26,782][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 6462689 word corpus (98.65% of original 6550866, drops 88177)', 'datetime': '2023-02-07T20:01:26.782338', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:01:26,868][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:01:26,870][gensim.models.word2vec][INFO] - sample=0.641481 downsamples 0 most-common words
[2023-02-07 20:01:26,870][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6462689 word corpus (100.0%% of prior 6462689)', 'datetime': '2023-02-07T20:01:26.870719', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:01:27,019][gensim.models.word2vec][INFO] - estimated required memory for 23400 words and 476 dimensions: 107659928 bytes
[2023-02-07 20:01:27,021][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:01:27,079][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 23400 vocabulary and 476 features, using sg=1 hs=0 sample=0.6414806050046349 negative=5 window=14 shrink_windows=True', 'datetime': '2023-02-07T20:01:27.079033', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:01:28,090][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 20.20% examples, 1266680 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:29,091][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 42.09% examples, 1381194 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:30,092][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 66.87% examples, 1452459 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:31,093][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 90.73% examples, 1459834 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:01:31,476][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6408417 effective words) took 4.4s, 1458691 effective words/s
[2023-02-07 20:01:32,480][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 23.58% examples, 1490077 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:33,492][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 46.24% examples, 1493424 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:01:34,492][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 69.14% examples, 1501843 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:35,494][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 94.14% examples, 1506658 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:35,731][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6408417 effective words) took 4.3s, 1506543 effective words/s
[2023-02-07 20:01:36,734][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 23.86% examples, 1517022 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:37,738][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 47.01% examples, 1530710 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:38,746][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 69.42% examples, 1508212 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:39,752][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 91.34% examples, 1465646 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:40,136][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6408417 effective words) took 4.4s, 1455420 effective words/s
[2023-02-07 20:01:41,140][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 20.97% examples, 1325534 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:42,152][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 40.84% examples, 1333498 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:01:43,152][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 62.27% examples, 1340950 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:44,166][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 83.33% examples, 1340071 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:01:44,915][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6408417 effective words) took 4.8s, 1341452 effective words/s
[2023-02-07 20:01:45,933][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 21.37% examples, 1335139 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:01:46,934][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 41.30% examples, 1346197 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:47,935][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 67.82% examples, 1472374 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:48,941][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 93.06% examples, 1492030 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:49,210][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6408417 effective words) took 4.3s, 1493613 effective words/s
[2023-02-07 20:01:50,217][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 23.40% examples, 1478074 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:01:51,223][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 45.47% examples, 1477836 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:01:52,224][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 68.28% examples, 1483624 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:53,224][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 92.45% examples, 1485652 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:53,525][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6408417 effective words) took 4.3s, 1486240 effective words/s
[2023-02-07 20:01:54,528][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 23.76% examples, 1507146 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:01:55,531][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 47.01% examples, 1530566 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:56,539][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 69.76% examples, 1519106 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:57,550][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 91.86% examples, 1474636 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:57,895][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6408417 effective words) took 4.4s, 1466806 effective words/s
[2023-02-07 20:01:58,900][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 21.31% examples, 1339715 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:01:59,908][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 40.84% examples, 1335816 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:00,910][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 62.27% examples, 1341424 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:01,910][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 83.33% examples, 1344989 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:02,649][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6408417 effective words) took 4.8s, 1348380 effective words/s
[2023-02-07 20:02:03,656][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 21.55% examples, 1355943 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:04,661][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 41.45% examples, 1358786 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:05,669][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 68.01% examples, 1474270 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:06,679][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 94.14% examples, 1502637 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:06,905][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6408417 effective words) took 4.3s, 1506792 effective words/s
[2023-02-07 20:02:07,913][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 23.76% examples, 1499765 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:08,920][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 46.45% examples, 1501964 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:09,921][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 69.42% examples, 1507257 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:10,927][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 94.14% examples, 1505369 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:11,160][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6408417 effective words) took 4.3s, 1506626 effective words/s
[2023-02-07 20:02:12,162][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 23.86% examples, 1517906 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:13,163][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 46.95% examples, 1531961 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:14,175][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 69.42% examples, 1507940 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:15,176][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 91.71% examples, 1475960 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:15,532][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6408417 effective words) took 4.4s, 1466210 effective words/s
[2023-02-07 20:02:16,547][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 21.55% examples, 1345760 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:17,548][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 41.42% examples, 1351061 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:18,560][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 62.94% examples, 1352527 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:19,561][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 84.31% examples, 1354192 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:20,265][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6408417 effective words) took 4.7s, 1354743 effective words/s
[2023-02-07 20:02:21,274][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 21.55% examples, 1354246 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:22,275][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 41.57% examples, 1365214 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:23,277][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 68.99% examples, 1501544 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:24,282][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 98.43% examples, 1573097 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:24,327][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6408417 effective words) took 4.1s, 1579050 effective words/s
[2023-02-07 20:02:25,341][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 27.17% examples, 1732812 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:02:26,349][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 51.89% examples, 1682745 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:27,351][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 77.06% examples, 1651973 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:28,245][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6408417 effective words) took 3.9s, 1636162 effective words/s
[2023-02-07 20:02:29,250][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 23.86% examples, 1513865 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:30,255][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 47.62% examples, 1550298 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:31,263][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 71.66% examples, 1550732 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:32,275][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 97.14% examples, 1547841 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:02:32,378][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6408417 effective words) took 4.1s, 1550991 effective words/s
[2023-02-07 20:02:32,379][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (96126255 effective words) took 65.3s, 1472091 effective words/s', 'datetime': '2023-02-07T20:02:32.379588', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:02:32.379 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:02:37,727][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200055-cfzhrb1e/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:02:37.727322', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:02:37,728][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200055-cfzhrb1e/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 20:02:37,772][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200055-cfzhrb1e/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 20:02:37,811][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:02:37,842][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200055-cfzhrb1e/files/../tmp/embedding_model.pt
2023-02-07 20:02:37.843 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:02:40.346 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:02:41.167 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:02:44.368 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0446552439151604, 'test_mae': 0.783824931670186, 'test_r2': -2.268472855006934}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.47
wandb: percentage 0.5671
wandb:   test_mae 0.78382
wandb:   test_mse 1.04466
wandb:    test_r2 -2.26847
wandb: 
wandb: üöÄ View run daily-sweep-67 at: https://wandb.ai/xiaoqiz/mof2vec/runs/cfzhrb1e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_200055-cfzhrb1e/logs
wandb: Agent Starting Run: v2ys89cu with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 503
wandb: 	model.gensim.alpha: 0.004221177770701002
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.66262319374603
wandb: 	model.gensim.vector_size: 400
wandb: 	model.gensim.window: 4
wandb: 	model.sklearn.learning_rate: 0.007969030085507185
wandb: 	model.sklearn.max_depth: 85
wandb: 	model.sklearn.min_child_weight: 0.030510114040276377
wandb: 	model.sklearn.n_estimators: 2082
wandb: 	model.sklearn.num_leaves: 16
wandb: 	model.sklearn.reg_alpha: 0.002972166668428181
wandb: 	model.sklearn.reg_lambda: 0.01753204104051886
wandb: 	model.sklearn.subsample: 0.5176424436421185
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200256-v2ys89cu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-68
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/v2ys89cu
2023-02-07 20:03:04.234 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 20:03:04.235 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 503 for sweep.
2023-02-07 20:03:04.235 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.004221177770701002 for sweep.
2023-02-07 20:03:04.235 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 20:03:04.235 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 20:03:04.236 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.66262319374603 for sweep.
2023-02-07 20:03:04.236 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 400 for sweep.
2023-02-07 20:03:04.236 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 4 for sweep.
2023-02-07 20:03:04.236 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.007969030085507185 for sweep.
2023-02-07 20:03:04.237 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 85 for sweep.
2023-02-07 20:03:04.237 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.030510114040276377 for sweep.
2023-02-07 20:03:04.238 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2082 for sweep.
2023-02-07 20:03:04.238 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 16 for sweep.
2023-02-07 20:03:04.238 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.002972166668428181 for sweep.
2023-02-07 20:03:04.238 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.01753204104051886 for sweep.
2023-02-07 20:03:04.239 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5176424436421185 for sweep.
2023-02-07 20:03:04.239 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:03:04.244 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200256-v2ys89cu/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 503, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 400, 'window': 4, 'min_count': 9, 'dm': 1, 'sample': 0.66262319374603, 'workers': 4, 'alpha': 0.004221177770701002, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2082, 'max_depth': 85, 'num_leaves': 16, 'reg_alpha': 0.002972166668428181, 'reg_lambda': 0.01753204104051886, 'subsample': 0.5176424436421185, 'min_child_weight': 0.030510114040276377, 'n_jobs': 4, 'learning_rate': 0.007969030085507185}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 19/3257 [00:00<00:17, 185.00it/s]  1%|‚ñè         | 41/3257 [00:00<00:16, 200.16it/s]  2%|‚ñè         | 62/3257 [00:00<00:15, 202.19it/s]  3%|‚ñé         | 85/3257 [00:00<00:15, 211.09it/s]  3%|‚ñé         | 107/3257 [00:00<00:16, 195.32it/s]  4%|‚ñç         | 130/3257 [00:00<00:15, 205.98it/s]  5%|‚ñç         | 154/3257 [00:00<00:14, 212.84it/s]  5%|‚ñå         | 176/3257 [00:00<00:14, 208.85it/s]  6%|‚ñå         | 201/3257 [00:00<00:14, 217.60it/s]  7%|‚ñã         | 231/3257 [00:01<00:12, 239.45it/s]  8%|‚ñä         | 256/3257 [00:01<00:12, 240.01it/s]  9%|‚ñâ         | 285/3257 [00:01<00:11, 251.81it/s] 10%|‚ñâ         | 311/3257 [00:01<00:11, 247.81it/s] 10%|‚ñà         | 336/3257 [00:01<00:16, 182.09it/s] 11%|‚ñà         | 359/3257 [00:01<00:15, 192.75it/s] 12%|‚ñà‚ñè        | 381/3257 [00:01<00:15, 191.71it/s] 12%|‚ñà‚ñè        | 404/3257 [00:01<00:14, 198.55it/s] 13%|‚ñà‚ñé        | 425/3257 [00:02<00:14, 192.34it/s] 14%|‚ñà‚ñé        | 445/3257 [00:02<00:14, 190.21it/s] 14%|‚ñà‚ñç        | 465/3257 [00:02<00:14, 191.70it/s] 15%|‚ñà‚ñç        | 485/3257 [00:02<00:14, 185.76it/s] 16%|‚ñà‚ñå        | 507/3257 [00:02<00:14, 194.47it/s] 16%|‚ñà‚ñå        | 527/3257 [00:02<00:14, 188.04it/s] 17%|‚ñà‚ñã        | 547/3257 [00:02<00:14, 188.26it/s] 17%|‚ñà‚ñã        | 566/3257 [00:02<00:15, 176.20it/s] 18%|‚ñà‚ñä        | 584/3257 [00:02<00:15, 169.66it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:15, 175.86it/s] 19%|‚ñà‚ñâ        | 622/3257 [00:03<00:15, 174.88it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:03<00:14, 183.76it/s] 20%|‚ñà‚ñà        | 663/3257 [00:03<00:15, 167.87it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:15, 167.24it/s] 22%|‚ñà‚ñà‚ñè       | 701/3257 [00:03<00:15, 169.64it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:03<00:14, 172.58it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:03<00:15, 162.54it/s] 23%|‚ñà‚ñà‚ñé       | 759/3257 [00:03<00:14, 173.27it/s] 24%|‚ñà‚ñà‚ñç       | 777/3257 [00:04<00:14, 167.67it/s] 24%|‚ñà‚ñà‚ñç       | 796/3257 [00:04<00:14, 172.12it/s] 25%|‚ñà‚ñà‚ñç       | 814/3257 [00:04<00:14, 172.73it/s] 26%|‚ñà‚ñà‚ñå       | 832/3257 [00:04<00:14, 165.74it/s] 26%|‚ñà‚ñà‚ñå       | 849/3257 [00:04<00:14, 161.39it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:04<00:14, 167.44it/s] 27%|‚ñà‚ñà‚ñã       | 889/3257 [00:04<00:13, 178.45it/s] 28%|‚ñà‚ñà‚ñä       | 913/3257 [00:04<00:12, 194.81it/s] 29%|‚ñà‚ñà‚ñä       | 933/3257 [00:04<00:12, 193.54it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:05<00:11, 203.24it/s] 30%|‚ñà‚ñà‚ñà       | 978/3257 [00:05<00:11, 204.96it/s] 31%|‚ñà‚ñà‚ñà       | 999/3257 [00:05<00:11, 194.68it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1021/3257 [00:05<00:11, 199.92it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1042/3257 [00:05<00:11, 185.82it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1064/3257 [00:05<00:11, 194.49it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1084/3257 [00:05<00:11, 195.69it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1106/3257 [00:05<00:10, 202.46it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1127/3257 [00:05<00:10, 197.36it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1147/3257 [00:06<00:10, 194.70it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:06<00:10, 202.65it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1192/3257 [00:06<00:10, 188.19it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1212/3257 [00:06<00:11, 182.29it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1236/3257 [00:06<00:10, 197.33it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:06<00:10, 192.38it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:06<00:10, 188.39it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1296/3257 [00:06<00:10, 181.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1317/3257 [00:06<00:10, 189.00it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:07<00:09, 195.72it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1359/3257 [00:07<00:09, 191.26it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1379/3257 [00:07<00:09, 191.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1399/3257 [00:07<00:09, 192.75it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:07<00:08, 204.90it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1445/3257 [00:07<00:08, 207.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1471/3257 [00:07<00:08, 221.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1494/3257 [00:07<00:08, 217.19it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1518/3257 [00:07<00:07, 220.61it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1541/3257 [00:07<00:08, 198.21it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1562/3257 [00:08<00:08, 194.61it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1582/3257 [00:08<00:08, 189.32it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1605/3257 [00:08<00:08, 198.46it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1628/3257 [00:08<00:07, 206.53it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1649/3257 [00:08<00:13, 122.51it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:08<00:11, 134.82it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1686/3257 [00:08<00:11, 141.76it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:09<00:09, 155.88it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:09<00:09, 159.79it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1747/3257 [00:09<00:09, 166.65it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1767/3257 [00:09<00:08, 174.15it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1786/3257 [00:09<00:08, 178.02it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1805/3257 [00:09<00:08, 171.30it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1823/3257 [00:09<00:08, 172.44it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1841/3257 [00:09<00:08, 166.37it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1858/3257 [00:09<00:08, 163.82it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:10<00:07, 174.54it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:10<00:07, 171.42it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:10<00:07, 174.32it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1935/3257 [00:10<00:07, 177.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1958/3257 [00:10<00:06, 189.70it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1978/3257 [00:10<00:07, 181.07it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1997/3257 [00:10<00:06, 181.81it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2016/3257 [00:10<00:07, 177.19it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:10<00:06, 180.71it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2054/3257 [00:11<00:07, 166.73it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2071/3257 [00:11<00:07, 158.02it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2088/3257 [00:11<00:07, 158.00it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2104/3257 [00:11<00:07, 153.24it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:11<00:07, 148.96it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2135/3257 [00:11<00:07, 147.18it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2150/3257 [00:11<00:07, 145.68it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:11<00:06, 155.69it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:11<00:06, 155.62it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:12<00:06, 161.47it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2221/3257 [00:12<00:06, 159.03it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:12<00:06, 156.10it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2253/3257 [00:12<00:06, 156.33it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2269/3257 [00:12<00:06, 154.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2288/3257 [00:12<00:05, 162.85it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2308/3257 [00:12<00:05, 171.42it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2335/3257 [00:12<00:04, 197.65it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2361/3257 [00:12<00:04, 213.76it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2386/3257 [00:12<00:03, 222.49it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2409/3257 [00:13<00:03, 215.77it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2431/3257 [00:13<00:03, 207.66it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2452/3257 [00:13<00:03, 205.12it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2479/3257 [00:13<00:03, 221.45it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2504/3257 [00:13<00:03, 228.61it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2527/3257 [00:13<00:03, 223.30it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2550/3257 [00:13<00:03, 221.72it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:13<00:03, 198.72it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2594/3257 [00:14<00:03, 195.83it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2621/3257 [00:14<00:02, 213.06it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2643/3257 [00:14<00:02, 209.31it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2665/3257 [00:14<00:02, 199.92it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2686/3257 [00:14<00:02, 202.50it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2707/3257 [00:14<00:03, 179.26it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2726/3257 [00:14<00:02, 181.92it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2748/3257 [00:14<00:02, 192.16it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2768/3257 [00:14<00:02, 188.65it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2791/3257 [00:15<00:02, 198.27it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2812/3257 [00:15<00:02, 199.09it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2833/3257 [00:15<00:02, 184.44it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2854/3257 [00:15<00:02, 190.22it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2883/3257 [00:15<00:01, 217.02it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:15<00:01, 197.00it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:15<00:01, 202.31it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2949/3257 [00:15<00:01, 189.70it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:16<00:02, 103.47it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:16<00:02, 110.44it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:16<00:02, 124.12it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3020/3257 [00:16<00:01, 131.63it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3039/3257 [00:16<00:01, 145.00it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3060/3257 [00:16<00:01, 160.97it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3080/3257 [00:16<00:01, 169.25it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3099/3257 [00:16<00:00, 167.69it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3120/3257 [00:17<00:00, 178.14it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3139/3257 [00:17<00:00, 170.63it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3157/3257 [00:17<00:00, 164.23it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3175/3257 [00:17<00:00, 166.46it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3192/3257 [00:17<00:00, 165.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3209/3257 [00:17<00:00, 163.58it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3226/3257 [00:17<00:00, 164.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3249/3257 [00:17<00:00, 182.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 181.87it/s]
2023-02-07 20:03:22.915 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:03:22,916][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d400,n5,w4,mc9,s0.662623,t4>', 'datetime': '2023-02-07T20:03:22.916251', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:03:22,916][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:03:22,916][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:03:23,440][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 20:03:23,440][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:03:23,476][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 11387 unique words (35.80% of original 31803, drops 20416)', 'datetime': '2023-02-07T20:03:23.476338', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:03:23,476][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 5023141 word corpus (98.59% of original 5095118, drops 71977)', 'datetime': '2023-02-07T20:03:23.476665', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:03:23,513][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 20:03:23,514][gensim.models.word2vec][INFO] - sample=0.662623 downsamples 0 most-common words
[2023-02-07 20:03:23,514][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5023141 word corpus (100.0%% of prior 5023141)', 'datetime': '2023-02-07T20:03:23.514260', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:03:23,577][gensim.models.word2vec][INFO] - estimated required memory for 11387 words and 400 dimensions: 47994500 bytes
[2023-02-07 20:03:23,577][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:03:23,600][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11387 vocabulary and 400 features, using sg=0 hs=0 sample=0.66262319374603 negative=5 window=4 shrink_windows=True', 'datetime': '2023-02-07T20:03:23.600276', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:03:24,605][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 31.72% examples, 1605835 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:25,609][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 62.85% examples, 1597335 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:26,618][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 96.59% examples, 1608720 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:26,723][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5015324 effective words) took 3.1s, 1607100 effective words/s
[2023-02-07 20:03:27,733][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 29.51% examples, 1470387 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:28,739][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 57.91% examples, 1476666 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:29,743][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 88.85% examples, 1487551 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:30,024][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5015324 effective words) took 3.3s, 1520725 effective words/s
[2023-02-07 20:03:31,038][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 35.89% examples, 1801171 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:32,053][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 69.02% examples, 1745857 words/s, in_qsize 6, out_qsize 1
[2023-02-07 20:03:32,927][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5015324 effective words) took 2.9s, 1728266 effective words/s
[2023-02-07 20:03:33,931][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 29.78% examples, 1496771 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:34,934][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 58.80% examples, 1501434 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:35,940][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 89.62% examples, 1501995 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:36,200][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5015324 effective words) took 3.3s, 1533203 effective words/s
[2023-02-07 20:03:37,208][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 36.91% examples, 1889204 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:38,214][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 70.37% examples, 1793190 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:39,034][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5015324 effective words) took 2.8s, 1770994 effective words/s
[2023-02-07 20:03:40,037][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 33.13% examples, 1674512 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:41,042][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 65.86% examples, 1683534 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:42,005][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5015324 effective words) took 3.0s, 1689194 effective words/s
[2023-02-07 20:03:43,008][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 33.13% examples, 1673725 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:44,013][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 65.77% examples, 1678725 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:44,989][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5015324 effective words) took 3.0s, 1681323 effective words/s
[2023-02-07 20:03:45,998][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 33.13% examples, 1664879 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:47,002][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 65.86% examples, 1679477 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:47,953][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5015324 effective words) took 3.0s, 1693102 effective words/s
[2023-02-07 20:03:48,958][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 34.05% examples, 1723474 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:49,964][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 67.85% examples, 1732336 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:50,835][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5015324 effective words) took 2.9s, 1741419 effective words/s
[2023-02-07 20:03:51,838][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 31.01% examples, 1569945 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:52,841][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 60.49% examples, 1536990 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:03:53,842][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 91.00% examples, 1530160 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:54,110][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5015324 effective words) took 3.3s, 1532300 effective words/s
[2023-02-07 20:03:55,115][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 30.37% examples, 1525776 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:56,119][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 60.61% examples, 1537430 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:57,122][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 91.50% examples, 1535986 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:57,377][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5015324 effective words) took 3.3s, 1535954 effective words/s
[2023-02-07 20:03:58,381][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 30.00% examples, 1505496 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:03:59,384][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 58.95% examples, 1505745 words/s, in_qsize 6, out_qsize 1
[2023-02-07 20:04:00,385][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 96.47% examples, 1610949 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:04:00,472][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5015324 effective words) took 3.1s, 1621832 effective words/s
[2023-02-07 20:04:01,474][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 35.86% examples, 1831695 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:04:02,475][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 69.67% examples, 1784674 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:04:03,307][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5015324 effective words) took 2.8s, 1769722 effective words/s
[2023-02-07 20:04:04,318][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 33.80% examples, 1705321 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:04:05,330][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 67.06% examples, 1700665 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:04:06,253][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5015324 effective words) took 2.9s, 1703862 effective words/s
[2023-02-07 20:04:07,256][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 33.13% examples, 1675011 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:04:08,263][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 66.47% examples, 1695799 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:04:09,206][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5015324 effective words) took 3.0s, 1699858 effective words/s
[2023-02-07 20:04:09,206][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75229860 effective words) took 45.6s, 1649554 effective words/s', 'datetime': '2023-02-07T20:04:09.206852', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:04:09.207 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:04:12,857][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200256-v2ys89cu/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:04:12.857845', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:04:12,858][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:04:12,918][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200256-v2ys89cu/files/../tmp/embedding_model.pt
2023-02-07 20:04:12.919 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:04:15.337 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:04:16.198 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:04:19.096 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.092008241356845, 'test_mae': 0.802175312000184, 'test_r2': -2.939562603161308}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.57
wandb: percentage 0.64195
wandb:   test_mae 0.80218
wandb:   test_mse 1.09201
wandb:    test_r2 -2.93956
wandb: 
wandb: üöÄ View run morning-sweep-68 at: https://wandb.ai/xiaoqiz/mof2vec/runs/v2ys89cu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_200256-v2ys89cu/logs
wandb: Agent Starting Run: ltnc5rw6 with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 536
wandb: 	model.gensim.alpha: 0.002040312331475752
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.6419614826752462
wandb: 	model.gensim.vector_size: 395
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.0010647335585513152
wandb: 	model.sklearn.max_depth: 69
wandb: 	model.sklearn.min_child_weight: 0.03750798999705649
wandb: 	model.sklearn.n_estimators: 846
wandb: 	model.sklearn.num_leaves: 223
wandb: 	model.sklearn.reg_alpha: 0.09853267307642428
wandb: 	model.sklearn.reg_lambda: 0.10739073821089122
wandb: 	model.sklearn.subsample: 0.8597975924187868
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200432-ltnc5rw6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-69
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/ltnc5rw6
2023-02-07 20:04:41.049 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 20:04:41.050 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 536 for sweep.
2023-02-07 20:04:41.051 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.002040312331475752 for sweep.
2023-02-07 20:04:41.051 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:04:41.051 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 20:04:41.052 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6419614826752462 for sweep.
2023-02-07 20:04:41.052 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 395 for sweep.
2023-02-07 20:04:41.053 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 20:04:41.053 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0010647335585513152 for sweep.
2023-02-07 20:04:41.053 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 69 for sweep.
2023-02-07 20:04:41.053 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03750798999705649 for sweep.
2023-02-07 20:04:41.054 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 846 for sweep.
2023-02-07 20:04:41.054 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 223 for sweep.
2023-02-07 20:04:41.054 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.09853267307642428 for sweep.
2023-02-07 20:04:41.054 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.10739073821089122 for sweep.
2023-02-07 20:04:41.055 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8597975924187868 for sweep.
2023-02-07 20:04:41.055 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:04:41.063 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200432-ltnc5rw6/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 536, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 395, 'window': 2, 'min_count': 6, 'dm': 0, 'sample': 0.6419614826752462, 'workers': 4, 'alpha': 0.002040312331475752, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 846, 'max_depth': 69, 'num_leaves': 223, 'reg_alpha': 0.09853267307642428, 'reg_lambda': 0.10739073821089122, 'subsample': 0.8597975924187868, 'min_child_weight': 0.03750798999705649, 'n_jobs': 4, 'learning_rate': 0.0010647335585513152}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 166.04it/s]  1%|          | 36/3257 [00:00<00:18, 178.00it/s]  2%|‚ñè         | 55/3257 [00:00<00:17, 178.82it/s]  3%|‚ñé         | 83/3257 [00:00<00:14, 216.06it/s]  3%|‚ñé         | 105/3257 [00:00<00:14, 215.32it/s]  4%|‚ñç         | 127/3257 [00:00<00:14, 215.94it/s]  5%|‚ñç         | 154/3257 [00:00<00:13, 229.52it/s]  5%|‚ñå         | 177/3257 [00:00<00:13, 226.23it/s]  6%|‚ñå         | 201/3257 [00:00<00:13, 228.57it/s]  7%|‚ñã         | 232/3257 [00:01<00:12, 250.53it/s]  8%|‚ñä         | 258/3257 [00:01<00:12, 247.25it/s]  9%|‚ñâ         | 285/3257 [00:01<00:11, 249.31it/s] 10%|‚ñâ         | 310/3257 [00:01<00:12, 243.46it/s] 10%|‚ñà         | 335/3257 [00:01<00:12, 242.72it/s] 11%|‚ñà         | 360/3257 [00:01<00:12, 237.42it/s] 12%|‚ñà‚ñè        | 384/3257 [00:01<00:12, 225.32it/s] 12%|‚ñà‚ñè        | 407/3257 [00:01<00:12, 220.12it/s] 13%|‚ñà‚ñé        | 430/3257 [00:01<00:14, 200.14it/s] 14%|‚ñà‚ñç        | 451/3257 [00:02<00:13, 202.71it/s] 15%|‚ñà‚ñç        | 475/3257 [00:02<00:13, 211.60it/s] 15%|‚ñà‚ñå        | 499/3257 [00:02<00:12, 217.49it/s] 16%|‚ñà‚ñå        | 523/3257 [00:02<00:12, 223.13it/s] 17%|‚ñà‚ñã        | 546/3257 [00:02<00:12, 219.35it/s] 17%|‚ñà‚ñã        | 569/3257 [00:02<00:12, 218.06it/s] 18%|‚ñà‚ñä        | 591/3257 [00:02<00:12, 210.26it/s] 19%|‚ñà‚ñâ        | 616/3257 [00:02<00:11, 220.18it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:02<00:11, 219.23it/s] 20%|‚ñà‚ñà        | 662/3257 [00:03<00:12, 202.47it/s] 21%|‚ñà‚ñà        | 685/3257 [00:03<00:12, 206.19it/s] 22%|‚ñà‚ñà‚ñè       | 709/3257 [00:03<00:11, 214.55it/s] 22%|‚ñà‚ñà‚ñè       | 731/3257 [00:03<00:12, 206.72it/s] 23%|‚ñà‚ñà‚ñé       | 752/3257 [00:03<00:12, 204.87it/s] 24%|‚ñà‚ñà‚ñç       | 774/3257 [00:03<00:11, 208.67it/s] 24%|‚ñà‚ñà‚ñç       | 795/3257 [00:03<00:11, 206.28it/s] 25%|‚ñà‚ñà‚ñå       | 816/3257 [00:03<00:11, 204.44it/s] 26%|‚ñà‚ñà‚ñå       | 837/3257 [00:03<00:12, 195.55it/s] 26%|‚ñà‚ñà‚ñã       | 857/3257 [00:03<00:12, 191.87it/s] 27%|‚ñà‚ñà‚ñã       | 877/3257 [00:04<00:12, 188.87it/s] 28%|‚ñà‚ñà‚ñä       | 902/3257 [00:04<00:11, 204.62it/s] 28%|‚ñà‚ñà‚ñä       | 925/3257 [00:04<00:11, 209.96it/s] 29%|‚ñà‚ñà‚ñâ       | 947/3257 [00:04<00:11, 205.06it/s] 30%|‚ñà‚ñà‚ñâ       | 969/3257 [00:04<00:11, 207.53it/s] 30%|‚ñà‚ñà‚ñà       | 990/3257 [00:04<00:11, 199.88it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:04<00:11, 196.48it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1031/3257 [00:05<00:17, 126.37it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1050/3257 [00:05<00:15, 137.94it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1072/3257 [00:05<00:14, 154.78it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:05<00:13, 159.56it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1113/3257 [00:05<00:12, 174.35it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1132/3257 [00:05<00:12, 169.49it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1151/3257 [00:05<00:12, 173.89it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1174/3257 [00:05<00:11, 187.96it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:05<00:11, 177.11it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1213/3257 [00:06<00:11, 173.43it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1239/3257 [00:06<00:10, 196.63it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1260/3257 [00:06<00:10, 194.89it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1280/3257 [00:06<00:10, 188.20it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1300/3257 [00:06<00:10, 187.91it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:06<00:10, 192.84it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:06<00:09, 202.36it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1365/3257 [00:06<00:09, 192.71it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:06<00:09, 190.46it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1410/3257 [00:07<00:08, 206.51it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1434/3257 [00:07<00:08, 212.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:07<00:07, 225.24it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1483/3257 [00:07<00:07, 223.41it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1510/3257 [00:07<00:07, 233.55it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1534/3257 [00:07<00:08, 209.53it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1556/3257 [00:07<00:08, 200.30it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1577/3257 [00:07<00:08, 198.06it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1601/3257 [00:07<00:07, 207.52it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1623/3257 [00:08<00:07, 208.71it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1645/3257 [00:08<00:07, 205.47it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1666/3257 [00:08<00:08, 197.05it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1686/3257 [00:08<00:08, 195.20it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:08<00:07, 197.83it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:08<00:07, 192.12it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1748/3257 [00:08<00:07, 189.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1770/3257 [00:08<00:07, 197.31it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1793/3257 [00:08<00:07, 206.28it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:08<00:07, 199.18it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1835/3257 [00:09<00:07, 200.90it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1857/3257 [00:09<00:06, 205.51it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1880/3257 [00:09<00:06, 209.67it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1902/3257 [00:09<00:06, 208.47it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1923/3257 [00:09<00:06, 205.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1952/3257 [00:09<00:05, 229.42it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1976/3257 [00:09<00:05, 229.12it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:09<00:05, 221.61it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:09<00:05, 221.80it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2045/3257 [00:10<00:05, 211.27it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2067/3257 [00:10<00:06, 193.19it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2090/3257 [00:10<00:05, 202.11it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2111/3257 [00:10<00:05, 201.91it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:10<00:05, 190.47it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2152/3257 [00:10<00:05, 190.80it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2175/3257 [00:10<00:05, 201.20it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2196/3257 [00:10<00:05, 202.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2217/3257 [00:10<00:05, 201.99it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:11<00:07, 127.57it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2256/3257 [00:11<00:07, 136.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2273/3257 [00:11<00:07, 136.97it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2295/3257 [00:11<00:06, 155.68it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2313/3257 [00:11<00:05, 158.48it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2336/3257 [00:11<00:05, 175.63it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:11<00:04, 186.38it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2381/3257 [00:11<00:04, 190.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2403/3257 [00:12<00:04, 196.47it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2424/3257 [00:12<00:04, 185.15it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:12<00:04, 172.42it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2464/3257 [00:12<00:04, 181.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2483/3257 [00:12<00:04, 183.23it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:12<00:03, 194.40it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2527/3257 [00:12<00:03, 195.20it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2547/3257 [00:12<00:03, 196.42it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2567/3257 [00:12<00:03, 185.21it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:13<00:03, 176.34it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2607/3257 [00:13<00:03, 183.72it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2629/3257 [00:13<00:03, 193.45it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2649/3257 [00:13<00:03, 181.98it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2668/3257 [00:13<00:03, 179.54it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:13<00:03, 182.19it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2706/3257 [00:13<00:03, 165.62it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2723/3257 [00:13<00:03, 159.27it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2746/3257 [00:14<00:02, 176.71it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2765/3257 [00:14<00:02, 176.03it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2783/3257 [00:14<00:02, 175.82it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2804/3257 [00:14<00:02, 184.36it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:14<00:02, 175.91it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2841/3257 [00:14<00:02, 167.40it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2864/3257 [00:14<00:02, 183.83it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:14<00:01, 191.92it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:14<00:01, 178.65it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:15<00:01, 183.09it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:15<00:01, 173.61it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2967/3257 [00:15<00:01, 176.87it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:15<00:01, 167.60it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3007/3257 [00:15<00:01, 181.60it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:15<00:01, 176.56it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:15<00:01, 185.54it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3070/3257 [00:15<00:00, 194.90it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3090/3257 [00:15<00:00, 188.97it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3111/3257 [00:16<00:00, 192.60it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3131/3257 [00:16<00:00, 188.17it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3150/3257 [00:16<00:00, 180.13it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3169/3257 [00:16<00:00, 178.12it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3187/3257 [00:16<00:00, 177.16it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3208/3257 [00:16<00:00, 183.27it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3227/3257 [00:16<00:00, 184.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3249/3257 [00:16<00:00, 193.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 193.69it/s]
2023-02-07 20:04:58.527 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:04:58,528][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d395,n5,mc6,s0.641961,t4>', 'datetime': '2023-02-07T20:04:58.528398', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:04:58,530][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:04:58,530][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:04:58,988][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 20:04:58,988][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:04:59,022][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 10832 unique words (49.92% of original 21699, drops 10867)', 'datetime': '2023-02-07T20:04:59.022162', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:04:59,022][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 4339647 word corpus (99.37% of original 4367244, drops 27597)', 'datetime': '2023-02-07T20:04:59.022605', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:04:59,062][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 20:04:59,063][gensim.models.word2vec][INFO] - sample=0.641961 downsamples 0 most-common words
[2023-02-07 20:04:59,063][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4339647 word corpus (100.0%% of prior 4339647)', 'datetime': '2023-02-07T20:04:59.063761', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:04:59,133][gensim.models.word2vec][INFO] - estimated required memory for 10832 words and 395 dimensions: 45442580 bytes
[2023-02-07 20:04:59,133][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:04:59,161][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 10832 vocabulary and 395 features, using sg=1 hs=0 sample=0.6419614826752462 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T20:04:59.161567', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:05:00,176][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 35.49% examples, 1549713 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:01,181][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 75.53% examples, 1651386 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:01,691][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4341209 effective words) took 2.5s, 1718748 effective words/s
[2023-02-07 20:05:02,693][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 42.03% examples, 1875709 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:03,695][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 84.59% examples, 1849132 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:05:04,040][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4341209 effective words) took 2.3s, 1849273 effective words/s
[2023-02-07 20:05:05,044][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 41.36% examples, 1843264 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:06,044][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 83.51% examples, 1832360 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:06,407][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4341209 effective words) took 2.4s, 1836560 effective words/s
[2023-02-07 20:05:07,412][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 40.93% examples, 1820321 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:08,423][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 83.51% examples, 1820666 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:08,778][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4341209 effective words) took 2.4s, 1831801 effective words/s
[2023-02-07 20:05:09,789][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 41.17% examples, 1822172 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:10,789][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 84.53% examples, 1844285 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:11,120][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4341209 effective words) took 2.3s, 1855943 effective words/s
[2023-02-07 20:05:12,132][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 39.30% examples, 1737094 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:13,144][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 78.94% examples, 1714819 words/s, in_qsize 7, out_qsize 1
[2023-02-07 20:05:13,659][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4341209 effective words) took 2.5s, 1711569 effective words/s
[2023-02-07 20:05:14,665][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.29% examples, 1696430 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:15,667][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 77.43% examples, 1693743 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:16,222][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4341209 effective words) took 2.6s, 1695091 effective words/s
[2023-02-07 20:05:17,225][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 37.98% examples, 1684611 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:18,230][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 77.53% examples, 1695254 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:05:18,776][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4341209 effective words) took 2.6s, 1701339 effective words/s
[2023-02-07 20:05:19,782][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 37.98% examples, 1679268 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:20,784][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 84.13% examples, 1837345 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:21,091][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4341209 effective words) took 2.3s, 1877023 effective words/s
[2023-02-07 20:05:22,096][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 41.63% examples, 1853256 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:23,097][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 84.59% examples, 1847270 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:05:23,440][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4341209 effective words) took 2.3s, 1848892 effective words/s
[2023-02-07 20:05:24,444][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 41.36% examples, 1840887 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:05:25,444][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 84.37% examples, 1845991 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:25,788][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4341209 effective words) took 2.3s, 1850335 effective words/s
[2023-02-07 20:05:26,800][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 41.17% examples, 1816928 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:27,804][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 84.37% examples, 1835054 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:28,151][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4341209 effective words) took 2.4s, 1838885 effective words/s
[2023-02-07 20:05:29,153][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 41.73% examples, 1861643 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:05:30,165][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 85.23% examples, 1857175 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:30,515][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4341209 effective words) took 2.4s, 1837799 effective words/s
[2023-02-07 20:05:31,521][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 37.61% examples, 1663356 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:05:32,523][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 76.85% examples, 1684099 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:05:33,089][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4341209 effective words) took 2.6s, 1688840 effective words/s
[2023-02-07 20:05:34,093][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 38.50% examples, 1711784 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:35,098][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 78.14% examples, 1707261 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:05:35,631][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4341209 effective words) took 2.5s, 1709860 effective words/s
[2023-02-07 20:05:35,632][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65118135 effective words) took 36.5s, 1785509 effective words/s', 'datetime': '2023-02-07T20:05:35.632431', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:05:35.632 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:05:38,837][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200432-ltnc5rw6/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:05:38.837060', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:05:38,838][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:05:38,895][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200432-ltnc5rw6/files/../tmp/embedding_model.pt
2023-02-07 20:05:38.896 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:05:40.941 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:05:41.687 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:05:44.338 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0085391555644139, 'test_mae': 0.7732374500369001, 'test_r2': -1.8352787420892818}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.46
wandb: percentage 0.50081
wandb:   test_mae 0.77324
wandb:   test_mse 1.00854
wandb:    test_r2 -1.83528
wandb: 
wandb: üöÄ View run glowing-sweep-69 at: https://wandb.ai/xiaoqiz/mof2vec/runs/ltnc5rw6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_200432-ltnc5rw6/logs
wandb: Agent Starting Run: 6xjw9v4t with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 567
wandb: 	model.gensim.alpha: 0.01545907043630944
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.9206324442453392
wandb: 	model.gensim.vector_size: 214
wandb: 	model.gensim.window: 6
wandb: 	model.sklearn.learning_rate: 0.009148281465556024
wandb: 	model.sklearn.max_depth: 47
wandb: 	model.sklearn.min_child_weight: 0.02337685120218553
wandb: 	model.sklearn.n_estimators: 623
wandb: 	model.sklearn.num_leaves: 104
wandb: 	model.sklearn.reg_alpha: 0.019730378123369977
wandb: 	model.sklearn.reg_lambda: 0.05635989870348819
wandb: 	model.sklearn.subsample: 0.997634155352308
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200557-6xjw9v4t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-70
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/6xjw9v4t
2023-02-07 20:06:05.764 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 20:06:05.765 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 567 for sweep.
2023-02-07 20:06:05.766 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.01545907043630944 for sweep.
2023-02-07 20:06:05.766 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:06:05.766 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 20:06:05.766 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9206324442453392 for sweep.
2023-02-07 20:06:05.767 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 214 for sweep.
2023-02-07 20:06:05.768 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 6 for sweep.
2023-02-07 20:06:05.768 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.009148281465556024 for sweep.
2023-02-07 20:06:05.768 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 47 for sweep.
2023-02-07 20:06:05.769 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.02337685120218553 for sweep.
2023-02-07 20:06:05.769 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 623 for sweep.
2023-02-07 20:06:05.769 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 104 for sweep.
2023-02-07 20:06:05.769 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.019730378123369977 for sweep.
2023-02-07 20:06:05.769 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.05635989870348819 for sweep.
2023-02-07 20:06:05.770 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.997634155352308 for sweep.
2023-02-07 20:06:05.770 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:06:05.779 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200557-6xjw9v4t/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 567, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 214, 'window': 6, 'min_count': 10, 'dm': 0, 'sample': 0.9206324442453392, 'workers': 4, 'alpha': 0.01545907043630944, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 623, 'max_depth': 47, 'num_leaves': 104, 'reg_alpha': 0.019730378123369977, 'reg_lambda': 0.05635989870348819, 'subsample': 0.997634155352308, 'min_child_weight': 0.02337685120218553, 'n_jobs': 4, 'learning_rate': 0.009148281465556024}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:20, 161.52it/s]  1%|          | 35/3257 [00:00<00:18, 171.82it/s]  2%|‚ñè         | 53/3257 [00:00<00:19, 166.79it/s]  2%|‚ñè         | 72/3257 [00:00<00:18, 175.47it/s]  3%|‚ñé         | 91/3257 [00:00<00:17, 177.64it/s]  3%|‚ñé         | 109/3257 [00:00<00:19, 163.92it/s]  4%|‚ñç         | 126/3257 [00:00<00:19, 163.78it/s]  5%|‚ñç         | 148/3257 [00:00<00:17, 178.30it/s]  5%|‚ñå         | 166/3257 [00:00<00:17, 171.73it/s]  6%|‚ñå         | 184/3257 [00:01<00:18, 170.29it/s]  6%|‚ñå         | 202/3257 [00:01<00:17, 171.68it/s]  7%|‚ñã         | 225/3257 [00:01<00:16, 188.52it/s]  8%|‚ñä         | 245/3257 [00:01<00:15, 189.67it/s]  8%|‚ñä         | 265/3257 [00:01<00:24, 121.65it/s]  9%|‚ñâ         | 290/3257 [00:01<00:20, 147.10it/s]  9%|‚ñâ         | 308/3257 [00:01<00:19, 152.60it/s] 10%|‚ñà         | 329/3257 [00:02<00:17, 164.33it/s] 11%|‚ñà         | 348/3257 [00:02<00:17, 164.48it/s] 11%|‚ñà‚ñè        | 368/3257 [00:02<00:16, 172.02it/s] 12%|‚ñà‚ñè        | 387/3257 [00:02<00:17, 160.53it/s] 12%|‚ñà‚ñè        | 406/3257 [00:02<00:17, 167.70it/s] 13%|‚ñà‚ñé        | 424/3257 [00:02<00:17, 166.49it/s] 14%|‚ñà‚ñé        | 442/3257 [00:02<00:18, 150.44it/s] 14%|‚ñà‚ñç        | 461/3257 [00:02<00:17, 158.90it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:17, 159.48it/s] 15%|‚ñà‚ñå        | 499/3257 [00:03<00:16, 169.29it/s] 16%|‚ñà‚ñå        | 518/3257 [00:03<00:15, 173.16it/s] 16%|‚ñà‚ñã        | 536/3257 [00:03<00:15, 171.97it/s] 17%|‚ñà‚ñã        | 555/3257 [00:03<00:15, 175.19it/s] 18%|‚ñà‚ñä        | 573/3257 [00:03<00:17, 150.48it/s] 18%|‚ñà‚ñä        | 592/3257 [00:03<00:16, 158.48it/s] 19%|‚ñà‚ñâ        | 611/3257 [00:03<00:15, 165.68it/s] 19%|‚ñà‚ñâ        | 629/3257 [00:03<00:15, 165.23it/s] 20%|‚ñà‚ñâ        | 646/3257 [00:03<00:16, 158.50it/s] 20%|‚ñà‚ñà        | 663/3257 [00:04<00:17, 150.41it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:16, 154.05it/s] 22%|‚ñà‚ñà‚ñè       | 701/3257 [00:04<00:15, 160.09it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:04<00:15, 165.66it/s] 23%|‚ñà‚ñà‚ñé       | 737/3257 [00:04<00:15, 157.94it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:04<00:15, 161.11it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:04<00:15, 165.57it/s] 24%|‚ñà‚ñà‚ñç       | 790/3257 [00:04<00:15, 163.80it/s] 25%|‚ñà‚ñà‚ñç       | 807/3257 [00:04<00:15, 160.02it/s] 25%|‚ñà‚ñà‚ñå       | 824/3257 [00:05<00:15, 160.16it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:05<00:15, 152.64it/s] 26%|‚ñà‚ñà‚ñã       | 859/3257 [00:05<00:15, 157.67it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:05<00:15, 155.58it/s] 27%|‚ñà‚ñà‚ñã       | 891/3257 [00:05<00:15, 155.26it/s] 28%|‚ñà‚ñà‚ñä       | 910/3257 [00:05<00:14, 164.70it/s] 28%|‚ñà‚ñà‚ñä       | 928/3257 [00:05<00:13, 168.91it/s] 29%|‚ñà‚ñà‚ñâ       | 945/3257 [00:05<00:13, 166.73it/s] 30%|‚ñà‚ñà‚ñâ       | 964/3257 [00:05<00:13, 172.49it/s] 30%|‚ñà‚ñà‚ñà       | 982/3257 [00:06<00:13, 166.47it/s] 31%|‚ñà‚ñà‚ñà       | 999/3257 [00:06<00:13, 164.87it/s] 31%|‚ñà‚ñà‚ñà       | 1017/3257 [00:06<00:13, 167.84it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1034/3257 [00:06<00:13, 160.02it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:06<00:13, 157.79it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1070/3257 [00:06<00:13, 166.03it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1087/3257 [00:06<00:13, 163.45it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1104/3257 [00:06<00:13, 164.49it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1121/3257 [00:06<00:13, 162.49it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1138/3257 [00:06<00:13, 161.81it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1155/3257 [00:07<00:13, 159.79it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:07<00:12, 164.77it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1190/3257 [00:07<00:14, 146.48it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1206/3257 [00:07<00:13, 148.15it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1223/3257 [00:07<00:13, 153.94it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1243/3257 [00:07<00:12, 164.94it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1260/3257 [00:07<00:12, 165.51it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:07<00:12, 159.95it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1295/3257 [00:07<00:11, 164.81it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1318/3257 [00:08<00:10, 183.37it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1341/3257 [00:08<00:09, 195.54it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1361/3257 [00:08<00:14, 131.21it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1381/3257 [00:08<00:13, 143.82it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1404/3257 [00:08<00:11, 163.65it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1429/3257 [00:08<00:09, 184.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:08<00:09, 193.17it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:08<00:09, 197.45it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1495/3257 [00:09<00:08, 199.62it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1516/3257 [00:09<00:08, 196.05it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1537/3257 [00:09<00:09, 177.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1556/3257 [00:09<00:09, 177.36it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:09<00:09, 179.23it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:09<00:08, 185.03it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1618/3257 [00:09<00:08, 193.78it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1638/3257 [00:09<00:08, 191.06it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1658/3257 [00:09<00:08, 188.01it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:10<00:08, 184.52it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1697/3257 [00:10<00:08, 188.02it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1716/3257 [00:10<00:08, 185.99it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1735/3257 [00:10<00:08, 171.53it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1757/3257 [00:10<00:08, 184.40it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:10<00:07, 190.97it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1800/3257 [00:10<00:07, 194.86it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1820/3257 [00:10<00:07, 196.24it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1840/3257 [00:10<00:07, 192.32it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1861/3257 [00:11<00:07, 196.87it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1883/3257 [00:11<00:06, 199.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1904/3257 [00:11<00:06, 201.21it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1925/3257 [00:11<00:06, 195.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1953/3257 [00:11<00:05, 218.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1976/3257 [00:11<00:05, 219.35it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:11<00:05, 211.08it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:11<00:05, 213.76it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2044/3257 [00:11<00:05, 204.49it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2065/3257 [00:12<00:06, 187.43it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:12<00:06, 188.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2106/3257 [00:12<00:05, 193.44it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2126/3257 [00:12<00:06, 182.82it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2145/3257 [00:12<00:06, 176.86it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:12<00:05, 189.52it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2188/3257 [00:12<00:05, 190.41it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:12<00:05, 188.52it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2230/3257 [00:12<00:05, 193.08it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2250/3257 [00:13<00:05, 187.30it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2269/3257 [00:13<00:05, 187.88it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2289/3257 [00:13<00:05, 190.90it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2309/3257 [00:13<00:05, 189.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2336/3257 [00:13<00:04, 211.96it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2361/3257 [00:13<00:04, 221.87it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2384/3257 [00:13<00:03, 221.55it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2407/3257 [00:13<00:03, 213.11it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2429/3257 [00:13<00:03, 211.18it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2451/3257 [00:13<00:04, 194.05it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:14<00:03, 204.14it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2497/3257 [00:14<00:03, 208.40it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2520/3257 [00:14<00:03, 213.57it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2542/3257 [00:14<00:03, 214.06it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2564/3257 [00:14<00:03, 202.65it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2585/3257 [00:14<00:03, 188.53it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2608/3257 [00:14<00:03, 199.54it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2633/3257 [00:14<00:02, 213.30it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2655/3257 [00:14<00:02, 202.35it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2676/3257 [00:15<00:02, 202.80it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2697/3257 [00:15<00:02, 198.23it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2717/3257 [00:15<00:02, 183.37it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2743/3257 [00:15<00:02, 202.91it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2764/3257 [00:15<00:02, 203.66it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2787/3257 [00:15<00:02, 208.15it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2809/3257 [00:15<00:02, 210.41it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2831/3257 [00:16<00:03, 121.19it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2854/3257 [00:16<00:02, 141.75it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2885/3257 [00:16<00:02, 177.06it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2908/3257 [00:16<00:02, 169.07it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2929/3257 [00:16<00:01, 172.40it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2949/3257 [00:16<00:01, 164.97it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:16<00:01, 169.35it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2988/3257 [00:16<00:01, 164.06it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:17<00:01, 178.30it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3030/3257 [00:17<00:01, 171.83it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:17<00:01, 176.56it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3072/3257 [00:17<00:00, 190.33it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3092/3257 [00:17<00:00, 182.65it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3115/3257 [00:17<00:00, 195.02it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3135/3257 [00:17<00:00, 184.47it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3154/3257 [00:17<00:00, 178.60it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3173/3257 [00:17<00:00, 178.10it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3191/3257 [00:18<00:00, 171.74it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3209/3257 [00:18<00:00, 168.44it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3226/3257 [00:18<00:00, 167.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3246/3257 [00:18<00:00, 176.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 176.67it/s]
2023-02-07 20:06:25.036 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:06:25,037][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d214,n5,mc10,s0.920632,t4>', 'datetime': '2023-02-07T20:06:25.037630', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:06:25,038][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:06:25,038][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:06:25,565][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 20:06:25,566][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:06:25,604][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 11126 unique words (34.98% of original 31803, drops 20677)', 'datetime': '2023-02-07T20:06:25.604882', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:06:25,605][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 5020792 word corpus (98.54% of original 5095118, drops 74326)', 'datetime': '2023-02-07T20:06:25.605334', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:06:25,646][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 20:06:25,648][gensim.models.word2vec][INFO] - sample=0.920632 downsamples 0 most-common words
[2023-02-07 20:06:25,649][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5020792 word corpus (100.0%% of prior 5020792)', 'datetime': '2023-02-07T20:06:25.649123', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:06:25,719][gensim.models.word2vec][INFO] - estimated required memory for 11126 words and 214 dimensions: 28050104 bytes
[2023-02-07 20:06:25,719][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:06:25,733][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11126 vocabulary and 214 features, using sg=1 hs=0 sample=0.9206324442453392 negative=5 window=6 shrink_windows=True', 'datetime': '2023-02-07T20:06:25.733524', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:06:26,745][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 42.40% examples, 2173874 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:27,746][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 88.85% examples, 2232065 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:27,972][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5012991 effective words) took 2.2s, 2241862 effective words/s
[2023-02-07 20:06:28,974][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 47.56% examples, 2428974 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:29,977][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 94.90% examples, 2382319 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:30,076][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5012991 effective words) took 2.1s, 2384586 effective words/s
[2023-02-07 20:06:31,081][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 52.63% examples, 2691064 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:31,815][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5012991 effective words) took 1.7s, 2887187 effective words/s
[2023-02-07 20:06:32,816][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 61.59% examples, 3138144 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:33,411][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5012991 effective words) took 1.6s, 3143160 effective words/s
[2023-02-07 20:06:34,414][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 59.47% examples, 3039311 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:35,108][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5012991 effective words) took 1.7s, 2955836 effective words/s
[2023-02-07 20:06:36,113][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 54.81% examples, 2807111 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:36,917][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5012991 effective words) took 1.8s, 2775543 effective words/s
[2023-02-07 20:06:37,922][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.85% examples, 2764086 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:38,720][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5012991 effective words) took 1.8s, 2784009 effective words/s
[2023-02-07 20:06:39,729][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 55.76% examples, 2842995 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:40,487][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5012991 effective words) took 1.8s, 2839211 effective words/s
[2023-02-07 20:06:41,489][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 54.59% examples, 2803156 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:42,261][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5012991 effective words) took 1.8s, 2828545 effective words/s
[2023-02-07 20:06:43,266][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 56.00% examples, 2866930 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:44,003][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5012991 effective words) took 1.7s, 2881142 effective words/s
[2023-02-07 20:06:45,005][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 56.09% examples, 2882536 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:45,754][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5012991 effective words) took 1.7s, 2866717 effective words/s
[2023-02-07 20:06:46,759][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 56.37% examples, 2887914 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:47,495][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5012991 effective words) took 1.7s, 2880625 effective words/s
[2023-02-07 20:06:48,498][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 55.11% examples, 2824514 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:49,257][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5012991 effective words) took 1.8s, 2848361 effective words/s
[2023-02-07 20:06:50,259][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 54.59% examples, 2801747 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:51,036][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5012991 effective words) took 1.8s, 2819288 effective words/s
[2023-02-07 20:06:52,045][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 55.76% examples, 2844858 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:06:52,785][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5012991 effective words) took 1.7s, 2868584 effective words/s
[2023-02-07 20:06:52,786][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75194865 effective words) took 27.1s, 2779589 effective words/s', 'datetime': '2023-02-07T20:06:52.786498', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:06:52.786 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:06:55,155][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200557-6xjw9v4t/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:06:55.155461', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:06:55,156][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:06:55,195][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200557-6xjw9v4t/files/../tmp/embedding_model.pt
2023-02-07 20:06:55.196 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:06:56.728 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:06:57.279 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:06:58.771 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9366891883918066, 'test_mae': 0.7460988007165903, 'test_r2': -2.326535680001355}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.88
wandb: percentage 0.65016
wandb:   test_mae 0.7461
wandb:   test_mse 0.93669
wandb:    test_r2 -2.32654
wandb: 
wandb: üöÄ View run sunny-sweep-70 at: https://wandb.ai/xiaoqiz/mof2vec/runs/6xjw9v4t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_200557-6xjw9v4t/logs
wandb: Agent Starting Run: vvln8tam with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 316
wandb: 	model.gensim.alpha: 0.00880229172305162
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.6011804696050693
wandb: 	model.gensim.vector_size: 353
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.002312543458406987
wandb: 	model.sklearn.max_depth: 61
wandb: 	model.sklearn.min_child_weight: 0.031771915689574784
wandb: 	model.sklearn.n_estimators: 2238
wandb: 	model.sklearn.num_leaves: 75
wandb: 	model.sklearn.reg_alpha: 0.0032028267822339913
wandb: 	model.sklearn.reg_lambda: 0.0156523199491733
wandb: 	model.sklearn.subsample: 0.9861185005718248
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200712-vvln8tam
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-71
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/vvln8tam
2023-02-07 20:07:19.943 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:07:19.944 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 316 for sweep.
2023-02-07 20:07:19.944 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.00880229172305162 for sweep.
2023-02-07 20:07:19.944 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:07:19.945 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 20:07:19.945 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6011804696050693 for sweep.
2023-02-07 20:07:19.945 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 353 for sweep.
2023-02-07 20:07:19.945 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 20:07:19.945 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.002312543458406987 for sweep.
2023-02-07 20:07:19.946 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 61 for sweep.
2023-02-07 20:07:19.946 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.031771915689574784 for sweep.
2023-02-07 20:07:19.946 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2238 for sweep.
2023-02-07 20:07:19.946 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 75 for sweep.
2023-02-07 20:07:19.947 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0032028267822339913 for sweep.
2023-02-07 20:07:19.947 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0156523199491733 for sweep.
2023-02-07 20:07:19.947 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9861185005718248 for sweep.
2023-02-07 20:07:19.947 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:07:19.953 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200712-vvln8tam/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 316, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 353, 'window': 11, 'min_count': 10, 'dm': 0, 'sample': 0.6011804696050693, 'workers': 4, 'alpha': 0.00880229172305162, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2238, 'max_depth': 61, 'num_leaves': 75, 'reg_alpha': 0.0032028267822339913, 'reg_lambda': 0.0156523199491733, 'subsample': 0.9861185005718248, 'min_child_weight': 0.031771915689574784, 'n_jobs': 4, 'learning_rate': 0.002312543458406987}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:22, 146.54it/s]  1%|          | 33/3257 [00:00<00:19, 163.41it/s]  2%|‚ñè         | 50/3257 [00:00<00:19, 161.54it/s]  2%|‚ñè         | 67/3257 [00:00<00:20, 154.87it/s]  3%|‚ñé         | 89/3257 [00:00<00:18, 172.77it/s]  3%|‚ñé         | 107/3257 [00:00<00:20, 157.24it/s]  4%|‚ñç         | 124/3257 [00:00<00:19, 158.30it/s]  4%|‚ñç         | 141/3257 [00:00<00:19, 159.72it/s]  5%|‚ñç         | 158/3257 [00:01<00:20, 149.68it/s]  5%|‚ñå         | 174/3257 [00:01<00:21, 142.59it/s]  6%|‚ñå         | 190/3257 [00:01<00:21, 144.39it/s]  6%|‚ñã         | 205/3257 [00:01<00:21, 141.39it/s]  7%|‚ñã         | 224/3257 [00:01<00:19, 154.17it/s]  7%|‚ñã         | 240/3257 [00:01<00:19, 153.86it/s]  8%|‚ñä         | 256/3257 [00:01<00:19, 150.18it/s]  8%|‚ñä         | 272/3257 [00:01<00:20, 147.64it/s]  9%|‚ñâ         | 291/3257 [00:01<00:18, 159.22it/s]  9%|‚ñâ         | 308/3257 [00:02<00:19, 150.99it/s] 10%|‚ñà         | 326/3257 [00:02<00:18, 157.09it/s] 11%|‚ñà         | 342/3257 [00:02<00:19, 145.81it/s] 11%|‚ñà         | 359/3257 [00:02<00:19, 150.97it/s] 12%|‚ñà‚ñè        | 375/3257 [00:02<00:20, 143.28it/s] 12%|‚ñà‚ñè        | 390/3257 [00:02<00:21, 134.83it/s] 12%|‚ñà‚ñè        | 406/3257 [00:02<00:20, 139.26it/s] 13%|‚ñà‚ñé        | 421/3257 [00:02<00:20, 139.53it/s] 13%|‚ñà‚ñé        | 436/3257 [00:02<00:24, 116.84it/s] 14%|‚ñà‚ñç        | 452/3257 [00:03<00:22, 126.00it/s] 14%|‚ñà‚ñç        | 468/3257 [00:03<00:20, 134.22it/s] 15%|‚ñà‚ñç        | 483/3257 [00:03<00:21, 131.83it/s] 15%|‚ñà‚ñå        | 501/3257 [00:03<00:19, 143.69it/s] 16%|‚ñà‚ñå        | 516/3257 [00:03<00:18, 145.20it/s] 16%|‚ñà‚ñã        | 531/3257 [00:03<00:19, 141.36it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:19, 139.40it/s] 17%|‚ñà‚ñã        | 561/3257 [00:03<00:20, 132.33it/s] 18%|‚ñà‚ñä        | 575/3257 [00:03<00:20, 131.79it/s] 18%|‚ñà‚ñä        | 595/3257 [00:04<00:17, 148.53it/s] 19%|‚ñà‚ñâ        | 615/3257 [00:04<00:16, 160.17it/s] 19%|‚ñà‚ñâ        | 634/3257 [00:04<00:15, 168.46it/s] 20%|‚ñà‚ñà        | 652/3257 [00:04<00:16, 160.36it/s] 21%|‚ñà‚ñà        | 669/3257 [00:04<00:16, 155.59it/s] 21%|‚ñà‚ñà        | 685/3257 [00:04<00:16, 151.55it/s] 22%|‚ñà‚ñà‚ñè       | 703/3257 [00:04<00:16, 157.78it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:04<00:15, 161.93it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:04<00:16, 150.33it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:05<00:23, 105.23it/s] 24%|‚ñà‚ñà‚ñé       | 772/3257 [00:05<00:20, 119.95it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:05<00:20, 123.54it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:18, 134.89it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:17, 139.61it/s] 26%|‚ñà‚ñà‚ñå       | 835/3257 [00:05<00:17, 137.86it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:05<00:18, 131.57it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:06<00:17, 137.02it/s] 27%|‚ñà‚ñà‚ñã       | 881/3257 [00:06<00:17, 137.62it/s] 28%|‚ñà‚ñà‚ñä       | 898/3257 [00:06<00:16, 144.98it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:06<00:16, 146.40it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:06<00:15, 152.13it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:06<00:15, 153.40it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:06<00:14, 159.84it/s] 30%|‚ñà‚ñà‚ñà       | 983/3257 [00:06<00:14, 153.98it/s] 31%|‚ñà‚ñà‚ñà       | 999/3257 [00:06<00:15, 149.15it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:06<00:14, 150.08it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1031/3257 [00:07<00:15, 147.33it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:07<00:15, 142.77it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:07<00:14, 146.84it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:15, 144.18it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1095/3257 [00:07<00:15, 140.38it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1111/3257 [00:07<00:14, 143.62it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1126/3257 [00:07<00:15, 133.87it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1140/3257 [00:07<00:16, 130.51it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1154/3257 [00:08<00:16, 130.14it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:08<00:15, 135.12it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1184/3257 [00:08<00:16, 123.71it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1197/3257 [00:08<00:16, 121.50it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:08<00:17, 117.37it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1226/3257 [00:08<00:15, 127.61it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:08<00:15, 134.17it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1256/3257 [00:08<00:15, 129.59it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:08<00:15, 131.93it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1285/3257 [00:09<00:16, 119.52it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1299/3257 [00:09<00:15, 124.72it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:09<00:15, 128.74it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:09<00:14, 131.16it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:09<00:13, 137.01it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1358/3257 [00:09<00:14, 130.50it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1372/3257 [00:09<00:14, 126.12it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:09<00:14, 126.21it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:09<00:14, 131.95it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:10<00:12, 146.89it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1437/3257 [00:10<00:12, 143.53it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:10<00:12, 144.79it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1469/3257 [00:10<00:11, 151.34it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1485/3257 [00:10<00:12, 143.97it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1507/3257 [00:10<00:10, 164.23it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1524/3257 [00:10<00:11, 156.39it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1540/3257 [00:10<00:11, 155.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1556/3257 [00:10<00:11, 152.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:11<00:10, 156.80it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1595/3257 [00:11<00:09, 168.05it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1616/3257 [00:11<00:09, 177.04it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:11<00:09, 167.31it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1651/3257 [00:11<00:09, 162.57it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:11<00:10, 158.21it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1684/3257 [00:11<00:10, 153.89it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1702/3257 [00:11<00:09, 160.25it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1719/3257 [00:11<00:09, 159.45it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1736/3257 [00:12<00:10, 142.58it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1753/3257 [00:12<00:10, 149.26it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1770/3257 [00:12<00:09, 154.44it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1787/3257 [00:12<00:09, 158.14it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1804/3257 [00:12<00:09, 154.97it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1820/3257 [00:12<00:09, 152.52it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1836/3257 [00:12<00:09, 147.53it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1852/3257 [00:12<00:09, 150.35it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1870/3257 [00:12<00:08, 157.99it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1886/3257 [00:13<00:08, 158.11it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1904/3257 [00:13<00:08, 161.74it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1921/3257 [00:13<00:08, 158.12it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1944/3257 [00:13<00:07, 177.43it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:13<00:06, 185.98it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1984/3257 [00:13<00:07, 164.35it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2001/3257 [00:13<00:07, 165.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2018/3257 [00:13<00:07, 157.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:13<00:07, 154.08it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2051/3257 [00:14<00:08, 137.75it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2066/3257 [00:14<00:08, 132.66it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2082/3257 [00:14<00:08, 135.62it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2096/3257 [00:14<00:16, 70.16it/s]  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2112/3257 [00:14<00:13, 83.90it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2124/3257 [00:15<00:12, 87.58it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2139/3257 [00:15<00:11, 99.21it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2152/3257 [00:15<00:10, 104.73it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:15<00:09, 117.33it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2182/3257 [00:15<00:09, 119.29it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2200/3257 [00:15<00:07, 134.01it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2215/3257 [00:15<00:08, 127.05it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2230/3257 [00:15<00:07, 131.82it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2244/3257 [00:15<00:07, 127.20it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:16<00:07, 131.62it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2274/3257 [00:16<00:07, 125.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2293/3257 [00:16<00:06, 141.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2308/3257 [00:16<00:06, 138.51it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2328/3257 [00:16<00:06, 154.43it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2345/3257 [00:16<00:05, 158.49it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2362/3257 [00:16<00:05, 159.67it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2381/3257 [00:16<00:05, 167.28it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2403/3257 [00:16<00:04, 181.63it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:16<00:04, 173.21it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:17<00:04, 168.95it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2458/3257 [00:17<00:04, 168.42it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2477/3257 [00:17<00:04, 173.61it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2496/3257 [00:17<00:04, 177.22it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2517/3257 [00:17<00:04, 183.76it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2537/3257 [00:17<00:03, 185.28it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2556/3257 [00:17<00:04, 170.91it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2574/3257 [00:17<00:04, 162.45it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2591/3257 [00:17<00:04, 157.18it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2615/3257 [00:18<00:03, 178.06it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2635/3257 [00:18<00:03, 183.42it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:18<00:03, 171.77it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:18<00:03, 172.67it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2691/3257 [00:18<00:03, 173.34it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2709/3257 [00:18<00:03, 149.91it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2726/3257 [00:18<00:03, 154.49it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2746/3257 [00:18<00:03, 166.24it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2764/3257 [00:19<00:03, 164.17it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2781/3257 [00:19<00:02, 162.50it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2802/3257 [00:19<00:02, 174.74it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2820/3257 [00:19<00:02, 164.98it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:19<00:02, 159.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2854/3257 [00:19<00:02, 158.26it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2875/3257 [00:19<00:02, 171.58it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2893/3257 [00:19<00:02, 155.45it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2909/3257 [00:19<00:02, 149.18it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2927/3257 [00:20<00:02, 156.69it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2943/3257 [00:20<00:02, 138.19it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2958/3257 [00:20<00:02, 134.05it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2975/3257 [00:20<00:01, 143.25it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2990/3257 [00:20<00:02, 132.26it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3009/3257 [00:20<00:01, 146.13it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3025/3257 [00:20<00:01, 137.41it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3041/3257 [00:20<00:01, 142.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3057/3257 [00:20<00:01, 145.32it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:21<00:01, 153.17it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3091/3257 [00:21<00:01, 146.47it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:21<00:00, 156.06it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:21<00:00, 159.30it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3144/3257 [00:21<00:00, 146.90it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3159/3257 [00:21<00:00, 145.92it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3174/3257 [00:21<00:00, 143.21it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3189/3257 [00:21<00:00, 134.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3204/3257 [00:22<00:00, 136.78it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3218/3257 [00:22<00:00, 128.08it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3237/3257 [00:22<00:00, 142.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:22<00:00, 141.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 145.54it/s]
2023-02-07 20:07:43.228 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:07:43,230][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d353,n5,mc10,s0.60118,t4>', 'datetime': '2023-02-07T20:07:43.230135', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:07:43,230][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:07:43,230][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:07:43,781][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:07:43,782][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:07:43,829][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 17915 unique words (33.14% of original 54054, drops 36139)', 'datetime': '2023-02-07T20:07:43.829674', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:07:43,830][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 6418960 word corpus (97.99% of original 6550866, drops 131906)', 'datetime': '2023-02-07T20:07:43.830834', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:07:43,890][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:07:43,892][gensim.models.word2vec][INFO] - sample=0.60118 downsamples 0 most-common words
[2023-02-07 20:07:43,892][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6418960 word corpus (100.0%% of prior 6418960)', 'datetime': '2023-02-07T20:07:43.892241', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:07:43,995][gensim.models.word2vec][INFO] - estimated required memory for 17915 words and 353 dimensions: 64799744 bytes
[2023-02-07 20:07:43,995][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:07:44,024][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 17915 vocabulary and 353 features, using sg=1 hs=0 sample=0.6011804696050693 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T20:07:44.024441', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:07:45,029][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 29.90% examples, 1898373 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:46,029][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 59.10% examples, 1919699 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:47,030][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 90.18% examples, 1922932 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:47,331][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6365106 effective words) took 3.3s, 1925885 effective words/s
[2023-02-07 20:07:48,339][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 34.57% examples, 2213474 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:07:49,339][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 67.58% examples, 2185820 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:50,254][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6365106 effective words) took 2.9s, 2178556 effective words/s
[2023-02-07 20:07:51,259][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 33.68% examples, 2160702 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:07:52,261][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 66.87% examples, 2165768 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:07:53,206][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6365106 effective words) took 3.0s, 2157435 effective words/s
[2023-02-07 20:07:54,212][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 33.87% examples, 2169294 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:55,213][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 67.61% examples, 2190992 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:56,086][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6365106 effective words) took 2.9s, 2212269 effective words/s
[2023-02-07 20:07:57,090][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 35.46% examples, 2284127 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:07:58,101][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 70.06% examples, 2262710 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:07:59,003][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6365106 effective words) took 2.9s, 2182966 effective words/s
[2023-02-07 20:08:00,010][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 31.81% examples, 2032801 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:01,012][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 63.22% examples, 2041566 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:02,018][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 96.19% examples, 2033721 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:02,129][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6365106 effective words) took 3.1s, 2037730 effective words/s
[2023-02-07 20:08:03,134][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 31.93% examples, 2046630 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:04,143][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 63.89% examples, 2056434 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:05,143][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 97.36% examples, 2061242 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:05,214][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6365106 effective words) took 3.1s, 2064737 effective words/s
[2023-02-07 20:08:06,218][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 32.15% examples, 2067995 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:07,220][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 69.76% examples, 2268647 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:07,933][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6365106 effective words) took 2.7s, 2342427 effective words/s
[2023-02-07 20:08:08,936][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 36.81% examples, 2389477 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:09,938][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 73.81% examples, 2376190 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:10,621][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6365106 effective words) took 2.7s, 2370338 effective words/s
[2023-02-07 20:08:11,625][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.44% examples, 2356506 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:12,625][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 72.15% examples, 2331670 words/s, in_qsize 7, out_qsize 1
[2023-02-07 20:08:13,349][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6365106 effective words) took 2.7s, 2334970 effective words/s
[2023-02-07 20:08:14,353][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 36.17% examples, 2329385 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:15,353][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 72.18% examples, 2330396 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:16,075][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6365106 effective words) took 2.7s, 2335404 effective words/s
[2023-02-07 20:08:17,082][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 36.44% examples, 2350405 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:18,083][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 73.81% examples, 2372435 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:18,754][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6365106 effective words) took 2.7s, 2377930 effective words/s
[2023-02-07 20:08:19,756][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 37.40% examples, 2438791 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:08:20,756][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 73.50% examples, 2369433 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:21,525][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6365106 effective words) took 2.8s, 2297929 effective words/s
[2023-02-07 20:08:22,530][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 32.88% examples, 2108644 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:08:23,532][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 65.64% examples, 2125402 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:08:24,517][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6365106 effective words) took 3.0s, 2128820 effective words/s
[2023-02-07 20:08:25,522][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 33.16% examples, 2128224 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:26,524][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 65.58% examples, 2125859 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:08:27,520][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6365106 effective words) took 3.0s, 2121386 effective words/s
[2023-02-07 20:08:27,521][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (95476590 effective words) took 43.5s, 2195056 effective words/s', 'datetime': '2023-02-07T20:08:27.521066', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:08:27.521 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:08:31,100][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200712-vvln8tam/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:08:31.100083', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:08:31,100][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:08:31,187][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200712-vvln8tam/files/../tmp/embedding_model.pt
2023-02-07 20:08:31.187 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:08:33.268 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:08:33.991 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:08:36.375 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9674495865223824, 'test_mae': 0.748598151457456, 'test_r2': -2.2001410284679075}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.87
wandb: percentage 0.66857
wandb:   test_mae 0.7486
wandb:   test_mse 0.96745
wandb:    test_r2 -2.20014
wandb: 
wandb: üöÄ View run jolly-sweep-71 at: https://wandb.ai/xiaoqiz/mof2vec/runs/vvln8tam
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_200712-vvln8tam/logs
wandb: Agent Starting Run: h4266mro with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 660
wandb: 	model.gensim.alpha: 0.004946640264464157
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.9486534951897064
wandb: 	model.gensim.vector_size: 403
wandb: 	model.gensim.window: 5
wandb: 	model.sklearn.learning_rate: 0.47990387191859024
wandb: 	model.sklearn.max_depth: 59
wandb: 	model.sklearn.min_child_weight: 0.030954602886128977
wandb: 	model.sklearn.n_estimators: 1973
wandb: 	model.sklearn.num_leaves: 147
wandb: 	model.sklearn.reg_alpha: 0.0033884857458941807
wandb: 	model.sklearn.reg_lambda: 0.0026602606044997985
wandb: 	model.sklearn.subsample: 0.7742933516633805
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200849-h4266mro
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-72
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/h4266mro
2023-02-07 20:08:57.664 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:08:57.665 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 660 for sweep.
2023-02-07 20:08:57.665 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.004946640264464157 for sweep.
2023-02-07 20:08:57.666 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:08:57.666 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 20:08:57.666 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9486534951897064 for sweep.
2023-02-07 20:08:57.666 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 403 for sweep.
2023-02-07 20:08:57.666 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 5 for sweep.
2023-02-07 20:08:57.667 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.47990387191859024 for sweep.
2023-02-07 20:08:57.667 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 59 for sweep.
2023-02-07 20:08:57.667 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.030954602886128977 for sweep.
2023-02-07 20:08:57.667 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1973 for sweep.
2023-02-07 20:08:57.668 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 147 for sweep.
2023-02-07 20:08:57.668 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0033884857458941807 for sweep.
2023-02-07 20:08:57.668 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.0026602606044997985 for sweep.
2023-02-07 20:08:57.668 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7742933516633805 for sweep.
2023-02-07 20:08:57.668 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:08:57.673 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200849-h4266mro/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 660, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 403, 'window': 5, 'min_count': 9, 'dm': 0, 'sample': 0.9486534951897064, 'workers': 4, 'alpha': 0.004946640264464157, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1973, 'max_depth': 59, 'num_leaves': 147, 'reg_alpha': 0.0033884857458941807, 'reg_lambda': 0.0026602606044997985, 'subsample': 0.7742933516633805, 'min_child_weight': 0.030954602886128977, 'n_jobs': 4, 'learning_rate': 0.47990387191859024}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 166.85it/s]  1%|          | 36/3257 [00:00<00:18, 176.80it/s]  2%|‚ñè         | 54/3257 [00:00<00:18, 175.69it/s]  2%|‚ñè         | 73/3257 [00:00<00:17, 181.07it/s]  3%|‚ñé         | 93/3257 [00:00<00:16, 186.72it/s]  3%|‚ñé         | 112/3257 [00:00<00:18, 173.66it/s]  4%|‚ñç         | 132/3257 [00:00<00:17, 180.86it/s]  5%|‚ñç         | 153/3257 [00:00<00:16, 188.22it/s]  5%|‚ñå         | 172/3257 [00:00<00:16, 182.08it/s]  6%|‚ñå         | 192/3257 [00:01<00:16, 184.24it/s]  6%|‚ñã         | 211/3257 [00:01<00:16, 185.72it/s]  7%|‚ñã         | 235/3257 [00:01<00:15, 200.64it/s]  8%|‚ñä         | 256/3257 [00:01<00:21, 140.23it/s]  8%|‚ñä         | 275/3257 [00:01<00:19, 151.31it/s]  9%|‚ñâ         | 298/3257 [00:01<00:17, 167.93it/s] 10%|‚ñâ         | 317/3257 [00:01<00:17, 171.66it/s] 10%|‚ñà         | 337/3257 [00:01<00:16, 177.90it/s] 11%|‚ñà         | 359/3257 [00:02<00:15, 184.97it/s] 12%|‚ñà‚ñè        | 379/3257 [00:02<00:16, 174.39it/s] 12%|‚ñà‚ñè        | 398/3257 [00:02<00:17, 162.26it/s] 13%|‚ñà‚ñé        | 415/3257 [00:02<00:17, 163.22it/s] 13%|‚ñà‚ñé        | 432/3257 [00:02<00:19, 141.86it/s] 14%|‚ñà‚ñé        | 447/3257 [00:02<00:20, 138.78it/s] 14%|‚ñà‚ñç        | 465/3257 [00:02<00:19, 146.41it/s] 15%|‚ñà‚ñç        | 481/3257 [00:02<00:19, 142.16it/s] 15%|‚ñà‚ñå        | 500/3257 [00:03<00:18, 152.86it/s] 16%|‚ñà‚ñå        | 517/3257 [00:03<00:17, 154.08it/s] 16%|‚ñà‚ñã        | 533/3257 [00:03<00:17, 152.06it/s] 17%|‚ñà‚ñã        | 549/3257 [00:03<00:17, 152.01it/s] 17%|‚ñà‚ñã        | 565/3257 [00:03<00:19, 138.87it/s] 18%|‚ñà‚ñä        | 580/3257 [00:03<00:19, 134.67it/s] 18%|‚ñà‚ñä        | 597/3257 [00:03<00:18, 142.66it/s] 19%|‚ñà‚ñâ        | 613/3257 [00:03<00:18, 146.65it/s] 19%|‚ñà‚ñâ        | 628/3257 [00:03<00:18, 142.10it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:04<00:18, 144.85it/s] 20%|‚ñà‚ñà        | 659/3257 [00:04<00:19, 133.31it/s] 21%|‚ñà‚ñà        | 676/3257 [00:04<00:18, 141.91it/s] 21%|‚ñà‚ñà        | 691/3257 [00:04<00:18, 139.33it/s] 22%|‚ñà‚ñà‚ñè       | 706/3257 [00:04<00:17, 141.74it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:04<00:17, 141.46it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:04<00:18, 132.81it/s] 23%|‚ñà‚ñà‚ñé       | 750/3257 [00:04<00:18, 134.65it/s] 24%|‚ñà‚ñà‚ñé       | 768/3257 [00:04<00:16, 147.19it/s] 24%|‚ñà‚ñà‚ñç       | 783/3257 [00:05<00:18, 135.65it/s] 25%|‚ñà‚ñà‚ñç       | 799/3257 [00:05<00:17, 141.00it/s] 25%|‚ñà‚ñà‚ñç       | 814/3257 [00:05<00:17, 141.87it/s] 25%|‚ñà‚ñà‚ñå       | 829/3257 [00:05<00:18, 134.23it/s] 26%|‚ñà‚ñà‚ñå       | 843/3257 [00:05<00:18, 128.19it/s] 26%|‚ñà‚ñà‚ñã       | 858/3257 [00:05<00:18, 133.05it/s] 27%|‚ñà‚ñà‚ñã       | 872/3257 [00:05<00:18, 132.16it/s] 27%|‚ñà‚ñà‚ñã       | 886/3257 [00:05<00:18, 129.28it/s] 28%|‚ñà‚ñà‚ñä       | 903/3257 [00:05<00:16, 139.66it/s] 28%|‚ñà‚ñà‚ñä       | 918/3257 [00:06<00:17, 136.08it/s] 29%|‚ñà‚ñà‚ñä       | 933/3257 [00:06<00:16, 138.73it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:06<00:16, 143.03it/s] 30%|‚ñà‚ñà‚ñâ       | 965/3257 [00:06<00:15, 147.55it/s] 30%|‚ñà‚ñà‚ñà       | 980/3257 [00:06<00:16, 141.89it/s] 31%|‚ñà‚ñà‚ñà       | 995/3257 [00:06<00:16, 141.13it/s] 31%|‚ñà‚ñà‚ñà       | 1010/3257 [00:06<00:16, 139.60it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:06<00:16, 137.85it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:06<00:16, 132.97it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1057/3257 [00:07<00:15, 137.66it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1075/3257 [00:07<00:14, 148.87it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:07<00:15, 139.31it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1108/3257 [00:07<00:14, 146.19it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:07<00:14, 143.23it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1138/3257 [00:07<00:14, 143.08it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1153/3257 [00:07<00:15, 138.40it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:14, 146.33it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:07<00:15, 135.60it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1199/3257 [00:08<00:15, 131.50it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1213/3257 [00:08<00:16, 126.41it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:08<00:14, 142.98it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1248/3257 [00:08<00:14, 141.17it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1264/3257 [00:08<00:13, 145.66it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1279/3257 [00:08<00:14, 132.89it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1293/3257 [00:08<00:14, 132.25it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:08<00:14, 136.02it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1324/3257 [00:08<00:13, 142.25it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1341/3257 [00:09<00:12, 148.13it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1356/3257 [00:09<00:13, 139.91it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1371/3257 [00:09<00:13, 140.30it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:09<00:13, 136.25it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1403/3257 [00:09<00:12, 144.92it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:09<00:11, 154.27it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:09<00:11, 153.47it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1459/3257 [00:09<00:10, 165.33it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1476/3257 [00:09<00:11, 160.30it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1494/3257 [00:10<00:10, 162.75it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1512/3257 [00:10<00:10, 164.47it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1529/3257 [00:10<00:11, 148.87it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1545/3257 [00:10<00:12, 139.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1560/3257 [00:10<00:11, 141.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1577/3257 [00:10<00:11, 147.95it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1598/3257 [00:10<00:10, 163.36it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:11<00:14, 112.98it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1636/3257 [00:11<00:13, 124.28it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:11<00:11, 136.74it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1671/3257 [00:11<00:11, 141.45it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:11<00:10, 150.68it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1711/3257 [00:11<00:09, 165.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:11<00:09, 157.64it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1746/3257 [00:11<00:09, 156.81it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1764/3257 [00:11<00:09, 161.78it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1784/3257 [00:11<00:08, 171.74it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:12<00:08, 172.48it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:12<00:08, 168.68it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1839/3257 [00:12<00:08, 165.95it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1857/3257 [00:12<00:08, 169.28it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1876/3257 [00:12<00:07, 175.03it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1894/3257 [00:12<00:08, 168.26it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:12<00:07, 171.88it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1935/3257 [00:12<00:07, 175.10it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1958/3257 [00:12<00:06, 189.05it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1978/3257 [00:13<00:07, 178.18it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1997/3257 [00:13<00:07, 177.98it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2015/3257 [00:13<00:07, 175.11it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2034/3257 [00:13<00:06, 175.51it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:13<00:07, 160.85it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2069/3257 [00:13<00:07, 156.56it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:13<00:07, 156.45it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2101/3257 [00:13<00:07, 156.56it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:13<00:07, 157.13it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:14<00:07, 155.50it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2152/3257 [00:14<00:07, 153.93it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:14<00:06, 158.07it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:14<00:06, 156.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:14<00:06, 165.74it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2221/3257 [00:14<00:06, 164.17it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:14<00:06, 159.35it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2256/3257 [00:14<00:06, 162.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2273/3257 [00:14<00:06, 152.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2296/3257 [00:15<00:05, 170.87it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2314/3257 [00:15<00:05, 167.21it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2336/3257 [00:15<00:05, 180.84it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:15<00:04, 188.36it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2380/3257 [00:15<00:04, 191.26it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2401/3257 [00:15<00:04, 195.29it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2421/3257 [00:15<00:04, 182.37it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:15<00:04, 174.33it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2458/3257 [00:15<00:04, 172.59it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2478/3257 [00:16<00:04, 179.92it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2500/3257 [00:16<00:03, 190.19it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2520/3257 [00:16<00:03, 190.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:16<00:03, 189.27it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2560/3257 [00:16<00:03, 182.22it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2579/3257 [00:16<00:04, 168.57it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2598/3257 [00:16<00:03, 172.95it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2624/3257 [00:16<00:03, 195.31it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2644/3257 [00:16<00:03, 189.01it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2664/3257 [00:17<00:03, 180.61it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2684/3257 [00:17<00:03, 185.59it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2703/3257 [00:17<00:03, 167.15it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2721/3257 [00:17<00:03, 166.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2745/3257 [00:17<00:02, 186.26it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2765/3257 [00:17<00:02, 182.83it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2784/3257 [00:17<00:02, 179.87it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2805/3257 [00:17<00:02, 186.81it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2824/3257 [00:17<00:02, 169.95it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:18<00:02, 168.96it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2866/3257 [00:18<00:02, 188.21it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:18<00:01, 190.64it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:18<00:01, 176.39it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:18<00:01, 181.89it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:18<00:01, 174.25it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2967/3257 [00:18<00:01, 177.20it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:18<00:01, 169.11it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3008/3257 [00:18<00:01, 182.48it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3027/3257 [00:19<00:02, 101.84it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3049/3257 [00:19<00:01, 121.36it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3074/3257 [00:19<00:01, 147.08it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3093/3257 [00:19<00:01, 153.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3116/3257 [00:19<00:00, 170.42it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3136/3257 [00:19<00:00, 171.35it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3155/3257 [00:20<00:00, 170.26it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3175/3257 [00:20<00:00, 175.54it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3194/3257 [00:20<00:00, 176.06it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:20<00:00, 168.83it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3236/3257 [00:20<00:00, 184.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3255/3257 [00:20<00:00, 185.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 158.19it/s]
2023-02-07 20:09:19.145 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:09:19,146][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d403,n5,mc9,s0.948653,t4>', 'datetime': '2023-02-07T20:09:19.146384', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:09:19,146][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:09:19,146][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:09:19,755][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:09:19,755][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:09:19,805][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 14828 unique words (34.73% of original 42701, drops 27873)', 'datetime': '2023-02-07T20:09:19.805165', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:09:19,805][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 5723647 word corpus (98.29% of original 5822992, drops 99345)', 'datetime': '2023-02-07T20:09:19.805592', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:09:19,859][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:09:19,860][gensim.models.word2vec][INFO] - sample=0.948653 downsamples 0 most-common words
[2023-02-07 20:09:19,861][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5723647 word corpus (100.0%% of prior 5723647)', 'datetime': '2023-02-07T20:09:19.861050', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:09:19,955][gensim.models.word2vec][INFO] - estimated required memory for 14828 words and 403 dimensions: 61121156 bytes
[2023-02-07 20:09:19,955][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:09:19,990][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14828 vocabulary and 403 features, using sg=1 hs=0 sample=0.9486534951897064 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-07T20:09:19.989992', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:09:20,995][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 26.87% examples, 1539663 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:21,998][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 53.58% examples, 1563966 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:22,999][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 82.68% examples, 1578971 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:23,581][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5697932 effective words) took 3.6s, 1588184 effective words/s
[2023-02-07 20:09:24,584][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 30.70% examples, 1758758 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:09:25,590][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 60.39% examples, 1742265 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:26,590][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 91.19% examples, 1739745 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:09:26,860][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5697932 effective words) took 3.3s, 1739567 effective words/s
[2023-02-07 20:09:27,866][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 37.58% examples, 2185580 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:28,867][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 74.52% examples, 2145860 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:29,560][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5697932 effective words) took 2.7s, 2111338 effective words/s
[2023-02-07 20:09:30,568][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 34.45% examples, 1978092 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:31,573][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 68.65% examples, 1986019 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:32,433][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5697932 effective words) took 2.9s, 1984870 effective words/s
[2023-02-07 20:09:33,442][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 34.45% examples, 1974385 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:34,448][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 68.65% examples, 1983567 words/s, in_qsize 6, out_qsize 2
[2023-02-07 20:09:35,282][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5697932 effective words) took 2.8s, 2001265 effective words/s
[2023-02-07 20:09:36,290][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 35.71% examples, 2051539 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:37,292][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 71.51% examples, 2069331 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:38,159][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5697932 effective words) took 2.9s, 1982699 effective words/s
[2023-02-07 20:09:39,162][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 30.92% examples, 1776081 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:40,163][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 61.71% examples, 1784811 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:41,169][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 93.74% examples, 1783997 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:09:41,345][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5697932 effective words) took 3.2s, 1789679 effective words/s
[2023-02-07 20:09:42,352][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 30.92% examples, 1769653 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:43,356][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 62.36% examples, 1792509 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:44,368][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 94.53% examples, 1787984 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:09:44,526][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5697932 effective words) took 3.2s, 1792543 effective words/s
[2023-02-07 20:09:45,532][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 31.50% examples, 1801904 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:46,535][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 68.22% examples, 1978100 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:47,304][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5697932 effective words) took 2.8s, 2053589 effective words/s
[2023-02-07 20:09:48,306][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 35.92% examples, 2077449 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:49,310][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 71.51% examples, 2071598 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:50,065][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5697932 effective words) took 2.8s, 2064994 effective words/s
[2023-02-07 20:09:51,067][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 35.49% examples, 2052458 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:52,068][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 70.62% examples, 2056333 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:52,828][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5697932 effective words) took 2.8s, 2063794 effective words/s
[2023-02-07 20:09:53,832][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 35.71% examples, 2055971 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:54,836][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 72.21% examples, 2082807 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:55,540][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5697932 effective words) took 2.7s, 2102117 effective words/s
[2023-02-07 20:09:56,544][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 32.36% examples, 1864013 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:09:57,553][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 64.17% examples, 1849602 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:58,562][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 97.11% examples, 1835023 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:09:58,642][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5697932 effective words) took 3.1s, 1838077 effective words/s
[2023-02-07 20:09:59,649][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 31.81% examples, 1826109 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:10:00,649][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 63.00% examples, 1821911 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:01,651][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 95.98% examples, 1819818 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:10:01,768][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5697932 effective words) took 3.1s, 1824601 effective words/s
[2023-02-07 20:10:02,771][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 31.93% examples, 1837686 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:03,774][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 63.37% examples, 1834877 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:04,775][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 99.75% examples, 1893138 words/s, in_qsize 0, out_qsize 3
[2023-02-07 20:10:04,775][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5697932 effective words) took 3.0s, 1896050 effective words/s
[2023-02-07 20:10:04,775][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85468980 effective words) took 44.8s, 1908460 effective words/s', 'datetime': '2023-02-07T20:10:04.775704', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:10:04.776 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:10:08,429][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200849-h4266mro/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:10:08.429530', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:10:08,430][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:10:08,504][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_200849-h4266mro/files/../tmp/embedding_model.pt
2023-02-07 20:10:08.505 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:10:10.734 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:10:11.497 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:10:14.160 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0081189814067926, 'test_mae': 0.7621825794957898, 'test_r2': -1.9634988153300523}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.79
wandb: percentage 0.65275
wandb:   test_mae 0.76218
wandb:   test_mse 1.00812
wandb:    test_r2 -1.9635
wandb: 
wandb: üöÄ View run celestial-sweep-72 at: https://wandb.ai/xiaoqiz/mof2vec/runs/h4266mro
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_200849-h4266mro/logs
wandb: Agent Starting Run: sbeiggov with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 739
wandb: 	model.gensim.alpha: 0.02023339369199638
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.7692171327270085
wandb: 	model.gensim.vector_size: 331
wandb: 	model.gensim.window: 16
wandb: 	model.sklearn.learning_rate: 0.0029020687370719476
wandb: 	model.sklearn.max_depth: 91
wandb: 	model.sklearn.min_child_weight: 0.004546987634689533
wandb: 	model.sklearn.n_estimators: 1587
wandb: 	model.sklearn.num_leaves: 343
wandb: 	model.sklearn.reg_alpha: 0.02646852264687326
wandb: 	model.sklearn.reg_lambda: 0.052475247987918104
wandb: 	model.sklearn.subsample: 0.9080861951551792
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201030-sbeiggov
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-73
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/sbeiggov
2023-02-07 20:10:38.638 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 20:10:38.639 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 739 for sweep.
2023-02-07 20:10:38.639 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.02023339369199638 for sweep.
2023-02-07 20:10:38.639 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:10:38.640 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 20:10:38.640 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7692171327270085 for sweep.
2023-02-07 20:10:38.640 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 331 for sweep.
2023-02-07 20:10:38.640 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 16 for sweep.
2023-02-07 20:10:38.641 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0029020687370719476 for sweep.
2023-02-07 20:10:38.641 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 91 for sweep.
2023-02-07 20:10:38.642 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.004546987634689533 for sweep.
2023-02-07 20:10:38.642 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1587 for sweep.
2023-02-07 20:10:38.642 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 343 for sweep.
2023-02-07 20:10:38.642 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.02646852264687326 for sweep.
2023-02-07 20:10:38.643 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.052475247987918104 for sweep.
2023-02-07 20:10:38.643 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9080861951551792 for sweep.
2023-02-07 20:10:38.643 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:10:38.650 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201030-sbeiggov/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 739, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 331, 'window': 16, 'min_count': 8, 'dm': 0, 'sample': 0.7692171327270085, 'workers': 4, 'alpha': 0.02023339369199638, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1587, 'max_depth': 91, 'num_leaves': 343, 'reg_alpha': 0.02646852264687326, 'reg_lambda': 0.052475247987918104, 'subsample': 0.9080861951551792, 'min_child_weight': 0.004546987634689533, 'n_jobs': 4, 'learning_rate': 0.0029020687370719476}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 169.58it/s]  1%|          | 36/3257 [00:00<00:18, 177.24it/s]  2%|‚ñè         | 54/3257 [00:00<00:18, 176.47it/s]  2%|‚ñè         | 79/3257 [00:00<00:15, 203.12it/s]  3%|‚ñé         | 104/3257 [00:00<00:14, 216.63it/s]  4%|‚ñç         | 126/3257 [00:00<00:15, 207.50it/s]  5%|‚ñç         | 151/3257 [00:00<00:14, 218.03it/s]  5%|‚ñå         | 173/3257 [00:00<00:14, 215.22it/s]  6%|‚ñå         | 199/3257 [00:00<00:13, 228.38it/s]  7%|‚ñã         | 228/3257 [00:01<00:12, 246.11it/s]  8%|‚ñä         | 253/3257 [00:01<00:12, 242.17it/s]  9%|‚ñä         | 281/3257 [00:01<00:11, 252.87it/s]  9%|‚ñâ         | 307/3257 [00:01<00:11, 246.96it/s] 10%|‚ñà         | 332/3257 [00:01<00:11, 246.33it/s] 11%|‚ñà         | 357/3257 [00:01<00:11, 245.48it/s] 12%|‚ñà‚ñè        | 382/3257 [00:01<00:12, 229.67it/s] 12%|‚ñà‚ñè        | 406/3257 [00:01<00:12, 225.33it/s] 13%|‚ñà‚ñé        | 429/3257 [00:01<00:13, 206.29it/s] 14%|‚ñà‚ñç        | 450/3257 [00:02<00:13, 205.24it/s] 15%|‚ñà‚ñç        | 474/3257 [00:02<00:12, 214.12it/s] 15%|‚ñà‚ñå        | 498/3257 [00:02<00:12, 218.86it/s] 16%|‚ñà‚ñå        | 522/3257 [00:02<00:12, 217.62it/s] 17%|‚ñà‚ñã        | 546/3257 [00:02<00:12, 219.19it/s] 17%|‚ñà‚ñã        | 569/3257 [00:02<00:12, 207.87it/s] 18%|‚ñà‚ñä        | 590/3257 [00:02<00:13, 200.06it/s] 19%|‚ñà‚ñâ        | 615/3257 [00:02<00:12, 213.34it/s] 20%|‚ñà‚ñâ        | 637/3257 [00:02<00:12, 211.22it/s] 20%|‚ñà‚ñà        | 659/3257 [00:03<00:13, 194.21it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:13, 196.32it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:03<00:12, 198.68it/s] 22%|‚ñà‚ñà‚ñè       | 725/3257 [00:03<00:12, 197.69it/s] 23%|‚ñà‚ñà‚ñé       | 745/3257 [00:03<00:12, 195.67it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:03<00:12, 205.03it/s] 24%|‚ñà‚ñà‚ñç       | 791/3257 [00:03<00:12, 196.98it/s] 25%|‚ñà‚ñà‚ñç       | 812/3257 [00:03<00:12, 200.06it/s] 26%|‚ñà‚ñà‚ñå       | 833/3257 [00:03<00:12, 194.29it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:04<00:12, 186.71it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:04<00:12, 193.72it/s] 27%|‚ñà‚ñà‚ñã       | 895/3257 [00:04<00:12, 192.47it/s] 28%|‚ñà‚ñà‚ñä       | 916/3257 [00:04<00:11, 195.98it/s] 29%|‚ñà‚ñà‚ñâ       | 938/3257 [00:04<00:11, 200.68it/s] 29%|‚ñà‚ñà‚ñâ       | 960/3257 [00:04<00:11, 205.07it/s] 30%|‚ñà‚ñà‚ñà       | 981/3257 [00:04<00:11, 199.59it/s] 31%|‚ñà‚ñà‚ñà       | 1002/3257 [00:04<00:17, 131.51it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:05<00:14, 148.80it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1043/3257 [00:05<00:14, 150.31it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1064/3257 [00:05<00:13, 163.02it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1083/3257 [00:05<00:12, 169.06it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1104/3257 [00:05<00:11, 179.49it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:05<00:11, 182.12it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1143/3257 [00:05<00:11, 183.72it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1165/3257 [00:05<00:10, 192.44it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:05<00:11, 180.80it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:06<00:11, 173.82it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1226/3257 [00:06<00:10, 185.47it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1246/3257 [00:06<00:10, 189.41it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1269/3257 [00:06<00:09, 199.15it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:06<00:11, 178.74it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1310/3257 [00:06<00:10, 183.53it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1331/3257 [00:06<00:10, 189.43it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1351/3257 [00:06<00:10, 187.72it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1371/3257 [00:06<00:10, 185.23it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1390/3257 [00:07<00:10, 183.50it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1417/3257 [00:07<00:08, 206.99it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1438/3257 [00:07<00:08, 203.79it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1464/3257 [00:07<00:08, 219.71it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1487/3257 [00:07<00:08, 216.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:07<00:07, 226.80it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1536/3257 [00:07<00:08, 208.03it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1558/3257 [00:07<00:08, 203.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1579/3257 [00:07<00:08, 202.31it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1603/3257 [00:08<00:07, 211.45it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1625/3257 [00:08<00:07, 209.70it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1647/3257 [00:08<00:07, 201.60it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:08<00:07, 200.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1689/3257 [00:08<00:07, 201.64it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1713/3257 [00:08<00:07, 209.86it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1735/3257 [00:08<00:08, 182.20it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1754/3257 [00:08<00:08, 183.72it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1773/3257 [00:08<00:08, 184.00it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:09<00:07, 184.80it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1811/3257 [00:09<00:08, 172.12it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1829/3257 [00:09<00:08, 170.17it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1848/3257 [00:09<00:08, 172.88it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:09<00:07, 176.91it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1887/3257 [00:09<00:07, 173.96it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1906/3257 [00:09<00:07, 177.92it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1924/3257 [00:09<00:07, 171.64it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1948/3257 [00:09<00:06, 190.25it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1971/3257 [00:09<00:06, 198.97it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1992/3257 [00:10<00:06, 187.78it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2011/3257 [00:10<00:06, 181.35it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2032/3257 [00:10<00:06, 186.59it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2051/3257 [00:10<00:07, 167.85it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2069/3257 [00:10<00:07, 164.50it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2087/3257 [00:10<00:07, 166.97it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2104/3257 [00:10<00:06, 165.46it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:10<00:07, 158.91it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2139/3257 [00:11<00:06, 163.79it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2156/3257 [00:11<00:06, 161.80it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2177/3257 [00:11<00:06, 172.64it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2195/3257 [00:11<00:06, 172.43it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2213/3257 [00:11<00:06, 162.68it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2230/3257 [00:11<00:10, 94.91it/s]  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2245/3257 [00:11<00:09, 104.37it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2262/3257 [00:12<00:08, 117.54it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2277/3257 [00:12<00:07, 122.89it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2297/3257 [00:12<00:06, 141.61it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:12<00:06, 147.47it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:12<00:05, 165.03it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:12<00:04, 179.41it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2379/3257 [00:12<00:04, 181.37it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2400/3257 [00:12<00:04, 187.43it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2420/3257 [00:12<00:04, 176.36it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2439/3257 [00:13<00:04, 170.93it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2457/3257 [00:13<00:04, 168.86it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2477/3257 [00:13<00:04, 175.92it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2496/3257 [00:13<00:04, 178.19it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2516/3257 [00:13<00:04, 183.32it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2536/3257 [00:13<00:03, 186.71it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2555/3257 [00:13<00:03, 176.96it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:13<00:03, 171.06it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2591/3257 [00:13<00:04, 166.36it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2615/3257 [00:14<00:03, 186.55it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2636/3257 [00:14<00:03, 191.65it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:14<00:03, 183.75it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2675/3257 [00:14<00:03, 180.43it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:14<00:03, 175.11it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2712/3257 [00:14<00:03, 160.92it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2730/3257 [00:14<00:03, 165.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2751/3257 [00:14<00:02, 173.76it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2769/3257 [00:14<00:02, 166.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2791/3257 [00:15<00:02, 176.48it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2809/3257 [00:15<00:02, 175.63it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2827/3257 [00:15<00:02, 169.60it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2845/3257 [00:15<00:02, 166.99it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2869/3257 [00:15<00:02, 186.36it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2888/3257 [00:15<00:01, 186.68it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:15<00:01, 177.41it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:15<00:01, 183.29it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:15<00:01, 177.98it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:16<00:01, 180.22it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:16<00:01, 170.85it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3006/3257 [00:16<00:01, 180.37it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3025/3257 [00:16<00:01, 175.00it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3047/3257 [00:16<00:01, 184.80it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3068/3257 [00:16<00:00, 190.28it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3088/3257 [00:16<00:00, 184.76it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:16<00:00, 193.57it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3130/3257 [00:16<00:00, 194.01it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3150/3257 [00:16<00:00, 187.82it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3174/3257 [00:17<00:00, 201.77it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3197/3257 [00:17<00:00, 207.90it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3218/3257 [00:17<00:00, 207.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:17<00:00, 220.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 186.64it/s]
2023-02-07 20:10:56.620 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:10:56,621][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d331,n5,mc8,s0.769217,t4>', 'datetime': '2023-02-07T20:10:56.621023', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:10:56,621][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:10:56,621][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:10:56,966][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 20:10:56,966][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:10:56,993][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 9584 unique words (44.17% of original 21699, drops 12115)', 'datetime': '2023-02-07T20:10:56.993425', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:10:56,993][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 4331919 word corpus (99.19% of original 4367244, drops 35325)', 'datetime': '2023-02-07T20:10:56.993636', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:10:57,023][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 20:10:57,024][gensim.models.word2vec][INFO] - sample=0.769217 downsamples 0 most-common words
[2023-02-07 20:10:57,024][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4331919 word corpus (100.0%% of prior 4331919)', 'datetime': '2023-02-07T20:10:57.024265', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:10:57,076][gensim.models.word2vec][INFO] - estimated required memory for 9584 words and 331 dimensions: 35134100 bytes
[2023-02-07 20:10:57,077][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:10:57,093][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 9584 vocabulary and 331 features, using sg=1 hs=0 sample=0.7692171327270085 negative=5 window=16 shrink_windows=True', 'datetime': '2023-02-07T20:10:57.093959', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:10:58,100][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 58.03% examples, 2563809 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:10:58,781][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4333519 effective words) took 1.7s, 2572316 effective words/s
[2023-02-07 20:10:59,793][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 58.03% examples, 2549461 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:00,501][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4333519 effective words) took 1.7s, 2522290 effective words/s
[2023-02-07 20:11:01,506][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 55.60% examples, 2465717 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:02,278][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4333519 effective words) took 1.8s, 2441691 effective words/s
[2023-02-07 20:11:03,281][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 56.83% examples, 2520306 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:03,999][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4333519 effective words) took 1.7s, 2520792 effective words/s
[2023-02-07 20:11:05,001][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 57.51% examples, 2548393 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:05,686][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4333519 effective words) took 1.7s, 2569680 effective words/s
[2023-02-07 20:11:06,688][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 59.04% examples, 2619333 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:07,332][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4333519 effective words) took 1.6s, 2636067 effective words/s
[2023-02-07 20:11:08,334][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 58.21% examples, 2579622 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:09,001][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4333519 effective words) took 1.7s, 2598673 effective words/s
[2023-02-07 20:11:10,010][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 59.96% examples, 2627384 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:10,642][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4333519 effective words) took 1.6s, 2642042 effective words/s
[2023-02-07 20:11:11,651][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 60.02% examples, 2630758 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:12,298][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4333519 effective words) took 1.7s, 2620350 effective words/s
[2023-02-07 20:11:13,303][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 58.03% examples, 2564057 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:13,972][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4333519 effective words) took 1.7s, 2591217 effective words/s
[2023-02-07 20:11:14,975][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 58.03% examples, 2571495 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:15,659][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4333519 effective words) took 1.7s, 2571293 effective words/s
[2023-02-07 20:11:16,668][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 58.03% examples, 2554897 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:11:17,334][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4333519 effective words) took 1.7s, 2588046 effective words/s
[2023-02-07 20:11:18,344][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 57.32% examples, 2522314 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:19,033][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4333519 effective words) took 1.7s, 2553746 effective words/s
[2023-02-07 20:11:20,036][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 58.86% examples, 2607368 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:20,702][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4333519 effective words) took 1.7s, 2598742 effective words/s
[2023-02-07 20:11:21,709][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 57.32% examples, 2527551 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:11:22,409][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4333519 effective words) took 1.7s, 2541763 effective words/s
[2023-02-07 20:11:22,410][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65002785 effective words) took 25.3s, 2567641 effective words/s', 'datetime': '2023-02-07T20:11:22.410449', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:11:22.410 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:11:24,540][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201030-sbeiggov/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:11:24.540599', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:11:24,541][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:11:24,586][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201030-sbeiggov/files/../tmp/embedding_model.pt
2023-02-07 20:11:24.586 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:11:26.469 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:11:27.200 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:11:29.432 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9523258539311089, 'test_mae': 0.7322989457681135, 'test_r2': -2.124376489362236}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.9
wandb: percentage 0.55832
wandb:   test_mae 0.7323
wandb:   test_mse 0.95233
wandb:    test_r2 -2.12438
wandb: 
wandb: üöÄ View run olive-sweep-73 at: https://wandb.ai/xiaoqiz/mof2vec/runs/sbeiggov
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_201030-sbeiggov/logs
wandb: Agent Starting Run: hm9ccpf6 with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 623
wandb: 	model.gensim.alpha: 0.019556106509726376
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.4076621838704359
wandb: 	model.gensim.vector_size: 351
wandb: 	model.gensim.window: 17
wandb: 	model.sklearn.learning_rate: 0.0011810229992010423
wandb: 	model.sklearn.max_depth: 56
wandb: 	model.sklearn.min_child_weight: 0.02369043684838962
wandb: 	model.sklearn.n_estimators: 53
wandb: 	model.sklearn.num_leaves: 311
wandb: 	model.sklearn.reg_alpha: 0.05523548044439065
wandb: 	model.sklearn.reg_lambda: 0.22127474329349725
wandb: 	model.sklearn.subsample: 0.890079134676139
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201143-hm9ccpf6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-74
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/hm9ccpf6
2023-02-07 20:11:51.866 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:11:51.866 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 623 for sweep.
2023-02-07 20:11:51.867 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.019556106509726376 for sweep.
2023-02-07 20:11:51.867 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:11:51.867 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 20:11:51.867 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4076621838704359 for sweep.
2023-02-07 20:11:51.868 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 351 for sweep.
2023-02-07 20:11:51.868 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 17 for sweep.
2023-02-07 20:11:51.868 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0011810229992010423 for sweep.
2023-02-07 20:11:51.868 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 56 for sweep.
2023-02-07 20:11:51.869 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.02369043684838962 for sweep.
2023-02-07 20:11:51.869 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 53 for sweep.
2023-02-07 20:11:51.869 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 311 for sweep.
2023-02-07 20:11:51.869 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.05523548044439065 for sweep.
2023-02-07 20:11:51.869 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.22127474329349725 for sweep.
2023-02-07 20:11:51.870 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.890079134676139 for sweep.
2023-02-07 20:11:51.870 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:11:51.876 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201143-hm9ccpf6/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 623, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 351, 'window': 17, 'min_count': 5, 'dm': 0, 'sample': 0.4076621838704359, 'workers': 4, 'alpha': 0.019556106509726376, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 53, 'max_depth': 56, 'num_leaves': 311, 'reg_alpha': 0.05523548044439065, 'reg_lambda': 0.22127474329349725, 'subsample': 0.890079134676139, 'min_child_weight': 0.02369043684838962, 'n_jobs': 4, 'learning_rate': 0.0011810229992010423}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:22, 141.82it/s]  1%|          | 33/3257 [00:00<00:20, 158.51it/s]  2%|‚ñè         | 49/3257 [00:00<00:20, 158.51it/s]  2%|‚ñè         | 66/3257 [00:00<00:19, 161.39it/s]  3%|‚ñé         | 83/3257 [00:00<00:19, 162.63it/s]  3%|‚ñé         | 100/3257 [00:00<00:19, 162.45it/s]  4%|‚ñé         | 117/3257 [00:00<00:20, 156.02it/s]  4%|‚ñç         | 134/3257 [00:00<00:19, 159.81it/s]  5%|‚ñç         | 154/3257 [00:00<00:18, 169.47it/s]  5%|‚ñå         | 171/3257 [00:01<00:20, 153.43it/s]  6%|‚ñå         | 187/3257 [00:01<00:20, 148.24it/s]  6%|‚ñå         | 203/3257 [00:01<00:21, 142.07it/s]  7%|‚ñã         | 219/3257 [00:01<00:20, 146.88it/s]  7%|‚ñã         | 237/3257 [00:01<00:20, 150.16it/s]  8%|‚ñä         | 253/3257 [00:01<00:20, 147.52it/s]  8%|‚ñä         | 268/3257 [00:01<00:21, 142.32it/s]  9%|‚ñâ         | 287/3257 [00:01<00:19, 153.96it/s]  9%|‚ñâ         | 303/3257 [00:01<00:19, 149.11it/s] 10%|‚ñâ         | 319/3257 [00:02<00:19, 147.73it/s] 10%|‚ñà         | 334/3257 [00:02<00:19, 147.90it/s] 11%|‚ñà         | 349/3257 [00:02<00:20, 140.67it/s] 11%|‚ñà         | 365/3257 [00:02<00:20, 143.86it/s] 12%|‚ñà‚ñè        | 380/3257 [00:02<00:21, 136.33it/s] 12%|‚ñà‚ñè        | 395/3257 [00:02<00:20, 139.37it/s] 13%|‚ñà‚ñé        | 412/3257 [00:02<00:19, 145.47it/s] 13%|‚ñà‚ñé        | 427/3257 [00:03<00:32, 88.35it/s]  14%|‚ñà‚ñé        | 440/3257 [00:03<00:29, 95.67it/s] 14%|‚ñà‚ñç        | 457/3257 [00:03<00:25, 111.01it/s] 15%|‚ñà‚ñç        | 473/3257 [00:03<00:22, 121.77it/s] 15%|‚ñà‚ñç        | 487/3257 [00:03<00:22, 124.12it/s] 16%|‚ñà‚ñå        | 505/3257 [00:03<00:19, 138.23it/s] 16%|‚ñà‚ñå        | 522/3257 [00:03<00:19, 141.82it/s] 16%|‚ñà‚ñã        | 537/3257 [00:03<00:19, 141.75it/s] 17%|‚ñà‚ñã        | 552/3257 [00:03<00:19, 141.95it/s] 17%|‚ñà‚ñã        | 567/3257 [00:04<00:20, 129.63it/s] 18%|‚ñà‚ñä        | 581/3257 [00:04<00:21, 126.32it/s] 18%|‚ñà‚ñä        | 601/3257 [00:04<00:18, 144.69it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:04<00:17, 150.39it/s] 20%|‚ñà‚ñâ        | 640/3257 [00:04<00:16, 161.57it/s] 20%|‚ñà‚ñà        | 657/3257 [00:04<00:17, 150.07it/s] 21%|‚ñà‚ñà        | 677/3257 [00:04<00:16, 160.85it/s] 21%|‚ñà‚ñà‚ñè       | 694/3257 [00:04<00:15, 161.12it/s] 22%|‚ñà‚ñà‚ñè       | 713/3257 [00:04<00:15, 167.03it/s] 22%|‚ñà‚ñà‚ñè       | 730/3257 [00:05<00:15, 160.23it/s] 23%|‚ñà‚ñà‚ñé       | 747/3257 [00:05<00:15, 158.80it/s] 24%|‚ñà‚ñà‚ñé       | 767/3257 [00:05<00:14, 169.12it/s] 24%|‚ñà‚ñà‚ñç       | 785/3257 [00:05<00:15, 156.03it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:15, 160.46it/s] 25%|‚ñà‚ñà‚ñå       | 821/3257 [00:05<00:15, 156.90it/s] 26%|‚ñà‚ñà‚ñå       | 837/3257 [00:05<00:15, 152.48it/s] 26%|‚ñà‚ñà‚ñå       | 853/3257 [00:05<00:16, 146.96it/s] 27%|‚ñà‚ñà‚ñã       | 870/3257 [00:05<00:15, 152.60it/s] 27%|‚ñà‚ñà‚ñã       | 886/3257 [00:06<00:15, 152.71it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:06<00:14, 161.97it/s] 28%|‚ñà‚ñà‚ñä       | 922/3257 [00:06<00:14, 164.03it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:06<00:14, 161.28it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:06<00:13, 168.98it/s] 30%|‚ñà‚ñà‚ñâ       | 977/3257 [00:06<00:13, 169.81it/s] 31%|‚ñà‚ñà‚ñà       | 995/3257 [00:06<00:14, 155.89it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:06<00:14, 156.26it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:06<00:14, 154.95it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1043/3257 [00:07<00:14, 151.77it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1061/3257 [00:07<00:14, 156.78it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:13, 161.90it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:07<00:14, 151.99it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1113/3257 [00:07<00:14, 153.12it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1129/3257 [00:07<00:15, 138.32it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:07<00:15, 137.21it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1158/3257 [00:07<00:15, 135.80it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:07<00:15, 138.23it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:08<00:16, 129.15it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1201/3257 [00:08<00:17, 119.57it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1215/3257 [00:08<00:16, 123.85it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:08<00:14, 136.29it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:08<00:15, 132.88it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1261/3257 [00:08<00:14, 134.15it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:08<00:15, 128.66it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:08<00:16, 120.96it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1302/3257 [00:09<00:15, 124.77it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1317/3257 [00:09<00:14, 131.12it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1331/3257 [00:09<00:14, 130.80it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:09<00:14, 135.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1360/3257 [00:09<00:14, 131.89it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1374/3257 [00:09<00:14, 126.45it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1387/3257 [00:09<00:14, 124.69it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:09<00:14, 130.21it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:09<00:12, 145.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1437/3257 [00:09<00:12, 142.57it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:10<00:12, 143.51it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1469/3257 [00:10<00:11, 150.27it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1485/3257 [00:10<00:12, 142.20it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1502/3257 [00:10<00:11, 149.39it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1518/3257 [00:10<00:11, 147.33it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1533/3257 [00:10<00:12, 142.75it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1548/3257 [00:10<00:11, 143.86it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1565/3257 [00:10<00:11, 151.19it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1581/3257 [00:10<00:10, 152.74it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1602/3257 [00:11<00:09, 166.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1621/3257 [00:11<00:09, 171.03it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:11<00:09, 171.91it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:11<00:09, 169.48it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:11<00:09, 168.16it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:11<00:09, 164.34it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:11<00:14, 103.57it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:12<00:13, 115.51it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1742/3257 [00:12<00:12, 119.72it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:12<00:10, 138.10it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1782/3257 [00:12<00:09, 150.75it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1799/3257 [00:12<00:09, 154.76it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1816/3257 [00:12<00:09, 153.09it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1833/3257 [00:12<00:09, 153.95it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1852/3257 [00:12<00:08, 162.14it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1871/3257 [00:12<00:08, 169.33it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1889/3257 [00:12<00:08, 169.67it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1908/3257 [00:13<00:07, 172.53it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1926/3257 [00:13<00:08, 165.53it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1950/3257 [00:13<00:07, 185.22it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1971/3257 [00:13<00:06, 187.62it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1990/3257 [00:13<00:07, 165.53it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:13<00:07, 156.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2025/3257 [00:13<00:07, 154.11it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2041/3257 [00:13<00:08, 142.52it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2056/3257 [00:14<00:08, 136.68it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2070/3257 [00:14<00:08, 135.55it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:14<00:08, 137.53it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2099/3257 [00:14<00:08, 133.73it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:14<00:08, 142.09it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:14<00:08, 132.10it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2146/3257 [00:14<00:08, 129.37it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2162/3257 [00:14<00:08, 135.94it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:14<00:07, 139.78it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2193/3257 [00:15<00:07, 139.89it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2208/3257 [00:15<00:07, 138.98it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2224/3257 [00:15<00:07, 139.35it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:15<00:07, 136.90it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2253/3257 [00:15<00:07, 140.29it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2268/3257 [00:15<00:07, 134.88it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2282/3257 [00:15<00:07, 130.98it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2298/3257 [00:15<00:06, 137.81it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2312/3257 [00:15<00:06, 135.83it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2332/3257 [00:16<00:06, 153.42it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2352/3257 [00:16<00:05, 165.13it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2369/3257 [00:16<00:05, 159.76it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2386/3257 [00:16<00:05, 160.85it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:16<00:05, 164.26it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2421/3257 [00:16<00:05, 153.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2437/3257 [00:16<00:05, 144.29it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2454/3257 [00:16<00:05, 150.51it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:16<00:04, 167.25it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2496/3257 [00:17<00:04, 174.79it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2518/3257 [00:17<00:03, 186.32it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2539/3257 [00:17<00:03, 192.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2559/3257 [00:17<00:03, 177.37it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2578/3257 [00:17<00:03, 172.93it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2596/3257 [00:17<00:03, 174.77it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2619/3257 [00:17<00:03, 190.13it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2639/3257 [00:17<00:03, 192.49it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2659/3257 [00:17<00:03, 174.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2680/3257 [00:18<00:03, 182.20it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2699/3257 [00:18<00:03, 167.75it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2717/3257 [00:18<00:03, 160.73it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2740/3257 [00:18<00:02, 178.12it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2759/3257 [00:18<00:02, 178.63it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2778/3257 [00:18<00:02, 169.74it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2800/3257 [00:18<00:02, 180.76it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2819/3257 [00:18<00:02, 171.39it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:18<00:02, 165.87it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2861/3257 [00:19<00:02, 184.42it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:19<00:01, 193.16it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:19<00:01, 181.08it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2927/3257 [00:19<00:01, 187.85it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:19<00:01, 158.35it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2964/3257 [00:19<00:01, 155.42it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2981/3257 [00:19<00:01, 143.15it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2998/3257 [00:19<00:01, 148.81it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3014/3257 [00:20<00:01, 148.85it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3030/3257 [00:20<00:01, 147.63it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3047/3257 [00:20<00:01, 153.04it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3066/3257 [00:20<00:01, 161.88it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3083/3257 [00:20<00:01, 161.67it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3100/3257 [00:20<00:01, 155.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:20<00:00, 160.53it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3135/3257 [00:21<00:01, 76.76it/s]  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3150/3257 [00:21<00:01, 87.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:21<00:00, 97.39it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3179/3257 [00:21<00:00, 105.34it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3197/3257 [00:21<00:00, 121.33it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3212/3257 [00:21<00:00, 127.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3227/3257 [00:21<00:00, 130.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:21<00:00, 139.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 147.72it/s]
2023-02-07 20:12:14.764 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:12:14,765][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d351,n5,mc5,s0.407662,t4>', 'datetime': '2023-02-07T20:12:14.765707', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:12:14,765][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:12:14,766][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:12:15,262][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:12:15,262][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:12:15,315][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 21312 unique words (49.91% of original 42701, drops 21389)', 'datetime': '2023-02-07T20:12:15.315492', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:12:15,315][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5769229 word corpus (99.08% of original 5822992, drops 53763)', 'datetime': '2023-02-07T20:12:15.315702', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:12:15,382][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:12:15,383][gensim.models.word2vec][INFO] - sample=0.407662 downsamples 0 most-common words
[2023-02-07 20:12:15,383][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5769229 word corpus (100.0%% of prior 5769229)', 'datetime': '2023-02-07T20:12:15.383489', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:12:15,499][gensim.models.word2vec][INFO] - estimated required memory for 21312 words and 351 dimensions: 75724324 bytes
[2023-02-07 20:12:15,500][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:12:15,539][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 21312 vocabulary and 351 features, using sg=1 hs=0 sample=0.4076621838704359 negative=5 window=17 shrink_windows=True', 'datetime': '2023-02-07T20:12:15.539230', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:12:16,544][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 33.16% examples, 1924625 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:17,546][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 65.83% examples, 1927755 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:18,504][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5743174 effective words) took 3.0s, 1938830 effective words/s
[2023-02-07 20:12:19,510][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 36.11% examples, 2102829 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:20,511][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 71.26% examples, 2084662 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:21,286][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5743174 effective words) took 2.8s, 2067073 effective words/s
[2023-02-07 20:12:22,289][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 35.71% examples, 2077612 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:23,294][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 70.53% examples, 2064377 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:24,078][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5743174 effective words) took 2.8s, 2059063 effective words/s
[2023-02-07 20:12:25,084][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 35.89% examples, 2081785 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:26,087][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 71.91% examples, 2096257 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:12:26,805][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5743174 effective words) took 2.7s, 2108616 effective words/s
[2023-02-07 20:12:27,809][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 36.48% examples, 2141520 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:28,812][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 74.64% examples, 2172396 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:29,449][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5743174 effective words) took 2.6s, 2174410 effective words/s
[2023-02-07 20:12:30,455][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 34.97% examples, 2032843 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:12:31,463][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 67.45% examples, 1964762 words/s, in_qsize 8, out_qsize 2
[2023-02-07 20:12:32,401][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5743174 effective words) took 2.9s, 1948087 effective words/s
[2023-02-07 20:12:33,407][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 32.51% examples, 1886031 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:34,409][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 65.06% examples, 1896256 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:35,410][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 99.36% examples, 1899441 words/s, in_qsize 5, out_qsize 0
[2023-02-07 20:12:35,426][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5743174 effective words) took 3.0s, 1900658 effective words/s
[2023-02-07 20:12:36,433][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 33.25% examples, 1929787 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:37,438][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 66.04% examples, 1929083 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:38,411][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5743174 effective words) took 3.0s, 1926500 effective words/s
[2023-02-07 20:12:39,415][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 40.13% examples, 2365057 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:12:40,416][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 81.61% examples, 2361658 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:40,869][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5743174 effective words) took 2.5s, 2338965 effective words/s
[2023-02-07 20:12:41,882][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 37.58% examples, 2187322 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:12:42,885][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 75.78% examples, 2192976 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:43,488][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5743174 effective words) took 2.6s, 2194619 effective words/s
[2023-02-07 20:12:44,490][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 36.84% examples, 2165738 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:45,493][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 73.81% examples, 2142909 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:46,168][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5743174 effective words) took 2.7s, 2144133 effective words/s
[2023-02-07 20:12:47,170][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 36.23% examples, 2114030 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:48,171][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 72.92% examples, 2124514 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:48,851][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5743174 effective words) took 2.7s, 2141931 effective words/s
[2023-02-07 20:12:49,854][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 36.97% examples, 2172549 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:12:50,857][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 74.95% examples, 2180830 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:12:51,485][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5743174 effective words) took 2.6s, 2181754 effective words/s
[2023-02-07 20:12:52,490][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 38.29% examples, 2240705 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:53,492][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 70.80% examples, 2073154 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:54,326][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5743174 effective words) took 2.8s, 2022796 effective words/s
[2023-02-07 20:12:55,330][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 32.36% examples, 1876885 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:56,337][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 64.54% examples, 1879187 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:57,343][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 98.34% examples, 1874684 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:12:57,384][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5743174 effective words) took 3.1s, 1878878 effective words/s
[2023-02-07 20:12:57,385][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86147610 effective words) took 41.8s, 2058746 effective words/s', 'datetime': '2023-02-07T20:12:57.385110', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:12:57.385 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:13:01,789][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201143-hm9ccpf6/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:13:01.789152', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:13:01,790][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:13:01,878][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201143-hm9ccpf6/files/../tmp/embedding_model.pt
2023-02-07 20:13:01.878 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:13:03.856 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:13:04.571 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:13:06.925 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9350504947492377, 'test_mae': 0.7259929253736888, 'test_r2': -2.0292693494015883}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.91
wandb: percentage 0.5009
wandb:   test_mae 0.72599
wandb:   test_mse 0.93505
wandb:    test_r2 -2.02927
wandb: 
wandb: üöÄ View run silver-sweep-74 at: https://wandb.ai/xiaoqiz/mof2vec/runs/hm9ccpf6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_201143-hm9ccpf6/logs
wandb: Agent Starting Run: miqjcw94 with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 858
wandb: 	model.gensim.alpha: 0.014908311559930608
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.8768501543493195
wandb: 	model.gensim.vector_size: 186
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.007651385045906005
wandb: 	model.sklearn.max_depth: 42
wandb: 	model.sklearn.min_child_weight: 0.042964064031574475
wandb: 	model.sklearn.n_estimators: 550
wandb: 	model.sklearn.num_leaves: 44
wandb: 	model.sklearn.reg_alpha: 0.004633987163296692
wandb: 	model.sklearn.reg_lambda: 0.03798699547726863
wandb: 	model.sklearn.subsample: 0.8922759002628047
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201319-miqjcw94
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-75
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/miqjcw94
2023-02-07 20:13:27.560 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 20:13:27.561 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 858 for sweep.
2023-02-07 20:13:27.561 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.014908311559930608 for sweep.
2023-02-07 20:13:27.561 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:13:27.561 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 20:13:27.562 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8768501543493195 for sweep.
2023-02-07 20:13:27.562 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 186 for sweep.
2023-02-07 20:13:27.562 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 20:13:27.562 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.007651385045906005 for sweep.
2023-02-07 20:13:27.563 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 42 for sweep.
2023-02-07 20:13:27.563 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.042964064031574475 for sweep.
2023-02-07 20:13:27.563 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 550 for sweep.
2023-02-07 20:13:27.563 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 44 for sweep.
2023-02-07 20:13:27.564 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004633987163296692 for sweep.
2023-02-07 20:13:27.564 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.03798699547726863 for sweep.
2023-02-07 20:13:27.564 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8922759002628047 for sweep.
2023-02-07 20:13:27.564 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:13:27.570 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201319-miqjcw94/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 858, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 186, 'window': 8, 'min_count': 7, 'dm': 0, 'sample': 0.8768501543493195, 'workers': 4, 'alpha': 0.014908311559930608, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 550, 'max_depth': 42, 'num_leaves': 44, 'reg_alpha': 0.004633987163296692, 'reg_lambda': 0.03798699547726863, 'subsample': 0.8922759002628047, 'min_child_weight': 0.042964064031574475, 'n_jobs': 4, 'learning_rate': 0.007651385045906005}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 178.64it/s]  1%|          | 39/3257 [00:00<00:16, 194.04it/s]  2%|‚ñè         | 59/3257 [00:00<00:17, 187.05it/s]  3%|‚ñé         | 83/3257 [00:00<00:15, 205.38it/s]  3%|‚ñé         | 104/3257 [00:00<00:15, 206.27it/s]  4%|‚ñç         | 125/3257 [00:00<00:15, 196.99it/s]  5%|‚ñç         | 150/3257 [00:00<00:14, 211.19it/s]  5%|‚ñå         | 172/3257 [00:00<00:15, 205.52it/s]  6%|‚ñå         | 194/3257 [00:00<00:14, 209.61it/s]  7%|‚ñã         | 217/3257 [00:01<00:14, 214.21it/s]  7%|‚ñã         | 240/3257 [00:01<00:13, 218.73it/s]  8%|‚ñä         | 262/3257 [00:01<00:14, 211.39it/s]  9%|‚ñâ         | 289/3257 [00:01<00:13, 228.03it/s] 10%|‚ñâ         | 312/3257 [00:01<00:13, 212.81it/s] 10%|‚ñà         | 335/3257 [00:01<00:13, 216.15it/s] 11%|‚ñà         | 358/3257 [00:01<00:13, 218.88it/s] 12%|‚ñà‚ñè        | 381/3257 [00:01<00:14, 202.11it/s] 12%|‚ñà‚ñè        | 404/3257 [00:01<00:13, 207.02it/s] 13%|‚ñà‚ñé        | 425/3257 [00:02<00:14, 195.31it/s] 14%|‚ñà‚ñé        | 445/3257 [00:02<00:14, 187.98it/s] 14%|‚ñà‚ñç        | 467/3257 [00:02<00:14, 196.50it/s] 15%|‚ñà‚ñç        | 487/3257 [00:02<00:14, 193.16it/s] 16%|‚ñà‚ñå        | 513/3257 [00:02<00:13, 209.20it/s] 16%|‚ñà‚ñã        | 535/3257 [00:02<00:12, 210.21it/s] 17%|‚ñà‚ñã        | 557/3257 [00:02<00:13, 206.77it/s] 18%|‚ñà‚ñä        | 578/3257 [00:02<00:14, 187.08it/s] 18%|‚ñà‚ñä        | 602/3257 [00:02<00:13, 199.34it/s] 19%|‚ñà‚ñâ        | 623/3257 [00:03<00:13, 197.50it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:03<00:13, 200.34it/s] 20%|‚ñà‚ñà        | 665/3257 [00:03<00:13, 193.03it/s] 21%|‚ñà‚ñà        | 685/3257 [00:03<00:13, 194.13it/s] 22%|‚ñà‚ñà‚ñè       | 707/3257 [00:03<00:12, 201.18it/s] 22%|‚ñà‚ñà‚ñè       | 728/3257 [00:03<00:12, 199.73it/s] 23%|‚ñà‚ñà‚ñé       | 749/3257 [00:03<00:12, 196.41it/s] 24%|‚ñà‚ñà‚ñé       | 771/3257 [00:03<00:12, 203.10it/s] 24%|‚ñà‚ñà‚ñç       | 792/3257 [00:03<00:12, 197.71it/s] 25%|‚ñà‚ñà‚ñç       | 814/3257 [00:04<00:12, 201.48it/s] 26%|‚ñà‚ñà‚ñå       | 835/3257 [00:04<00:12, 196.44it/s] 26%|‚ñà‚ñà‚ñã       | 855/3257 [00:04<00:12, 187.65it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:04<00:12, 190.03it/s] 28%|‚ñà‚ñà‚ñä       | 896/3257 [00:04<00:12, 195.20it/s] 28%|‚ñà‚ñà‚ñä       | 918/3257 [00:04<00:11, 202.09it/s] 29%|‚ñà‚ñà‚ñâ       | 941/3257 [00:04<00:11, 207.78it/s] 30%|‚ñà‚ñà‚ñâ       | 962/3257 [00:04<00:11, 197.76it/s] 30%|‚ñà‚ñà‚ñà       | 982/3257 [00:04<00:12, 187.54it/s] 31%|‚ñà‚ñà‚ñà       | 1001/3257 [00:05<00:12, 178.76it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1020/3257 [00:05<00:12, 174.46it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1038/3257 [00:05<00:13, 162.08it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1055/3257 [00:05<00:13, 158.80it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1073/3257 [00:05<00:13, 163.37it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1090/3257 [00:05<00:13, 162.77it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1107/3257 [00:05<00:13, 161.01it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:05<00:13, 158.08it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1140/3257 [00:05<00:13, 155.46it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1156/3257 [00:06<00:21, 98.22it/s]  36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:06<00:18, 111.63it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1187/3257 [00:06<00:17, 116.31it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1201/3257 [00:06<00:17, 118.10it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:06<00:15, 128.56it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1240/3257 [00:06<00:13, 150.53it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:06<00:13, 149.75it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:06<00:13, 150.23it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:07<00:13, 145.93it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:07<00:12, 151.44it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1327/3257 [00:07<00:11, 161.38it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:07<00:11, 165.62it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:07<00:11, 164.47it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1381/3257 [00:07<00:11, 160.94it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1400/3257 [00:07<00:10, 169.02it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1421/3257 [00:07<00:10, 180.59it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1440/3257 [00:07<00:10, 171.17it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1462/3257 [00:08<00:09, 182.13it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1481/3257 [00:08<00:09, 180.65it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1502/3257 [00:08<00:09, 188.45it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1521/3257 [00:08<00:09, 175.95it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1539/3257 [00:08<00:10, 168.38it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1557/3257 [00:08<00:10, 164.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:08<00:10, 165.25it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:08<00:09, 170.14it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:08<00:09, 179.51it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:09<00:09, 166.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1651/3257 [00:09<00:09, 164.92it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:09<00:09, 161.76it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1685/3257 [00:09<00:10, 156.85it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1704/3257 [00:09<00:09, 163.42it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1721/3257 [00:09<00:09, 164.58it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1738/3257 [00:09<00:10, 150.85it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1756/3257 [00:09<00:09, 158.65it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1774/3257 [00:09<00:09, 164.18it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1793/3257 [00:10<00:08, 168.61it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1811/3257 [00:10<00:08, 162.06it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:10<00:08, 160.01it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1848/3257 [00:10<00:08, 169.77it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:10<00:07, 176.32it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1888/3257 [00:10<00:07, 179.96it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1909/3257 [00:10<00:07, 186.74it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1928/3257 [00:10<00:07, 181.70it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:10<00:06, 201.49it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1975/3257 [00:11<00:06, 197.25it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1995/3257 [00:11<00:06, 188.40it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2014/3257 [00:11<00:06, 181.80it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:11<00:06, 183.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:11<00:07, 167.09it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2070/3257 [00:11<00:07, 162.07it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2089/3257 [00:11<00:06, 169.43it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2107/3257 [00:11<00:06, 169.15it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2125/3257 [00:11<00:06, 162.04it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:12<00:06, 159.24it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2163/3257 [00:12<00:06, 168.88it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2182/3257 [00:12<00:06, 169.78it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:12<00:05, 180.68it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2223/3257 [00:12<00:05, 179.43it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2242/3257 [00:12<00:05, 174.71it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2261/3257 [00:12<00:05, 176.91it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2279/3257 [00:12<00:05, 171.68it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:12<00:05, 178.51it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2322/3257 [00:13<00:04, 191.46it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2349/3257 [00:13<00:04, 213.96it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2374/3257 [00:13<00:03, 222.99it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:13<00:05, 150.85it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2419/3257 [00:13<00:05, 164.21it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2441/3257 [00:13<00:04, 175.96it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2469/3257 [00:13<00:03, 201.55it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2495/3257 [00:13<00:03, 215.65it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:14<00:03, 234.55it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2551/3257 [00:14<00:02, 244.32it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2577/3257 [00:14<00:02, 227.98it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2601/3257 [00:14<00:02, 222.78it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2631/3257 [00:14<00:02, 242.59it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:14<00:02, 235.11it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2680/3257 [00:14<00:02, 228.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:14<00:02, 210.09it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2726/3257 [00:14<00:02, 211.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2751/3257 [00:15<00:02, 222.31it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:15<00:02, 215.16it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2804/3257 [00:15<00:01, 237.14it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2829/3257 [00:15<00:02, 213.26it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:15<00:01, 219.84it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2884/3257 [00:15<00:01, 243.48it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2909/3257 [00:15<00:01, 220.89it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2932/3257 [00:15<00:01, 219.78it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2955/3257 [00:15<00:01, 211.61it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2977/3257 [00:16<00:01, 212.18it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3001/3257 [00:16<00:01, 219.52it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3024/3257 [00:16<00:01, 215.29it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3051/3257 [00:16<00:00, 228.78it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3079/3257 [00:16<00:00, 242.81it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3105/3257 [00:16<00:00, 246.20it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3130/3257 [00:16<00:00, 242.49it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3155/3257 [00:16<00:00, 231.07it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3179/3257 [00:16<00:00, 220.72it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3205/3257 [00:17<00:00, 230.22it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3229/3257 [00:17<00:00, 221.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:17<00:00, 226.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 188.49it/s]
2023-02-07 20:13:45.474 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:13:45,475][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d186,n5,mc7,s0.87685,t4>', 'datetime': '2023-02-07T20:13:45.475858', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:13:45,477][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:13:45,477][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:13:45,879][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 20:13:45,879][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:13:45,908][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 9824 unique words (45.27% of original 21699, drops 11875)', 'datetime': '2023-02-07T20:13:45.908190', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:13:45,908][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 4333599 word corpus (99.23% of original 4367244, drops 33645)', 'datetime': '2023-02-07T20:13:45.908548', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:13:45,943][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 20:13:45,943][gensim.models.word2vec][INFO] - sample=0.87685 downsamples 0 most-common words
[2023-02-07 20:13:45,944][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4333599 word corpus (100.0%% of prior 4333599)', 'datetime': '2023-02-07T20:13:45.944090', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:13:46,002][gensim.models.word2vec][INFO] - estimated required memory for 9824 words and 186 dimensions: 22604720 bytes
[2023-02-07 20:13:46,003][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:13:46,013][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 9824 vocabulary and 186 features, using sg=1 hs=0 sample=0.8768501543493195 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T20:13:46.013618', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:13:47,016][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 56.65% examples, 2516777 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:13:47,706][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4335166 effective words) took 1.7s, 2563832 effective words/s
[2023-02-07 20:13:48,710][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 63.31% examples, 2797363 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:13:49,263][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4335166 effective words) took 1.6s, 2790025 effective words/s
[2023-02-07 20:13:50,266][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 63.31% examples, 2796744 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:13:50,801][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4335166 effective words) took 1.5s, 2822917 effective words/s
[2023-02-07 20:13:51,806][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 57.32% examples, 2533149 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:13:52,515][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4335166 effective words) took 1.7s, 2530227 effective words/s
[2023-02-07 20:13:53,523][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 56.34% examples, 2498604 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:13:54,244][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4335166 effective words) took 1.7s, 2513053 effective words/s
[2023-02-07 20:13:55,247][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 56.65% examples, 2515429 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:13:55,959][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4335166 effective words) took 1.7s, 2531698 effective words/s
[2023-02-07 20:13:56,967][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 58.03% examples, 2562910 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:13:57,644][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4335166 effective words) took 1.7s, 2577433 effective words/s
[2023-02-07 20:13:58,648][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 58.52% examples, 2587816 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:13:59,319][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4335166 effective words) took 1.7s, 2592180 effective words/s
[2023-02-07 20:14:00,321][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 70.22% examples, 3111396 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:00,708][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4335166 effective words) took 1.4s, 3124158 effective words/s
[2023-02-07 20:14:01,714][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 65.27% examples, 2875458 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:02,216][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4335166 effective words) took 1.5s, 2876298 effective words/s
[2023-02-07 20:14:03,221][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 65.09% examples, 2870901 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:03,728][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4335166 effective words) took 1.5s, 2870369 effective words/s
[2023-02-07 20:14:04,741][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 65.89% examples, 2890573 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:05,212][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4335166 effective words) took 1.5s, 2924533 effective words/s
[2023-02-07 20:14:06,215][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 66.38% examples, 2938891 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:06,692][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4335166 effective words) took 1.5s, 2931884 effective words/s
[2023-02-07 20:14:07,698][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 66.84% examples, 2949085 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:08,167][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4335166 effective words) took 1.5s, 2946675 effective words/s
[2023-02-07 20:14:09,170][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 66.66% examples, 2949072 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:09,647][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4335166 effective words) took 1.5s, 2933993 effective words/s
[2023-02-07 20:14:09,648][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65027490 effective words) took 23.6s, 2751413 effective words/s', 'datetime': '2023-02-07T20:14:09.648292', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:14:09.648 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:14:12,194][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201319-miqjcw94/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:14:12.194098', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:14:12,195][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:14:12,231][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201319-miqjcw94/files/../tmp/embedding_model.pt
2023-02-07 20:14:12.232 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:14:13.824 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:14:14.418 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:14:15.796 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.8735024308757072, 'test_mae': 0.7069767885869997, 'test_r2': -1.849703691471309}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.86
wandb: percentage 0.54726
wandb:   test_mae 0.70698
wandb:   test_mse 0.8735
wandb:    test_r2 -1.8497
wandb: 
wandb: üöÄ View run smooth-sweep-75 at: https://wandb.ai/xiaoqiz/mof2vec/runs/miqjcw94
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_201319-miqjcw94/logs
wandb: Agent Starting Run: tlqc8ab3 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 591
wandb: 	model.gensim.alpha: 0.11789756544846931
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.9092237017172472
wandb: 	model.gensim.vector_size: 361
wandb: 	model.gensim.window: 9
wandb: 	model.sklearn.learning_rate: 0.020463424440616752
wandb: 	model.sklearn.max_depth: 91
wandb: 	model.sklearn.min_child_weight: 0.03832389664127028
wandb: 	model.sklearn.n_estimators: 1251
wandb: 	model.sklearn.num_leaves: 49
wandb: 	model.sklearn.reg_alpha: 0.0050452164487608565
wandb: 	model.sklearn.reg_lambda: 0.037029505807604675
wandb: 	model.sklearn.subsample: 0.8296483729620743
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201427-tlqc8ab3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-76
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/tlqc8ab3
2023-02-07 20:14:36.289 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 20:14:36.290 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 591 for sweep.
2023-02-07 20:14:36.290 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.11789756544846931 for sweep.
2023-02-07 20:14:36.290 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:14:36.291 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 20:14:36.291 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9092237017172472 for sweep.
2023-02-07 20:14:36.291 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 361 for sweep.
2023-02-07 20:14:36.291 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 9 for sweep.
2023-02-07 20:14:36.291 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.020463424440616752 for sweep.
2023-02-07 20:14:36.292 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 91 for sweep.
2023-02-07 20:14:36.292 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03832389664127028 for sweep.
2023-02-07 20:14:36.292 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1251 for sweep.
2023-02-07 20:14:36.292 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 49 for sweep.
2023-02-07 20:14:36.293 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0050452164487608565 for sweep.
2023-02-07 20:14:36.293 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.037029505807604675 for sweep.
2023-02-07 20:14:36.293 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8296483729620743 for sweep.
2023-02-07 20:14:36.293 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:14:36.300 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201427-tlqc8ab3/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 591, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 361, 'window': 9, 'min_count': 10, 'dm': 0, 'sample': 0.9092237017172472, 'workers': 4, 'alpha': 0.11789756544846931, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1251, 'max_depth': 91, 'num_leaves': 49, 'reg_alpha': 0.0050452164487608565, 'reg_lambda': 0.037029505807604675, 'subsample': 0.8296483729620743, 'min_child_weight': 0.03832389664127028, 'n_jobs': 4, 'learning_rate': 0.020463424440616752}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 18/3257 [00:00<00:18, 171.74it/s]  1%|‚ñè         | 41/3257 [00:00<00:16, 195.44it/s]  2%|‚ñè         | 61/3257 [00:00<00:16, 194.02it/s]  3%|‚ñé         | 82/3257 [00:00<00:16, 197.30it/s]  3%|‚ñé         | 104/3257 [00:00<00:15, 199.32it/s]  4%|‚ñç         | 124/3257 [00:00<00:16, 190.41it/s]  5%|‚ñç         | 147/3257 [00:00<00:15, 200.68it/s]  5%|‚ñå         | 168/3257 [00:00<00:15, 194.81it/s]  6%|‚ñå         | 188/3257 [00:00<00:15, 195.79it/s]  6%|‚ñã         | 208/3257 [00:01<00:15, 194.42it/s]  7%|‚ñã         | 232/3257 [00:01<00:14, 205.35it/s]  8%|‚ñä         | 253/3257 [00:01<00:14, 202.28it/s]  8%|‚ñä         | 274/3257 [00:01<00:14, 203.31it/s]  9%|‚ñâ         | 298/3257 [00:01<00:13, 212.64it/s] 10%|‚ñâ         | 320/3257 [00:01<00:14, 208.77it/s] 10%|‚ñà         | 341/3257 [00:01<00:14, 201.23it/s] 11%|‚ñà         | 363/3257 [00:01<00:14, 204.36it/s] 12%|‚ñà‚ñè        | 384/3257 [00:01<00:14, 194.65it/s] 12%|‚ñà‚ñè        | 404/3257 [00:02<00:14, 192.14it/s] 13%|‚ñà‚ñé        | 424/3257 [00:02<00:14, 190.15it/s] 14%|‚ñà‚ñé        | 444/3257 [00:02<00:16, 172.51it/s] 14%|‚ñà‚ñç        | 467/3257 [00:02<00:14, 186.16it/s] 15%|‚ñà‚ñç        | 486/3257 [00:02<00:14, 185.99it/s] 16%|‚ñà‚ñå        | 510/3257 [00:02<00:13, 200.08it/s] 16%|‚ñà‚ñã        | 531/3257 [00:02<00:13, 196.75it/s] 17%|‚ñà‚ñã        | 551/3257 [00:02<00:19, 139.27it/s] 17%|‚ñà‚ñã        | 568/3257 [00:03<00:18, 144.72it/s] 18%|‚ñà‚ñä        | 585/3257 [00:03<00:17, 148.75it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:16, 158.78it/s] 19%|‚ñà‚ñâ        | 624/3257 [00:03<00:15, 168.22it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:14, 174.20it/s] 20%|‚ñà‚ñà        | 664/3257 [00:03<00:15, 170.81it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:14, 172.98it/s] 22%|‚ñà‚ñà‚ñè       | 702/3257 [00:03<00:14, 176.60it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:03<00:14, 179.46it/s] 23%|‚ñà‚ñà‚ñé       | 740/3257 [00:04<00:14, 168.56it/s] 23%|‚ñà‚ñà‚ñé       | 763/3257 [00:04<00:13, 182.77it/s] 24%|‚ñà‚ñà‚ñç       | 782/3257 [00:04<00:13, 179.06it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:04<00:13, 183.49it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:04<00:13, 174.39it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:04<00:14, 168.92it/s] 26%|‚ñà‚ñà‚ñã       | 861/3257 [00:04<00:13, 175.95it/s] 27%|‚ñà‚ñà‚ñã       | 879/3257 [00:04<00:13, 172.89it/s] 28%|‚ñà‚ñà‚ñä       | 901/3257 [00:04<00:12, 184.44it/s] 28%|‚ñà‚ñà‚ñä       | 920/3257 [00:05<00:12, 182.39it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:05<00:12, 183.66it/s] 29%|‚ñà‚ñà‚ñâ       | 960/3257 [00:05<00:12, 190.29it/s] 30%|‚ñà‚ñà‚ñà       | 980/3257 [00:05<00:12, 186.46it/s] 31%|‚ñà‚ñà‚ñà       | 999/3257 [00:05<00:12, 186.28it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1018/3257 [00:05<00:11, 186.68it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1037/3257 [00:05<00:12, 175.82it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1055/3257 [00:05<00:12, 173.52it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1078/3257 [00:05<00:11, 189.19it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1098/3257 [00:06<00:12, 176.15it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1118/3257 [00:06<00:11, 181.37it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1137/3257 [00:06<00:11, 178.61it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1156/3257 [00:06<00:11, 177.85it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:06<00:11, 178.40it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1193/3257 [00:06<00:12, 167.92it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:06<00:12, 163.94it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:06<00:11, 179.39it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1252/3257 [00:06<00:11, 181.16it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:06<00:10, 182.63it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:07<00:11, 170.88it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:07<00:11, 174.32it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1329/3257 [00:07<00:10, 181.29it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:07<00:10, 182.78it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:07<00:10, 182.72it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1389/3257 [00:07<00:10, 178.07it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1417/3257 [00:07<00:08, 204.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1438/3257 [00:07<00:09, 201.74it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1463/3257 [00:07<00:08, 214.63it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1485/3257 [00:08<00:08, 204.46it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1506/3257 [00:08<00:08, 201.99it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1527/3257 [00:08<00:09, 176.45it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:08<00:10, 162.36it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1565/3257 [00:08<00:10, 164.52it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1582/3257 [00:08<00:10, 160.91it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1599/3257 [00:08<00:10, 163.13it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1616/3257 [00:09<00:16, 99.28it/s]  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1632/3257 [00:09<00:14, 110.59it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1646/3257 [00:09<00:14, 114.51it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:09<00:13, 118.59it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:09<00:12, 125.77it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:09<00:11, 131.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:09<00:10, 141.72it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1726/3257 [00:09<00:10, 151.08it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1742/3257 [00:10<00:11, 130.77it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1762/3257 [00:10<00:10, 147.32it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1778/3257 [00:10<00:09, 149.12it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:10<00:09, 153.94it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1812/3257 [00:10<00:09, 150.17it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:10<00:09, 147.79it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:10<00:09, 155.98it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1867/3257 [00:10<00:08, 170.25it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1885/3257 [00:10<00:08, 163.01it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1902/3257 [00:11<00:08, 164.14it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1919/3257 [00:11<00:08, 161.31it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1940/3257 [00:11<00:07, 173.16it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1962/3257 [00:11<00:06, 185.30it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1981/3257 [00:11<00:07, 172.12it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:11<00:07, 171.81it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2017/3257 [00:11<00:07, 169.71it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:11<00:07, 168.45it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:11<00:07, 156.16it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2068/3257 [00:12<00:07, 151.65it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:12<00:07, 153.20it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2101/3257 [00:12<00:07, 151.84it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:12<00:07, 152.49it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2136/3257 [00:12<00:07, 152.94it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2152/3257 [00:12<00:07, 152.70it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:12<00:06, 155.46it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:12<00:06, 156.20it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:12<00:06, 164.07it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2221/3257 [00:12<00:06, 162.59it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:13<00:06, 158.62it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2256/3257 [00:13<00:06, 163.24it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2273/3257 [00:13<00:06, 151.80it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2294/3257 [00:13<00:05, 167.10it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2311/3257 [00:13<00:05, 165.38it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2334/3257 [00:13<00:05, 181.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2357/3257 [00:13<00:04, 194.47it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2377/3257 [00:13<00:04, 182.66it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:13<00:04, 191.10it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2419/3257 [00:14<00:04, 176.82it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2438/3257 [00:14<00:04, 172.44it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2456/3257 [00:14<00:04, 171.05it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2476/3257 [00:14<00:04, 178.90it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2496/3257 [00:14<00:04, 184.19it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2519/3257 [00:14<00:03, 192.69it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:14<00:03, 191.34it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2560/3257 [00:14<00:03, 181.52it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2579/3257 [00:15<00:04, 164.74it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2596/3257 [00:15<00:03, 165.89it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2619/3257 [00:15<00:03, 182.90it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2640/3257 [00:15<00:03, 184.95it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2659/3257 [00:15<00:03, 170.68it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2678/3257 [00:15<00:03, 175.37it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2696/3257 [00:15<00:03, 166.05it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2713/3257 [00:15<00:03, 155.65it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:15<00:03, 162.03it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2752/3257 [00:16<00:02, 171.50it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2770/3257 [00:16<00:02, 163.90it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:16<00:02, 176.88it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2810/3257 [00:16<00:02, 177.73it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2828/3257 [00:16<00:02, 170.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2851/3257 [00:16<00:02, 185.35it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2881/3257 [00:16<00:01, 216.29it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:16<00:01, 207.97it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:16<00:01, 218.03it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2951/3257 [00:17<00:01, 208.14it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:17<00:01, 212.01it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3001/3257 [00:17<00:01, 222.41it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3024/3257 [00:17<00:01, 223.57it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3054/3257 [00:17<00:00, 244.76it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3082/3257 [00:17<00:00, 253.58it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3109/3257 [00:17<00:00, 253.60it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3135/3257 [00:17<00:00, 240.85it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3160/3257 [00:18<00:00, 138.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3181/3257 [00:18<00:00, 151.26it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3208/3257 [00:18<00:00, 174.75it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3234/3257 [00:18<00:00, 194.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 175.73it/s]
2023-02-07 20:14:55.433 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:14:55,434][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d361,n5,mc10,s0.909224,t4>', 'datetime': '2023-02-07T20:14:55.434792', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:14:55,436][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:14:55,436][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:14:55,907][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 20:14:55,908][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:14:55,937][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 11126 unique words (34.98% of original 31803, drops 20677)', 'datetime': '2023-02-07T20:14:55.937923', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:14:55,938][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 5020792 word corpus (98.54% of original 5095118, drops 74326)', 'datetime': '2023-02-07T20:14:55.938107', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:14:55,971][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 20:14:55,972][gensim.models.word2vec][INFO] - sample=0.909224 downsamples 0 most-common words
[2023-02-07 20:14:55,972][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5020792 word corpus (100.0%% of prior 5020792)', 'datetime': '2023-02-07T20:14:55.972434', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:14:56,035][gensim.models.word2vec][INFO] - estimated required memory for 11126 words and 361 dimensions: 43049396 bytes
[2023-02-07 20:14:56,036][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:14:56,056][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11126 vocabulary and 361 features, using sg=1 hs=0 sample=0.9092237017172472 negative=5 window=9 shrink_windows=True', 'datetime': '2023-02-07T20:14:56.055990', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:14:57,059][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 47.71% examples, 2442411 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:14:58,060][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 99.72% examples, 2498804 words/s, in_qsize 1, out_qsize 1
[2023-02-07 20:14:58,061][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5012991 effective words) took 2.0s, 2502701 effective words/s
[2023-02-07 20:14:59,064][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 51.21% examples, 2620907 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:14:59,952][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5012991 effective words) took 1.9s, 2652631 effective words/s
[2023-02-07 20:15:00,956][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 52.44% examples, 2678824 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:01,840][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5012991 effective words) took 1.9s, 2656997 effective words/s
[2023-02-07 20:15:02,843][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 53.18% examples, 2730782 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:03,679][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5012991 effective words) took 1.8s, 2728847 effective words/s
[2023-02-07 20:15:04,681][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 53.05% examples, 2725825 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:05,529][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5012991 effective words) took 1.8s, 2711918 effective words/s
[2023-02-07 20:15:06,531][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 54.28% examples, 2785449 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:07,357][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5012991 effective words) took 1.8s, 2744484 effective words/s
[2023-02-07 20:15:08,360][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.02% examples, 2712366 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:09,207][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5012991 effective words) took 1.8s, 2712095 effective words/s
[2023-02-07 20:15:10,210][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 52.63% examples, 2690610 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:11,049][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5012991 effective words) took 1.8s, 2722645 effective words/s
[2023-02-07 20:15:12,051][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 51.86% examples, 2661248 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:15:12,932][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5012991 effective words) took 1.9s, 2665070 effective words/s
[2023-02-07 20:15:13,936][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 52.13% examples, 2666722 words/s, in_qsize 7, out_qsize 1
[2023-02-07 20:15:14,801][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5012991 effective words) took 1.9s, 2684484 effective words/s
[2023-02-07 20:15:15,803][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 51.70% examples, 2651012 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:16,674][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5012991 effective words) took 1.9s, 2678097 effective words/s
[2023-02-07 20:15:17,676][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 52.78% examples, 2704231 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:18,519][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5012991 effective words) took 1.8s, 2719414 effective words/s
[2023-02-07 20:15:19,527][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 52.78% examples, 2689906 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:20,369][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5012991 effective words) took 1.8s, 2712265 effective words/s
[2023-02-07 20:15:21,372][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 53.30% examples, 2741994 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:22,216][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5012991 effective words) took 1.8s, 2716927 effective words/s
[2023-02-07 20:15:23,218][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 51.89% examples, 2662283 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:15:24,156][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5012991 effective words) took 1.9s, 2585549 effective words/s
[2023-02-07 20:15:24,157][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75194865 effective words) took 28.1s, 2675907 effective words/s', 'datetime': '2023-02-07T20:15:24.157087', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:15:24.157 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:15:27,126][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201427-tlqc8ab3/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:15:27.126546', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:15:27,128][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:15:27,189][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201427-tlqc8ab3/files/../tmp/embedding_model.pt
2023-02-07 20:15:27.190 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:15:29.399 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:15:30.157 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:15:32.422 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0188308449821066, 'test_mae': 0.781789980828762, 'test_r2': -2.70448979355394}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: | 0.028 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: / 0.028 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: - 0.028 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.89
wandb: percentage 0.65016
wandb:   test_mae 0.78179
wandb:   test_mse 1.01883
wandb:    test_r2 -2.70449
wandb: 
wandb: üöÄ View run clean-sweep-76 at: https://wandb.ai/xiaoqiz/mof2vec/runs/tlqc8ab3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_201427-tlqc8ab3/logs
wandb: Agent Starting Run: zb9nnj5y with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 817
wandb: 	model.gensim.alpha: 0.011452202281338312
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.6731098733126339
wandb: 	model.gensim.vector_size: 376
wandb: 	model.gensim.window: 8
wandb: 	model.sklearn.learning_rate: 0.0008939572944730193
wandb: 	model.sklearn.max_depth: 64
wandb: 	model.sklearn.min_child_weight: 0.028362526588030828
wandb: 	model.sklearn.n_estimators: 392
wandb: 	model.sklearn.num_leaves: 159
wandb: 	model.sklearn.reg_alpha: 0.05579237379787607
wandb: 	model.sklearn.reg_lambda: 0.16294248136485076
wandb: 	model.sklearn.subsample: 0.9411474549732994
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201546-zb9nnj5y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-77
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/zb9nnj5y
2023-02-07 20:15:54.496 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:15:54.496 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 817 for sweep.
2023-02-07 20:15:54.497 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.011452202281338312 for sweep.
2023-02-07 20:15:54.497 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:15:54.497 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 20:15:54.498 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6731098733126339 for sweep.
2023-02-07 20:15:54.498 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 376 for sweep.
2023-02-07 20:15:54.498 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 8 for sweep.
2023-02-07 20:15:54.498 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0008939572944730193 for sweep.
2023-02-07 20:15:54.499 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 64 for sweep.
2023-02-07 20:15:54.499 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.028362526588030828 for sweep.
2023-02-07 20:15:54.499 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 392 for sweep.
2023-02-07 20:15:54.499 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 159 for sweep.
2023-02-07 20:15:54.500 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.05579237379787607 for sweep.
2023-02-07 20:15:54.500 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.16294248136485076 for sweep.
2023-02-07 20:15:54.500 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9411474549732994 for sweep.
2023-02-07 20:15:54.500 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:15:54.506 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201546-zb9nnj5y/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 817, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 376, 'window': 8, 'min_count': 6, 'dm': 0, 'sample': 0.6731098733126339, 'workers': 4, 'alpha': 0.011452202281338312, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 392, 'max_depth': 64, 'num_leaves': 159, 'reg_alpha': 0.05579237379787607, 'reg_lambda': 0.16294248136485076, 'subsample': 0.9411474549732994, 'min_child_weight': 0.028362526588030828, 'n_jobs': 4, 'learning_rate': 0.0008939572944730193}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:20, 155.04it/s]  1%|          | 34/3257 [00:00<00:19, 161.53it/s]  2%|‚ñè         | 52/3257 [00:00<00:19, 167.69it/s]  2%|‚ñè         | 69/3257 [00:00<00:19, 166.95it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 173.25it/s]  3%|‚ñé         | 108/3257 [00:00<00:18, 167.15it/s]  4%|‚ñç         | 126/3257 [00:00<00:18, 169.11it/s]  5%|‚ñç         | 148/3257 [00:00<00:17, 181.89it/s]  5%|‚ñå         | 167/3257 [00:00<00:17, 173.37it/s]  6%|‚ñå         | 185/3257 [00:01<00:18, 169.99it/s]  6%|‚ñå         | 203/3257 [00:01<00:17, 169.72it/s]  7%|‚ñã         | 227/3257 [00:01<00:16, 187.70it/s]  8%|‚ñä         | 249/3257 [00:01<00:15, 193.15it/s]  8%|‚ñä         | 269/3257 [00:01<00:15, 187.65it/s]  9%|‚ñâ         | 296/3257 [00:01<00:14, 207.18it/s] 10%|‚ñâ         | 317/3257 [00:01<00:15, 191.26it/s] 10%|‚ñà         | 337/3257 [00:01<00:15, 186.41it/s] 11%|‚ñà         | 356/3257 [00:01<00:15, 184.99it/s] 12%|‚ñà‚ñè        | 375/3257 [00:02<00:17, 168.63it/s] 12%|‚ñà‚ñè        | 393/3257 [00:02<00:18, 155.48it/s] 13%|‚ñà‚ñé        | 412/3257 [00:02<00:17, 162.64it/s] 13%|‚ñà‚ñé        | 429/3257 [00:02<00:20, 140.50it/s] 14%|‚ñà‚ñé        | 444/3257 [00:02<00:19, 142.55it/s] 14%|‚ñà‚ñç        | 461/3257 [00:02<00:18, 148.06it/s] 15%|‚ñà‚ñç        | 477/3257 [00:02<00:18, 149.23it/s] 15%|‚ñà‚ñå        | 494/3257 [00:02<00:17, 154.20it/s] 16%|‚ñà‚ñå        | 513/3257 [00:03<00:16, 163.98it/s] 16%|‚ñà‚ñã        | 530/3257 [00:03<00:16, 164.02it/s] 17%|‚ñà‚ñã        | 547/3257 [00:03<00:17, 158.40it/s] 17%|‚ñà‚ñã        | 563/3257 [00:03<00:18, 146.92it/s] 18%|‚ñà‚ñä        | 578/3257 [00:03<00:18, 141.41it/s] 18%|‚ñà‚ñä        | 597/3257 [00:03<00:17, 154.07it/s] 19%|‚ñà‚ñâ        | 615/3257 [00:03<00:16, 159.23it/s] 19%|‚ñà‚ñâ        | 632/3257 [00:03<00:16, 157.41it/s] 20%|‚ñà‚ñâ        | 648/3257 [00:03<00:17, 151.79it/s] 20%|‚ñà‚ñà        | 664/3257 [00:04<00:18, 143.17it/s] 21%|‚ñà‚ñà        | 682/3257 [00:04<00:16, 152.25it/s] 21%|‚ñà‚ñà‚ñè       | 698/3257 [00:04<00:17, 145.22it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:16, 157.72it/s] 23%|‚ñà‚ñà‚ñé       | 734/3257 [00:04<00:16, 150.04it/s] 23%|‚ñà‚ñà‚ñé       | 750/3257 [00:04<00:17, 144.85it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:04<00:16, 154.84it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:04<00:16, 147.76it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:04<00:15, 153.66it/s] 25%|‚ñà‚ñà‚ñå       | 821/3257 [00:05<00:15, 157.04it/s] 26%|‚ñà‚ñà‚ñå       | 839/3257 [00:05<00:14, 162.47it/s] 26%|‚ñà‚ñà‚ñã       | 856/3257 [00:05<00:14, 160.59it/s] 27%|‚ñà‚ñà‚ñã       | 875/3257 [00:05<00:14, 165.77it/s] 27%|‚ñà‚ñà‚ñã       | 894/3257 [00:05<00:13, 169.29it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:05<00:13, 175.73it/s] 29%|‚ñà‚ñà‚ñä       | 935/3257 [00:05<00:12, 184.31it/s] 29%|‚ñà‚ñà‚ñâ       | 957/3257 [00:05<00:11, 194.48it/s] 30%|‚ñà‚ñà‚ñà       | 978/3257 [00:05<00:11, 197.21it/s] 31%|‚ñà‚ñà‚ñà       | 998/3257 [00:06<00:12, 186.10it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1019/3257 [00:06<00:11, 191.71it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1039/3257 [00:06<00:12, 179.72it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1058/3257 [00:06<00:12, 176.15it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:12, 175.45it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1098/3257 [00:06<00:18, 116.28it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1118/3257 [00:06<00:16, 131.63it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1137/3257 [00:06<00:14, 143.44it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1154/3257 [00:07<00:14, 148.09it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:07<00:13, 159.15it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1193/3257 [00:07<00:13, 152.72it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:07<00:13, 151.18it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:07<00:12, 166.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1250/3257 [00:07<00:12, 162.14it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1270/3257 [00:07<00:11, 171.98it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:07<00:12, 153.12it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1306/3257 [00:08<00:12, 158.98it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1324/3257 [00:08<00:11, 163.49it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1343/3257 [00:08<00:11, 170.39it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1361/3257 [00:08<00:11, 166.16it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1378/3257 [00:08<00:11, 161.31it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1395/3257 [00:08<00:11, 158.23it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1416/3257 [00:08<00:10, 171.94it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1434/3257 [00:08<00:10, 166.83it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1455/3257 [00:08<00:10, 178.42it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1475/3257 [00:09<00:09, 181.84it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:09<00:09, 187.06it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1517/3257 [00:09<00:09, 190.62it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1537/3257 [00:09<00:10, 170.16it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1555/3257 [00:09<00:10, 168.28it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:09<00:09, 171.71it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:09<00:09, 179.48it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:09<00:08, 183.02it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1636/3257 [00:09<00:09, 176.09it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:10<00:09, 173.34it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1672/3257 [00:10<00:09, 167.43it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1689/3257 [00:10<00:09, 164.79it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1707/3257 [00:10<00:09, 167.61it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1727/3257 [00:10<00:08, 173.30it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:10<00:10, 150.63it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1764/3257 [00:10<00:09, 158.79it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1784/3257 [00:10<00:08, 167.89it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1802/3257 [00:10<00:08, 168.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1820/3257 [00:11<00:08, 165.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1837/3257 [00:11<00:08, 163.29it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1854/3257 [00:11<00:08, 164.72it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1875/3257 [00:11<00:07, 175.51it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1893/3257 [00:11<00:08, 168.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:11<00:07, 177.01it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1935/3257 [00:11<00:07, 179.89it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1958/3257 [00:11<00:06, 192.76it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1978/3257 [00:11<00:06, 186.51it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:12<00:06, 188.93it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2019/3257 [00:12<00:06, 191.04it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2039/3257 [00:12<00:06, 186.81it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2058/3257 [00:12<00:07, 170.30it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2076/3257 [00:12<00:06, 169.84it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2094/3257 [00:12<00:06, 171.72it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2112/3257 [00:12<00:06, 170.00it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2130/3257 [00:12<00:06, 161.53it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2147/3257 [00:12<00:07, 157.20it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:13<00:06, 170.36it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2186/3257 [00:13<00:06, 169.30it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2205/3257 [00:13<00:06, 174.56it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2223/3257 [00:13<00:06, 171.22it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2241/3257 [00:13<00:06, 160.16it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:13<00:06, 164.78it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:13<00:06, 153.06it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2298/3257 [00:13<00:05, 170.52it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2316/3257 [00:13<00:05, 172.79it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2340/3257 [00:14<00:04, 191.13it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2362/3257 [00:14<00:04, 198.40it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2383/3257 [00:14<00:04, 197.21it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:14<00:04, 199.17it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2425/3257 [00:14<00:04, 184.07it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2444/3257 [00:14<00:04, 172.28it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2465/3257 [00:14<00:04, 181.11it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2484/3257 [00:14<00:04, 180.89it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:14<00:03, 193.19it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2527/3257 [00:15<00:06, 107.82it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2547/3257 [00:15<00:05, 124.06it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2564/3257 [00:15<00:05, 130.16it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2581/3257 [00:15<00:05, 134.16it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2599/3257 [00:15<00:04, 144.74it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2622/3257 [00:15<00:03, 165.81it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2641/3257 [00:15<00:03, 170.58it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2660/3257 [00:16<00:03, 162.54it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2680/3257 [00:16<00:03, 171.75it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2698/3257 [00:16<00:03, 159.31it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2715/3257 [00:16<00:03, 155.79it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2738/3257 [00:16<00:02, 174.39it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2758/3257 [00:16<00:02, 178.52it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2777/3257 [00:16<00:02, 172.01it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2800/3257 [00:16<00:02, 185.78it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2819/3257 [00:16<00:02, 176.68it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:17<00:02, 170.37it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2859/3257 [00:17<00:02, 182.68it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2882/3257 [00:17<00:01, 195.68it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2902/3257 [00:17<00:02, 176.62it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2924/3257 [00:17<00:01, 187.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2944/3257 [00:17<00:01, 171.81it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2965/3257 [00:17<00:01, 180.26it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:17<00:01, 167.82it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3005/3257 [00:17<00:01, 178.07it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3024/3257 [00:18<00:01, 173.97it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3047/3257 [00:18<00:01, 188.70it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3069/3257 [00:18<00:00, 195.81it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3089/3257 [00:18<00:00, 193.39it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3113/3257 [00:18<00:00, 206.20it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3134/3257 [00:18<00:00, 204.01it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3155/3257 [00:18<00:00, 197.22it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3175/3257 [00:18<00:00, 197.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3196/3257 [00:18<00:00, 198.99it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3216/3257 [00:19<00:00, 186.75it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3240/3257 [00:19<00:00, 200.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 169.11it/s]
2023-02-07 20:16:14.595 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:16:14,596][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d376,n5,mc6,s0.67311,t4>', 'datetime': '2023-02-07T20:16:14.596784', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:16:14,597][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:16:14,597][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:16:15,209][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:16:15,209][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:16:15,273][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 20659 unique words (48.38% of original 42701, drops 22042)', 'datetime': '2023-02-07T20:16:15.273514', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:16:15,274][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 5765964 word corpus (99.02% of original 5822992, drops 57028)', 'datetime': '2023-02-07T20:16:15.274850', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:16:15,351][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:16:15,352][gensim.models.word2vec][INFO] - sample=0.67311 downsamples 0 most-common words
[2023-02-07 20:16:15,352][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5765964 word corpus (100.0%% of prior 5765964)', 'datetime': '2023-02-07T20:16:15.352824', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:16:15,484][gensim.models.word2vec][INFO] - estimated required memory for 20659 words and 376 dimensions: 78021700 bytes
[2023-02-07 20:16:15,484][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:16:15,532][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 20659 vocabulary and 376 features, using sg=1 hs=0 sample=0.6731098733126339 negative=5 window=8 shrink_windows=True', 'datetime': '2023-02-07T20:16:15.532608', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:16:16,543][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 28.89% examples, 1653020 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:17,544][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 57.88% examples, 1691283 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:18,547][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 88.82% examples, 1704599 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:18,891][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5739976 effective words) took 3.4s, 1710466 effective words/s
[2023-02-07 20:16:19,895][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 33.53% examples, 1946671 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:20,901][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 65.83% examples, 1923728 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:21,888][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5739976 effective words) took 3.0s, 1916802 effective words/s
[2023-02-07 20:16:22,892][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 33.47% examples, 1942015 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:23,895][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 72.92% examples, 2121942 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:24,491][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5739976 effective words) took 2.6s, 2208108 effective words/s
[2023-02-07 20:16:25,500][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 36.97% examples, 2158433 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:26,503][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 75.19% examples, 2182947 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:27,118][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5739976 effective words) took 2.6s, 2186687 effective words/s
[2023-02-07 20:16:28,125][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 36.97% examples, 2167128 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:16:29,128][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 74.95% examples, 2177462 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:16:29,764][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5739976 effective words) took 2.6s, 2172084 effective words/s
[2023-02-07 20:16:30,777][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 37.58% examples, 2189498 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:16:31,779][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 75.41% examples, 2185614 words/s, in_qsize 7, out_qsize 1
[2023-02-07 20:16:32,389][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5739976 effective words) took 2.6s, 2189849 effective words/s
[2023-02-07 20:16:33,404][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 37.70% examples, 2185823 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:34,405][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 76.51% examples, 2210107 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:34,979][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5739976 effective words) took 2.6s, 2218468 effective words/s
[2023-02-07 20:16:35,988][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 38.29% examples, 2233918 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:36,988][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 78.78% examples, 2276103 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:37,535][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5739976 effective words) took 2.6s, 2248038 effective words/s
[2023-02-07 20:16:38,544][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 34.45% examples, 1989046 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:39,545][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 68.04% examples, 1985278 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:40,435][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5739976 effective words) took 2.9s, 1980763 effective words/s
[2023-02-07 20:16:41,440][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 33.47% examples, 1936756 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:42,445][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 66.41% examples, 1939714 words/s, in_qsize 7, out_qsize 1
[2023-02-07 20:16:43,403][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5739976 effective words) took 3.0s, 1935659 effective words/s
[2023-02-07 20:16:44,409][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 33.37% examples, 1927110 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:16:45,415][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 66.04% examples, 1925918 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:46,289][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5739976 effective words) took 2.9s, 1990360 effective words/s
[2023-02-07 20:16:47,292][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 43.35% examples, 2550523 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:48,292][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 82.99% examples, 2404703 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:48,704][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5739976 effective words) took 2.4s, 2377512 effective words/s
[2023-02-07 20:16:49,708][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 38.16% examples, 2234797 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:50,709][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 77.25% examples, 2238015 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:16:51,285][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5739976 effective words) took 2.6s, 2225728 effective words/s
[2023-02-07 20:16:52,289][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 37.12% examples, 2181044 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:16:53,290][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 74.82% examples, 2178893 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:53,909][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5739976 effective words) took 2.6s, 2189769 effective words/s
[2023-02-07 20:16:54,914][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 38.16% examples, 2235372 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:55,916][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 76.94% examples, 2229099 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:16:56,488][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5739976 effective words) took 2.6s, 2228808 effective words/s
[2023-02-07 20:16:56,488][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86099640 effective words) took 41.0s, 2102257 effective words/s', 'datetime': '2023-02-07T20:16:56.488889', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:16:56.489 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:17:00,504][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201546-zb9nnj5y/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:17:00.504070', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:17:00,504][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:17:00,614][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201546-zb9nnj5y/files/../tmp/embedding_model.pt
2023-02-07 20:17:00.614 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:17:03.002 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:17:03.813 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:17:06.452 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9069048682552345, 'test_mae': 0.7170607612633998, 'test_r2': -2.0921092672618906}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.85
wandb: percentage 0.51619
wandb:   test_mae 0.71706
wandb:   test_mse 0.9069
wandb:    test_r2 -2.09211
wandb: 
wandb: üöÄ View run peach-sweep-77 at: https://wandb.ai/xiaoqiz/mof2vec/runs/zb9nnj5y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_201546-zb9nnj5y/logs
wandb: Agent Starting Run: 91pha318 with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 964
wandb: 	model.gensim.alpha: 0.0006722587174028791
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.5280112235796761
wandb: 	model.gensim.vector_size: 392
wandb: 	model.gensim.window: 9
wandb: 	model.sklearn.learning_rate: 0.020727700926803944
wandb: 	model.sklearn.max_depth: 51
wandb: 	model.sklearn.min_child_weight: 0.013727791226961626
wandb: 	model.sklearn.n_estimators: 732
wandb: 	model.sklearn.num_leaves: 168
wandb: 	model.sklearn.reg_alpha: 0.012177196348128845
wandb: 	model.sklearn.reg_lambda: 0.07038720636192154
wandb: 	model.sklearn.subsample: 0.932205763596847
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201716-91pha318
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-78
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/91pha318
2023-02-07 20:17:25.394 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 20:17:25.395 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 964 for sweep.
2023-02-07 20:17:25.396 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0006722587174028791 for sweep.
2023-02-07 20:17:25.396 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:17:25.396 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 20:17:25.396 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5280112235796761 for sweep.
2023-02-07 20:17:25.397 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 392 for sweep.
2023-02-07 20:17:25.397 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 9 for sweep.
2023-02-07 20:17:25.397 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.020727700926803944 for sweep.
2023-02-07 20:17:25.397 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 51 for sweep.
2023-02-07 20:17:25.398 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.013727791226961626 for sweep.
2023-02-07 20:17:25.398 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 732 for sweep.
2023-02-07 20:17:25.398 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 168 for sweep.
2023-02-07 20:17:25.398 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.012177196348128845 for sweep.
2023-02-07 20:17:25.399 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.07038720636192154 for sweep.
2023-02-07 20:17:25.399 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.932205763596847 for sweep.
2023-02-07 20:17:25.399 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:17:25.406 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201716-91pha318/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 964, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 392, 'window': 9, 'min_count': 7, 'dm': 0, 'sample': 0.5280112235796761, 'workers': 4, 'alpha': 0.0006722587174028791, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 732, 'max_depth': 51, 'num_leaves': 168, 'reg_alpha': 0.012177196348128845, 'reg_lambda': 0.07038720636192154, 'subsample': 0.932205763596847, 'min_child_weight': 0.013727791226961626, 'n_jobs': 4, 'learning_rate': 0.020727700926803944}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 163.64it/s]  1%|          | 35/3257 [00:00<00:18, 169.85it/s]  2%|‚ñè         | 53/3257 [00:00<00:19, 167.59it/s]  2%|‚ñè         | 72/3257 [00:00<00:18, 174.65it/s]  3%|‚ñé         | 91/3257 [00:00<00:17, 178.06it/s]  3%|‚ñé         | 109/3257 [00:00<00:18, 168.46it/s]  4%|‚ñç         | 127/3257 [00:00<00:18, 170.57it/s]  5%|‚ñç         | 149/3257 [00:00<00:16, 183.97it/s]  5%|‚ñå         | 171/3257 [00:00<00:15, 193.34it/s]  6%|‚ñå         | 194/3257 [00:01<00:15, 202.07it/s]  7%|‚ñã         | 219/3257 [00:01<00:14, 216.12it/s]  8%|‚ñä         | 248/3257 [00:01<00:12, 237.61it/s]  8%|‚ñä         | 272/3257 [00:01<00:12, 235.66it/s]  9%|‚ñâ         | 300/3257 [00:01<00:11, 247.45it/s] 10%|‚ñà         | 328/3257 [00:01<00:11, 249.68it/s] 11%|‚ñà         | 353/3257 [00:01<00:11, 247.19it/s] 12%|‚ñà‚ñè        | 378/3257 [00:01<00:12, 231.08it/s] 12%|‚ñà‚ñè        | 404/3257 [00:01<00:12, 235.14it/s] 13%|‚ñà‚ñé        | 428/3257 [00:02<00:13, 210.43it/s] 14%|‚ñà‚ñç        | 450/3257 [00:02<00:13, 211.55it/s] 15%|‚ñà‚ñç        | 476/3257 [00:02<00:12, 222.28it/s] 15%|‚ñà‚ñå        | 502/3257 [00:02<00:11, 230.46it/s] 16%|‚ñà‚ñå        | 526/3257 [00:02<00:12, 225.33it/s] 17%|‚ñà‚ñã        | 549/3257 [00:02<00:11, 226.33it/s] 18%|‚ñà‚ñä        | 572/3257 [00:02<00:13, 202.25it/s] 18%|‚ñà‚ñä        | 597/3257 [00:02<00:12, 214.74it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:02<00:12, 210.37it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:03<00:12, 216.11it/s] 20%|‚ñà‚ñà        | 666/3257 [00:03<00:12, 203.04it/s] 21%|‚ñà‚ñà        | 687/3257 [00:03<00:12, 200.08it/s] 22%|‚ñà‚ñà‚ñè       | 711/3257 [00:03<00:12, 209.86it/s] 23%|‚ñà‚ñà‚ñé       | 733/3257 [00:03<00:17, 141.96it/s] 23%|‚ñà‚ñà‚ñé       | 751/3257 [00:03<00:17, 146.92it/s] 24%|‚ñà‚ñà‚ñé       | 772/3257 [00:03<00:15, 161.10it/s] 24%|‚ñà‚ñà‚ñç       | 791/3257 [00:03<00:14, 167.38it/s] 25%|‚ñà‚ñà‚ñç       | 812/3257 [00:04<00:13, 175.45it/s] 26%|‚ñà‚ñà‚ñå       | 831/3257 [00:04<00:13, 174.55it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:04<00:13, 172.69it/s] 27%|‚ñà‚ñà‚ñã       | 872/3257 [00:04<00:12, 184.56it/s] 27%|‚ñà‚ñà‚ñã       | 891/3257 [00:04<00:12, 185.70it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:04<00:11, 196.94it/s] 29%|‚ñà‚ñà‚ñâ       | 937/3257 [00:04<00:11, 204.14it/s] 29%|‚ñà‚ñà‚ñâ       | 960/3257 [00:04<00:10, 210.12it/s] 30%|‚ñà‚ñà‚ñà       | 982/3257 [00:04<00:11, 202.87it/s] 31%|‚ñà‚ñà‚ñà       | 1003/3257 [00:05<00:11, 202.94it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:05<00:10, 203.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1046/3257 [00:05<00:11, 191.43it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:05<00:11, 194.94it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:05<00:11, 194.98it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1108/3257 [00:05<00:10, 196.30it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1128/3257 [00:05<00:11, 190.51it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1148/3257 [00:05<00:11, 186.20it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:05<00:10, 197.41it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:06<00:11, 184.65it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:06<00:11, 180.66it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:06<00:10, 193.85it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1254/3257 [00:06<00:10, 197.41it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:06<00:10, 194.19it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1295/3257 [00:06<00:10, 186.52it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1317/3257 [00:06<00:09, 195.26it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1340/3257 [00:06<00:09, 204.01it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1361/3257 [00:06<00:09, 201.19it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1382/3257 [00:06<00:09, 192.13it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1404/3257 [00:07<00:09, 198.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1431/3257 [00:07<00:08, 217.88it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1453/3257 [00:07<00:08, 216.59it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:07<00:08, 220.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1503/3257 [00:07<00:07, 230.98it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1527/3257 [00:07<00:08, 213.85it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1549/3257 [00:07<00:08, 205.51it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1570/3257 [00:07<00:08, 206.35it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:07<00:08, 204.71it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:08<00:07, 216.51it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1639/3257 [00:08<00:07, 211.24it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:08<00:07, 202.54it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1683/3257 [00:08<00:07, 203.15it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1706/3257 [00:08<00:07, 209.71it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:08<00:07, 200.20it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1749/3257 [00:08<00:07, 202.88it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1772/3257 [00:08<00:07, 210.12it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:08<00:06, 214.05it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1818/3257 [00:09<00:06, 213.67it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1840/3257 [00:09<00:06, 213.78it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1863/3257 [00:09<00:06, 218.18it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1885/3257 [00:09<00:06, 217.69it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1908/3257 [00:09<00:06, 218.68it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1930/3257 [00:09<00:06, 213.72it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1959/3257 [00:09<00:05, 235.38it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1983/3257 [00:09<00:05, 217.21it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:09<00:05, 225.04it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2032/3257 [00:09<00:05, 227.96it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2056/3257 [00:10<00:05, 205.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2078/3257 [00:10<00:05, 206.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:10<00:05, 204.18it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:10<00:08, 132.76it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2143/3257 [00:10<00:07, 147.77it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:10<00:06, 171.38it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2193/3257 [00:10<00:05, 186.51it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2214/3257 [00:11<00:05, 191.29it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:11<00:05, 199.87it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:11<00:05, 192.22it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2281/3257 [00:11<00:05, 183.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:11<00:05, 182.13it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2324/3257 [00:11<00:04, 194.09it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2347/3257 [00:11<00:04, 202.41it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2368/3257 [00:11<00:04, 200.92it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2391/3257 [00:11<00:04, 208.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2413/3257 [00:12<00:04, 192.89it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2433/3257 [00:12<00:04, 183.62it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2452/3257 [00:12<00:04, 179.42it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:12<00:04, 190.39it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2496/3257 [00:12<00:03, 193.38it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2519/3257 [00:12<00:03, 200.77it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:12<00:03, 200.04it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2561/3257 [00:12<00:03, 192.80it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2581/3257 [00:12<00:03, 182.08it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2601/3257 [00:13<00:03, 185.59it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2628/3257 [00:13<00:03, 204.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2649/3257 [00:13<00:03, 193.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2669/3257 [00:13<00:03, 189.28it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:13<00:02, 193.75it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2710/3257 [00:13<00:03, 169.75it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2731/3257 [00:13<00:02, 178.76it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2752/3257 [00:13<00:02, 185.40it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2771/3257 [00:14<00:02, 178.61it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2793/3257 [00:14<00:02, 188.75it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:14<00:02, 187.23it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2832/3257 [00:14<00:02, 177.68it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2852/3257 [00:14<00:02, 181.19it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2879/3257 [00:14<00:01, 204.59it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2900/3257 [00:14<00:01, 183.46it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:14<00:01, 186.92it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2940/3257 [00:14<00:01, 189.21it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2960/3257 [00:15<00:01, 177.53it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2979/3257 [00:15<00:01, 178.43it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2999/3257 [00:15<00:01, 183.56it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:15<00:01, 178.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3039/3257 [00:15<00:01, 185.75it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3061/3257 [00:15<00:01, 195.31it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3081/3257 [00:15<00:00, 196.06it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3103/3257 [00:15<00:00, 201.97it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3125/3257 [00:15<00:00, 206.26it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3146/3257 [00:15<00:00, 188.30it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:16<00:00, 186.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:16<00:00, 182.31it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3206/3257 [00:16<00:00, 189.26it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3226/3257 [00:16<00:00, 181.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3250/3257 [00:16<00:00, 196.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 196.38it/s]
2023-02-07 20:17:42.665 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:17:42,666][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d392,n5,mc7,s0.528011,t4>', 'datetime': '2023-02-07T20:17:42.666638', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:17:42,667][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:17:42,667][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:17:43,147][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 20:17:43,148][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:17:43,180][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 9824 unique words (45.27% of original 21699, drops 11875)', 'datetime': '2023-02-07T20:17:43.180097', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:17:43,182][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 4333599 word corpus (99.23% of original 4367244, drops 33645)', 'datetime': '2023-02-07T20:17:43.182177', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:17:43,218][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 20:17:43,219][gensim.models.word2vec][INFO] - sample=0.528011 downsamples 0 most-common words
[2023-02-07 20:17:43,219][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4333599 word corpus (100.0%% of prior 4333599)', 'datetime': '2023-02-07T20:17:43.219672', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:17:43,281][gensim.models.word2vec][INFO] - estimated required memory for 9824 words and 392 dimensions: 41478440 bytes
[2023-02-07 20:17:43,281][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:17:43,307][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 9824 vocabulary and 392 features, using sg=1 hs=0 sample=0.5280112235796761 negative=5 window=9 shrink_windows=True', 'datetime': '2023-02-07T20:17:43.307065', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:17:44,310][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 35.92% examples, 1583053 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:17:45,313][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 73.81% examples, 1619001 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:17:45,881][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4335166 effective words) took 2.6s, 1686225 effective words/s
[2023-02-07 20:17:46,884][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 40.22% examples, 1793909 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:17:47,893][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 80.87% examples, 1757547 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:17:48,357][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4335166 effective words) took 2.5s, 1752153 effective words/s
[2023-02-07 20:17:49,359][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 38.13% examples, 1692470 words/s, in_qsize 6, out_qsize 1
[2023-02-07 20:17:50,364][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 77.43% examples, 1692159 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:17:50,915][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4335166 effective words) took 2.6s, 1696306 effective words/s
[2023-02-07 20:17:51,922][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 38.13% examples, 1683354 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:17:52,929][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 78.14% examples, 1699126 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:17:53,457][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4335166 effective words) took 2.5s, 1706219 effective words/s
[2023-02-07 20:17:54,460][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 38.72% examples, 1717899 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:17:55,464][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 80.32% examples, 1752850 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:17:55,980][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4335166 effective words) took 2.5s, 1719325 effective words/s
[2023-02-07 20:17:56,986][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 35.22% examples, 1552873 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:17:57,986][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 70.83% examples, 1569455 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:17:58,743][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4335166 effective words) took 2.8s, 1571463 effective words/s
[2023-02-07 20:17:59,746][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 35.49% examples, 1563157 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:18:00,754][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 71.05% examples, 1567525 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:18:01,508][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4335166 effective words) took 2.8s, 1569278 effective words/s
[2023-02-07 20:18:02,515][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 35.77% examples, 1566770 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:18:03,515][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 72.34% examples, 1588641 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:18:04,212][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4335166 effective words) took 2.7s, 1604670 effective words/s
[2023-02-07 20:18:05,221][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 43.87% examples, 1935285 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:18:06,225][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 84.96% examples, 1846286 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:06,581][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4335166 effective words) took 2.4s, 1830877 effective words/s
[2023-02-07 20:18:07,583][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 38.50% examples, 1709092 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:18:08,588][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 78.35% examples, 1709987 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:09,117][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4335166 effective words) took 2.5s, 1710943 effective words/s
[2023-02-07 20:18:10,123][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 38.13% examples, 1684676 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:18:11,125][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 78.14% examples, 1703828 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:11,663][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4335166 effective words) took 2.5s, 1703758 effective words/s
[2023-02-07 20:18:12,666][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 38.29% examples, 1700544 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:18:13,667][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 78.48% examples, 1717690 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:18:14,183][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4335166 effective words) took 2.5s, 1722040 effective words/s
[2023-02-07 20:18:15,187][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 35.77% examples, 1571750 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:18:16,188][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 72.34% examples, 1590179 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:18:16,904][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4335166 effective words) took 2.7s, 1594343 effective words/s
[2023-02-07 20:18:17,910][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 36.11% examples, 1588818 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:18:18,915][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 72.74% examples, 1595818 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:18:19,620][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4335166 effective words) took 2.7s, 1598299 effective words/s
[2023-02-07 20:18:20,627][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 35.77% examples, 1563810 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:18:21,633][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 71.66% examples, 1574083 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:18:22,353][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4335166 effective words) took 2.7s, 1586939 effective words/s
[2023-02-07 20:18:22,354][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65027490 effective words) took 39.0s, 1665382 effective words/s', 'datetime': '2023-02-07T20:18:22.354109', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:18:22.355 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:18:24,894][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201716-91pha318/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:18:24.893979', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:18:24,894][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:18:24,949][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201716-91pha318/files/../tmp/embedding_model.pt
2023-02-07 20:18:24.950 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:18:27.122 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:18:27.892 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:18:30.439 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0888052957485932, 'test_mae': 0.7871291857281345, 'test_r2': -2.6444353935550535}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.22
wandb: percentage 0.54726
wandb:   test_mae 0.78713
wandb:   test_mse 1.08881
wandb:    test_r2 -2.64444
wandb: 
wandb: üöÄ View run woven-sweep-78 at: https://wandb.ai/xiaoqiz/mof2vec/runs/91pha318
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_201716-91pha318/logs
wandb: Agent Starting Run: 4pea1vfy with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 722
wandb: 	model.gensim.alpha: 0.006246722219943291
wandb: 	model.gensim.dm: 1
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.6246090833813587
wandb: 	model.gensim.vector_size: 324
wandb: 	model.gensim.window: 16
wandb: 	model.sklearn.learning_rate: 0.00034019289624631074
wandb: 	model.sklearn.max_depth: 57
wandb: 	model.sklearn.min_child_weight: 0.04484588451563675
wandb: 	model.sklearn.n_estimators: 633
wandb: 	model.sklearn.num_leaves: 286
wandb: 	model.sklearn.reg_alpha: 0.01693151916215795
wandb: 	model.sklearn.reg_lambda: 0.3804505055016067
wandb: 	model.sklearn.subsample: 0.9457034449145184
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201841-4pea1vfy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-79
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/4pea1vfy
2023-02-07 20:18:49.599 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:18:49.600 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 722 for sweep.
2023-02-07 20:18:49.600 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.006246722219943291 for sweep.
2023-02-07 20:18:49.601 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 1 for sweep.
2023-02-07 20:18:49.601 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 20:18:49.601 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6246090833813587 for sweep.
2023-02-07 20:18:49.601 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 324 for sweep.
2023-02-07 20:18:49.602 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 16 for sweep.
2023-02-07 20:18:49.602 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.00034019289624631074 for sweep.
2023-02-07 20:18:49.602 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 57 for sweep.
2023-02-07 20:18:49.602 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.04484588451563675 for sweep.
2023-02-07 20:18:49.603 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 633 for sweep.
2023-02-07 20:18:49.603 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 286 for sweep.
2023-02-07 20:18:49.603 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.01693151916215795 for sweep.
2023-02-07 20:18:49.604 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.3804505055016067 for sweep.
2023-02-07 20:18:49.604 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9457034449145184 for sweep.
2023-02-07 20:18:49.604 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:18:49.611 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201841-4pea1vfy/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 722, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 324, 'window': 16, 'min_count': 10, 'dm': 1, 'sample': 0.6246090833813587, 'workers': 4, 'alpha': 0.006246722219943291, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 633, 'max_depth': 57, 'num_leaves': 286, 'reg_alpha': 0.01693151916215795, 'reg_lambda': 0.3804505055016067, 'subsample': 0.9457034449145184, 'min_child_weight': 0.04484588451563675, 'n_jobs': 4, 'learning_rate': 0.00034019289624631074}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:26, 124.01it/s]  1%|          | 29/3257 [00:00<00:22, 141.30it/s]  1%|‚ñè         | 44/3257 [00:00<00:23, 137.49it/s]  2%|‚ñè         | 58/3257 [00:00<00:23, 134.76it/s]  2%|‚ñè         | 73/3257 [00:00<00:22, 139.46it/s]  3%|‚ñé         | 90/3257 [00:00<00:22, 139.82it/s]  3%|‚ñé         | 105/3257 [00:00<00:22, 138.33it/s]  4%|‚ñé         | 119/3257 [00:00<00:22, 136.47it/s]  4%|‚ñç         | 134/3257 [00:00<00:22, 136.13it/s]  5%|‚ñç         | 151/3257 [00:01<00:21, 143.26it/s]  5%|‚ñå         | 166/3257 [00:01<00:22, 138.22it/s]  6%|‚ñå         | 180/3257 [00:01<00:22, 136.79it/s]  6%|‚ñå         | 197/3257 [00:01<00:21, 143.12it/s]  7%|‚ñã         | 214/3257 [00:01<00:20, 149.79it/s]  7%|‚ñã         | 231/3257 [00:01<00:19, 153.84it/s]  8%|‚ñä         | 247/3257 [00:01<00:19, 152.81it/s]  8%|‚ñä         | 263/3257 [00:01<00:20, 144.60it/s]  9%|‚ñä         | 281/3257 [00:01<00:19, 153.10it/s]  9%|‚ñâ         | 297/3257 [00:02<00:19, 148.55it/s] 10%|‚ñâ         | 312/3257 [00:02<00:31, 93.66it/s]  10%|‚ñà         | 329/3257 [00:02<00:27, 107.86it/s] 11%|‚ñà         | 343/3257 [00:02<00:25, 112.53it/s] 11%|‚ñà         | 359/3257 [00:02<00:23, 122.62it/s] 11%|‚ñà‚ñè        | 374/3257 [00:02<00:22, 128.96it/s] 12%|‚ñà‚ñè        | 389/3257 [00:02<00:24, 119.31it/s] 12%|‚ñà‚ñè        | 405/3257 [00:03<00:22, 128.71it/s] 13%|‚ñà‚ñé        | 420/3257 [00:03<00:21, 131.17it/s] 13%|‚ñà‚ñé        | 434/3257 [00:03<00:24, 113.23it/s] 14%|‚ñà‚ñç        | 448/3257 [00:03<00:23, 118.93it/s] 14%|‚ñà‚ñç        | 465/3257 [00:03<00:21, 130.51it/s] 15%|‚ñà‚ñç        | 479/3257 [00:03<00:21, 127.78it/s] 15%|‚ñà‚ñå        | 495/3257 [00:03<00:20, 134.95it/s] 16%|‚ñà‚ñå        | 512/3257 [00:03<00:19, 142.27it/s] 16%|‚ñà‚ñå        | 527/3257 [00:03<00:19, 137.48it/s] 17%|‚ñà‚ñã        | 545/3257 [00:04<00:18, 147.08it/s] 17%|‚ñà‚ñã        | 560/3257 [00:04<00:20, 132.12it/s] 18%|‚ñà‚ñä        | 574/3257 [00:04<00:21, 123.75it/s] 18%|‚ñà‚ñä        | 589/3257 [00:04<00:20, 128.97it/s] 19%|‚ñà‚ñä        | 604/3257 [00:04<00:20, 131.87it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:04<00:19, 132.83it/s] 20%|‚ñà‚ñâ        | 637/3257 [00:04<00:18, 140.50it/s] 20%|‚ñà‚ñà        | 652/3257 [00:04<00:19, 134.48it/s] 20%|‚ñà‚ñà        | 666/3257 [00:05<00:20, 127.18it/s] 21%|‚ñà‚ñà        | 683/3257 [00:05<00:20, 127.92it/s] 21%|‚ñà‚ñà‚ñè       | 697/3257 [00:05<00:19, 130.64it/s] 22%|‚ñà‚ñà‚ñè       | 715/3257 [00:05<00:17, 142.61it/s] 22%|‚ñà‚ñà‚ñè       | 730/3257 [00:05<00:19, 128.44it/s] 23%|‚ñà‚ñà‚ñé       | 744/3257 [00:05<00:19, 127.92it/s] 23%|‚ñà‚ñà‚ñé       | 759/3257 [00:05<00:18, 133.49it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:05<00:18, 132.81it/s] 24%|‚ñà‚ñà‚ñç       | 787/3257 [00:05<00:18, 133.10it/s] 25%|‚ñà‚ñà‚ñç       | 803/3257 [00:06<00:17, 140.10it/s] 25%|‚ñà‚ñà‚ñå       | 818/3257 [00:06<00:18, 133.02it/s] 26%|‚ñà‚ñà‚ñå       | 832/3257 [00:06<00:19, 126.65it/s] 26%|‚ñà‚ñà‚ñå       | 845/3257 [00:06<00:20, 120.14it/s] 26%|‚ñà‚ñà‚ñã       | 860/3257 [00:06<00:18, 126.31it/s] 27%|‚ñà‚ñà‚ñã       | 873/3257 [00:06<00:18, 126.98it/s] 27%|‚ñà‚ñà‚ñã       | 886/3257 [00:06<00:19, 123.98it/s] 28%|‚ñà‚ñà‚ñä       | 903/3257 [00:06<00:17, 135.94it/s] 28%|‚ñà‚ñà‚ñä       | 917/3257 [00:06<00:17, 130.07it/s] 29%|‚ñà‚ñà‚ñä       | 932/3257 [00:07<00:17, 134.65it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:07<00:16, 138.71it/s] 30%|‚ñà‚ñà‚ñâ       | 963/3257 [00:07<00:16, 140.06it/s] 30%|‚ñà‚ñà‚ñà       | 978/3257 [00:07<00:16, 136.38it/s] 30%|‚ñà‚ñà‚ñà       | 992/3257 [00:07<00:17, 130.06it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:07<00:17, 126.18it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1024/3257 [00:07<00:16, 137.13it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1038/3257 [00:07<00:17, 126.03it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:07<00:17, 123.69it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:08<00:16, 130.15it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1082/3257 [00:08<00:16, 135.39it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1101/3257 [00:08<00:14, 149.06it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1119/3257 [00:08<00:13, 153.05it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1138/3257 [00:08<00:13, 162.36it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1155/3257 [00:08<00:12, 162.58it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:08<00:12, 166.98it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1192/3257 [00:08<00:13, 155.59it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1208/3257 [00:08<00:13, 155.24it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:09<00:11, 175.96it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1250/3257 [00:09<00:11, 175.41it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1270/3257 [00:09<00:10, 181.59it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1289/3257 [00:09<00:12, 160.83it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1306/3257 [00:09<00:11, 162.73it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1325/3257 [00:09<00:11, 168.51it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1344/3257 [00:09<00:11, 173.83it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1362/3257 [00:09<00:11, 171.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1380/3257 [00:09<00:10, 171.75it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1399/3257 [00:10<00:10, 175.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1417/3257 [00:10<00:14, 125.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1435/3257 [00:10<00:13, 136.86it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1458/3257 [00:10<00:11, 158.80it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:10<00:10, 163.47it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1500/3257 [00:10<00:09, 178.92it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1519/3257 [00:10<00:10, 172.98it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1538/3257 [00:10<00:10, 168.84it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1556/3257 [00:11<00:10, 167.46it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:11<00:09, 169.33it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:11<00:09, 178.40it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:11<00:08, 186.56it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1636/3257 [00:11<00:09, 178.97it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1655/3257 [00:11<00:09, 170.12it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1673/3257 [00:11<00:10, 156.70it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:11<00:09, 158.26it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1708/3257 [00:11<00:09, 163.93it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1727/3257 [00:12<00:08, 170.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:12<00:09, 151.92it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1765/3257 [00:12<00:09, 162.31it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1785/3257 [00:12<00:08, 171.38it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:12<00:08, 169.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:12<00:08, 168.51it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1839/3257 [00:12<00:08, 166.24it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1857/3257 [00:12<00:08, 168.32it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1878/3257 [00:12<00:07, 179.49it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:13<00:07, 172.73it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:13<00:07, 174.44it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:13<00:07, 183.21it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1963/3257 [00:13<00:06, 203.22it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1984/3257 [00:13<00:06, 187.03it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:13<00:06, 188.79it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2025/3257 [00:13<00:06, 192.82it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2045/3257 [00:13<00:06, 183.90it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2064/3257 [00:13<00:07, 165.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2081/3257 [00:14<00:07, 165.20it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2098/3257 [00:14<00:07, 152.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:14<00:07, 161.79it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:14<00:07, 152.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2150/3257 [00:14<00:07, 150.85it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:14<00:06, 159.23it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2186/3257 [00:14<00:06, 160.30it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2205/3257 [00:14<00:06, 168.51it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2223/3257 [00:14<00:06, 167.28it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2240/3257 [00:15<00:06, 156.68it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:15<00:06, 164.51it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2276/3257 [00:15<00:06, 152.92it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:15<00:05, 166.24it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2321/3257 [00:15<00:05, 178.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2343/3257 [00:15<00:04, 188.33it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2364/3257 [00:15<00:04, 194.01it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2384/3257 [00:15<00:04, 194.22it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2405/3257 [00:15<00:04, 185.39it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2424/3257 [00:16<00:04, 184.30it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:16<00:04, 168.26it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2463/3257 [00:16<00:04, 176.54it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2482/3257 [00:16<00:04, 178.17it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2505/3257 [00:16<00:03, 192.60it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2525/3257 [00:16<00:03, 190.57it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2545/3257 [00:16<00:03, 189.21it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2565/3257 [00:16<00:04, 171.71it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2583/3257 [00:17<00:04, 163.95it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:17<00:03, 165.19it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2624/3257 [00:17<00:03, 185.23it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2643/3257 [00:17<00:03, 179.24it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2662/3257 [00:17<00:03, 169.59it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2684/3257 [00:17<00:03, 180.44it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2703/3257 [00:17<00:03, 161.74it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2720/3257 [00:17<00:03, 160.93it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2742/3257 [00:17<00:02, 176.58it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:18<00:05, 98.66it/s]  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2779/3257 [00:18<00:04, 112.37it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2802/3257 [00:18<00:03, 135.14it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2820/3257 [00:18<00:03, 138.64it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:18<00:02, 141.45it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2859/3257 [00:18<00:02, 160.04it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2883/3257 [00:18<00:02, 180.55it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:19<00:02, 166.61it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2925/3257 [00:19<00:01, 178.70it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2944/3257 [00:19<00:01, 164.51it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2965/3257 [00:19<00:01, 175.41it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:19<00:01, 165.56it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3007/3257 [00:19<00:01, 181.18it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:19<00:01, 175.89it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:19<00:01, 187.05it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3071/3257 [00:20<00:00, 197.40it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3092/3257 [00:20<00:00, 188.00it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3115/3257 [00:20<00:00, 199.45it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3136/3257 [00:20<00:00, 186.08it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3156/3257 [00:20<00:00, 177.33it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3175/3257 [00:20<00:00, 174.70it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3193/3257 [00:20<00:00, 173.60it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3211/3257 [00:20<00:00, 167.54it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3229/3257 [00:20<00:00, 170.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:21<00:00, 177.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 154.58it/s]
2023-02-07 20:19:11.512 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:19:11,513][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d324,n5,w16,mc10,s0.624609,t4>', 'datetime': '2023-02-07T20:19:11.513811', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:19:11,514][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:19:11,514][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:19:12,121][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:19:12,121][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:19:12,176][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 17915 unique words (33.14% of original 54054, drops 36139)', 'datetime': '2023-02-07T20:19:12.176557', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:19:12,176][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 6418960 word corpus (97.99% of original 6550866, drops 131906)', 'datetime': '2023-02-07T20:19:12.176829', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:19:12,238][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:19:12,239][gensim.models.word2vec][INFO] - sample=0.624609 downsamples 0 most-common words
[2023-02-07 20:19:12,239][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6418960 word corpus (100.0%% of prior 6418960)', 'datetime': '2023-02-07T20:19:12.239382', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:19:12,349][gensim.models.word2vec][INFO] - estimated required memory for 17915 words and 324 dimensions: 60265652 bytes
[2023-02-07 20:19:12,349][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:19:12,385][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 17915 vocabulary and 324 features, using sg=0 hs=0 sample=0.6246090833813587 negative=5 window=16 shrink_windows=True', 'datetime': '2023-02-07T20:19:12.385406', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:19:13,393][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 18.18% examples, 1129208 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:14,394][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 36.14% examples, 1163728 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:15,395][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 54.34% examples, 1176574 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:16,406][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 73.84% examples, 1186801 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:17,407][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 93.46% examples, 1191065 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:17,715][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6365106 effective words) took 5.3s, 1194803 effective words/s
[2023-02-07 20:19:18,723][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 19.50% examples, 1199205 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:19,728][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 37.30% examples, 1209976 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:20,736][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 56.09% examples, 1211669 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:21,746][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 75.35% examples, 1209933 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:22,747][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 95.03% examples, 1205741 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:22,988][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6365106 effective words) took 5.3s, 1207772 effective words/s
[2023-02-07 20:19:23,991][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 19.22% examples, 1195143 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:24,998][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 37.06% examples, 1201560 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:26,005][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 56.09% examples, 1213025 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:27,015][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 75.35% examples, 1210961 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:28,018][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 96.07% examples, 1216918 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:28,226][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6365106 effective words) took 5.2s, 1215652 effective words/s
[2023-02-07 20:19:29,244][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 18.18% examples, 1118075 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:30,249][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 35.00% examples, 1118200 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:31,252][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 52.16% examples, 1123042 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:32,261][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 69.54% examples, 1122051 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:33,263][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 88.46% examples, 1123679 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:33,885][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6365106 effective words) took 5.7s, 1125327 effective words/s
[2023-02-07 20:19:34,894][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 17.96% examples, 1116773 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:35,895][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 34.82% examples, 1118033 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:36,896][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 52.47% examples, 1133735 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:37,899][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 74.64% examples, 1202956 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:38,899][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 96.07% examples, 1220799 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:39,084][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6365106 effective words) took 5.2s, 1224829 effective words/s
[2023-02-07 20:19:40,089][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 21.15% examples, 1323968 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:41,094][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 39.85% examples, 1298360 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:42,096][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 57.60% examples, 1244296 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:43,113][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 76.05% examples, 1218627 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:44,124][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 96.78% examples, 1224921 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:44,258][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6365106 effective words) took 5.2s, 1230604 effective words/s
[2023-02-07 20:19:45,261][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 20.94% examples, 1306703 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:46,263][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 39.30% examples, 1280843 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:47,271][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 58.61% examples, 1264270 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:48,276][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 78.72% examples, 1260493 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:49,284][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 97.30% examples, 1233940 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:49,422][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6365106 effective words) took 5.2s, 1232866 effective words/s
[2023-02-07 20:19:50,432][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 17.96% examples, 1115739 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:51,432][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 34.82% examples, 1118485 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:52,434][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 54.10% examples, 1170767 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:53,435][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 74.52% examples, 1199101 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:54,447][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 94.87% examples, 1205888 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:54,685][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6365106 effective words) took 5.3s, 1210003 effective words/s
[2023-02-07 20:19:55,702][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 19.77% examples, 1211898 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:19:56,706][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 36.35% examples, 1165857 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:57,711][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 53.61% examples, 1156637 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:58,718][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 71.26% examples, 1148288 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:19:59,721][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 92.91% examples, 1182854 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:00,046][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6365106 effective words) took 5.4s, 1187848 effective words/s
[2023-02-07 20:20:01,050][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 19.86% examples, 1232540 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:02,060][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 38.19% examples, 1233173 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:03,072][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 55.48% examples, 1196691 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:04,072][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 73.32% examples, 1175375 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:05,087][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 91.37% examples, 1163120 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:05,485][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6365106 effective words) took 5.4s, 1170659 effective words/s
[2023-02-07 20:20:06,491][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 20.94% examples, 1303945 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:07,492][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 39.21% examples, 1275695 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:08,498][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 57.97% examples, 1252627 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:09,503][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 75.59% examples, 1215944 words/s, in_qsize 7, out_qsize 1
[2023-02-07 20:20:10,509][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 94.14% examples, 1197085 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:10,831][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6365106 effective words) took 5.3s, 1191189 effective words/s
[2023-02-07 20:20:11,844][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 19.22% examples, 1185399 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:12,844][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 38.29% examples, 1238891 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:13,855][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 57.45% examples, 1237075 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:14,874][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 76.05% examples, 1215001 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:15,878][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 94.50% examples, 1195577 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:16,183][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6365106 effective words) took 5.3s, 1190128 effective words/s
[2023-02-07 20:20:17,186][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 17.81% examples, 1114758 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:18,189][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 36.63% examples, 1189324 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:19,190][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 56.65% examples, 1228300 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:20,198][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 76.30% examples, 1227923 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:21,209][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 96.53% examples, 1225077 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:21,380][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6365106 effective words) took 5.2s, 1225581 effective words/s
[2023-02-07 20:20:22,385][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 19.40% examples, 1202263 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:23,389][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 37.06% examples, 1202340 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:24,407][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 56.09% examples, 1208744 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:25,417][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 75.35% examples, 1207876 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:20:26,419][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 95.61% examples, 1209082 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:26,632][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6365106 effective words) took 5.2s, 1212458 effective words/s
[2023-02-07 20:20:27,648][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 19.74% examples, 1209872 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:28,653][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 37.55% examples, 1213423 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:29,660][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 56.83% examples, 1224199 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:30,661][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 76.30% examples, 1223461 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:31,669][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 96.68% examples, 1223653 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:20:31,817][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6365106 effective words) took 5.2s, 1228380 effective words/s
[2023-02-07 20:20:31,817][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (95476590 effective words) took 79.4s, 1202006 effective words/s', 'datetime': '2023-02-07T20:20:31.817925', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:20:31.818 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:20:37,804][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201841-4pea1vfy/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:20:37.804708', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:20:37,805][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:20:37,885][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_201841-4pea1vfy/files/../tmp/embedding_model.pt
2023-02-07 20:20:37.885 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:20:40.181 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:20:40.979 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:20:43.108 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.2088444535299272, 'test_mae': 0.8411946066775204, 'test_r2': -2.43938360290631}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.48
wandb: percentage 0.66857
wandb:   test_mae 0.84119
wandb:   test_mse 1.20884
wandb:    test_r2 -2.43938
wandb: 
wandb: üöÄ View run earnest-sweep-79 at: https://wandb.ai/xiaoqiz/mof2vec/runs/4pea1vfy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_201841-4pea1vfy/logs
wandb: Agent Starting Run: 6zf1bka1 with config:
wandb: 	data.data.wl_step: 4
wandb: 	data.nn.batch_size: 924
wandb: 	model.gensim.alpha: 0.007575798104701562
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.7021873112803811
wandb: 	model.gensim.vector_size: 404
wandb: 	model.gensim.window: 17
wandb: 	model.sklearn.learning_rate: 0.0013486803704463157
wandb: 	model.sklearn.max_depth: 51
wandb: 	model.sklearn.min_child_weight: 0.03102084662872402
wandb: 	model.sklearn.n_estimators: 506
wandb: 	model.sklearn.num_leaves: 334
wandb: 	model.sklearn.reg_alpha: 0.009691702111061467
wandb: 	model.sklearn.reg_lambda: 0.010070632066272137
wandb: 	model.sklearn.subsample: 0.88796321875689
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202054-6zf1bka1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-80
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/6zf1bka1
2023-02-07 20:21:04.107 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 4 for sweep.
2023-02-07 20:21:04.108 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 924 for sweep.
2023-02-07 20:21:04.108 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.007575798104701562 for sweep.
2023-02-07 20:21:04.109 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:21:04.109 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 20:21:04.109 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7021873112803811 for sweep.
2023-02-07 20:21:04.110 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 404 for sweep.
2023-02-07 20:21:04.110 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 17 for sweep.
2023-02-07 20:21:04.110 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0013486803704463157 for sweep.
2023-02-07 20:21:04.110 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 51 for sweep.
2023-02-07 20:21:04.110 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03102084662872402 for sweep.
2023-02-07 20:21:04.111 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 506 for sweep.
2023-02-07 20:21:04.111 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 334 for sweep.
2023-02-07 20:21:04.111 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.009691702111061467 for sweep.
2023-02-07 20:21:04.111 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.010070632066272137 for sweep.
2023-02-07 20:21:04.112 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.88796321875689 for sweep.
2023-02-07 20:21:04.112 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:21:04.116 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 4}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202054-6zf1bka1/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 924, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 404, 'window': 17, 'min_count': 8, 'dm': 0, 'sample': 0.7021873112803811, 'workers': 4, 'alpha': 0.007575798104701562, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 506, 'max_depth': 51, 'num_leaves': 334, 'reg_alpha': 0.009691702111061467, 'reg_lambda': 0.010070632066272137, 'subsample': 0.88796321875689, 'min_child_weight': 0.03102084662872402, 'n_jobs': 4, 'learning_rate': 0.0013486803704463157}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 24/3257 [00:00<00:14, 227.58it/s]  2%|‚ñè         | 50/3257 [00:00<00:13, 238.25it/s]  2%|‚ñè         | 77/3257 [00:00<00:12, 251.42it/s]  3%|‚ñé         | 103/3257 [00:00<00:12, 253.17it/s]  4%|‚ñç         | 129/3257 [00:00<00:12, 245.78it/s]  5%|‚ñç         | 154/3257 [00:00<00:12, 245.72it/s]  5%|‚ñå         | 179/3257 [00:00<00:13, 235.93it/s]  6%|‚ñã         | 206/3257 [00:00<00:12, 245.16it/s]  7%|‚ñã         | 236/3257 [00:00<00:11, 258.74it/s]  8%|‚ñä         | 262/3257 [00:01<00:11, 251.26it/s]  9%|‚ñâ         | 291/3257 [00:01<00:11, 262.51it/s] 10%|‚ñâ         | 318/3257 [00:01<00:11, 251.37it/s] 11%|‚ñà         | 344/3257 [00:01<00:11, 247.70it/s] 11%|‚ñà‚ñè        | 370/3257 [00:01<00:11, 249.03it/s] 12%|‚ñà‚ñè        | 395/3257 [00:01<00:12, 233.41it/s] 13%|‚ñà‚ñé        | 421/3257 [00:01<00:11, 237.32it/s] 14%|‚ñà‚ñé        | 445/3257 [00:01<00:12, 216.42it/s] 14%|‚ñà‚ñç        | 471/3257 [00:01<00:12, 226.65it/s] 15%|‚ñà‚ñå        | 495/3257 [00:02<00:12, 228.54it/s] 16%|‚ñà‚ñå        | 520/3257 [00:02<00:11, 232.91it/s] 17%|‚ñà‚ñã        | 544/3257 [00:02<00:11, 233.30it/s] 17%|‚ñà‚ñã        | 568/3257 [00:02<00:12, 216.62it/s] 18%|‚ñà‚ñä        | 590/3257 [00:02<00:12, 210.42it/s] 19%|‚ñà‚ñâ        | 618/3257 [00:02<00:11, 228.87it/s] 20%|‚ñà‚ñâ        | 642/3257 [00:02<00:11, 221.29it/s] 20%|‚ñà‚ñà        | 665/3257 [00:02<00:12, 207.96it/s] 21%|‚ñà‚ñà        | 687/3257 [00:02<00:12, 208.61it/s] 22%|‚ñà‚ñà‚ñè       | 713/3257 [00:03<00:11, 221.04it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:03<00:12, 209.72it/s] 23%|‚ñà‚ñà‚ñé       | 758/3257 [00:03<00:16, 149.89it/s] 24%|‚ñà‚ñà‚ñç       | 780/3257 [00:03<00:15, 164.46it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:03<00:13, 179.34it/s] 25%|‚ñà‚ñà‚ñå       | 824/3257 [00:03<00:13, 182.96it/s] 26%|‚ñà‚ñà‚ñå       | 844/3257 [00:03<00:13, 182.70it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:03<00:12, 190.57it/s] 27%|‚ñà‚ñà‚ñã       | 886/3257 [00:04<00:12, 192.36it/s] 28%|‚ñà‚ñà‚ñä       | 911/3257 [00:04<00:11, 207.42it/s] 29%|‚ñà‚ñà‚ñä       | 934/3257 [00:04<00:10, 212.05it/s] 29%|‚ñà‚ñà‚ñâ       | 959/3257 [00:04<00:10, 218.75it/s] 30%|‚ñà‚ñà‚ñà       | 982/3257 [00:04<00:10, 217.33it/s] 31%|‚ñà‚ñà‚ñà       | 1004/3257 [00:04<00:10, 212.16it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1026/3257 [00:04<00:10, 212.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1048/3257 [00:04<00:10, 203.86it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1074/3257 [00:04<00:09, 218.59it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:05<00:10, 212.28it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1120/3257 [00:05<00:09, 216.58it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1142/3257 [00:05<00:09, 213.93it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1167/3257 [00:05<00:09, 222.41it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1190/3257 [00:05<00:10, 203.92it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1211/3257 [00:05<00:09, 205.38it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1238/3257 [00:05<00:09, 220.63it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1261/3257 [00:05<00:09, 214.41it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1283/3257 [00:05<00:09, 207.73it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1304/3257 [00:06<00:09, 208.33it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1329/3257 [00:06<00:08, 217.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1352/3257 [00:06<00:08, 219.85it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1375/3257 [00:06<00:08, 216.86it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1398/3257 [00:06<00:08, 219.35it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1424/3257 [00:06<00:08, 227.90it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1448/3257 [00:06<00:07, 230.66it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1473/3257 [00:06<00:07, 235.71it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1500/3257 [00:06<00:07, 244.27it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1525/3257 [00:06<00:07, 231.79it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1549/3257 [00:07<00:07, 220.66it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:07<00:07, 224.40it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1599/3257 [00:07<00:07, 230.41it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1625/3257 [00:07<00:06, 237.70it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1649/3257 [00:07<00:07, 225.93it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1672/3257 [00:07<00:07, 220.71it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1695/3257 [00:07<00:07, 222.64it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1720/3257 [00:07<00:06, 229.01it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1743/3257 [00:07<00:07, 213.87it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1770/3257 [00:08<00:06, 227.71it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:08<00:06, 234.23it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:08<00:06, 237.32it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1845/3257 [00:08<00:06, 233.99it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1871/3257 [00:08<00:05, 241.21it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1896/3257 [00:08<00:05, 239.38it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1921/3257 [00:08<00:05, 235.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:08<00:05, 259.66it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1981/3257 [00:08<00:04, 256.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2007/3257 [00:08<00:04, 256.18it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:09<00:04, 252.34it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2059/3257 [00:09<00:05, 235.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2084/3257 [00:09<00:04, 238.23it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2109/3257 [00:09<00:07, 152.64it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2130/3257 [00:09<00:06, 163.01it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2153/3257 [00:09<00:06, 177.88it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2179/3257 [00:09<00:05, 197.73it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:10<00:05, 208.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2227/3257 [00:10<00:04, 212.67it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2250/3257 [00:10<00:04, 215.34it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2273/3257 [00:10<00:04, 213.12it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:10<00:04, 229.03it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2334/3257 [00:10<00:03, 255.78it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2365/3257 [00:10<00:03, 270.67it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2393/3257 [00:10<00:03, 256.83it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2420/3257 [00:10<00:03, 225.60it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2444/3257 [00:11<00:03, 209.11it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2467/3257 [00:11<00:03, 212.58it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2489/3257 [00:11<00:03, 209.20it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2513/3257 [00:11<00:03, 216.58it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2536/3257 [00:11<00:03, 218.96it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2559/3257 [00:11<00:03, 204.31it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2580/3257 [00:11<00:03, 195.61it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:11<00:03, 195.39it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2628/3257 [00:11<00:02, 218.64it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2651/3257 [00:12<00:02, 205.69it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:12<00:02, 205.77it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:12<00:02, 200.19it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2715/3257 [00:12<00:03, 178.53it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:12<00:02, 198.71it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2762/3257 [00:12<00:02, 198.52it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2783/3257 [00:12<00:02, 199.36it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2806/3257 [00:12<00:02, 204.44it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2827/3257 [00:12<00:02, 188.71it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2847/3257 [00:13<00:02, 188.01it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2872/3257 [00:13<00:01, 204.62it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2893/3257 [00:13<00:01, 199.00it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2915/3257 [00:13<00:01, 201.26it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2936/3257 [00:13<00:01, 198.41it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2956/3257 [00:13<00:01, 190.71it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:13<00:01, 192.98it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2996/3257 [00:13<00:01, 194.11it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3017/3257 [00:13<00:01, 198.04it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3039/3257 [00:14<00:01, 204.33it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:14<00:00, 214.46it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3085/3257 [00:14<00:00, 210.12it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3109/3257 [00:14<00:00, 217.53it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3131/3257 [00:14<00:00, 211.21it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3153/3257 [00:14<00:00, 200.10it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3174/3257 [00:14<00:00, 202.17it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3195/3257 [00:14<00:00, 199.51it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3216/3257 [00:14<00:00, 189.86it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3240/3257 [00:15<00:00, 201.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:15<00:00, 215.38it/s]
2023-02-07 20:21:19.768 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:21:19,769][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d404,n5,mc8,s0.702187,t4>', 'datetime': '2023-02-07T20:21:19.769785', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:21:19,770][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:21:19,770][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:21:20,126][gensim.models.doc2vec][INFO] - collected 13061 word types and 3257 unique tags from a corpus of 3257 examples and 3639370 words
[2023-02-07 20:21:20,127][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:21:20,147][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 5936 unique words (45.45% of original 13061, drops 7125)', 'datetime': '2023-02-07T20:21:20.147441', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:21:20,147][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 3618620 word corpus (99.43% of original 3639370, drops 20750)', 'datetime': '2023-02-07T20:21:20.147921', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:21:20,169][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 13061 items
[2023-02-07 20:21:20,170][gensim.models.word2vec][INFO] - sample=0.702187 downsamples 0 most-common words
[2023-02-07 20:21:20,170][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3618620 word corpus (100.0%% of prior 3618620)', 'datetime': '2023-02-07T20:21:20.170750', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:21:20,209][gensim.models.word2vec][INFO] - estimated required memory for 5936 words and 404 dimensions: 28067864 bytes
[2023-02-07 20:21:20,210][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:21:20,227][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 5936 vocabulary and 404 features, using sg=1 hs=0 sample=0.7021873112803811 negative=5 window=17 shrink_windows=True', 'datetime': '2023-02-07T20:21:20.227038', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:21:21,237][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 45.04% examples, 1656575 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:21:22,246][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 94.38% examples, 1701871 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:21:22,349][gensim.models.word2vec][INFO] - EPOCH 0: training on 3639370 raw words (3621877 effective words) took 2.1s, 1710179 effective words/s
[2023-02-07 20:21:23,356][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 53.42% examples, 1980106 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:21:24,052][gensim.models.word2vec][INFO] - EPOCH 1: training on 3639370 raw words (3621877 effective words) took 1.7s, 2129687 effective words/s
[2023-02-07 20:21:25,058][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 61.59% examples, 2258277 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:21:25,687][gensim.models.word2vec][INFO] - EPOCH 2: training on 3639370 raw words (3621877 effective words) took 1.6s, 2217381 effective words/s
[2023-02-07 20:21:26,690][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 57.02% examples, 2115603 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:27,408][gensim.models.word2vec][INFO] - EPOCH 3: training on 3639370 raw words (3621877 effective words) took 1.7s, 2106979 effective words/s
[2023-02-07 20:21:28,411][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 56.77% examples, 2107605 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:29,139][gensim.models.word2vec][INFO] - EPOCH 4: training on 3639370 raw words (3621877 effective words) took 1.7s, 2093942 effective words/s
[2023-02-07 20:21:30,147][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 56.56% examples, 2087104 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:30,857][gensim.models.word2vec][INFO] - EPOCH 5: training on 3639370 raw words (3621877 effective words) took 1.7s, 2110866 effective words/s
[2023-02-07 20:21:31,860][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 56.77% examples, 2105281 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:21:32,561][gensim.models.word2vec][INFO] - EPOCH 6: training on 3639370 raw words (3621877 effective words) took 1.7s, 2126854 effective words/s
[2023-02-07 20:21:33,565][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 58.21% examples, 2154598 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:34,229][gensim.models.word2vec][INFO] - EPOCH 7: training on 3639370 raw words (3621877 effective words) took 1.7s, 2175588 effective words/s
[2023-02-07 20:21:35,237][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 56.56% examples, 2085316 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:21:36,002][gensim.models.word2vec][INFO] - EPOCH 8: training on 3639370 raw words (3621877 effective words) took 1.8s, 2044292 effective words/s
[2023-02-07 20:21:37,006][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 52.53% examples, 1941365 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:21:37,871][gensim.models.word2vec][INFO] - EPOCH 9: training on 3639370 raw words (3621877 effective words) took 1.9s, 1940362 effective words/s
[2023-02-07 20:21:38,881][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 53.21% examples, 1964772 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:21:39,712][gensim.models.word2vec][INFO] - EPOCH 10: training on 3639370 raw words (3621877 effective words) took 1.8s, 1969506 effective words/s
[2023-02-07 20:21:40,717][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 52.13% examples, 1928696 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:41,581][gensim.models.word2vec][INFO] - EPOCH 11: training on 3639370 raw words (3621877 effective words) took 1.9s, 1941271 effective words/s
[2023-02-07 20:21:42,584][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 53.05% examples, 1970643 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:43,410][gensim.models.word2vec][INFO] - EPOCH 12: training on 3639370 raw words (3621877 effective words) took 1.8s, 1983296 effective words/s
[2023-02-07 20:21:44,415][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 63.92% examples, 2348324 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:44,997][gensim.models.word2vec][INFO] - EPOCH 13: training on 3639370 raw words (3621877 effective words) took 1.6s, 2283871 effective words/s
[2023-02-07 20:21:46,000][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 56.19% examples, 2088560 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:21:46,728][gensim.models.word2vec][INFO] - EPOCH 14: training on 3639370 raw words (3621877 effective words) took 1.7s, 2094996 effective words/s
[2023-02-07 20:21:46,728][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 54590550 raw words (54328155 effective words) took 26.5s, 2050018 effective words/s', 'datetime': '2023-02-07T20:21:46.728851', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:21:46.729 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:21:48,962][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202054-6zf1bka1/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:21:48.962870', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:21:48,963][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:21:49,003][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202054-6zf1bka1/files/../tmp/embedding_model.pt
2023-02-07 20:21:49.003 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:21:51.188 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:21:51.940 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:21:54.672 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9404305859082187, 'test_mae': 0.7309911522122979, 'test_r2': -1.769818546093176}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.77
wandb: percentage 0.54552
wandb:   test_mae 0.73099
wandb:   test_mse 0.94043
wandb:    test_r2 -1.76982
wandb: 
wandb: üöÄ View run quiet-sweep-80 at: https://wandb.ai/xiaoqiz/mof2vec/runs/6zf1bka1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_202054-6zf1bka1/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1lb9m0lx with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 556
wandb: 	model.gensim.alpha: 0.07970914795728788
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.6980392821117132
wandb: 	model.gensim.vector_size: 443
wandb: 	model.gensim.window: 16
wandb: 	model.sklearn.learning_rate: 0.007196400248548493
wandb: 	model.sklearn.max_depth: 62
wandb: 	model.sklearn.min_child_weight: 0.05063078676762667
wandb: 	model.sklearn.n_estimators: 1589
wandb: 	model.sklearn.num_leaves: 13
wandb: 	model.sklearn.reg_alpha: 0.1566456136824693
wandb: 	model.sklearn.reg_lambda: 0.25044162605497905
wandb: 	model.sklearn.subsample: 0.9407108376045504
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202214-1lb9m0lx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-81
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/1lb9m0lx
2023-02-07 20:22:23.304 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 20:22:23.305 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 556 for sweep.
2023-02-07 20:22:23.305 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.07970914795728788 for sweep.
2023-02-07 20:22:23.305 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:22:23.305 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 20:22:23.306 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6980392821117132 for sweep.
2023-02-07 20:22:23.306 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 443 for sweep.
2023-02-07 20:22:23.306 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 16 for sweep.
2023-02-07 20:22:23.306 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.007196400248548493 for sweep.
2023-02-07 20:22:23.306 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 62 for sweep.
2023-02-07 20:22:23.307 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05063078676762667 for sweep.
2023-02-07 20:22:23.307 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1589 for sweep.
2023-02-07 20:22:23.307 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 13 for sweep.
2023-02-07 20:22:23.307 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.1566456136824693 for sweep.
2023-02-07 20:22:23.308 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.25044162605497905 for sweep.
2023-02-07 20:22:23.308 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9407108376045504 for sweep.
2023-02-07 20:22:23.308 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:22:23.314 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202214-1lb9m0lx/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 556, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 443, 'window': 16, 'min_count': 8, 'dm': 0, 'sample': 0.6980392821117132, 'workers': 4, 'alpha': 0.07970914795728788, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1589, 'max_depth': 62, 'num_leaves': 13, 'reg_alpha': 0.1566456136824693, 'reg_lambda': 0.25044162605497905, 'subsample': 0.9407108376045504, 'min_child_weight': 0.05063078676762667, 'n_jobs': 4, 'learning_rate': 0.007196400248548493}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 19/3257 [00:00<00:17, 185.35it/s]  1%|‚ñè         | 41/3257 [00:00<00:16, 200.25it/s]  2%|‚ñè         | 63/3257 [00:00<00:15, 207.36it/s]  3%|‚ñé         | 87/3257 [00:00<00:14, 218.26it/s]  3%|‚ñé         | 109/3257 [00:00<00:15, 198.52it/s]  4%|‚ñç         | 131/3257 [00:00<00:15, 201.92it/s]  5%|‚ñç         | 154/3257 [00:00<00:14, 207.04it/s]  5%|‚ñå         | 175/3257 [00:00<00:15, 202.85it/s]  6%|‚ñå         | 199/3257 [00:00<00:14, 213.51it/s]  7%|‚ñã         | 224/3257 [00:01<00:13, 223.97it/s]  8%|‚ñä         | 247/3257 [00:01<00:13, 224.07it/s]  8%|‚ñä         | 270/3257 [00:01<00:14, 211.64it/s]  9%|‚ñâ         | 297/3257 [00:01<00:13, 226.65it/s] 10%|‚ñâ         | 320/3257 [00:01<00:13, 223.92it/s] 11%|‚ñà         | 343/3257 [00:01<00:13, 220.05it/s] 11%|‚ñà         | 366/3257 [00:01<00:18, 155.42it/s] 12%|‚ñà‚ñè        | 386/3257 [00:01<00:17, 160.73it/s] 13%|‚ñà‚ñé        | 410/3257 [00:02<00:15, 178.80it/s] 13%|‚ñà‚ñé        | 430/3257 [00:02<00:16, 169.02it/s] 14%|‚ñà‚ñç        | 450/3257 [00:02<00:16, 174.93it/s] 15%|‚ñà‚ñç        | 474/3257 [00:02<00:14, 189.33it/s] 15%|‚ñà‚ñå        | 497/3257 [00:02<00:13, 199.75it/s] 16%|‚ñà‚ñå        | 519/3257 [00:02<00:13, 205.23it/s] 17%|‚ñà‚ñã        | 541/3257 [00:02<00:13, 208.30it/s] 17%|‚ñà‚ñã        | 563/3257 [00:02<00:13, 193.57it/s] 18%|‚ñà‚ñä        | 583/3257 [00:02<00:14, 190.94it/s] 19%|‚ñà‚ñä        | 607/3257 [00:03<00:12, 204.01it/s] 19%|‚ñà‚ñâ        | 628/3257 [00:03<00:12, 205.20it/s] 20%|‚ñà‚ñâ        | 649/3257 [00:03<00:12, 201.89it/s] 21%|‚ñà‚ñà        | 670/3257 [00:03<00:13, 198.09it/s] 21%|‚ñà‚ñà        | 690/3257 [00:03<00:13, 192.79it/s] 22%|‚ñà‚ñà‚ñè       | 715/3257 [00:03<00:12, 207.59it/s] 23%|‚ñà‚ñà‚ñé       | 736/3257 [00:03<00:13, 189.25it/s] 23%|‚ñà‚ñà‚ñé       | 757/3257 [00:03<00:12, 193.31it/s] 24%|‚ñà‚ñà‚ñç       | 777/3257 [00:03<00:12, 194.11it/s] 25%|‚ñà‚ñà‚ñç       | 799/3257 [00:04<00:12, 198.12it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:04<00:12, 199.42it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:04<00:12, 189.68it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:04<00:12, 198.79it/s] 27%|‚ñà‚ñà‚ñã       | 885/3257 [00:04<00:12, 197.45it/s] 28%|‚ñà‚ñà‚ñä       | 910/3257 [00:04<00:11, 211.36it/s] 29%|‚ñà‚ñà‚ñä       | 932/3257 [00:04<00:11, 210.83it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:04<00:10, 217.49it/s] 30%|‚ñà‚ñà‚ñà       | 979/3257 [00:04<00:10, 214.89it/s] 31%|‚ñà‚ñà‚ñà       | 1001/3257 [00:05<00:10, 210.32it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1023/3257 [00:05<00:10, 211.70it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1045/3257 [00:05<00:11, 193.77it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:05<00:11, 198.64it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1089/3257 [00:05<00:10, 203.87it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1111/3257 [00:05<00:10, 206.55it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1132/3257 [00:05<00:10, 199.32it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1154/3257 [00:05<00:10, 203.54it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1177/3257 [00:05<00:10, 207.84it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1198/3257 [00:05<00:10, 198.36it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:06<00:11, 179.23it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1240/3257 [00:06<00:10, 189.43it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1260/3257 [00:06<00:11, 175.70it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1278/3257 [00:06<00:11, 165.13it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1295/3257 [00:06<00:12, 160.09it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:06<00:11, 163.91it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1330/3257 [00:06<00:11, 164.35it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:06<00:11, 166.97it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1367/3257 [00:07<00:11, 165.81it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1384/3257 [00:07<00:11, 163.51it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:07<00:11, 166.11it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1424/3257 [00:07<00:10, 180.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1443/3257 [00:07<00:10, 178.46it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1464/3257 [00:07<00:09, 186.33it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1483/3257 [00:07<00:09, 186.15it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1505/3257 [00:07<00:08, 194.84it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1525/3257 [00:07<00:09, 179.31it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1544/3257 [00:08<00:10, 165.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1562/3257 [00:08<00:10, 169.26it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1580/3257 [00:08<00:10, 166.05it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1598/3257 [00:08<00:09, 167.14it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:08<00:09, 168.62it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:08<00:10, 160.19it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1651/3257 [00:08<00:10, 156.29it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1667/3257 [00:08<00:10, 155.94it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1683/3257 [00:09<00:17, 92.05it/s]  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:09<00:14, 106.76it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1717/3257 [00:09<00:12, 118.69it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1732/3257 [00:09<00:12, 121.97it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1749/3257 [00:09<00:11, 132.88it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1767/3257 [00:09<00:10, 143.22it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1786/3257 [00:09<00:09, 154.02it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1803/3257 [00:09<00:09, 157.30it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1820/3257 [00:09<00:09, 158.33it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1837/3257 [00:10<00:08, 157.89it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1854/3257 [00:10<00:08, 159.85it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1871/3257 [00:10<00:08, 160.83it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1888/3257 [00:10<00:08, 160.93it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1905/3257 [00:10<00:08, 161.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1922/3257 [00:10<00:08, 160.59it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1943/3257 [00:10<00:07, 174.12it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1963/3257 [00:10<00:07, 178.75it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1981/3257 [00:10<00:07, 169.72it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1999/3257 [00:11<00:07, 169.30it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2017/3257 [00:11<00:07, 166.49it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:11<00:07, 169.43it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2053/3257 [00:11<00:07, 158.53it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2070/3257 [00:11<00:07, 156.56it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2088/3257 [00:11<00:07, 160.65it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2105/3257 [00:11<00:07, 158.24it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:11<00:07, 147.44it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2139/3257 [00:11<00:07, 154.03it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2155/3257 [00:12<00:07, 154.05it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2176/3257 [00:12<00:06, 168.89it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2194/3257 [00:12<00:06, 163.53it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2211/3257 [00:12<00:06, 155.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2231/3257 [00:12<00:06, 167.06it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2248/3257 [00:12<00:06, 166.26it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2267/3257 [00:12<00:05, 171.43it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2285/3257 [00:12<00:05, 172.60it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2303/3257 [00:12<00:05, 171.93it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2327/3257 [00:13<00:04, 190.35it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2348/3257 [00:13<00:04, 195.10it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2368/3257 [00:13<00:04, 196.04it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2390/3257 [00:13<00:04, 200.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2411/3257 [00:13<00:04, 189.45it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2431/3257 [00:13<00:04, 179.23it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2450/3257 [00:13<00:04, 173.51it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2474/3257 [00:13<00:04, 190.22it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2494/3257 [00:13<00:04, 187.71it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:14<00:03, 188.93it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2536/3257 [00:14<00:03, 196.20it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2556/3257 [00:14<00:03, 183.01it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2575/3257 [00:14<00:03, 170.87it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2593/3257 [00:14<00:04, 165.67it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2622/3257 [00:14<00:03, 196.82it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2644/3257 [00:14<00:03, 202.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2666/3257 [00:14<00:02, 207.50it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2691/3257 [00:14<00:02, 216.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2713/3257 [00:15<00:02, 205.05it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:15<00:02, 222.79it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2766/3257 [00:15<00:02, 229.66it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2790/3257 [00:15<00:02, 231.53it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2814/3257 [00:15<00:01, 228.39it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:15<00:01, 224.63it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2867/3257 [00:15<00:01, 245.42it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2892/3257 [00:15<00:01, 246.68it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2917/3257 [00:15<00:01, 232.08it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2942/3257 [00:15<00:01, 236.04it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:16<00:01, 224.71it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2989/3257 [00:16<00:01, 213.81it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3016/3257 [00:16<00:01, 223.74it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3043/3257 [00:16<00:00, 234.65it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3069/3257 [00:16<00:00, 240.28it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3094/3257 [00:16<00:00, 238.43it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3120/3257 [00:16<00:00, 244.09it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3145/3257 [00:17<00:00, 134.09it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:17<00:00, 145.19it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:17<00:00, 155.01it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:17<00:00, 165.01it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3227/3257 [00:17<00:00, 171.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:17<00:00, 185.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:17<00:00, 184.07it/s]
2023-02-07 20:22:41.588 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:22:41,589][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d443,n5,mc8,s0.698039,t4>', 'datetime': '2023-02-07T20:22:41.589784', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:22:41,590][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:22:41,590][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:22:41,984][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 20:22:41,984][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:22:42,014][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 9584 unique words (44.17% of original 21699, drops 12115)', 'datetime': '2023-02-07T20:22:42.014260', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:22:42,015][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 4331919 word corpus (99.19% of original 4367244, drops 35325)', 'datetime': '2023-02-07T20:22:42.015554', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:22:42,049][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 20:22:42,050][gensim.models.word2vec][INFO] - sample=0.698039 downsamples 0 most-common words
[2023-02-07 20:22:42,050][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4331919 word corpus (100.0%% of prior 4331919)', 'datetime': '2023-02-07T20:22:42.050424', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:22:42,108][gensim.models.word2vec][INFO] - estimated required memory for 9584 words and 443 dimensions: 45180500 bytes
[2023-02-07 20:22:42,108][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:22:42,134][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 9584 vocabulary and 443 features, using sg=1 hs=0 sample=0.6980392821117132 negative=5 window=16 shrink_windows=True', 'datetime': '2023-02-07T20:22:42.134821', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:22:43,143][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 42.89% examples, 1902875 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:22:44,146][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 88.12% examples, 1913728 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:22:44,397][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4333519 effective words) took 2.3s, 1916742 effective words/s
[2023-02-07 20:22:45,405][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 47.22% examples, 2082751 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:46,410][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 96.81% examples, 2089638 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:22:46,464][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4333519 effective words) took 2.1s, 2099084 effective words/s
[2023-02-07 20:22:47,469][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 45.81% examples, 2014203 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:22:48,471][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 89.28% examples, 1942952 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:22:48,701][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4333519 effective words) took 2.2s, 1937819 effective words/s
[2023-02-07 20:22:49,704][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 41.88% examples, 1866763 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:22:50,709][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 85.23% examples, 1859534 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:22:51,029][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4333519 effective words) took 2.3s, 1862857 effective words/s
[2023-02-07 20:22:52,033][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 41.48% examples, 1849706 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:22:53,044][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 85.23% examples, 1853942 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:53,361][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4333519 effective words) took 2.3s, 1860697 effective words/s
[2023-02-07 20:22:54,368][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 42.19% examples, 1874795 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:22:55,368][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 86.12% examples, 1874430 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:22:55,680][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4333519 effective words) took 2.3s, 1870425 effective words/s
[2023-02-07 20:22:56,685][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.24% examples, 2360457 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:22:57,512][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4333519 effective words) took 1.8s, 2368223 effective words/s
[2023-02-07 20:22:58,520][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 53.85% examples, 2379673 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:22:59,355][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4333519 effective words) took 1.8s, 2352391 effective words/s
[2023-02-07 20:23:00,362][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 47.22% examples, 2085317 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:23:01,373][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 96.81% examples, 2084251 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:01,431][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4333519 effective words) took 2.1s, 2088902 effective words/s
[2023-02-07 20:23:02,433][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 45.32% examples, 2002564 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:03,447][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 95.09% examples, 2050870 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:03,537][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4333519 effective words) took 2.1s, 2060097 effective words/s
[2023-02-07 20:23:04,546][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 47.37% examples, 2079892 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:05,548][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 95.67% examples, 2064501 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:05,636][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4333519 effective words) took 2.1s, 2066374 effective words/s
[2023-02-07 20:23:06,638][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 46.70% examples, 2057398 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:23:07,640][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 95.98% examples, 2076855 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:23:07,724][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4333519 effective words) took 2.1s, 2076761 effective words/s
[2023-02-07 20:23:08,736][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 47.37% examples, 2077472 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:09,745][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 96.81% examples, 2082608 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:23:09,800][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4333519 effective words) took 2.1s, 2090953 effective words/s
[2023-02-07 20:23:10,806][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 46.70% examples, 2052600 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:11,807][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 94.87% examples, 2058175 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:11,912][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4333519 effective words) took 2.1s, 2055174 effective words/s
[2023-02-07 20:23:12,921][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 45.32% examples, 1995892 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:23:13,921][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 91.77% examples, 1999824 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:23:14,083][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4333519 effective words) took 2.2s, 2000201 effective words/s
[2023-02-07 20:23:14,084][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65002785 effective words) took 31.9s, 2034578 effective words/s', 'datetime': '2023-02-07T20:23:14.084285', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:23:14.084 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:23:16,591][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202214-1lb9m0lx/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:23:16.591250', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:23:16,592][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:23:16,649][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202214-1lb9m0lx/files/../tmp/embedding_model.pt
2023-02-07 20:23:16.650 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:23:18.882 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:23:19.665 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:23:22.522 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0505300141441836, 'test_mae': 0.7875417902882845, 'test_r2': -2.8642292895101886}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.93
wandb: percentage 0.55832
wandb:   test_mae 0.78754
wandb:   test_mse 1.05053
wandb:    test_r2 -2.86423
wandb: 
wandb: üöÄ View run scarlet-sweep-81 at: https://wandb.ai/xiaoqiz/mof2vec/runs/1lb9m0lx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_202214-1lb9m0lx/logs
wandb: Agent Starting Run: vnjrl6ql with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 454
wandb: 	model.gensim.alpha: 0.02288229654980565
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.5839395535525924
wandb: 	model.gensim.vector_size: 506
wandb: 	model.gensim.window: 18
wandb: 	model.sklearn.learning_rate: 0.03907848179845296
wandb: 	model.sklearn.max_depth: 38
wandb: 	model.sklearn.min_child_weight: 0.004765049499019574
wandb: 	model.sklearn.n_estimators: 202
wandb: 	model.sklearn.num_leaves: 107
wandb: 	model.sklearn.reg_alpha: 0.011582933132959971
wandb: 	model.sklearn.reg_lambda: 0.09159006825882464
wandb: 	model.sklearn.subsample: 0.8248230135165178
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202333-vnjrl6ql
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-82
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/vnjrl6ql
2023-02-07 20:23:41.717 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:23:41.718 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 454 for sweep.
2023-02-07 20:23:41.718 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.02288229654980565 for sweep.
2023-02-07 20:23:41.719 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:23:41.719 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 20:23:41.719 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5839395535525924 for sweep.
2023-02-07 20:23:41.719 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 506 for sweep.
2023-02-07 20:23:41.719 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 18 for sweep.
2023-02-07 20:23:41.720 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.03907848179845296 for sweep.
2023-02-07 20:23:41.720 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 38 for sweep.
2023-02-07 20:23:41.720 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.004765049499019574 for sweep.
2023-02-07 20:23:41.720 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 202 for sweep.
2023-02-07 20:23:41.720 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 107 for sweep.
2023-02-07 20:23:41.721 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.011582933132959971 for sweep.
2023-02-07 20:23:41.721 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.09159006825882464 for sweep.
2023-02-07 20:23:41.721 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8248230135165178 for sweep.
2023-02-07 20:23:41.721 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:23:41.724 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202333-vnjrl6ql/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 454, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 506, 'window': 18, 'min_count': 9, 'dm': 0, 'sample': 0.5839395535525924, 'workers': 4, 'alpha': 0.02288229654980565, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 202, 'max_depth': 38, 'num_leaves': 107, 'reg_alpha': 0.011582933132959971, 'reg_lambda': 0.09159006825882464, 'subsample': 0.8248230135165178, 'min_child_weight': 0.004765049499019574, 'n_jobs': 4, 'learning_rate': 0.03907848179845296}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:20, 158.53it/s]  1%|          | 34/3257 [00:00<00:19, 161.93it/s]  2%|‚ñè         | 51/3257 [00:00<00:19, 164.18it/s]  2%|‚ñè         | 68/3257 [00:00<00:19, 159.73it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 171.14it/s]  3%|‚ñé         | 108/3257 [00:00<00:19, 164.00it/s]  4%|‚ñç         | 125/3257 [00:00<00:18, 165.26it/s]  4%|‚ñç         | 146/3257 [00:00<00:17, 178.18it/s]  5%|‚ñå         | 164/3257 [00:00<00:18, 168.91it/s]  6%|‚ñå         | 184/3257 [00:01<00:17, 174.89it/s]  6%|‚ñå         | 202/3257 [00:01<00:17, 175.64it/s]  7%|‚ñã         | 226/3257 [00:01<00:15, 193.94it/s]  8%|‚ñä         | 246/3257 [00:01<00:15, 194.05it/s]  8%|‚ñä         | 266/3257 [00:01<00:16, 185.58it/s]  9%|‚ñâ         | 289/3257 [00:01<00:15, 197.03it/s]  9%|‚ñâ         | 309/3257 [00:01<00:16, 179.93it/s] 10%|‚ñà         | 328/3257 [00:01<00:16, 179.41it/s] 11%|‚ñà         | 347/3257 [00:01<00:16, 172.66it/s] 11%|‚ñà         | 365/3257 [00:02<00:16, 174.11it/s] 12%|‚ñà‚ñè        | 383/3257 [00:02<00:17, 163.38it/s] 12%|‚ñà‚ñè        | 400/3257 [00:02<00:18, 157.14it/s] 13%|‚ñà‚ñé        | 419/3257 [00:02<00:17, 163.64it/s] 13%|‚ñà‚ñé        | 436/3257 [00:02<00:20, 137.30it/s] 14%|‚ñà‚ñç        | 453/3257 [00:02<00:19, 143.93it/s] 14%|‚ñà‚ñç        | 472/3257 [00:02<00:18, 153.65it/s] 15%|‚ñà‚ñç        | 488/3257 [00:02<00:18, 151.43it/s] 16%|‚ñà‚ñå        | 506/3257 [00:03<00:17, 158.95it/s] 16%|‚ñà‚ñå        | 523/3257 [00:03<00:17, 159.97it/s] 17%|‚ñà‚ñã        | 540/3257 [00:03<00:16, 162.33it/s] 17%|‚ñà‚ñã        | 557/3257 [00:03<00:16, 164.06it/s] 18%|‚ñà‚ñä        | 574/3257 [00:03<00:18, 144.09it/s] 18%|‚ñà‚ñä        | 593/3257 [00:03<00:17, 155.31it/s] 19%|‚ñà‚ñâ        | 612/3257 [00:03<00:16, 164.16it/s] 19%|‚ñà‚ñâ        | 629/3257 [00:03<00:16, 161.05it/s] 20%|‚ñà‚ñâ        | 646/3257 [00:03<00:16, 154.27it/s] 20%|‚ñà‚ñà        | 662/3257 [00:04<00:17, 146.80it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:16, 151.68it/s] 21%|‚ñà‚ñà‚ñè       | 700/3257 [00:04<00:16, 155.62it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:04<00:15, 162.55it/s] 23%|‚ñà‚ñà‚ñé       | 737/3257 [00:04<00:16, 154.36it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:04<00:16, 155.52it/s] 24%|‚ñà‚ñà‚ñé       | 773/3257 [00:04<00:15, 160.37it/s] 24%|‚ñà‚ñà‚ñç       | 790/3257 [00:04<00:15, 155.89it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:17, 143.86it/s] 25%|‚ñà‚ñà‚ñå       | 821/3257 [00:05<00:17, 141.93it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:05<00:18, 130.68it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:05<00:19, 122.15it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:05<00:19, 123.05it/s] 27%|‚ñà‚ñà‚ñã       | 877/3257 [00:05<00:20, 117.57it/s] 27%|‚ñà‚ñà‚ñã       | 891/3257 [00:05<00:19, 121.74it/s] 28%|‚ñà‚ñà‚ñä       | 906/3257 [00:05<00:18, 126.15it/s] 28%|‚ñà‚ñà‚ñä       | 919/3257 [00:05<00:18, 125.81it/s] 29%|‚ñà‚ñà‚ñä       | 933/3257 [00:06<00:18, 127.08it/s] 29%|‚ñà‚ñà‚ñâ       | 947/3257 [00:06<00:17, 130.11it/s] 30%|‚ñà‚ñà‚ñâ       | 961/3257 [00:06<00:17, 130.86it/s] 30%|‚ñà‚ñà‚ñâ       | 975/3257 [00:06<00:17, 131.08it/s] 30%|‚ñà‚ñà‚ñà       | 989/3257 [00:06<00:18, 123.22it/s] 31%|‚ñà‚ñà‚ñà       | 1002/3257 [00:06<00:18, 122.07it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:06<00:18, 121.63it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1028/3257 [00:06<00:19, 116.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:06<00:19, 115.42it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1055/3257 [00:07<00:18, 122.01it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1068/3257 [00:07<00:17, 123.56it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1081/3257 [00:07<00:18, 119.46it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:07<00:18, 119.36it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1108/3257 [00:07<00:17, 124.54it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1121/3257 [00:07<00:17, 121.79it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1134/3257 [00:07<00:30, 69.71it/s]  35%|‚ñà‚ñà‚ñà‚ñå      | 1146/3257 [00:08<00:27, 78.15it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1164/3257 [00:08<00:21, 98.24it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1177/3257 [00:08<00:19, 104.88it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1190/3257 [00:08<00:19, 105.42it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1204/3257 [00:08<00:18, 113.75it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1218/3257 [00:08<00:17, 119.90it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1240/3257 [00:08<00:13, 145.23it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1256/3257 [00:08<00:14, 140.60it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1274/3257 [00:08<00:13, 150.71it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:09<00:14, 137.16it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1305/3257 [00:09<00:14, 137.45it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:09<00:13, 140.62it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:09<00:13, 146.53it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:09<00:13, 139.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:09<00:13, 141.61it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:09<00:13, 139.74it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:09<00:12, 143.52it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:09<00:11, 156.58it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1438/3257 [00:10<00:12, 150.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1458/3257 [00:10<00:11, 163.25it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1475/3257 [00:10<00:11, 161.90it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1492/3257 [00:10<00:10, 163.89it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1511/3257 [00:10<00:10, 168.69it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1528/3257 [00:10<00:11, 153.29it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1544/3257 [00:10<00:11, 144.56it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1560/3257 [00:10<00:11, 148.04it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1576/3257 [00:10<00:11, 149.12it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1595/3257 [00:11<00:10, 158.53it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:11<00:09, 166.95it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1632/3257 [00:11<00:09, 167.81it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1649/3257 [00:11<00:10, 149.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1665/3257 [00:11<00:10, 149.83it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1681/3257 [00:11<00:10, 147.51it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1696/3257 [00:11<00:10, 142.80it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1712/3257 [00:11<00:10, 146.80it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1727/3257 [00:11<00:10, 144.68it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1742/3257 [00:12<00:12, 121.31it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1760/3257 [00:12<00:11, 132.94it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1774/3257 [00:12<00:11, 134.30it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1791/3257 [00:12<00:10, 142.81it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1806/3257 [00:12<00:10, 134.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:12<00:10, 137.20it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1835/3257 [00:12<00:10, 131.71it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:12<00:10, 133.57it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1865/3257 [00:12<00:09, 139.68it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1880/3257 [00:13<00:09, 139.51it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:13<00:09, 137.53it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1911/3257 [00:13<00:09, 143.73it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1926/3257 [00:13<00:09, 137.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1946/3257 [00:13<00:08, 152.78it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:13<00:08, 159.13it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1982/3257 [00:13<00:08, 152.34it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1998/3257 [00:13<00:08, 153.38it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2014/3257 [00:13<00:08, 145.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2032/3257 [00:14<00:07, 154.79it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2048/3257 [00:14<00:08, 135.53it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2063/3257 [00:14<00:09, 127.16it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2078/3257 [00:14<00:09, 129.64it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2092/3257 [00:14<00:08, 131.60it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2106/3257 [00:14<00:08, 128.01it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:14<00:09, 122.71it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2135/3257 [00:14<00:08, 129.90it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2149/3257 [00:15<00:08, 131.68it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:15<00:07, 144.62it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2183/3257 [00:15<00:07, 143.55it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2202/3257 [00:15<00:06, 153.95it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2218/3257 [00:15<00:06, 149.78it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:15<00:06, 155.23it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2252/3257 [00:15<00:06, 155.11it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2268/3257 [00:15<00:06, 152.09it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2284/3257 [00:16<00:10, 89.66it/s]  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:16<00:09, 100.16it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2317/3257 [00:16<00:08, 116.56it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:16<00:06, 135.47it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:16<00:05, 152.98it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2379/3257 [00:16<00:05, 161.91it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2398/3257 [00:16<00:05, 168.53it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2416/3257 [00:16<00:05, 159.92it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2433/3257 [00:17<00:05, 152.69it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2449/3257 [00:17<00:05, 150.67it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2471/3257 [00:17<00:04, 168.76it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2489/3257 [00:17<00:04, 165.00it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2509/3257 [00:17<00:04, 174.62it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2529/3257 [00:17<00:04, 179.67it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2548/3257 [00:17<00:03, 180.65it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2567/3257 [00:17<00:04, 162.10it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2584/3257 [00:17<00:04, 148.35it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:18<00:04, 144.15it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2619/3257 [00:18<00:04, 153.02it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2635/3257 [00:18<00:04, 152.33it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2651/3257 [00:18<00:04, 140.76it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2666/3257 [00:18<00:04, 139.49it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2682/3257 [00:18<00:04, 143.56it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2697/3257 [00:18<00:04, 135.42it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2711/3257 [00:18<00:04, 124.49it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2726/3257 [00:18<00:04, 130.57it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2744/3257 [00:19<00:03, 142.38it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2759/3257 [00:19<00:03, 142.36it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:19<00:03, 132.12it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2792/3257 [00:19<00:03, 144.35it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2807/3257 [00:19<00:03, 141.62it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2822/3257 [00:19<00:03, 139.40it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:19<00:03, 131.84it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:19<00:02, 137.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2873/3257 [00:19<00:02, 154.04it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2889/3257 [00:20<00:02, 146.70it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2904/3257 [00:20<00:02, 133.65it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:20<00:02, 137.70it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2935/3257 [00:20<00:02, 134.81it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2949/3257 [00:20<00:02, 123.41it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2964/3257 [00:20<00:02, 129.89it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2978/3257 [00:20<00:02, 124.08it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2991/3257 [00:20<00:02, 125.06it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:21<00:01, 142.62it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3027/3257 [00:21<00:01, 146.39it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:21<00:01, 161.98it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3070/3257 [00:21<00:01, 177.63it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3088/3257 [00:21<00:00, 173.72it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:21<00:00, 184.64it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3130/3257 [00:21<00:00, 186.59it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3149/3257 [00:21<00:00, 176.05it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3167/3257 [00:21<00:00, 176.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3185/3257 [00:22<00:00, 168.45it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3204/3257 [00:22<00:00, 173.64it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3222/3257 [00:22<00:00, 164.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3243/3257 [00:22<00:00, 176.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 145.27it/s]
2023-02-07 20:24:05.019 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:24:05,020][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d506,n5,mc9,s0.58394,t4>', 'datetime': '2023-02-07T20:24:05.020340', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:24:05,020][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:24:05,020][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:24:05,651][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:24:05,652][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:24:05,715][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 18315 unique words (33.88% of original 54054, drops 35739)', 'datetime': '2023-02-07T20:24:05.715734', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:24:05,716][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 6422560 word corpus (98.04% of original 6550866, drops 128306)', 'datetime': '2023-02-07T20:24:05.716177', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:24:05,783][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:24:05,785][gensim.models.word2vec][INFO] - sample=0.58394 downsamples 0 most-common words
[2023-02-07 20:24:05,786][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6422560 word corpus (100.0%% of prior 6422560)', 'datetime': '2023-02-07T20:24:05.786007', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:24:05,902][gensim.models.word2vec][INFO] - estimated required memory for 18315 words and 506 dimensions: 90540188 bytes
[2023-02-07 20:24:05,902][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:24:05,952][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18315 vocabulary and 506 features, using sg=1 hs=0 sample=0.5839395535525924 negative=5 window=18 shrink_windows=True', 'datetime': '2023-02-07T20:24:05.952881', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:24:06,966][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 21.55% examples, 1340410 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:07,970][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 42.40% examples, 1380174 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:08,975][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 65.43% examples, 1407899 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:09,977][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 95.98% examples, 1520217 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:10,100][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6368654 effective words) took 4.1s, 1536558 effective words/s
[2023-02-07 20:24:11,103][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 28.06% examples, 1798153 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:12,105][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 53.91% examples, 1756038 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:13,107][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 81.15% examples, 1734659 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:13,785][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6368654 effective words) took 3.7s, 1729172 effective words/s
[2023-02-07 20:24:14,800][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 27.79% examples, 1757655 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:15,808][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 54.47% examples, 1756936 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:16,808][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 82.32% examples, 1749674 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:17,420][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6368654 effective words) took 3.6s, 1753028 effective words/s
[2023-02-07 20:24:18,434][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 27.79% examples, 1759582 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:19,437][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 54.47% examples, 1762261 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:20,439][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 82.96% examples, 1770638 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:21,012][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6368654 effective words) took 3.6s, 1774152 effective words/s
[2023-02-07 20:24:22,023][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 28.55% examples, 1806078 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:23,030][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 56.09% examples, 1814405 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:24,040][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 85.97% examples, 1822992 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:24,487][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6368654 effective words) took 3.5s, 1833436 effective words/s
[2023-02-07 20:24:25,494][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 24.78% examples, 1564949 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:26,497][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 48.14% examples, 1560267 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:27,501][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 72.77% examples, 1563164 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:28,516][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 98.43% examples, 1558695 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:24:28,567][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6368654 effective words) took 4.1s, 1562410 effective words/s
[2023-02-07 20:24:29,572][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 24.96% examples, 1573928 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:30,580][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 48.42% examples, 1567843 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:31,581][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 72.89% examples, 1565479 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:32,581][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 98.34% examples, 1563510 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:24:32,632][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6368654 effective words) took 4.1s, 1567643 effective words/s
[2023-02-07 20:24:33,635][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 27.17% examples, 1743503 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:34,637][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 58.43% examples, 1898332 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:35,643][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 88.09% examples, 1876301 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:36,039][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6368654 effective words) took 3.4s, 1870526 effective words/s
[2023-02-07 20:24:37,043][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 28.40% examples, 1809098 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:38,046][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 55.48% examples, 1805035 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:39,050][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 84.59% examples, 1805518 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:39,564][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6368654 effective words) took 3.5s, 1807631 effective words/s
[2023-02-07 20:24:40,570][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 28.34% examples, 1803525 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:41,573][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 55.20% examples, 1791661 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:42,578][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 83.57% examples, 1788051 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:43,132][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6368654 effective words) took 3.6s, 1786519 effective words/s
[2023-02-07 20:24:44,136][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 28.40% examples, 1810254 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:45,140][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 55.48% examples, 1805537 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:46,145][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 85.20% examples, 1821374 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:46,614][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6368654 effective words) took 3.5s, 1830293 effective words/s
[2023-02-07 20:24:47,623][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 28.55% examples, 1809712 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:48,629][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 52.63% examples, 1700778 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:49,630][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 77.53% examples, 1654985 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:50,515][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6368654 effective words) took 3.9s, 1633460 effective words/s
[2023-02-07 20:24:51,522][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 24.78% examples, 1566069 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:52,524][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 48.42% examples, 1571950 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:53,527][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 73.50% examples, 1577361 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:54,528][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 98.86% examples, 1573552 words/s, in_qsize 6, out_qsize 1
[2023-02-07 20:24:54,560][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6368654 effective words) took 4.0s, 1575923 effective words/s
[2023-02-07 20:24:55,565][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 24.78% examples, 1567351 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:56,569][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 50.69% examples, 1640753 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:24:57,575][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 82.19% examples, 1752352 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:24:58,178][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6368654 effective words) took 3.6s, 1761549 effective words/s
[2023-02-07 20:24:59,196][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 27.79% examples, 1752419 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:25:00,199][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 54.47% examples, 1758658 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:25:01,200][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 82.71% examples, 1759904 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:25:01,797][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6368654 effective words) took 3.6s, 1761009 effective words/s
[2023-02-07 20:25:01,797][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (95529810 effective words) took 55.8s, 1710684 effective words/s', 'datetime': '2023-02-07T20:25:01.797483', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:25:01.797 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:25:06,957][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202333-vnjrl6ql/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:25:06.957629', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:25:06,958][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:25:07,045][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202333-vnjrl6ql/files/../tmp/embedding_model.pt
2023-02-07 20:25:07.046 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:25:09.693 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:25:10.664 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:25:14.157 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0208959304635996, 'test_mae': 0.7796828970313072, 'test_r2': -1.9155111162605039}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.87
wandb: percentage 0.66117
wandb:   test_mae 0.77968
wandb:   test_mse 1.0209
wandb:    test_r2 -1.91551
wandb: 
wandb: üöÄ View run cosmic-sweep-82 at: https://wandb.ai/xiaoqiz/mof2vec/runs/vnjrl6ql
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_202333-vnjrl6ql/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: d5opoin0 with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 716
wandb: 	model.gensim.alpha: 0.014320916045232704
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.7031331869745008
wandb: 	model.gensim.vector_size: 235
wandb: 	model.gensim.window: 9
wandb: 	model.sklearn.learning_rate: 0.0014147158131262016
wandb: 	model.sklearn.max_depth: 95
wandb: 	model.sklearn.min_child_weight: 0.04766629255237126
wandb: 	model.sklearn.n_estimators: 1780
wandb: 	model.sklearn.num_leaves: 209
wandb: 	model.sklearn.reg_alpha: 0.013543751837280512
wandb: 	model.sklearn.reg_lambda: 0.04656251862498252
wandb: 	model.sklearn.subsample: 0.5108074538593017
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202534-d5opoin0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-83
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/d5opoin0
2023-02-07 20:25:42.662 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:25:42.663 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 716 for sweep.
2023-02-07 20:25:42.663 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.014320916045232704 for sweep.
2023-02-07 20:25:42.664 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:25:42.664 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 20:25:42.664 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7031331869745008 for sweep.
2023-02-07 20:25:42.664 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 235 for sweep.
2023-02-07 20:25:42.665 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 9 for sweep.
2023-02-07 20:25:42.665 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0014147158131262016 for sweep.
2023-02-07 20:25:42.665 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 95 for sweep.
2023-02-07 20:25:42.665 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.04766629255237126 for sweep.
2023-02-07 20:25:42.666 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1780 for sweep.
2023-02-07 20:25:42.666 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 209 for sweep.
2023-02-07 20:25:42.666 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.013543751837280512 for sweep.
2023-02-07 20:25:42.666 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.04656251862498252 for sweep.
2023-02-07 20:25:42.666 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5108074538593017 for sweep.
2023-02-07 20:25:42.667 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:25:42.672 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202534-d5opoin0/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 716, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 235, 'window': 9, 'min_count': 9, 'dm': 0, 'sample': 0.7031331869745008, 'workers': 4, 'alpha': 0.014320916045232704, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1780, 'max_depth': 95, 'num_leaves': 209, 'reg_alpha': 0.013543751837280512, 'reg_lambda': 0.04656251862498252, 'subsample': 0.5108074538593017, 'min_child_weight': 0.04766629255237126, 'n_jobs': 4, 'learning_rate': 0.0014147158131262016}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:24, 134.55it/s]  1%|          | 30/3257 [00:00<00:22, 146.04it/s]  1%|‚ñè         | 46/3257 [00:00<00:21, 152.23it/s]  2%|‚ñè         | 62/3257 [00:00<00:21, 149.84it/s]  2%|‚ñè         | 79/3257 [00:00<00:20, 156.79it/s]  3%|‚ñé         | 95/3257 [00:00<00:20, 156.55it/s]  3%|‚ñé         | 111/3257 [00:00<00:21, 147.26it/s]  4%|‚ñç         | 128/3257 [00:00<00:20, 152.98it/s]  5%|‚ñç         | 148/3257 [00:00<00:18, 164.42it/s]  5%|‚ñå         | 165/3257 [00:01<00:20, 148.74it/s]  6%|‚ñå         | 181/3257 [00:01<00:20, 148.92it/s]  6%|‚ñå         | 200/3257 [00:01<00:19, 157.95it/s]  7%|‚ñã         | 218/3257 [00:01<00:18, 162.83it/s]  7%|‚ñã         | 237/3257 [00:01<00:18, 167.09it/s]  8%|‚ñä         | 254/3257 [00:01<00:18, 166.70it/s]  8%|‚ñä         | 271/3257 [00:01<00:18, 159.59it/s]  9%|‚ñâ         | 292/3257 [00:01<00:17, 173.43it/s] 10%|‚ñâ         | 310/3257 [00:01<00:17, 168.63it/s] 10%|‚ñà         | 328/3257 [00:02<00:17, 168.74it/s] 11%|‚ñà         | 345/3257 [00:02<00:17, 163.07it/s] 11%|‚ñà         | 362/3257 [00:02<00:24, 116.31it/s] 12%|‚ñà‚ñè        | 376/3257 [00:02<00:23, 120.45it/s] 12%|‚ñà‚ñè        | 390/3257 [00:02<00:22, 124.76it/s] 13%|‚ñà‚ñé        | 408/3257 [00:02<00:20, 136.78it/s] 13%|‚ñà‚ñé        | 424/3257 [00:02<00:20, 141.45it/s] 13%|‚ñà‚ñé        | 439/3257 [00:02<00:21, 128.64it/s] 14%|‚ñà‚ñç        | 458/3257 [00:03<00:19, 142.60it/s] 15%|‚ñà‚ñç        | 475/3257 [00:03<00:18, 149.74it/s] 15%|‚ñà‚ñå        | 492/3257 [00:03<00:17, 155.31it/s] 16%|‚ñà‚ñå        | 512/3257 [00:03<00:16, 165.39it/s] 16%|‚ñà‚ñå        | 529/3257 [00:03<00:16, 161.45it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:16, 162.82it/s] 17%|‚ñà‚ñã        | 563/3257 [00:03<00:17, 150.10it/s] 18%|‚ñà‚ñä        | 579/3257 [00:03<00:19, 139.83it/s] 18%|‚ñà‚ñä        | 594/3257 [00:03<00:18, 141.74it/s] 19%|‚ñà‚ñä        | 610/3257 [00:04<00:18, 143.31it/s] 19%|‚ñà‚ñâ        | 625/3257 [00:04<00:19, 135.28it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:04<00:18, 138.05it/s] 20%|‚ñà‚ñà        | 655/3257 [00:04<00:20, 129.63it/s] 21%|‚ñà‚ñà        | 669/3257 [00:04<00:20, 129.26it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:20, 124.47it/s] 21%|‚ñà‚ñà‚ñè       | 696/3257 [00:04<00:20, 123.73it/s] 22%|‚ñà‚ñà‚ñè       | 711/3257 [00:04<00:19, 129.55it/s] 22%|‚ñà‚ñà‚ñè       | 725/3257 [00:05<00:20, 123.83it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:05<00:20, 121.03it/s] 23%|‚ñà‚ñà‚ñé       | 753/3257 [00:05<00:19, 126.83it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:05<00:18, 133.22it/s] 24%|‚ñà‚ñà‚ñç       | 784/3257 [00:05<00:19, 127.14it/s] 25%|‚ñà‚ñà‚ñç       | 800/3257 [00:05<00:18, 133.94it/s] 25%|‚ñà‚ñà‚ñç       | 814/3257 [00:05<00:18, 133.34it/s] 25%|‚ñà‚ñà‚ñå       | 828/3257 [00:05<00:19, 126.94it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:05<00:20, 119.19it/s] 26%|‚ñà‚ñà‚ñã       | 855/3257 [00:06<00:19, 123.30it/s] 27%|‚ñà‚ñà‚ñã       | 869/3257 [00:06<00:18, 127.55it/s] 27%|‚ñà‚ñà‚ñã       | 882/3257 [00:06<00:18, 126.00it/s] 27%|‚ñà‚ñà‚ñã       | 895/3257 [00:06<00:18, 125.99it/s] 28%|‚ñà‚ñà‚ñä       | 911/3257 [00:06<00:17, 134.26it/s] 28%|‚ñà‚ñà‚ñä       | 926/3257 [00:06<00:16, 138.57it/s] 29%|‚ñà‚ñà‚ñâ       | 940/3257 [00:06<00:17, 133.86it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:06<00:16, 138.46it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:06<00:16, 136.88it/s] 30%|‚ñà‚ñà‚ñà       | 984/3257 [00:06<00:16, 135.48it/s] 31%|‚ñà‚ñà‚ñà       | 998/3257 [00:07<00:17, 129.71it/s] 31%|‚ñà‚ñà‚ñà       | 1012/3257 [00:07<00:17, 127.61it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:07<00:17, 125.11it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1040/3257 [00:07<00:17, 126.30it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1053/3257 [00:07<00:17, 123.59it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:07<00:17, 127.25it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:17, 126.45it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1093/3257 [00:07<00:17, 126.90it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1108/3257 [00:07<00:16, 132.55it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1122/3257 [00:08<00:16, 130.49it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1136/3257 [00:08<00:16, 126.95it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1149/3257 [00:08<00:17, 121.75it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1166/3257 [00:08<00:15, 134.60it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1180/3257 [00:08<00:16, 123.37it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1193/3257 [00:08<00:17, 120.35it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1206/3257 [00:08<00:17, 118.89it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:08<00:16, 120.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1238/3257 [00:08<00:14, 138.54it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1253/3257 [00:09<00:15, 131.63it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1269/3257 [00:09<00:14, 138.64it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1284/3257 [00:09<00:16, 119.97it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1297/3257 [00:09<00:16, 120.00it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1312/3257 [00:09<00:15, 126.87it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1327/3257 [00:09<00:14, 132.54it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1342/3257 [00:09<00:14, 136.13it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1356/3257 [00:09<00:14, 129.09it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:10<00:14, 129.33it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1384/3257 [00:10<00:14, 126.14it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1400/3257 [00:10<00:13, 134.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1417/3257 [00:10<00:12, 143.88it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:10<00:12, 141.63it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1448/3257 [00:10<00:12, 144.45it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1465/3257 [00:10<00:11, 149.55it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1481/3257 [00:10<00:12, 146.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1498/3257 [00:10<00:11, 151.89it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1514/3257 [00:10<00:11, 151.36it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:11<00:12, 137.40it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1545/3257 [00:11<00:13, 130.17it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1559/3257 [00:11<00:12, 131.98it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:11<00:12, 134.36it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1588/3257 [00:11<00:21, 76.12it/s]  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1604/3257 [00:11<00:18, 90.67it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:12<00:16, 101.34it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:12<00:15, 107.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1649/3257 [00:12<00:13, 116.96it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1665/3257 [00:12<00:12, 126.83it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1681/3257 [00:12<00:11, 135.47it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:12<00:10, 147.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1717/3257 [00:12<00:10, 152.74it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1733/3257 [00:12<00:10, 146.95it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1751/3257 [00:12<00:09, 154.89it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:13<00:08, 165.11it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1791/3257 [00:13<00:08, 174.23it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1809/3257 [00:13<00:08, 165.34it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1826/3257 [00:13<00:08, 166.61it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1844/3257 [00:13<00:08, 170.33it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1862/3257 [00:13<00:08, 168.78it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1879/3257 [00:13<00:08, 168.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1896/3257 [00:13<00:08, 164.82it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:13<00:08, 164.39it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1936/3257 [00:13<00:07, 173.39it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1958/3257 [00:14<00:07, 184.64it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1977/3257 [00:14<00:07, 176.10it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1996/3257 [00:14<00:07, 177.96it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2014/3257 [00:14<00:07, 167.63it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:14<00:07, 171.92it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2051/3257 [00:14<00:07, 155.30it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2067/3257 [00:14<00:08, 147.09it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2084/3257 [00:14<00:07, 151.75it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:15<00:07, 146.22it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2119/3257 [00:15<00:07, 157.21it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2135/3257 [00:15<00:07, 143.45it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2150/3257 [00:15<00:07, 140.08it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:15<00:07, 148.53it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2184/3257 [00:15<00:07, 146.34it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2202/3257 [00:15<00:06, 155.10it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2218/3257 [00:15<00:06, 151.41it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2234/3257 [00:15<00:06, 153.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2250/3257 [00:16<00:06, 146.46it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2266/3257 [00:16<00:06, 146.99it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2281/3257 [00:16<00:06, 144.07it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:16<00:06, 151.02it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2317/3257 [00:16<00:05, 158.49it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:16<00:05, 170.32it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:16<00:05, 178.13it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2378/3257 [00:16<00:04, 176.17it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:16<00:04, 178.66it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2415/3257 [00:17<00:05, 163.83it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2432/3257 [00:17<00:05, 151.47it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2448/3257 [00:17<00:05, 149.06it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2470/3257 [00:17<00:04, 167.79it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2488/3257 [00:17<00:04, 165.75it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2509/3257 [00:17<00:04, 174.55it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2527/3257 [00:17<00:04, 175.87it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2546/3257 [00:17<00:03, 177.96it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2564/3257 [00:17<00:04, 164.85it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2581/3257 [00:18<00:04, 155.07it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2597/3257 [00:18<00:04, 152.55it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2620/3257 [00:18<00:03, 173.60it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2638/3257 [00:18<00:03, 173.64it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:18<00:03, 161.56it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:18<00:03, 157.95it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:18<00:03, 159.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2707/3257 [00:18<00:03, 139.86it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2722/3257 [00:18<00:03, 138.61it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2742/3257 [00:19<00:03, 153.22it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2759/3257 [00:19<00:03, 156.88it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2776/3257 [00:19<00:03, 147.87it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2796/3257 [00:19<00:02, 158.94it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:19<00:02, 156.59it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2829/3257 [00:19<00:02, 146.09it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2846/3257 [00:19<00:02, 150.53it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2867/3257 [00:19<00:02, 166.06it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:19<00:02, 166.03it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2903/3257 [00:20<00:02, 154.65it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:20<00:02, 158.18it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2937/3257 [00:20<00:02, 157.37it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2953/3257 [00:20<00:02, 146.42it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2970/3257 [00:20<00:01, 150.33it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2986/3257 [00:20<00:01, 142.17it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3007/3257 [00:20<00:01, 159.57it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3024/3257 [00:20<00:01, 151.17it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3044/3257 [00:21<00:01, 164.11it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3065/3257 [00:21<00:01, 173.94it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3083/3257 [00:21<00:01, 173.46it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3101/3257 [00:21<00:01, 93.87it/s]  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3122/3257 [00:21<00:01, 114.07it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3139/3257 [00:21<00:00, 124.87it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3155/3257 [00:21<00:00, 131.45it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3172/3257 [00:22<00:00, 137.90it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3188/3257 [00:22<00:00, 134.56it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:22<00:00, 137.94it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3218/3257 [00:22<00:00, 129.57it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3237/3257 [00:22<00:00, 142.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:22<00:00, 141.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 143.76it/s]
2023-02-07 20:26:06.302 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:26:06,303][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d235,n5,mc9,s0.703133,t4>', 'datetime': '2023-02-07T20:26:06.303479', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:26:06,303][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:26:06,304][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:26:06,996][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:26:06,996][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:26:07,059][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 18315 unique words (33.88% of original 54054, drops 35739)', 'datetime': '2023-02-07T20:26:07.059891', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:26:07,060][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 6422560 word corpus (98.04% of original 6550866, drops 128306)', 'datetime': '2023-02-07T20:26:07.060333', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:26:07,129][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:26:07,132][gensim.models.word2vec][INFO] - sample=0.703133 downsamples 0 most-common words
[2023-02-07 20:26:07,132][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6422560 word corpus (100.0%% of prior 6422560)', 'datetime': '2023-02-07T20:26:07.132837', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:26:07,249][gensim.models.word2vec][INFO] - estimated required memory for 18315 words and 235 dimensions: 47302680 bytes
[2023-02-07 20:26:07,249][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:26:07,274][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18315 vocabulary and 235 features, using sg=1 hs=0 sample=0.7031331869745008 negative=5 window=9 shrink_windows=True', 'datetime': '2023-02-07T20:26:07.274055', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:26:08,290][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 32.55% examples, 2075132 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:26:09,294][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 65.80% examples, 2125863 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:10,252][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6368654 effective words) took 3.0s, 2142680 effective words/s
[2023-02-07 20:26:11,255][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 37.40% examples, 2440451 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:12,258][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 75.07% examples, 2420548 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:12,882][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6368654 effective words) took 2.6s, 2423410 effective words/s
[2023-02-07 20:26:13,885][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 43.11% examples, 2819648 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:14,887][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 92.75% examples, 2969135 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:15,031][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6368654 effective words) took 2.1s, 2965757 effective words/s
[2023-02-07 20:26:16,034][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 43.41% examples, 2836870 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:17,034][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 88.89% examples, 2850055 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:17,269][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6368654 effective words) took 2.2s, 2849308 effective words/s
[2023-02-07 20:26:18,274][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 43.41% examples, 2827592 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:19,274][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 89.04% examples, 2849523 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:19,497][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6368654 effective words) took 2.2s, 2859755 effective words/s
[2023-02-07 20:26:20,499][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 45.04% examples, 2923313 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:21,501][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 91.59% examples, 2935748 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:21,662][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6368654 effective words) took 2.2s, 2943174 effective words/s
[2023-02-07 20:26:22,664][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 47.07% examples, 3053633 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:23,666][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 91.71% examples, 2941210 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:23,856][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6368654 effective words) took 2.2s, 2905400 effective words/s
[2023-02-07 20:26:24,862][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 39.48% examples, 2571020 words/s, in_qsize 6, out_qsize 1
[2023-02-07 20:26:25,863][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 80.01% examples, 2567774 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:26,332][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6368654 effective words) took 2.5s, 2572747 effective words/s
[2023-02-07 20:26:27,336][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 39.21% examples, 2552405 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:28,337][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 80.44% examples, 2579576 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:28,797][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6368654 effective words) took 2.5s, 2585405 effective words/s
[2023-02-07 20:26:29,804][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 39.73% examples, 2588592 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:30,808][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 81.67% examples, 2614356 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:31,229][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6368654 effective words) took 2.4s, 2620968 effective words/s
[2023-02-07 20:26:32,232][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 45.04% examples, 2924174 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:33,233][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 99.26% examples, 3159953 words/s, in_qsize 5, out_qsize 1
[2023-02-07 20:26:33,243][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6368654 effective words) took 2.0s, 3165903 effective words/s
[2023-02-07 20:26:34,247][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 46.61% examples, 3006704 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:35,251][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 93.77% examples, 2989242 words/s, in_qsize 6, out_qsize 1
[2023-02-07 20:26:35,367][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6368654 effective words) took 2.1s, 2999858 effective words/s
[2023-02-07 20:26:36,372][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 45.59% examples, 2958307 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:37,374][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 92.91% examples, 2974059 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:37,512][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6368654 effective words) took 2.1s, 2974985 effective words/s
[2023-02-07 20:26:38,513][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 46.36% examples, 2995454 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:39,514][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 93.28% examples, 2985173 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:39,642][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6368654 effective words) took 2.1s, 2990709 effective words/s
[2023-02-07 20:26:40,644][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 46.05% examples, 2977921 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:41,645][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 91.71% examples, 2943429 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:26:41,825][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6368654 effective words) took 2.2s, 2919668 effective words/s
[2023-02-07 20:26:41,826][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (95529810 effective words) took 34.6s, 2764932 effective words/s', 'datetime': '2023-02-07T20:26:41.826088', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:26:41.827 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:26:45,722][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202534-d5opoin0/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:26:45.722069', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:26:45,722][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:26:45,800][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202534-d5opoin0/files/../tmp/embedding_model.pt
2023-02-07 20:26:45.800 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:26:47.659 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:26:48.309 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:26:49.998 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.973432749981551, 'test_mae': 0.7567524288786701, 'test_r2': -2.4283223774495353}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.87
wandb: percentage 0.66117
wandb:   test_mae 0.75675
wandb:   test_mse 0.97343
wandb:    test_r2 -2.42832
wandb: 
wandb: üöÄ View run dainty-sweep-83 at: https://wandb.ai/xiaoqiz/mof2vec/runs/d5opoin0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_202534-d5opoin0/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: h1vze53c with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 511
wandb: 	model.gensim.alpha: 0.005934613191974938
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.6080355365720052
wandb: 	model.gensim.vector_size: 272
wandb: 	model.gensim.window: 3
wandb: 	model.sklearn.learning_rate: 0.15945505968480844
wandb: 	model.sklearn.max_depth: 17
wandb: 	model.sklearn.min_child_weight: 0.02986795998991716
wandb: 	model.sklearn.n_estimators: 25
wandb: 	model.sklearn.num_leaves: 47
wandb: 	model.sklearn.reg_alpha: 0.0239119785924504
wandb: 	model.sklearn.reg_lambda: 0.007308234762328372
wandb: 	model.sklearn.subsample: 0.5943275992678512
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202709-h1vze53c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-84
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/h1vze53c
2023-02-07 20:27:18.129 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:27:18.130 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 511 for sweep.
2023-02-07 20:27:18.131 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.005934613191974938 for sweep.
2023-02-07 20:27:18.131 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:27:18.131 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 20:27:18.132 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6080355365720052 for sweep.
2023-02-07 20:27:18.132 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 272 for sweep.
2023-02-07 20:27:18.132 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 3 for sweep.
2023-02-07 20:27:18.132 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.15945505968480844 for sweep.
2023-02-07 20:27:18.132 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 17 for sweep.
2023-02-07 20:27:18.133 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.02986795998991716 for sweep.
2023-02-07 20:27:18.133 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 25 for sweep.
2023-02-07 20:27:18.133 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 47 for sweep.
2023-02-07 20:27:18.133 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0239119785924504 for sweep.
2023-02-07 20:27:18.133 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.007308234762328372 for sweep.
2023-02-07 20:27:18.134 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5943275992678512 for sweep.
2023-02-07 20:27:18.134 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:27:18.140 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202709-h1vze53c/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 511, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 272, 'window': 3, 'min_count': 9, 'dm': 0, 'sample': 0.6080355365720052, 'workers': 4, 'alpha': 0.005934613191974938, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 25, 'max_depth': 17, 'num_leaves': 47, 'reg_alpha': 0.0239119785924504, 'reg_lambda': 0.007308234762328372, 'subsample': 0.5943275992678512, 'min_child_weight': 0.02986795998991716, 'n_jobs': 4, 'learning_rate': 0.15945505968480844}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:21, 149.05it/s]  1%|          | 34/3257 [00:00<00:20, 160.73it/s]  2%|‚ñè         | 53/3257 [00:00<00:19, 165.14it/s]  2%|‚ñè         | 71/3257 [00:00<00:18, 169.54it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 173.83it/s]  3%|‚ñé         | 108/3257 [00:00<00:19, 164.00it/s]  4%|‚ñç         | 125/3257 [00:00<00:19, 162.14it/s]  4%|‚ñç         | 146/3257 [00:00<00:17, 174.24it/s]  5%|‚ñå         | 164/3257 [00:00<00:18, 164.89it/s]  6%|‚ñå         | 181/3257 [00:01<00:18, 165.17it/s]  6%|‚ñå         | 201/3257 [00:01<00:18, 168.38it/s]  7%|‚ñã         | 224/3257 [00:01<00:16, 185.75it/s]  8%|‚ñä         | 245/3257 [00:01<00:15, 190.44it/s]  8%|‚ñä         | 265/3257 [00:01<00:16, 181.81it/s]  9%|‚ñâ         | 289/3257 [00:01<00:14, 197.98it/s] 10%|‚ñâ         | 310/3257 [00:01<00:16, 183.77it/s] 10%|‚ñà         | 329/3257 [00:01<00:16, 175.84it/s] 11%|‚ñà         | 347/3257 [00:02<00:17, 166.42it/s] 11%|‚ñà         | 364/3257 [00:02<00:17, 163.89it/s] 12%|‚ñà‚ñè        | 381/3257 [00:02<00:18, 153.23it/s] 12%|‚ñà‚ñè        | 397/3257 [00:02<00:19, 150.12it/s] 13%|‚ñà‚ñé        | 414/3257 [00:02<00:18, 153.03it/s] 13%|‚ñà‚ñé        | 430/3257 [00:02<00:20, 135.04it/s] 14%|‚ñà‚ñé        | 444/3257 [00:02<00:20, 136.05it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:20, 139.50it/s] 15%|‚ñà‚ñç        | 476/3257 [00:02<00:19, 145.45it/s] 15%|‚ñà‚ñå        | 494/3257 [00:03<00:17, 154.53it/s] 16%|‚ñà‚ñå        | 514/3257 [00:03<00:16, 165.63it/s] 16%|‚ñà‚ñã        | 531/3257 [00:03<00:16, 164.50it/s] 17%|‚ñà‚ñã        | 549/3257 [00:03<00:16, 167.57it/s] 17%|‚ñà‚ñã        | 566/3257 [00:03<00:17, 155.56it/s] 18%|‚ñà‚ñä        | 582/3257 [00:03<00:18, 148.06it/s] 18%|‚ñà‚ñä        | 600/3257 [00:03<00:17, 156.03it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:16, 157.09it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:03<00:15, 164.57it/s] 20%|‚ñà‚ñà        | 656/3257 [00:04<00:17, 151.06it/s] 21%|‚ñà‚ñà        | 674/3257 [00:04<00:16, 157.71it/s] 21%|‚ñà‚ñà        | 691/3257 [00:04<00:16, 153.83it/s] 22%|‚ñà‚ñà‚ñè       | 708/3257 [00:04<00:16, 157.69it/s] 22%|‚ñà‚ñà‚ñè       | 724/3257 [00:04<00:16, 150.89it/s] 23%|‚ñà‚ñà‚ñé       | 740/3257 [00:04<00:17, 145.83it/s] 23%|‚ñà‚ñà‚ñé       | 758/3257 [00:04<00:16, 154.81it/s] 24%|‚ñà‚ñà‚ñç       | 774/3257 [00:04<00:16, 155.10it/s] 24%|‚ñà‚ñà‚ñç       | 790/3257 [00:04<00:15, 154.99it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:05<00:16, 152.28it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:05<00:16, 150.27it/s] 26%|‚ñà‚ñà‚ñå       | 839/3257 [00:05<00:16, 150.89it/s] 26%|‚ñà‚ñà‚ñã       | 855/3257 [00:05<00:16, 145.98it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:05<00:16, 148.85it/s] 27%|‚ñà‚ñà‚ñã       | 886/3257 [00:05<00:16, 146.77it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:14, 158.86it/s] 28%|‚ñà‚ñà‚ñä       | 922/3257 [00:05<00:14, 161.77it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:05<00:14, 156.52it/s] 29%|‚ñà‚ñà‚ñâ       | 957/3257 [00:05<00:14, 161.63it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:06<00:23, 98.46it/s]  30%|‚ñà‚ñà‚ñà       | 988/3257 [00:06<00:21, 105.58it/s] 31%|‚ñà‚ñà‚ñà       | 1005/3257 [00:06<00:18, 119.25it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1021/3257 [00:06<00:17, 128.27it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1036/3257 [00:06<00:17, 128.17it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:06<00:16, 130.54it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1068/3257 [00:06<00:15, 140.68it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1083/3257 [00:07<00:15, 142.28it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1099/3257 [00:07<00:14, 147.07it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1116/3257 [00:07<00:14, 152.26it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1132/3257 [00:07<00:14, 142.40it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1148/3257 [00:07<00:14, 143.95it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1168/3257 [00:07<00:13, 159.13it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:07<00:14, 146.33it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1201/3257 [00:07<00:14, 137.90it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1217/3257 [00:07<00:14, 142.67it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1238/3257 [00:08<00:12, 159.17it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1255/3257 [00:08<00:13, 151.53it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:08<00:12, 153.99it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1288/3257 [00:08<00:13, 141.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1304/3257 [00:08<00:13, 144.93it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:08<00:12, 151.11it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:08<00:12, 157.91it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1355/3257 [00:08<00:12, 147.53it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:08<00:12, 145.67it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:09<00:13, 142.16it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1401/3257 [00:09<00:12, 146.00it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1420/3257 [00:09<00:11, 155.61it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1436/3257 [00:09<00:11, 152.56it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:09<00:11, 154.59it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1468/3257 [00:09<00:11, 155.89it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1484/3257 [00:09<00:11, 150.54it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1503/3257 [00:09<00:10, 160.33it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1520/3257 [00:09<00:11, 147.72it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1536/3257 [00:10<00:11, 144.93it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1551/3257 [00:10<00:11, 144.91it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1566/3257 [00:10<00:11, 143.96it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1585/3257 [00:10<00:10, 154.47it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1608/3257 [00:10<00:09, 175.81it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1632/3257 [00:10<00:08, 192.80it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1652/3257 [00:10<00:09, 177.21it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1671/3257 [00:10<00:09, 172.64it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1690/3257 [00:10<00:08, 174.56it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1712/3257 [00:11<00:08, 186.56it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1731/3257 [00:11<00:08, 172.00it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1751/3257 [00:11<00:08, 178.64it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1774/3257 [00:11<00:07, 188.04it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:11<00:07, 195.64it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1816/3257 [00:11<00:07, 188.49it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1836/3257 [00:11<00:07, 186.32it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1855/3257 [00:11<00:07, 182.04it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1877/3257 [00:11<00:07, 190.63it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:12<00:07, 181.43it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:12<00:07, 181.46it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:12<00:07, 188.25it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1962/3257 [00:12<00:06, 204.71it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1983/3257 [00:12<00:06, 188.39it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:12<00:06, 192.04it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2024/3257 [00:12<00:06, 191.33it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2044/3257 [00:12<00:06, 182.86it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2063/3257 [00:12<00:06, 171.63it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:13<00:06, 180.23it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2106/3257 [00:13<00:06, 188.13it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2126/3257 [00:13<00:06, 183.17it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2145/3257 [00:13<00:06, 178.32it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:13<00:05, 192.27it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2188/3257 [00:13<00:05, 191.62it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2208/3257 [00:13<00:05, 192.88it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2228/3257 [00:13<00:05, 187.18it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2247/3257 [00:14<00:08, 113.88it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2265/3257 [00:14<00:07, 126.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2281/3257 [00:14<00:07, 128.93it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2298/3257 [00:14<00:06, 137.81it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2314/3257 [00:14<00:06, 142.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2335/3257 [00:14<00:05, 158.61it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2355/3257 [00:14<00:05, 168.99it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2373/3257 [00:14<00:05, 160.09it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2393/3257 [00:15<00:05, 166.74it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2411/3257 [00:15<00:05, 155.46it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2428/3257 [00:15<00:05, 152.90it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2444/3257 [00:15<00:05, 142.16it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2461/3257 [00:15<00:05, 148.27it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2478/3257 [00:15<00:05, 152.36it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2496/3257 [00:15<00:04, 157.53it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:15<00:04, 163.32it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2533/3257 [00:15<00:04, 170.51it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2551/3257 [00:16<00:04, 163.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2568/3257 [00:16<00:04, 145.53it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2584/3257 [00:16<00:04, 148.07it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2600/3257 [00:16<00:04, 148.95it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2622/3257 [00:16<00:03, 167.45it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2640/3257 [00:16<00:03, 165.34it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2657/3257 [00:16<00:03, 156.54it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2674/3257 [00:16<00:03, 159.53it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:16<00:03, 167.09it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2711/3257 [00:17<00:03, 157.91it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:17<00:03, 170.00it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2755/3257 [00:17<00:02, 186.16it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:17<00:02, 175.92it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2797/3257 [00:17<00:02, 189.75it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2817/3257 [00:17<00:02, 180.12it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2836/3257 [00:17<00:02, 175.11it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2859/3257 [00:17<00:02, 189.07it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:17<00:01, 205.80it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2907/3257 [00:18<00:01, 201.14it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2929/3257 [00:18<00:01, 206.14it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:18<00:01, 194.90it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2972/3257 [00:18<00:01, 201.26it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2993/3257 [00:18<00:01, 185.12it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3015/3257 [00:18<00:01, 192.28it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3035/3257 [00:18<00:01, 190.90it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3055/3257 [00:18<00:01, 192.49it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3077/3257 [00:18<00:00, 198.53it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3097/3257 [00:19<00:00, 189.76it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3119/3257 [00:19<00:00, 198.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3139/3257 [00:19<00:00, 188.75it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3159/3257 [00:19<00:00, 181.29it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3178/3257 [00:19<00:00, 167.06it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3199/3257 [00:19<00:00, 176.76it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3217/3257 [00:19<00:00, 166.68it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:19<00:00, 178.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 162.97it/s]
2023-02-07 20:27:38.920 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:27:38,921][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d272,n5,mc9,s0.608036,t4>', 'datetime': '2023-02-07T20:27:38.921002', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:27:38,921][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:27:38,921][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:27:39,440][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:27:39,440][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:27:39,484][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 14828 unique words (34.73% of original 42701, drops 27873)', 'datetime': '2023-02-07T20:27:39.484317', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:27:39,484][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 5723647 word corpus (98.29% of original 5822992, drops 99345)', 'datetime': '2023-02-07T20:27:39.484683', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:27:39,534][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:27:39,535][gensim.models.word2vec][INFO] - sample=0.608036 downsamples 0 most-common words
[2023-02-07 20:27:39,535][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5723647 word corpus (100.0%% of prior 5723647)', 'datetime': '2023-02-07T20:27:39.535877', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:27:39,620][gensim.models.word2vec][INFO] - estimated required memory for 14828 words and 272 dimensions: 43874744 bytes
[2023-02-07 20:27:39,621][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:27:39,643][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14828 vocabulary and 272 features, using sg=1 hs=0 sample=0.6080355365720052 negative=5 window=3 shrink_windows=True', 'datetime': '2023-02-07T20:27:39.643030', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:27:40,646][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 34.97% examples, 2021092 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:41,647][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 69.33% examples, 2015137 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:27:42,465][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5697932 effective words) took 2.8s, 2020936 effective words/s
[2023-02-07 20:27:43,469][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 39.51% examples, 2312800 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:44,470][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 88.33% examples, 2528964 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:27:44,727][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5697932 effective words) took 2.3s, 2522677 effective words/s
[2023-02-07 20:27:45,734][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 41.97% examples, 2444723 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:46,735][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 86.31% examples, 2471785 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:27:47,041][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5697932 effective words) took 2.3s, 2465993 effective words/s
[2023-02-07 20:27:48,051][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 37.58% examples, 2179494 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:27:49,054][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 76.51% examples, 2197569 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:27:49,636][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5697932 effective words) took 2.6s, 2197805 effective words/s
[2023-02-07 20:27:50,640][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 41.91% examples, 2456578 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:27:51,641][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 90.51% examples, 2595563 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:27:51,838][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5697932 effective words) took 2.2s, 2591219 effective words/s
[2023-02-07 20:27:52,846][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 43.14% examples, 2517296 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:27:53,854][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 86.25% examples, 2461235 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:27:54,179][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5697932 effective words) took 2.3s, 2437732 effective words/s
[2023-02-07 20:27:55,183][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.29% examples, 2232359 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:27:56,186][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 78.26% examples, 2246426 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:27:56,717][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5697932 effective words) took 2.5s, 2248425 effective words/s
[2023-02-07 20:27:57,723][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 50.38% examples, 2917230 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:27:58,725][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 97.24% examples, 2769294 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:27:58,777][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5697932 effective words) took 2.1s, 2770638 effective words/s
[2023-02-07 20:27:59,779][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 42.77% examples, 2509623 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:00,781][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 87.07% examples, 2502528 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:28:01,053][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5697932 effective words) took 2.3s, 2505602 effective words/s
[2023-02-07 20:28:02,055][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 43.41% examples, 2545600 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:03,055][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 88.67% examples, 2543116 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:03,295][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5697932 effective words) took 2.2s, 2542932 effective words/s
[2023-02-07 20:28:04,302][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 42.77% examples, 2499645 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:05,304][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 87.50% examples, 2506079 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:05,570][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5697932 effective words) took 2.3s, 2507107 effective words/s
[2023-02-07 20:28:06,575][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 43.41% examples, 2539951 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:07,577][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 89.13% examples, 2551788 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:07,801][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5697932 effective words) took 2.2s, 2557384 effective words/s
[2023-02-07 20:28:08,806][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 44.03% examples, 2565150 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:09,807][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 89.99% examples, 2573742 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:10,015][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5697932 effective words) took 2.2s, 2575479 effective words/s
[2023-02-07 20:28:11,022][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 45.38% examples, 2626263 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:28:12,023][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 92.94% examples, 2659155 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:12,151][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5697932 effective words) took 2.1s, 2671063 effective words/s
[2023-02-07 20:28:13,161][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 39.36% examples, 2286187 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:28:14,161][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 79.49% examples, 2283779 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:28:14,651][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5697932 effective words) took 2.5s, 2280205 effective words/s
[2023-02-07 20:28:14,652][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85468980 effective words) took 35.0s, 2441337 effective words/s', 'datetime': '2023-02-07T20:28:14.652523', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:28:14.652 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:28:18,391][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202709-h1vze53c/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:28:18.391472', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:28:18,392][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:28:18,457][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202709-h1vze53c/files/../tmp/embedding_model.pt
2023-02-07 20:28:18.458 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:28:20.446 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:28:21.123 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:28:22.912 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0073852227675972, 'test_mae': 0.7449434710883656, 'test_r2': -1.994110917899072}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.8
wandb: percentage 0.65275
wandb:   test_mae 0.74494
wandb:   test_mse 1.00739
wandb:    test_r2 -1.99411
wandb: 
wandb: üöÄ View run sparkling-sweep-84 at: https://wandb.ai/xiaoqiz/mof2vec/runs/h1vze53c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_202709-h1vze53c/logs
wandb: Agent Starting Run: axop0po1 with config:
wandb: 	data.data.wl_step: 8
wandb: 	data.nn.batch_size: 594
wandb: 	model.gensim.alpha: 0.006105277983229288
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.7809206537853264
wandb: 	model.gensim.vector_size: 438
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.0019905998883064727
wandb: 	model.sklearn.max_depth: 45
wandb: 	model.sklearn.min_child_weight: 0.03241053177067378
wandb: 	model.sklearn.n_estimators: 1238
wandb: 	model.sklearn.num_leaves: 174
wandb: 	model.sklearn.reg_alpha: 0.003940733000286943
wandb: 	model.sklearn.reg_lambda: 0.021890874242877275
wandb: 	model.sklearn.subsample: 0.6920030998944093
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202834-axop0po1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-85
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/axop0po1
2023-02-07 20:28:43.095 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 8 for sweep.
2023-02-07 20:28:43.095 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 594 for sweep.
2023-02-07 20:28:43.096 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.006105277983229288 for sweep.
2023-02-07 20:28:43.096 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:28:43.096 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 20:28:43.096 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7809206537853264 for sweep.
2023-02-07 20:28:43.097 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 438 for sweep.
2023-02-07 20:28:43.097 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 20:28:43.097 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0019905998883064727 for sweep.
2023-02-07 20:28:43.097 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 45 for sweep.
2023-02-07 20:28:43.097 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03241053177067378 for sweep.
2023-02-07 20:28:43.098 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1238 for sweep.
2023-02-07 20:28:43.098 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 174 for sweep.
2023-02-07 20:28:43.098 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.003940733000286943 for sweep.
2023-02-07 20:28:43.098 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.021890874242877275 for sweep.
2023-02-07 20:28:43.098 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6920030998944093 for sweep.
2023-02-07 20:28:43.099 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:28:43.102 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 8}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202834-axop0po1/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 594, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 438, 'window': 11, 'min_count': 8, 'dm': 0, 'sample': 0.7809206537853264, 'workers': 4, 'alpha': 0.006105277983229288, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1238, 'max_depth': 45, 'num_leaves': 174, 'reg_alpha': 0.003940733000286943, 'reg_lambda': 0.021890874242877275, 'subsample': 0.6920030998944093, 'min_child_weight': 0.03241053177067378, 'n_jobs': 4, 'learning_rate': 0.0019905998883064727}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 162.22it/s]  1%|          | 36/3257 [00:00<00:18, 173.96it/s]  2%|‚ñè         | 54/3257 [00:00<00:18, 175.43it/s]  2%|‚ñè         | 74/3257 [00:00<00:17, 181.92it/s]  3%|‚ñé         | 93/3257 [00:00<00:17, 183.04it/s]  3%|‚ñé         | 112/3257 [00:00<00:18, 169.88it/s]  4%|‚ñç         | 131/3257 [00:00<00:17, 175.09it/s]  5%|‚ñç         | 152/3257 [00:00<00:16, 184.39it/s]  5%|‚ñå         | 171/3257 [00:00<00:17, 179.53it/s]  6%|‚ñå         | 190/3257 [00:01<00:16, 180.89it/s]  6%|‚ñã         | 209/3257 [00:01<00:16, 179.76it/s]  7%|‚ñã         | 230/3257 [00:01<00:16, 187.71it/s]  8%|‚ñä         | 249/3257 [00:01<00:16, 187.61it/s]  8%|‚ñä         | 268/3257 [00:01<00:16, 176.27it/s]  9%|‚ñâ         | 293/3257 [00:01<00:15, 195.58it/s] 10%|‚ñâ         | 313/3257 [00:01<00:16, 177.62it/s] 10%|‚ñà         | 334/3257 [00:01<00:15, 185.72it/s] 11%|‚ñà         | 353/3257 [00:01<00:16, 177.76it/s] 11%|‚ñà‚ñè        | 372/3257 [00:02<00:16, 177.24it/s] 12%|‚ñà‚ñè        | 390/3257 [00:02<00:18, 158.71it/s] 13%|‚ñà‚ñé        | 408/3257 [00:02<00:17, 163.97it/s] 13%|‚ñà‚ñé        | 425/3257 [00:02<00:26, 108.00it/s] 13%|‚ñà‚ñé        | 439/3257 [00:02<00:25, 110.82it/s] 14%|‚ñà‚ñç        | 457/3257 [00:02<00:22, 125.64it/s] 15%|‚ñà‚ñç        | 474/3257 [00:02<00:20, 135.16it/s] 15%|‚ñà‚ñå        | 490/3257 [00:03<00:20, 138.22it/s] 16%|‚ñà‚ñå        | 510/3257 [00:03<00:17, 153.04it/s] 16%|‚ñà‚ñå        | 527/3257 [00:03<00:18, 148.55it/s] 17%|‚ñà‚ñã        | 545/3257 [00:03<00:17, 156.43it/s] 17%|‚ñà‚ñã        | 562/3257 [00:03<00:19, 141.00it/s] 18%|‚ñà‚ñä        | 577/3257 [00:03<00:19, 135.67it/s] 18%|‚ñà‚ñä        | 595/3257 [00:03<00:18, 146.74it/s] 19%|‚ñà‚ñâ        | 615/3257 [00:03<00:16, 159.90it/s] 19%|‚ñà‚ñâ        | 632/3257 [00:03<00:16, 159.71it/s] 20%|‚ñà‚ñâ        | 649/3257 [00:04<00:17, 151.99it/s] 20%|‚ñà‚ñà        | 665/3257 [00:04<00:18, 143.33it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:17, 144.55it/s] 21%|‚ñà‚ñà‚ñè       | 699/3257 [00:04<00:17, 145.82it/s] 22%|‚ñà‚ñà‚ñè       | 719/3257 [00:04<00:16, 157.14it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:04<00:16, 150.46it/s] 23%|‚ñà‚ñà‚ñé       | 751/3257 [00:04<00:17, 144.44it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:04<00:16, 154.47it/s] 24%|‚ñà‚ñà‚ñç       | 786/3257 [00:04<00:16, 149.10it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:15, 154.49it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:16, 151.89it/s] 26%|‚ñà‚ñà‚ñå       | 836/3257 [00:05<00:16, 143.58it/s] 26%|‚ñà‚ñà‚ñå       | 851/3257 [00:05<00:17, 139.61it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:05<00:16, 145.52it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:05<00:16, 142.21it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:14, 158.75it/s] 28%|‚ñà‚ñà‚ñä       | 922/3257 [00:05<00:14, 159.85it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:06<00:14, 154.62it/s] 29%|‚ñà‚ñà‚ñâ       | 958/3257 [00:06<00:14, 162.65it/s] 30%|‚ñà‚ñà‚ñâ       | 975/3257 [00:06<00:14, 160.95it/s] 30%|‚ñà‚ñà‚ñà       | 992/3257 [00:06<00:14, 153.02it/s] 31%|‚ñà‚ñà‚ñà       | 1008/3257 [00:06<00:15, 148.20it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:06<00:14, 153.39it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:06<00:15, 139.26it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1057/3257 [00:06<00:15, 143.30it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1077/3257 [00:06<00:13, 157.25it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:07<00:14, 144.59it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:07<00:13, 153.65it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1128/3257 [00:07<00:14, 144.85it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1144/3257 [00:07<00:14, 147.72it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1160/3257 [00:07<00:13, 150.84it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1176/3257 [00:07<00:14, 146.34it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:07<00:15, 134.48it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:07<00:15, 132.78it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1220/3257 [00:07<00:15, 135.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1241/3257 [00:08<00:13, 152.77it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:08<00:13, 147.30it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1274/3257 [00:08<00:13, 152.10it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:08<00:14, 134.61it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1304/3257 [00:08<00:14, 135.18it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:08<00:13, 141.74it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:08<00:12, 148.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1355/3257 [00:08<00:13, 142.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:08<00:13, 143.97it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:09<00:13, 142.81it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:09<00:12, 148.92it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:09<00:11, 158.86it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:09<00:11, 158.67it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:09<00:10, 170.27it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1478/3257 [00:09<00:10, 165.69it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:09<00:10, 168.54it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:09<00:10, 167.33it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1530/3257 [00:09<00:11, 152.74it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:10<00:11, 145.25it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1563/3257 [00:10<00:11, 151.00it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1579/3257 [00:10<00:11, 147.43it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1598/3257 [00:10<00:10, 156.11it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1616/3257 [00:10<00:10, 160.76it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1633/3257 [00:10<00:09, 163.01it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:10<00:11, 143.07it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1665/3257 [00:10<00:11, 139.38it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1680/3257 [00:10<00:11, 141.88it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1695/3257 [00:11<00:11, 141.46it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1713/3257 [00:11<00:10, 150.92it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:11<00:16, 91.60it/s]  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1742/3257 [00:11<00:15, 97.74it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1761/3257 [00:11<00:12, 116.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1776/3257 [00:11<00:12, 120.64it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:11<00:11, 126.92it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1806/3257 [00:12<00:11, 125.18it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:12<00:11, 130.37it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1835/3257 [00:12<00:11, 126.14it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:12<00:11, 126.50it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1866/3257 [00:12<00:10, 137.46it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1881/3257 [00:12<00:10, 132.89it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1895/3257 [00:12<00:10, 130.06it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1910/3257 [00:12<00:10, 134.68it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1924/3257 [00:12<00:10, 128.71it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1942/3257 [00:13<00:09, 142.56it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1959/3257 [00:13<00:08, 148.78it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1975/3257 [00:13<00:08, 144.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1990/3257 [00:13<00:09, 138.50it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:13<00:09, 137.28it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2019/3257 [00:13<00:08, 139.99it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2034/3257 [00:13<00:09, 135.37it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2048/3257 [00:13<00:09, 124.88it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2061/3257 [00:14<00:10, 119.27it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2078/3257 [00:14<00:09, 128.27it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2092/3257 [00:14<00:08, 131.05it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2106/3257 [00:14<00:08, 130.50it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:14<00:09, 123.26it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2133/3257 [00:14<00:09, 121.99it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2146/3257 [00:14<00:09, 118.10it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2161/3257 [00:14<00:08, 124.24it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:14<00:08, 130.55it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2192/3257 [00:15<00:08, 131.22it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2206/3257 [00:15<00:08, 130.44it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2220/3257 [00:15<00:08, 129.01it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2234/3257 [00:15<00:07, 131.96it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2248/3257 [00:15<00:08, 123.43it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2262/3257 [00:15<00:07, 125.16it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:15<00:08, 119.23it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2293/3257 [00:15<00:07, 135.01it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2307/3257 [00:15<00:07, 132.53it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2325/3257 [00:16<00:06, 145.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2341/3257 [00:16<00:06, 147.48it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:16<00:05, 154.12it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2376/3257 [00:16<00:05, 150.17it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2394/3257 [00:16<00:05, 156.30it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2410/3257 [00:16<00:06, 140.26it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2425/3257 [00:16<00:05, 142.25it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:16<00:06, 132.63it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2454/3257 [00:16<00:06, 129.68it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2473/3257 [00:17<00:05, 143.74it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2488/3257 [00:17<00:05, 140.35it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2506/3257 [00:17<00:04, 150.91it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2522/3257 [00:17<00:04, 147.13it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2537/3257 [00:17<00:04, 145.54it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2552/3257 [00:17<00:04, 141.03it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2567/3257 [00:17<00:05, 129.41it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2581/3257 [00:17<00:05, 126.17it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2595/3257 [00:17<00:05, 127.60it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2615/3257 [00:18<00:04, 146.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2632/3257 [00:18<00:04, 150.30it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2648/3257 [00:18<00:04, 140.58it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2663/3257 [00:18<00:04, 136.47it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2678/3257 [00:18<00:04, 139.66it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:18<00:04, 137.76it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2708/3257 [00:18<00:04, 128.39it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2721/3257 [00:18<00:04, 126.80it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:18<00:03, 143.88it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2756/3257 [00:19<00:03, 144.16it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2771/3257 [00:19<00:03, 138.27it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2789/3257 [00:19<00:03, 148.89it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2805/3257 [00:19<00:03, 148.98it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2821/3257 [00:19<00:03, 138.81it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2836/3257 [00:19<00:03, 131.02it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:19<00:02, 138.92it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2873/3257 [00:19<00:02, 154.10it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2889/3257 [00:19<00:02, 150.71it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2905/3257 [00:20<00:02, 140.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2921/3257 [00:20<00:02, 143.99it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2937/3257 [00:20<00:02, 148.33it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2953/3257 [00:20<00:02, 144.57it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2972/3257 [00:20<00:01, 156.60it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2988/3257 [00:20<00:01, 153.20it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:20<00:01, 170.54it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3030/3257 [00:20<00:01, 171.24it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3052/3257 [00:20<00:01, 184.23it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:21<00:00, 196.22it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3095/3257 [00:21<00:00, 187.73it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3119/3257 [00:21<00:00, 201.24it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3140/3257 [00:21<00:00, 185.03it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3159/3257 [00:21<00:00, 98.23it/s]  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3175/3257 [00:21<00:00, 108.49it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3191/3257 [00:22<00:00, 118.47it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:22<00:00, 126.62it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3223/3257 [00:22<00:00, 131.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3244/3257 [00:22<00:00, 148.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:22<00:00, 144.98it/s]
2023-02-07 20:29:06.453 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:29:06,454][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d438,n5,mc8,s0.780921,t4>', 'datetime': '2023-02-07T20:29:06.454444', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:29:06,454][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:29:06,454][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:29:07,091][gensim.models.doc2vec][INFO] - collected 54054 word types and 3257 unique tags from a corpus of 3257 examples and 6550866 words
[2023-02-07 20:29:07,091][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:29:07,163][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 22849 unique words (42.27% of original 54054, drops 31205)', 'datetime': '2023-02-07T20:29:07.163525', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:29:07,163][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 6458832 word corpus (98.60% of original 6550866, drops 92034)', 'datetime': '2023-02-07T20:29:07.163923', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:29:07,243][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 54054 items
[2023-02-07 20:29:07,245][gensim.models.word2vec][INFO] - sample=0.780921 downsamples 0 most-common words
[2023-02-07 20:29:07,246][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 6458832 word corpus (100.0%% of prior 6458832)', 'datetime': '2023-02-07T20:29:07.246255', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:29:07,381][gensim.models.word2vec][INFO] - estimated required memory for 22849 words and 438 dimensions: 97845060 bytes
[2023-02-07 20:29:07,382][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:29:07,427][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 22849 vocabulary and 438 features, using sg=1 hs=0 sample=0.7809206537853264 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T20:29:07.427703', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:29:08,435][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 24.29% examples, 1535800 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:09,435][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 48.33% examples, 1575832 words/s, in_qsize 6, out_qsize 0
[2023-02-07 20:29:10,446][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 73.81% examples, 1587211 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:11,431][gensim.models.word2vec][INFO] - EPOCH 0: training on 6550866 raw words (6404777 effective words) took 4.0s, 1600746 effective words/s
[2023-02-07 20:29:12,434][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 28.34% examples, 1816901 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:13,435][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 54.62% examples, 1786693 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:14,441][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 83.33% examples, 1793358 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:14,982][gensim.models.word2vec][INFO] - EPOCH 1: training on 6550866 raw words (6404777 effective words) took 3.5s, 1804769 effective words/s
[2023-02-07 20:29:15,986][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 24.72% examples, 1567614 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:16,988][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 48.05% examples, 1570023 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:17,989][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 72.64% examples, 1572472 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:18,991][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 98.19% examples, 1572067 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:19,064][gensim.models.word2vec][INFO] - EPOCH 2: training on 6550866 raw words (6404777 effective words) took 4.1s, 1570248 effective words/s
[2023-02-07 20:29:20,074][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 24.78% examples, 1566963 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:21,080][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 48.14% examples, 1564096 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:22,083][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 72.89% examples, 1572065 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:23,086][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 98.62% examples, 1573913 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:23,132][gensim.models.word2vec][INFO] - EPOCH 3: training on 6550866 raw words (6404777 effective words) took 4.1s, 1575338 effective words/s
[2023-02-07 20:29:24,142][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 27.17% examples, 1740611 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:25,147][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 58.80% examples, 1907951 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:26,150][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 88.42% examples, 1886555 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:26,536][gensim.models.word2vec][INFO] - EPOCH 4: training on 6550866 raw words (6404777 effective words) took 3.4s, 1883005 effective words/s
[2023-02-07 20:29:27,538][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 27.76% examples, 1778353 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:28,542][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 54.62% examples, 1784486 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:29:29,542][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 83.11% examples, 1789955 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:30,112][gensim.models.word2vec][INFO] - EPOCH 5: training on 6550866 raw words (6404777 effective words) took 3.6s, 1791920 effective words/s
[2023-02-07 20:29:31,114][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 27.88% examples, 1797772 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:32,116][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 55.08% examples, 1799796 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:33,119][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 83.97% examples, 1806851 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:33,644][gensim.models.word2vec][INFO] - EPOCH 6: training on 6550866 raw words (6404777 effective words) took 3.5s, 1814158 effective words/s
[2023-02-07 20:29:34,654][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 29.66% examples, 1886046 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:35,657][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 55.08% examples, 1793214 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:36,659][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 81.15% examples, 1740083 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:37,378][gensim.models.word2vec][INFO] - EPOCH 7: training on 6550866 raw words (6404777 effective words) took 3.7s, 1716640 effective words/s
[2023-02-07 20:29:38,393][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 25.76% examples, 1633133 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:39,397][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 50.72% examples, 1642457 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:40,403][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 76.30% examples, 1641061 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:41,287][gensim.models.word2vec][INFO] - EPOCH 8: training on 6550866 raw words (6404777 effective words) took 3.9s, 1640546 effective words/s
[2023-02-07 20:29:42,289][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 25.30% examples, 1615227 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:43,293][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 49.80% examples, 1620368 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:44,294][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 79.58% examples, 1716878 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:44,876][gensim.models.word2vec][INFO] - EPOCH 9: training on 6550866 raw words (6404777 effective words) took 3.6s, 1785386 effective words/s
[2023-02-07 20:29:45,881][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 29.90% examples, 1906935 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:46,883][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 57.97% examples, 1892206 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:47,887][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 87.57% examples, 1879744 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:48,287][gensim.models.word2vec][INFO] - EPOCH 10: training on 6550866 raw words (6404777 effective words) took 3.4s, 1878366 effective words/s
[2023-02-07 20:29:49,292][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 28.55% examples, 1825538 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:50,295][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 56.56% examples, 1846642 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:51,296][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 85.97% examples, 1844533 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:51,754][gensim.models.word2vec][INFO] - EPOCH 11: training on 6550866 raw words (6404777 effective words) took 3.5s, 1848123 effective words/s
[2023-02-07 20:29:52,757][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 29.08% examples, 1865729 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:53,760][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 58.21% examples, 1902174 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:54,764][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 86.52% examples, 1858658 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:55,259][gensim.models.word2vec][INFO] - EPOCH 12: training on 6550866 raw words (6404777 effective words) took 3.5s, 1828673 effective words/s
[2023-02-07 20:29:56,269][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 25.30% examples, 1604789 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:57,269][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 49.80% examples, 1617762 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:29:58,275][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 75.16% examples, 1624253 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:29:59,196][gensim.models.word2vec][INFO] - EPOCH 13: training on 6550866 raw words (6404777 effective words) took 3.9s, 1628040 effective words/s
[2023-02-07 20:30:00,199][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 25.51% examples, 1631484 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:30:01,203][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 50.35% examples, 1637401 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:30:02,207][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 76.05% examples, 1640704 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:30:03,096][gensim.models.word2vec][INFO] - EPOCH 14: training on 6550866 raw words (6404777 effective words) took 3.9s, 1642935 effective words/s
[2023-02-07 20:30:03,097][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 98262990 raw words (96071655 effective words) took 55.7s, 1725765 effective words/s', 'datetime': '2023-02-07T20:30:03.097120', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:30:03.097 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:30:07,850][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202834-axop0po1/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:30:07.850778', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:30:07,851][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:30:07,972][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_202834-axop0po1/files/../tmp/embedding_model.pt
2023-02-07 20:30:07.973 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:30:10.364 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:30:11.164 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:30:14.132 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9067288416857485, 'test_mae': 0.7193390076602895, 'test_r2': -1.7539057247478986}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.83
wandb: percentage 0.57729
wandb:   test_mae 0.71934
wandb:   test_mse 0.90673
wandb:    test_r2 -1.75391
wandb: 
wandb: üöÄ View run clear-sweep-85 at: https://wandb.ai/xiaoqiz/mof2vec/runs/axop0po1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_202834-axop0po1/logs
wandb: Agent Starting Run: ukqratds with config:
wandb: 	data.data.wl_step: 2
wandb: 	data.nn.batch_size: 474
wandb: 	model.gensim.alpha: 0.0021028165494053454
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.6696374182254083
wandb: 	model.gensim.vector_size: 282
wandb: 	model.gensim.window: 5
wandb: 	model.sklearn.learning_rate: 0.008322332049276678
wandb: 	model.sklearn.max_depth: 59
wandb: 	model.sklearn.min_child_weight: 0.0408294250085568
wandb: 	model.sklearn.n_estimators: 1896
wandb: 	model.sklearn.num_leaves: 325
wandb: 	model.sklearn.reg_alpha: 0.005261143357898891
wandb: 	model.sklearn.reg_lambda: 0.008486574807389888
wandb: 	model.sklearn.subsample: 0.8981384108602035
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203024-ukqratds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-86
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/ukqratds
2023-02-07 20:30:33.122 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 2 for sweep.
2023-02-07 20:30:33.123 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 474 for sweep.
2023-02-07 20:30:33.123 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0021028165494053454 for sweep.
2023-02-07 20:30:33.123 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:30:33.124 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 20:30:33.124 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.6696374182254083 for sweep.
2023-02-07 20:30:33.124 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 282 for sweep.
2023-02-07 20:30:33.124 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 5 for sweep.
2023-02-07 20:30:33.125 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.008322332049276678 for sweep.
2023-02-07 20:30:33.125 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 59 for sweep.
2023-02-07 20:30:33.125 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0408294250085568 for sweep.
2023-02-07 20:30:33.125 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1896 for sweep.
2023-02-07 20:30:33.125 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 325 for sweep.
2023-02-07 20:30:33.126 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.005261143357898891 for sweep.
2023-02-07 20:30:33.126 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.008486574807389888 for sweep.
2023-02-07 20:30:33.126 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8981384108602035 for sweep.
2023-02-07 20:30:33.126 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:30:33.133 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 2}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203024-ukqratds/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 474, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 282, 'window': 5, 'min_count': 9, 'dm': 0, 'sample': 0.6696374182254083, 'workers': 4, 'alpha': 0.0021028165494053454, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1896, 'max_depth': 59, 'num_leaves': 325, 'reg_alpha': 0.005261143357898891, 'reg_lambda': 0.008486574807389888, 'subsample': 0.8981384108602035, 'min_child_weight': 0.0408294250085568, 'n_jobs': 4, 'learning_rate': 0.008322332049276678}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 23/3257 [00:00<00:14, 226.19it/s]  1%|‚ñè         | 47/3257 [00:00<00:13, 229.73it/s]  2%|‚ñè         | 72/3257 [00:00<00:13, 236.55it/s]  3%|‚ñé         | 96/3257 [00:00<00:13, 236.67it/s]  4%|‚ñé         | 120/3257 [00:00<00:13, 235.97it/s]  5%|‚ñç         | 148/3257 [00:00<00:12, 249.68it/s]  5%|‚ñå         | 173/3257 [00:00<00:12, 242.90it/s]  6%|‚ñå         | 199/3257 [00:00<00:12, 246.07it/s]  7%|‚ñã         | 227/3257 [00:00<00:11, 255.58it/s]  8%|‚ñä         | 253/3257 [00:01<00:12, 248.14it/s]  9%|‚ñä         | 279/3257 [00:01<00:11, 251.03it/s]  9%|‚ñâ         | 305/3257 [00:01<00:11, 246.25it/s] 10%|‚ñà         | 332/3257 [00:01<00:11, 251.12it/s] 11%|‚ñà         | 360/3257 [00:01<00:11, 258.02it/s] 12%|‚ñà‚ñè        | 386/3257 [00:01<00:12, 238.43it/s] 13%|‚ñà‚ñé        | 411/3257 [00:01<00:11, 241.65it/s] 13%|‚ñà‚ñé        | 436/3257 [00:01<00:12, 218.79it/s] 14%|‚ñà‚ñç        | 461/3257 [00:01<00:12, 225.86it/s] 15%|‚ñà‚ñç        | 485/3257 [00:02<00:12, 227.97it/s] 16%|‚ñà‚ñå        | 512/3257 [00:02<00:11, 237.82it/s] 16%|‚ñà‚ñã        | 537/3257 [00:02<00:11, 237.87it/s] 17%|‚ñà‚ñã        | 561/3257 [00:02<00:11, 230.28it/s] 18%|‚ñà‚ñä        | 585/3257 [00:02<00:11, 230.82it/s] 19%|‚ñà‚ñâ        | 614/3257 [00:02<00:10, 247.29it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:02<00:10, 242.72it/s] 20%|‚ñà‚ñà        | 664/3257 [00:02<00:11, 231.40it/s] 21%|‚ñà‚ñà        | 688/3257 [00:02<00:11, 228.47it/s] 22%|‚ñà‚ñà‚ñè       | 717/3257 [00:02<00:10, 243.15it/s] 23%|‚ñà‚ñà‚ñé       | 742/3257 [00:03<00:10, 230.34it/s] 24%|‚ñà‚ñà‚ñé       | 769/3257 [00:03<00:10, 240.19it/s] 24%|‚ñà‚ñà‚ñç       | 794/3257 [00:03<00:10, 234.93it/s] 25%|‚ñà‚ñà‚ñå       | 818/3257 [00:03<00:10, 235.73it/s] 26%|‚ñà‚ñà‚ñå       | 842/3257 [00:03<00:10, 223.12it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:03<00:10, 223.60it/s] 27%|‚ñà‚ñà‚ñã       | 889/3257 [00:03<00:10, 225.15it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:03<00:10, 227.04it/s] 29%|‚ñà‚ñà‚ñâ       | 941/3257 [00:03<00:09, 237.79it/s] 30%|‚ñà‚ñà‚ñâ       | 967/3257 [00:04<00:09, 242.78it/s] 30%|‚ñà‚ñà‚ñà       | 992/3257 [00:04<00:09, 241.63it/s] 31%|‚ñà‚ñà‚ñà       | 1017/3257 [00:04<00:09, 242.20it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1042/3257 [00:04<00:09, 229.78it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:04<00:09, 234.20it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1091/3257 [00:04<00:14, 150.56it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:04<00:12, 168.08it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1138/3257 [00:05<00:11, 181.49it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1163/3257 [00:05<00:10, 196.94it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:05<00:10, 201.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:05<00:10, 204.29it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1234/3257 [00:05<00:09, 221.09it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1260/3257 [00:05<00:08, 229.85it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1284/3257 [00:05<00:08, 222.82it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:05<00:08, 229.42it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1338/3257 [00:05<00:07, 246.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1364/3257 [00:05<00:07, 239.35it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1392/3257 [00:06<00:07, 250.41it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:06<00:06, 288.97it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1472/3257 [00:06<00:05, 320.15it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1510/3257 [00:06<00:05, 336.48it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1544/3257 [00:06<00:05, 319.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1577/3257 [00:06<00:05, 319.35it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1612/3257 [00:06<00:05, 328.05it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1646/3257 [00:06<00:04, 326.29it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1679/3257 [00:06<00:04, 321.94it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:06<00:04, 332.61it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1749/3257 [00:07<00:04, 327.17it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1786/3257 [00:07<00:04, 338.66it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1820/3257 [00:07<00:04, 332.15it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1854/3257 [00:07<00:04, 321.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1887/3257 [00:07<00:04, 320.26it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1920/3257 [00:07<00:04, 308.91it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1958/3257 [00:07<00:03, 326.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1991/3257 [00:07<00:03, 320.32it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2024/3257 [00:07<00:03, 313.94it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2056/3257 [00:08<00:04, 297.00it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2087/3257 [00:08<00:03, 300.55it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:08<00:03, 299.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2151/3257 [00:08<00:03, 290.20it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2182/3257 [00:08<00:03, 292.52it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2212/3257 [00:08<00:03, 291.85it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2243/3257 [00:08<00:03, 293.76it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2273/3257 [00:08<00:03, 291.24it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2303/3257 [00:09<00:04, 200.33it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2340/3257 [00:09<00:03, 237.13it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2376/3257 [00:09<00:03, 264.83it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2410/3257 [00:09<00:03, 281.94it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2441/3257 [00:09<00:02, 288.47it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2474/3257 [00:09<00:02, 298.06it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2508/3257 [00:09<00:02, 308.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:09<00:02, 311.05it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:09<00:02, 301.66it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2605/3257 [00:10<00:02, 307.68it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2640/3257 [00:10<00:01, 318.73it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:10<00:01, 305.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:10<00:01, 287.90it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2737/3257 [00:10<00:01, 297.92it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2769/3257 [00:10<00:01, 299.69it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2805/3257 [00:10<00:01, 313.88it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:10<00:01, 296.46it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2879/3257 [00:10<00:01, 328.75it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2913/3257 [00:11<00:01, 316.83it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2946/3257 [00:11<00:01, 310.71it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2978/3257 [00:11<00:00, 303.42it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:11<00:00, 309.26it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3043/3257 [00:11<00:00, 306.21it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3080/3257 [00:11<00:00, 323.80it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3117/3257 [00:11<00:00, 336.10it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3151/3257 [00:11<00:00, 322.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3184/3257 [00:11<00:00, 316.77it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3217/3257 [00:11<00:00, 318.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:12<00:00, 330.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:12<00:00, 269.46it/s]
2023-02-07 20:30:45.507 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:30:45,508][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d282,n5,mc9,s0.669637,t4>', 'datetime': '2023-02-07T20:30:45.508639', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:30:45,509][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:30:45,509][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:30:45,702][gensim.models.doc2vec][INFO] - collected 2819 word types and 3257 unique tags from a corpus of 3257 examples and 2183622 words
[2023-02-07 20:30:45,703][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:30:45,706][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1249 unique words (44.31% of original 2819, drops 1570)', 'datetime': '2023-02-07T20:30:45.706877', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:30:45,707][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 2177896 word corpus (99.74% of original 2183622, drops 5726)', 'datetime': '2023-02-07T20:30:45.707873', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:30:45,712][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 2819 items
[2023-02-07 20:30:45,712][gensim.models.word2vec][INFO] - sample=0.669637 downsamples 0 most-common words
[2023-02-07 20:30:45,713][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2177896 word corpus (100.0%% of prior 2177896)', 'datetime': '2023-02-07T20:30:45.713079', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:30:45,720][gensim.models.word2vec][INFO] - estimated required memory for 1249 words and 282 dimensions: 7767540 bytes
[2023-02-07 20:30:45,721][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:30:45,726][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 1249 vocabulary and 282 features, using sg=1 hs=0 sample=0.6696374182254083 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-07T20:30:45.726003', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:30:46,735][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 80.47% examples, 1757736 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:30:46,949][gensim.models.word2vec][INFO] - EPOCH 0: training on 2183622 raw words (2181153 effective words) took 1.2s, 1785583 effective words/s
[2023-02-07 20:30:47,952][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 98.43% examples, 2145939 words/s, in_qsize 4, out_qsize 0
[2023-02-07 20:30:47,960][gensim.models.word2vec][INFO] - EPOCH 1: training on 2183622 raw words (2181153 effective words) took 1.0s, 2160549 effective words/s
[2023-02-07 20:30:48,964][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 97.51% examples, 2125482 words/s, in_qsize 6, out_qsize 0
[2023-02-07 20:30:48,983][gensim.models.word2vec][INFO] - EPOCH 2: training on 2183622 raw words (2181153 effective words) took 1.0s, 2134670 effective words/s
[2023-02-07 20:30:49,986][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 96.28% examples, 2101429 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:30:50,015][gensim.models.word2vec][INFO] - EPOCH 3: training on 2183622 raw words (2181153 effective words) took 1.0s, 2118354 effective words/s
[2023-02-07 20:30:51,019][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 95.89% examples, 2087913 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:30:51,053][gensim.models.word2vec][INFO] - EPOCH 4: training on 2183622 raw words (2181153 effective words) took 1.0s, 2104895 effective words/s
[2023-02-07 20:30:52,059][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 96.28% examples, 2093502 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:30:52,090][gensim.models.word2vec][INFO] - EPOCH 5: training on 2183622 raw words (2181153 effective words) took 1.0s, 2106906 effective words/s
[2023-02-07 20:30:53,095][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 96.68% examples, 2107098 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:30:53,120][gensim.models.word2vec][INFO] - EPOCH 6: training on 2183622 raw words (2181153 effective words) took 1.0s, 2123047 effective words/s
[2023-02-07 20:30:54,123][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 97.05% examples, 2116180 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:30:54,146][gensim.models.word2vec][INFO] - EPOCH 7: training on 2183622 raw words (2181153 effective words) took 1.0s, 2128698 effective words/s
[2023-02-07 20:30:55,152][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 97.91% examples, 2130761 words/s, in_qsize 5, out_qsize 0
[2023-02-07 20:30:55,165][gensim.models.word2vec][INFO] - EPOCH 8: training on 2183622 raw words (2181153 effective words) took 1.0s, 2144809 effective words/s
[2023-02-07 20:30:56,168][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 99.39% examples, 2170649 words/s, in_qsize 1, out_qsize 1
[2023-02-07 20:30:56,169][gensim.models.word2vec][INFO] - EPOCH 9: training on 2183622 raw words (2181153 effective words) took 1.0s, 2177068 effective words/s
[2023-02-07 20:30:57,116][gensim.models.word2vec][INFO] - EPOCH 10: training on 2183622 raw words (2181153 effective words) took 0.9s, 2308342 effective words/s
[2023-02-07 20:30:57,954][gensim.models.word2vec][INFO] - EPOCH 11: training on 2183622 raw words (2181153 effective words) took 0.8s, 2606054 effective words/s
[2023-02-07 20:30:58,798][gensim.models.word2vec][INFO] - EPOCH 12: training on 2183622 raw words (2181153 effective words) took 0.8s, 2587946 effective words/s
[2023-02-07 20:30:59,665][gensim.models.word2vec][INFO] - EPOCH 13: training on 2183622 raw words (2181153 effective words) took 0.9s, 2518795 effective words/s
[2023-02-07 20:31:00,570][gensim.models.word2vec][INFO] - EPOCH 14: training on 2183622 raw words (2181153 effective words) took 0.9s, 2414293 effective words/s
[2023-02-07 20:31:00,571][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 32754330 raw words (32717295 effective words) took 14.8s, 2203953 effective words/s', 'datetime': '2023-02-07T20:31:00.571155', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:31:00.571 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:31:01,659][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203024-ukqratds/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:31:01.659670', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:31:01,660][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:31:01,677][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203024-ukqratds/files/../tmp/embedding_model.pt
2023-02-07 20:31:01.677 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:31:03.377 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:31:03.988 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:31:05.920 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0243605508263742, 'test_mae': 0.7745399932645581, 'test_r2': -2.0064669612100032}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.36
wandb: percentage 0.55694
wandb:   test_mae 0.77454
wandb:   test_mse 1.02436
wandb:    test_r2 -2.00647
wandb: 
wandb: üöÄ View run fearless-sweep-86 at: https://wandb.ai/xiaoqiz/mof2vec/runs/ukqratds
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_203024-ukqratds/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 80jtlfzg with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 880
wandb: 	model.gensim.alpha: 0.0061410140966888654
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 1
wandb: 	model.gensim.sample: 0.8153544461965778
wandb: 	model.gensim.vector_size: 349
wandb: 	model.gensim.window: 9
wandb: 	model.sklearn.learning_rate: 0.0017767206429990256
wandb: 	model.sklearn.max_depth: 76
wandb: 	model.sklearn.min_child_weight: 0.028580959672376796
wandb: 	model.sklearn.n_estimators: 1352
wandb: 	model.sklearn.num_leaves: 163
wandb: 	model.sklearn.reg_alpha: 0.006393769066474328
wandb: 	model.sklearn.reg_lambda: 0.03405181433571121
wandb: 	model.sklearn.subsample: 0.947991098908466
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203123-80jtlfzg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-87
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/80jtlfzg
2023-02-07 20:31:31.807 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:31:31.808 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 880 for sweep.
2023-02-07 20:31:31.808 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0061410140966888654 for sweep.
2023-02-07 20:31:31.809 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:31:31.809 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 1 for sweep.
2023-02-07 20:31:31.810 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8153544461965778 for sweep.
2023-02-07 20:31:31.810 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 349 for sweep.
2023-02-07 20:31:31.810 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 9 for sweep.
2023-02-07 20:31:31.810 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0017767206429990256 for sweep.
2023-02-07 20:31:31.811 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 76 for sweep.
2023-02-07 20:31:31.811 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.028580959672376796 for sweep.
2023-02-07 20:31:31.811 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1352 for sweep.
2023-02-07 20:31:31.811 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 163 for sweep.
2023-02-07 20:31:31.811 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.006393769066474328 for sweep.
2023-02-07 20:31:31.812 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.03405181433571121 for sweep.
2023-02-07 20:31:31.812 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.947991098908466 for sweep.
2023-02-07 20:31:31.812 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:31:31.817 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203123-80jtlfzg/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 880, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 349, 'window': 9, 'min_count': 1, 'dm': 0, 'sample': 0.8153544461965778, 'workers': 4, 'alpha': 0.0061410140966888654, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1352, 'max_depth': 76, 'num_leaves': 163, 'reg_alpha': 0.006393769066474328, 'reg_lambda': 0.03405181433571121, 'subsample': 0.947991098908466, 'min_child_weight': 0.028580959672376796, 'n_jobs': 4, 'learning_rate': 0.0017767206429990256}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 16/3257 [00:00<00:21, 152.09it/s]  1%|          | 34/3257 [00:00<00:20, 157.18it/s]  2%|‚ñè         | 53/3257 [00:00<00:19, 162.39it/s]  2%|‚ñè         | 71/3257 [00:00<00:19, 165.55it/s]  3%|‚ñé         | 90/3257 [00:00<00:18, 170.17it/s]  3%|‚ñé         | 108/3257 [00:00<00:19, 160.74it/s]  4%|‚ñç         | 125/3257 [00:00<00:19, 163.25it/s]  4%|‚ñç         | 145/3257 [00:00<00:18, 171.55it/s]  5%|‚ñå         | 163/3257 [00:01<00:19, 159.26it/s]  6%|‚ñå         | 180/3257 [00:01<00:19, 159.78it/s]  6%|‚ñå         | 199/3257 [00:01<00:18, 167.24it/s]  7%|‚ñã         | 217/3257 [00:01<00:17, 170.68it/s]  7%|‚ñã         | 237/3257 [00:01<00:17, 176.48it/s]  8%|‚ñä         | 256/3257 [00:01<00:16, 178.85it/s]  8%|‚ñä         | 274/3257 [00:01<00:16, 175.66it/s]  9%|‚ñâ         | 296/3257 [00:01<00:15, 187.07it/s] 10%|‚ñâ         | 315/3257 [00:01<00:16, 174.14it/s] 10%|‚ñà         | 334/3257 [00:01<00:16, 177.98it/s] 11%|‚ñà         | 352/3257 [00:02<00:16, 173.01it/s] 11%|‚ñà‚ñè        | 371/3257 [00:02<00:16, 176.11it/s] 12%|‚ñà‚ñè        | 389/3257 [00:02<00:17, 160.52it/s] 13%|‚ñà‚ñé        | 408/3257 [00:02<00:16, 168.43it/s] 13%|‚ñà‚ñé        | 426/3257 [00:02<00:18, 152.01it/s] 14%|‚ñà‚ñé        | 442/3257 [00:02<00:18, 151.92it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:17, 155.80it/s] 15%|‚ñà‚ñç        | 475/3257 [00:03<00:26, 106.09it/s] 15%|‚ñà‚ñå        | 493/3257 [00:03<00:22, 120.87it/s] 16%|‚ñà‚ñå        | 513/3257 [00:03<00:20, 137.16it/s] 16%|‚ñà‚ñå        | 529/3257 [00:03<00:19, 142.15it/s] 17%|‚ñà‚ñã        | 547/3257 [00:03<00:18, 149.60it/s] 17%|‚ñà‚ñã        | 564/3257 [00:03<00:18, 142.78it/s] 18%|‚ñà‚ñä        | 580/3257 [00:03<00:18, 143.92it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:17, 153.54it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:16, 161.42it/s] 20%|‚ñà‚ñâ        | 644/3257 [00:04<00:14, 180.85it/s] 20%|‚ñà‚ñà        | 663/3257 [00:04<00:14, 173.98it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:14, 180.14it/s] 22%|‚ñà‚ñà‚ñè       | 705/3257 [00:04<00:13, 189.34it/s] 22%|‚ñà‚ñà‚ñè       | 725/3257 [00:04<00:13, 187.29it/s] 23%|‚ñà‚ñà‚ñé       | 744/3257 [00:04<00:13, 185.73it/s] 24%|‚ñà‚ñà‚ñé       | 769/3257 [00:04<00:12, 201.51it/s] 24%|‚ñà‚ñà‚ñç       | 790/3257 [00:04<00:12, 194.65it/s] 25%|‚ñà‚ñà‚ñç       | 812/3257 [00:04<00:12, 198.64it/s] 26%|‚ñà‚ñà‚ñå       | 832/3257 [00:04<00:12, 193.60it/s] 26%|‚ñà‚ñà‚ñå       | 852/3257 [00:05<00:13, 182.06it/s] 27%|‚ñà‚ñà‚ñã       | 872/3257 [00:05<00:12, 186.45it/s] 27%|‚ñà‚ñà‚ñã       | 891/3257 [00:05<00:12, 183.61it/s] 28%|‚ñà‚ñà‚ñä       | 913/3257 [00:05<00:12, 191.94it/s] 29%|‚ñà‚ñà‚ñä       | 933/3257 [00:05<00:12, 186.77it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:05<00:11, 196.30it/s] 30%|‚ñà‚ñà‚ñâ       | 976/3257 [00:05<00:11, 197.00it/s] 31%|‚ñà‚ñà‚ñà       | 996/3257 [00:05<00:12, 181.51it/s] 31%|‚ñà‚ñà‚ñà       | 1016/3257 [00:05<00:12, 185.27it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1035/3257 [00:06<00:12, 178.23it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1053/3257 [00:06<00:12, 173.03it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1074/3257 [00:06<00:11, 183.11it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1093/3257 [00:06<00:12, 175.50it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:06<00:11, 186.99it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1136/3257 [00:06<00:11, 186.44it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1155/3257 [00:06<00:11, 187.37it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1175/3257 [00:06<00:11, 186.87it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1194/3257 [00:06<00:12, 171.70it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1212/3257 [00:07<00:12, 167.79it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1234/3257 [00:07<00:11, 181.72it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1253/3257 [00:07<00:11, 179.89it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1272/3257 [00:07<00:10, 181.39it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:07<00:11, 167.03it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:07<00:11, 167.58it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:07<00:11, 168.16it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1346/3257 [00:07<00:11, 168.56it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1363/3257 [00:07<00:11, 160.96it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1380/3257 [00:08<00:12, 155.32it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1396/3257 [00:08<00:12, 149.52it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1414/3257 [00:08<00:11, 156.46it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:08<00:11, 157.52it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1452/3257 [00:08<00:10, 165.16it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1470/3257 [00:08<00:10, 168.75it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1487/3257 [00:08<00:10, 165.21it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1507/3257 [00:08<00:10, 174.39it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1525/3257 [00:09<00:10, 159.15it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1542/3257 [00:09<00:10, 157.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1558/3257 [00:09<00:11, 151.17it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:09<00:17, 95.18it/s]  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:09<00:15, 108.01it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1610/3257 [00:09<00:13, 124.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1627/3257 [00:09<00:12, 134.62it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1643/3257 [00:09<00:12, 133.95it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1658/3257 [00:10<00:11, 135.53it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1675/3257 [00:10<00:11, 142.95it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:10<00:10, 149.69it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1714/3257 [00:10<00:09, 166.38it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1732/3257 [00:10<00:09, 158.40it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1751/3257 [00:10<00:09, 166.07it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1770/3257 [00:10<00:08, 170.54it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1791/3257 [00:10<00:08, 180.34it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1810/3257 [00:10<00:08, 173.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:11<00:08, 170.91it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:11<00:07, 178.88it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1872/3257 [00:11<00:07, 192.42it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1892/3257 [00:11<00:07, 189.11it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:11<00:06, 195.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1938/3257 [00:11<00:06, 201.45it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1964/3257 [00:11<00:05, 217.70it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1986/3257 [00:11<00:06, 194.47it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2006/3257 [00:11<00:06, 194.26it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2027/3257 [00:12<00:06, 198.45it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2048/3257 [00:12<00:06, 177.06it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2067/3257 [00:12<00:06, 170.84it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:12<00:06, 170.03it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2103/3257 [00:12<00:06, 169.69it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:12<00:06, 164.57it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2140/3257 [00:12<00:06, 171.47it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2158/3257 [00:12<00:06, 171.46it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:12<00:06, 173.27it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2198/3257 [00:13<00:05, 178.75it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2216/3257 [00:13<00:06, 173.35it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:13<00:05, 176.92it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2254/3257 [00:13<00:05, 170.92it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2272/3257 [00:13<00:06, 160.41it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2294/3257 [00:13<00:05, 175.86it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2312/3257 [00:13<00:05, 173.78it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:13<00:04, 191.75it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2361/3257 [00:13<00:04, 204.10it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2382/3257 [00:14<00:04, 203.21it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:14<00:04, 206.48it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2425/3257 [00:14<00:04, 195.44it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2445/3257 [00:14<00:04, 181.14it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2467/3257 [00:14<00:04, 190.32it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2487/3257 [00:14<00:03, 192.57it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2510/3257 [00:14<00:03, 203.04it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2533/3257 [00:14<00:03, 209.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2555/3257 [00:14<00:03, 194.74it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2575/3257 [00:15<00:03, 176.59it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2594/3257 [00:15<00:04, 164.45it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2615/3257 [00:15<00:03, 173.58it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:15<00:03, 175.73it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2652/3257 [00:15<00:03, 162.82it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2669/3257 [00:15<00:03, 161.61it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:15<00:03, 162.41it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2704/3257 [00:15<00:03, 144.18it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2719/3257 [00:16<00:03, 141.65it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2740/3257 [00:16<00:03, 159.01it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:16<00:03, 157.48it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:16<00:03, 148.16it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2793/3257 [00:16<00:02, 158.65it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2810/3257 [00:16<00:02, 154.41it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2826/3257 [00:16<00:02, 144.46it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2841/3257 [00:16<00:02, 143.43it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2861/3257 [00:16<00:02, 158.61it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2881/3257 [00:17<00:02, 168.78it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2899/3257 [00:17<00:02, 154.82it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2915/3257 [00:17<00:02, 154.99it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2931/3257 [00:17<00:02, 151.74it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:17<00:02, 147.84it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2963/3257 [00:17<00:01, 150.82it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2979/3257 [00:17<00:01, 146.28it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2995/3257 [00:17<00:01, 148.86it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3013/3257 [00:17<00:01, 156.70it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3029/3257 [00:18<00:01, 155.98it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3045/3257 [00:18<00:02, 86.66it/s]  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3068/3257 [00:18<00:01, 113.10it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3088/3257 [00:18<00:01, 130.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3112/3257 [00:18<00:00, 154.87it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3133/3257 [00:18<00:00, 166.82it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3153/3257 [00:18<00:00, 168.35it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3175/3257 [00:19<00:00, 178.86it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3196/3257 [00:19<00:00, 186.20it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3216/3257 [00:19<00:00, 176.37it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3239/3257 [00:19<00:00, 190.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 167.09it/s]
2023-02-07 20:31:52.036 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:31:52,037][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d349,n5,s0.815354,t4>', 'datetime': '2023-02-07T20:31:52.037252', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:31:52,037][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:31:52,037][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:31:52,566][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:31:52,567][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:31:52,676][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 42701 unique words (100.00% of original 42701, drops 0)', 'datetime': '2023-02-07T20:31:52.676310', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:31:52,676][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 5822992 word corpus (100.00% of original 5822992, drops 0)', 'datetime': '2023-02-07T20:31:52.676686', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:31:52,825][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:31:52,826][gensim.models.word2vec][INFO] - sample=0.815354 downsamples 0 most-common words
[2023-02-07 20:31:52,827][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5822992 word corpus (100.0%% of prior 5822992)', 'datetime': '2023-02-07T20:31:52.827110', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:31:53,078][gensim.models.word2vec][INFO] - estimated required memory for 42701 words and 349 dimensions: 145769864 bytes
[2023-02-07 20:31:53,078][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:31:53,140][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 42701 vocabulary and 349 features, using sg=1 hs=0 sample=0.8153544461965778 negative=5 window=9 shrink_windows=True', 'datetime': '2023-02-07T20:31:53.140621', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:31:54,144][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 27.42% examples, 1595679 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:55,153][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 53.45% examples, 1580970 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:56,158][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 81.39% examples, 1576896 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:56,810][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5795785 effective words) took 3.7s, 1580166 effective words/s
[2023-02-07 20:31:57,818][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 35.31% examples, 2068503 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:58,822][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 69.14% examples, 2038493 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:31:59,694][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5795785 effective words) took 2.9s, 2012528 effective words/s
[2023-02-07 20:32:00,698][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 31.93% examples, 1864342 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:01,699][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 61.41% examples, 1802944 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:32:02,705][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 91.28% examples, 1769018 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:02,967][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5795785 effective words) took 3.3s, 1771559 effective words/s
[2023-02-07 20:32:03,974][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 32.02% examples, 1872275 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:32:04,978][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 68.35% examples, 2013502 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:32:05,863][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5795785 effective words) took 2.9s, 2003707 effective words/s
[2023-02-07 20:32:06,867][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 32.67% examples, 1911979 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:32:07,871][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 62.14% examples, 1819247 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:32:08,873][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 92.60% examples, 1796134 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:32:09,095][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5795785 effective words) took 3.2s, 1794230 effective words/s
[2023-02-07 20:32:10,106][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 30.92% examples, 1789988 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:11,108][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 68.84% examples, 2026617 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:11,945][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5795785 effective words) took 2.8s, 2034558 effective words/s
[2023-02-07 20:32:12,948][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 33.90% examples, 1982477 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:13,950][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 66.99% examples, 1979847 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:14,890][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5795785 effective words) took 2.9s, 1968785 effective words/s
[2023-02-07 20:32:15,893][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 33.31% examples, 1957257 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:32:16,895][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 66.60% examples, 1967887 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:32:17,844][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5795785 effective words) took 3.0s, 1964004 effective words/s
[2023-02-07 20:32:18,847][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 33.16% examples, 1942421 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:19,851][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 65.83% examples, 1943164 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:20,822][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5795785 effective words) took 3.0s, 1947336 effective words/s
[2023-02-07 20:32:21,824][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 33.71% examples, 1976338 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:22,829][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 67.30% examples, 1984134 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:32:23,723][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5795785 effective words) took 2.9s, 1998542 effective words/s
[2023-02-07 20:32:24,726][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 34.97% examples, 2053215 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:25,727][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 69.88% examples, 2071517 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:26,675][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5795785 effective words) took 2.9s, 1964778 effective words/s
[2023-02-07 20:32:27,683][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 29.81% examples, 1720807 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:32:28,685][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 58.80% examples, 1730411 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:29,685][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 89.13% examples, 1729475 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:30,020][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5795785 effective words) took 3.3s, 1733984 effective words/s
[2023-02-07 20:32:31,026][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 29.81% examples, 1724280 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:32,033][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 58.83% examples, 1731844 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:32:33,036][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 89.65% examples, 1734477 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:33,364][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5795785 effective words) took 3.3s, 1734269 effective words/s
[2023-02-07 20:32:34,371][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 29.97% examples, 1731033 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:32:35,372][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 65.83% examples, 1943655 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:32:36,261][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5795785 effective words) took 2.9s, 2002652 effective words/s
[2023-02-07 20:32:37,266][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 34.45% examples, 2013542 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:32:38,268][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 68.04% examples, 2007460 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:32:39,163][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5795785 effective words) took 2.9s, 1998817 effective words/s
[2023-02-07 20:32:39,163][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86936775 effective words) took 46.0s, 1889004 effective words/s', 'datetime': '2023-02-07T20:32:39.163582', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:32:39.163 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:32:43,512][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203123-80jtlfzg/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:32:43.512603', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:32:43,513][gensim.utils][INFO] - storing np array 'vectors' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203123-80jtlfzg/files/../tmp/embedding_model.pt.wv.vectors.npy
[2023-02-07 20:32:43,572][gensim.utils][INFO] - storing np array 'syn1neg' to /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203123-80jtlfzg/files/../tmp/embedding_model.pt.syn1neg.npy
[2023-02-07 20:32:43,627][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:32:43,665][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203123-80jtlfzg/files/../tmp/embedding_model.pt
2023-02-07 20:32:43.665 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:32:45.680 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:32:46.377 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:32:48.677 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9722375984389083, 'test_mae': 0.7371120881174971, 'test_r2': -1.8215391956342089}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: / 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.78
wandb: percentage 0.0
wandb:   test_mae 0.73711
wandb:   test_mse 0.97224
wandb:    test_r2 -1.82154
wandb: 
wandb: üöÄ View run upbeat-sweep-87 at: https://wandb.ai/xiaoqiz/mof2vec/runs/80jtlfzg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_203123-80jtlfzg/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: fehqdyzg with config:
wandb: 	data.data.wl_step: 3
wandb: 	data.nn.batch_size: 814
wandb: 	model.gensim.alpha: 0.01120782865103553
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.8233438585711208
wandb: 	model.gensim.vector_size: 279
wandb: 	model.gensim.window: 13
wandb: 	model.sklearn.learning_rate: 0.0005263577763448085
wandb: 	model.sklearn.max_depth: 78
wandb: 	model.sklearn.min_child_weight: 0.0702409096733626
wandb: 	model.sklearn.n_estimators: 2962
wandb: 	model.sklearn.num_leaves: 205
wandb: 	model.sklearn.reg_alpha: 0.023764137759215945
wandb: 	model.sklearn.reg_lambda: 0.03902942655694736
wandb: 	model.sklearn.subsample: 0.8578478326121455
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203308-fehqdyzg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-88
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/fehqdyzg
2023-02-07 20:33:17.448 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 3 for sweep.
2023-02-07 20:33:17.448 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 814 for sweep.
2023-02-07 20:33:17.449 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.01120782865103553 for sweep.
2023-02-07 20:33:17.449 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:33:17.449 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 20:33:17.449 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8233438585711208 for sweep.
2023-02-07 20:33:17.449 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 279 for sweep.
2023-02-07 20:33:17.450 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 13 for sweep.
2023-02-07 20:33:17.450 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0005263577763448085 for sweep.
2023-02-07 20:33:17.450 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 78 for sweep.
2023-02-07 20:33:17.450 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0702409096733626 for sweep.
2023-02-07 20:33:17.450 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2962 for sweep.
2023-02-07 20:33:17.451 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 205 for sweep.
2023-02-07 20:33:17.451 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.023764137759215945 for sweep.
2023-02-07 20:33:17.451 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.03902942655694736 for sweep.
2023-02-07 20:33:17.452 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8578478326121455 for sweep.
2023-02-07 20:33:17.452 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:33:17.457 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 3}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203308-fehqdyzg/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 814, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 279, 'window': 13, 'min_count': 9, 'dm': 0, 'sample': 0.8233438585711208, 'workers': 4, 'alpha': 0.01120782865103553, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2962, 'max_depth': 78, 'num_leaves': 205, 'reg_alpha': 0.023764137759215945, 'reg_lambda': 0.03902942655694736, 'subsample': 0.8578478326121455, 'min_child_weight': 0.0702409096733626, 'n_jobs': 4, 'learning_rate': 0.0005263577763448085}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 29/3257 [00:00<00:11, 288.47it/s]  2%|‚ñè         | 58/3257 [00:00<00:11, 286.48it/s]  3%|‚ñé         | 91/3257 [00:00<00:10, 303.75it/s]  4%|‚ñé         | 122/3257 [00:00<00:10, 297.57it/s]  5%|‚ñç         | 154/3257 [00:00<00:10, 305.40it/s]  6%|‚ñå         | 185/3257 [00:00<00:10, 300.90it/s]  7%|‚ñã         | 220/3257 [00:00<00:09, 315.57it/s]  8%|‚ñä         | 252/3257 [00:00<00:09, 315.48it/s]  9%|‚ñâ         | 285/3257 [00:00<00:09, 317.84it/s] 10%|‚ñâ         | 317/3257 [00:01<00:09, 306.68it/s] 11%|‚ñà         | 348/3257 [00:01<00:09, 304.33it/s] 12%|‚ñà‚ñè        | 379/3257 [00:01<00:09, 293.02it/s] 13%|‚ñà‚ñé        | 409/3257 [00:01<00:09, 292.47it/s] 13%|‚ñà‚ñé        | 439/3257 [00:01<00:10, 264.06it/s] 14%|‚ñà‚ñç        | 471/3257 [00:01<00:10, 278.00it/s] 15%|‚ñà‚ñå        | 500/3257 [00:01<00:09, 279.87it/s] 16%|‚ñà‚ñå        | 529/3257 [00:01<00:09, 280.53it/s] 17%|‚ñà‚ñã        | 558/3257 [00:01<00:09, 271.76it/s] 18%|‚ñà‚ñä        | 586/3257 [00:02<00:10, 255.30it/s] 19%|‚ñà‚ñâ        | 614/3257 [00:02<00:10, 260.47it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:02<00:10, 253.10it/s] 20%|‚ñà‚ñà        | 667/3257 [00:02<00:10, 242.69it/s] 21%|‚ñà‚ñà        | 692/3257 [00:02<00:10, 242.51it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:02<00:10, 246.37it/s] 23%|‚ñà‚ñà‚ñé       | 743/3257 [00:02<00:10, 236.57it/s] 24%|‚ñà‚ñà‚ñé       | 772/3257 [00:02<00:09, 249.26it/s] 25%|‚ñà‚ñà‚ñç       | 798/3257 [00:02<00:09, 249.16it/s] 25%|‚ñà‚ñà‚ñå       | 824/3257 [00:03<00:10, 238.22it/s] 26%|‚ñà‚ñà‚ñå       | 848/3257 [00:03<00:10, 229.96it/s] 27%|‚ñà‚ñà‚ñã       | 874/3257 [00:03<00:10, 236.45it/s] 28%|‚ñà‚ñà‚ñä       | 900/3257 [00:03<00:09, 242.65it/s] 29%|‚ñà‚ñà‚ñä       | 930/3257 [00:03<00:09, 257.48it/s] 29%|‚ñà‚ñà‚ñâ       | 958/3257 [00:03<00:08, 263.16it/s] 30%|‚ñà‚ñà‚ñà       | 985/3257 [00:03<00:08, 260.39it/s] 31%|‚ñà‚ñà‚ñà       | 1012/3257 [00:03<00:09, 247.88it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1037/3257 [00:03<00:09, 243.92it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:03<00:09, 236.61it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:04<00:09, 240.91it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1114/3257 [00:04<00:08, 244.84it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:04<00:13, 157.27it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1166/3257 [00:04<00:11, 179.46it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:04<00:11, 182.63it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1212/3257 [00:04<00:10, 194.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:04<00:09, 218.66it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1270/3257 [00:05<00:08, 232.56it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1295/3257 [00:05<00:08, 222.12it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1323/3257 [00:05<00:08, 236.01it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:05<00:07, 241.47it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1375/3257 [00:05<00:07, 242.83it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:05<00:07, 247.12it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:05<00:06, 261.67it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1464/3257 [00:05<00:06, 277.13it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1492/3257 [00:05<00:06, 277.49it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1520/3257 [00:05<00:06, 270.27it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1548/3257 [00:06<00:06, 256.77it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1575/3257 [00:06<00:06, 254.87it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1605/3257 [00:06<00:06, 266.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:06<00:06, 265.12it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1661/3257 [00:06<00:06, 257.97it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1687/3257 [00:06<00:06, 253.60it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:06<00:06, 256.29it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1741/3257 [00:06<00:06, 242.07it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:06<00:05, 256.30it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1800/3257 [00:07<00:05, 264.45it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1827/3257 [00:07<00:05, 261.55it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1856/3257 [00:07<00:05, 267.32it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1885/3257 [00:07<00:05, 270.71it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:07<00:04, 273.62it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1948/3257 [00:07<00:04, 284.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1978/3257 [00:07<00:04, 284.72it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2007/3257 [00:07<00:04, 281.85it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2036/3257 [00:07<00:04, 283.28it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2065/3257 [00:08<00:04, 264.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2095/3257 [00:08<00:04, 270.72it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2123/3257 [00:08<00:04, 258.14it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2150/3257 [00:08<00:04, 259.91it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2180/3257 [00:08<00:03, 270.32it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2208/3257 [00:08<00:03, 272.14it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:08<00:03, 271.41it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2264/3257 [00:08<00:03, 265.78it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2291/3257 [00:08<00:03, 266.98it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2322/3257 [00:08<00:03, 277.42it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2358/3257 [00:09<00:02, 300.23it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2389/3257 [00:09<00:02, 296.36it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2419/3257 [00:09<00:02, 282.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2448/3257 [00:09<00:04, 188.69it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:09<00:03, 217.39it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:09<00:03, 241.78it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2545/3257 [00:09<00:02, 257.27it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2574/3257 [00:10<00:02, 255.29it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2602/3257 [00:10<00:02, 261.16it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2637/3257 [00:10<00:02, 285.08it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2667/3257 [00:10<00:02, 279.31it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2696/3257 [00:10<00:02, 276.12it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2725/3257 [00:10<00:01, 271.25it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2757/3257 [00:10<00:01, 284.45it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2786/3257 [00:10<00:01, 274.81it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2814/3257 [00:10<00:01, 259.74it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2841/3257 [00:11<00:01, 238.82it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2869/3257 [00:11<00:01, 248.76it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2895/3257 [00:11<00:01, 233.50it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2920/3257 [00:11<00:01, 235.09it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2944/3257 [00:11<00:01, 224.57it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:11<00:01, 229.64it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2993/3257 [00:11<00:01, 222.15it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:11<00:01, 227.12it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3045/3257 [00:11<00:00, 238.39it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3072/3257 [00:12<00:00, 246.15it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3097/3257 [00:12<00:00, 245.25it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:12<00:00, 256.03it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3153/3257 [00:12<00:00, 241.29it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3178/3257 [00:12<00:00, 232.78it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3206/3257 [00:12<00:00, 245.15it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3231/3257 [00:12<00:00, 242.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3256/3257 [00:12<00:00, 244.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:12<00:00, 255.12it/s]
2023-02-07 20:33:30.637 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:33:30,638][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d279,n5,mc9,s0.823344,t4>', 'datetime': '2023-02-07T20:33:30.638267', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:33:30,638][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:33:30,638][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:33:30,926][gensim.models.doc2vec][INFO] - collected 6662 word types and 3257 unique tags from a corpus of 3257 examples and 2911496 words
[2023-02-07 20:33:30,926][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:33:30,936][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 2762 unique words (41.46% of original 6662, drops 3900)', 'datetime': '2023-02-07T20:33:30.936162', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:33:30,936][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 2897962 word corpus (99.54% of original 2911496, drops 13534)', 'datetime': '2023-02-07T20:33:30.936622', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:33:30,946][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 6662 items
[2023-02-07 20:33:30,948][gensim.models.word2vec][INFO] - sample=0.823344 downsamples 0 most-common words
[2023-02-07 20:33:30,948][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2897962 word corpus (100.0%% of prior 2897962)', 'datetime': '2023-02-07T20:33:30.948606', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:33:30,966][gensim.models.word2vec][INFO] - estimated required memory for 2762 words and 279 dimensions: 11831996 bytes
[2023-02-07 20:33:30,966][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:33:30,974][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 2762 vocabulary and 279 features, using sg=1 hs=0 sample=0.8233438585711208 negative=5 window=13 shrink_windows=True', 'datetime': '2023-02-07T20:33:30.974049', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:33:31,983][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 71.66% examples, 2106905 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:32,317][gensim.models.word2vec][INFO] - EPOCH 0: training on 2911496 raw words (2901219 effective words) took 1.3s, 2164614 effective words/s
[2023-02-07 20:33:33,320][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 86.67% examples, 2534050 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:33:33,465][gensim.models.word2vec][INFO] - EPOCH 1: training on 2911496 raw words (2901219 effective words) took 1.1s, 2532237 effective words/s
[2023-02-07 20:33:34,472][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 83.94% examples, 2448105 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:33:34,643][gensim.models.word2vec][INFO] - EPOCH 2: training on 2911496 raw words (2901219 effective words) took 1.2s, 2466964 effective words/s
[2023-02-07 20:33:35,647][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 84.74% examples, 2475595 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:33:35,811][gensim.models.word2vec][INFO] - EPOCH 3: training on 2911496 raw words (2901219 effective words) took 1.2s, 2490017 effective words/s
[2023-02-07 20:33:36,821][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 85.78% examples, 2487838 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:36,952][gensim.models.word2vec][INFO] - EPOCH 4: training on 2911496 raw words (2901219 effective words) took 1.1s, 2546117 effective words/s
[2023-02-07 20:33:37,921][gensim.models.word2vec][INFO] - EPOCH 5: training on 2911496 raw words (2901219 effective words) took 1.0s, 2998969 effective words/s
[2023-02-07 20:33:38,924][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 90.70% examples, 2647175 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:39,014][gensim.models.word2vec][INFO] - EPOCH 6: training on 2911496 raw words (2901219 effective words) took 1.1s, 2659006 effective words/s
[2023-02-07 20:33:40,016][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 90.73% examples, 2650724 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:33:40,109][gensim.models.word2vec][INFO] - EPOCH 7: training on 2911496 raw words (2901219 effective words) took 1.1s, 2652104 effective words/s
[2023-02-07 20:33:41,111][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 91.34% examples, 2665758 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:41,198][gensim.models.word2vec][INFO] - EPOCH 8: training on 2911496 raw words (2901219 effective words) took 1.1s, 2668452 effective words/s
[2023-02-07 20:33:42,201][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 90.73% examples, 2649127 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:42,294][gensim.models.word2vec][INFO] - EPOCH 9: training on 2911496 raw words (2901219 effective words) took 1.1s, 2653561 effective words/s
[2023-02-07 20:33:43,298][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 91.86% examples, 2679932 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:43,372][gensim.models.word2vec][INFO] - EPOCH 10: training on 2911496 raw words (2901219 effective words) took 1.1s, 2695077 effective words/s
[2023-02-07 20:33:44,375][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 91.86% examples, 2682866 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:44,448][gensim.models.word2vec][INFO] - EPOCH 11: training on 2911496 raw words (2901219 effective words) took 1.1s, 2698272 effective words/s
[2023-02-07 20:33:45,456][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 93.00% examples, 2697706 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:45,518][gensim.models.word2vec][INFO] - EPOCH 12: training on 2911496 raw words (2901219 effective words) took 1.1s, 2714702 effective words/s
[2023-02-07 20:33:46,523][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 93.49% examples, 2717531 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:33:46,581][gensim.models.word2vec][INFO] - EPOCH 13: training on 2911496 raw words (2901219 effective words) took 1.1s, 2733396 effective words/s
[2023-02-07 20:33:47,586][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 91.53% examples, 2668726 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:33:47,673][gensim.models.word2vec][INFO] - EPOCH 14: training on 2911496 raw words (2901219 effective words) took 1.1s, 2659485 effective words/s
[2023-02-07 20:33:47,674][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 43672440 raw words (43518285 effective words) took 16.7s, 2605860 effective words/s', 'datetime': '2023-02-07T20:33:47.674665', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:33:47.674 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:33:49,284][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203308-fehqdyzg/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:33:49.284036', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:33:49,284][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:33:49,309][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203308-fehqdyzg/files/../tmp/embedding_model.pt
2023-02-07 20:33:49.309 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:33:51.188 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:33:51.882 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:33:53.880 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9221626963447738, 'test_mae': 0.7086168111193399, 'test_r2': -1.8611824297146353}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.85
wandb: percentage 0.58541
wandb:   test_mae 0.70862
wandb:   test_mse 0.92216
wandb:    test_r2 -1.86118
wandb: 
wandb: üöÄ View run expert-sweep-88 at: https://wandb.ai/xiaoqiz/mof2vec/runs/fehqdyzg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_203308-fehqdyzg/logs
wandb: Agent Starting Run: 5torgcnl with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 635
wandb: 	model.gensim.alpha: 0.0027303412131525775
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 5
wandb: 	model.gensim.sample: 0.8235196464838697
wandb: 	model.gensim.vector_size: 424
wandb: 	model.gensim.window: 18
wandb: 	model.sklearn.learning_rate: 0.0007170310339906024
wandb: 	model.sklearn.max_depth: 78
wandb: 	model.sklearn.min_child_weight: 0.0562883003806931
wandb: 	model.sklearn.n_estimators: 2695
wandb: 	model.sklearn.num_leaves: 32
wandb: 	model.sklearn.reg_alpha: 0.006944877009046088
wandb: 	model.sklearn.reg_lambda: 0.004987805558008113
wandb: 	model.sklearn.subsample: 0.7756636619177644
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203404-5torgcnl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-89
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/5torgcnl
2023-02-07 20:34:13.278 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 20:34:13.279 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 635 for sweep.
2023-02-07 20:34:13.279 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.0027303412131525775 for sweep.
2023-02-07 20:34:13.280 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:34:13.280 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 5 for sweep.
2023-02-07 20:34:13.280 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8235196464838697 for sweep.
2023-02-07 20:34:13.280 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 424 for sweep.
2023-02-07 20:34:13.281 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 18 for sweep.
2023-02-07 20:34:13.281 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0007170310339906024 for sweep.
2023-02-07 20:34:13.281 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 78 for sweep.
2023-02-07 20:34:13.281 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0562883003806931 for sweep.
2023-02-07 20:34:13.282 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2695 for sweep.
2023-02-07 20:34:13.282 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 32 for sweep.
2023-02-07 20:34:13.282 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.006944877009046088 for sweep.
2023-02-07 20:34:13.282 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.004987805558008113 for sweep.
2023-02-07 20:34:13.283 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7756636619177644 for sweep.
2023-02-07 20:34:13.283 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:34:13.293 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203404-5torgcnl/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 635, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 424, 'window': 18, 'min_count': 5, 'dm': 0, 'sample': 0.8235196464838697, 'workers': 4, 'alpha': 0.0027303412131525775, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2695, 'max_depth': 78, 'num_leaves': 32, 'reg_alpha': 0.006944877009046088, 'reg_lambda': 0.004987805558008113, 'subsample': 0.7756636619177644, 'min_child_weight': 0.0562883003806931, 'n_jobs': 4, 'learning_rate': 0.0007170310339906024}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:20, 161.93it/s]  1%|          | 36/3257 [00:00<00:18, 175.92it/s]  2%|‚ñè         | 54/3257 [00:00<00:18, 170.72it/s]  2%|‚ñè         | 75/3257 [00:00<00:17, 184.86it/s]  3%|‚ñé         | 94/3257 [00:00<00:17, 180.83it/s]  3%|‚ñé         | 113/3257 [00:00<00:18, 174.36it/s]  4%|‚ñç         | 132/3257 [00:00<00:17, 175.95it/s]  5%|‚ñç         | 158/3257 [00:00<00:15, 198.73it/s]  5%|‚ñå         | 179/3257 [00:00<00:15, 201.88it/s]  6%|‚ñå         | 203/3257 [00:01<00:14, 212.95it/s]  7%|‚ñã         | 232/3257 [00:01<00:12, 234.63it/s]  8%|‚ñä         | 257/3257 [00:01<00:12, 237.06it/s]  9%|‚ñâ         | 285/3257 [00:01<00:11, 249.45it/s] 10%|‚ñâ         | 311/3257 [00:01<00:11, 245.75it/s] 10%|‚ñà         | 336/3257 [00:01<00:12, 243.37it/s] 11%|‚ñà         | 361/3257 [00:01<00:11, 244.93it/s] 12%|‚ñà‚ñè        | 386/3257 [00:01<00:12, 231.97it/s] 13%|‚ñà‚ñé        | 412/3257 [00:01<00:11, 238.19it/s] 13%|‚ñà‚ñé        | 436/3257 [00:02<00:13, 207.66it/s] 14%|‚ñà‚ñç        | 461/3257 [00:02<00:12, 216.85it/s] 15%|‚ñà‚ñç        | 484/3257 [00:02<00:12, 216.76it/s] 16%|‚ñà‚ñå        | 510/3257 [00:02<00:12, 228.15it/s] 16%|‚ñà‚ñã        | 534/3257 [00:02<00:12, 220.86it/s] 17%|‚ñà‚ñã        | 558/3257 [00:02<00:12, 214.87it/s] 18%|‚ñà‚ñä        | 580/3257 [00:02<00:12, 208.11it/s] 19%|‚ñà‚ñä        | 604/3257 [00:02<00:12, 216.59it/s] 19%|‚ñà‚ñâ        | 627/3257 [00:02<00:11, 219.60it/s] 20%|‚ñà‚ñâ        | 650/3257 [00:03<00:11, 218.91it/s] 21%|‚ñà‚ñà        | 673/3257 [00:03<00:12, 211.46it/s] 21%|‚ñà‚ñà‚ñè       | 695/3257 [00:03<00:12, 204.09it/s] 22%|‚ñà‚ñà‚ñè       | 716/3257 [00:03<00:17, 145.42it/s] 23%|‚ñà‚ñà‚ñé       | 735/3257 [00:03<00:16, 154.49it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:03<00:15, 162.26it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:03<00:14, 172.50it/s] 25%|‚ñà‚ñà‚ñç       | 801/3257 [00:03<00:12, 192.45it/s] 25%|‚ñà‚ñà‚ñå       | 822/3257 [00:04<00:12, 191.72it/s] 26%|‚ñà‚ñà‚ñå       | 842/3257 [00:04<00:12, 187.16it/s] 27%|‚ñà‚ñà‚ñã       | 864/3257 [00:04<00:12, 192.60it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:04<00:12, 189.60it/s] 28%|‚ñà‚ñà‚ñä       | 909/3257 [00:04<00:11, 205.72it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:04<00:11, 209.40it/s] 29%|‚ñà‚ñà‚ñâ       | 955/3257 [00:04<00:10, 217.74it/s] 30%|‚ñà‚ñà‚ñâ       | 977/3257 [00:04<00:10, 216.59it/s] 31%|‚ñà‚ñà‚ñà       | 999/3257 [00:04<00:11, 205.08it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1021/3257 [00:04<00:10, 208.22it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1042/3257 [00:05<00:11, 193.65it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1065/3257 [00:05<00:10, 201.88it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1086/3257 [00:05<00:10, 200.43it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1107/3257 [00:05<00:10, 198.30it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1127/3257 [00:05<00:11, 191.70it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1147/3257 [00:05<00:11, 190.38it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:05<00:10, 200.68it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1192/3257 [00:05<00:11, 187.33it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1211/3257 [00:05<00:10, 187.03it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1235/3257 [00:06<00:10, 200.97it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1256/3257 [00:06<00:10, 199.19it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:06<00:10, 194.44it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1297/3257 [00:06<00:10, 186.92it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:06<00:09, 197.92it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1345/3257 [00:06<00:09, 207.90it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1366/3257 [00:06<00:09, 199.93it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1387/3257 [00:06<00:09, 195.32it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:06<00:08, 208.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1435/3257 [00:07<00:08, 210.97it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1461/3257 [00:07<00:07, 224.66it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1484/3257 [00:07<00:07, 225.40it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1512/3257 [00:07<00:07, 238.15it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1536/3257 [00:07<00:07, 215.89it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1559/3257 [00:07<00:08, 208.79it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1581/3257 [00:07<00:08, 208.05it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1606/3257 [00:07<00:07, 219.55it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1631/3257 [00:07<00:07, 228.09it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1655/3257 [00:08<00:07, 211.69it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1677/3257 [00:08<00:07, 200.65it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:08<00:07, 206.35it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:08<00:07, 210.43it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1745/3257 [00:08<00:07, 192.30it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1768/3257 [00:08<00:07, 201.53it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:08<00:06, 211.57it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:08<00:07, 203.12it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1837/3257 [00:08<00:06, 210.52it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1859/3257 [00:09<00:06, 208.91it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1883/3257 [00:09<00:06, 215.91it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1907/3257 [00:09<00:06, 221.41it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1930/3257 [00:09<00:06, 210.49it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:09<00:05, 236.75it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1985/3257 [00:09<00:05, 223.99it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2009/3257 [00:09<00:05, 227.41it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2034/3257 [00:09<00:05, 231.70it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2058/3257 [00:09<00:05, 216.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2080/3257 [00:10<00:05, 210.39it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2102/3257 [00:10<00:10, 112.84it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:10<00:09, 123.22it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2137/3257 [00:10<00:08, 131.27it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:10<00:08, 137.38it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2174/3257 [00:10<00:07, 150.86it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2192/3257 [00:11<00:06, 155.62it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2210/3257 [00:11<00:06, 155.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2229/3257 [00:11<00:06, 164.37it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2247/3257 [00:11<00:06, 163.96it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2266/3257 [00:11<00:05, 168.23it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2284/3257 [00:11<00:05, 169.08it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2302/3257 [00:11<00:05, 169.47it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2324/3257 [00:11<00:05, 183.27it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2345/3257 [00:11<00:04, 189.32it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2367/3257 [00:11<00:04, 193.36it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2387/3257 [00:12<00:04, 195.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2407/3257 [00:12<00:04, 187.51it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2426/3257 [00:12<00:04, 187.79it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2445/3257 [00:12<00:04, 173.08it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2465/3257 [00:12<00:04, 179.70it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2484/3257 [00:12<00:04, 178.44it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:12<00:03, 191.21it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2528/3257 [00:12<00:03, 196.15it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2548/3257 [00:12<00:03, 194.46it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2568/3257 [00:13<00:03, 173.86it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:13<00:03, 174.86it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2606/3257 [00:13<00:03, 181.16it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2629/3257 [00:13<00:03, 194.76it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2649/3257 [00:13<00:03, 185.55it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2668/3257 [00:13<00:03, 183.74it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2688/3257 [00:13<00:03, 185.43it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2707/3257 [00:13<00:03, 168.75it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2725/3257 [00:13<00:03, 169.18it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2746/3257 [00:14<00:02, 178.04it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2765/3257 [00:14<00:02, 177.60it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2783/3257 [00:14<00:02, 174.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2804/3257 [00:14<00:02, 183.79it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2823/3257 [00:14<00:02, 176.08it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2841/3257 [00:14<00:02, 167.31it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2864/3257 [00:14<00:02, 183.62it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:14<00:01, 188.76it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:14<00:01, 176.99it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:15<00:01, 182.89it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:15<00:01, 176.89it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:15<00:01, 179.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:15<00:01, 171.99it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3006/3257 [00:15<00:01, 182.17it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3025/3257 [00:15<00:01, 176.40it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3047/3257 [00:15<00:01, 186.42it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3069/3257 [00:15<00:00, 193.94it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3089/3257 [00:15<00:00, 191.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3112/3257 [00:16<00:00, 200.44it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3133/3257 [00:16<00:00, 197.66it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3153/3257 [00:16<00:00, 186.53it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3172/3257 [00:16<00:00, 186.15it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3191/3257 [00:16<00:00, 185.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3210/3257 [00:16<00:00, 186.32it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3229/3257 [00:16<00:00, 185.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3253/3257 [00:16<00:00, 193.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 193.47it/s]
2023-02-07 20:34:30.774 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:34:30,776][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d424,n5,mc5,s0.82352,t4>', 'datetime': '2023-02-07T20:34:30.776325', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:34:30,777][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:34:30,778][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:34:31,205][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 20:34:31,205][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:34:31,240][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 11219 unique words (51.70% of original 21699, drops 10480)', 'datetime': '2023-02-07T20:34:31.240830', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:34:31,241][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 4341582 word corpus (99.41% of original 4367244, drops 25662)', 'datetime': '2023-02-07T20:34:31.241270', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:34:31,280][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 20:34:31,281][gensim.models.word2vec][INFO] - sample=0.82352 downsamples 0 most-common words
[2023-02-07 20:34:31,282][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4341582 word corpus (100.0%% of prior 4341582)', 'datetime': '2023-02-07T20:34:31.282942', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:34:31,354][gensim.models.word2vec][INFO] - estimated required memory for 11219 words and 424 dimensions: 49839620 bytes
[2023-02-07 20:34:31,354][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:34:31,382][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11219 vocabulary and 424 features, using sg=1 hs=0 sample=0.8235196464838697 negative=5 window=18 shrink_windows=True', 'datetime': '2023-02-07T20:34:31.382054', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:34:32,388][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 37.98% examples, 1682377 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:34:33,389][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 80.87% examples, 1766664 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:34:33,840][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4343128 effective words) took 2.5s, 1769687 effective words/s
[2023-02-07 20:34:34,845][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 41.17% examples, 1828798 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:35,847][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 85.02% examples, 1859598 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:36,167][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4343128 effective words) took 2.3s, 1867748 effective words/s
[2023-02-07 20:34:37,179][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 42.77% examples, 1896651 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:34:38,179][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 87.69% examples, 1910236 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:38,441][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4343128 effective words) took 2.3s, 1911265 effective words/s
[2023-02-07 20:34:39,443][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 42.62% examples, 1909448 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:34:40,450][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 87.38% examples, 1908132 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:40,710][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4343128 effective words) took 2.3s, 1915271 effective words/s
[2023-02-07 20:34:41,725][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 40.99% examples, 1802557 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:42,731][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 81.61% examples, 1771161 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:43,168][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4343128 effective words) took 2.5s, 1767860 effective words/s
[2023-02-07 20:34:44,173][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 38.84% examples, 1726384 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:45,180][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 79.31% examples, 1735276 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:45,671][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4343128 effective words) took 2.5s, 1737475 effective words/s
[2023-02-07 20:34:46,673][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 39.18% examples, 1746721 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:47,673][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 79.31% examples, 1741598 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:34:48,165][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4343128 effective words) took 2.5s, 1742407 effective words/s
[2023-02-07 20:34:49,179][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 38.62% examples, 1702088 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:34:50,180][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 82.07% examples, 1785658 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:50,525][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4343128 effective words) took 2.4s, 1842710 effective words/s
[2023-02-07 20:34:51,531][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 49.40% examples, 2176931 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:52,481][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4343128 effective words) took 2.0s, 2221251 effective words/s
[2023-02-07 20:34:53,483][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 48.54% examples, 2151158 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:54,484][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 94.87% examples, 2064412 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:54,588][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4343128 effective words) took 2.1s, 2062841 effective words/s
[2023-02-07 20:34:55,591][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 44.24% examples, 1968000 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:34:56,593][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 89.07% examples, 1945055 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:34:56,813][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4343128 effective words) took 2.2s, 1953062 effective words/s
[2023-02-07 20:34:57,816][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 45.53% examples, 2016511 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:34:58,820][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 92.14% examples, 2010063 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:34:58,972][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4343128 effective words) took 2.2s, 2014188 effective words/s
[2023-02-07 20:34:59,986][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 44.83% examples, 1965435 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:35:00,989][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 91.25% examples, 1980505 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:35:01,162][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4343128 effective words) took 2.2s, 1985138 effective words/s
[2023-02-07 20:35:02,164][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 44.24% examples, 1971199 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:35:03,168][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 90.57% examples, 1977407 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:35:03,354][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4343128 effective words) took 2.2s, 1982739 effective words/s
[2023-02-07 20:35:04,363][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 45.81% examples, 2014590 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:35:05,372][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 93.00% examples, 2017302 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:35:05,503][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4343128 effective words) took 2.1s, 2023767 effective words/s
[2023-02-07 20:35:05,503][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65146920 effective words) took 34.1s, 1909274 effective words/s', 'datetime': '2023-02-07T20:35:05.503841', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:35:05.504 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:35:08,235][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203404-5torgcnl/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:35:08.235867', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:35:08,237][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:35:08,303][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203404-5torgcnl/files/../tmp/embedding_model.pt
2023-02-07 20:35:08.304 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:35:10.506 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:35:11.289 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:35:14.128 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9458795118732937, 'test_mae': 0.7554785408582424, 'test_r2': -1.68870562143811}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.55
wandb: percentage 0.48297
wandb:   test_mae 0.75548
wandb:   test_mse 0.94588
wandb:    test_r2 -1.68871
wandb: 
wandb: üöÄ View run pious-sweep-89 at: https://wandb.ai/xiaoqiz/mof2vec/runs/5torgcnl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_203404-5torgcnl/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 82ov7mw5 with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 874
wandb: 	model.gensim.alpha: 0.013556646250636724
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.9968881102845036
wandb: 	model.gensim.vector_size: 215
wandb: 	model.gensim.window: 12
wandb: 	model.sklearn.learning_rate: 0.0073797900691553505
wandb: 	model.sklearn.max_depth: 37
wandb: 	model.sklearn.min_child_weight: 0.031097285456720965
wandb: 	model.sklearn.n_estimators: 2380
wandb: 	model.sklearn.num_leaves: 63
wandb: 	model.sklearn.reg_alpha: 0.033358416376143216
wandb: 	model.sklearn.reg_lambda: 0.2098436405262062
wandb: 	model.sklearn.subsample: 0.9602809656173814
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203533-82ov7mw5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-90
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/82ov7mw5
2023-02-07 20:35:41.078 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:35:41.079 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 874 for sweep.
2023-02-07 20:35:41.079 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.013556646250636724 for sweep.
2023-02-07 20:35:41.080 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:35:41.080 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 20:35:41.080 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9968881102845036 for sweep.
2023-02-07 20:35:41.080 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 215 for sweep.
2023-02-07 20:35:41.081 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 12 for sweep.
2023-02-07 20:35:41.081 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0073797900691553505 for sweep.
2023-02-07 20:35:41.081 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 37 for sweep.
2023-02-07 20:35:41.082 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.031097285456720965 for sweep.
2023-02-07 20:35:41.082 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2380 for sweep.
2023-02-07 20:35:41.082 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 63 for sweep.
2023-02-07 20:35:41.082 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.033358416376143216 for sweep.
2023-02-07 20:35:41.083 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.2098436405262062 for sweep.
2023-02-07 20:35:41.083 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9602809656173814 for sweep.
2023-02-07 20:35:41.083 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:35:41.092 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203533-82ov7mw5/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 874, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 215, 'window': 12, 'min_count': 6, 'dm': 0, 'sample': 0.9968881102845036, 'workers': 4, 'alpha': 0.013556646250636724, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2380, 'max_depth': 37, 'num_leaves': 63, 'reg_alpha': 0.033358416376143216, 'reg_lambda': 0.2098436405262062, 'subsample': 0.9602809656173814, 'min_child_weight': 0.031097285456720965, 'n_jobs': 4, 'learning_rate': 0.0073797900691553505}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 138.67it/s]  1%|          | 30/3257 [00:00<00:22, 142.97it/s]  1%|‚ñè         | 45/3257 [00:00<00:22, 143.63it/s]  2%|‚ñè         | 60/3257 [00:00<00:22, 141.02it/s]  2%|‚ñè         | 77/3257 [00:00<00:21, 148.84it/s]  3%|‚ñé         | 93/3257 [00:00<00:20, 152.02it/s]  3%|‚ñé         | 109/3257 [00:00<00:22, 140.57it/s]  4%|‚ñç         | 124/3257 [00:00<00:21, 142.80it/s]  4%|‚ñç         | 141/3257 [00:00<00:20, 149.31it/s]  5%|‚ñç         | 158/3257 [00:01<00:20, 149.94it/s]  5%|‚ñå         | 174/3257 [00:01<00:21, 145.19it/s]  6%|‚ñå         | 189/3257 [00:01<00:30, 101.14it/s]  6%|‚ñå         | 202/3257 [00:01<00:28, 107.19it/s]  7%|‚ñã         | 221/3257 [00:01<00:24, 124.99it/s]  7%|‚ñã         | 240/3257 [00:01<00:21, 140.16it/s]  8%|‚ñä         | 256/3257 [00:01<00:20, 144.52it/s]  8%|‚ñä         | 272/3257 [00:01<00:20, 142.60it/s]  9%|‚ñâ         | 293/3257 [00:02<00:18, 159.88it/s] 10%|‚ñâ         | 310/3257 [00:02<00:19, 154.17it/s] 10%|‚ñà         | 328/3257 [00:02<00:18, 158.00it/s] 11%|‚ñà         | 345/3257 [00:02<00:18, 157.05it/s] 11%|‚ñà         | 363/3257 [00:02<00:17, 162.33it/s] 12%|‚ñà‚ñè        | 380/3257 [00:02<00:18, 158.57it/s] 12%|‚ñà‚ñè        | 397/3257 [00:02<00:17, 159.44it/s] 13%|‚ñà‚ñé        | 416/3257 [00:02<00:17, 166.41it/s] 13%|‚ñà‚ñé        | 433/3257 [00:03<00:20, 140.41it/s] 14%|‚ñà‚ñç        | 450/3257 [00:03<00:19, 146.97it/s] 14%|‚ñà‚ñç        | 472/3257 [00:03<00:16, 164.48it/s] 15%|‚ñà‚ñå        | 492/3257 [00:03<00:16, 172.39it/s] 16%|‚ñà‚ñå        | 514/3257 [00:03<00:14, 184.33it/s] 16%|‚ñà‚ñã        | 533/3257 [00:03<00:14, 182.10it/s] 17%|‚ñà‚ñã        | 555/3257 [00:03<00:14, 190.65it/s] 18%|‚ñà‚ñä        | 575/3257 [00:03<00:16, 167.27it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:14, 182.15it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:04<00:14, 185.30it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:04<00:13, 188.97it/s] 20%|‚ñà‚ñà        | 661/3257 [00:04<00:15, 172.06it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:14, 174.08it/s] 22%|‚ñà‚ñà‚ñè       | 702/3257 [00:04<00:14, 176.26it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:04<00:14, 176.34it/s] 23%|‚ñà‚ñà‚ñé       | 739/3257 [00:04<00:15, 166.30it/s] 23%|‚ñà‚ñà‚ñé       | 761/3257 [00:04<00:13, 179.59it/s] 24%|‚ñà‚ñà‚ñç       | 780/3257 [00:04<00:14, 173.64it/s] 25%|‚ñà‚ñà‚ñç       | 799/3257 [00:05<00:14, 174.97it/s] 25%|‚ñà‚ñà‚ñå       | 817/3257 [00:05<00:14, 173.04it/s] 26%|‚ñà‚ñà‚ñå       | 835/3257 [00:05<00:14, 161.74it/s] 26%|‚ñà‚ñà‚ñå       | 852/3257 [00:05<00:15, 152.44it/s] 27%|‚ñà‚ñà‚ñã       | 869/3257 [00:05<00:15, 156.37it/s] 27%|‚ñà‚ñà‚ñã       | 885/3257 [00:05<00:15, 153.81it/s] 28%|‚ñà‚ñà‚ñä       | 906/3257 [00:05<00:14, 165.91it/s] 28%|‚ñà‚ñà‚ñä       | 925/3257 [00:05<00:13, 170.38it/s] 29%|‚ñà‚ñà‚ñâ       | 943/3257 [00:05<00:13, 168.15it/s] 30%|‚ñà‚ñà‚ñâ       | 963/3257 [00:06<00:13, 176.04it/s] 30%|‚ñà‚ñà‚ñà       | 981/3257 [00:06<00:13, 168.58it/s] 31%|‚ñà‚ñà‚ñà       | 998/3257 [00:06<00:13, 165.01it/s] 31%|‚ñà‚ñà‚ñà       | 1015/3257 [00:06<00:13, 166.30it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1032/3257 [00:06<00:13, 163.13it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1049/3257 [00:06<00:14, 156.11it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1065/3257 [00:06<00:14, 152.65it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1081/3257 [00:06<00:14, 145.85it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1096/3257 [00:06<00:14, 145.97it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:07<00:14, 146.53it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1127/3257 [00:07<00:15, 134.98it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1141/3257 [00:07<00:15, 133.36it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1157/3257 [00:07<00:15, 138.88it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1172/3257 [00:07<00:15, 137.95it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1186/3257 [00:07<00:15, 129.95it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1200/3257 [00:07<00:16, 123.93it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1213/3257 [00:07<00:16, 123.53it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1233/3257 [00:07<00:14, 141.32it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1248/3257 [00:08<00:14, 138.43it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1263/3257 [00:08<00:14, 140.63it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1278/3257 [00:08<00:15, 129.51it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1292/3257 [00:08<00:15, 126.27it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1307/3257 [00:08<00:14, 130.52it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:08<00:14, 132.12it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1337/3257 [00:08<00:13, 139.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1352/3257 [00:08<00:14, 132.63it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1366/3257 [00:08<00:14, 132.45it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1381/3257 [00:09<00:14, 132.45it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1396/3257 [00:09<00:13, 136.79it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1413/3257 [00:09<00:12, 143.15it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1431/3257 [00:09<00:11, 153.21it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1447/3257 [00:09<00:11, 150.93it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1464/3257 [00:09<00:11, 154.86it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1480/3257 [00:09<00:19, 93.09it/s]  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1502/3257 [00:10<00:14, 117.82it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1519/3257 [00:10<00:13, 125.92it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1535/3257 [00:10<00:13, 132.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1552/3257 [00:10<00:12, 140.87it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1570/3257 [00:10<00:11, 150.78it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1587/3257 [00:10<00:10, 153.46it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1609/3257 [00:10<00:09, 170.46it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1628/3257 [00:10<00:09, 175.03it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1647/3257 [00:10<00:09, 164.88it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1664/3257 [00:11<00:09, 162.36it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1681/3257 [00:11<00:09, 163.88it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1700/3257 [00:11<00:09, 168.91it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1718/3257 [00:11<00:09, 170.87it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1736/3257 [00:11<00:09, 158.99it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1756/3257 [00:11<00:08, 168.73it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1776/3257 [00:11<00:08, 173.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:11<00:08, 180.59it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1815/3257 [00:11<00:08, 175.42it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1833/3257 [00:11<00:08, 173.55it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1853/3257 [00:12<00:07, 179.16it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1875/3257 [00:12<00:07, 187.97it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1894/3257 [00:12<00:07, 179.76it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:12<00:07, 184.18it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1938/3257 [00:12<00:06, 193.54it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1964/3257 [00:12<00:06, 211.07it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1986/3257 [00:12<00:06, 197.70it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2007/3257 [00:12<00:06, 186.20it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2026/3257 [00:13<00:06, 184.84it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2045/3257 [00:13<00:07, 170.30it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2063/3257 [00:13<00:07, 151.75it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2079/3257 [00:13<00:07, 153.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2095/3257 [00:13<00:07, 152.39it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2111/3257 [00:13<00:07, 151.81it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2127/3257 [00:13<00:08, 140.98it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2142/3257 [00:13<00:07, 141.20it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2157/3257 [00:13<00:07, 142.93it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2173/3257 [00:14<00:07, 147.31it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2188/3257 [00:14<00:07, 143.01it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2204/3257 [00:14<00:07, 147.03it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:14<00:07, 143.68it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:14<00:06, 147.10it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2251/3257 [00:14<00:07, 142.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2266/3257 [00:14<00:06, 142.90it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2281/3257 [00:14<00:06, 141.78it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:14<00:06, 146.44it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2316/3257 [00:15<00:06, 151.71it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:15<00:05, 164.99it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:15<00:05, 176.76it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2378/3257 [00:15<00:05, 175.76it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:15<00:04, 176.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2415/3257 [00:15<00:05, 160.50it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2432/3257 [00:15<00:05, 148.89it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2448/3257 [00:15<00:05, 146.00it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2469/3257 [00:15<00:04, 160.94it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2486/3257 [00:16<00:04, 158.81it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2509/3257 [00:16<00:04, 177.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2531/3257 [00:16<00:03, 187.97it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2551/3257 [00:16<00:03, 186.40it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2570/3257 [00:16<00:04, 171.72it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2588/3257 [00:16<00:03, 170.94it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2610/3257 [00:16<00:03, 183.93it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:16<00:03, 197.55it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2654/3257 [00:16<00:03, 187.48it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:17<00:03, 188.17it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2693/3257 [00:17<00:02, 191.39it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2713/3257 [00:17<00:03, 170.19it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:17<00:03, 172.79it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2754/3257 [00:17<00:02, 184.28it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2773/3257 [00:17<00:02, 170.32it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2794/3257 [00:17<00:02, 179.16it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:17<00:02, 174.46it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2831/3257 [00:17<00:02, 165.68it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2851/3257 [00:18<00:02, 172.87it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2876/3257 [00:18<00:01, 193.89it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2896/3257 [00:18<00:03, 105.51it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:18<00:02, 120.32it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2933/3257 [00:18<00:02, 129.72it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:18<00:02, 132.83it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:19<00:01, 144.95it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2986/3257 [00:19<00:01, 141.48it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3009/3257 [00:19<00:01, 163.22it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3027/3257 [00:19<00:01, 158.92it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3048/3257 [00:19<00:01, 169.79it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3069/3257 [00:19<00:01, 178.74it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3088/3257 [00:19<00:00, 172.73it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3109/3257 [00:19<00:00, 179.99it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3129/3257 [00:19<00:00, 183.47it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3148/3257 [00:20<00:00, 170.64it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3166/3257 [00:20<00:00, 170.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3184/3257 [00:20<00:00, 164.41it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3204/3257 [00:20<00:00, 172.77it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3222/3257 [00:20<00:00, 164.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3243/3257 [00:20<00:00, 176.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 157.64it/s]
2023-02-07 20:36:02.567 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:36:02,568][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d215,n5,mc6,s0.996888,t4>', 'datetime': '2023-02-07T20:36:02.568628', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:36:02,568][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:36:02,569][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:36:03,107][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:36:03,107][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:36:03,169][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 20659 unique words (48.38% of original 42701, drops 22042)', 'datetime': '2023-02-07T20:36:03.169079', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:36:03,169][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 5765964 word corpus (99.02% of original 5822992, drops 57028)', 'datetime': '2023-02-07T20:36:03.169481', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:36:03,240][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:36:03,241][gensim.models.word2vec][INFO] - sample=0.996888 downsamples 0 most-common words
[2023-02-07 20:36:03,242][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5765964 word corpus (100.0%% of prior 5765964)', 'datetime': '2023-02-07T20:36:03.241980', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:36:03,362][gensim.models.word2vec][INFO] - estimated required memory for 20659 words and 215 dimensions: 49315400 bytes
[2023-02-07 20:36:03,363][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:36:03,384][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 20659 vocabulary and 215 features, using sg=1 hs=0 sample=0.9968881102845036 negative=5 window=12 shrink_windows=True', 'datetime': '2023-02-07T20:36:03.384760', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:36:04,389][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 38.44% examples, 2252222 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:36:05,392][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 79.95% examples, 2312951 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:05,851][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5739976 effective words) took 2.5s, 2328922 effective words/s
[2023-02-07 20:36:06,856][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 45.04% examples, 2631360 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:07,857][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 90.76% examples, 2620047 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:08,044][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5739976 effective words) took 2.2s, 2620065 effective words/s
[2023-02-07 20:36:09,052][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 45.04% examples, 2624391 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:10,053][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 90.51% examples, 2606999 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:10,244][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5739976 effective words) took 2.2s, 2611560 effective words/s
[2023-02-07 20:36:11,249][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 45.19% examples, 2637421 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:12,250][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 92.94% examples, 2678729 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:12,374][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5739976 effective words) took 2.1s, 2697105 effective words/s
[2023-02-07 20:36:13,388][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 39.91% examples, 2329507 words/s, in_qsize 6, out_qsize 1
[2023-02-07 20:36:14,389][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 80.81% examples, 2321860 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:14,845][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5739976 effective words) took 2.5s, 2324771 effective words/s
[2023-02-07 20:36:15,850][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 39.36% examples, 2313744 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:16,855][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 79.95% examples, 2309583 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:17,317][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5739976 effective words) took 2.5s, 2323540 effective words/s
[2023-02-07 20:36:18,320][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 39.48% examples, 2330094 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:19,321][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 81.24% examples, 2349155 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:19,758][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5739976 effective words) took 2.4s, 2353533 effective words/s
[2023-02-07 20:36:20,763][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 40.90% examples, 2406427 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:21,763][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 90.64% examples, 2617795 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:21,920][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5739976 effective words) took 2.2s, 2658219 effective words/s
[2023-02-07 20:36:22,925][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 50.84% examples, 2965943 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:23,927][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 99.14% examples, 2841859 words/s, in_qsize 5, out_qsize 0
[2023-02-07 20:36:23,938][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5739976 effective words) took 2.0s, 2848116 effective words/s
[2023-02-07 20:36:24,943][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 46.15% examples, 2681018 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:25,945][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 93.83% examples, 2693183 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:26,062][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5739976 effective words) took 2.1s, 2703604 effective words/s
[2023-02-07 20:36:27,067][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 46.15% examples, 2683564 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:36:28,073][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 93.74% examples, 2690468 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:28,191][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5739976 effective words) took 2.1s, 2699571 effective words/s
[2023-02-07 20:36:29,196][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 46.61% examples, 2707554 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:30,205][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 93.74% examples, 2684793 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:36:30,325][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5739976 effective words) took 2.1s, 2691286 effective words/s
[2023-02-07 20:36:31,327][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 45.53% examples, 2663661 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:32,334][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 93.74% examples, 2692967 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:32,447][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5739976 effective words) took 2.1s, 2706644 effective words/s
[2023-02-07 20:36:33,451][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 47.10% examples, 2752254 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:34,452][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 96.19% examples, 2758471 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:34,527][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5739976 effective words) took 2.1s, 2762174 effective words/s
[2023-02-07 20:36:35,531][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 46.12% examples, 2682407 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:36,533][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 86.46% examples, 2497253 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:36:36,851][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5739976 effective words) took 2.3s, 2471018 effective words/s
[2023-02-07 20:36:36,852][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (86099640 effective words) took 33.5s, 2572656 effective words/s', 'datetime': '2023-02-07T20:36:36.852434', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:36:36.852 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:36:40,643][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203533-82ov7mw5/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:36:40.642918', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:36:40,643][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:36:40,715][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203533-82ov7mw5/files/../tmp/embedding_model.pt
2023-02-07 20:36:40.715 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:36:42.506 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:36:43.131 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:36:44.600 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9825544316988408, 'test_mae': 0.7684624795259142, 'test_r2': -2.0995899852598066}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.81
wandb: percentage 0.51619
wandb:   test_mae 0.76846
wandb:   test_mse 0.98255
wandb:    test_r2 -2.09959
wandb: 
wandb: üöÄ View run effortless-sweep-90 at: https://wandb.ai/xiaoqiz/mof2vec/runs/82ov7mw5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_203533-82ov7mw5/logs
wandb: Agent Starting Run: cgkc29zn with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 766
wandb: 	model.gensim.alpha: 0.003486206190015957
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.8793603404661989
wandb: 	model.gensim.vector_size: 187
wandb: 	model.gensim.window: 7
wandb: 	model.sklearn.learning_rate: 0.0007644131544702455
wandb: 	model.sklearn.max_depth: 77
wandb: 	model.sklearn.min_child_weight: 0.0398192546377128
wandb: 	model.sklearn.n_estimators: 931
wandb: 	model.sklearn.num_leaves: 7
wandb: 	model.sklearn.reg_alpha: 0.17645240980838983
wandb: 	model.sklearn.reg_lambda: 0.11372538586974212
wandb: 	model.sklearn.subsample: 0.6754419496275871
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203654-cgkc29zn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-91
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/cgkc29zn
2023-02-07 20:37:03.142 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:37:03.143 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 766 for sweep.
2023-02-07 20:37:03.143 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.003486206190015957 for sweep.
2023-02-07 20:37:03.143 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:37:03.144 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 20:37:03.144 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8793603404661989 for sweep.
2023-02-07 20:37:03.144 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 187 for sweep.
2023-02-07 20:37:03.144 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 7 for sweep.
2023-02-07 20:37:03.144 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0007644131544702455 for sweep.
2023-02-07 20:37:03.145 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 77 for sweep.
2023-02-07 20:37:03.145 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.0398192546377128 for sweep.
2023-02-07 20:37:03.145 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 931 for sweep.
2023-02-07 20:37:03.145 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 7 for sweep.
2023-02-07 20:37:03.146 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.17645240980838983 for sweep.
2023-02-07 20:37:03.147 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.11372538586974212 for sweep.
2023-02-07 20:37:03.147 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6754419496275871 for sweep.
2023-02-07 20:37:03.147 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:37:03.152 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203654-cgkc29zn/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 766, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 187, 'window': 7, 'min_count': 7, 'dm': 0, 'sample': 0.8793603404661989, 'workers': 4, 'alpha': 0.003486206190015957, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 931, 'max_depth': 77, 'num_leaves': 7, 'reg_alpha': 0.17645240980838983, 'reg_lambda': 0.11372538586974212, 'subsample': 0.6754419496275871, 'min_child_weight': 0.0398192546377128, 'n_jobs': 4, 'learning_rate': 0.0007644131544702455}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 138.99it/s]  1%|          | 30/3257 [00:00<00:21, 151.07it/s]  1%|‚ñè         | 46/3257 [00:00<00:21, 150.04it/s]  2%|‚ñè         | 62/3257 [00:00<00:21, 148.47it/s]  2%|‚ñè         | 78/3257 [00:00<00:20, 152.37it/s]  3%|‚ñé         | 94/3257 [00:00<00:20, 152.06it/s]  3%|‚ñé         | 110/3257 [00:00<00:22, 141.42it/s]  4%|‚ñç         | 127/3257 [00:00<00:20, 149.67it/s]  4%|‚ñç         | 145/3257 [00:00<00:19, 157.72it/s]  5%|‚ñç         | 161/3257 [00:01<00:20, 153.59it/s]  5%|‚ñå         | 177/3257 [00:01<00:20, 149.62it/s]  6%|‚ñå         | 198/3257 [00:01<00:18, 166.32it/s]  7%|‚ñã         | 220/3257 [00:01<00:16, 180.91it/s]  7%|‚ñã         | 244/3257 [00:01<00:15, 196.38it/s]  8%|‚ñä         | 264/3257 [00:01<00:15, 196.26it/s]  9%|‚ñâ         | 290/3257 [00:01<00:14, 211.76it/s] 10%|‚ñâ         | 312/3257 [00:01<00:14, 202.54it/s] 10%|‚ñà         | 335/3257 [00:01<00:13, 209.10it/s] 11%|‚ñà         | 358/3257 [00:02<00:13, 213.33it/s] 12%|‚ñà‚ñè        | 380/3257 [00:02<00:14, 197.51it/s] 12%|‚ñà‚ñè        | 403/3257 [00:02<00:13, 205.26it/s] 13%|‚ñà‚ñé        | 424/3257 [00:02<00:14, 195.94it/s] 14%|‚ñà‚ñé        | 444/3257 [00:02<00:16, 174.31it/s] 14%|‚ñà‚ñç        | 465/3257 [00:02<00:15, 182.28it/s] 15%|‚ñà‚ñç        | 484/3257 [00:02<00:15, 179.90it/s] 16%|‚ñà‚ñå        | 507/3257 [00:02<00:14, 193.01it/s] 16%|‚ñà‚ñå        | 527/3257 [00:02<00:14, 186.21it/s] 17%|‚ñà‚ñã        | 547/3257 [00:03<00:14, 188.64it/s] 17%|‚ñà‚ñã        | 567/3257 [00:03<00:15, 178.91it/s] 18%|‚ñà‚ñä        | 586/3257 [00:03<00:15, 173.64it/s] 19%|‚ñà‚ñä        | 606/3257 [00:03<00:14, 179.21it/s] 19%|‚ñà‚ñâ        | 625/3257 [00:03<00:14, 177.37it/s] 20%|‚ñà‚ñâ        | 645/3257 [00:03<00:14, 177.16it/s] 20%|‚ñà‚ñà        | 663/3257 [00:03<00:15, 167.22it/s] 21%|‚ñà‚ñà        | 683/3257 [00:03<00:15, 171.02it/s] 22%|‚ñà‚ñà‚ñè       | 701/3257 [00:03<00:14, 173.43it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:04<00:14, 177.00it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:04<00:15, 163.00it/s] 23%|‚ñà‚ñà‚ñé       | 758/3257 [00:04<00:14, 171.67it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:04<00:14, 169.29it/s] 24%|‚ñà‚ñà‚ñç       | 794/3257 [00:04<00:14, 170.25it/s] 25%|‚ñà‚ñà‚ñç       | 812/3257 [00:04<00:20, 117.00it/s] 25%|‚ñà‚ñà‚ñå       | 827/3257 [00:04<00:19, 123.84it/s] 26%|‚ñà‚ñà‚ñå       | 842/3257 [00:04<00:18, 128.73it/s] 26%|‚ñà‚ñà‚ñã       | 861/3257 [00:05<00:16, 142.48it/s] 27%|‚ñà‚ñà‚ñã       | 877/3257 [00:05<00:16, 143.57it/s] 28%|‚ñà‚ñà‚ñä       | 897/3257 [00:05<00:14, 157.80it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:05<00:14, 159.72it/s] 29%|‚ñà‚ñà‚ñä       | 933/3257 [00:05<00:14, 164.64it/s] 29%|‚ñà‚ñà‚ñâ       | 952/3257 [00:05<00:13, 171.67it/s] 30%|‚ñà‚ñà‚ñâ       | 970/3257 [00:05<00:13, 173.44it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:05<00:13, 166.98it/s] 31%|‚ñà‚ñà‚ñà       | 1007/3257 [00:05<00:13, 164.57it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1027/3257 [00:06<00:13, 165.94it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1044/3257 [00:06<00:13, 163.95it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:06<00:13, 167.43it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:06<00:12, 167.99it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1098/3257 [00:06<00:12, 170.49it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:06<00:12, 171.37it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1135/3257 [00:06<00:12, 166.40it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1152/3257 [00:06<00:12, 163.01it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1171/3257 [00:06<00:12, 168.18it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1188/3257 [00:07<00:13, 150.87it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1205/3257 [00:07<00:13, 153.78it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1225/3257 [00:07<00:12, 165.85it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1244/3257 [00:07<00:11, 172.07it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:07<00:11, 172.78it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1280/3257 [00:07<00:12, 161.88it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1297/3257 [00:07<00:12, 155.92it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1317/3257 [00:07<00:11, 166.59it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1336/3257 [00:07<00:11, 171.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:08<00:11, 163.86it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1372/3257 [00:08<00:11, 167.09it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1389/3257 [00:08<00:11, 164.47it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:08<00:10, 182.18it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:08<00:09, 185.79it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1453/3257 [00:08<00:09, 190.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1474/3257 [00:08<00:09, 194.53it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1494/3257 [00:08<00:09, 192.37it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1515/3257 [00:08<00:08, 196.01it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1535/3257 [00:09<00:09, 173.17it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1553/3257 [00:09<00:10, 168.48it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:09<00:09, 174.85it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1592/3257 [00:09<00:09, 175.28it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1612/3257 [00:09<00:09, 180.07it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1631/3257 [00:09<00:08, 181.59it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:09<00:09, 164.79it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1667/3257 [00:09<00:09, 163.55it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1684/3257 [00:09<00:09, 162.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1703/3257 [00:10<00:09, 169.41it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1721/3257 [00:10<00:08, 172.02it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1739/3257 [00:10<00:09, 156.78it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1760/3257 [00:10<00:08, 169.69it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1779/3257 [00:10<00:08, 173.37it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1798/3257 [00:10<00:08, 177.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1816/3257 [00:10<00:08, 172.83it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1834/3257 [00:10<00:08, 171.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1853/3257 [00:10<00:07, 175.91it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1874/3257 [00:10<00:07, 185.52it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1893/3257 [00:11<00:07, 175.40it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:11<00:07, 180.34it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1937/3257 [00:11<00:07, 187.72it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1963/3257 [00:11<00:06, 204.31it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1984/3257 [00:11<00:06, 187.59it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2005/3257 [00:11<00:06, 192.32it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2025/3257 [00:11<00:06, 194.09it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2045/3257 [00:11<00:06, 187.20it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2064/3257 [00:12<00:10, 109.89it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2083/3257 [00:12<00:09, 124.90it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:12<00:08, 133.68it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:12<00:08, 141.14it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:12<00:08, 132.71it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2149/3257 [00:12<00:08, 129.83it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2166/3257 [00:12<00:07, 138.12it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2181/3257 [00:13<00:07, 136.73it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2197/3257 [00:13<00:07, 142.67it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2212/3257 [00:13<00:07, 134.93it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2228/3257 [00:13<00:07, 140.44it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2243/3257 [00:13<00:07, 134.65it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:13<00:07, 138.40it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:13<00:07, 132.53it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2295/3257 [00:13<00:06, 150.37it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2311/3257 [00:13<00:06, 146.57it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2331/3257 [00:14<00:05, 160.29it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2350/3257 [00:14<00:05, 168.33it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2368/3257 [00:14<00:05, 165.33it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2387/3257 [00:14<00:05, 171.49it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2405/3257 [00:14<00:05, 160.78it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:14<00:05, 161.08it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2439/3257 [00:14<00:05, 152.73it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2455/3257 [00:14<00:05, 147.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2475/3257 [00:14<00:04, 159.56it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2492/3257 [00:15<00:04, 161.09it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2510/3257 [00:15<00:04, 166.12it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2527/3257 [00:15<00:04, 164.49it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2544/3257 [00:15<00:04, 163.77it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2561/3257 [00:15<00:04, 153.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2577/3257 [00:15<00:04, 147.67it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2592/3257 [00:15<00:04, 141.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2612/3257 [00:15<00:04, 156.77it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2631/3257 [00:15<00:03, 163.92it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2648/3257 [00:16<00:03, 155.39it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2664/3257 [00:16<00:03, 150.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2680/3257 [00:16<00:03, 152.20it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2696/3257 [00:16<00:03, 144.94it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2711/3257 [00:16<00:04, 134.28it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2728/3257 [00:16<00:03, 141.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2745/3257 [00:16<00:03, 149.36it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2761/3257 [00:16<00:03, 145.74it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2776/3257 [00:16<00:03, 143.80it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:17<00:02, 155.22it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2811/3257 [00:17<00:02, 154.08it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2827/3257 [00:17<00:03, 142.73it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2842/3257 [00:17<00:02, 144.12it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2863/3257 [00:17<00:02, 162.43it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2883/3257 [00:17<00:02, 170.98it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2901/3257 [00:17<00:02, 151.92it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2918/3257 [00:17<00:02, 156.44it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2935/3257 [00:17<00:02, 152.63it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2951/3257 [00:18<00:02, 141.55it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2968/3257 [00:18<00:01, 148.75it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2984/3257 [00:18<00:01, 139.45it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3002/3257 [00:18<00:01, 149.34it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:18<00:01, 144.98it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3036/3257 [00:18<00:01, 153.67it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3053/3257 [00:18<00:01, 157.29it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3071/3257 [00:18<00:01, 163.13it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3088/3257 [00:18<00:01, 158.30it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3108/3257 [00:19<00:00, 169.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3127/3257 [00:19<00:00, 169.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3145/3257 [00:19<00:00, 154.89it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3161/3257 [00:19<00:00, 154.97it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3177/3257 [00:19<00:00, 146.63it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3196/3257 [00:19<00:00, 157.73it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3213/3257 [00:19<00:00, 147.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3232/3257 [00:19<00:00, 158.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3250/3257 [00:19<00:00, 163.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 162.39it/s]
2023-02-07 20:37:24.135 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:37:24,137][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d187,n5,mc7,s0.87936,t4>', 'datetime': '2023-02-07T20:37:24.137546', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:37:24,138][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:37:24,138][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:37:24,630][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:37:24,630][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:37:24,681][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 18716 unique words (43.83% of original 42701, drops 23985)', 'datetime': '2023-02-07T20:37:24.681021', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:37:24,681][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 5754306 word corpus (98.82% of original 5822992, drops 68686)', 'datetime': '2023-02-07T20:37:24.681815', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:37:24,739][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:37:24,740][gensim.models.word2vec][INFO] - sample=0.87936 downsamples 0 most-common words
[2023-02-07 20:37:24,741][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5754306 word corpus (100.0%% of prior 5754306)', 'datetime': '2023-02-07T20:37:24.741057', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:37:24,842][gensim.models.word2vec][INFO] - estimated required memory for 18716 words and 187 dimensions: 40444772 bytes
[2023-02-07 20:37:24,842][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:37:24,857][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18716 vocabulary and 187 features, using sg=1 hs=0 sample=0.8793603404661989 negative=5 window=7 shrink_windows=True', 'datetime': '2023-02-07T20:37:24.857733', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:37:25,861][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 40.56% examples, 2380875 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:26,864][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 80.44% examples, 2317672 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:27,344][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5728381 effective words) took 2.5s, 2305625 effective words/s
[2023-02-07 20:37:28,347][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 40.56% examples, 2380245 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:29,351][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 82.38% examples, 2369241 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:29,757][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5728381 effective words) took 2.4s, 2374828 effective words/s
[2023-02-07 20:37:30,763][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 39.94% examples, 2343535 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:37:31,765][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 82.53% examples, 2374477 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:32,164][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5728381 effective words) took 2.4s, 2382080 effective words/s
[2023-02-07 20:37:33,168][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 41.42% examples, 2432641 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:34,170][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 84.89% examples, 2449654 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:34,501][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5728381 effective words) took 2.3s, 2455015 effective words/s
[2023-02-07 20:37:35,505][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 39.94% examples, 2345547 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:36,509][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 77.10% examples, 2224074 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:37,102][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5728381 effective words) took 2.6s, 2202921 effective words/s
[2023-02-07 20:37:38,104][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 36.44% examples, 2127396 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:39,113][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 73.81% examples, 2131279 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:39,777][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5728381 effective words) took 2.7s, 2142536 effective words/s
[2023-02-07 20:37:40,780][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 36.63% examples, 2149973 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:37:41,784][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 73.66% examples, 2135285 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:42,461][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5728381 effective words) took 2.7s, 2136181 effective words/s
[2023-02-07 20:37:43,467][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 36.48% examples, 2127208 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:44,469][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 81.03% examples, 2328870 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:44,842][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5728381 effective words) took 2.4s, 2406879 effective words/s
[2023-02-07 20:37:45,847][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 42.77% examples, 2517698 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:46,847][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 86.00% examples, 2477335 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:47,161][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5728381 effective words) took 2.3s, 2471836 effective words/s
[2023-02-07 20:37:48,166][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 41.97% examples, 2459239 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:37:49,166][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 84.89% examples, 2448238 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:49,499][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5728381 effective words) took 2.3s, 2451195 effective words/s
[2023-02-07 20:37:50,502][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 41.42% examples, 2433037 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:51,502][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 84.89% examples, 2451382 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:51,828][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5728381 effective words) took 2.3s, 2461613 effective words/s
[2023-02-07 20:37:52,835][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 43.14% examples, 2528796 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:53,840][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 88.64% examples, 2540138 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:54,079][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5728381 effective words) took 2.2s, 2547039 effective words/s
[2023-02-07 20:37:55,090][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 38.99% examples, 2259382 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:56,092][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 76.76% examples, 2211484 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:56,688][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5728381 effective words) took 2.6s, 2196949 effective words/s
[2023-02-07 20:37:57,694][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 36.97% examples, 2161493 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:58,694][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 75.13% examples, 2180014 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:37:59,312][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5728381 effective words) took 2.6s, 2184212 effective words/s
[2023-02-07 20:38:00,326][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 36.97% examples, 2143648 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:38:01,329][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 75.19% examples, 2172675 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:38:01,954][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5728381 effective words) took 2.6s, 2169707 effective words/s
[2023-02-07 20:38:01,955][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85925715 effective words) took 37.1s, 2316207 effective words/s', 'datetime': '2023-02-07T20:38:01.955638', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:38:01.956 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:38:05,176][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203654-cgkc29zn/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:38:05.175996', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:38:05,176][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:38:05,238][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203654-cgkc29zn/files/../tmp/embedding_model.pt
2023-02-07 20:38:05.238 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:38:06.788 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:38:07.330 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:38:08.653 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.039730212564378, 'test_mae': 0.7901322498369071, 'test_r2': -2.5841991010519005}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.75
wandb: percentage 0.5617
wandb:   test_mae 0.79013
wandb:   test_mse 1.03973
wandb:    test_r2 -2.5842
wandb: 
wandb: üöÄ View run skilled-sweep-91 at: https://wandb.ai/xiaoqiz/mof2vec/runs/cgkc29zn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_203654-cgkc29zn/logs
wandb: Agent Starting Run: mnyuz8hg with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 637
wandb: 	model.gensim.alpha: 0.004444534179976654
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.7724618940169414
wandb: 	model.gensim.vector_size: 217
wandb: 	model.gensim.window: 1
wandb: 	model.sklearn.learning_rate: 0.008932048243855727
wandb: 	model.sklearn.max_depth: 31
wandb: 	model.sklearn.min_child_weight: 0.029013845219746832
wandb: 	model.sklearn.n_estimators: 82
wandb: 	model.sklearn.num_leaves: 140
wandb: 	model.sklearn.reg_alpha: 0.05127676568162506
wandb: 	model.sklearn.reg_lambda: 0.011406862873070396
wandb: 	model.sklearn.subsample: 0.7880804198501292
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203819-mnyuz8hg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-92
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/mnyuz8hg
2023-02-07 20:38:27.313 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 20:38:27.313 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 637 for sweep.
2023-02-07 20:38:27.314 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.004444534179976654 for sweep.
2023-02-07 20:38:27.314 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:38:27.314 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 20:38:27.315 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7724618940169414 for sweep.
2023-02-07 20:38:27.315 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 217 for sweep.
2023-02-07 20:38:27.315 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 1 for sweep.
2023-02-07 20:38:27.316 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.008932048243855727 for sweep.
2023-02-07 20:38:27.316 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 31 for sweep.
2023-02-07 20:38:27.316 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.029013845219746832 for sweep.
2023-02-07 20:38:27.316 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 82 for sweep.
2023-02-07 20:38:27.316 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 140 for sweep.
2023-02-07 20:38:27.317 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.05127676568162506 for sweep.
2023-02-07 20:38:27.317 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.011406862873070396 for sweep.
2023-02-07 20:38:27.317 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.7880804198501292 for sweep.
2023-02-07 20:38:27.317 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:38:27.323 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203819-mnyuz8hg/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 637, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 217, 'window': 1, 'min_count': 8, 'dm': 0, 'sample': 0.7724618940169414, 'workers': 4, 'alpha': 0.004444534179976654, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 82, 'max_depth': 31, 'num_leaves': 140, 'reg_alpha': 0.05127676568162506, 'reg_lambda': 0.011406862873070396, 'subsample': 0.7880804198501292, 'min_child_weight': 0.029013845219746832, 'n_jobs': 4, 'learning_rate': 0.008932048243855727}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 162.02it/s]  1%|          | 36/3257 [00:00<00:18, 173.35it/s]  2%|‚ñè         | 54/3257 [00:00<00:18, 171.59it/s]  2%|‚ñè         | 73/3257 [00:00<00:18, 176.82it/s]  3%|‚ñé         | 94/3257 [00:00<00:17, 182.87it/s]  3%|‚ñé         | 113/3257 [00:00<00:17, 174.69it/s]  4%|‚ñç         | 131/3257 [00:00<00:17, 176.03it/s]  5%|‚ñç         | 151/3257 [00:00<00:16, 182.93it/s]  5%|‚ñå         | 170/3257 [00:01<00:24, 124.46it/s]  6%|‚ñå         | 189/3257 [00:01<00:22, 139.03it/s]  6%|‚ñã         | 208/3257 [00:01<00:20, 150.41it/s]  7%|‚ñã         | 232/3257 [00:01<00:17, 172.38it/s]  8%|‚ñä         | 251/3257 [00:01<00:17, 176.82it/s]  8%|‚ñä         | 270/3257 [00:01<00:16, 177.43it/s]  9%|‚ñâ         | 296/3257 [00:01<00:15, 196.62it/s] 10%|‚ñâ         | 317/3257 [00:01<00:15, 188.94it/s] 10%|‚ñà         | 338/3257 [00:01<00:15, 192.85it/s] 11%|‚ñà         | 360/3257 [00:02<00:14, 198.29it/s] 12%|‚ñà‚ñè        | 381/3257 [00:02<00:15, 187.65it/s] 12%|‚ñà‚ñè        | 401/3257 [00:02<00:15, 190.07it/s] 13%|‚ñà‚ñé        | 421/3257 [00:02<00:14, 191.88it/s] 14%|‚ñà‚ñé        | 441/3257 [00:02<00:16, 169.06it/s] 14%|‚ñà‚ñç        | 462/3257 [00:02<00:15, 178.33it/s] 15%|‚ñà‚ñç        | 481/3257 [00:02<00:15, 175.55it/s] 15%|‚ñà‚ñå        | 504/3257 [00:02<00:14, 187.72it/s] 16%|‚ñà‚ñå        | 525/3257 [00:02<00:14, 193.09it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:13, 193.83it/s] 17%|‚ñà‚ñã        | 566/3257 [00:03<00:14, 186.21it/s] 18%|‚ñà‚ñä        | 585/3257 [00:03<00:15, 171.03it/s] 19%|‚ñà‚ñä        | 604/3257 [00:03<00:15, 170.80it/s] 19%|‚ñà‚ñâ        | 622/3257 [00:03<00:16, 164.44it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:03<00:15, 167.01it/s] 20%|‚ñà‚ñà        | 658/3257 [00:03<00:17, 151.07it/s] 21%|‚ñà‚ñà        | 676/3257 [00:03<00:16, 154.86it/s] 21%|‚ñà‚ñà        | 692/3257 [00:04<00:17, 150.50it/s] 22%|‚ñà‚ñà‚ñè       | 709/3257 [00:04<00:16, 155.47it/s] 22%|‚ñà‚ñà‚ñè       | 725/3257 [00:04<00:17, 146.44it/s] 23%|‚ñà‚ñà‚ñé       | 740/3257 [00:04<00:17, 143.16it/s] 23%|‚ñà‚ñà‚ñé       | 759/3257 [00:04<00:16, 152.94it/s] 24%|‚ñà‚ñà‚ñç       | 775/3257 [00:04<00:16, 153.36it/s] 24%|‚ñà‚ñà‚ñç       | 791/3257 [00:04<00:16, 145.69it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:17, 143.73it/s] 25%|‚ñà‚ñà‚ñå       | 822/3257 [00:04<00:16, 147.43it/s] 26%|‚ñà‚ñà‚ñå       | 837/3257 [00:05<00:16, 143.37it/s] 26%|‚ñà‚ñà‚ñå       | 852/3257 [00:05<00:17, 138.67it/s] 27%|‚ñà‚ñà‚ñã       | 868/3257 [00:05<00:16, 143.42it/s] 27%|‚ñà‚ñà‚ñã       | 883/3257 [00:05<00:16, 144.78it/s] 28%|‚ñà‚ñà‚ñä       | 899/3257 [00:05<00:15, 148.46it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:05<00:15, 148.28it/s] 29%|‚ñà‚ñà‚ñä       | 932/3257 [00:05<00:14, 155.93it/s] 29%|‚ñà‚ñà‚ñâ       | 949/3257 [00:05<00:14, 158.52it/s] 30%|‚ñà‚ñà‚ñâ       | 967/3257 [00:05<00:14, 162.14it/s] 30%|‚ñà‚ñà‚ñà       | 984/3257 [00:05<00:14, 158.79it/s] 31%|‚ñà‚ñà‚ñà       | 1000/3257 [00:06<00:14, 153.62it/s] 31%|‚ñà‚ñà‚ñà       | 1016/3257 [00:06<00:14, 153.71it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1032/3257 [00:06<00:14, 149.67it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1048/3257 [00:06<00:15, 146.39it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1065/3257 [00:06<00:14, 151.19it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1081/3257 [00:06<00:14, 151.18it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1097/3257 [00:06<00:14, 152.17it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1114/3257 [00:06<00:13, 155.82it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1130/3257 [00:06<00:14, 145.14it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1145/3257 [00:07<00:14, 143.26it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1162/3257 [00:07<00:13, 150.65it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1178/3257 [00:07<00:14, 141.21it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1193/3257 [00:07<00:15, 137.01it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1207/3257 [00:07<00:15, 133.84it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1223/3257 [00:07<00:14, 140.04it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1242/3257 [00:07<00:13, 150.46it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1258/3257 [00:07<00:13, 147.41it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1275/3257 [00:07<00:13, 147.38it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:08<00:14, 139.95it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1305/3257 [00:08<00:13, 141.64it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1321/3257 [00:08<00:13, 144.93it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:08<00:12, 152.65it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1355/3257 [00:08<00:13, 145.73it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:08<00:12, 145.16it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:08<00:12, 144.87it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:08<00:12, 150.52it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:08<00:11, 162.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1440/3257 [00:09<00:11, 160.12it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1461/3257 [00:09<00:10, 170.68it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1479/3257 [00:09<00:10, 169.60it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1496/3257 [00:09<00:10, 169.03it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1514/3257 [00:09<00:10, 170.93it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1532/3257 [00:09<00:18, 95.28it/s]  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1546/3257 [00:09<00:16, 100.69it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1563/3257 [00:10<00:14, 114.84it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1578/3257 [00:10<00:13, 120.03it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:10<00:12, 134.39it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:10<00:11, 147.55it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1632/3257 [00:10<00:10, 151.53it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1649/3257 [00:10<00:11, 138.75it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1664/3257 [00:10<00:11, 139.51it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1680/3257 [00:10<00:11, 143.07it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1695/3257 [00:10<00:10, 142.68it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1713/3257 [00:11<00:10, 151.76it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:11<00:10, 140.90it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:11<00:10, 139.75it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:11<00:10, 148.76it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1780/3257 [00:11<00:09, 154.42it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1797/3257 [00:11<00:09, 155.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1813/3257 [00:11<00:09, 153.90it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1831/3257 [00:11<00:08, 160.92it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1853/3257 [00:11<00:07, 176.77it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1876/3257 [00:12<00:07, 191.96it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1896/3257 [00:12<00:07, 193.08it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1917/3257 [00:12<00:06, 197.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1943/3257 [00:12<00:06, 214.94it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1968/3257 [00:12<00:05, 223.71it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1991/3257 [00:12<00:05, 215.94it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2013/3257 [00:12<00:05, 213.51it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2036/3257 [00:12<00:05, 217.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2058/3257 [00:12<00:06, 199.26it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2079/3257 [00:13<00:06, 195.96it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2099/3257 [00:13<00:06, 188.43it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2120/3257 [00:13<00:06, 185.34it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2139/3257 [00:13<00:06, 182.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2158/3257 [00:13<00:05, 184.03it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:13<00:05, 186.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2199/3257 [00:13<00:05, 193.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:13<00:05, 183.68it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:13<00:05, 175.19it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2256/3257 [00:13<00:05, 175.81it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2274/3257 [00:14<00:05, 165.39it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2296/3257 [00:14<00:05, 178.77it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2315/3257 [00:14<00:05, 178.61it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2340/3257 [00:14<00:04, 196.88it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2363/3257 [00:14<00:04, 205.25it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2384/3257 [00:14<00:04, 201.05it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2405/3257 [00:14<00:04, 191.47it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2425/3257 [00:14<00:04, 187.57it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2444/3257 [00:15<00:04, 172.40it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2462/3257 [00:15<00:04, 173.43it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2481/3257 [00:15<00:04, 174.55it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2501/3257 [00:15<00:04, 179.98it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2520/3257 [00:15<00:04, 175.01it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2539/3257 [00:15<00:04, 176.81it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2557/3257 [00:15<00:04, 168.62it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2574/3257 [00:15<00:04, 162.16it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2591/3257 [00:15<00:04, 160.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:15<00:03, 177.85it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:16<00:03, 183.60it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2653/3257 [00:16<00:03, 183.08it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2672/3257 [00:16<00:03, 184.07it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2692/3257 [00:16<00:03, 187.91it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2711/3257 [00:16<00:03, 166.87it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:16<00:02, 175.68it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2752/3257 [00:16<00:02, 182.35it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2771/3257 [00:16<00:02, 178.30it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2793/3257 [00:16<00:02, 188.50it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2813/3257 [00:17<00:02, 185.55it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2832/3257 [00:17<00:02, 176.71it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2851/3257 [00:17<00:02, 179.95it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2880/3257 [00:17<00:01, 208.73it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2902/3257 [00:17<00:01, 187.47it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2922/3257 [00:17<00:01, 188.05it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2942/3257 [00:17<00:01, 186.36it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2961/3257 [00:17<00:01, 168.43it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2979/3257 [00:18<00:01, 166.52it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3002/3257 [00:18<00:01, 181.92it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3021/3257 [00:18<00:01, 179.74it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3045/3257 [00:18<00:01, 194.93it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3065/3257 [00:18<00:00, 193.20it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3085/3257 [00:18<00:00, 187.23it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3107/3257 [00:18<00:00, 195.57it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3128/3257 [00:18<00:00, 198.21it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3148/3257 [00:19<00:01, 103.83it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3167/3257 [00:19<00:00, 119.04it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3184/3257 [00:19<00:00, 128.66it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:19<00:00, 147.34it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3225/3257 [00:19<00:00, 154.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3247/3257 [00:19<00:00, 170.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 164.95it/s]
2023-02-07 20:38:47.723 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:38:47,724][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d217,n5,mc8,s0.772462,t4>', 'datetime': '2023-02-07T20:38:47.724729', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:38:47,725][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:38:47,725][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:38:48,223][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 20:38:48,224][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:38:48,271][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 13798 unique words (43.39% of original 31803, drops 18005)', 'datetime': '2023-02-07T20:38:48.271006', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:38:48,271][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 5042429 word corpus (98.97% of original 5095118, drops 52689)', 'datetime': '2023-02-07T20:38:48.271476', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:38:48,322][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 20:38:48,323][gensim.models.word2vec][INFO] - sample=0.772462 downsamples 0 most-common words
[2023-02-07 20:38:48,324][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5042429 word corpus (100.0%% of prior 5042429)', 'datetime': '2023-02-07T20:38:48.324281', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:38:48,412][gensim.models.word2vec][INFO] - estimated required memory for 13798 words and 217 dimensions: 34330804 bytes
[2023-02-07 20:38:48,412][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:38:48,430][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 13798 vocabulary and 217 features, using sg=1 hs=0 sample=0.7724618940169414 negative=5 window=1 shrink_windows=True', 'datetime': '2023-02-07T20:38:48.430262', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:38:49,439][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 38.29% examples, 1964282 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:38:50,445][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 78.54% examples, 1985428 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:38:50,954][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5034594 effective words) took 2.5s, 1997330 effective words/s
[2023-02-07 20:38:51,958][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 41.39% examples, 2137015 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:38:52,965][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 85.39% examples, 2160263 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:38:53,278][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5034594 effective words) took 2.3s, 2168656 effective words/s
[2023-02-07 20:38:54,282][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 42.00% examples, 2171232 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:38:55,283][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 85.82% examples, 2175118 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:38:55,591][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5034594 effective words) took 2.3s, 2179536 effective words/s
[2023-02-07 20:38:56,598][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 42.28% examples, 2182428 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:38:57,599][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 98.43% examples, 2471983 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:38:57,622][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5034594 effective words) took 2.0s, 2481066 effective words/s
[2023-02-07 20:38:58,624][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 55.45% examples, 2859709 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:38:59,375][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5034594 effective words) took 1.8s, 2875311 effective words/s
[2023-02-07 20:39:00,377][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 54.44% examples, 2806132 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:01,285][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5034594 effective words) took 1.9s, 2638486 effective words/s
[2023-02-07 20:39:02,287][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 48.36% examples, 2490860 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:03,291][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 97.24% examples, 2447692 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:03,334][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5034594 effective words) took 2.0s, 2458448 effective words/s
[2023-02-07 20:39:04,336][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 48.08% examples, 2473931 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:05,337][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 99.11% examples, 2496707 words/s, in_qsize 5, out_qsize 0
[2023-02-07 20:39:05,349][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5034594 effective words) took 2.0s, 2500550 effective words/s
[2023-02-07 20:39:06,357][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 47.71% examples, 2442009 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:07,358][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 98.56% examples, 2474400 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:07,378][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5034594 effective words) took 2.0s, 2483619 effective words/s
[2023-02-07 20:39:08,388][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 49.25% examples, 2508253 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:09,357][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5034594 effective words) took 2.0s, 2545355 effective words/s
[2023-02-07 20:39:10,366][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 49.25% examples, 2512348 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:11,321][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5034594 effective words) took 2.0s, 2565569 effective words/s
[2023-02-07 20:39:12,332][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 49.86% examples, 2545099 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:13,283][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5034594 effective words) took 2.0s, 2568881 effective words/s
[2023-02-07 20:39:14,286][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 49.25% examples, 2528531 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:15,283][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5034594 effective words) took 2.0s, 2520516 effective words/s
[2023-02-07 20:39:16,288][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 49.49% examples, 2536348 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:17,283][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5034594 effective words) took 2.0s, 2521450 effective words/s
[2023-02-07 20:39:18,285][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 49.00% examples, 2518817 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:39:19,267][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5034594 effective words) took 2.0s, 2539351 effective words/s
[2023-02-07 20:39:19,267][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75518910 effective words) took 30.8s, 2449065 effective words/s', 'datetime': '2023-02-07T20:39:19.267759', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:39:19.268 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:39:21,882][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203819-mnyuz8hg/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:39:21.882152', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:39:21,882][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:39:21,924][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203819-mnyuz8hg/files/../tmp/embedding_model.pt
2023-02-07 20:39:21.925 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:39:23.414 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:39:23.993 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:39:25.521 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0379507600797249, 'test_mae': 0.7832578062736915, 'test_r2': -2.3829925572644353}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.78
wandb: percentage 0.56614
wandb:   test_mae 0.78326
wandb:   test_mse 1.03795
wandb:    test_r2 -2.38299
wandb: 
wandb: üöÄ View run rural-sweep-92 at: https://wandb.ai/xiaoqiz/mof2vec/runs/mnyuz8hg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_203819-mnyuz8hg/logs
wandb: Agent Starting Run: xltngs3w with config:
wandb: 	data.data.wl_step: 3
wandb: 	data.nn.batch_size: 675
wandb: 	model.gensim.alpha: 0.014071059390217194
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 6
wandb: 	model.gensim.sample: 0.4677560312963309
wandb: 	model.gensim.vector_size: 509
wandb: 	model.gensim.window: 16
wandb: 	model.sklearn.learning_rate: 0.0009080720943529362
wandb: 	model.sklearn.max_depth: 84
wandb: 	model.sklearn.min_child_weight: 0.029813924310812877
wandb: 	model.sklearn.n_estimators: 331
wandb: 	model.sklearn.num_leaves: 254
wandb: 	model.sklearn.reg_alpha: 0.020229217558812372
wandb: 	model.sklearn.reg_lambda: 0.06628267073731574
wandb: 	model.sklearn.subsample: 0.831980476338448
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203938-xltngs3w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-93
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/xltngs3w
2023-02-07 20:39:46.547 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 3 for sweep.
2023-02-07 20:39:46.548 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 675 for sweep.
2023-02-07 20:39:46.548 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.014071059390217194 for sweep.
2023-02-07 20:39:46.548 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:39:46.548 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 6 for sweep.
2023-02-07 20:39:46.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.4677560312963309 for sweep.
2023-02-07 20:39:46.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 509 for sweep.
2023-02-07 20:39:46.549 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 16 for sweep.
2023-02-07 20:39:46.550 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0009080720943529362 for sweep.
2023-02-07 20:39:46.550 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 84 for sweep.
2023-02-07 20:39:46.550 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.029813924310812877 for sweep.
2023-02-07 20:39:46.550 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 331 for sweep.
2023-02-07 20:39:46.550 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 254 for sweep.
2023-02-07 20:39:46.551 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.020229217558812372 for sweep.
2023-02-07 20:39:46.551 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.06628267073731574 for sweep.
2023-02-07 20:39:46.551 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.831980476338448 for sweep.
2023-02-07 20:39:46.551 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:39:46.559 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 3}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203938-xltngs3w/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 675, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 509, 'window': 16, 'min_count': 6, 'dm': 0, 'sample': 0.4677560312963309, 'workers': 4, 'alpha': 0.014071059390217194, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 331, 'max_depth': 84, 'num_leaves': 254, 'reg_alpha': 0.020229217558812372, 'reg_lambda': 0.06628267073731574, 'subsample': 0.831980476338448, 'min_child_weight': 0.029813924310812877, 'n_jobs': 4, 'learning_rate': 0.0009080720943529362}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 27/3257 [00:00<00:12, 266.77it/s]  2%|‚ñè         | 54/3257 [00:00<00:12, 247.69it/s]  3%|‚ñé         | 83/3257 [00:00<00:11, 266.07it/s]  3%|‚ñé         | 110/3257 [00:00<00:12, 254.26it/s]  4%|‚ñç         | 141/3257 [00:00<00:11, 270.68it/s]  5%|‚ñå         | 169/3257 [00:00<00:11, 271.65it/s]  6%|‚ñå         | 199/3257 [00:00<00:10, 280.17it/s]  7%|‚ñã         | 232/3257 [00:00<00:10, 292.09it/s]  8%|‚ñä         | 262/3257 [00:00<00:10, 287.16it/s]  9%|‚ñâ         | 297/3257 [00:01<00:09, 305.72it/s] 10%|‚ñà         | 328/3257 [00:01<00:09, 304.87it/s] 11%|‚ñà         | 360/3257 [00:01<00:09, 307.05it/s] 12%|‚ñà‚ñè        | 391/3257 [00:01<00:09, 295.16it/s] 13%|‚ñà‚ñé        | 421/3257 [00:01<00:09, 287.37it/s] 14%|‚ñà‚ñç        | 450/3257 [00:01<00:11, 244.91it/s] 15%|‚ñà‚ñç        | 476/3257 [00:01<00:11, 245.02it/s] 15%|‚ñà‚ñå        | 502/3257 [00:01<00:11, 241.09it/s] 16%|‚ñà‚ñå        | 527/3257 [00:01<00:11, 237.34it/s] 17%|‚ñà‚ñã        | 553/3257 [00:02<00:11, 241.20it/s] 18%|‚ñà‚ñä        | 578/3257 [00:02<00:12, 221.64it/s] 19%|‚ñà‚ñä        | 604/3257 [00:02<00:11, 226.58it/s] 19%|‚ñà‚ñâ        | 628/3257 [00:02<00:11, 228.29it/s] 20%|‚ñà‚ñà        | 652/3257 [00:02<00:11, 229.75it/s] 21%|‚ñà‚ñà        | 676/3257 [00:02<00:11, 225.45it/s] 21%|‚ñà‚ñà‚ñè       | 699/3257 [00:02<00:11, 219.08it/s] 22%|‚ñà‚ñà‚ñè       | 722/3257 [00:02<00:11, 221.85it/s] 23%|‚ñà‚ñà‚ñé       | 745/3257 [00:02<00:11, 216.34it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:03<00:11, 224.39it/s] 24%|‚ñà‚ñà‚ñç       | 793/3257 [00:03<00:11, 221.87it/s] 25%|‚ñà‚ñà‚ñå       | 817/3257 [00:03<00:10, 226.20it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:03<00:11, 213.82it/s] 26%|‚ñà‚ñà‚ñã       | 862/3257 [00:03<00:11, 209.75it/s] 27%|‚ñà‚ñà‚ñã       | 884/3257 [00:03<00:11, 207.11it/s] 28%|‚ñà‚ñà‚ñä       | 909/3257 [00:03<00:10, 218.81it/s] 29%|‚ñà‚ñà‚ñä       | 932/3257 [00:03<00:10, 221.49it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:03<00:10, 225.48it/s] 30%|‚ñà‚ñà‚ñà       | 979/3257 [00:04<00:10, 219.66it/s] 31%|‚ñà‚ñà‚ñà       | 1002/3257 [00:04<00:10, 214.44it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1025/3257 [00:04<00:10, 216.63it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1047/3257 [00:04<00:10, 204.65it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1071/3257 [00:04<00:10, 213.78it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1093/3257 [00:04<00:10, 208.34it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1114/3257 [00:04<00:14, 147.68it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:04<00:12, 169.75it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:05<00:10, 198.82it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1193/3257 [00:05<00:10, 204.21it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1219/3257 [00:05<00:09, 218.49it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1249/3257 [00:05<00:08, 239.13it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1276/3257 [00:05<00:08, 246.82it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1302/3257 [00:05<00:08, 244.19it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1332/3257 [00:05<00:07, 259.18it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1359/3257 [00:05<00:07, 258.85it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:05<00:07, 252.90it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1416/3257 [00:05<00:06, 266.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1444/3257 [00:06<00:06, 268.73it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:06<00:06, 283.52it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1510/3257 [00:06<00:05, 295.72it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1540/3257 [00:06<00:06, 269.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1568/3257 [00:06<00:06, 265.68it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1596/3257 [00:06<00:06, 268.78it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1627/3257 [00:06<00:05, 279.82it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1656/3257 [00:06<00:06, 264.02it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1683/3257 [00:06<00:06, 253.68it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1711/3257 [00:07<00:05, 260.68it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1738/3257 [00:07<00:06, 245.53it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1767/3257 [00:07<00:05, 255.30it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1797/3257 [00:07<00:05, 266.13it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1825/3257 [00:07<00:05, 268.60it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1853/3257 [00:07<00:05, 267.48it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1883/3257 [00:07<00:04, 275.00it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1911/3257 [00:07<00:04, 274.61it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1942/3257 [00:07<00:04, 284.92it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1976/3257 [00:08<00:04, 299.36it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2007/3257 [00:08<00:04, 295.57it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2038/3257 [00:08<00:04, 297.22it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2068/3257 [00:08<00:04, 255.73it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2095/3257 [00:08<00:04, 249.97it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:08<00:04, 229.88it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2145/3257 [00:08<00:04, 225.12it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2168/3257 [00:08<00:04, 226.01it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2191/3257 [00:08<00:04, 222.89it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2214/3257 [00:09<00:04, 218.68it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2237/3257 [00:09<00:04, 219.66it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:09<00:04, 216.02it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2282/3257 [00:09<00:04, 216.50it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2306/3257 [00:09<00:04, 220.25it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2334/3257 [00:09<00:03, 236.76it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2362/3257 [00:09<00:03, 248.39it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2388/3257 [00:09<00:03, 249.43it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2414/3257 [00:09<00:03, 241.29it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2439/3257 [00:10<00:03, 230.86it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2463/3257 [00:10<00:05, 147.74it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2488/3257 [00:10<00:04, 167.60it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2514/3257 [00:10<00:03, 186.26it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2540/3257 [00:10<00:03, 202.25it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2563/3257 [00:10<00:03, 205.14it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2586/3257 [00:10<00:03, 204.24it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:10<00:02, 223.09it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2640/3257 [00:11<00:02, 231.08it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2664/3257 [00:11<00:02, 225.78it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2690/3257 [00:11<00:02, 233.26it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2714/3257 [00:11<00:02, 213.89it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2741/3257 [00:11<00:02, 226.81it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2768/3257 [00:11<00:02, 234.93it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2803/3257 [00:11<00:01, 264.81it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2830/3257 [00:11<00:01, 264.64it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2868/3257 [00:11<00:01, 296.27it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2898/3257 [00:12<00:01, 293.42it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2930/3257 [00:12<00:01, 298.06it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2960/3257 [00:12<00:01, 292.59it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2990/3257 [00:12<00:00, 289.76it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3025/3257 [00:12<00:00, 306.92it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3063/3257 [00:12<00:00, 327.21it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3096/3257 [00:12<00:00, 323.21it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3131/3257 [00:12<00:00, 326.83it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3164/3257 [00:12<00:00, 315.56it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3196/3257 [00:12<00:00, 313.88it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3228/3257 [00:13<00:00, 305.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:13<00:00, 247.05it/s]
2023-02-07 20:40:00.143 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:40:00,144][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d509,n5,mc6,s0.467756,t4>', 'datetime': '2023-02-07T20:40:00.144742', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:40:00,145][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:40:00,145][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:40:00,402][gensim.models.doc2vec][INFO] - collected 6662 word types and 3257 unique tags from a corpus of 3257 examples and 2911496 words
[2023-02-07 20:40:00,402][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:40:00,412][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 retains 3569 unique words (53.57% of original 6662, drops 3093)', 'datetime': '2023-02-07T20:40:00.412634', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:40:00,412][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=6 leaves 2903654 word corpus (99.73% of original 2911496, drops 7842)', 'datetime': '2023-02-07T20:40:00.412952', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:40:00,426][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 6662 items
[2023-02-07 20:40:00,426][gensim.models.word2vec][INFO] - sample=0.467756 downsamples 0 most-common words
[2023-02-07 20:40:00,426][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2903654 word corpus (100.0%% of prior 2903654)', 'datetime': '2023-02-07T20:40:00.426722', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:40:00,447][gensim.models.word2vec][INFO] - estimated required memory for 3569 words and 509 dimensions: 23600120 bytes
[2023-02-07 20:40:00,447][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:40:00,460][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 3569 vocabulary and 509 features, using sg=1 hs=0 sample=0.4677560312963309 negative=5 window=16 shrink_windows=True', 'datetime': '2023-02-07T20:40:00.460336', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:40:01,463][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 52.72% examples, 1572448 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:40:02,305][gensim.models.word2vec][INFO] - EPOCH 0: training on 2911496 raw words (2906911 effective words) took 1.8s, 1577422 effective words/s
[2023-02-07 20:40:03,309][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 58.46% examples, 1738421 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:40:03,989][gensim.models.word2vec][INFO] - EPOCH 1: training on 2911496 raw words (2906911 effective words) took 1.7s, 1728876 effective words/s
[2023-02-07 20:40:04,991][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 64.11% examples, 1899957 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:40:05,473][gensim.models.word2vec][INFO] - EPOCH 2: training on 2911496 raw words (2906911 effective words) took 1.5s, 1960314 effective words/s
[2023-02-07 20:40:06,476][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 64.26% examples, 1898743 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:40:07,013][gensim.models.word2vec][INFO] - EPOCH 3: training on 2911496 raw words (2906911 effective words) took 1.5s, 1889613 effective words/s
[2023-02-07 20:40:08,018][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 62.54% examples, 1839510 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:40:08,586][gensim.models.word2vec][INFO] - EPOCH 4: training on 2911496 raw words (2906911 effective words) took 1.6s, 1850518 effective words/s
[2023-02-07 20:40:09,591][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 63.00% examples, 1858504 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:40:10,141][gensim.models.word2vec][INFO] - EPOCH 5: training on 2911496 raw words (2906911 effective words) took 1.6s, 1871729 effective words/s
[2023-02-07 20:40:11,146][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 63.92% examples, 1886246 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:40:11,684][gensim.models.word2vec][INFO] - EPOCH 6: training on 2911496 raw words (2906911 effective words) took 1.5s, 1887096 effective words/s
[2023-02-07 20:40:12,686][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 63.92% examples, 1890692 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:40:13,210][gensim.models.word2vec][INFO] - EPOCH 7: training on 2911496 raw words (2906911 effective words) took 1.5s, 1906736 effective words/s
[2023-02-07 20:40:14,216][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 64.81% examples, 1909433 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:40:14,727][gensim.models.word2vec][INFO] - EPOCH 8: training on 2911496 raw words (2906911 effective words) took 1.5s, 1918624 effective words/s
[2023-02-07 20:40:15,729][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 63.59% examples, 1880222 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:40:16,255][gensim.models.word2vec][INFO] - EPOCH 9: training on 2911496 raw words (2906911 effective words) took 1.5s, 1904611 effective words/s
[2023-02-07 20:40:17,263][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 65.15% examples, 1923787 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:40:17,761][gensim.models.word2vec][INFO] - EPOCH 10: training on 2911496 raw words (2906911 effective words) took 1.5s, 1933010 effective words/s
[2023-02-07 20:40:18,764][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 65.15% examples, 1932895 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:40:19,258][gensim.models.word2vec][INFO] - EPOCH 11: training on 2911496 raw words (2906911 effective words) took 1.5s, 1943707 effective words/s
[2023-02-07 20:40:20,262][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 65.15% examples, 1931997 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:40:20,804][gensim.models.word2vec][INFO] - EPOCH 12: training on 2911496 raw words (2906911 effective words) took 1.5s, 1882804 effective words/s
[2023-02-07 20:40:21,809][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 59.20% examples, 1755286 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:40:22,459][gensim.models.word2vec][INFO] - EPOCH 13: training on 2911496 raw words (2906911 effective words) took 1.7s, 1758447 effective words/s
[2023-02-07 20:40:23,462][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 58.24% examples, 1731603 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:40:24,133][gensim.models.word2vec][INFO] - EPOCH 14: training on 2911496 raw words (2906911 effective words) took 1.7s, 1739146 effective words/s
[2023-02-07 20:40:24,133][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 43672440 raw words (43603665 effective words) took 23.7s, 1841907 effective words/s', 'datetime': '2023-02-07T20:40:24.133844', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:40:24.134 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:40:26,362][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203938-xltngs3w/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:40:26.362757', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:40:26,364][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:40:26,405][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_203938-xltngs3w/files/../tmp/embedding_model.pt
2023-02-07 20:40:26.405 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:40:29.096 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:40:29.897 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:40:33.327 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9540906729651731, 'test_mae': 0.7335471931867804, 'test_r2': -1.6910007406592014}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.82
wandb: percentage 0.46427
wandb:   test_mae 0.73355
wandb:   test_mse 0.95409
wandb:    test_r2 -1.691
wandb: 
wandb: üöÄ View run stoic-sweep-93 at: https://wandb.ai/xiaoqiz/mof2vec/runs/xltngs3w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_203938-xltngs3w/logs
wandb: Agent Starting Run: 2bxnh258 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 422
wandb: 	model.gensim.alpha: 0.002766452158911725
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.5150077538492879
wandb: 	model.gensim.vector_size: 302
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.0033398606236330498
wandb: 	model.sklearn.max_depth: 52
wandb: 	model.sklearn.min_child_weight: 0.028644154321437788
wandb: 	model.sklearn.n_estimators: 2522
wandb: 	model.sklearn.num_leaves: 215
wandb: 	model.sklearn.reg_alpha: 0.004028463761648936
wandb: 	model.sklearn.reg_lambda: 0.1029273468989174
wandb: 	model.sklearn.subsample: 0.8066435449901797
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204046-2bxnh258
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-94
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/2bxnh258
2023-02-07 20:40:55.065 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 20:40:55.065 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 422 for sweep.
2023-02-07 20:40:55.066 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.002766452158911725 for sweep.
2023-02-07 20:40:55.066 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:40:55.066 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 20:40:55.066 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.5150077538492879 for sweep.
2023-02-07 20:40:55.067 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 302 for sweep.
2023-02-07 20:40:55.067 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 20:40:55.068 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0033398606236330498 for sweep.
2023-02-07 20:40:55.068 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 52 for sweep.
2023-02-07 20:40:55.068 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.028644154321437788 for sweep.
2023-02-07 20:40:55.068 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 2522 for sweep.
2023-02-07 20:40:55.069 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 215 for sweep.
2023-02-07 20:40:55.069 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.004028463761648936 for sweep.
2023-02-07 20:40:55.069 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.1029273468989174 for sweep.
2023-02-07 20:40:55.069 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8066435449901797 for sweep.
2023-02-07 20:40:55.069 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:40:55.077 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204046-2bxnh258/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 422, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 302, 'window': 11, 'min_count': 7, 'dm': 0, 'sample': 0.5150077538492879, 'workers': 4, 'alpha': 0.002766452158911725, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 2522, 'max_depth': 52, 'num_leaves': 215, 'reg_alpha': 0.004028463761648936, 'reg_lambda': 0.1029273468989174, 'subsample': 0.8066435449901797, 'min_child_weight': 0.028644154321437788, 'n_jobs': 4, 'learning_rate': 0.0033398606236330498}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 162.73it/s]  1%|          | 35/3257 [00:00<00:19, 168.72it/s]  2%|‚ñè         | 53/3257 [00:00<00:19, 166.09it/s]  2%|‚ñè         | 72/3257 [00:00<00:18, 172.98it/s]  3%|‚ñé         | 92/3257 [00:00<00:17, 178.96it/s]  3%|‚ñé         | 110/3257 [00:00<00:18, 169.08it/s]  4%|‚ñç         | 129/3257 [00:00<00:17, 175.22it/s]  5%|‚ñç         | 149/3257 [00:00<00:17, 181.84it/s]  5%|‚ñå         | 168/3257 [00:00<00:17, 174.12it/s]  6%|‚ñå         | 187/3257 [00:01<00:17, 176.22it/s]  6%|‚ñã         | 206/3257 [00:01<00:17, 179.29it/s]  7%|‚ñã         | 230/3257 [00:01<00:15, 192.42it/s]  8%|‚ñä         | 250/3257 [00:01<00:16, 187.63it/s]  8%|‚ñä         | 269/3257 [00:01<00:16, 177.16it/s]  9%|‚ñâ         | 294/3257 [00:01<00:15, 195.90it/s] 10%|‚ñâ         | 314/3257 [00:01<00:15, 185.93it/s] 10%|‚ñà         | 336/3257 [00:01<00:15, 192.81it/s] 11%|‚ñà         | 358/3257 [00:01<00:14, 198.32it/s] 12%|‚ñà‚ñè        | 378/3257 [00:02<00:15, 181.45it/s] 12%|‚ñà‚ñè        | 398/3257 [00:02<00:15, 182.97it/s] 13%|‚ñà‚ñé        | 420/3257 [00:02<00:15, 188.10it/s] 13%|‚ñà‚ñé        | 439/3257 [00:02<00:16, 167.31it/s] 14%|‚ñà‚ñç        | 459/3257 [00:02<00:16, 174.31it/s] 15%|‚ñà‚ñç        | 479/3257 [00:02<00:15, 176.42it/s] 15%|‚ñà‚ñå        | 501/3257 [00:02<00:14, 187.52it/s] 16%|‚ñà‚ñå        | 522/3257 [00:02<00:14, 187.77it/s] 17%|‚ñà‚ñã        | 542/3257 [00:02<00:14, 188.56it/s] 17%|‚ñà‚ñã        | 562/3257 [00:03<00:15, 177.78it/s] 18%|‚ñà‚ñä        | 580/3257 [00:03<00:15, 172.09it/s] 18%|‚ñà‚ñä        | 600/3257 [00:03<00:14, 179.40it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:14, 177.16it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:03<00:14, 182.82it/s] 20%|‚ñà‚ñà        | 660/3257 [00:03<00:15, 168.85it/s] 21%|‚ñà‚ñà        | 681/3257 [00:03<00:14, 177.95it/s] 21%|‚ñà‚ñà‚ñè       | 700/3257 [00:03<00:14, 170.79it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:20, 126.25it/s] 23%|‚ñà‚ñà‚ñé       | 733/3257 [00:04<00:19, 130.58it/s] 23%|‚ñà‚ñà‚ñé       | 749/3257 [00:04<00:18, 136.66it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:04<00:16, 154.82it/s] 24%|‚ñà‚ñà‚ñç       | 787/3257 [00:04<00:15, 155.65it/s] 25%|‚ñà‚ñà‚ñç       | 806/3257 [00:04<00:15, 161.29it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:04<00:15, 161.76it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:04<00:15, 159.20it/s] 26%|‚ñà‚ñà‚ñã       | 859/3257 [00:04<00:14, 163.87it/s] 27%|‚ñà‚ñà‚ñã       | 876/3257 [00:05<00:14, 163.51it/s] 27%|‚ñà‚ñà‚ñã       | 895/3257 [00:05<00:13, 169.08it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:05<00:13, 173.73it/s] 29%|‚ñà‚ñà‚ñä       | 934/3257 [00:05<00:12, 180.64it/s] 29%|‚ñà‚ñà‚ñâ       | 955/3257 [00:05<00:12, 188.03it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:05<00:12, 183.98it/s] 30%|‚ñà‚ñà‚ñà       | 993/3257 [00:05<00:12, 177.84it/s] 31%|‚ñà‚ñà‚ñà       | 1011/3257 [00:05<00:12, 174.15it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1029/3257 [00:05<00:12, 174.29it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1047/3257 [00:06<00:13, 168.49it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1067/3257 [00:06<00:12, 173.62it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1086/3257 [00:06<00:12, 175.97it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:06<00:11, 179.41it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1123/3257 [00:06<00:11, 179.27it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1141/3257 [00:06<00:12, 171.96it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1163/3257 [00:06<00:11, 182.36it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1182/3257 [00:06<00:12, 166.72it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1199/3257 [00:06<00:12, 162.96it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1216/3257 [00:07<00:12, 159.93it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1239/3257 [00:07<00:11, 177.68it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:07<00:11, 173.08it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1276/3257 [00:07<00:11, 173.62it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1294/3257 [00:07<00:11, 169.22it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1313/3257 [00:07<00:11, 174.47it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1332/3257 [00:07<00:10, 177.29it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:07<00:11, 169.75it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1368/3257 [00:07<00:11, 160.71it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:08<00:12, 151.94it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:08<00:12, 153.58it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:08<00:11, 163.69it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1440/3257 [00:08<00:11, 159.62it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1461/3257 [00:08<00:10, 172.01it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1479/3257 [00:08<00:10, 172.15it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1498/3257 [00:08<00:09, 176.91it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1516/3257 [00:08<00:10, 172.82it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1534/3257 [00:08<00:11, 152.84it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:09<00:11, 153.79it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1566/3257 [00:09<00:11, 152.08it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1582/3257 [00:09<00:11, 150.97it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1599/3257 [00:09<00:10, 154.25it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1617/3257 [00:09<00:10, 156.63it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1634/3257 [00:09<00:10, 151.76it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1650/3257 [00:09<00:10, 148.56it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1665/3257 [00:09<00:10, 145.22it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1680/3257 [00:09<00:10, 143.42it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1695/3257 [00:10<00:10, 143.81it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1713/3257 [00:10<00:10, 150.57it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:10<00:10, 141.26it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:10<00:10, 137.87it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:10<00:10, 147.04it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1780/3257 [00:10<00:09, 151.25it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1797/3257 [00:10<00:09, 154.87it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1813/3257 [00:10<00:09, 151.29it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1829/3257 [00:10<00:09, 150.92it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1846/3257 [00:11<00:09, 154.68it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1864/3257 [00:11<00:08, 161.44it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1881/3257 [00:11<00:08, 158.89it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1897/3257 [00:11<00:08, 155.20it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:11<00:08, 158.42it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1933/3257 [00:11<00:08, 160.19it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:11<00:07, 173.30it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1973/3257 [00:11<00:07, 175.95it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1991/3257 [00:11<00:07, 165.85it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2008/3257 [00:12<00:07, 165.09it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2026/3257 [00:12<00:07, 167.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2043/3257 [00:12<00:07, 159.61it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2060/3257 [00:12<00:08, 144.85it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2078/3257 [00:12<00:07, 153.56it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2094/3257 [00:12<00:13, 88.44it/s]  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2109/3257 [00:12<00:11, 99.01it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2122/3257 [00:13<00:11, 103.02it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2138/3257 [00:13<00:09, 115.61it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2152/3257 [00:13<00:09, 119.95it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2169/3257 [00:13<00:08, 130.51it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2185/3257 [00:13<00:07, 136.89it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2203/3257 [00:13<00:07, 147.51it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2219/3257 [00:13<00:07, 145.72it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2236/3257 [00:13<00:06, 148.56it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2252/3257 [00:13<00:06, 144.42it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2267/3257 [00:14<00:06, 143.74it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2282/3257 [00:14<00:06, 143.78it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:14<00:06, 149.22it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2316/3257 [00:14<00:06, 153.76it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2337/3257 [00:14<00:05, 167.52it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:14<00:05, 176.19it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2378/3257 [00:14<00:05, 173.41it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:14<00:04, 176.40it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2415/3257 [00:14<00:05, 164.58it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2432/3257 [00:15<00:05, 153.85it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2448/3257 [00:15<00:05, 151.28it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2468/3257 [00:15<00:04, 164.29it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2485/3257 [00:15<00:04, 161.65it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2506/3257 [00:15<00:04, 174.38it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:15<00:04, 170.57it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2542/3257 [00:15<00:04, 167.72it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2559/3257 [00:15<00:04, 162.63it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2576/3257 [00:15<00:04, 154.70it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2592/3257 [00:16<00:04, 150.78it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2614/3257 [00:16<00:03, 168.20it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2637/3257 [00:16<00:03, 184.05it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2656/3257 [00:16<00:03, 183.63it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2677/3257 [00:16<00:03, 186.52it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2698/3257 [00:16<00:03, 184.29it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2717/3257 [00:16<00:02, 182.29it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2744/3257 [00:16<00:02, 204.46it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2766/3257 [00:16<00:02, 207.81it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2789/3257 [00:16<00:02, 213.45it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2812/3257 [00:17<00:02, 216.76it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2834/3257 [00:17<00:02, 202.73it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2861/3257 [00:17<00:01, 221.46it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:17<00:01, 224.82it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2909/3257 [00:17<00:01, 209.72it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2931/3257 [00:17<00:01, 206.97it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2952/3257 [00:17<00:01, 195.92it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2975/3257 [00:17<00:01, 204.08it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2996/3257 [00:18<00:01, 196.28it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3018/3257 [00:18<00:01, 198.57it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3041/3257 [00:18<00:01, 206.72it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3066/3257 [00:18<00:00, 218.31it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3088/3257 [00:18<00:00, 213.29it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3113/3257 [00:18<00:00, 223.57it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3136/3257 [00:18<00:00, 215.22it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3158/3257 [00:18<00:00, 204.83it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3179/3257 [00:18<00:00, 195.06it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:18<00:00, 203.56it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3224/3257 [00:19<00:00, 193.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3247/3257 [00:19<00:00, 202.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 169.05it/s]
2023-02-07 20:41:15.092 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:41:15,093][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d302,n5,mc7,s0.515008,t4>', 'datetime': '2023-02-07T20:41:15.093785', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:41:15,094][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:41:15,094][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:41:15,570][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 20:41:15,570][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:41:15,612][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 14137 unique words (44.45% of original 31803, drops 17666)', 'datetime': '2023-02-07T20:41:15.612843', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:41:15,614][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 5044802 word corpus (99.01% of original 5095118, drops 50316)', 'datetime': '2023-02-07T20:41:15.614726', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:41:15,665][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 20:41:15,666][gensim.models.word2vec][INFO] - sample=0.515008 downsamples 0 most-common words
[2023-02-07 20:41:15,666][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5044802 word corpus (100.0%% of prior 5044802)', 'datetime': '2023-02-07T20:41:15.666259', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:41:15,753][gensim.models.word2vec][INFO] - estimated required memory for 14137 words and 302 dimensions: 45809348 bytes
[2023-02-07 20:41:15,753][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:41:15,777][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14137 vocabulary and 302 features, using sg=1 hs=0 sample=0.5150077538492879 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T20:41:15.777070', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:41:16,787][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 39.18% examples, 2011415 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:17,795][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 80.84% examples, 2035584 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:41:18,238][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5036861 effective words) took 2.5s, 2049009 effective words/s
[2023-02-07 20:41:19,244][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 42.00% examples, 2168535 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:41:20,246][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 86.40% examples, 2186390 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:20,538][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5036861 effective words) took 2.3s, 2193278 effective words/s
[2023-02-07 20:41:21,542][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 42.55% examples, 2205525 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:22,546][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 87.84% examples, 2220718 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:22,788][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5036861 effective words) took 2.2s, 2239626 effective words/s
[2023-02-07 20:41:23,792][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 37.64% examples, 1938702 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:24,796][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 76.54% examples, 1946517 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:25,372][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5036861 effective words) took 2.6s, 1950622 effective words/s
[2023-02-07 20:41:26,376][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 38.29% examples, 1973381 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:41:27,379][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 77.96% examples, 1977125 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:27,919][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5036861 effective words) took 2.5s, 1979973 effective words/s
[2023-02-07 20:41:28,926][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 38.47% examples, 1977440 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:29,930][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 78.17% examples, 1980790 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:30,459][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5036861 effective words) took 2.5s, 1985966 effective words/s
[2023-02-07 20:41:31,469][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 38.29% examples, 1960331 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:32,471][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 87.53% examples, 2212562 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:32,697][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5036861 effective words) took 2.2s, 2252472 effective words/s
[2023-02-07 20:41:33,699][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 43.84% examples, 2263253 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:34,699][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 88.15% examples, 2231286 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:34,957][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5036861 effective words) took 2.3s, 2229848 effective words/s
[2023-02-07 20:41:35,963][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 42.55% examples, 2202362 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:36,964][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 86.49% examples, 2189807 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:37,253][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5036861 effective words) took 2.3s, 2195100 effective words/s
[2023-02-07 20:41:38,258][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 41.94% examples, 2168707 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:39,259][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 86.77% examples, 2200193 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:39,536][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5036861 effective words) took 2.3s, 2208478 effective words/s
[2023-02-07 20:41:40,541][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 43.02% examples, 2222167 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:41,547][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 88.85% examples, 2243032 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:41:41,769][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5036861 effective words) took 2.2s, 2256596 effective words/s
[2023-02-07 20:41:42,779][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 42.40% examples, 2185221 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:41:43,781][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 82.16% examples, 2075723 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:44,207][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5036861 effective words) took 2.4s, 2067481 effective words/s
[2023-02-07 20:41:45,212][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 38.29% examples, 1971397 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:46,216][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 78.54% examples, 1990756 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:46,729][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5036861 effective words) took 2.5s, 1998674 effective words/s
[2023-02-07 20:41:47,734][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 38.93% examples, 2000871 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:48,734][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 78.91% examples, 2008563 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:49,235][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5036861 effective words) took 2.5s, 2011966 effective words/s
[2023-02-07 20:41:50,241][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 39.12% examples, 2009134 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:51,243][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 79.52% examples, 2022000 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:41:51,616][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5036861 effective words) took 2.4s, 2116795 effective words/s
[2023-02-07 20:41:51,618][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75552915 effective words) took 35.8s, 2108030 effective words/s', 'datetime': '2023-02-07T20:41:51.618002', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:41:51.618 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:41:54,318][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204046-2bxnh258/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:41:54.318532', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:41:54,319][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:41:54,376][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204046-2bxnh258/files/../tmp/embedding_model.pt
2023-02-07 20:41:54.376 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:41:56.245 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:41:56.897 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:41:58.946 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.938276854650271, 'test_mae': 0.7447432707880903, 'test_r2': -1.8990318987324555}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.62
wandb: percentage 0.55548
wandb:   test_mae 0.74474
wandb:   test_mse 0.93828
wandb:    test_r2 -1.89903
wandb: 
wandb: üöÄ View run desert-sweep-94 at: https://wandb.ai/xiaoqiz/mof2vec/runs/2bxnh258
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_204046-2bxnh258/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 826ofr2g with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 681
wandb: 	model.gensim.alpha: 0.01571168665458515
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 8
wandb: 	model.gensim.sample: 0.8209313386773769
wandb: 	model.gensim.vector_size: 456
wandb: 	model.gensim.window: 1
wandb: 	model.sklearn.learning_rate: 0.004858828143289056
wandb: 	model.sklearn.max_depth: 25
wandb: 	model.sklearn.min_child_weight: 0.05366384467079114
wandb: 	model.sklearn.n_estimators: 18
wandb: 	model.sklearn.num_leaves: 316
wandb: 	model.sklearn.reg_alpha: 0.0035349045077167525
wandb: 	model.sklearn.reg_lambda: 0.02785836057621531
wandb: 	model.sklearn.subsample: 0.8651394492536617
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204217-826ofr2g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-95
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/826ofr2g
2023-02-07 20:42:25.841 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:42:25.842 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 681 for sweep.
2023-02-07 20:42:25.842 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.01571168665458515 for sweep.
2023-02-07 20:42:25.842 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:42:25.843 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 8 for sweep.
2023-02-07 20:42:25.843 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8209313386773769 for sweep.
2023-02-07 20:42:25.843 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 456 for sweep.
2023-02-07 20:42:25.843 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 1 for sweep.
2023-02-07 20:42:25.844 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.004858828143289056 for sweep.
2023-02-07 20:42:25.844 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 25 for sweep.
2023-02-07 20:42:25.844 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.05366384467079114 for sweep.
2023-02-07 20:42:25.844 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 18 for sweep.
2023-02-07 20:42:25.845 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 316 for sweep.
2023-02-07 20:42:25.845 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.0035349045077167525 for sweep.
2023-02-07 20:42:25.845 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.02785836057621531 for sweep.
2023-02-07 20:42:25.845 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8651394492536617 for sweep.
2023-02-07 20:42:25.846 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:42:25.852 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204217-826ofr2g/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 681, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 456, 'window': 1, 'min_count': 8, 'dm': 0, 'sample': 0.8209313386773769, 'workers': 4, 'alpha': 0.01571168665458515, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 18, 'max_depth': 25, 'num_leaves': 316, 'reg_alpha': 0.0035349045077167525, 'reg_lambda': 0.02785836057621531, 'subsample': 0.8651394492536617, 'min_child_weight': 0.05366384467079114, 'n_jobs': 4, 'learning_rate': 0.004858828143289056}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:26, 122.22it/s]  1%|          | 28/3257 [00:00<00:24, 134.30it/s]  1%|‚ñè         | 42/3257 [00:00<00:25, 127.97it/s]  2%|‚ñè         | 55/3257 [00:00<00:25, 126.00it/s]  2%|‚ñè         | 69/3257 [00:00<00:24, 129.27it/s]  3%|‚ñé         | 82/3257 [00:00<00:37, 85.57it/s]   3%|‚ñé         | 96/3257 [00:00<00:33, 95.71it/s]  3%|‚ñé         | 108/3257 [00:01<00:31, 101.05it/s]  4%|‚ñç         | 124/3257 [00:01<00:27, 113.83it/s]  4%|‚ñç         | 138/3257 [00:01<00:26, 119.62it/s]  5%|‚ñç         | 153/3257 [00:01<00:24, 127.22it/s]  5%|‚ñå         | 167/3257 [00:01<00:24, 126.74it/s]  6%|‚ñå         | 181/3257 [00:01<00:23, 128.46it/s]  6%|‚ñå         | 197/3257 [00:01<00:22, 136.69it/s]  7%|‚ñã         | 217/3257 [00:01<00:19, 153.84it/s]  7%|‚ñã         | 237/3257 [00:01<00:18, 164.37it/s]  8%|‚ñä         | 258/3257 [00:01<00:17, 176.10it/s]  9%|‚ñä         | 279/3257 [00:02<00:16, 185.47it/s]  9%|‚ñâ         | 299/3257 [00:02<00:15, 187.08it/s] 10%|‚ñâ         | 318/3257 [00:02<00:16, 183.41it/s] 10%|‚ñà         | 339/3257 [00:02<00:15, 187.52it/s] 11%|‚ñà         | 360/3257 [00:02<00:14, 193.65it/s] 12%|‚ñà‚ñè        | 380/3257 [00:02<00:15, 187.36it/s] 12%|‚ñà‚ñè        | 399/3257 [00:02<00:15, 188.06it/s] 13%|‚ñà‚ñé        | 420/3257 [00:02<00:14, 194.15it/s] 14%|‚ñà‚ñé        | 440/3257 [00:02<00:16, 166.76it/s] 14%|‚ñà‚ñç        | 458/3257 [00:03<00:16, 169.18it/s] 15%|‚ñà‚ñç        | 476/3257 [00:03<00:16, 170.09it/s] 15%|‚ñà‚ñå        | 494/3257 [00:03<00:16, 169.15it/s] 16%|‚ñà‚ñå        | 515/3257 [00:03<00:15, 180.07it/s] 16%|‚ñà‚ñã        | 534/3257 [00:03<00:15, 178.88it/s] 17%|‚ñà‚ñã        | 553/3257 [00:03<00:15, 178.51it/s] 18%|‚ñà‚ñä        | 571/3257 [00:03<00:17, 154.37it/s] 18%|‚ñà‚ñä        | 588/3257 [00:03<00:16, 158.42it/s] 19%|‚ñà‚ñä        | 605/3257 [00:03<00:16, 161.42it/s] 19%|‚ñà‚ñâ        | 622/3257 [00:04<00:16, 159.86it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:04<00:15, 167.43it/s] 20%|‚ñà‚ñà        | 658/3257 [00:04<00:17, 151.44it/s] 21%|‚ñà‚ñà        | 676/3257 [00:04<00:16, 157.54it/s] 21%|‚ñà‚ñà‚ñè       | 693/3257 [00:04<00:16, 153.61it/s] 22%|‚ñà‚ñà‚ñè       | 709/3257 [00:04<00:16, 155.05it/s] 22%|‚ñà‚ñà‚ñè       | 725/3257 [00:04<00:17, 145.83it/s] 23%|‚ñà‚ñà‚ñé       | 740/3257 [00:04<00:17, 142.39it/s] 23%|‚ñà‚ñà‚ñé       | 759/3257 [00:04<00:16, 153.93it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:05<00:16, 152.82it/s] 24%|‚ñà‚ñà‚ñç       | 792/3257 [00:05<00:15, 154.68it/s] 25%|‚ñà‚ñà‚ñç       | 808/3257 [00:05<00:15, 154.92it/s] 25%|‚ñà‚ñà‚ñå       | 824/3257 [00:05<00:16, 149.57it/s] 26%|‚ñà‚ñà‚ñå       | 840/3257 [00:05<00:16, 148.07it/s] 26%|‚ñà‚ñà‚ñã       | 855/3257 [00:05<00:16, 143.33it/s] 27%|‚ñà‚ñà‚ñã       | 871/3257 [00:05<00:16, 146.32it/s] 27%|‚ñà‚ñà‚ñã       | 886/3257 [00:05<00:16, 144.32it/s] 28%|‚ñà‚ñà‚ñä       | 905/3257 [00:05<00:15, 154.29it/s] 28%|‚ñà‚ñà‚ñä       | 922/3257 [00:06<00:14, 158.33it/s] 29%|‚ñà‚ñà‚ñâ       | 938/3257 [00:06<00:15, 154.08it/s] 29%|‚ñà‚ñà‚ñâ       | 956/3257 [00:06<00:14, 159.28it/s] 30%|‚ñà‚ñà‚ñâ       | 972/3257 [00:06<00:14, 154.32it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:06<00:15, 148.43it/s] 31%|‚ñà‚ñà‚ñà       | 1004/3257 [00:06<00:14, 151.08it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1020/3257 [00:06<00:14, 151.91it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1036/3257 [00:06<00:15, 144.84it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1051/3257 [00:06<00:15, 143.26it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1068/3257 [00:07<00:14, 148.92it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1083/3257 [00:07<00:14, 148.25it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1099/3257 [00:07<00:14, 150.27it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1115/3257 [00:07<00:14, 152.94it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1131/3257 [00:07<00:14, 144.03it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1146/3257 [00:07<00:14, 143.21it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1165/3257 [00:07<00:13, 154.50it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1181/3257 [00:07<00:14, 143.58it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1196/3257 [00:07<00:14, 137.92it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1210/3257 [00:08<00:15, 134.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1228/3257 [00:08<00:13, 146.53it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1244/3257 [00:08<00:13, 149.27it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1260/3257 [00:08<00:13, 149.85it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1276/3257 [00:08<00:13, 144.59it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:08<00:21, 90.18it/s]  40%|‚ñà‚ñà‚ñà‚ñà      | 1307/3257 [00:08<00:18, 103.16it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1322/3257 [00:08<00:17, 112.99it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1340/3257 [00:09<00:14, 128.78it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1355/3257 [00:09<00:14, 130.47it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:09<00:14, 134.57it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:09<00:13, 138.54it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1404/3257 [00:09<00:12, 148.70it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1423/3257 [00:09<00:11, 158.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1441/3257 [00:09<00:11, 162.96it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1462/3257 [00:09<00:10, 175.87it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1480/3257 [00:09<00:10, 174.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1498/3257 [00:10<00:10, 174.56it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1516/3257 [00:10<00:10, 172.50it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1534/3257 [00:10<00:11, 154.24it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1550/3257 [00:10<00:11, 153.36it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1566/3257 [00:10<00:10, 154.54it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1584/3257 [00:10<00:10, 161.28it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1604/3257 [00:10<00:09, 171.26it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1622/3257 [00:10<00:09, 168.91it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1640/3257 [00:10<00:09, 163.13it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1657/3257 [00:11<00:11, 145.23it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1672/3257 [00:11<00:11, 136.00it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1686/3257 [00:11<00:11, 133.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1701/3257 [00:11<00:11, 136.76it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1715/3257 [00:11<00:11, 134.70it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1729/3257 [00:11<00:11, 128.60it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1742/3257 [00:11<00:12, 123.21it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1760/3257 [00:11<00:11, 135.61it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1774/3257 [00:11<00:10, 136.70it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1791/3257 [00:12<00:10, 143.81it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1806/3257 [00:12<00:10, 137.43it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1821/3257 [00:12<00:10, 140.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1836/3257 [00:12<00:10, 138.68it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1852/3257 [00:12<00:09, 141.75it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1869/3257 [00:12<00:09, 145.64it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1884/3257 [00:12<00:09, 146.05it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1899/3257 [00:12<00:09, 142.92it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:12<00:09, 142.25it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1931/3257 [00:13<00:09, 140.19it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1951/3257 [00:13<00:08, 155.36it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1969/3257 [00:13<00:08, 160.28it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1986/3257 [00:13<00:08, 147.48it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2004/3257 [00:13<00:08, 154.38it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2022/3257 [00:13<00:07, 159.36it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2039/3257 [00:13<00:07, 153.69it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2055/3257 [00:13<00:08, 140.68it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2070/3257 [00:13<00:08, 136.72it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2085/3257 [00:14<00:08, 139.67it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2100/3257 [00:14<00:08, 135.87it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2117/3257 [00:14<00:08, 141.43it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:14<00:08, 130.28it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2146/3257 [00:14<00:08, 127.27it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2162/3257 [00:14<00:08, 135.09it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2179/3257 [00:14<00:07, 143.31it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2195/3257 [00:14<00:07, 147.29it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2210/3257 [00:15<00:07, 136.25it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2227/3257 [00:15<00:07, 143.99it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2242/3257 [00:15<00:07, 138.34it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2257/3257 [00:15<00:07, 141.33it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2272/3257 [00:15<00:07, 131.47it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2289/3257 [00:15<00:06, 141.59it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2304/3257 [00:15<00:06, 137.17it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2321/3257 [00:15<00:06, 146.05it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2339/3257 [00:15<00:05, 154.44it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2360/3257 [00:16<00:05, 159.47it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2377/3257 [00:16<00:05, 157.10it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2396/3257 [00:16<00:05, 163.34it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2413/3257 [00:16<00:05, 149.33it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2429/3257 [00:16<00:05, 148.95it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2445/3257 [00:16<00:05, 143.71it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2461/3257 [00:16<00:05, 145.82it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2477/3257 [00:16<00:05, 148.30it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2493/3257 [00:16<00:05, 151.14it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2510/3257 [00:16<00:04, 156.38it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2526/3257 [00:17<00:04, 151.21it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2542/3257 [00:17<00:04, 153.18it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2558/3257 [00:17<00:04, 148.99it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:17<00:04, 137.67it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2587/3257 [00:17<00:04, 135.14it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2604/3257 [00:17<00:04, 143.28it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2624/3257 [00:17<00:04, 158.24it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2641/3257 [00:17<00:04, 152.51it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2657/3257 [00:18<00:04, 142.66it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2673/3257 [00:18<00:04, 144.93it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2688/3257 [00:18<00:07, 73.91it/s]  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2700/3257 [00:18<00:07, 77.42it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2715/3257 [00:18<00:06, 88.34it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2734/3257 [00:18<00:04, 107.92it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2752/3257 [00:19<00:04, 122.76it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2768/3257 [00:19<00:03, 127.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2785/3257 [00:19<00:03, 136.73it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2802/3257 [00:19<00:03, 144.12it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2818/3257 [00:19<00:03, 144.61it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2835/3257 [00:19<00:02, 150.91it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2861/3257 [00:19<00:02, 180.19it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2886/3257 [00:19<00:01, 193.23it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2906/3257 [00:19<00:01, 184.11it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:20<00:01, 187.68it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:20<00:01, 182.64it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2968/3257 [00:20<00:01, 188.83it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2988/3257 [00:20<00:01, 177.21it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3012/3257 [00:20<00:01, 193.81it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3032/3257 [00:20<00:01, 190.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3052/3257 [00:20<00:01, 190.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3075/3257 [00:20<00:00, 199.04it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3096/3257 [00:20<00:00, 191.16it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3119/3257 [00:21<00:00, 201.47it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3140/3257 [00:21<00:00, 190.47it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3160/3257 [00:21<00:00, 182.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3179/3257 [00:21<00:00, 171.32it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3201/3257 [00:21<00:00, 181.45it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3220/3257 [00:21<00:00, 172.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3242/3257 [00:21<00:00, 183.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:21<00:00, 149.35it/s]
2023-02-07 20:42:48.465 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:42:48,467][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d456,n5,mc8,s0.820931,t4>', 'datetime': '2023-02-07T20:42:48.467412', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:42:48,467][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:42:48,467][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:42:49,008][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:42:49,008][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:42:49,062][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 retains 18271 unique words (42.79% of original 42701, drops 24430)', 'datetime': '2023-02-07T20:42:49.061963', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:42:49,062][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=8 leaves 5751191 word corpus (98.77% of original 5822992, drops 71801)', 'datetime': '2023-02-07T20:42:49.062365', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:42:49,125][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:42:49,127][gensim.models.word2vec][INFO] - sample=0.820931 downsamples 0 most-common words
[2023-02-07 20:42:49,127][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5751191 word corpus (100.0%% of prior 5751191)', 'datetime': '2023-02-07T20:42:49.127264', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:42:49,235][gensim.models.word2vec][INFO] - estimated required memory for 18271 words and 456 dimensions: 82380276 bytes
[2023-02-07 20:42:49,235][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:42:49,274][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 18271 vocabulary and 456 features, using sg=1 hs=0 sample=0.8209313386773769 negative=5 window=1 shrink_windows=True', 'datetime': '2023-02-07T20:42:49.274257', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:42:50,283][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 28.89% examples, 1651331 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:42:51,286][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 58.83% examples, 1714400 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:52,287][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 91.34% examples, 1748488 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:52,533][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5725443 effective words) took 3.3s, 1758453 effective words/s
[2023-02-07 20:42:53,535][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 34.45% examples, 1996735 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:42:54,541][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 66.69% examples, 1944501 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:55,544][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 97.21% examples, 1852064 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:42:55,626][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5725443 effective words) took 3.1s, 1852296 effective words/s
[2023-02-07 20:42:56,632][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 30.03% examples, 1715788 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:42:57,639][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 59.13% examples, 1722111 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:42:58,641][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 90.33% examples, 1726518 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:42:58,948][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5725443 effective words) took 3.3s, 1725134 effective words/s
[2023-02-07 20:42:59,961][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 30.92% examples, 1768026 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:43:00,966][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 61.13% examples, 1766685 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:01,973][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 92.94% examples, 1771860 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:02,174][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5725443 effective words) took 3.2s, 1776095 effective words/s
[2023-02-07 20:43:03,179][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 31.50% examples, 1812463 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:04,182][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 70.53% examples, 2059182 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:04,901][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5725443 effective words) took 2.7s, 2102049 effective words/s
[2023-02-07 20:43:05,903][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 40.56% examples, 2382885 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:06,908][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 79.40% examples, 2293345 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:07,459][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5725443 effective words) took 2.6s, 2239714 effective words/s
[2023-02-07 20:43:08,461][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 36.17% examples, 2098382 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:43:09,471][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 71.51% examples, 2075036 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:10,210][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5725443 effective words) took 2.7s, 2081998 effective words/s
[2023-02-07 20:43:11,223][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 37.70% examples, 2184475 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:43:12,224][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 75.41% examples, 2179957 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:43:12,864][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5725443 effective words) took 2.7s, 2159179 effective words/s
[2023-02-07 20:43:13,868][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 36.44% examples, 2123925 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:14,872][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 72.92% examples, 2112798 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:15,566][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5725443 effective words) took 2.7s, 2120372 effective words/s
[2023-02-07 20:43:16,577][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.44% examples, 2109331 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:17,578][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 73.81% examples, 2129396 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:18,258][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5725443 effective words) took 2.7s, 2128668 effective words/s
[2023-02-07 20:43:19,262][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 36.48% examples, 2133648 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:43:20,268][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 73.81% examples, 2131828 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:20,947][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5725443 effective words) took 2.7s, 2130401 effective words/s
[2023-02-07 20:43:21,953][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 36.44% examples, 2119404 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:22,962][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 73.81% examples, 2126686 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:23,641][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5725443 effective words) took 2.7s, 2127393 effective words/s
[2023-02-07 20:43:24,651][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 36.48% examples, 2123016 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:43:25,651][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 73.66% examples, 2132826 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:43:26,329][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5725443 effective words) took 2.7s, 2132660 effective words/s
[2023-02-07 20:43:27,330][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 36.05% examples, 2093339 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:28,332][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 71.91% examples, 2093075 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:29,070][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5725443 effective words) took 2.7s, 2089523 effective words/s
[2023-02-07 20:43:30,074][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 36.48% examples, 2133577 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:43:31,077][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 73.81% examples, 2134247 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:43:31,753][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5725443 effective words) took 2.7s, 2135798 effective words/s
[2023-02-07 20:43:31,753][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85881645 effective words) took 42.5s, 2021785 effective words/s', 'datetime': '2023-02-07T20:43:31.753673', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:43:31.753 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:43:35,542][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204217-826ofr2g/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:43:35.542124', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:43:35,543][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:43:35,652][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204217-826ofr2g/files/../tmp/embedding_model.pt
2023-02-07 20:43:35.653 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:43:38.189 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:43:39.102 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:43:42.134 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.875290664454093, 'test_mae': 0.7166348023374388, 'test_r2': -1.657943438807473}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.83
wandb: percentage 0.57212
wandb:   test_mae 0.71663
wandb:   test_mse 0.87529
wandb:    test_r2 -1.65794
wandb: 
wandb: üöÄ View run fresh-sweep-95 at: https://wandb.ai/xiaoqiz/mof2vec/runs/826ofr2g
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_204217-826ofr2g/logs
wandb: Agent Starting Run: 4v1wghjb with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 328
wandb: 	model.gensim.alpha: 0.00978212342724743
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.7902152137726521
wandb: 	model.gensim.vector_size: 244
wandb: 	model.gensim.window: 3
wandb: 	model.sklearn.learning_rate: 0.007019674385768313
wandb: 	model.sklearn.max_depth: 23
wandb: 	model.sklearn.min_child_weight: 0.06245133122292962
wandb: 	model.sklearn.n_estimators: 1701
wandb: 	model.sklearn.num_leaves: 334
wandb: 	model.sklearn.reg_alpha: 0.003885176946481372
wandb: 	model.sklearn.reg_lambda: 0.04426566007423058
wandb: 	model.sklearn.subsample: 0.6529610107670187
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204353-4v1wghjb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-96
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/4v1wghjb
2023-02-07 20:44:01.588 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:44:01.588 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 328 for sweep.
2023-02-07 20:44:01.589 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.00978212342724743 for sweep.
2023-02-07 20:44:01.589 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:44:01.589 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 20:44:01.589 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.7902152137726521 for sweep.
2023-02-07 20:44:01.590 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 244 for sweep.
2023-02-07 20:44:01.590 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 3 for sweep.
2023-02-07 20:44:01.590 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.007019674385768313 for sweep.
2023-02-07 20:44:01.590 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 23 for sweep.
2023-02-07 20:44:01.591 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.06245133122292962 for sweep.
2023-02-07 20:44:01.591 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1701 for sweep.
2023-02-07 20:44:01.591 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 334 for sweep.
2023-02-07 20:44:01.591 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.003885176946481372 for sweep.
2023-02-07 20:44:01.592 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.04426566007423058 for sweep.
2023-02-07 20:44:01.592 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.6529610107670187 for sweep.
2023-02-07 20:44:01.592 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:44:01.599 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204353-4v1wghjb/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 328, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 244, 'window': 3, 'min_count': 9, 'dm': 0, 'sample': 0.7902152137726521, 'workers': 4, 'alpha': 0.00978212342724743, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1701, 'max_depth': 23, 'num_leaves': 334, 'reg_alpha': 0.003885176946481372, 'reg_lambda': 0.04426566007423058, 'subsample': 0.6529610107670187, 'min_child_weight': 0.06245133122292962, 'n_jobs': 4, 'learning_rate': 0.007019674385768313}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 17/3257 [00:00<00:19, 168.05it/s]  1%|          | 35/3257 [00:00<00:18, 173.93it/s]  2%|‚ñè         | 53/3257 [00:00<00:20, 160.04it/s]  2%|‚ñè         | 70/3257 [00:00<00:20, 156.44it/s]  3%|‚ñé         | 88/3257 [00:00<00:19, 162.02it/s]  3%|‚ñé         | 105/3257 [00:00<00:21, 146.01it/s]  4%|‚ñé         | 120/3257 [00:00<00:21, 146.79it/s]  4%|‚ñç         | 135/3257 [00:00<00:21, 145.11it/s]  5%|‚ñç         | 152/3257 [00:00<00:20, 151.81it/s]  5%|‚ñå         | 168/3257 [00:01<00:20, 148.89it/s]  6%|‚ñå         | 183/3257 [00:01<00:21, 145.22it/s]  6%|‚ñå         | 198/3257 [00:01<00:20, 146.14it/s]  7%|‚ñã         | 215/3257 [00:01<00:20, 151.86it/s]  7%|‚ñã         | 233/3257 [00:01<00:18, 159.74it/s]  8%|‚ñä         | 250/3257 [00:01<00:19, 157.36it/s]  8%|‚ñä         | 266/3257 [00:01<00:19, 150.21it/s]  9%|‚ñâ         | 286/3257 [00:01<00:18, 161.67it/s]  9%|‚ñâ         | 303/3257 [00:01<00:18, 155.82it/s] 10%|‚ñâ         | 319/3257 [00:02<00:18, 154.80it/s] 10%|‚ñà         | 335/3257 [00:02<00:18, 154.68it/s] 11%|‚ñà         | 351/3257 [00:02<00:19, 148.81it/s] 11%|‚ñà‚ñè        | 367/3257 [00:02<00:19, 148.25it/s] 12%|‚ñà‚ñè        | 382/3257 [00:02<00:20, 142.20it/s] 12%|‚ñà‚ñè        | 397/3257 [00:02<00:20, 141.03it/s] 13%|‚ñà‚ñé        | 414/3257 [00:02<00:19, 148.35it/s] 13%|‚ñà‚ñé        | 429/3257 [00:02<00:21, 130.53it/s] 14%|‚ñà‚ñé        | 443/3257 [00:02<00:21, 132.71it/s] 14%|‚ñà‚ñç        | 459/3257 [00:03<00:20, 137.73it/s] 15%|‚ñà‚ñç        | 475/3257 [00:03<00:19, 141.52it/s] 15%|‚ñà‚ñå        | 491/3257 [00:03<00:19, 145.22it/s] 16%|‚ñà‚ñå        | 510/3257 [00:03<00:17, 154.87it/s] 16%|‚ñà‚ñå        | 526/3257 [00:03<00:18, 149.60it/s] 17%|‚ñà‚ñã        | 546/3257 [00:03<00:17, 159.19it/s] 17%|‚ñà‚ñã        | 562/3257 [00:03<00:17, 158.01it/s] 18%|‚ñà‚ñä        | 578/3257 [00:03<00:17, 153.87it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:15, 168.41it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:04<00:15, 171.84it/s] 20%|‚ñà‚ñâ        | 641/3257 [00:04<00:14, 179.96it/s] 20%|‚ñà‚ñà        | 660/3257 [00:04<00:15, 167.02it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:14, 173.63it/s] 22%|‚ñà‚ñà‚ñè       | 701/3257 [00:04<00:14, 175.29it/s] 22%|‚ñà‚ñà‚ñè       | 720/3257 [00:04<00:14, 178.74it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:04<00:15, 165.35it/s] 23%|‚ñà‚ñà‚ñé       | 758/3257 [00:04<00:14, 173.63it/s] 24%|‚ñà‚ñà‚ñç       | 776/3257 [00:05<00:21, 115.17it/s] 24%|‚ñà‚ñà‚ñç       | 794/3257 [00:05<00:19, 127.65it/s] 25%|‚ñà‚ñà‚ñç       | 811/3257 [00:05<00:17, 137.25it/s] 25%|‚ñà‚ñà‚ñå       | 827/3257 [00:05<00:17, 137.87it/s] 26%|‚ñà‚ñà‚ñå       | 843/3257 [00:05<00:17, 138.26it/s] 26%|‚ñà‚ñà‚ñã       | 861/3257 [00:05<00:16, 148.72it/s] 27%|‚ñà‚ñà‚ñã       | 877/3257 [00:05<00:16, 148.31it/s] 28%|‚ñà‚ñà‚ñä       | 897/3257 [00:05<00:14, 162.23it/s] 28%|‚ñà‚ñà‚ñä       | 915/3257 [00:05<00:14, 166.65it/s] 29%|‚ñà‚ñà‚ñä       | 934/3257 [00:06<00:13, 171.37it/s] 29%|‚ñà‚ñà‚ñâ       | 955/3257 [00:06<00:12, 180.96it/s] 30%|‚ñà‚ñà‚ñâ       | 974/3257 [00:06<00:12, 175.76it/s] 30%|‚ñà‚ñà‚ñà       | 992/3257 [00:06<00:13, 167.96it/s] 31%|‚ñà‚ñà‚ñà       | 1009/3257 [00:06<00:13, 162.07it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1026/3257 [00:06<00:13, 160.24it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1043/3257 [00:06<00:15, 141.47it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1058/3257 [00:06<00:15, 142.95it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1076/3257 [00:07<00:14, 152.39it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1092/3257 [00:07<00:15, 139.72it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1109/3257 [00:07<00:14, 145.81it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1124/3257 [00:07<00:15, 140.17it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1139/3257 [00:07<00:15, 137.49it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1153/3257 [00:07<00:15, 137.05it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:07<00:14, 142.01it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1185/3257 [00:07<00:15, 134.90it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1199/3257 [00:07<00:15, 132.38it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1213/3257 [00:08<00:16, 126.26it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:08<00:14, 143.22it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1247/3257 [00:08<00:14, 142.01it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1262/3257 [00:08<00:13, 143.35it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1277/3257 [00:08<00:14, 136.91it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1291/3257 [00:08<00:14, 134.69it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1306/3257 [00:08<00:14, 138.54it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1322/3257 [00:08<00:13, 141.91it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1339/3257 [00:08<00:12, 149.12it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1354/3257 [00:09<00:13, 141.04it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:09<00:13, 142.90it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1385/3257 [00:09<00:13, 142.52it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1402/3257 [00:09<00:12, 149.65it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1422/3257 [00:09<00:11, 163.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1439/3257 [00:09<00:11, 156.06it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:09<00:10, 166.93it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1477/3257 [00:09<00:10, 167.20it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1495/3257 [00:09<00:10, 169.74it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1516/3257 [00:09<00:09, 180.72it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1535/3257 [00:10<00:10, 169.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1553/3257 [00:10<00:10, 170.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1574/3257 [00:10<00:09, 178.44it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1594/3257 [00:10<00:09, 183.63it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1616/3257 [00:10<00:08, 193.06it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1636/3257 [00:10<00:08, 184.54it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1655/3257 [00:10<00:08, 183.00it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:10<00:09, 173.15it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:10<00:09, 169.36it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1713/3257 [00:11<00:08, 179.67it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1732/3257 [00:11<00:09, 167.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1751/3257 [00:11<00:08, 171.86it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1771/3257 [00:11<00:08, 177.07it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1792/3257 [00:11<00:08, 182.82it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1811/3257 [00:11<00:08, 173.29it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1829/3257 [00:11<00:08, 171.95it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:11<00:07, 176.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1870/3257 [00:11<00:07, 185.76it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1889/3257 [00:12<00:07, 182.67it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1909/3257 [00:12<00:07, 187.48it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1928/3257 [00:12<00:07, 180.52it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1954/3257 [00:12<00:06, 200.99it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1975/3257 [00:12<00:06, 203.25it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1996/3257 [00:12<00:06, 198.53it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2016/3257 [00:12<00:06, 184.95it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2035/3257 [00:13<00:12, 99.76it/s]  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2050/3257 [00:13<00:11, 103.63it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2064/3257 [00:13<00:10, 110.53it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2081/3257 [00:13<00:09, 122.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2096/3257 [00:13<00:09, 124.25it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2114/3257 [00:13<00:08, 137.53it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2130/3257 [00:13<00:08, 129.04it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2145/3257 [00:13<00:08, 129.27it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2161/3257 [00:14<00:07, 137.10it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:14<00:07, 142.99it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2195/3257 [00:14<00:07, 149.24it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2211/3257 [00:14<00:07, 139.44it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2228/3257 [00:14<00:07, 146.51it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2244/3257 [00:14<00:07, 143.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2260/3257 [00:14<00:06, 145.68it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2275/3257 [00:14<00:07, 137.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2296/3257 [00:14<00:06, 154.61it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2312/3257 [00:15<00:06, 150.01it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2333/3257 [00:15<00:05, 164.69it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2353/3257 [00:15<00:05, 173.42it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2371/3257 [00:15<00:05, 166.90it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2390/3257 [00:15<00:05, 172.55it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2408/3257 [00:15<00:05, 161.68it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2426/3257 [00:15<00:05, 164.11it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:15<00:05, 150.63it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2462/3257 [00:15<00:05, 158.97it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2483/3257 [00:16<00:04, 170.60it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2508/3257 [00:16<00:03, 191.44it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2531/3257 [00:16<00:03, 200.74it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2552/3257 [00:16<00:03, 199.10it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:16<00:03, 182.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2592/3257 [00:16<00:03, 181.96it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2617/3257 [00:16<00:03, 200.34it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2640/3257 [00:16<00:03, 205.18it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2661/3257 [00:16<00:03, 193.51it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2684/3257 [00:17<00:02, 202.73it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2705/3257 [00:17<00:02, 187.80it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2725/3257 [00:17<00:02, 185.47it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2749/3257 [00:17<00:02, 199.71it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2770/3257 [00:17<00:02, 189.24it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2793/3257 [00:17<00:02, 198.26it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2814/3257 [00:17<00:02, 194.72it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2834/3257 [00:17<00:02, 183.95it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2856/3257 [00:17<00:02, 192.46it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2883/3257 [00:18<00:01, 213.38it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2905/3257 [00:18<00:01, 191.89it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:18<00:01, 195.14it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2948/3257 [00:18<00:01, 185.06it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2967/3257 [00:18<00:01, 186.02it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2986/3257 [00:18<00:01, 172.38it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3011/3257 [00:18<00:01, 189.87it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3031/3257 [00:18<00:01, 184.78it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3054/3257 [00:19<00:01, 195.83it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3076/3257 [00:19<00:00, 201.77it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3097/3257 [00:19<00:00, 196.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3122/3257 [00:19<00:00, 209.22it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3144/3257 [00:19<00:00, 193.08it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3164/3257 [00:19<00:00, 189.32it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3184/3257 [00:19<00:00, 178.96it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3205/3257 [00:19<00:00, 187.01it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3224/3257 [00:19<00:00, 178.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3246/3257 [00:20<00:00, 188.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 162.09it/s]
2023-02-07 20:44:22.528 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:44:22,530][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d244,n5,mc9,s0.790215,t4>', 'datetime': '2023-02-07T20:44:22.530266', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:44:22,530][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:44:22,530][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:44:23,109][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:44:23,109][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:44:23,157][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 14828 unique words (34.73% of original 42701, drops 27873)', 'datetime': '2023-02-07T20:44:23.157557', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:44:23,158][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 5723647 word corpus (98.29% of original 5822992, drops 99345)', 'datetime': '2023-02-07T20:44:23.158836', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:44:23,211][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:44:23,212][gensim.models.word2vec][INFO] - sample=0.790215 downsamples 0 most-common words
[2023-02-07 20:44:23,213][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5723647 word corpus (100.0%% of prior 5723647)', 'datetime': '2023-02-07T20:44:23.213054', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:44:23,306][gensim.models.word2vec][INFO] - estimated required memory for 14828 words and 244 dimensions: 40188488 bytes
[2023-02-07 20:44:23,307][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:44:23,325][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14828 vocabulary and 244 features, using sg=1 hs=0 sample=0.7902152137726521 negative=5 window=3 shrink_windows=True', 'datetime': '2023-02-07T20:44:23.325042', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:44:24,332][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 38.99% examples, 2258151 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:25,335][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 79.95% examples, 2293058 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:25,791][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5697932 effective words) took 2.5s, 2312402 effective words/s
[2023-02-07 20:44:26,796][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 46.61% examples, 2690692 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:27,807][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 93.74% examples, 2663647 words/s, in_qsize 6, out_qsize 3
[2023-02-07 20:44:27,927][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5697932 effective words) took 2.1s, 2669884 effective words/s
[2023-02-07 20:44:28,929][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 46.24% examples, 2678778 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:29,932][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 93.83% examples, 2678700 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:44:30,049][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5697932 effective words) took 2.1s, 2687914 effective words/s
[2023-02-07 20:44:31,055][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 46.76% examples, 2706523 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:32,056][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 97.08% examples, 2762757 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:32,111][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5697932 effective words) took 2.1s, 2767702 effective words/s
[2023-02-07 20:44:33,117][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 49.89% examples, 2885586 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:34,120][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 93.12% examples, 2658575 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:34,263][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5697932 effective words) took 2.2s, 2649100 effective words/s
[2023-02-07 20:44:35,268][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 41.48% examples, 2424514 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:36,271][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 84.59% examples, 2424667 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:36,616][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5697932 effective words) took 2.4s, 2423796 effective words/s
[2023-02-07 20:44:37,618][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 41.42% examples, 2421273 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:38,619][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 85.32% examples, 2453220 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:38,935][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5697932 effective words) took 2.3s, 2459357 effective words/s
[2023-02-07 20:44:39,939][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 42.43% examples, 2486574 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:40,941][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 86.95% examples, 2495819 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:41,219][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5697932 effective words) took 2.3s, 2497246 effective words/s
[2023-02-07 20:44:42,227][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 46.61% examples, 2681425 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:43,160][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5697932 effective words) took 1.9s, 2937690 effective words/s
[2023-02-07 20:44:44,164][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 49.09% examples, 2852794 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:45,166][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 99.75% examples, 2839146 words/s, in_qsize 1, out_qsize 1
[2023-02-07 20:44:45,166][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5697932 effective words) took 2.0s, 2843211 effective words/s
[2023-02-07 20:44:46,172][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 47.71% examples, 2770695 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:47,173][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 98.62% examples, 2807262 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:47,196][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5697932 effective words) took 2.0s, 2810064 effective words/s
[2023-02-07 20:44:48,201][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 48.45% examples, 2814761 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:49,207][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 98.89% examples, 2809638 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:49,222][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5697932 effective words) took 2.0s, 2815941 effective words/s
[2023-02-07 20:44:50,226][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 47.71% examples, 2769992 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:51,227][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 97.88% examples, 2787542 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:51,263][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5697932 effective words) took 2.0s, 2793178 effective words/s
[2023-02-07 20:44:52,266][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 47.90% examples, 2784301 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:53,266][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 98.89% examples, 2820279 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:53,279][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5697932 effective words) took 2.0s, 2828202 effective words/s
[2023-02-07 20:44:54,287][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 48.45% examples, 2804306 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:44:55,281][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5697932 effective words) took 2.0s, 2848472 effective words/s
[2023-02-07 20:44:55,282][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85468980 effective words) took 32.0s, 2674539 effective words/s', 'datetime': '2023-02-07T20:44:55.281975', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:44:55.282 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:44:58,671][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204353-4v1wghjb/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:44:58.671449', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:44:58,672][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:44:58,725][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204353-4v1wghjb/files/../tmp/embedding_model.pt
2023-02-07 20:44:58.726 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:45:00.631 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:45:01.323 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:45:03.105 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9875905180280027, 'test_mae': 0.7561636889364822, 'test_r2': -1.8751441830655544}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.014 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.87
wandb: percentage 0.65275
wandb:   test_mae 0.75616
wandb:   test_mse 0.98759
wandb:    test_r2 -1.87514
wandb: 
wandb: üöÄ View run magic-sweep-96 at: https://wandb.ai/xiaoqiz/mof2vec/runs/4v1wghjb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_204353-4v1wghjb/logs
wandb: Agent Starting Run: ohk98q33 with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 558
wandb: 	model.gensim.alpha: 0.02410904204929482
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 4
wandb: 	model.gensim.sample: 0.9927131235199472
wandb: 	model.gensim.vector_size: 425
wandb: 	model.gensim.window: 11
wandb: 	model.sklearn.learning_rate: 0.0013344260971080604
wandb: 	model.sklearn.max_depth: 51
wandb: 	model.sklearn.min_child_weight: 0.03491764615762766
wandb: 	model.sklearn.n_estimators: 1227
wandb: 	model.sklearn.num_leaves: 62
wandb: 	model.sklearn.reg_alpha: 0.03230288928665175
wandb: 	model.sklearn.reg_lambda: 0.007761368459711097
wandb: 	model.sklearn.subsample: 0.9495703876492336
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204512-ohk98q33
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-97
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/ohk98q33
2023-02-07 20:45:21.257 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 20:45:21.258 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 558 for sweep.
2023-02-07 20:45:21.258 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.02410904204929482 for sweep.
2023-02-07 20:45:21.259 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:45:21.259 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 4 for sweep.
2023-02-07 20:45:21.260 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9927131235199472 for sweep.
2023-02-07 20:45:21.260 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 425 for sweep.
2023-02-07 20:45:21.260 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 11 for sweep.
2023-02-07 20:45:21.260 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0013344260971080604 for sweep.
2023-02-07 20:45:21.261 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 51 for sweep.
2023-02-07 20:45:21.261 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.03491764615762766 for sweep.
2023-02-07 20:45:21.261 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1227 for sweep.
2023-02-07 20:45:21.261 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 62 for sweep.
2023-02-07 20:45:21.262 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.03230288928665175 for sweep.
2023-02-07 20:45:21.262 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.007761368459711097 for sweep.
2023-02-07 20:45:21.262 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9495703876492336 for sweep.
2023-02-07 20:45:21.262 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:45:21.273 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204512-ohk98q33/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 558, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 425, 'window': 11, 'min_count': 4, 'dm': 0, 'sample': 0.9927131235199472, 'workers': 4, 'alpha': 0.02410904204929482, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1227, 'max_depth': 51, 'num_leaves': 62, 'reg_alpha': 0.03230288928665175, 'reg_lambda': 0.007761368459711097, 'subsample': 0.9495703876492336, 'min_child_weight': 0.03491764615762766, 'n_jobs': 4, 'learning_rate': 0.0013344260971080604}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 15/3257 [00:00<00:22, 144.04it/s]  1%|          | 33/3257 [00:00<00:20, 160.34it/s]  2%|‚ñè         | 50/3257 [00:00<00:20, 157.13it/s]  2%|‚ñè         | 67/3257 [00:00<00:20, 158.38it/s]  3%|‚ñé         | 89/3257 [00:00<00:18, 174.48it/s]  3%|‚ñé         | 107/3257 [00:00<00:30, 104.18it/s]  4%|‚ñç         | 124/3257 [00:00<00:26, 116.98it/s]  4%|‚ñç         | 143/3257 [00:01<00:23, 132.92it/s]  5%|‚ñç         | 159/3257 [00:01<00:22, 135.79it/s]  5%|‚ñå         | 175/3257 [00:01<00:22, 137.31it/s]  6%|‚ñå         | 193/3257 [00:01<00:20, 146.71it/s]  6%|‚ñã         | 211/3257 [00:01<00:19, 153.74it/s]  7%|‚ñã         | 231/3257 [00:01<00:18, 164.20it/s]  8%|‚ñä         | 250/3257 [00:01<00:17, 167.86it/s]  8%|‚ñä         | 268/3257 [00:01<00:18, 162.96it/s]  9%|‚ñâ         | 291/3257 [00:01<00:16, 180.00it/s] 10%|‚ñâ         | 310/3257 [00:02<00:17, 172.76it/s] 10%|‚ñà         | 329/3257 [00:02<00:16, 174.92it/s] 11%|‚ñà         | 347/3257 [00:02<00:17, 166.69it/s] 11%|‚ñà         | 366/3257 [00:02<00:16, 171.70it/s] 12%|‚ñà‚ñè        | 384/3257 [00:02<00:17, 162.64it/s] 12%|‚ñà‚ñè        | 401/3257 [00:02<00:17, 161.83it/s] 13%|‚ñà‚ñé        | 418/3257 [00:02<00:17, 163.77it/s] 13%|‚ñà‚ñé        | 435/3257 [00:02<00:20, 136.68it/s] 14%|‚ñà‚ñç        | 452/3257 [00:02<00:19, 144.07it/s] 14%|‚ñà‚ñç        | 471/3257 [00:03<00:17, 155.88it/s] 15%|‚ñà‚ñç        | 488/3257 [00:03<00:17, 154.29it/s] 16%|‚ñà‚ñå        | 505/3257 [00:03<00:17, 158.24it/s] 16%|‚ñà‚ñå        | 523/3257 [00:03<00:16, 162.54it/s] 17%|‚ñà‚ñã        | 541/3257 [00:03<00:16, 166.11it/s] 17%|‚ñà‚ñã        | 558/3257 [00:03<00:16, 164.83it/s] 18%|‚ñà‚ñä        | 575/3257 [00:03<00:16, 161.31it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:14, 179.92it/s] 19%|‚ñà‚ñâ        | 620/3257 [00:03<00:14, 184.43it/s] 20%|‚ñà‚ñâ        | 642/3257 [00:04<00:13, 194.42it/s] 20%|‚ñà‚ñà        | 662/3257 [00:04<00:14, 181.75it/s] 21%|‚ñà‚ñà        | 683/3257 [00:04<00:13, 184.96it/s] 22%|‚ñà‚ñà‚ñè       | 704/3257 [00:04<00:13, 190.08it/s] 22%|‚ñà‚ñà‚ñè       | 724/3257 [00:04<00:13, 187.61it/s] 23%|‚ñà‚ñà‚ñé       | 743/3257 [00:04<00:13, 187.73it/s] 23%|‚ñà‚ñà‚ñé       | 764/3257 [00:04<00:12, 193.41it/s] 24%|‚ñà‚ñà‚ñç       | 784/3257 [00:04<00:13, 182.08it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:04<00:13, 186.84it/s] 25%|‚ñà‚ñà‚ñå       | 823/3257 [00:05<00:13, 177.87it/s] 26%|‚ñà‚ñà‚ñå       | 841/3257 [00:05<00:13, 173.78it/s] 26%|‚ñà‚ñà‚ñã       | 861/3257 [00:05<00:13, 179.15it/s] 27%|‚ñà‚ñà‚ñã       | 880/3257 [00:05<00:13, 176.64it/s] 28%|‚ñà‚ñà‚ñä       | 901/3257 [00:05<00:12, 185.99it/s] 28%|‚ñà‚ñà‚ñä       | 920/3257 [00:05<00:12, 186.26it/s] 29%|‚ñà‚ñà‚ñâ       | 939/3257 [00:05<00:12, 186.75it/s] 29%|‚ñà‚ñà‚ñâ       | 960/3257 [00:05<00:12, 191.26it/s] 30%|‚ñà‚ñà‚ñà       | 980/3257 [00:05<00:12, 185.56it/s] 31%|‚ñà‚ñà‚ñà       | 999/3257 [00:05<00:12, 182.08it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1019/3257 [00:06<00:12, 184.27it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1038/3257 [00:06<00:12, 172.90it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1056/3257 [00:06<00:12, 171.50it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1079/3257 [00:06<00:11, 187.04it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1098/3257 [00:06<00:12, 174.39it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1117/3257 [00:06<00:12, 176.77it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1135/3257 [00:06<00:12, 174.10it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1153/3257 [00:06<00:12, 172.65it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1173/3257 [00:06<00:11, 179.03it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:07<00:12, 162.60it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1208/3257 [00:07<00:12, 161.50it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:07<00:11, 180.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1251/3257 [00:07<00:11, 179.32it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:07<00:10, 183.77it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:07<00:11, 168.34it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:07<00:11, 169.86it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:07<00:11, 173.31it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1349/3257 [00:07<00:10, 182.03it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1368/3257 [00:08<00:10, 175.32it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:08<00:11, 169.93it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1404/3257 [00:08<00:16, 112.37it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1426/3257 [00:08<00:13, 134.03it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1446/3257 [00:08<00:12, 147.72it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1470/3257 [00:08<00:10, 169.81it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1490/3257 [00:08<00:10, 175.67it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1513/3257 [00:09<00:09, 187.51it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1533/3257 [00:09<00:09, 178.51it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1552/3257 [00:09<00:09, 175.98it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1572/3257 [00:09<00:09, 182.21it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:09<00:09, 183.04it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1615/3257 [00:09<00:08, 196.64it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1635/3257 [00:09<00:08, 186.98it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1654/3257 [00:09<00:08, 183.35it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1673/3257 [00:09<00:08, 177.05it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:10<00:09, 173.18it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1713/3257 [00:10<00:08, 184.79it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1732/3257 [00:10<00:08, 174.52it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1752/3257 [00:10<00:08, 178.32it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1772/3257 [00:10<00:08, 184.02it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1793/3257 [00:10<00:07, 190.15it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1813/3257 [00:10<00:07, 183.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1832/3257 [00:10<00:07, 179.72it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1853/3257 [00:10<00:07, 186.86it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1876/3257 [00:11<00:07, 196.20it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1896/3257 [00:11<00:07, 194.07it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1917/3257 [00:11<00:06, 195.81it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1941/3257 [00:11<00:06, 206.72it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1965/3257 [00:11<00:06, 211.95it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1987/3257 [00:11<00:06, 206.97it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2009/3257 [00:11<00:05, 208.69it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2032/3257 [00:11<00:05, 214.34it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2054/3257 [00:11<00:06, 193.48it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2074/3257 [00:11<00:06, 192.03it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2094/3257 [00:12<00:06, 192.92it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2114/3257 [00:12<00:05, 193.37it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2134/3257 [00:12<00:06, 180.26it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2153/3257 [00:12<00:06, 182.07it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2177/3257 [00:12<00:05, 194.54it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2198/3257 [00:12<00:05, 195.71it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2218/3257 [00:12<00:05, 190.49it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2238/3257 [00:12<00:05, 188.33it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2259/3257 [00:12<00:05, 192.32it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2279/3257 [00:13<00:05, 185.01it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2301/3257 [00:13<00:04, 193.14it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2325/3257 [00:13<00:04, 206.05it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2351/3257 [00:13<00:04, 221.04it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2374/3257 [00:13<00:04, 215.18it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:13<00:03, 224.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2422/3257 [00:13<00:03, 214.59it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2444/3257 [00:13<00:04, 201.86it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2469/3257 [00:13<00:03, 214.86it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2491/3257 [00:14<00:03, 215.28it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2518/3257 [00:14<00:03, 230.73it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2542/3257 [00:14<00:03, 227.33it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2565/3257 [00:14<00:03, 216.28it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2587/3257 [00:14<00:03, 204.69it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2615/3257 [00:14<00:02, 222.72it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2638/3257 [00:14<00:02, 214.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2660/3257 [00:14<00:03, 184.41it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2680/3257 [00:14<00:03, 185.60it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2700/3257 [00:15<00:03, 164.67it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2718/3257 [00:15<00:03, 161.76it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2740/3257 [00:15<00:02, 175.74it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2759/3257 [00:15<00:02, 175.79it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2777/3257 [00:15<00:02, 167.71it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2799/3257 [00:15<00:02, 181.15it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2818/3257 [00:16<00:04, 94.58it/s]  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2834/3257 [00:16<00:04, 105.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:16<00:03, 120.89it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2878/3257 [00:16<00:02, 148.30it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2897/3257 [00:16<00:02, 144.33it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2916/3257 [00:16<00:02, 152.69it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2934/3257 [00:16<00:02, 155.53it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2951/3257 [00:16<00:02, 150.40it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2969/3257 [00:17<00:01, 157.95it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2986/3257 [00:17<00:01, 152.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3008/3257 [00:17<00:01, 169.58it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3026/3257 [00:17<00:01, 166.21it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3047/3257 [00:17<00:01, 177.16it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3069/3257 [00:17<00:01, 186.88it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3088/3257 [00:17<00:00, 182.83it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3110/3257 [00:17<00:00, 192.56it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3130/3257 [00:17<00:00, 194.10it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3150/3257 [00:18<00:00, 178.63it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3169/3257 [00:18<00:00, 178.79it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3188/3257 [00:18<00:00, 172.82it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3207/3257 [00:18<00:00, 176.40it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3225/3257 [00:18<00:00, 173.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3246/3257 [00:18<00:00, 182.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:18<00:00, 175.04it/s]
2023-02-07 20:45:40.680 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:45:40,681][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d425,n5,mc4,s0.992713,t4>', 'datetime': '2023-02-07T20:45:40.681407', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:45:40,681][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:45:40,681][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:45:41,209][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 20:45:41,209][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:45:41,275][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 retains 21730 unique words (68.33% of original 31803, drops 10073)', 'datetime': '2023-02-07T20:45:41.275464', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:45:41,277][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=4 leaves 5078596 word corpus (99.68% of original 5095118, drops 16522)', 'datetime': '2023-02-07T20:45:41.277193', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:45:41,357][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 20:45:41,358][gensim.models.word2vec][INFO] - sample=0.992713 downsamples 0 most-common words
[2023-02-07 20:45:41,360][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5078596 word corpus (100.0%% of prior 5078596)', 'datetime': '2023-02-07T20:45:41.359977', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:45:41,497][gensim.models.word2vec][INFO] - estimated required memory for 21730 words and 425 dimensions: 90935300 bytes
[2023-02-07 20:45:41,498][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:45:41,548][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 21730 vocabulary and 425 features, using sg=1 hs=0 sample=0.9927131235199472 negative=5 window=11 shrink_windows=True', 'datetime': '2023-02-07T20:45:41.548543', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:45:42,554][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 31.01% examples, 1583111 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:43,555][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 63.92% examples, 1645204 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:44,559][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 98.56% examples, 1662877 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:44,586][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5070569 effective words) took 3.0s, 1670406 effective words/s
[2023-02-07 20:45:45,589][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 45.13% examples, 2330869 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:46,592][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 84.83% examples, 2165429 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:45:46,960][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5070569 effective words) took 2.4s, 2136720 effective words/s
[2023-02-07 20:45:47,966][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 38.47% examples, 1990199 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:48,969][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 78.39% examples, 2000004 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:49,493][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5070569 effective words) took 2.5s, 2003173 effective words/s
[2023-02-07 20:45:50,500][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 38.47% examples, 1988076 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:51,502][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 78.54% examples, 2004472 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:52,020][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5070569 effective words) took 2.5s, 2008263 effective words/s
[2023-02-07 20:45:53,023][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 39.51% examples, 2061810 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:54,030][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 81.24% examples, 2069352 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:54,461][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5070569 effective words) took 2.4s, 2079155 effective words/s
[2023-02-07 20:45:55,468][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 39.39% examples, 2045213 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:56,468][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 75.96% examples, 1947473 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:57,107][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5070569 effective words) took 2.6s, 1918454 effective words/s
[2023-02-07 20:45:58,110][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 36.11% examples, 1858240 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:59,116][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 72.52% examples, 1861852 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:45:59,831][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5070569 effective words) took 2.7s, 1862402 effective words/s
[2023-02-07 20:46:00,835][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 35.89% examples, 1840182 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:46:01,836][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 71.88% examples, 1853492 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:02,557][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5070569 effective words) took 2.7s, 1861936 effective words/s
[2023-02-07 20:46:03,567][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 36.44% examples, 1870371 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:04,569][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 78.66% examples, 2005164 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:05,002][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5070569 effective words) took 2.4s, 2075549 effective words/s
[2023-02-07 20:46:06,011][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 42.40% examples, 2200478 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:07,012][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 84.99% examples, 2167125 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:07,347][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5070569 effective words) took 2.3s, 2164288 effective words/s
[2023-02-07 20:46:08,350][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 40.07% examples, 2088625 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:09,352][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 82.47% examples, 2103389 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:09,751][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5070569 effective words) took 2.4s, 2111157 effective words/s
[2023-02-07 20:46:10,754][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 40.71% examples, 2118955 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:11,758][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 82.84% examples, 2118000 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:12,147][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5070569 effective words) took 2.4s, 2118525 effective words/s
[2023-02-07 20:46:13,154][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 41.08% examples, 2131118 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:46:14,159][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 84.28% examples, 2147117 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:46:14,535][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5070569 effective words) took 2.4s, 2126354 effective words/s
[2023-02-07 20:46:15,550][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 35.89% examples, 1821904 words/s, in_qsize 6, out_qsize 1
[2023-02-07 20:46:16,550][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 71.88% examples, 1844769 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:46:17,289][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5070569 effective words) took 2.8s, 1843273 effective words/s
[2023-02-07 20:46:18,295][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 36.11% examples, 1855070 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:46:19,298][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 71.88% examples, 1849855 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:46:20,031][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5070569 effective words) took 2.7s, 1851039 effective words/s
[2023-02-07 20:46:20,031][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (76058535 effective words) took 38.5s, 1976443 effective words/s', 'datetime': '2023-02-07T20:46:20.031590', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:46:20.031 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:46:23,791][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204512-ohk98q33/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:46:23.791251', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:46:23,792][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:46:23,891][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204512-ohk98q33/files/../tmp/embedding_model.pt
2023-02-07 20:46:23.891 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:46:26.106 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:46:26.904 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:46:29.714 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.976096650626104, 'test_mae': 0.738107770544254, 'test_r2': -2.0818715975923805}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.92
wandb: percentage 0.31673
wandb:   test_mae 0.73811
wandb:   test_mse 0.9761
wandb:    test_r2 -2.08187
wandb: 
wandb: üöÄ View run splendid-sweep-97 at: https://wandb.ai/xiaoqiz/mof2vec/runs/ohk98q33
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_204512-ohk98q33/logs
wandb: Agent Starting Run: lsc35qiz with config:
wandb: 	data.data.wl_step: 6
wandb: 	data.nn.batch_size: 853
wandb: 	model.gensim.alpha: 0.004745462058118724
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 9
wandb: 	model.gensim.sample: 0.8499639485563333
wandb: 	model.gensim.vector_size: 472
wandb: 	model.gensim.window: 12
wandb: 	model.sklearn.learning_rate: 0.0004812274995678037
wandb: 	model.sklearn.max_depth: 25
wandb: 	model.sklearn.min_child_weight: 0.030817712967057605
wandb: 	model.sklearn.n_estimators: 1265
wandb: 	model.sklearn.num_leaves: 207
wandb: 	model.sklearn.reg_alpha: 0.06107023835650192
wandb: 	model.sklearn.reg_lambda: 0.026230989658969774
wandb: 	model.sklearn.subsample: 0.9776878790106696
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204642-lsc35qiz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-98
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/lsc35qiz
2023-02-07 20:46:50.754 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 6 for sweep.
2023-02-07 20:46:50.755 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 853 for sweep.
2023-02-07 20:46:50.756 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.004745462058118724 for sweep.
2023-02-07 20:46:50.756 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:46:50.756 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 9 for sweep.
2023-02-07 20:46:50.756 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8499639485563333 for sweep.
2023-02-07 20:46:50.757 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 472 for sweep.
2023-02-07 20:46:50.757 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 12 for sweep.
2023-02-07 20:46:50.757 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0004812274995678037 for sweep.
2023-02-07 20:46:50.757 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 25 for sweep.
2023-02-07 20:46:50.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.030817712967057605 for sweep.
2023-02-07 20:46:50.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1265 for sweep.
2023-02-07 20:46:50.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 207 for sweep.
2023-02-07 20:46:50.758 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.06107023835650192 for sweep.
2023-02-07 20:46:50.759 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.026230989658969774 for sweep.
2023-02-07 20:46:50.759 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.9776878790106696 for sweep.
2023-02-07 20:46:50.759 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:46:50.771 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 6}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204642-lsc35qiz/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 853, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 472, 'window': 12, 'min_count': 9, 'dm': 0, 'sample': 0.8499639485563333, 'workers': 4, 'alpha': 0.004745462058118724, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1265, 'max_depth': 25, 'num_leaves': 207, 'reg_alpha': 0.06107023835650192, 'reg_lambda': 0.026230989658969774, 'subsample': 0.9776878790106696, 'min_child_weight': 0.030817712967057605, 'n_jobs': 4, 'learning_rate': 0.0004812274995678037}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 13/3257 [00:00<00:25, 129.53it/s]  1%|          | 29/3257 [00:00<00:22, 145.97it/s]  1%|‚ñè         | 44/3257 [00:00<00:22, 145.53it/s]  2%|‚ñè         | 59/3257 [00:00<00:22, 139.28it/s]  2%|‚ñè         | 76/3257 [00:00<00:21, 149.35it/s]  3%|‚ñé         | 92/3257 [00:00<00:20, 151.56it/s]  3%|‚ñé         | 108/3257 [00:00<00:21, 143.36it/s]  4%|‚ñç         | 123/3257 [00:00<00:21, 144.61it/s]  4%|‚ñç         | 139/3257 [00:00<00:21, 147.74it/s]  5%|‚ñç         | 155/3257 [00:01<00:20, 150.51it/s]  5%|‚ñå         | 171/3257 [00:01<00:21, 145.87it/s]  6%|‚ñå         | 186/3257 [00:01<00:21, 145.88it/s]  6%|‚ñå         | 201/3257 [00:01<00:20, 145.90it/s]  7%|‚ñã         | 219/3257 [00:01<00:19, 155.04it/s]  7%|‚ñã         | 237/3257 [00:01<00:18, 161.39it/s]  8%|‚ñä         | 254/3257 [00:01<00:18, 162.97it/s]  8%|‚ñä         | 271/3257 [00:01<00:19, 156.47it/s]  9%|‚ñâ         | 291/3257 [00:01<00:17, 166.00it/s]  9%|‚ñâ         | 308/3257 [00:02<00:18, 160.71it/s] 10%|‚ñà         | 326/3257 [00:02<00:17, 164.58it/s] 11%|‚ñà         | 343/3257 [00:02<00:18, 155.77it/s] 11%|‚ñà         | 360/3257 [00:02<00:18, 159.01it/s] 12%|‚ñà‚ñè        | 377/3257 [00:02<00:18, 152.03it/s] 12%|‚ñà‚ñè        | 393/3257 [00:02<00:19, 150.15it/s] 13%|‚ñà‚ñé        | 411/3257 [00:02<00:18, 155.05it/s] 13%|‚ñà‚ñé        | 427/3257 [00:02<00:20, 136.80it/s] 14%|‚ñà‚ñé        | 442/3257 [00:02<00:20, 138.47it/s] 14%|‚ñà‚ñç        | 458/3257 [00:03<00:19, 144.16it/s] 15%|‚ñà‚ñç        | 475/3257 [00:03<00:18, 147.72it/s] 15%|‚ñà‚ñå        | 491/3257 [00:03<00:18, 149.00it/s] 16%|‚ñà‚ñå        | 510/3257 [00:03<00:17, 158.24it/s] 16%|‚ñà‚ñå        | 526/3257 [00:03<00:18, 149.77it/s] 17%|‚ñà‚ñã        | 544/3257 [00:03<00:17, 156.13it/s] 17%|‚ñà‚ñã        | 560/3257 [00:03<00:18, 143.24it/s] 18%|‚ñà‚ñä        | 575/3257 [00:03<00:19, 138.07it/s] 18%|‚ñà‚ñä        | 591/3257 [00:03<00:18, 143.76it/s] 19%|‚ñà‚ñä        | 606/3257 [00:04<00:18, 144.37it/s] 19%|‚ñà‚ñâ        | 621/3257 [00:04<00:18, 145.71it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:04<00:17, 153.43it/s] 20%|‚ñà‚ñà        | 655/3257 [00:04<00:18, 142.32it/s] 21%|‚ñà‚ñà        | 670/3257 [00:04<00:18, 143.47it/s] 21%|‚ñà‚ñà        | 685/3257 [00:04<00:18, 138.08it/s] 21%|‚ñà‚ñà‚ñè       | 700/3257 [00:04<00:18, 138.36it/s] 22%|‚ñà‚ñà‚ñè       | 718/3257 [00:04<00:17, 149.15it/s] 23%|‚ñà‚ñà‚ñé       | 734/3257 [00:04<00:17, 143.23it/s] 23%|‚ñà‚ñà‚ñé       | 749/3257 [00:05<00:18, 137.63it/s] 24%|‚ñà‚ñà‚ñé       | 768/3257 [00:05<00:16, 150.22it/s] 24%|‚ñà‚ñà‚ñç       | 784/3257 [00:05<00:27, 91.03it/s]  25%|‚ñà‚ñà‚ñç       | 802/3257 [00:05<00:22, 107.53it/s] 25%|‚ñà‚ñà‚ñå       | 816/3257 [00:05<00:21, 113.42it/s] 25%|‚ñà‚ñà‚ñå       | 830/3257 [00:05<00:20, 116.75it/s] 26%|‚ñà‚ñà‚ñå       | 844/3257 [00:05<00:20, 118.43it/s] 26%|‚ñà‚ñà‚ñã       | 859/3257 [00:06<00:19, 124.12it/s] 27%|‚ñà‚ñà‚ñã       | 874/3257 [00:06<00:18, 129.62it/s] 27%|‚ñà‚ñà‚ñã       | 889/3257 [00:06<00:17, 132.99it/s] 28%|‚ñà‚ñà‚ñä       | 906/3257 [00:06<00:16, 140.48it/s] 28%|‚ñà‚ñà‚ñä       | 924/3257 [00:06<00:15, 149.96it/s] 29%|‚ñà‚ñà‚ñâ       | 940/3257 [00:06<00:15, 144.97it/s] 29%|‚ñà‚ñà‚ñâ       | 957/3257 [00:06<00:15, 148.96it/s] 30%|‚ñà‚ñà‚ñâ       | 973/3257 [00:06<00:15, 145.88it/s] 30%|‚ñà‚ñà‚ñà       | 988/3257 [00:06<00:16, 141.32it/s] 31%|‚ñà‚ñà‚ñà       | 1003/3257 [00:07<00:15, 141.31it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1018/3257 [00:07<00:15, 143.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1033/3257 [00:07<00:16, 134.44it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1047/3257 [00:07<00:16, 133.76it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1062/3257 [00:07<00:15, 137.82it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1080/3257 [00:07<00:15, 139.23it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1094/3257 [00:07<00:15, 138.18it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1112/3257 [00:07<00:14, 148.11it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1127/3257 [00:07<00:14, 142.17it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1142/3257 [00:08<00:14, 141.83it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1158/3257 [00:08<00:14, 146.26it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1176/3257 [00:08<00:13, 155.43it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1192/3257 [00:08<00:13, 152.84it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1208/3257 [00:08<00:13, 154.21it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1232/3257 [00:08<00:11, 176.01it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1250/3257 [00:08<00:11, 174.32it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:08<00:10, 181.28it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1290/3257 [00:08<00:11, 170.94it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1309/3257 [00:08<00:11, 171.16it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:09<00:10, 175.61it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1350/3257 [00:09<00:10, 180.44it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1370/3257 [00:09<00:10, 181.44it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1389/3257 [00:09<00:10, 174.36it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1413/3257 [00:09<00:09, 191.38it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1435/3257 [00:09<00:09, 196.46it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1460/3257 [00:09<00:08, 207.98it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1481/3257 [00:09<00:08, 205.18it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1502/3257 [00:09<00:08, 206.49it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1523/3257 [00:10<00:09, 189.12it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1543/3257 [00:10<00:09, 185.41it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1562/3257 [00:10<00:09, 177.11it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1580/3257 [00:10<00:09, 176.59it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1599/3257 [00:10<00:09, 179.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1619/3257 [00:10<00:09, 180.64it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1638/3257 [00:10<00:09, 176.75it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1656/3257 [00:10<00:09, 174.50it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1674/3257 [00:10<00:09, 164.99it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1691/3257 [00:11<00:09, 165.77it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1712/3257 [00:11<00:08, 178.18it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1730/3257 [00:11<00:09, 169.10it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1749/3257 [00:11<00:08, 173.95it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1769/3257 [00:11<00:08, 180.40it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1790/3257 [00:11<00:07, 187.78it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1809/3257 [00:11<00:08, 176.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1828/3257 [00:11<00:07, 178.90it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1849/3257 [00:11<00:07, 184.25it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1872/3257 [00:12<00:07, 195.10it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1892/3257 [00:12<00:07, 189.07it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1916/3257 [00:12<00:06, 194.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1938/3257 [00:12<00:06, 200.97it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1964/3257 [00:12<00:05, 216.93it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1986/3257 [00:12<00:06, 200.28it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2007/3257 [00:12<00:06, 199.80it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2029/3257 [00:12<00:06, 203.18it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2050/3257 [00:12<00:06, 185.65it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2069/3257 [00:13<00:06, 182.45it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2090/3257 [00:13<00:06, 189.35it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2110/3257 [00:13<00:06, 185.33it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2129/3257 [00:13<00:10, 106.42it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2147/3257 [00:13<00:09, 119.75it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2171/3257 [00:13<00:07, 144.46it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2190/3257 [00:13<00:07, 152.40it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2209/3257 [00:14<00:06, 157.36it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2229/3257 [00:14<00:06, 167.71it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2248/3257 [00:14<00:05, 169.00it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2267/3257 [00:14<00:05, 173.86it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2287/3257 [00:14<00:05, 181.07it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2306/3257 [00:14<00:05, 176.84it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2330/3257 [00:14<00:04, 191.66it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2354/3257 [00:14<00:04, 203.72it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2375/3257 [00:14<00:04, 198.07it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2399/3257 [00:15<00:04, 207.06it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2420/3257 [00:15<00:04, 196.73it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2440/3257 [00:15<00:04, 192.04it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2461/3257 [00:15<00:04, 195.24it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2482/3257 [00:15<00:03, 199.19it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2507/3257 [00:15<00:03, 208.50it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2529/3257 [00:15<00:03, 210.01it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2551/3257 [00:15<00:03, 207.03it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2572/3257 [00:15<00:03, 188.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2592/3257 [00:16<00:03, 186.72it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2620/3257 [00:16<00:03, 211.46it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2642/3257 [00:16<00:02, 210.79it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2664/3257 [00:16<00:02, 200.83it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2687/3257 [00:16<00:02, 206.47it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2708/3257 [00:16<00:02, 186.25it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2729/3257 [00:16<00:02, 192.38it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2751/3257 [00:16<00:02, 198.56it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2772/3257 [00:16<00:02, 191.36it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2795/3257 [00:17<00:02, 201.94it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2816/3257 [00:17<00:02, 181.22it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2835/3257 [00:17<00:02, 170.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2853/3257 [00:17<00:02, 172.44it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2876/3257 [00:17<00:02, 186.84it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2896/3257 [00:17<00:02, 167.48it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2915/3257 [00:17<00:02, 170.70it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2933/3257 [00:17<00:01, 164.65it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2950/3257 [00:17<00:01, 156.51it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2968/3257 [00:18<00:01, 162.05it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:18<00:01, 151.81it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3004/3257 [00:18<00:01, 158.31it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3021/3257 [00:18<00:01, 158.73it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3040/3257 [00:18<00:01, 167.21it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3061/3257 [00:18<00:01, 177.79it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3080/3257 [00:18<00:00, 178.76it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3099/3257 [00:18<00:00, 174.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3118/3257 [00:18<00:00, 178.72it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3136/3257 [00:19<00:00, 169.08it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3154/3257 [00:19<00:00, 158.87it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3171/3257 [00:19<00:00, 160.58it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3188/3257 [00:19<00:00, 155.03it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3206/3257 [00:19<00:00, 161.81it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3223/3257 [00:19<00:00, 155.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3243/3257 [00:19<00:00, 166.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:19<00:00, 164.11it/s]
2023-02-07 20:47:11.466 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:47:11,467][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d472,n5,mc9,s0.849964,t4>', 'datetime': '2023-02-07T20:47:11.467613', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:47:11,468][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:47:11,468][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:47:12,005][gensim.models.doc2vec][INFO] - collected 31803 word types and 3257 unique tags from a corpus of 3257 examples and 5095118 words
[2023-02-07 20:47:12,006][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:47:12,045][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 11387 unique words (35.80% of original 31803, drops 20416)', 'datetime': '2023-02-07T20:47:12.045936', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:47:12,046][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 5023141 word corpus (98.59% of original 5095118, drops 71977)', 'datetime': '2023-02-07T20:47:12.046406', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:47:12,087][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 31803 items
[2023-02-07 20:47:12,089][gensim.models.word2vec][INFO] - sample=0.849964 downsamples 0 most-common words
[2023-02-07 20:47:12,089][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5023141 word corpus (100.0%% of prior 5023141)', 'datetime': '2023-02-07T20:47:12.089371', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:47:12,161][gensim.models.word2vec][INFO] - estimated required memory for 11387 words and 472 dimensions: 55491428 bytes
[2023-02-07 20:47:12,161][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:47:12,195][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 11387 vocabulary and 472 features, using sg=1 hs=0 sample=0.8499639485563333 negative=5 window=12 shrink_windows=True', 'datetime': '2023-02-07T20:47:12.195277', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:47:13,204][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 27.82% examples, 1395573 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:14,205][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 55.23% examples, 1412317 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:15,217][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 84.99% examples, 1425845 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:15,698][gensim.models.word2vec][INFO] - EPOCH 0: training on 5095118 raw words (5015324 effective words) took 3.5s, 1433268 effective words/s
[2023-02-07 20:47:16,702][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 33.34% examples, 1684324 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:47:17,708][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 74.06% examples, 1878772 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:18,306][gensim.models.word2vec][INFO] - EPOCH 1: training on 5095118 raw words (5015324 effective words) took 2.6s, 1926165 effective words/s
[2023-02-07 20:47:19,309][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 40.07% examples, 2068129 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:20,310][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 79.12% examples, 2005075 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:20,851][gensim.models.word2vec][INFO] - EPOCH 2: training on 5095118 raw words (5015324 effective words) took 2.5s, 1972091 effective words/s
[2023-02-07 20:47:21,858][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 36.32% examples, 1849610 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:22,865][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 72.21% examples, 1829859 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:23,583][gensim.models.word2vec][INFO] - EPOCH 3: training on 5095118 raw words (5015324 effective words) took 2.7s, 1837424 effective words/s
[2023-02-07 20:47:24,586][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 36.48% examples, 1872550 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:47:25,592][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 74.06% examples, 1878179 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:26,265][gensim.models.word2vec][INFO] - EPOCH 4: training on 5095118 raw words (5015324 effective words) took 2.7s, 1871698 effective words/s
[2023-02-07 20:47:27,271][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 36.91% examples, 1893938 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:28,271][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 75.13% examples, 1910068 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:28,882][gensim.models.word2vec][INFO] - EPOCH 5: training on 5095118 raw words (5015324 effective words) took 2.6s, 1918085 effective words/s
[2023-02-07 20:47:29,885][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 36.44% examples, 1864414 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:30,887][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 74.64% examples, 1899080 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:31,521][gensim.models.word2vec][INFO] - EPOCH 6: training on 5095118 raw words (5015324 effective words) took 2.6s, 1902358 effective words/s
[2023-02-07 20:47:32,529][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 36.91% examples, 1887605 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:33,533][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 74.79% examples, 1894841 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:47:34,166][gensim.models.word2vec][INFO] - EPOCH 7: training on 5095118 raw words (5015324 effective words) took 2.6s, 1897159 effective words/s
[2023-02-07 20:47:35,175][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 37.64% examples, 1921221 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:36,178][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 76.54% examples, 1934891 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:47:36,756][gensim.models.word2vec][INFO] - EPOCH 8: training on 5095118 raw words (5015324 effective words) took 2.6s, 1937436 effective words/s
[2023-02-07 20:47:37,764][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 36.91% examples, 1888591 words/s, in_qsize 7, out_qsize 1
[2023-02-07 20:47:38,770][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 75.01% examples, 1898354 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:47:39,388][gensim.models.word2vec][INFO] - EPOCH 9: training on 5095118 raw words (5015324 effective words) took 2.6s, 1907481 effective words/s
[2023-02-07 20:47:40,392][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 38.16% examples, 1954098 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:41,393][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 77.31% examples, 1955477 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:47:41,948][gensim.models.word2vec][INFO] - EPOCH 10: training on 5095118 raw words (5015324 effective words) took 2.6s, 1959880 effective words/s
[2023-02-07 20:47:42,954][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 36.97% examples, 1894449 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:43,955][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 75.01% examples, 1905671 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:47:44,576][gensim.models.word2vec][INFO] - EPOCH 11: training on 5095118 raw words (5015324 effective words) took 2.6s, 1910669 effective words/s
[2023-02-07 20:47:45,580][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 37.86% examples, 1939687 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:46,591][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 77.06% examples, 1942029 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:47,155][gensim.models.word2vec][INFO] - EPOCH 12: training on 5095118 raw words (5015324 effective words) took 2.6s, 1946581 effective words/s
[2023-02-07 20:47:48,164][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 37.64% examples, 1922154 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:49,170][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 71.88% examples, 1823958 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:47:49,938][gensim.models.word2vec][INFO] - EPOCH 13: training on 5095118 raw words (5015324 effective words) took 2.8s, 1803648 effective words/s
[2023-02-07 20:47:50,947][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 33.83% examples, 1707471 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:47:51,950][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 67.79% examples, 1727647 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:47:52,850][gensim.models.word2vec][INFO] - EPOCH 14: training on 5095118 raw words (5015324 effective words) took 2.9s, 1723808 effective words/s
[2023-02-07 20:47:52,850][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 76426770 raw words (75229860 effective words) took 40.7s, 1850441 effective words/s', 'datetime': '2023-02-07T20:47:52.850907', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:47:52.851 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:47:56,922][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204642-lsc35qiz/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:47:56.921955', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:47:56,923][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:47:56,995][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204642-lsc35qiz/files/../tmp/embedding_model.pt
2023-02-07 20:47:56.995 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:47:59.089 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:47:59.851 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:48:02.860 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9875537752518934, 'test_mae': 0.7627533181039102, 'test_r2': -1.8283489168695608}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.030 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.77
wandb: percentage 0.64195
wandb:   test_mae 0.76275
wandb:   test_mse 0.98755
wandb:    test_r2 -1.82835
wandb: 
wandb: üöÄ View run balmy-sweep-98 at: https://wandb.ai/xiaoqiz/mof2vec/runs/lsc35qiz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_204642-lsc35qiz/logs
wandb: Agent Starting Run: jymsvvkw with config:
wandb: 	data.data.wl_step: 5
wandb: 	data.nn.batch_size: 978
wandb: 	model.gensim.alpha: 0.11387874419565654
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 7
wandb: 	model.gensim.sample: 0.9532771072923014
wandb: 	model.gensim.vector_size: 355
wandb: 	model.gensim.window: 2
wandb: 	model.sklearn.learning_rate: 0.0016404248425858036
wandb: 	model.sklearn.max_depth: 8
wandb: 	model.sklearn.min_child_weight: 0.016562252446872074
wandb: 	model.sklearn.n_estimators: 873
wandb: 	model.sklearn.num_leaves: 431
wandb: 	model.sklearn.reg_alpha: 0.002536759193796324
wandb: 	model.sklearn.reg_lambda: 0.07145827250160416
wandb: 	model.sklearn.subsample: 0.8172760607029723
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204812-jymsvvkw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-99
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/jymsvvkw
2023-02-07 20:48:21.132 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 5 for sweep.
2023-02-07 20:48:21.133 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 978 for sweep.
2023-02-07 20:48:21.133 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.11387874419565654 for sweep.
2023-02-07 20:48:21.133 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:48:21.134 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 7 for sweep.
2023-02-07 20:48:21.134 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.9532771072923014 for sweep.
2023-02-07 20:48:21.134 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 355 for sweep.
2023-02-07 20:48:21.134 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 2 for sweep.
2023-02-07 20:48:21.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.0016404248425858036 for sweep.
2023-02-07 20:48:21.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 8 for sweep.
2023-02-07 20:48:21.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.016562252446872074 for sweep.
2023-02-07 20:48:21.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 873 for sweep.
2023-02-07 20:48:21.135 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 431 for sweep.
2023-02-07 20:48:21.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.002536759193796324 for sweep.
2023-02-07 20:48:21.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.07145827250160416 for sweep.
2023-02-07 20:48:21.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.8172760607029723 for sweep.
2023-02-07 20:48:21.136 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:48:21.143 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 5}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204812-jymsvvkw/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 978, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 355, 'window': 2, 'min_count': 7, 'dm': 0, 'sample': 0.9532771072923014, 'workers': 4, 'alpha': 0.11387874419565654, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 873, 'max_depth': 8, 'num_leaves': 431, 'reg_alpha': 0.002536759193796324, 'reg_lambda': 0.07145827250160416, 'subsample': 0.8172760607029723, 'min_child_weight': 0.016562252446872074, 'n_jobs': 4, 'learning_rate': 0.0016404248425858036}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  1%|          | 21/3257 [00:00<00:15, 206.24it/s]  1%|‚ñè         | 43/3257 [00:00<00:15, 214.01it/s]  2%|‚ñè         | 66/3257 [00:00<00:14, 218.42it/s]  3%|‚ñé         | 89/3257 [00:00<00:14, 222.73it/s]  3%|‚ñé         | 112/3257 [00:00<00:15, 205.59it/s]  4%|‚ñç         | 133/3257 [00:00<00:15, 203.68it/s]  5%|‚ñç         | 154/3257 [00:00<00:15, 201.36it/s]  5%|‚ñå         | 175/3257 [00:00<00:16, 190.35it/s]  6%|‚ñå         | 195/3257 [00:00<00:15, 192.57it/s]  7%|‚ñã         | 216/3257 [00:01<00:15, 195.79it/s]  7%|‚ñã         | 237/3257 [00:01<00:15, 198.60it/s]  8%|‚ñä         | 258/3257 [00:01<00:14, 200.43it/s]  9%|‚ñä         | 280/3257 [00:01<00:14, 205.70it/s]  9%|‚ñâ         | 301/3257 [00:01<00:15, 196.63it/s] 10%|‚ñâ         | 323/3257 [00:01<00:14, 202.88it/s] 11%|‚ñà         | 344/3257 [00:01<00:15, 189.47it/s] 11%|‚ñà         | 365/3257 [00:01<00:14, 194.28it/s] 12%|‚ñà‚ñè        | 385/3257 [00:01<00:15, 185.74it/s] 12%|‚ñà‚ñè        | 404/3257 [00:02<00:15, 183.68it/s] 13%|‚ñà‚ñé        | 423/3257 [00:02<00:22, 123.61it/s] 13%|‚ñà‚ñé        | 438/3257 [00:02<00:23, 122.33it/s] 14%|‚ñà‚ñç        | 457/3257 [00:02<00:20, 137.19it/s] 15%|‚ñà‚ñç        | 476/3257 [00:02<00:18, 149.21it/s] 15%|‚ñà‚ñå        | 497/3257 [00:02<00:16, 163.96it/s] 16%|‚ñà‚ñå        | 517/3257 [00:02<00:15, 172.96it/s] 16%|‚ñà‚ñã        | 536/3257 [00:02<00:15, 174.14it/s] 17%|‚ñà‚ñã        | 556/3257 [00:03<00:15, 178.74it/s] 18%|‚ñà‚ñä        | 575/3257 [00:03<00:16, 160.31it/s] 18%|‚ñà‚ñä        | 597/3257 [00:03<00:15, 174.76it/s] 19%|‚ñà‚ñâ        | 619/3257 [00:03<00:14, 185.28it/s] 20%|‚ñà‚ñâ        | 639/3257 [00:03<00:14, 181.56it/s] 20%|‚ñà‚ñà        | 658/3257 [00:03<00:15, 170.71it/s] 21%|‚ñà‚ñà        | 678/3257 [00:03<00:14, 178.33it/s] 21%|‚ñà‚ñà‚ñè       | 697/3257 [00:03<00:14, 177.13it/s] 22%|‚ñà‚ñà‚ñè       | 721/3257 [00:03<00:13, 193.54it/s] 23%|‚ñà‚ñà‚ñé       | 741/3257 [00:04<00:13, 191.21it/s] 24%|‚ñà‚ñà‚ñé       | 769/3257 [00:04<00:11, 216.12it/s] 24%|‚ñà‚ñà‚ñç       | 791/3257 [00:04<00:11, 214.43it/s] 25%|‚ñà‚ñà‚ñå       | 815/3257 [00:04<00:11, 221.16it/s] 26%|‚ñà‚ñà‚ñå       | 838/3257 [00:04<00:11, 217.55it/s] 26%|‚ñà‚ñà‚ñã       | 860/3257 [00:04<00:11, 214.04it/s] 27%|‚ñà‚ñà‚ñã       | 882/3257 [00:04<00:11, 214.15it/s] 28%|‚ñà‚ñà‚ñä       | 906/3257 [00:04<00:10, 217.63it/s] 29%|‚ñà‚ñà‚ñä       | 930/3257 [00:04<00:10, 223.61it/s] 29%|‚ñà‚ñà‚ñâ       | 953/3257 [00:05<00:10, 219.95it/s] 30%|‚ñà‚ñà‚ñâ       | 976/3257 [00:05<00:10, 217.55it/s] 31%|‚ñà‚ñà‚ñà       | 998/3257 [00:05<00:10, 208.08it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1021/3257 [00:05<00:10, 212.15it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1043/3257 [00:05<00:11, 195.38it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1064/3257 [00:05<00:11, 198.25it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1085/3257 [00:05<00:10, 197.76it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1105/3257 [00:05<00:10, 197.45it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1125/3257 [00:05<00:10, 197.96it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1145/3257 [00:06<00:11, 191.70it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1170/3257 [00:06<00:10, 203.85it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1191/3257 [00:06<00:10, 189.77it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1211/3257 [00:06<00:11, 185.48it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1236/3257 [00:06<00:09, 202.23it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 1257/3257 [00:06<00:09, 201.34it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1278/3257 [00:06<00:10, 190.48it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1298/3257 [00:06<00:11, 177.32it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1317/3257 [00:06<00:10, 178.60it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1337/3257 [00:07<00:10, 183.95it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1356/3257 [00:07<00:10, 173.78it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1374/3257 [00:07<00:11, 171.11it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1392/3257 [00:07<00:10, 170.89it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1412/3257 [00:07<00:10, 177.02it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1432/3257 [00:07<00:10, 181.65it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1453/3257 [00:07<00:09, 187.39it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1475/3257 [00:07<00:09, 194.56it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1495/3257 [00:07<00:09, 191.95it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1515/3257 [00:08<00:08, 193.64it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1535/3257 [00:08<00:09, 172.84it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1553/3257 [00:08<00:10, 168.22it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1573/3257 [00:08<00:09, 175.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1591/3257 [00:08<00:09, 169.55it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1612/3257 [00:08<00:09, 178.56it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1632/3257 [00:08<00:08, 184.38it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1651/3257 [00:09<00:15, 105.39it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1668/3257 [00:09<00:13, 116.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1685/3257 [00:09<00:12, 125.63it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1704/3257 [00:09<00:11, 139.00it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1723/3257 [00:09<00:10, 151.06it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1740/3257 [00:09<00:10, 144.88it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1759/3257 [00:09<00:09, 156.38it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1777/3257 [00:09<00:09, 162.62it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1796/3257 [00:09<00:08, 167.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1814/3257 [00:10<00:08, 169.55it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1838/3257 [00:10<00:07, 187.46it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1860/3257 [00:10<00:07, 196.59it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1884/3257 [00:10<00:06, 208.60it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1908/3257 [00:10<00:06, 217.10it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1930/3257 [00:10<00:06, 215.75it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1961/3257 [00:10<00:05, 243.30it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1986/3257 [00:10<00:05, 231.01it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2011/3257 [00:10<00:05, 235.68it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2036/3257 [00:10<00:05, 236.80it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2060/3257 [00:11<00:05, 212.45it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2086/3257 [00:11<00:05, 223.35it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2109/3257 [00:11<00:05, 223.67it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2132/3257 [00:11<00:05, 212.76it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2154/3257 [00:11<00:05, 211.14it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2178/3257 [00:11<00:05, 215.77it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2201/3257 [00:11<00:04, 219.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2224/3257 [00:11<00:04, 215.04it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2246/3257 [00:11<00:04, 210.54it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2269/3257 [00:12<00:04, 215.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2293/3257 [00:12<00:04, 221.34it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2316/3257 [00:12<00:04, 223.21it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2346/3257 [00:12<00:03, 245.33it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2371/3257 [00:12<00:03, 246.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2397/3257 [00:12<00:03, 250.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2423/3257 [00:12<00:03, 233.79it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2447/3257 [00:12<00:03, 223.02it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2474/3257 [00:12<00:03, 233.23it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2499/3257 [00:13<00:03, 237.59it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2524/3257 [00:13<00:03, 240.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2549/3257 [00:13<00:02, 237.88it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2573/3257 [00:13<00:03, 217.63it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2596/3257 [00:13<00:03, 216.75it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2627/3257 [00:13<00:02, 241.35it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2652/3257 [00:13<00:02, 212.44it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2675/3257 [00:13<00:02, 214.69it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2698/3257 [00:13<00:02, 205.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2720/3257 [00:14<00:02, 203.59it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2749/3257 [00:14<00:02, 226.33it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2773/3257 [00:14<00:02, 219.19it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2801/3257 [00:14<00:01, 234.44it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2825/3257 [00:14<00:01, 217.83it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2848/3257 [00:14<00:01, 220.73it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2879/3257 [00:14<00:01, 245.17it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2904/3257 [00:14<00:01, 223.31it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2929/3257 [00:14<00:01, 228.48it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2953/3257 [00:15<00:01, 218.86it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2976/3257 [00:15<00:01, 220.38it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3001/3257 [00:15<00:01, 227.70it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3025/3257 [00:15<00:01, 225.04it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3053/3257 [00:15<00:00, 239.10it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3078/3257 [00:15<00:01, 141.60it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3101/3257 [00:15<00:00, 158.17it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3128/3257 [00:16<00:00, 180.69it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3150/3257 [00:16<00:00, 186.50it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3175/3257 [00:16<00:00, 199.33it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3198/3257 [00:16<00:00, 206.96it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3221/3257 [00:16<00:00, 208.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3252/3257 [00:16<00:00, 235.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:16<00:00, 196.33it/s]
2023-02-07 20:48:38.293 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:48:38,294][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d355,n5,mc7,s0.953277,t4>', 'datetime': '2023-02-07T20:48:38.294728', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:48:38,295][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:48:38,296][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:48:38,690][gensim.models.doc2vec][INFO] - collected 21699 word types and 3257 unique tags from a corpus of 3257 examples and 4367244 words
[2023-02-07 20:48:38,690][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:48:38,721][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 9824 unique words (45.27% of original 21699, drops 11875)', 'datetime': '2023-02-07T20:48:38.721071', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:48:38,721][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 4333599 word corpus (99.23% of original 4367244, drops 33645)', 'datetime': '2023-02-07T20:48:38.721456', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:48:38,755][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 21699 items
[2023-02-07 20:48:38,756][gensim.models.word2vec][INFO] - sample=0.953277 downsamples 0 most-common words
[2023-02-07 20:48:38,756][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 4333599 word corpus (100.0%% of prior 4333599)', 'datetime': '2023-02-07T20:48:38.756223', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:48:38,814][gensim.models.word2vec][INFO] - estimated required memory for 9824 words and 355 dimensions: 38088500 bytes
[2023-02-07 20:48:38,814][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:48:38,832][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 9824 vocabulary and 355 features, using sg=1 hs=0 sample=0.9532771072923014 negative=5 window=2 shrink_windows=True', 'datetime': '2023-02-07T20:48:38.832710', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:48:39,836][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 56.34% examples, 2503762 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:40,559][gensim.models.word2vec][INFO] - EPOCH 0: training on 4367244 raw words (4335166 effective words) took 1.7s, 2514010 effective words/s
[2023-02-07 20:48:41,568][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 61.68% examples, 2696851 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:42,175][gensim.models.word2vec][INFO] - EPOCH 1: training on 4367244 raw words (4335166 effective words) took 1.6s, 2684345 effective words/s
[2023-02-07 20:48:43,178][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 60.82% examples, 2681132 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:43,791][gensim.models.word2vec][INFO] - EPOCH 2: training on 4367244 raw words (4335166 effective words) took 1.6s, 2684185 effective words/s
[2023-02-07 20:48:44,796][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 60.88% examples, 2674794 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:48:45,405][gensim.models.word2vec][INFO] - EPOCH 3: training on 4367244 raw words (4335166 effective words) took 1.6s, 2689998 effective words/s
[2023-02-07 20:48:46,407][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 61.68% examples, 2718832 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:48:47,060][gensim.models.word2vec][INFO] - EPOCH 4: training on 4367244 raw words (4335166 effective words) took 1.7s, 2621362 effective words/s
[2023-02-07 20:48:48,063][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 54.50% examples, 2422309 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:48,861][gensim.models.word2vec][INFO] - EPOCH 5: training on 4367244 raw words (4335166 effective words) took 1.8s, 2410942 effective words/s
[2023-02-07 20:48:49,864][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 53.39% examples, 2377122 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:50,691][gensim.models.word2vec][INFO] - EPOCH 6: training on 4367244 raw words (4335166 effective words) took 1.8s, 2370994 effective words/s
[2023-02-07 20:48:51,697][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 54.10% examples, 2397474 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:52,506][gensim.models.word2vec][INFO] - EPOCH 7: training on 4367244 raw words (4335166 effective words) took 1.8s, 2392652 effective words/s
[2023-02-07 20:48:53,508][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 53.85% examples, 2397072 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:54,311][gensim.models.word2vec][INFO] - EPOCH 8: training on 4367244 raw words (4335166 effective words) took 1.8s, 2404519 effective words/s
[2023-02-07 20:48:55,315][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 53.67% examples, 2386230 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:56,034][gensim.models.word2vec][INFO] - EPOCH 9: training on 4367244 raw words (4335166 effective words) took 1.7s, 2520826 effective words/s
[2023-02-07 20:48:57,036][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 63.31% examples, 2795844 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:57,628][gensim.models.word2vec][INFO] - EPOCH 10: training on 4367244 raw words (4335166 effective words) took 1.6s, 2721938 effective words/s
[2023-02-07 20:48:58,634][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 58.86% examples, 2598844 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:48:59,301][gensim.models.word2vec][INFO] - EPOCH 11: training on 4367244 raw words (4335166 effective words) took 1.7s, 2592741 effective words/s
[2023-02-07 20:49:00,304][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 58.03% examples, 2572762 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:49:00,983][gensim.models.word2vec][INFO] - EPOCH 12: training on 4367244 raw words (4335166 effective words) took 1.7s, 2580311 effective words/s
[2023-02-07 20:49:01,992][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 58.03% examples, 2554856 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:49:02,687][gensim.models.word2vec][INFO] - EPOCH 13: training on 4367244 raw words (4335166 effective words) took 1.7s, 2546516 effective words/s
[2023-02-07 20:49:03,692][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 57.32% examples, 2534672 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:49:04,396][gensim.models.word2vec][INFO] - EPOCH 14: training on 4367244 raw words (4335166 effective words) took 1.7s, 2539085 effective words/s
[2023-02-07 20:49:04,397][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 65508660 raw words (65027490 effective words) took 25.6s, 2543692 effective words/s', 'datetime': '2023-02-07T20:49:04.397348', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:49:04.397 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:49:06,526][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204812-jymsvvkw/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:49:06.526721', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:49:06,527][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:49:06,575][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204812-jymsvvkw/files/../tmp/embedding_model.pt
2023-02-07 20:49:06.575 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:49:08.553 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:49:09.241 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:49:11.609 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 1.0506646432609479, 'test_mae': 0.7911140418217226, 'test_r2': -2.7662851556534864}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.9
wandb: percentage 0.54726
wandb:   test_mae 0.79111
wandb:   test_mse 1.05066
wandb:    test_r2 -2.76629
wandb: 
wandb: üöÄ View run curious-sweep-99 at: https://wandb.ai/xiaoqiz/mof2vec/runs/jymsvvkw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_204812-jymsvvkw/logs
wandb: Agent Starting Run: x14seto2 with config:
wandb: 	data.data.wl_step: 7
wandb: 	data.nn.batch_size: 432
wandb: 	model.gensim.alpha: 0.008570349858204577
wandb: 	model.gensim.dm: 0
wandb: 	model.gensim.min_count: 10
wandb: 	model.gensim.sample: 0.8334410415710378
wandb: 	model.gensim.vector_size: 396
wandb: 	model.gensim.window: 5
wandb: 	model.sklearn.learning_rate: 0.004001019827188635
wandb: 	model.sklearn.max_depth: 41
wandb: 	model.sklearn.min_child_weight: 0.04057058556646475
wandb: 	model.sklearn.n_estimators: 1313
wandb: 	model.sklearn.num_leaves: 205
wandb: 	model.sklearn.reg_alpha: 0.010760954539897463
wandb: 	model.sklearn.reg_lambda: 0.2123800157257271
wandb: 	model.sklearn.subsample: 0.5542793261178415
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204922-x14seto2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-100
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xiaoqiz/mof2vec
wandb: üßπ View sweep at https://wandb.ai/xiaoqiz/mof2vec/sweeps/5qa4vj5i
wandb: üöÄ View run at https://wandb.ai/xiaoqiz/mof2vec/runs/x14seto2
2023-02-07 20:49:30.104 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.data.wl_step with 7 for sweep.
2023-02-07 20:49:30.105 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding data.nn.batch_size with 432 for sweep.
2023-02-07 20:49:30.105 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.alpha with 0.008570349858204577 for sweep.
2023-02-07 20:49:30.105 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.dm with 0 for sweep.
2023-02-07 20:49:30.106 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.min_count with 10 for sweep.
2023-02-07 20:49:30.106 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.sample with 0.8334410415710378 for sweep.
2023-02-07 20:49:30.106 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.vector_size with 396 for sweep.
2023-02-07 20:49:30.106 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.gensim.window with 5 for sweep.
2023-02-07 20:49:30.107 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.learning_rate with 0.004001019827188635 for sweep.
2023-02-07 20:49:30.107 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.max_depth with 41 for sweep.
2023-02-07 20:49:30.108 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.min_child_weight with 0.04057058556646475 for sweep.
2023-02-07 20:49:30.108 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.n_estimators with 1313 for sweep.
2023-02-07 20:49:30.108 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.num_leaves with 205 for sweep.
2023-02-07 20:49:30.108 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_alpha with 0.010760954539897463 for sweep.
2023-02-07 20:49:30.109 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.reg_lambda with 0.2123800157257271 for sweep.
2023-02-07 20:49:30.109 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:22 - Overriding model.sklearn.subsample with 0.5542793261178415 for sweep.
2023-02-07 20:49:30.109 | DEBUG    | mofgraph2vec.trainer.sklearn_workflow:train:25 - Completed overriding config for sweep.
2023-02-07 20:49:30.115 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:32 - {'logger': {'project': 'mof2vec', 'entity': 'xiaoqiz', 'mode': 'online', 'tags': 'rsm, kh_co2, xgb'}, 'seed': 1234, 'load_model': False, 'model_checkpoint': None, 'sweep': {'count': 100, 'id': None, 'config': {'method': 'bayes', 'metric': {'name': 'test_mse', 'goal': 'minimize'}, 'early_terminate': {'type': 'hyperband', 'min_iter': 5}, 'parameters': {'data.data.wl_step': {'min': 1, 'max': 8, 'distribution': 'int_uniform'}, 'model.gensim.vector_size': {'min': 8, 'max': 512, 'distribution': 'int_uniform'}, 'model.gensim.window': {'min': 1, 'max': 20, 'distribution': 'int_uniform'}, 'model.gensim.min_count': {'min': 1, 'max': 10, 'distribution': 'int_uniform'}, 'model.gensim.dm': {'values': [0, 1]}, 'model.gensim.sample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.gensim.alpha': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}, 'data.nn.batch_size': {'min': 32, 'max': 1024, 'distribution': 'int_uniform'}, 'model.sklearn.n_estimators': {'min': 10, 'max': 5000, 'distribution': 'int_uniform'}, 'model.sklearn.max_depth': {'min': 5, 'max': 100, 'distribution': 'int_uniform'}, 'model.sklearn.num_leaves': {'min': 5, 'max': 500, 'distribution': 'int_uniform'}, 'model.sklearn.reg_alpha': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.reg_lambda': {'min': -6, 'max': 0, 'distribution': 'log_uniform'}, 'model.sklearn.subsample': {'min': 0.2, 'max': 1.0, 'distribution': 'uniform'}, 'model.sklearn.min_child_weight': {'min': 0.001, 'max': 0.1, 'distribution': 'uniform'}, 'model.sklearn.learning_rate': {'min': -8, 'max': 0, 'distribution': 'log_uniform'}}}}, 'data': {'data': {'_target_': 'mofgraph2vec.graph.mof2doc.MOF2doc', 'cif_path': ['../../data/cifs/rsm/'], 'subsample': None, 'wl_step': 7}, 'nn': {'task': ['logKH_CO2'], 'MOF_id': 'cif.label', 'label_path': '../../data/data.csv', 'embedding_path': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204922-x14seto2/files/../tmp/embedding.csv', 'train_frac': 0.8, 'valid_frac': 0.1, 'test_frac': 0.1, 'batch_size': 432, 'num_workers': None}}, 'model': {'gensim': {'vector_size': 396, 'window': 5, 'min_count': 10, 'dm': 0, 'sample': 0.8334410415710378, 'workers': 4, 'alpha': 0.008570349858204577, 'epochs': 15}, 'cv': False, 'sklearn': {'_target_': 'mofgraph2vec.model.gbt.Regressor', 'n_estimators': 1313, 'max_depth': 41, 'num_leaves': 205, 'reg_alpha': 0.010760954539897463, 'reg_lambda': 0.2123800157257271, 'subsample': 0.5542793261178415, 'min_child_weight': 0.04057058556646475, 'n_jobs': 4, 'learning_rate': 0.004001019827188635}}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'auto_lr_find': True, 'max_epochs': 500}}
  0%|          | 0/3257 [00:00<?, ?it/s]  0%|          | 14/3257 [00:00<00:23, 138.05it/s]  1%|          | 30/3257 [00:00<00:21, 149.59it/s]  1%|‚ñè         | 46/3257 [00:00<00:21, 151.62it/s]  2%|‚ñè         | 62/3257 [00:00<00:21, 152.14it/s]  2%|‚ñè         | 79/3257 [00:00<00:20, 157.96it/s]  3%|‚ñé         | 95/3257 [00:00<00:19, 158.38it/s]  3%|‚ñé         | 111/3257 [00:00<00:20, 150.44it/s]  4%|‚ñç         | 128/3257 [00:00<00:20, 155.76it/s]  5%|‚ñç         | 148/3257 [00:00<00:18, 167.47it/s]  5%|‚ñå         | 165/3257 [00:01<00:19, 157.35it/s]  6%|‚ñå         | 181/3257 [00:01<00:19, 158.09it/s]  6%|‚ñå         | 200/3257 [00:01<00:18, 165.96it/s]  7%|‚ñã         | 217/3257 [00:01<00:18, 165.62it/s]  7%|‚ñã         | 237/3257 [00:01<00:17, 169.01it/s]  8%|‚ñä         | 254/3257 [00:01<00:17, 168.71it/s]  8%|‚ñä         | 271/3257 [00:01<00:18, 161.32it/s]  9%|‚ñâ         | 292/3257 [00:01<00:17, 173.36it/s] 10%|‚ñâ         | 310/3257 [00:01<00:17, 168.68it/s] 10%|‚ñà         | 328/3257 [00:02<00:17, 166.89it/s] 11%|‚ñà         | 345/3257 [00:02<00:18, 156.92it/s] 11%|‚ñà         | 362/3257 [00:02<00:18, 159.75it/s] 12%|‚ñà‚ñè        | 379/3257 [00:02<00:19, 149.54it/s] 12%|‚ñà‚ñè        | 395/3257 [00:02<00:19, 147.03it/s] 13%|‚ñà‚ñé        | 411/3257 [00:02<00:18, 150.38it/s] 13%|‚ñà‚ñé        | 427/3257 [00:02<00:21, 131.45it/s] 14%|‚ñà‚ñé        | 442/3257 [00:02<00:21, 133.68it/s] 14%|‚ñà‚ñç        | 458/3257 [00:02<00:20, 138.15it/s] 15%|‚ñà‚ñç        | 474/3257 [00:03<00:19, 141.85it/s] 15%|‚ñà‚ñå        | 489/3257 [00:03<00:19, 140.72it/s] 16%|‚ñà‚ñå        | 505/3257 [00:03<00:19, 143.89it/s] 16%|‚ñà‚ñå        | 522/3257 [00:03<00:18, 146.84it/s] 16%|‚ñà‚ñã        | 537/3257 [00:03<00:18, 144.28it/s] 17%|‚ñà‚ñã        | 552/3257 [00:03<00:18, 145.28it/s] 17%|‚ñà‚ñã        | 567/3257 [00:03<00:19, 135.10it/s] 18%|‚ñà‚ñä        | 581/3257 [00:03<00:20, 128.97it/s] 18%|‚ñà‚ñä        | 599/3257 [00:03<00:19, 138.06it/s] 19%|‚ñà‚ñâ        | 617/3257 [00:04<00:17, 149.15it/s] 19%|‚ñà‚ñâ        | 633/3257 [00:04<00:18, 143.59it/s] 20%|‚ñà‚ñâ        | 648/3257 [00:04<00:18, 137.48it/s] 20%|‚ñà‚ñà        | 662/3257 [00:04<00:20, 127.98it/s] 21%|‚ñà‚ñà        | 678/3257 [00:04<00:19, 133.73it/s] 21%|‚ñà‚ñà        | 692/3257 [00:04<00:19, 134.20it/s] 22%|‚ñà‚ñà‚ñè       | 708/3257 [00:04<00:18, 140.62it/s] 22%|‚ñà‚ñà‚ñè       | 723/3257 [00:04<00:18, 134.35it/s] 23%|‚ñà‚ñà‚ñé       | 738/3257 [00:04<00:18, 133.01it/s] 23%|‚ñà‚ñà‚ñé       | 754/3257 [00:05<00:17, 140.15it/s] 24%|‚ñà‚ñà‚ñé       | 770/3257 [00:05<00:17, 145.19it/s] 24%|‚ñà‚ñà‚ñç       | 785/3257 [00:05<00:17, 139.75it/s] 25%|‚ñà‚ñà‚ñç       | 804/3257 [00:05<00:16, 147.71it/s] 25%|‚ñà‚ñà‚ñå       | 820/3257 [00:05<00:16, 147.86it/s] 26%|‚ñà‚ñà‚ñå       | 835/3257 [00:05<00:16, 144.40it/s] 26%|‚ñà‚ñà‚ñå       | 850/3257 [00:05<00:17, 135.07it/s] 27%|‚ñà‚ñà‚ñã       | 866/3257 [00:05<00:16, 141.48it/s] 27%|‚ñà‚ñà‚ñã       | 881/3257 [00:05<00:16, 142.70it/s] 28%|‚ñà‚ñà‚ñä       | 897/3257 [00:06<00:16, 146.77it/s] 28%|‚ñà‚ñà‚ñä       | 914/3257 [00:06<00:15, 147.26it/s] 29%|‚ñà‚ñà‚ñä       | 931/3257 [00:06<00:15, 153.65it/s] 29%|‚ñà‚ñà‚ñâ       | 948/3257 [00:06<00:14, 154.12it/s] 30%|‚ñà‚ñà‚ñâ       | 966/3257 [00:06<00:14, 159.91it/s] 30%|‚ñà‚ñà‚ñà       | 983/3257 [00:06<00:14, 152.71it/s] 31%|‚ñà‚ñà‚ñà       | 999/3257 [00:06<00:15, 147.57it/s] 31%|‚ñà‚ñà‚ñà       | 1014/3257 [00:06<00:15, 145.44it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1029/3257 [00:07<00:25, 86.90it/s]  32%|‚ñà‚ñà‚ñà‚ñè      | 1041/3257 [00:07<00:23, 93.03it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1056/3257 [00:07<00:20, 104.89it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1073/3257 [00:07<00:18, 120.05it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1088/3257 [00:07<00:17, 124.59it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1103/3257 [00:07<00:16, 130.62it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1118/3257 [00:07<00:15, 134.14it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1133/3257 [00:07<00:15, 132.93it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1147/3257 [00:08<00:15, 132.87it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 1166/3257 [00:08<00:14, 147.00it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 1182/3257 [00:08<00:14, 140.95it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1198/3257 [00:08<00:14, 145.55it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 1213/3257 [00:08<00:14, 141.39it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1235/3257 [00:08<00:12, 163.09it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 1252/3257 [00:08<00:12, 163.93it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 1271/3257 [00:08<00:11, 169.46it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 1289/3257 [00:08<00:12, 159.81it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 1308/3257 [00:09<00:11, 167.36it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 1328/3257 [00:09<00:11, 172.35it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1349/3257 [00:09<00:10, 181.48it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 1368/3257 [00:09<00:10, 174.41it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1386/3257 [00:09<00:11, 166.62it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1408/3257 [00:09<00:10, 179.89it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1429/3257 [00:09<00:09, 187.56it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1448/3257 [00:09<00:09, 187.75it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1471/3257 [00:09<00:09, 197.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1491/3257 [00:09<00:09, 194.88it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1512/3257 [00:10<00:08, 196.59it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1532/3257 [00:10<00:09, 179.57it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1551/3257 [00:10<00:09, 172.56it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1569/3257 [00:10<00:09, 171.32it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1587/3257 [00:10<00:09, 169.60it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1606/3257 [00:10<00:09, 173.57it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1624/3257 [00:10<00:09, 175.34it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1642/3257 [00:10<00:09, 167.89it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1659/3257 [00:10<00:09, 167.60it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1676/3257 [00:11<00:09, 158.65it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1692/3257 [00:11<00:09, 158.32it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1711/3257 [00:11<00:09, 166.39it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1728/3257 [00:11<00:09, 157.68it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1744/3257 [00:11<00:09, 154.47it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1763/3257 [00:11<00:09, 162.50it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1782/3257 [00:11<00:08, 170.21it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1800/3257 [00:11<00:08, 168.18it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1817/3257 [00:11<00:08, 166.79it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1834/3257 [00:12<00:08, 165.06it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1853/3257 [00:12<00:08, 171.46it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1872/3257 [00:12<00:07, 176.35it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1890/3257 [00:12<00:07, 173.76it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1909/3257 [00:12<00:07, 177.91it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1927/3257 [00:12<00:07, 169.43it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1952/3257 [00:12<00:06, 192.01it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1972/3257 [00:12<00:06, 194.01it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1992/3257 [00:12<00:06, 182.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2011/3257 [00:13<00:06, 181.34it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2033/3257 [00:13<00:06, 185.01it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2052/3257 [00:13<00:07, 166.66it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2070/3257 [00:13<00:07, 163.26it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2087/3257 [00:13<00:07, 164.34it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2104/3257 [00:13<00:06, 164.95it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2121/3257 [00:13<00:07, 155.95it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2139/3257 [00:13<00:06, 162.05it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2156/3257 [00:13<00:06, 159.46it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2177/3257 [00:14<00:06, 172.28it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2195/3257 [00:14<00:11, 96.54it/s]  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2210/3257 [00:14<00:09, 104.99it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 2230/3257 [00:14<00:08, 123.53it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2246/3257 [00:14<00:07, 129.35it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2262/3257 [00:14<00:07, 136.43it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2278/3257 [00:14<00:07, 138.66it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2299/3257 [00:15<00:06, 154.24it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2321/3257 [00:15<00:05, 169.53it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2343/3257 [00:15<00:05, 182.50it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2364/3257 [00:15<00:04, 189.95it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2384/3257 [00:15<00:04, 191.88it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2404/3257 [00:15<00:04, 193.47it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2424/3257 [00:15<00:04, 182.05it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2443/3257 [00:15<00:04, 167.64it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 2465/3257 [00:15<00:04, 179.68it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2484/3257 [00:16<00:04, 180.85it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2508/3257 [00:16<00:03, 196.82it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2529/3257 [00:16<00:03, 198.44it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 2550/3257 [00:16<00:03, 193.82it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2570/3257 [00:16<00:03, 173.83it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 2588/3257 [00:16<00:03, 173.72it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2611/3257 [00:16<00:03, 188.19it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2634/3257 [00:16<00:03, 198.75it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2655/3257 [00:16<00:03, 192.55it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2675/3257 [00:17<00:03, 183.92it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2694/3257 [00:17<00:03, 182.06it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2713/3257 [00:17<00:03, 169.63it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2732/3257 [00:17<00:03, 174.01it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2755/3257 [00:17<00:02, 187.24it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2774/3257 [00:17<00:02, 173.82it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2798/3257 [00:17<00:02, 190.51it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2818/3257 [00:17<00:02, 179.17it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2837/3257 [00:17<00:02, 175.45it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2858/3257 [00:18<00:02, 184.40it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2883/3257 [00:18<00:01, 200.81it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2904/3257 [00:18<00:01, 179.89it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2928/3257 [00:18<00:01, 185.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2947/3257 [00:18<00:01, 179.43it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2966/3257 [00:18<00:01, 181.78it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2985/3257 [00:18<00:01, 173.64it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3008/3257 [00:18<00:01, 188.07it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3028/3257 [00:18<00:01, 186.45it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3053/3257 [00:19<00:01, 202.42it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3078/3257 [00:19<00:00, 213.84it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3100/3257 [00:19<00:00, 209.71it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3123/3257 [00:19<00:00, 212.18it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3145/3257 [00:19<00:00, 183.63it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3165/3257 [00:19<00:00, 172.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3183/3257 [00:19<00:00, 162.61it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3203/3257 [00:19<00:00, 169.28it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3221/3257 [00:20<00:00, 158.65it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 3240/3257 [00:20<00:00, 165.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 162.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3257/3257 [00:20<00:00, 160.52it/s]
2023-02-07 20:49:51.358 | INFO     | mofgraph2vec.trainer.unsupervised:train:22 - Instantiate model. 
[2023-02-07 20:49:51,359][gensim.utils][INFO] - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d396,n5,mc10,s0.833441,t4>', 'datetime': '2023-02-07T20:49:51.359442', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'created'}
[2023-02-07 20:49:51,359][gensim.models.doc2vec][INFO] - collecting all words and their counts
[2023-02-07 20:49:51,360][gensim.models.doc2vec][INFO] - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
[2023-02-07 20:49:51,966][gensim.models.doc2vec][INFO] - collected 42701 word types and 3257 unique tags from a corpus of 3257 examples and 5822992 words
[2023-02-07 20:49:51,967][gensim.models.word2vec][INFO] - Creating a fresh vocabulary
[2023-02-07 20:49:52,018][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 retains 14497 unique words (33.95% of original 42701, drops 28204)', 'datetime': '2023-02-07T20:49:52.018549', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:49:52,020][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 5720668 word corpus (98.24% of original 5822992, drops 102324)', 'datetime': '2023-02-07T20:49:52.020100', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:49:52,073][gensim.models.word2vec][INFO] - deleting the raw counts dictionary of 42701 items
[2023-02-07 20:49:52,074][gensim.models.word2vec][INFO] - sample=0.833441 downsamples 0 most-common words
[2023-02-07 20:49:52,075][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 5720668 word corpus (100.0%% of prior 5720668)', 'datetime': '2023-02-07T20:49:52.075014', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}
[2023-02-07 20:49:52,165][gensim.models.word2vec][INFO] - estimated required memory for 14497 words and 396 dimensions: 58985484 bytes
[2023-02-07 20:49:52,165][gensim.models.word2vec][INFO] - resetting layer weights
[2023-02-07 20:49:52,199][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training model with 4 workers on 14497 vocabulary and 396 features, using sg=1 hs=0 sample=0.8334410415710378 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-07T20:49:52.199082', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
[2023-02-07 20:49:53,205][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 29.41% examples, 1676217 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:49:54,206][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 58.21% examples, 1691345 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:49:55,210][gensim.models.word2vec][INFO] - EPOCH 0 - PROGRESS: at 89.87% examples, 1710993 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:49:55,519][gensim.models.word2vec][INFO] - EPOCH 0: training on 5822992 raw words (5694995 effective words) took 3.3s, 1717791 effective words/s
[2023-02-07 20:49:56,521][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 34.69% examples, 2004191 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:49:57,524][gensim.models.word2vec][INFO] - EPOCH 1 - PROGRESS: at 68.04% examples, 1975576 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:49:58,402][gensim.models.word2vec][INFO] - EPOCH 1: training on 5822992 raw words (5694995 effective words) took 2.9s, 1976821 effective words/s
[2023-02-07 20:49:59,405][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 45.38% examples, 2631605 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:00,406][gensim.models.word2vec][INFO] - EPOCH 2 - PROGRESS: at 86.25% examples, 2472177 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:00,734][gensim.models.word2vec][INFO] - EPOCH 2: training on 5822992 raw words (5694995 effective words) took 2.3s, 2443546 effective words/s
[2023-02-07 20:50:01,736][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 38.99% examples, 2266380 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:50:02,737][gensim.models.word2vec][INFO] - EPOCH 3 - PROGRESS: at 79.95% examples, 2299230 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:03,205][gensim.models.word2vec][INFO] - EPOCH 3: training on 5822992 raw words (5694995 effective words) took 2.5s, 2305768 effective words/s
[2023-02-07 20:50:04,209][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 39.24% examples, 2290953 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:05,211][gensim.models.word2vec][INFO] - EPOCH 4 - PROGRESS: at 79.40% examples, 2283234 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:05,708][gensim.models.word2vec][INFO] - EPOCH 4: training on 5822992 raw words (5694995 effective words) took 2.5s, 2276762 effective words/s
[2023-02-07 20:50:06,713][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 39.15% examples, 2285726 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:07,717][gensim.models.word2vec][INFO] - EPOCH 5 - PROGRESS: at 79.95% examples, 2295943 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:08,178][gensim.models.word2vec][INFO] - EPOCH 5: training on 5822992 raw words (5694995 effective words) took 2.5s, 2309973 effective words/s
[2023-02-07 20:50:09,183][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 40.56% examples, 2368628 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:10,186][gensim.models.word2vec][INFO] - EPOCH 6 - PROGRESS: at 76.94% examples, 2209989 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:10,799][gensim.models.word2vec][INFO] - EPOCH 6: training on 5822992 raw words (5694995 effective words) took 2.6s, 2176088 effective words/s
[2023-02-07 20:50:11,801][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 34.97% examples, 2021532 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:50:12,804][gensim.models.word2vec][INFO] - EPOCH 7 - PROGRESS: at 70.10% examples, 2035373 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:13,599][gensim.models.word2vec][INFO] - EPOCH 7: training on 5822992 raw words (5694995 effective words) took 2.8s, 2035053 effective words/s
[2023-02-07 20:50:14,605][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 35.40% examples, 2043609 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:15,605][gensim.models.word2vec][INFO] - EPOCH 8 - PROGRESS: at 70.53% examples, 2048906 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:50:16,385][gensim.models.word2vec][INFO] - EPOCH 8: training on 5822992 raw words (5694995 effective words) took 2.8s, 2046070 effective words/s
[2023-02-07 20:50:17,388][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 34.94% examples, 2020839 words/s, in_qsize 8, out_qsize 2
[2023-02-07 20:50:18,392][gensim.models.word2vec][INFO] - EPOCH 9 - PROGRESS: at 77.96% examples, 2234669 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:18,836][gensim.models.word2vec][INFO] - EPOCH 9: training on 5822992 raw words (5694995 effective words) took 2.4s, 2325911 effective words/s
[2023-02-07 20:50:19,842][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 42.59% examples, 2492682 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:20,844][gensim.models.word2vec][INFO] - EPOCH 10 - PROGRESS: at 85.60% examples, 2450972 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:50:21,168][gensim.models.word2vec][INFO] - EPOCH 10: training on 5822992 raw words (5694995 effective words) took 2.3s, 2444235 effective words/s
[2023-02-07 20:50:22,172][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 40.47% examples, 2363853 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:23,178][gensim.models.word2vec][INFO] - EPOCH 11 - PROGRESS: at 82.16% examples, 2349899 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:23,594][gensim.models.word2vec][INFO] - EPOCH 11: training on 5822992 raw words (5694995 effective words) took 2.4s, 2350103 effective words/s
[2023-02-07 20:50:24,605][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 39.94% examples, 2317819 words/s, in_qsize 8, out_qsize 1
[2023-02-07 20:50:25,606][gensim.models.word2vec][INFO] - EPOCH 12 - PROGRESS: at 82.16% examples, 2346866 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:26,015][gensim.models.word2vec][INFO] - EPOCH 12: training on 5822992 raw words (5694995 effective words) took 2.4s, 2353305 effective words/s
[2023-02-07 20:50:27,021][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 41.42% examples, 2415099 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:28,024][gensim.models.word2vec][INFO] - EPOCH 13 - PROGRESS: at 86.00% examples, 2459913 words/s, in_qsize 8, out_qsize 0
[2023-02-07 20:50:28,337][gensim.models.word2vec][INFO] - EPOCH 13: training on 5822992 raw words (5694995 effective words) took 2.3s, 2456190 effective words/s
[2023-02-07 20:50:29,344][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 36.44% examples, 2105193 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:50:30,355][gensim.models.word2vec][INFO] - EPOCH 14 - PROGRESS: at 72.92% examples, 2092143 words/s, in_qsize 7, out_qsize 0
[2023-02-07 20:50:31,067][gensim.models.word2vec][INFO] - EPOCH 14: training on 5822992 raw words (5694995 effective words) took 2.7s, 2087951 effective words/s
[2023-02-07 20:50:31,067][gensim.utils][INFO] - Doc2Vec lifecycle event {'msg': 'training on 87344880 raw words (85424925 effective words) took 38.9s, 2197804 effective words/s', 'datetime': '2023-02-07T20:50:31.067863', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'train'}
2023-02-07 20:50:31.068 | INFO     | mofgraph2vec.trainer.unsupervised:train:34 - Evaluating the model performance. 
[2023-02-07 20:50:35,337][gensim.utils][INFO] - Doc2Vec lifecycle event {'fname_or_handle': '/scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204922-x14seto2/files/../tmp/embedding_model.pt', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-07T20:50:35.337293', 'gensim': '4.3.0', 'python': '3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]', 'platform': 'Linux-4.18.0-348.23.1.el8_5.x86_64-x86_64-with-glibc2.17', 'event': 'saving'}
[2023-02-07 20:50:35,338][gensim.utils][INFO] - not storing attribute cum_table
[2023-02-07 20:50:35,424][gensim.utils][INFO] - saved /scratch/xiazhang/mofgraph2vec/experiments/workflow/wandb/run-20230207_204922-x14seto2/files/../tmp/embedding_model.pt
2023-02-07 20:50:35.424 | INFO     | mofgraph2vec.trainer.unsupervised:train:38 - Saving embedded vectors. 
2023-02-07 20:50:37.715 | INFO     | mofgraph2vec.data.datamodule:__init__:66 - Train: 2637 Valid: 294 Test: 326
2023-02-07 20:50:38.411 | INFO     | mofgraph2vec.trainer.sklearn_supervised:train:26 - Start fitting xgbt model. 
2023-02-07 20:50:41.074 | INFO     | mofgraph2vec.trainer.sklearn_workflow:train:35 - Model performance: {'test_mse': 0.9505561640847088, 'test_mae': 0.7383092496018469, 'test_r2': -2.1448985811769137}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:   accuracy ‚ñÅ
wandb: percentage ‚ñÅ
wandb:   test_mae ‚ñÅ
wandb:   test_mse ‚ñÅ
wandb:    test_r2 ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   accuracy 0.84
wandb: percentage 0.6605
wandb:   test_mae 0.73831
wandb:   test_mse 0.95056
wandb:    test_r2 -2.1449
wandb: 
wandb: üöÄ View run soft-sweep-100 at: https://wandb.ai/xiaoqiz/mof2vec/runs/x14seto2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230207_204922-x14seto2/logs
